{"version":1,"kind":"Notebook","sha256":"9d711c3358c7d7c747db6f876745988a0a4fe5df634a8e14d87471419bb5aea7","slug":"chapter8-2","location":"/python/chapter8.md","dependencies":[],"frontmatter":{"title":"Chapter 8","numbering":{"heading_1":{"enabled":false},"heading_2":{"enabled":false},"heading_3":{"enabled":false},"heading_4":{"enabled":false},"heading_5":{"enabled":false},"heading_6":{"enabled":false},"title":{"offset":2}},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"content_includes_title":false,"authors":[{"nameParsed":{"literal":"Tobin A. Driscoll","given":"Tobin A.","family":"Driscoll"},"name":"Tobin A. Driscoll","email":"driscoll@udel.edu","id":"contributors-myst-generated-uid-0","corresponding":true},{"nameParsed":{"literal":"Richard J. Braun","given":"Richard J.","family":"Braun"},"name":"Richard J. Braun","id":"contributors-myst-generated-uid-1"}],"github":"https://github.com/fncbook/fnc","math":{"\\float":{"macro":"\\mathbb{F}"},"\\real":{"macro":"\\mathbb{R}"},"\\complex":{"macro":"\\mathbb{C}"},"\\nat":{"macro":"\\mathbb{N}"},"\\integer":{"macro":"\\mathbb{Z}"},"\\rmn":{"macro":"\\mathbb{R}^{#1 \\times #2}"},"\\dd":{"macro":"\\frac{d #1}{d #2}"},"\\ddd":{"macro":"\\frac{d^2 #1}{d #2^2}"},"\\pp":{"macro":"\\frac{\\partial #1}{\\partial #2}"},"\\ppp":{"macro":"\\frac{\\partial^2 #1}{\\partial #2^2}"},"\\ppdd":{"macro":"\\frac{\\partial^2 #1}{\\partial #2 \\partial #3}"},"\\abs":{"macro":"\\left\\lvert #1 \\right\\rvert"},"\\norm":{"macro":"\\left\\lVert #1 \\right\\rVert"},"\\twonorm":{"macro":"\\norm{#1}_2"},"\\onenorm":{"macro":"\\norm{#1}_1"},"\\infnorm":{"macro":"\\norm{#1}_\\infty"},"\\anynorm":{"macro":"\\norm{#1}_#2"},"\\innerprod":{"macro":"\\langle #1,#2 \\rangle"},"\\pr":{"macro":"^{(#1)}"},"\\kron":{"macro":"#1 \\otimes #2"},"\\eye":{"macro":"\\mathbf{e}_#1"},"\\meye":{"macro":"\\mathbf{I}"},"\\Qhat":{"macro":"\\hat{\\mathbf{Q}}"},"\\Rhat":{"macro":"\\hat{\\mathbf{R}}"},"\\bfalpha":{"macro":"\\mathbf{alpha}"},"\\bfdelta":{"macro":"\\mathbf{delta}"},"\\bfzero":{"macro":"\\boldsymbol{0}"},"\\macheps":{"macro":"\\epsilon_\\text{mach}"},"\\fl":{"macro":"\\operatorname{fl}"},"\\diag":{"macro":"\\operatorname{diag}"},"\\ign":{"macro":"\\operatorname{sign}"},"\\Re":{"macro":"\\operatorname{Re}"},"\\Im":{"macro":"\\operatorname{Im}"},"\\ee":{"macro":"\\times 10^"},"\\lnorm":{"macro":"\\|"},"\\rnorm":{"macro":"\\|"},"\\floor":{"macro":"\\lfloor#1\\rfloor"},"\\cI":{"macro":"\\mathcal{I}"},"\\mtx":{"macro":"\\operatorname{mtx}"},"\\myvec":{"macro":"\\operatorname{vec}"},"\\argmin":{"macro":"\\operatorname{argmin}"}},"abbreviations":{"IVP":"initial-value problem","BVP":"boundary-value problem","ONC":"matrix with orthonormal columns","SVD":"singular value decomposition","EVD":"eigenvalue decomposition","SPD":"symmetric positive definite","HPD":"hermitian positive definite","PDE":"partial differential equation","ODE":"ordinary differential equation"},"edit_url":"https://github.com/fncbook/fnc/blob/master/python/chapter8.md","exports":[{"format":"md","filename":"chapter8.md","url":"/build/chapter8-726e0ecb2d038f2f6e0cef7faf5a95ab.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Functions","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"TuevSQNkgf"}],"identifier":"functions","label":"Functions","html_id":"functions","implicit":true,"key":"xj32fFlQNA"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"text","value":"Power iteration","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"ZDhaTWxdll"}],"key":"jbDDPBzSBJ"},{"type":"include","file":"fncbook/fncbook/chapter08.py","literal":true,"filter":{"startAt":"def poweriter","endAt":"return gamma, x"},"children":[{"type":"code","value":"def poweriter(A, numiter):\n    \"\"\"\n    poweriter(A, numiter)\n\n    Perform numiter power iterations with the matrix A, starting from a random vector, \n    and return a vector of eigenvalue estimates and the final eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    for k in range(numiter):\n        y = A @ x\n        m = np.argmax(abs(y))\n        gamma[k] = y[m] / x[m]\n        x = y / y[m]\n\n    return gamma, x","lang":"python","showLineNumbers":true,"filename":"poweriter.py","key":"iPgW9hOtm5"}],"key":"HGdAJc7d4s"}],"label":"function-poweriter-python","identifier":"function-poweriter-python","html_id":"function-poweriter-python","key":"HIMLy2uIgu"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"text","value":"Inverse iteration","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"mrUqzacyNq"}],"key":"lQXUOAXyCB"},{"type":"include","file":"fncbook/fncbook/chapter08.py","literal":true,"filter":{"startAt":"def inviter","endAt":"return gamma, x"},"children":[{"type":"code","value":"def inviter(A, s, numiter):\n    \"\"\"\n    inviter(A, s, numiter)\n\n    Perform numiter inverse iterations with the matrix A and shift s, starting\n    from a random vector, and return a vector of eigenvalue estimates and the final\n    eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    PL, U = lu(A - s * np.eye(n), permute_l=True)\n    for k in range(numiter):\n        y = np.linalg.solve(U, np.linalg.solve(PL, x))\n        m = np.argmax(abs(y))\n        gamma[k] = x[m] / y[m] + s\n        x = y / y[m]\n\n    return gamma, x","lang":"python","showLineNumbers":true,"filename":"inviter.py","key":"PZYftROkeJ"}],"key":"gwNGeTIn0u"}],"label":"function-inviter-python","identifier":"function-inviter-python","html_id":"function-inviter-python","key":"Xn9cNXO4xu"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"text","value":"Arnoldi iteration","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"m77EubC1GS"}],"key":"sV2G24iG3F"},{"type":"include","file":"fncbook/fncbook/chapter08.py","literal":true,"filter":{"startAt":"def arnoldi","endAt":"return Q, H"},"children":[{"type":"code","value":"def arnoldi(A, u, m):\n    \"\"\"\n    arnoldi(A, u, m)\n\n    Perform the Arnoldi iteration for A starting with vector u, out to the Krylov\n    subspace of degree m. Return the orthonormal basis (m+1 columns) and the upper\n    Hessenberg H of size m+1 by m.\n    \"\"\"\n    n = u.size\n    Q = np.zeros([n, m + 1])\n    H = np.zeros([m + 1, m])\n    Q[:, 0] = u / np.linalg.norm(u)\n    for j in range(m):\n        # Find the new direction that extends the Krylov subspace.\n        v = A @ Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        # Normalize and store the new basis vector.\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n    return Q, H","lang":"python","showLineNumbers":true,"filename":"arnoldi.py","key":"GIOMd8nWlz"}],"key":"f3RjF5F1rw"}],"label":"function-arnoldi-python","identifier":"function-arnoldi-python","html_id":"function-arnoldi-python","key":"enEISwgCow"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"text","value":"GMRES","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"VYJveNJJgt"}],"key":"L0foIxOGVe"},{"type":"include","file":"fncbook/fncbook/chapter08.py","literal":true,"filter":{"startAt":"def gmres","endAt":"return x, residual"},"children":[{"type":"code","value":"def gmres(A, b, m):\n    \"\"\"\n    gmres(A, b, m)\n\n    Do m iterations of GMRES for the linear system A*x=b. Return the final solution\n    estimate x and a vector with the history of residual norms. (This function is for\n    demo only, not practical use.)\n    \"\"\"\n    n = len(b)\n    Q = np.zeros([n, m + 1])\n    Q[:, 0] = b / np.linalg.norm(b)\n    H = np.zeros([m + 1, m])\n\n    # Initial \"solution\" is zero.\n    residual = np.hstack([np.linalg.norm(b), np.zeros(m)])\n\n    for j in range(m):\n        # Next step of Arnoldi iteration.\n        v = A @ Q[:, j]\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n        # Solve the minimum residual problem.\n        r = np.hstack([np.linalg.norm(b), np.zeros(j + 1)])\n        z = np.linalg.lstsq(H[:j + 2, :j + 1], r)[0]\n        x = Q[:, :j + 1] @ z\n        residual[j + 1] = np.linalg.norm(A @ x - b)\n\n    return x, residual","lang":"python","showLineNumbers":true,"filename":"gmres.py","key":"xykZw7kxuc"}],"key":"mP20Utd5hI"}],"label":"function-gmres-python","identifier":"function-gmres-python","html_id":"function-gmres-python","key":"kju9PQiLgA"},{"type":"heading","depth":2,"position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"children":[{"type":"text","value":"Examples","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"sOhrXN6tbQ"}],"identifier":"examples","label":"Examples","html_id":"examples","implicit":true,"key":"iaHr7VDBkj"}],"key":"OSldXwqrIy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"exec(open(\"FNC_init.py\").read())","visibility":"show","key":"q7xZnRqIT1"},{"type":"output","id":"UGC4GGXD_jkXEApwXrugi","data":[],"visibility":"show","key":"Q7iVzkZ1yz"}],"data":{"tags":[]},"visibility":"remove","key":"KwETdZFBx9"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"8.1 ","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"dnbbkT6Nl7"},{"type":"link","identifier":"section-krylov-structure","label":"section-krylov-structure","kind":"narrative","position":{"start":{"line":68,"column":5},"end":{"line":68,"column":30}},"url":"/structure-1","internal":true,"dataUrl":"/structure-1.json","children":[{"type":"text","value":"Sparsity and structure","key":"xd0qvNkYcZ"}],"key":"hd6xsnry2z"}],"identifier":"id-8-1","label":"8.1 ","html_id":"id-8-1","implicit":true,"key":"x3Tzb9VFnh"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-structure-sparse","label":"demo-structure-sparse","kind":"proof:example","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":23}},"children":[{"type":"text","value":"Example ","key":"UodB8ZJDZg"},{"type":"text","value":"8.1.1","key":"RA659LNvs2"}],"template":"Example %s","enumerator":"8.1.1","resolved":true,"html_id":"demo-structure-sparse","remote":true,"url":"/structure-1","dataUrl":"/structure-1.json","key":"WtgdsmcFNq"}],"key":"ne15eBSAZR"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"lLBj071Zml"}],"key":"jRNHoY8M6i"},{"type":"paragraph","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"Functions to work with sparse matrices are found in the ","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"kR57vWTV9Y"},{"type":"inlineCode","value":"scipy.sparse","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"bmqHHBKtgl"},{"type":"text","value":" module.","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"T36S32cya9"}],"key":"b8nETdM3zw"}],"key":"LavEledlYg"},{"type":"paragraph","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"Here we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"LE88koO68Z"}],"key":"qroOxSYB56"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import scipy.sparse as sp\nfrom scipy.io import loadmat\n\nvars = loadmat(\"roswelladj.mat\")    # get from the book's website\nA = sp.csr_matrix(vars[\"A\"])","key":"XS1awIKXo2"},{"type":"output","id":"-grKD0BcIEOpciQ7IGOvg","data":[],"key":"btvpKG0GzG"}],"data":{},"key":"F5LqjHJV1L"},{"type":"paragraph","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"text","value":"We may define the density of ","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"HAIt1oKJhQ"},{"type":"inlineMath","value":"\\mathbf{A}","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">A</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{A}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">A</span></span></span></span>","key":"T7cRC53Vey"},{"type":"text","value":" as the number of nonzeros divided by the total number of entries.","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"CdRFXnfGvv"}],"key":"TZajBS987R"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"m, n = A.shape\nprint(f\"density is {A.nnz / (m * n):.3%}\")","key":"k1MKDzpMyZ"},{"type":"output","id":"Iqss9AcM5dE7eIJSwHOBb","data":[{"output_type":"stream","name":"stdout","text":"density is 0.109%\n"}],"key":"P0UwUcxpBM"}],"data":{},"indexEntries":[{"entry":"Python","subEntry":{"value":"nnz","kind":"entry"},"emphasis":true}],"label":"index-VweSArIOZv","identifier":"index-vwesariozv","html_id":"index-vwesariozv","key":"rSnDPtlKUU"},{"type":"paragraph","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"children":[{"type":"text","value":"We can compare the storage space needed for the sparse ","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"meAEhVAV8d"},{"type":"inlineMath","value":"\\mathbf{A}","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">A</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{A}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">A</span></span></span></span>","key":"m2WlHfAqlY"},{"type":"text","value":" with the space needed for its dense / full counterpart.","position":{"start":{"line":97,"column":1},"end":{"line":97,"column":1}},"key":"ddv4wn8ga9"}],"key":"FDFCnUff4X"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"F = A.todense()\nprint(f\"{A.data.nbytes/1e6:.3f} MB for sparse form, {F.nbytes/1e6:.3f} MB for dense form\")","key":"rdI5VXD0xq"},{"type":"output","id":"ObIe2_s5fpCveBWMAM8Hw","data":[{"output_type":"stream","name":"stdout","text":"0.068 MB for sparse form, 62.273 MB for dense form\n"}],"key":"BjIRSNa6GM"}],"data":{},"key":"yB0OVVmp7x"},{"type":"paragraph","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"children":[{"type":"text","value":"Matrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.","position":{"start":{"line":105,"column":1},"end":{"line":105,"column":1}},"key":"RUkIeWNRWU"}],"key":"o18EjGfTTt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from timeit import default_timer as timer\nx = random.randn(n)\nstart = timer()\nfor i in range(1000):\n    A @ x\nprint(f\"sparse time: {timer() - start:.4g} sec\")","key":"lKWFWCSbLI"},{"type":"output","id":"8bTyb6b2K2WtcOEQj9zxU","data":[{"output_type":"stream","name":"stdout","text":"sparse time: 0.01379 sec\n"}],"key":"JApsjg8FNa"}],"data":{},"key":"GwRpHT30NJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"start = timer()\nfor i in range(1000):\n    F @ x\nprint(f\"dense time: {timer() - start:.4g} sec\")","key":"sVagWUDjK1"},{"type":"output","id":"xoCNk1avggQaB3VFnk7Kv","data":[{"output_type":"stream","name":"stdout","text":"dense time: 1.674 sec\n"}],"key":"FCbsOFDsiC"}],"data":{},"key":"dZyOlnYhj9"}],"label":"demo-structure-sparse-python","identifier":"demo-structure-sparse-python","html_id":"demo-structure-sparse-python","key":"GTQgmRBUBc"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-structure-fill","label":"demo-structure-fill","kind":"proof:example","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":21}},"children":[{"type":"text","value":"Example ","key":"X5dwl4iI7o"},{"type":"text","value":"8.1.2","key":"DunM3nkV5U"}],"template":"Example %s","enumerator":"8.1.2","resolved":true,"html_id":"demo-structure-fill","remote":true,"url":"/structure-1","dataUrl":"/structure-1.json","key":"MdJeRPyHGB"}],"key":"GWHnlWwssr"},{"type":"paragraph","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"children":[{"type":"text","value":"Here is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"Vplr6N7dZB"}],"key":"rsP9w2siVb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import networkx as nx\nwsg = nx.watts_strogatz_graph(200, 4, 0.02)","key":"gHsmQw8cR8"},{"type":"output","id":"6OeUxilSEJCiXEVNNuEKH","data":[],"key":"N7NgRY1U3D"}],"data":{},"key":"dAMqJSQZ8P"},{"type":"paragraph","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"text","value":"Because each node connects to relatively few others, the adjacency matrix is quite sparse.","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"gQa3Fv1hqF"}],"key":"RZhPmR3YF4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"A = nx.adjacency_matrix(wsg)\nspy(A)\ntitle(\"Adjacency matrix $A$\");","key":"lu8xNh0LbC"},{"type":"output","id":"QLFEXBxjOnGeSHzXWMzXF","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"bf87658e3156a484927b6646d9230f22","path":"/build/bf87658e3156a484927b6646d9230f22.png"}}}],"key":"NZ5ZHEpJUy"}],"data":{},"key":"D8uedhFhoW"},{"type":"paragraph","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"text","value":"By ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"bMIJbNWjgn"},{"type":"crossReference","kind":"proof:theorem","identifier":"theorem-insight-adjmat","label":"theorem-insight-adjmat","children":[{"type":"text","value":"Theorem ","key":"vCwdt9jjUu"},{"type":"text","value":"7.1.1","key":"MdGDaFuamS"}],"template":"Theorem %s","enumerator":"7.1.1","resolved":true,"html_id":"theorem-insight-adjmat","remote":true,"url":"/insight","dataUrl":"/insight.json","key":"MyYl3mgTK7"},{"type":"text","value":", the entries of ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"XQTT63oETC"},{"type":"inlineMath","value":"\\mathbf{A}^k","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"bold\">A</mi><mi>k</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbf{A}^k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8491em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span></span></span></span>","key":"o2asZexWH4"},{"type":"text","value":" give the number of walks of length ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"Jok1scgmQp"},{"type":"inlineMath","value":"k","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"ueMWc6IE58"},{"type":"text","value":" between pairs of nodes, as with “","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"UTsq2YCJZv"},{"type":"emphasis","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"text","value":"k","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"lNkeGU5nHy"}],"key":"Hbkhodmu8c"},{"type":"text","value":" degrees of separation” within a social network. As ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"rDcZxqas05"},{"type":"inlineMath","value":"k","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span>","key":"CMxfohh8Tv"},{"type":"text","value":" grows, the density of ","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"uLtnXNx88z"},{"type":"inlineMath","value":"\\mathbf{A}^k","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"bold\">A</mi><mi>k</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbf{A}^k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8491em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span></span></span></span>","key":"uxXLEzka6P"},{"type":"text","value":" also grows.","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"XJJLKopCfT"}],"key":"fhK0NQ7aTV"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"t4ds92985M"}],"key":"UOBJwCxB1s"},{"type":"paragraph","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"While ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"JpanfIZF7m"},{"type":"inlineCode","value":"A**6","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"pqIgZq7zFo"},{"type":"text","value":" is valid syntax here, it means elementwise power, not matrix power.","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"i2wvTtI023"}],"key":"zdk5ALZL4U"}],"class":"dropdown","key":"HMxwNeErkG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import matrix_power\nspy(matrix_power(A, 6))\ntitle((\"$A^6$\"));","key":"lj28dkGygp"},{"type":"output","id":"gxb6H7t6Eeg7kqtmkjs2W","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"83dacb8662cfb625eee91b1c44dd929f","path":"/build/83dacb8662cfb625eee91b1c44dd929f.png"}}}],"key":"Dzo4WKGNYy"}],"data":{},"indexEntries":[{"entry":"Python","subEntry":{"value":"matrix_power","kind":"entry"},"emphasis":true}],"label":"index-iFz7IX71Rz","identifier":"index-ifz7ix71rz","html_id":"index-ifz7ix71rz","key":"mTnpOcHOJd"}],"label":"demo-structure-fill-python","identifier":"demo-structure-fill-python","html_id":"demo-structure-fill-python","key":"I6nhz7rjz5"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-structure-sparseband","label":"demo-structure-sparseband","kind":"proof:example","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":27}},"children":[{"type":"text","value":"Example ","key":"Kd9NkslLAI"},{"type":"text","value":"8.1.3","key":"t89OF2QhbW"}],"template":"Example %s","enumerator":"8.1.3","resolved":true,"html_id":"demo-structure-sparseband","remote":true,"url":"/structure-1","dataUrl":"/structure-1.json","key":"yNJZPhaKfP"}],"key":"V0dr0Cmu3C"},{"type":"paragraph","position":{"start":{"line":165,"column":1},"end":{"line":165,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":165,"column":1},"end":{"line":165,"column":1}},"key":"fwPBtxdgER"},{"type":"inlineCode","value":"scipi.sparse.diags","position":{"start":{"line":165,"column":1},"end":{"line":165,"column":1}},"key":"py5ueVR3Vy"},{"type":"text","value":" function creates a sparse matrix given its diagonal elements and the diagonal indexes to put them on. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.","position":{"start":{"line":165,"column":1},"end":{"line":165,"column":1}},"key":"EBqUMHQ4EC"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"diags","kind":"entry"},"emphasis":true}],"label":"index-SnrF7cglem","identifier":"index-snrf7cglem","html_id":"index-snrf7cglem","key":"jBByZwAH0S"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"n = 50\ndata = [n * ones(n-3), ones(n), linspace(-1, 1-n, n-1)]\noffsets = [-3, 0, 1]    # 3rd below, main, 1st above\nA = sp.diags(data, offsets, format=\"lil\")\nprint(A[:7, :7].todense())","key":"NrZPnG3UZO"},{"type":"output","id":"bO4HvkgDH1LEO1ktiPv3W","data":[{"output_type":"stream","name":"stdout","text":"[[ 1. -1.  0.  0.  0.  0.  0.]\n [ 0.  1. -2.  0.  0.  0.  0.]\n [ 0.  0.  1. -3.  0.  0.  0.]\n [50.  0.  0.  1. -4.  0.  0.]\n [ 0. 50.  0.  0.  1. -5.  0.]\n [ 0.  0. 50.  0.  0.  1. -6.]\n [ 0.  0.  0. 50.  0.  0.  1.]]\n"}],"key":"mkPj4oNPVH"}],"data":{},"key":"Ek9s9qK26t"},{"type":"paragraph","position":{"start":{"line":175,"column":1},"end":{"line":175,"column":1}},"children":[{"type":"text","value":"Without pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.","position":{"start":{"line":175,"column":1},"end":{"line":175,"column":1}},"key":"vv2WnFPCed"}],"key":"rmlQLLCBVF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"L, U = FNC.lufact(A.todense())\nsubplot(1, 2, 1), spy(L)\nsubplot(1, 2, 2), spy(U);","key":"kUJELRTImK"},{"type":"output","id":"WxoodGQFmc-ENqLTxMPno","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 2 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"b9b58db058e30b06125ba5957e17466a","path":"/build/b9b58db058e30b06125ba5957e17466a.png"}}}],"key":"YCqDcdkLS3"}],"data":{},"key":"wKk6pzyrSh"},{"type":"paragraph","position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"children":[{"type":"text","value":"However, if we introduce row pivoting, bandedness may be expanded or destroyed.","position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"key":"Djmo1EL0ai"}],"key":"RrlJYKGVG7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"L, U, p = FNC.plufact(A.todense())\nsubplot(1, 2, 1), spy(L[p, :])\nsubplot(1, 2, 2), spy(U)","key":"bKt79urgxG"},{"type":"output","id":"v6QgJm-PpjKis_s8dWgt8","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 2 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"6d9b517d3399a41c419b8a0f7e078788","path":"/build/6d9b517d3399a41c419b8a0f7e078788.png"}}}],"key":"pdI74osp1v"}],"data":{},"key":"HhWr6CjPy7"}],"label":"demo-structure-sparseband-python","identifier":"demo-structure-sparseband-python","html_id":"demo-structure-sparseband-python","key":"Tg8Ap3RLHM"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-structure-linalg","label":"demo-structure-linalg","kind":"proof:example","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":23}},"children":[{"type":"text","value":"Example ","key":"GiSytUmBFm"},{"type":"text","value":"8.1.4","key":"F6S0yTL0Hb"}],"template":"Example %s","enumerator":"8.1.4","resolved":true,"html_id":"demo-structure-linalg","remote":true,"url":"/structure-1","dataUrl":"/structure-1.json","key":"UANxRK3tQr"}],"key":"vBhHai2Scq"},{"type":"paragraph","position":{"start":{"line":197,"column":1},"end":{"line":197,"column":1}},"children":[{"type":"text","value":"The following generates a random sparse matrix with prescribed eigenvalues.","position":{"start":{"line":197,"column":1},"end":{"line":197,"column":1}},"key":"GFNS5fPwk1"}],"key":"jDMIhwR3mm"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"n = 4000\ndensity = 4e-4\nev = 1 / arange(1, n + 1)\nA = FNC.sprandsym(n, density, eigvals=ev)\nprint(f\"density is {A.nnz / prod(A.shape):.3%}\")","key":"oPkJ7TkhTJ"},{"type":"output","id":"fnKiIBJlO-KG7VCmP9fWf","data":[{"output_type":"stream","name":"stdout","text":"density is 0.040%\n"}],"key":"pTBrFD2TJK"}],"data":{},"key":"SHO3W1RxWk"},{"type":"paragraph","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"mjDLWioFfd"},{"type":"inlineCode","value":"eigs","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"PRF07KOyOB"},{"type":"text","value":" function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using ","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"d9F5GvPUqS"},{"type":"inlineCode","value":"which=\"LM\"","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"YAnIFW8LNo"},{"type":"text","value":".","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"HKj4x17dst"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"eigs","kind":"entry"},"emphasis":true}],"label":"index-g40u03IrUD","identifier":"index-g40u03irud","html_id":"index-g40u03irud","key":"vkt9bzsrwv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import eigs\nev, V = eigs(A, k=5, which=\"LM\")    # largest magnitude\nprint(1 / ev)","key":"QYRBpvyMRI"},{"type":"output","id":"nzi9cGdojgug0bo2GwqVk","data":[{"output_type":"stream","name":"stdout","text":"[1.+0.j 2.+0.j 3.+0.j 4.+0.j 5.+0.j]\n"}],"key":"aC6rw6mwWA"}],"data":{},"key":"MkwPbTF4g0"},{"type":"paragraph","position":{"start":{"line":218,"column":1},"end":{"line":218,"column":1}},"children":[{"type":"text","value":"Now we find the 4 closest to the value 1 in the complex plane, via ","position":{"start":{"line":218,"column":1},"end":{"line":218,"column":1}},"key":"tyKOIqEg6U"},{"type":"inlineCode","value":"sigma=1","position":{"start":{"line":218,"column":1},"end":{"line":218,"column":1}},"key":"nG4xN23zmd"},{"type":"text","value":".","position":{"start":{"line":218,"column":1},"end":{"line":218,"column":1}},"key":"wf31HQWe5G"}],"key":"pxSAOd1mKW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import eigs\nev, V = eigs(A, k=4, sigma=0.03)    # closest to sigma\nprint(ev)","key":"CGi8jMlCFf"},{"type":"output","id":"sxCV4HRB1m7SUUW37a2JG","data":[{"output_type":"stream","name":"stdout","text":"[0.03030303+0.j 0.02941176+0.j 0.03125   +0.j 0.02857143+0.j]\n"}],"key":"P9RCnHvSof"}],"data":{},"key":"SF4GpbPfPF"},{"type":"paragraph","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"children":[{"type":"text","value":"The time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"key":"XrJ4695UXD"}],"key":"QA1tVWQmsZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import spsolve\nx = 1 / arange(1, n + 1)\nb = A @ x\nstart = timer()\nxx = spsolve(A, b)\nprint(f\"sparse time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")","key":"SSBOhpVdSR"},{"type":"output","id":"n3YG1iEPh8A9cEnc3kxnQ","data":[{"output_type":"stream","name":"stdout","text":"sparse time: 0.00154 sec\nresidual: 7.2e-18\n"}],"key":"DM6rniyVEt"}],"data":{},"key":"qEfyUHTR4S"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from numpy.linalg import solve\nF = A.todense()\nstart = timer()\nxx = solve(F, b)\nprint(f\"dense time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")","key":"rUTCDOlhLg"},{"type":"output","id":"zl00K7-E0VJj88rylj3-w","data":[{"output_type":"stream","name":"stdout","text":"dense time: 0.666 sec\nresidual: 7.4e-18\n"}],"key":"blBeWQVHvK"}],"data":{},"key":"Ke22wdkon6"}],"label":"demo-structure-linalg-python","identifier":"demo-structure-linalg-python","html_id":"demo-structure-linalg-python","key":"HA9Ct5Luk6"},{"type":"heading","depth":3,"position":{"start":{"line":248,"column":1},"end":{"line":248,"column":1}},"children":[{"type":"text","value":"8.2 ","position":{"start":{"line":248,"column":1},"end":{"line":248,"column":1}},"key":"SINDvQIdRy"},{"type":"link","identifier":"section-krylov-power","label":"section-krylov-power","kind":"narrative","position":{"start":{"line":248,"column":5},"end":{"line":248,"column":26}},"url":"/power","internal":true,"dataUrl":"/power.json","children":[{"type":"text","value":"Power iteration","key":"FheNysnhwg"}],"key":"YdqRjvNUDm"}],"identifier":"id-8-2","label":"8.2 ","html_id":"id-8-2","implicit":true,"key":"KtfKuJZ70F"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-power-one","label":"demo-power-one","kind":"proof:example","position":{"start":{"line":251,"column":1},"end":{"line":251,"column":16}},"children":[{"type":"text","value":"Example ","key":"OJdsEczeTA"},{"type":"text","value":"8.2.1","key":"v6P8DsCIZu"}],"template":"Example %s","enumerator":"8.2.1","resolved":true,"html_id":"demo-power-one","remote":true,"url":"/power","dataUrl":"/power.json","key":"QkylH6N29k"}],"key":"s9OjbFkP7I"},{"type":"paragraph","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"children":[{"type":"text","value":"Here we choose a random 5×5 matrix and a random 5-vector.","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"key":"cabTg0hGp8"}],"key":"ZfzxNAuusq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"A = random.choice(range(10), (5, 5))\nA = A / sum(A, 0)\nx = random.randn(5)\nprint(x)","key":"EsZJ84P4zJ"},{"type":"output","id":"BuhWNBhcQSg52aWwve_WZ","data":[{"output_type":"stream","name":"stdout","text":"[-1.25180976 -0.0306434   1.52696477  0.12656446 -0.2223697 ]\n"}],"key":"pxmXuEcBZ0"}],"data":{},"key":"SegIZfPSRp"},{"type":"paragraph","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"children":[{"type":"text","value":"Applying matrix-vector multiplication once doesn’t do anything recognizable.","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"BBFpLDEn09"}],"key":"k4gxXswvwc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"y = A @ x\nprint(y)","key":"U6nvlHDeUa"},{"type":"output","id":"tiuC-CAIxqJlpoe9qfteJ","data":[{"output_type":"stream","name":"stdout","text":"[ 0.10917933 -0.26797746 -0.17570311  0.32710551  0.1561021 ]\n"}],"key":"pWgQfP00FQ"}],"data":{},"key":"sMesg5bbY7"},{"type":"paragraph","position":{"start":{"line":269,"column":1},"end":{"line":269,"column":1}},"children":[{"type":"text","value":"Repeating the multiplication still doesn’t do anything obvious.","position":{"start":{"line":269,"column":1},"end":{"line":269,"column":1}},"key":"mtDEysAdnq"}],"key":"uK2M07Y5Vr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"z = A @ y\nprint(z)","key":"THM7b0ulx8"},{"type":"output","id":"DoeqIwbN7s1j_5uYIE32_","data":[{"output_type":"stream","name":"stdout","text":"[ 0.03235955 -0.01946441  0.142689   -0.01057079  0.00369303]\n"}],"key":"uxU4rf19YC"}],"data":{},"key":"vqCzc8cL6Q"},{"type":"paragraph","position":{"start":{"line":276,"column":1},"end":{"line":276,"column":1}},"children":[{"type":"text","value":"But if we keep repeating the matrix-vector multiplication, something remarkable happens: ","position":{"start":{"line":276,"column":1},"end":{"line":276,"column":1}},"key":"bw4Lfpbh4W"},{"type":"inlineMath","value":"\\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}","position":{"start":{"line":276,"column":1},"end":{"line":276,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">A</mi><mi mathvariant=\"bold\">x</mi><mo>≈</mo><mi mathvariant=\"bold\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">Ax</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4444em;\"></span><span class=\"mord mathbf\">x</span></span></span></span>","key":"bFUCBPql2X"},{"type":"text","value":".","position":{"start":{"line":276,"column":1},"end":{"line":276,"column":1}},"key":"E4X64Brib4"}],"key":"z9V40WcQam"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"x = random.randn(5)\nfor j in range(6):\n    x = A @ x\nprint(x)\nprint(A @ x)","key":"xhtBT6vR95"},{"type":"output","id":"gPGH-hQc0-g6nPZzTl02M","data":[{"output_type":"stream","name":"stdout","text":"[-0.61186524 -0.6023346  -1.02069264 -1.38879704 -0.26452851]\n[-0.61186363 -0.60233173 -1.02069962 -1.38879852 -0.26452452]\n"}],"key":"phdXMt8GRn"}],"data":{},"key":"Q3fg6XvasQ"},{"type":"paragraph","position":{"start":{"line":286,"column":1},"end":{"line":286,"column":1}},"children":[{"type":"text","value":"This phenomenon is unlikely to be a coincidence!","position":{"start":{"line":286,"column":1},"end":{"line":286,"column":1}},"key":"lV8lrWlIBf"}],"key":"gnGhfdlYMb"}],"label":"demo-power-one-python","identifier":"demo-power-one-python","html_id":"demo-power-one-python","key":"grbPLenHxy"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-power-iter","label":"demo-power-iter","kind":"proof:example","position":{"start":{"line":291,"column":1},"end":{"line":291,"column":17}},"children":[{"type":"text","value":"Example ","key":"zbxDpFILv9"},{"type":"text","value":"8.2.2","key":"eRsA970W29"}],"template":"Example %s","enumerator":"8.2.2","resolved":true,"html_id":"demo-power-iter","remote":true,"url":"/power","dataUrl":"/power.json","key":"XmrAvEPAeC"}],"key":"c8GjZ0flBy"},{"type":"paragraph","position":{"start":{"line":293,"column":1},"end":{"line":293,"column":1}},"children":[{"type":"text","value":"We will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.","position":{"start":{"line":293,"column":1},"end":{"line":293,"column":1}},"key":"u8H9Ps27CF"}],"key":"BpJUknWUWH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = [1, -0.75, 0.6, -0.4, 0]\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal","key":"mYqJuIl0R4"},{"type":"output","id":"sihBqgAeU8ud4WQsCAVxw","data":[],"key":"pdHWi93I8t"}],"data":{},"key":"RZ1XEmK4oL"},{"type":"paragraph","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"children":[{"type":"text","value":"We run the power iteration 60 times. The first output should be a sequence of estimates converging to the dominant eigenvalue—which, in this case, we set up to be 1.","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"c3D5SuVvSb"}],"key":"zDF7z5FMHy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"beta, x = FNC.poweriter(A, 60)\nprint(beta)","key":"Nr5PnhyqDH"},{"type":"output","id":"N8rb7jxORsVbeoB-stJsH","data":[{"output_type":"stream","name":"stdout","text":"[-2.14871431  5.46719918  0.49248351  1.90118432  0.68497856  1.3803895\n  0.80874     1.18880487  0.88665774  1.09977911  0.93408606  1.05429266\n  0.96215641  1.02998481  0.97844905  1.01669274  0.9877884   1.00933413\n  0.99310112  1.00523244  0.99610943  1.00293736  0.99780824  1.00165032\n  0.99876603  1.00092766  0.99930552  1.00052159  0.99960923  1.00029332\n  0.99978015  1.00016497  0.99987632  1.00009279  0.99993043  1.00005219\n  0.99996086  1.00002936  0.99997798  1.00001651  0.99998762  1.00000929\n  0.99999303  1.00000522  0.99999608  1.00000294  0.9999978   1.00000165\n  0.99999876  1.00000093  0.9999993   1.00000052  0.99999961  1.00000029\n  0.99999978  1.00000017  0.99999988  1.00000009  0.99999993  1.00000005]\n"}],"key":"nKQvd2sKj4"}],"data":{},"key":"msj5V4O8Jb"},{"type":"paragraph","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"children":[{"type":"text","value":"We check for linear convergence using a log-linear plot of the error.","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"key":"JOc4l6k30m"}],"key":"gmXynSr1M9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"err = 1 - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1)\nxlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");","key":"rVorU5mJO9"},{"type":"output","id":"hmiWmhb7W_UAP-nnQqQNv","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"3d508aa3b11dcb6cfba863bdbd43257c","path":"/build/3d508aa3b11dcb6cfba863bdbd43257c.png"}}}],"key":"BdM83qFgii"}],"data":{},"key":"jb2sLKS1Oz"},{"type":"paragraph","position":{"start":{"line":318,"column":1},"end":{"line":318,"column":1}},"children":[{"type":"text","value":"The asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.","position":{"start":{"line":318,"column":1},"end":{"line":318,"column":1}},"key":"skqqdLZUky"}],"key":"J7SpTmQBtS"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(f\"theory: {ev[1] / ev[0]:.5f}\")\nprint(f\"observed: {err[40] / err[39]:.5f}\")","key":"AzzjZBUeY2"},{"type":"output","id":"S-68pJ7C5VxGA55SovqM1","data":[{"output_type":"stream","name":"stdout","text":"theory: -0.75000\nobserved: -0.74996\n"}],"key":"tX9H7lMQTo"}],"data":{},"key":"yvceYFUOB1"},{"type":"paragraph","position":{"start":{"line":325,"column":1},"end":{"line":325,"column":1}},"children":[{"type":"text","value":"Note that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.","position":{"start":{"line":325,"column":1},"end":{"line":325,"column":1}},"key":"QYvv9uloih"}],"key":"Fdl6bNsA7W"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(beta[26:30])","key":"XWyh8yUGJS"},{"type":"output","id":"_CltXWpzT1qQnX46B5fKe","data":[{"output_type":"stream","name":"stdout","text":"[0.99930552 1.00052159 0.99960923 1.00029332]\n"}],"key":"EfMvq6zRBR"}],"data":{},"key":"onvB9Rr0Qk"},{"type":"paragraph","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"children":[{"type":"text","value":"In practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final ","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"key":"HlYM2TdQv6"},{"type":"text","value":"β","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"key":"s5ouyz7gys"},{"type":"text","value":" that was found, as in the following plot.","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"key":"sluIMyivg2"}],"key":"XqgH5MnHrE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"err = beta[-1] - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1), xlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");","key":"piGgDmPB8t"},{"type":"output","id":"UmD4kvGisOorzuY7WsSjB","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"24008f92bf7d89e8e84a025619096647","path":"/build/24008f92bf7d89e8e84a025619096647.png"}}}],"key":"P9fo5W5Qpe"}],"data":{},"key":"XWV9BbV0bx"},{"type":"paragraph","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"children":[{"type":"text","value":"The results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of ","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"ZSNKWPaGAu"},{"type":"inlineMath","value":"\\lambda_1","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>λ</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\lambda_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>","key":"fIT75rX4Mp"},{"type":"text","value":", it is less good as an estimate of the error in nearby estimates.","position":{"start":{"line":341,"column":1},"end":{"line":341,"column":1}},"key":"mbbQf9TmDk"}],"key":"znhnHSzgh3"}],"label":"demo-power-iter-python","identifier":"demo-power-iter-python","html_id":"demo-power-iter-python","key":"rq37LykqlZ"},{"type":"heading","depth":3,"position":{"start":{"line":345,"column":1},"end":{"line":345,"column":1}},"children":[{"type":"text","value":"8.3 ","position":{"start":{"line":345,"column":1},"end":{"line":345,"column":1}},"key":"eao1rQyMwM"},{"type":"link","identifier":"section-krylov-inviter","label":"section-krylov-inviter","kind":"narrative","position":{"start":{"line":345,"column":5},"end":{"line":345,"column":28}},"url":"/inviter","internal":true,"dataUrl":"/inviter.json","children":[{"type":"text","value":"Inverse iteration","key":"ES1zo1Fn6T"}],"key":"ZIzFU3THHe"}],"identifier":"id-8-3","label":"8.3 ","html_id":"id-8-3","implicit":true,"key":"z38oJoIiDC"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-inviter-conv","label":"demo-inviter-conv","kind":"proof:example","position":{"start":{"line":348,"column":1},"end":{"line":348,"column":19}},"children":[{"type":"text","value":"Example ","key":"eHgbffhAKQ"},{"type":"text","value":"8.3.1","key":"WXFPqpowgV"}],"template":"Example %s","enumerator":"8.3.1","resolved":true,"html_id":"demo-inviter-conv","remote":true,"url":"/inviter","dataUrl":"/inviter.json","key":"Od9OXRqCXk"}],"key":"HVOK18CaCd"},{"type":"paragraph","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"children":[{"type":"text","value":"We set up a ","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"k6ZKmHQVgR"},{"type":"inlineMath","value":"5\\times 5","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">5\\times 5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span>","key":"SQAJ6AwhzM"},{"type":"text","value":" triangular matrix with prescribed eigenvalues on its diagonal.","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"wGwTuZKWTQ"}],"key":"pcnPZAeZyV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal","key":"cGxRUQ3UkS"},{"type":"output","id":"xgIMSBOXX5zkgaz-QBX1T","data":[],"key":"BIlUzV4wt6"}],"data":{},"key":"JBaTGa1ZCe"},{"type":"paragraph","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"children":[{"type":"text","value":"We run inverse iteration with the shift ","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"TkZ2BeMvaS"},{"type":"inlineMath","value":"s=0.7","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mo>=</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">s=0.7</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.7</span></span></span></span>","key":"cM2e8IBzzd"},{"type":"text","value":". Convergence should be to the eigenvalue closest to the shift, which we know to be ","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"yv4UwXssvX"},{"type":"text","value":"0.6","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"eEYjFdSE3o"},{"type":"text","value":" here.","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"ZonUefaKPh"}],"key":"KSGSPf79u0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"beta, x = FNC.inviter(A, 0.7, 30)\nprint(beta)","key":"BzAyRq2cMV"},{"type":"output","id":"WRFB9Z4cQa8WDk8g8mQe6","data":[{"output_type":"stream","name":"stdout","text":"[0.68992465 0.56804978 0.61022905 0.59654958 0.60114633 0.59961767\n 0.60012745 0.59995752 0.60001416 0.59999528 0.60000157 0.59999948\n 0.60000017 0.59999994 0.60000002 0.59999999 0.6        0.6\n 0.6        0.6        0.6        0.6        0.6        0.6\n 0.6        0.6        0.6        0.6        0.6        0.6       ]\n"}],"key":"B1zD2KyCrY"}],"data":{},"key":"k17qQPuixL"},{"type":"paragraph","position":{"start":{"line":364,"column":1},"end":{"line":364,"column":1}},"children":[{"type":"text","value":"As expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.","position":{"start":{"line":364,"column":1},"end":{"line":364,"column":1}},"key":"gEDrlUUplT"}],"key":"mii6GZB8HF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"err = beta[-1] - beta    # last estimate is our best\nsemilogy(arange(30), abs(err), \"-o\")\nylim(1e-16, 1)\nxlabel(\"$k$\"),  ylabel(\"$|\\\\lambda_3 - \\\\beta_k|$\")\ntitle((\"Convergence of inverse iteration\"));","key":"keOapMtxmg"},{"type":"output","id":"ppuG24gck5WeXontdqqt_","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"57c0f071d0df7504ad704472ee5045cf","path":"/build/57c0f071d0df7504ad704472ee5045cf.png"}}}],"key":"Ko48NT0Zbd"}],"data":{},"key":"qH62ZnApUx"},{"type":"paragraph","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"children":[{"type":"text","value":"Let’s reorder the eigenvalues to enforce ","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"key":"VWX011uIof"},{"type":"crossReference","kind":"equation","identifier":"shiftorder","label":"shiftorder","children":[{"type":"text","value":"(","key":"XGmGyOEPbj"},{"type":"text","value":"8.3.3","key":"ZW08xCTkcT"},{"type":"text","value":")","key":"R13TAueD25"}],"template":"(%s)","enumerator":"8.3.3","resolved":true,"html_id":"shiftorder","remote":true,"url":"/inviter","dataUrl":"/inviter.json","key":"tkzQhXmHsl"},{"type":"text","value":".","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"key":"U0kt2DKNMa"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"argsort","kind":"entry"},"emphasis":true}],"label":"index-MRlDWawlOf","identifier":"index-mrldwawlof","html_id":"index-mrldwawlof","key":"mAJLJsxvDZ"},{"type":"admonition","kind":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Tip","key":"XrpgYtWKXY"}],"key":"sNCjc4loOi"},{"type":"paragraph","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"key":"e6A0RNOo6T"},{"type":"inlineCode","value":"argsort","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"key":"pIxONky7LW"},{"type":"text","value":" function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"key":"cQLLoYGW6V"}],"key":"UeH5IGmBC6"}],"class":"dropdown","key":"JD1cpvxJeL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = ev[argsort(abs(ev - 0.7))]\nprint(ev)","key":"bpAXh7ykL4"},{"type":"output","id":"pRDYaTiEO20k18wf8aR9Z","data":[{"output_type":"stream","name":"stdout","text":"[ 0.6   1.    0.   -0.4  -0.75]\n"}],"key":"sEsvZMKVmF"}],"data":{},"key":"AAuYSfHcIT"},{"type":"paragraph","position":{"start":{"line":388,"column":1},"end":{"line":388,"column":1}},"children":[{"type":"text","value":"Now it is easy to compare the theoretical and observed linear convergence rates.","position":{"start":{"line":388,"column":1},"end":{"line":388,"column":1}},"key":"QUvrHOuRiX"}],"key":"nvkzbxzsGt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(f\"theory: {(ev[0] - 0.7) / (ev[1] - 0.7):.5f}\")\nprint(f\"observed: {err[21] / err[20]:.5f}\")","key":"OTDfqaqkhb"},{"type":"output","id":"J8TzAXD5KZcoa1ShGdJq-","data":[{"output_type":"stream","name":"stdout","text":"theory: -0.33333\nobserved: -0.33327\n"}],"key":"sHYcRYo1R2"}],"data":{},"key":"silNpBupmF"}],"label":"demo-inviter-conv-python","identifier":"demo-inviter-conv-python","html_id":"demo-inviter-conv-python","key":"IZs8ZuCIcd"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-inviter-accel","label":"demo-inviter-accel","kind":"proof:example","position":{"start":{"line":397,"column":1},"end":{"line":397,"column":20}},"children":[{"type":"text","value":"Example ","key":"Ka00K5z5Wy"},{"type":"text","value":"8.3.2","key":"UzYJ5U7kOM"}],"template":"Example %s","enumerator":"8.3.2","resolved":true,"html_id":"demo-inviter-accel","remote":true,"url":"/inviter","dataUrl":"/inviter.json","key":"kKsEllbwod"}],"key":"sz7Tix1ug4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal","key":"NKUlYW22Td"},{"type":"output","id":"jg8IEIqojOLD6L_lx2Jda","data":[],"key":"RYFHeePUi2"}],"data":{},"key":"Gm9wI0qwWX"},{"type":"paragraph","position":{"start":{"line":404,"column":1},"end":{"line":404,"column":1}},"children":[{"type":"text","value":"We begin with a shift ","position":{"start":{"line":404,"column":1},"end":{"line":404,"column":1}},"key":"JmbFZaLcUn"},{"type":"inlineMath","value":"s=0.7","position":{"start":{"line":404,"column":1},"end":{"line":404,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mo>=</mo><mn>0.7</mn></mrow><annotation encoding=\"application/x-tex\">s=0.7</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.7</span></span></span></span>","key":"DHK7SlHn23"},{"type":"text","value":", which is closest to the eigenvalue 0.6.","position":{"start":{"line":404,"column":1},"end":{"line":404,"column":1}},"key":"xswb34JUJo"}],"key":"FhIHJTTVAT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from numpy.linalg import solve\ns = 0.7\nx = ones(5)\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")","key":"EZkwrTU31c"},{"type":"output","id":"UT18hRHABxfI57GKTxDEn","data":[{"output_type":"stream","name":"stdout","text":"latest estimate: 0.70348139\n"}],"key":"cfJ4Gtg6RE"}],"data":{},"key":"YZKb7GPyxD"},{"type":"paragraph","position":{"start":{"line":415,"column":1},"end":{"line":415,"column":1}},"children":[{"type":"text","value":"Note that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).","position":{"start":{"line":415,"column":1},"end":{"line":415,"column":1}},"key":"vPlYXUqWf9"}],"key":"voSvmCth6L"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"s = beta\nx = y / y[0]\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")","key":"M0JTQC3m5j"},{"type":"output","id":"NE451DbCd5HDc-e25iimf","data":[{"output_type":"stream","name":"stdout","text":"latest estimate: 0.56127614\n"}],"key":"LfNvWjzZrl"}],"data":{},"key":"B3DNmfMKKo"},{"type":"paragraph","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"children":[{"type":"text","value":"Still not much apparent progress. However, in just a few more iterations the results are dramatically better.","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"key":"DdWELmX6JC"}],"key":"PdDJkOofeB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for k in range(4):\n    s = beta\n    x = y / y[0]\n    y = solve(A - s * eye(5), x)\n    beta = x[0] / y[0] + s\n    print(f\"latest estimate: {beta:.12f}\")","key":"diPG2bllee"},{"type":"output","id":"3y9Bp5xeopvZgGCkuuTtR","data":[{"output_type":"stream","name":"stdout","text":"latest estimate: 0.596431288475\nlatest estimate: 0.599971709182\nlatest estimate: 0.599999997856\nlatest estimate: 0.600000000000\n"}],"key":"FwRlsKqXqe"}],"data":{},"key":"niFMkE6qbp"}],"label":"demo-inviter-accel-python","identifier":"demo-inviter-accel-python","html_id":"demo-inviter-accel-python","key":"HIO00zfFAn"},{"type":"heading","depth":3,"position":{"start":{"line":437,"column":1},"end":{"line":437,"column":1}},"children":[{"type":"text","value":"8.4 ","position":{"start":{"line":437,"column":1},"end":{"line":437,"column":1}},"key":"bvBjtuOG8Y"},{"type":"link","identifier":"section-krylov-subspace","label":"section-krylov-subspace","kind":"narrative","position":{"start":{"line":437,"column":5},"end":{"line":437,"column":29}},"url":"/subspace","internal":true,"dataUrl":"/subspace.json","children":[{"type":"text","value":"Krylov subspaces","key":"k34Uc6RWK9"}],"key":"OBlTzwhYIt"}],"identifier":"id-8-4","label":"8.4 ","html_id":"id-8-4","implicit":true,"key":"Nk6bynpL5N"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-subspace-unstable","label":"demo-subspace-unstable","kind":"proof:example","position":{"start":{"line":440,"column":1},"end":{"line":440,"column":24}},"children":[{"type":"text","value":"Example ","key":"KYKWl2fT6V"},{"type":"text","value":"8.4.1","key":"YvNCe8aK3V"}],"template":"Example %s","enumerator":"8.4.1","resolved":true,"html_id":"demo-subspace-unstable","remote":true,"url":"/subspace","dataUrl":"/subspace.json","key":"FSSgbB0GNU"}],"key":"bMPIO9tkUr"},{"type":"paragraph","position":{"start":{"line":442,"column":1},"end":{"line":442,"column":1}},"children":[{"type":"text","value":"First we define a triangular matrix with known eigenvalues, and a random vector ","position":{"start":{"line":442,"column":1},"end":{"line":442,"column":1}},"key":"zVQlZXszQl"},{"type":"inlineMath","value":"b","position":{"start":{"line":442,"column":1},"end":{"line":442,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span>","key":"Cll7EXCE3p"},{"type":"text","value":".","position":{"start":{"line":442,"column":1},"end":{"line":442,"column":1}},"key":"tMvUY3xHpl"}],"key":"sTqCIVW5cT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100)","key":"FGX7MsTGVC"},{"type":"output","id":"286PUMdTWV8wkhT9DuYM3","data":[],"key":"hUMGvuL6xV"}],"data":{},"key":"qQUNdEEiAw"},{"type":"paragraph","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"children":[{"type":"text","value":"Next we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"key":"TlutveYOWI"}],"key":"Jvn5lSWOtS"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"Km = zeros([100, 30])\nKm[:, 0] = b\nfor m in range(29):\n    v = A @ Km[:, m]\n    Km[:, m + 1] = v / norm(v)","key":"VE5QpxlPQj"},{"type":"output","id":"ABwzO-kRkLjlQpQxDldIh","data":[],"key":"VwMpjFHGVA"}],"data":{},"key":"V3HBR3Vj8C"},{"type":"paragraph","position":{"start":{"line":460,"column":1},"end":{"line":460,"column":1}},"children":[{"type":"text","value":"Now we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.","position":{"start":{"line":460,"column":1},"end":{"line":460,"column":1}},"key":"Sj6tMFtdOC"}],"key":"CjJ8GOzY8a"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from numpy.linalg import lstsq\nresid = zeros(30)\nresid[0] = norm(b)\nfor m in range(1, 30):\n    z = lstsq(A @ Km[:, :m], b, rcond=None)[0]\n    x = Km[:, :m] @ z\n    resid[m] = norm(b - A @ x)","key":"DravLp9LMw"},{"type":"output","id":"RBi4fHRPvwV2wiEfrpHH5","data":[],"key":"byuqTvbxO5"}],"data":{},"key":"XWHfIBVJmA"},{"type":"paragraph","position":{"start":{"line":472,"column":1},"end":{"line":472,"column":1}},"children":[{"type":"text","value":"The linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.","position":{"start":{"line":472,"column":1},"end":{"line":472,"column":1}},"key":"cGZphaEcRs"}],"key":"nJAXx5I1MG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"semilogy(range(30), resid, \"-o\")\nxlabel(\"$m$\"),  ylabel(\"$\\\\| b-Ax_m \\\\|$\")\ntitle((\"Residual for linear systems\"));","key":"pj0HUmaOw4"},{"type":"output","id":"_XBpo0U2JW0X73RMQKgH4","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"049ecd2b1b7cecd376fb7869f951a300","path":"/build/049ecd2b1b7cecd376fb7869f951a300.png"}}}],"key":"exEdDFzVDb"}],"data":{},"key":"t108B3DX4A"}],"label":"demo-subspace-unstable-python","identifier":"demo-subspace-unstable-python","html_id":"demo-subspace-unstable-python","key":"nU8Tm6bugW"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-subspace-arnoldi","label":"demo-subspace-arnoldi","kind":"proof:example","position":{"start":{"line":482,"column":1},"end":{"line":482,"column":23}},"children":[{"type":"text","value":"Example ","key":"y831uCcDev"},{"type":"text","value":"8.4.2","key":"uDMnG2jaxn"}],"template":"Example %s","enumerator":"8.4.2","resolved":true,"html_id":"demo-subspace-arnoldi","remote":true,"url":"/subspace","dataUrl":"/subspace.json","key":"Lp8xz0vm28"}],"key":"XZfpDTFEY8"},{"type":"paragraph","position":{"start":{"line":484,"column":1},"end":{"line":484,"column":1}},"children":[{"type":"text","value":"Here again is the linear system from ","position":{"start":{"line":484,"column":1},"end":{"line":484,"column":1}},"key":"MK9PfYfNrV"},{"type":"crossReference","identifier":"demo-subspace-unstable","label":"demo-subspace-unstable","kind":"proof:example","position":{"start":{"line":484,"column":38},"end":{"line":484,"column":61}},"children":[{"type":"text","value":"Example ","key":"EPEoRW318L"},{"type":"text","value":"8.4.1","key":"kWoakVHkxn"}],"template":"Example %s","enumerator":"8.4.1","resolved":true,"html_id":"demo-subspace-unstable","remote":true,"url":"/subspace","dataUrl":"/subspace.json","key":"ZBIAJjj6jF"},{"type":"text","value":".","position":{"start":{"line":484,"column":1},"end":{"line":484,"column":1}},"key":"GxAQNL7oiH"}],"key":"EeovRRYXSK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100);","key":"jpP2RE52L8"},{"type":"output","id":"CaG1AeuRPxFLbc6sLj77-","data":[],"key":"uYSnANMy1S"}],"data":{},"key":"L7knnshsvI"},{"type":"paragraph","position":{"start":{"line":492,"column":1},"end":{"line":492,"column":1}},"children":[{"type":"text","value":"We can use ","position":{"start":{"line":492,"column":1},"end":{"line":492,"column":1}},"key":"yAfgtuLpNQ"},{"type":"inlineMath","value":"\\mathbf{b}","position":{"start":{"line":492,"column":1},"end":{"line":492,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">b</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathbf\">b</span></span></span></span>","key":"TojHYqrJR6"},{"type":"text","value":" as the seed vector for the Arnoldi iteration.","position":{"start":{"line":492,"column":1},"end":{"line":492,"column":1}},"key":"Fr3B4BpmIc"}],"key":"Ca0ogvmEML"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"Q, H = FNC.arnoldi(A, b, 30)\nprint(\"Q has size\", Q.shape)\nprint(\"H has size\", H.shape)","key":"eB1Rs3bELO"},{"type":"output","id":"CuU2mI7LGw-SughROt9wI","data":[{"output_type":"stream","name":"stdout","text":"Q has size (100, 31)\nH has size (31, 30)\n"}],"key":"FRFKYW7pMd"}],"data":{},"key":"umoSmjTcgw"},{"type":"paragraph","position":{"start":{"line":500,"column":1},"end":{"line":500,"column":1}},"children":[{"type":"text","value":"Here’s one validation of the key identity ","position":{"start":{"line":500,"column":1},"end":{"line":500,"column":1}},"key":"uqHuOD7GT9"},{"type":"crossReference","identifier":"arnoldimat","label":"arnoldimat","kind":"equation","position":{"start":{"line":500,"column":43},"end":{"line":500,"column":54}},"children":[{"type":"text","value":"(","key":"CGSH7aRHDe"},{"type":"text","value":"8.4.10","key":"I0eKgNjIdJ"},{"type":"text","value":")","key":"pez1ZCOQGs"}],"template":"(%s)","enumerator":"8.4.10","resolved":true,"html_id":"arnoldimat","remote":true,"url":"/subspace","dataUrl":"/subspace.json","key":"vvphiQzksp"},{"type":"text","value":".","position":{"start":{"line":500,"column":1},"end":{"line":500,"column":1}},"key":"QkHP0UhzM9"}],"key":"gUXr2N4iR6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from numpy.linalg import norm\nshould_be_near_zero = norm(A @ Q[:, :20] - Q[:, :21] @ H[:21, :20])\nprint(should_be_near_zero)","key":"f9jmJKmWJO"},{"type":"output","id":"oOihX4cl-xBRBXQ8ffUtV","data":[{"output_type":"stream","name":"stdout","text":"7.064671167505779e-14\n"}],"key":"AhIzCmqn9b"}],"data":{},"key":"Uf9qjbfKaw"},{"type":"paragraph","position":{"start":{"line":507,"column":1},"end":{"line":507,"column":1}},"children":[{"type":"text","value":"Using the Krylov matrix to project the linear system into a Kyrlov subspace in ","position":{"start":{"line":507,"column":1},"end":{"line":507,"column":1}},"key":"eMNRyJZGQd"},{"type":"crossReference","identifier":"demo-subspace-unstable","label":"demo-subspace-unstable","kind":"proof:example","position":{"start":{"line":507,"column":80},"end":{"line":507,"column":103}},"children":[{"type":"text","value":"Example ","key":"EjkEL3pX81"},{"type":"text","value":"8.4.1","key":"IlLVOklSg7"}],"template":"Example %s","enumerator":"8.4.1","resolved":true,"html_id":"demo-subspace-unstable","remote":true,"url":"/subspace","dataUrl":"/subspace.json","key":"VHedU13e0y"},{"type":"text","value":" was unable to get the residual much smaller than about ","position":{"start":{"line":507,"column":1},"end":{"line":507,"column":1}},"key":"EdZs0P1YNH"},{"type":"span","position":{"start":{"line":507,"column":1},"end":{"line":507,"column":1}},"children":[{"type":"text","value":"10","key":"LfJGOxtGUq"},{"type":"superscript","children":[{"type":"text","value":"-4","key":"NS2le7nl2w"}],"key":"Cj7tHVPY2w"}],"key":"eMDLN1RJ3u"},{"type":"text","value":". But the Arnoldi basis gives us a stable way to work in that subspace and get better results.","position":{"start":{"line":507,"column":1},"end":{"line":507,"column":1}},"key":"uavsoClX31"}],"key":"SjMPBC58KE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"z, _, _, _ = linalg.lstsq(A @ Q, b)\nx = Q @ z\nresid_norm = norm(b - A @ x)\nprint(f\"residual norm: {resid_norm:.2e}\")","key":"h1xCRZZjU9"},{"type":"output","id":"ovetC8etQtjwOEBZ8gvg1","data":[{"output_type":"stream","name":"stdout","text":"residual norm: 2.13e-09\n"}],"key":"zIojQVnN5C"}],"data":{},"key":"YsbHXzTc9c"}],"label":"demo-subspace-arnoldi-python","identifier":"demo-subspace-arnoldi-python","html_id":"demo-subspace-arnoldi-python","key":"Pa62JXNArn"},{"type":"heading","depth":3,"position":{"start":{"line":517,"column":1},"end":{"line":517,"column":1}},"children":[{"type":"text","value":"8.5 ","position":{"start":{"line":517,"column":1},"end":{"line":517,"column":1}},"key":"BiR8ZAVbQV"},{"type":"link","identifier":"section-krylov-gmres","label":"section-krylov-gmres","kind":"narrative","position":{"start":{"line":517,"column":5},"end":{"line":517,"column":26}},"url":"/gmres","internal":true,"dataUrl":"/gmres.json","children":[{"type":"text","value":"GMRES","key":"le9o1KtGG6"}],"key":"VfUWXCb1y0"}],"identifier":"id-8-5","label":"8.5 ","html_id":"id-8-5","implicit":true,"key":"hzZltjTemf"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-gmres-intro","label":"demo-gmres-intro","kind":"proof:example","position":{"start":{"line":520,"column":1},"end":{"line":520,"column":18}},"children":[{"type":"text","value":"Example ","key":"WMZ1NY2xNh"},{"type":"text","value":"8.5.1","key":"rm9bLsNSoa"}],"template":"Example %s","enumerator":"8.5.1","resolved":true,"html_id":"demo-gmres-intro","remote":true,"url":"/gmres","dataUrl":"/gmres.json","key":"wz1MfWJSmd"}],"key":"FkaWU36YU6"},{"type":"paragraph","position":{"start":{"line":522,"column":1},"end":{"line":522,"column":1}},"children":[{"type":"text","value":"We define a triangular matrix with known eigenvalues and a random vector ","position":{"start":{"line":522,"column":1},"end":{"line":522,"column":1}},"key":"bWPMKI0LoX"},{"type":"inlineMath","value":"\\mathbf{b}","position":{"start":{"line":522,"column":1},"end":{"line":522,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">b</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{b}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathbf\">b</span></span></span></span>","key":"SgTAYNhGQF"},{"type":"text","value":".","position":{"start":{"line":522,"column":1},"end":{"line":522,"column":1}},"key":"b4JZDZjjDa"}],"key":"CX6sMLoLqM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100)","key":"JOpLxuxrOK"},{"type":"output","id":"2tFHs2dZFD14Gr_llgNL-","data":[],"key":"yRpmwmQHkP"}],"data":{},"key":"C2ohGUFZTT"},{"type":"paragraph","position":{"start":{"line":530,"column":1},"end":{"line":530,"column":1}},"children":[{"type":"text","value":"Instead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.","position":{"start":{"line":530,"column":1},"end":{"line":530,"column":1}},"key":"LI15iqIAX3"}],"key":"F1s92ZmQVv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"Q, H = FNC.arnoldi(A, b, 60)\nprint(H[:5, :5])","key":"Iy1H07ls5M"},{"type":"output","id":"iVZUNAyph2LVLGd688m65","data":[{"output_type":"stream","name":"stdout","text":"[[77.29010626 36.95505789  7.41595504  3.16443332 -2.2726075 ]\n [23.43762227 51.97889611 27.14804215  1.81803633 -0.90127511]\n [ 0.         22.00432482 58.84923536 25.15422873  1.26826341]\n [ 0.          0.         23.17890298 60.87291191 26.07605599]\n [ 0.          0.          0.         25.40745709 55.50209834]]\n"}],"key":"ovdVZlm7oT"}],"data":{},"key":"arfHdkTE0s"},{"type":"paragraph","position":{"start":{"line":537,"column":1},"end":{"line":537,"column":1}},"children":[{"type":"text","value":"The Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.","position":{"start":{"line":537,"column":1},"end":{"line":537,"column":1}},"key":"bqqMDyVz0x"}],"key":"s3PHRj5TkH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from numpy.linalg import lstsq\nresid = zeros(61)\nresid[0] = norm(b)\nfor m in range(1, 61):\n    s = hstack([norm(b), zeros(m)])\n    z = lstsq(H[: m + 1, :m], s, rcond=None)[0]\n    x = Q[:, :m] @ z\n    resid[m] = norm(b - A @ x)","key":"Uc43BIo3fv"},{"type":"output","id":"Mcqb-DgeAlR7OIwk-Rn-R","data":[],"key":"IRm1kODeKi"}],"data":{},"key":"HQ1nzt1eQa"},{"type":"paragraph","position":{"start":{"line":550,"column":1},"end":{"line":550,"column":1}},"children":[{"type":"text","value":"The approximations converge smoothly, practically all the way to machine epsilon.","position":{"start":{"line":550,"column":1},"end":{"line":550,"column":1}},"key":"WSro0JlL9x"}],"key":"TuQRaRGOk2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"semilogy(range(61), resid, \"-o\")\nxlabel(\"$m$\"),  ylabel(\"$\\| b-Ax_m \\|$\")\ntitle(\"Residual for GMRES\");","key":"f6FHIo76jo"},{"type":"output","id":"--hFFm7YXSZpixL3kuWZf","data":[{"output_type":"stream","name":"stderr","text":"<>:2: SyntaxWarning: invalid escape sequence '\\|'\n<>:2: SyntaxWarning: invalid escape sequence '\\|'\n/var/folders/gc/0752xrm56pnf0r0dsrn5370c0000gr/T/ipykernel_74583/580350478.py:2: SyntaxWarning: invalid escape sequence '\\|'\n  xlabel(\"$m$\"),  ylabel(\"$\\| b-Ax_m \\|$\")\n"},{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"f65dbd620847a252cfd0468f6af1ed51","path":"/build/f65dbd620847a252cfd0468f6af1ed51.png"}}}],"key":"E69ihkXVHR"}],"data":{},"key":"Jbrv6607Vk"}],"label":"demo-gmres-intro-python","identifier":"demo-gmres-intro-python","html_id":"demo-gmres-intro-python","key":"WfzOp4U8PP"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-gmres-restart","label":"demo-gmres-restart","kind":"proof:example","position":{"start":{"line":560,"column":1},"end":{"line":560,"column":20}},"children":[{"type":"text","value":"Example ","key":"rIIMYQP1zb"},{"type":"text","value":"8.5.2","key":"slTtR2GCqh"}],"template":"Example %s","enumerator":"8.5.2","resolved":true,"html_id":"demo-gmres-restart","remote":true,"url":"/gmres","dataUrl":"/gmres.json","key":"wW6uWdOq6M"}],"key":"AChRZ2FOOw"},{"type":"paragraph","position":{"start":{"line":562,"column":1},"end":{"line":562,"column":1}},"children":[{"type":"text","value":"The following experiments are based on a matrix resulting from discretization of a partial differential equation.","position":{"start":{"line":562,"column":1},"end":{"line":562,"column":1}},"key":"Z4nS49ibUO"}],"key":"Ay4PoDm6FX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"d = 50;  n = d**2\nA = FNC.poisson2d(d)\nb = ones(n)\nspy(A);","key":"lA0S06q58L"},{"type":"output","id":"DkYD3_zz0Y5ByTrHmheUP","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"2f28202d37aec32e09f3f84a559b5d9f","path":"/build/2f28202d37aec32e09f3f84a559b5d9f.png"}}}],"key":"tZlYb3pDBc"}],"data":{},"key":"xuZR4MbYIs"},{"type":"paragraph","position":{"start":{"line":574,"column":1},"end":{"line":574,"column":1}},"children":[{"type":"text","value":"We compare unrestarted GMRES with three different thresholds for restarting. Here we are using ","position":{"start":{"line":574,"column":1},"end":{"line":574,"column":1}},"key":"OCjRG5C0yv"},{"type":"inlineCode","value":"gmres","position":{"start":{"line":574,"column":1},"end":{"line":574,"column":1}},"key":"PLqQo4bkxa"},{"type":"text","value":" from ","position":{"start":{"line":574,"column":1},"end":{"line":574,"column":1}},"key":"SL0YSKz9QO"},{"type":"inlineCode","value":"scipy.sparse.linalg","position":{"start":{"line":574,"column":1},"end":{"line":574,"column":1}},"key":"Od6SfcyBAt"},{"type":"text","value":", since our simple implementation does not offer restarting. We’re also using a trick to accumulate the vector of residual norms as it runs.","position":{"start":{"line":574,"column":1},"end":{"line":574,"column":1}},"key":"BYlZdIoi0j"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"gmres","kind":"entry"},"emphasis":true}],"label":"index-MQNgE54cIO","identifier":"index-mqnge54cio","html_id":"index-mqnge54cio","key":"XY9fdsedjo"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import gmres\nctr = lambda rvec: resid.append(norm(rvec))\nresid = [1.]\nx, flag = gmres(A, b, restart=None, rtol=1e-8, atol=1e-14, maxiter=120, callback=ctr)\nsemilogy(resid); \nxlabel(\"$m$\"), ylabel(\"residual norm\")\ntitle((\"Convergence of unrestarted GMRES\"));","key":"ipgWW4yTGk"},{"type":"output","id":"nJ68D97bLr6vV49pMO49E","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"64c2e4714ac90a8178a228acc4fd1138","path":"/build/64c2e4714ac90a8178a228acc4fd1138.png"}}}],"key":"u9eGcfC9Uq"}],"data":{},"key":"chwUB0Q1RU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"maxit = 120\nrtol = 1e-8\nrestarts = [maxit, 20, 40, 60]\nhist = lambda rvec: resid.append(norm(rvec))\nfor r in restarts:\n    resid = [1.]\n    x, flag = gmres(A, b, restart=r, rtol=rtol, atol=1e-14, maxiter=maxit, callback=hist)\n    semilogy(resid)\n\nylim(1e-8, 2)\nlegend([\"none\", \"20\", \"40\", \"60\"])\ntitle((\"Convergence of restarted GMRES\"));","key":"HMJgIaFkt0"},{"type":"output","id":"ALl1NFMm6bZFpK67ESCge","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"9df824ebcea1e928132c8bef193a50fc","path":"/build/9df824ebcea1e928132c8bef193a50fc.png"}}}],"key":"RR1My2RFeG"}],"data":{},"key":"UPZ2THDtUB"},{"type":"paragraph","position":{"start":{"line":601,"column":1},"end":{"line":601,"column":1}},"children":[{"type":"text","value":"The “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.","position":{"start":{"line":601,"column":1},"end":{"line":601,"column":1}},"key":"bC1YxhBpL1"}],"key":"gSoagVoPC0"}],"label":"demo-gmres-restart-python","identifier":"demo-gmres-restart-python","html_id":"demo-gmres-restart-python","key":"qSrm0vgKfr"},{"type":"heading","depth":3,"position":{"start":{"line":604,"column":1},"end":{"line":604,"column":1}},"children":[{"type":"text","value":"8.6 ","position":{"start":{"line":604,"column":1},"end":{"line":604,"column":1}},"key":"pnJ39CBhED"},{"type":"link","identifier":"section-krylov-minrescg","label":"section-krylov-minrescg","kind":"narrative","position":{"start":{"line":604,"column":5},"end":{"line":604,"column":29}},"url":"/minrescg","internal":true,"dataUrl":"/minrescg.json","children":[{"type":"text","value":"MINRES and conjugate gradients","key":"rLEyuRkYvD"}],"key":"pUiQzcC9Cu"}],"identifier":"id-8-6","label":"8.6 ","html_id":"id-8-6","implicit":true,"key":"qPUBngC0w0"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-minrescg-indefinite","label":"demo-minrescg-indefinite","kind":"proof:example","position":{"start":{"line":607,"column":1},"end":{"line":607,"column":26}},"children":[{"type":"text","value":"Example ","key":"dtcEzASjx9"},{"type":"text","value":"8.6.2","key":"IvGuDJPRKy"}],"template":"Example %s","enumerator":"8.6.2","resolved":true,"html_id":"demo-minrescg-indefinite","remote":true,"url":"/minrescg","dataUrl":"/minrescg.json","key":"W4vG1zh5h1"}],"key":"uFXa1KRLxX"},{"type":"paragraph","position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"children":[{"type":"text","value":"The following matrix is indefinite.","position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"key":"J4uQKsG9T4"}],"key":"Mut3szgzl9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from numpy.linalg import eig\nimport scipy.sparse as sp\nA = FNC.poisson2d(10) - 20*sp.eye(100)\nev, _ = eig(A.todense())\nnum_negative_ev = sum(ev < 0)\nprint(f\"There are {sum(ev < 0)} negative and {sum(ev > 0)} positive eigenvalues\")","key":"pz0Ynr7a8F"},{"type":"output","id":"Eo6jw4sLCJ9RQrPhRkmjE","data":[{"output_type":"stream","name":"stdout","text":"There are 13 negative and 87 positive eigenvalues\n"}],"key":"IwRpTknuqL"}],"data":{},"key":"GZ2JzfraK1"},{"type":"paragraph","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"children":[{"type":"text","value":"We can compute the relevant quantities from ","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"Pql5IW761H"},{"type":"crossReference","kind":"proof:theorem","identifier":"theorem-minrescg-indefinite","label":"theorem-minrescg-indefinite","children":[{"type":"text","value":"Theorem ","key":"yZ7n3I8jJ0"},{"type":"text","value":"8.6.1","key":"ARbGHMxwTX"}],"template":"Theorem %s","enumerator":"8.6.1","resolved":true,"html_id":"theorem-minrescg-indefinite","remote":true,"url":"/minrescg","dataUrl":"/minrescg.json","key":"LDocEGqxc6"},{"type":"text","value":".","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"KKrtPqzX3t"}],"key":"MNd15DIDfs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"m, M = min(-ev[ev < 0]), max(-ev[ev < 0])\nkappa_minus = M / m\nm, M = min(ev[ev > 0]), max(ev[ev > 0])\nkappa_plus = M / m\nS = sqrt(kappa_plus * kappa_minus)\nrho = sqrt((S - 1) / (S + 1))\nprint(f\"Condition numbers: {kappa_minus:.2e}, {kappa_plus:.2e}\")\nprint(f\"Convergence rate: {rho:.3f}\")","key":"YoEkWghbtd"},{"type":"output","id":"ZeU-jwD6ACeXAscXdDYR9","data":[{"output_type":"stream","name":"stdout","text":"Condition numbers: 1.02e+01, 3.76e+01\nConvergence rate: 0.950\n"}],"key":"nGngD7CWIs"}],"data":{},"key":"bj4IPk7Y22"},{"type":"paragraph","position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"children":[{"type":"text","value":"Because the iteration number ","position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"key":"UyCNh2ZGUZ"},{"type":"inlineMath","value":"m","position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>","key":"rLPJlflgs8"},{"type":"text","value":" is halved in ","position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"key":"V615r2dlsY"},{"type":"crossReference","kind":"equation","identifier":"minres-conv","label":"minres-conv","children":[{"type":"text","value":"(","key":"IQHU7ZodML"},{"type":"text","value":"8.6.4","key":"WxAapMmdWP"},{"type":"text","value":")","key":"IeBgYF1Ec2"}],"template":"(%s)","enumerator":"8.6.4","resolved":true,"html_id":"minres-conv","remote":true,"url":"/minrescg","dataUrl":"/minrescg.json","key":"zqAASVOejY"},{"type":"text","value":", the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.","position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"key":"RCgFjnNGP3"}],"key":"pydWZiZIx9"},{"type":"paragraph","position":{"start":{"line":635,"column":1},"end":{"line":635,"column":1}},"children":[{"type":"text","value":"Now we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.","position":{"start":{"line":635,"column":1},"end":{"line":635,"column":1}},"key":"dV4Z4QdKJf"}],"key":"uTQjyTWL4q"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import minres\nb = random.rand(100)\nresid = [norm(b)]\nhist = lambda x: resid.append(norm(b - A @ x))\nx, flag = minres(A, b, rtol=1e-8, maxiter=1000, callback=hist)","key":"zzJqj8KwA2"},{"type":"output","id":"CDD2IZd5ckOJdW6NMU1y9","data":[],"key":"upcd0Mt7DR"}],"data":{},"indexEntries":[{"entry":"Python","subEntry":{"value":"minres","kind":"entry"},"emphasis":true}],"label":"index-fITkRmLwW0","identifier":"index-fitkrmlww0","html_id":"index-fitkrmlww0","key":"u3h4BrTFqN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"semilogy(resid, \".-\");\nupper = norm(b) * rho**arange(len(resid))\nsemilogy(upper, \"k--\")\nxlabel(\"$m$\"),  ylabel(\"residual norm\")\nlegend([\"MINRES\", \"upper bound\"], loc=\"lower left\")\ntitle(\"Convergence of MINRES\");","visibility":"hide","key":"jnSg1BDmmK"},{"type":"output","id":"ANA03ILFy9OQmbuiOlw5i","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"4897f4acde609ac5aba17e5106e984b7","path":"/build/4897f4acde609ac5aba17e5106e984b7.png"}}}],"visibility":"show","key":"x2wfOFFLx0"}],"data":{"tags":[]},"visibility":"show","key":"gQd6Yy9zpi"},{"type":"paragraph","position":{"start":{"line":658,"column":1},"end":{"line":658,"column":1}},"children":[{"type":"text","value":"The upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.","position":{"start":{"line":658,"column":1},"end":{"line":658,"column":1}},"key":"jOu2Rtawtb"}],"key":"p0iaflke6v"}],"label":"demo-minrescg-indefinite-python","identifier":"demo-minrescg-indefinite-python","html_id":"demo-minrescg-indefinite-python","key":"OQ8ygTaFIr"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-minrescg-converge","label":"demo-minrescg-converge","kind":"proof:example","position":{"start":{"line":662,"column":1},"end":{"line":662,"column":24}},"children":[{"type":"text","value":"Example ","key":"KD1752Fzk6"},{"type":"text","value":"8.6.3","key":"B8iNm0sjoX"}],"template":"Example %s","enumerator":"8.6.3","resolved":true,"html_id":"demo-minrescg-converge","remote":true,"url":"/minrescg","dataUrl":"/minrescg.json","key":"ZhJtPRUkb6"}],"key":"CbtqjUYxvT"},{"type":"paragraph","position":{"start":{"line":664,"column":1},"end":{"line":664,"column":1}},"children":[{"type":"text","value":"We will compare MINRES and CG on some quasi-random ","key":"Br5pbykuNo"},{"type":"abbreviation","title":"symmetric positive definite","children":[{"type":"text","value":"SPD","key":"BLIctS6vaH"}],"key":"LPncnkQjXg"},{"type":"text","value":" problems.  The first matrix has a condition number of 100.","key":"mc8otsnFmK"}],"key":"G2HqNeDSGO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"n = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, rcond=1e-2)\nx = arange(1, n+1) / n\nb = A @ x","key":"MxBsZk0oKr"},{"type":"output","id":"F4W3_18YEm1OVQXzD97SK","data":[],"key":"piefaCgWLU"}],"data":{},"key":"f5MWcaivye"},{"type":"paragraph","position":{"start":{"line":677,"column":1},"end":{"line":677,"column":1}},"children":[{"type":"text","value":"Now we apply both methods and compare the convergence of the system residuals, using implementations imported from ","position":{"start":{"line":677,"column":1},"end":{"line":677,"column":1}},"key":"hyjjMJ5RlK"},{"type":"inlineCode","value":"scipy.sparse.linalg","position":{"start":{"line":677,"column":1},"end":{"line":677,"column":1}},"key":"N6ctQpvBjD"},{"type":"text","value":".","position":{"start":{"line":677,"column":1},"end":{"line":677,"column":1}},"key":"DFI5aPdC5V"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"cg","kind":"entry"},"emphasis":true},{"entry":"Python","subEntry":{"value":"minres","kind":"entry"},"emphasis":false}],"label":"index-AItonQcmDr","identifier":"index-aitonqcmdr","html_id":"index-aitonqcmdr","key":"jO9F7tEmpC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import cg, minres\nhist = lambda x: resid.append(norm(b - A @ x))\n\nresid = [norm(b)]\nxMR, flag = minres(A, b, rtol=1e-12, maxiter=100, callback=hist)\nsemilogy(resid / norm(b), label=\"MINRES\")\n\nresid = [norm(b)]\nxCG, flag = cg(A, b, rtol=1e-12, maxiter=100, callback=hist)\nsemilogy(resid / norm(b), label=\"CG\")\n\nxlabel(\"Krylov dimension $m$\"), ylabel(\"$\\\\|r_m\\\\| / \\\\|b\\\\|$\")\ngrid(),  legend(),  title(\"Convergence of MINRES and CG\");","key":"y2h8gIJqzT"},{"type":"output","id":"ykOYvbnX1jrOZjGALyAFY","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"d2955a6151a0c6036b8158427eadb27f","path":"/build/d2955a6151a0c6036b8158427eadb27f.png"}}}],"key":"wOQts8TdMk"}],"data":{},"key":"m3owimVFOs"},{"type":"paragraph","position":{"start":{"line":695,"column":1},"end":{"line":695,"column":1}},"children":[{"type":"text","value":"There is little difference between the two methods here. Both achieve relative residual of ","position":{"start":{"line":695,"column":1},"end":{"line":695,"column":1}},"key":"OI5tGQxYfW"},{"type":"span","position":{"start":{"line":695,"column":1},"end":{"line":695,"column":1}},"children":[{"type":"text","value":"10","key":"VMPC9aVqmt"},{"type":"superscript","children":[{"type":"text","value":"-6","key":"q6JEG4EMfk"}],"key":"vUDrI1ME1b"}],"key":"DIOUuFhi5d"},{"type":"text","value":" in aout 60 iterations, for example. The final errors are similar, too.","position":{"start":{"line":695,"column":1},"end":{"line":695,"column":1}},"key":"guSRUnLg1B"}],"key":"dSVCDjO10m"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(f\"MINRES error: {norm(xMR - x) / norm(x):.2e}\")\nprint(f\"CG error: {norm(xCG - x) / norm(x):.2e}\")","key":"X6v30qQZOf"},{"type":"output","id":"lUkrbMAcfVtHkTQYtknMq","data":[{"output_type":"stream","name":"stdout","text":"MINRES error: 4.61e-09\nCG error: 2.96e-09\n"}],"key":"OF94cwzqZn"}],"data":{},"key":"QYH0EP7sJC"},{"type":"paragraph","position":{"start":{"line":702,"column":1},"end":{"line":702,"column":1}},"children":[{"type":"text","value":"Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5; i.e., 300 iterations to reach ","position":{"start":{"line":702,"column":1},"end":{"line":702,"column":1}},"key":"YPqGVmzdHk"},{"type":"span","position":{"start":{"line":702,"column":1},"end":{"line":702,"column":1}},"children":[{"type":"text","value":"10","key":"FFC1MPS2gC"},{"type":"superscript","children":[{"type":"text","value":"-6","key":"Kk7PYVzxDu"}],"key":"uYHCuzjD0J"}],"key":"ctpabiA1hi"},{"type":"text","value":".","position":{"start":{"line":702,"column":1},"end":{"line":702,"column":1}},"key":"JGxVnFoWUH"}],"key":"VeOYcft88P"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"A = FNC.sprandsym(n, density, rcond=1e-2 / 25)\nx = arange(1, n+1) / n\nb = A @ x","key":"gYaNq29j1h"},{"type":"output","id":"rb7O0tDE_UN5iHjlglDll","data":[],"key":"SaPx2EtxeP"}],"data":{},"key":"PWNaKkBZXZ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import cg, minres\nhist = lambda x: resid.append(norm(b - A @ x))\n\nresid = [norm(b)]\nxMR, flag = minres(A, b, rtol=1e-12, maxiter=400, callback=hist)\nsemilogy(resid / norm(b), label=\"MINRES\")\n\nresid = [norm(b)]\nxCG, flag = cg(A, b, rtol=1e-12, maxiter=400, callback=hist)\nsemilogy(resid / norm(b), label=\"CG\")\n\nxlabel(\"Krylov dimension $m$\"), ylabel(\"$\\\\|r_m\\\\| / \\\\|b\\\\|$\")\ngrid(),  legend(),  title(\"Convergence of MINRES and CG\")\n\nprint(f\"MINRES error: {norm(xMR - x) / norm(x):.2e}\")\nprint(f\"CG error: {norm(xCG - x) / norm(x):.2e}\")","visibility":"hide","key":"nvm44pRKsi"},{"type":"output","id":"ItpMt1rvm-vUulVQbi9R1","data":[{"output_type":"stream","name":"stdout","text":"MINRES error: 2.42e-07\nCG error: 1.45e-07\n"},{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"42d917ca8d9ee0e11a71726a78d706ea","path":"/build/42d917ca8d9ee0e11a71726a78d706ea.png"}}}],"visibility":"show","key":"SMId6NfMEZ"}],"data":{"tags":[]},"visibility":"show","key":"QTQZ8Rsq5u"},{"type":"paragraph","position":{"start":{"line":730,"column":1},"end":{"line":730,"column":1}},"children":[{"type":"text","value":"Both methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: ","position":{"start":{"line":730,"column":1},"end":{"line":730,"column":1}},"key":"TI8Mq9oQja"},{"type":"crossReference","kind":"proof:theorem","identifier":"theorem-minrescg-converge","label":"theorem-minrescg-converge","children":[{"type":"text","value":"Theorem ","key":"ObbmRKmSpf"},{"type":"text","value":"8.6.2","key":"G6R0xECMNV"}],"template":"Theorem %s","enumerator":"8.6.2","resolved":true,"html_id":"theorem-minrescg-converge","remote":true,"url":"/minrescg","dataUrl":"/minrescg.json","key":"JSvgTywoON"},{"type":"text","value":" is an upper bound, not necessarily an approximation.","position":{"start":{"line":730,"column":1},"end":{"line":730,"column":1}},"key":"mV35X7Zw6d"}],"key":"nfjZkZKtAQ"}],"label":"demo-minrescg-converge-python","identifier":"demo-minrescg-converge-python","html_id":"demo-minrescg-converge-python","key":"yHba4602mO"},{"type":"heading","depth":3,"position":{"start":{"line":733,"column":1},"end":{"line":733,"column":1}},"children":[{"type":"text","value":"8.7 ","position":{"start":{"line":733,"column":1},"end":{"line":733,"column":1}},"key":"dVTTIG4sAl"},{"type":"link","identifier":"section-krylov-matrixfree","label":"section-krylov-matrixfree","kind":"narrative","position":{"start":{"line":733,"column":5},"end":{"line":733,"column":31}},"url":"/matrixfree","internal":true,"dataUrl":"/matrixfree.json","children":[{"type":"text","value":"Matrix-free iterations","key":"kRx56tBWrM"}],"key":"nh05U4n01b"}],"identifier":"id-8-7","label":"8.7 ","html_id":"id-8-7","implicit":true,"key":"r1w50zw4TG"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-matrixfree-blur","label":"demo-matrixfree-blur","kind":"proof:example","position":{"start":{"line":736,"column":1},"end":{"line":736,"column":22}},"children":[{"type":"text","value":"Example ","key":"aiNXPv0XCC"},{"type":"text","value":"8.7.1","key":"G3INZhIBZM"}],"template":"Example %s","enumerator":"8.7.1","resolved":true,"html_id":"demo-matrixfree-blur","remote":true,"url":"/matrixfree","dataUrl":"/matrixfree.json","key":"qnZMoUzsEy"}],"key":"xTBuTM7m41"},{"type":"paragraph","position":{"start":{"line":738,"column":1},"end":{"line":738,"column":1}},"children":[{"type":"text","value":"We use a readily available test image.","position":{"start":{"line":738,"column":1},"end":{"line":738,"column":1}},"key":"D5QkvXuFSd"}],"key":"jepxqEIzjq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from skimage import data as testimages\nfrom skimage.color import rgb2gray\nimg = getattr(testimages, \"coffee\")()\nX = rgb2gray(img)\nimshow(X, cmap=\"gray\");","key":"CPpP946n5k"},{"type":"output","id":"IjK4yU737ZLW5mCYCUuL9","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"d2bec04d13cf33ce992d054cda071a24","path":"/build/d2bec04d13cf33ce992d054cda071a24.png"}}}],"key":"IIrHkwXr7l"}],"data":{},"key":"vNuaL8NUcJ"},{"type":"paragraph","position":{"start":{"line":748,"column":1},"end":{"line":748,"column":1}},"children":[{"type":"text","value":"We define the one-dimensional tridiagonal blurring matrices.","position":{"start":{"line":748,"column":1},"end":{"line":748,"column":1}},"key":"TTpOl8X2Yx"}],"key":"Ti8GbcBvcU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import scipy.sparse as sp\ndef blurmatrix(d):\n    data = [[0.25] * (d-1), [0.5] * d, [0.25] * (d-1)]\n    return sp.diags(data, [-1, 0, 1], shape=(d, d))\n\nm, n = X.shape\nB = blurmatrix(m)\nC = blurmatrix(n)","key":"vTcrL5itmj"},{"type":"output","id":"lOkZZYGZoLRFdc6CncVF-","data":[],"key":"zFa9cdow8v"}],"data":{},"key":"YnHVY1MASR"},{"type":"paragraph","position":{"start":{"line":761,"column":1},"end":{"line":761,"column":1}},"children":[{"type":"text","value":"Finally, we show the results of using ","position":{"start":{"line":761,"column":1},"end":{"line":761,"column":1}},"key":"QLThHtsjYO"},{"type":"inlineMath","value":"k=12","position":{"start":{"line":761,"column":1},"end":{"line":761,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>=</mo><mn>12</mn></mrow><annotation encoding=\"application/x-tex\">k=12</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">12</span></span></span></span>","key":"h67Mw5A0PW"},{"type":"text","value":" repetitions of the blur in each direction.","position":{"start":{"line":761,"column":1},"end":{"line":761,"column":1}},"key":"npqO2x86ow"}],"key":"psi5RuaGB1"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import matrix_power\nblur = lambda X: matrix_power(B, 12) @ X @ matrix_power(C, 12)\n\nimshow(blur(X), cmap=\"gray\")\ntitle(\"Blurred image\");","key":"eVpoOIbuJW"},{"type":"output","id":"pTZwYP7BVsJKoNzBqZyau","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"630304258ba17797d84cac30ac121eb3","path":"/build/630304258ba17797d84cac30ac121eb3.png"}}}],"key":"ltpn9WGemr"}],"data":{},"key":"hjcfMtenNR"}],"label":"demo-matrixfree-blur-python","identifier":"demo-matrixfree-blur-python","html_id":"demo-matrixfree-blur-python","key":"ailM5hct7y"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-matrixfree-deblur","label":"demo-matrixfree-deblur","kind":"proof:example","position":{"start":{"line":773,"column":1},"end":{"line":773,"column":24}},"children":[{"type":"text","value":"Example ","key":"LcO7dQcBwg"},{"type":"text","value":"8.7.2","key":"V9wgYUPOS1"}],"template":"Example %s","enumerator":"8.7.2","resolved":true,"html_id":"demo-matrixfree-deblur","remote":true,"url":"/matrixfree","dataUrl":"/matrixfree.json","key":"rPPwhcRvJ6"}],"key":"uBGOzayKFI"},{"type":"paragraph","position":{"start":{"line":775,"column":1},"end":{"line":775,"column":1}},"children":[{"type":"text","value":"We repeat the earlier process to blur an original image ","position":{"start":{"line":775,"column":1},"end":{"line":775,"column":1}},"key":"CUzw09CgqE"},{"type":"inlineMath","value":"\\mathbf{X}","position":{"start":{"line":775,"column":1},"end":{"line":775,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">X</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{X}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">X</span></span></span></span>","key":"pb0knlkCXL"},{"type":"text","value":" to get ","position":{"start":{"line":775,"column":1},"end":{"line":775,"column":1}},"key":"oYdyUwVwXO"},{"type":"inlineMath","value":"\\mathbf{Z}","position":{"start":{"line":775,"column":1},"end":{"line":775,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">Z</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Z}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">Z</span></span></span></span>","key":"ybDkRGRs2Y"},{"type":"text","value":".","position":{"start":{"line":775,"column":1},"end":{"line":775,"column":1}},"key":"Lglhp1L81M"}],"key":"vgYmmniXSS"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"img = getattr(testimages, \"coffee\")()\nX = rgb2gray(img)\nm, n = X.shape\n\nimport scipy.sparse as sp\ndef blurmatrix(d):\n    data = [[0.25] * (d-1), [0.5] * d, [0.25] * (d-1)]\n    return sp.diags(data, [-1, 0, 1], shape=(d, d))\nB = blurmatrix(m)\nC = blurmatrix(n)\n\nfrom scipy.sparse.linalg import matrix_power\nblur = lambda X: matrix_power(B, 12) @ X @ matrix_power(C, 12)","visibility":"show","key":"h9ulLpBJjn"},{"type":"output","id":"9ieXSdBsTs1ZodqMuyh9R","data":[],"visibility":"show","key":"eJc6BTQzFH"}],"data":{"tags":[]},"visibility":"hide","key":"VAJpdZRClT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"Z = blur(X)\nimshow(Z, cmap=\"gray\")\ntitle(\"Blurred image\");","key":"CmfMt2P5rK"},{"type":"output","id":"RLnSYZFvKANKy9Kbw9alf","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"630304258ba17797d84cac30ac121eb3","path":"/build/630304258ba17797d84cac30ac121eb3.png"}}}],"key":"S3sZPDAodg"}],"data":{},"key":"gaPv6JA3vc"},{"type":"paragraph","position":{"start":{"line":801,"column":1},"end":{"line":801,"column":1}},"children":[{"type":"text","value":"Now we imagine that ","position":{"start":{"line":801,"column":1},"end":{"line":801,"column":1}},"key":"SD6Rom9nUI"},{"type":"inlineMath","value":"\\mathbf{X}","position":{"start":{"line":801,"column":1},"end":{"line":801,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">X</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{X}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">X</span></span></span></span>","key":"Z32HM53RV0"},{"type":"text","value":" is unknown and that we want to recover it from ","position":{"start":{"line":801,"column":1},"end":{"line":801,"column":1}},"key":"BuTR8ku9gN"},{"type":"inlineMath","value":"\\mathbf{Z}","position":{"start":{"line":801,"column":1},"end":{"line":801,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">Z</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Z}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">Z</span></span></span></span>","key":"HIj54w4LNE"},{"type":"text","value":". We first need functions that translate between vector and matrix representations.","position":{"start":{"line":801,"column":1},"end":{"line":801,"column":1}},"key":"a5GLLI4VWU"}],"key":"sXJiYH0qfO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import LinearOperator\nvec = lambda Z: Z.reshape(m * n)\nunvec = lambda z: z.reshape(m, n)\nxform = lambda x: vec(blur(unvec(x)))","key":"ZzuOOf4Wm4"},{"type":"output","id":"Hm451zKlPsHh-fm5DK1rE","data":[],"key":"kZQuf4vQWH"}],"data":{},"key":"itNTj4LfEI"},{"type":"paragraph","position":{"start":{"line":813,"column":1},"end":{"line":813,"column":1}},"children":[{"type":"text","value":"Now we declare the three-step blur transformation as a ","position":{"start":{"line":813,"column":1},"end":{"line":813,"column":1}},"key":"kkFkJwhSel"},{"type":"inlineCode","value":"LinearOperator","position":{"start":{"line":813,"column":1},"end":{"line":813,"column":1}},"key":"z8L8ZXuyV7"},{"type":"text","value":", supplying also the size of the vector form of an image.","position":{"start":{"line":813,"column":1},"end":{"line":813,"column":1}},"key":"ejUeRMpGdy"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"LinearOperator","kind":"entry"},"emphasis":true}],"label":"index-qSIUFTIkDJ","identifier":"index-qsiuftikdj","html_id":"index-qsiuftikdj","key":"xkTRUQIFi4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"T = LinearOperator((m * n, m * n), matvec=xform)","key":"QjZNHRYJyv"},{"type":"output","id":"92uMqFDmKawYCvJlPexCb","data":[],"key":"DTCH9mF5fR"}],"data":{},"key":"q1XLZ8PjhD"},{"type":"paragraph","position":{"start":{"line":819,"column":1},"end":{"line":819,"column":1}},"children":[{"type":"text","value":"The blurring operators are symmetric, so we apply ","position":{"start":{"line":819,"column":1},"end":{"line":819,"column":1}},"key":"bhusOGc2q6"},{"type":"inlineCode","value":"minres","position":{"start":{"line":819,"column":1},"end":{"line":819,"column":1}},"key":"ATR1lrrABZ"},{"type":"text","value":" to the composite blurring transformation ","position":{"start":{"line":819,"column":1},"end":{"line":819,"column":1}},"key":"YgVQX0yiXX"},{"type":"inlineCode","value":"T","position":{"start":{"line":819,"column":1},"end":{"line":819,"column":1}},"key":"K4dAddmw22"},{"type":"text","value":".","position":{"start":{"line":819,"column":1},"end":{"line":819,"column":1}},"key":"jjP1f2wFNW"}],"key":"hbKBn5OtFf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import gmres\ny, flag = gmres(T, vec(Z), rtol=1e-5, maxiter=50)\nY = unvec(maximum(0, minimum(1, y)))\n\n\nsubplot(1, 2, 1),  imshow(X, cmap=\"gray\")\naxis(\"off\"),  title(\"Original\")\nsubplot(1, 2, 2),  imshow(Y, cmap=\"gray\")\naxis(\"off\"),  title(\"Deblurred\");","key":"NRyJ5Vm04S"},{"type":"output","id":"DcP2ijVQnuTeVKQfcsm6B","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 2 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"d3cdd3bb48448fb07e88303f7c9a0081","path":"/build/d3cdd3bb48448fb07e88303f7c9a0081.png"}}}],"key":"Tre8TWhdb7"}],"data":{},"key":"T8HEunCX2T"}],"label":"demo-matrixfree-deblur-python","identifier":"demo-matrixfree-deblur-python","html_id":"demo-matrixfree-deblur-python","key":"dJsnw4foYN"},{"type":"heading","depth":3,"position":{"start":{"line":834,"column":1},"end":{"line":834,"column":1}},"children":[{"type":"text","value":"8.8 ","position":{"start":{"line":834,"column":1},"end":{"line":834,"column":1}},"key":"p1npi8b2XR"},{"type":"link","identifier":"section-krylov-precond","label":"section-krylov-precond","kind":"narrative","position":{"start":{"line":834,"column":5},"end":{"line":834,"column":28}},"url":"/precond","internal":true,"dataUrl":"/precond.json","children":[{"type":"text","value":"Preconditioning","key":"t9CeGod5Xx"}],"key":"CJztoZVcry"}],"identifier":"id-8-8","label":"8.8 ","html_id":"id-8-8","implicit":true,"key":"EFMrfuYJ0D"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-precond-diagonal","label":"demo-precond-diagonal","kind":"proof:example","position":{"start":{"line":837,"column":1},"end":{"line":837,"column":23}},"children":[{"type":"text","value":"Example ","key":"H7JBcVwTFX"},{"type":"text","value":"8.8.1","key":"MoKfgzjYYP"}],"template":"Example %s","enumerator":"8.8.1","resolved":true,"html_id":"demo-precond-diagonal","remote":true,"url":"/precond","dataUrl":"/precond.json","key":"aoGnA83OMF"}],"key":"wFIJlR08ta"},{"type":"paragraph","position":{"start":{"line":839,"column":1},"end":{"line":839,"column":1}},"children":[{"type":"text","value":"Here is an ","key":"RJJgHRErjq"},{"type":"abbreviation","title":"symmetric positive definite","children":[{"type":"text","value":"SPD","key":"FQAxMQhVz7"}],"key":"ycEWHMxvCk"},{"type":"text","value":" matrix that arises from solving partial differential equations.","key":"pEBW9wDUba"}],"key":"O2jInUJyip"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse import sparray\nimport rogues\nA = rogues.wathen(60, 60)\nn = A.shape[0]\nprint(f\"Matrix is {n} x {n} with {A.nnz} nonzeros\")","key":"aGfBWME8yD"},{"type":"output","id":"6fRrLE6_PG7I9Do3s6Kli","data":[{"output_type":"stream","name":"stdout","text":"Matrix is 11041 x 11041 with 170161 nonzeros\n"}],"key":"yWto7tapn9"}],"data":{},"key":"m1VATnC3f5"},{"type":"paragraph","position":{"start":{"line":849,"column":1},"end":{"line":849,"column":1}},"children":[{"type":"text","value":"There is an easy way to use the diagonal elements of ","position":{"start":{"line":849,"column":1},"end":{"line":849,"column":1}},"key":"awmYmGXxz7"},{"type":"inlineMath","value":"\\mathbf{A}","position":{"start":{"line":849,"column":1},"end":{"line":849,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">A</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{A}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">A</span></span></span></span>","key":"eNmUpharxh"},{"type":"text","value":", or any other vector, as a diagonal preconditioner.","position":{"start":{"line":849,"column":1},"end":{"line":849,"column":1}},"key":"yMAwoundMD"}],"key":"yf2WuIcEEU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import scipy.sparse as sp\nprec = sp.diags(1 / A.diagonal(), 0)","key":"D824Nl9VzQ"},{"type":"output","id":"Lm6JRZZ1AiMJruSiRXdf1","data":[],"key":"Mtz5MFXqdn"}],"data":{},"key":"jAz5DaHNk7"},{"type":"paragraph","position":{"start":{"line":856,"column":1},"end":{"line":856,"column":1}},"children":[{"type":"text","value":"We now compare CG with and without the preconditioner.","position":{"start":{"line":856,"column":1},"end":{"line":856,"column":1}},"key":"YcgU9ELEoQ"}],"key":"nj9xgqcr8Q"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import cg\nb = ones(n)\nhist = lambda x: resid.append(norm(b - A @ x))\nresid = [norm(b)]\nstart = timer()\nx, _ = cg(A, b, rtol=1e-4, maxiter=200, callback=hist)\nprint(f\"No preconditioner: Finished in {timer() - start:.2f} sec\")\nresid_plain = resid.copy()\nresid = [norm(b)]\nstart = timer()\nx, _ = cg(A, b, rtol=1e-4, maxiter=200, M=prec, callback=hist)\nprint(f\"Diagonal preconditioner: Finished in {timer() - start:.2f} sec\")\nresid_prec = resid.copy()\n\nsemilogy(resid_plain, label=\"no preconditioner\")\nsemilogy(resid_prec, label=\"diagonal preconditioner\")\nxlabel(\"iteration\"), ylabel(\"residual norm\")\nlegend(),  title(\"Convergence of CG with and without preconditioning\");","visibility":"hide","key":"gqmpdPx7Pu"},{"type":"output","id":"qOllnC7IHU5KpdAoKBf19","data":[{"output_type":"stream","name":"stdout","text":"No preconditioner: Finished in 2.33 sec\n"},{"output_type":"stream","name":"stdout","text":"Diagonal preconditioner: Finished in 0.68 sec\n"},{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"c451f82afaaa37baad3251ed4656ea2e","path":"/build/c451f82afaaa37baad3251ed4656ea2e.png"}}}],"visibility":"show","key":"pgxeVwX5Li"}],"data":{"tags":[]},"visibility":"show","key":"lfgYr9frjk"},{"type":"paragraph","position":{"start":{"line":881,"column":1},"end":{"line":881,"column":1}},"children":[{"type":"text","value":"The diagonal preconditioner cut down substantially on the number of iterations and the execution time.","position":{"start":{"line":881,"column":1},"end":{"line":881,"column":1}},"key":"iLfllvcuil"}],"key":"Aoo0I5Rgyw"}],"label":"demo-precond-diagonal-python","identifier":"demo-precond-diagonal-python","html_id":"demo-precond-diagonal-python","key":"UPZ401TF8l"},{"type":"details","open":true,"children":[{"type":"summary","children":[{"type":"crossReference","identifier":"demo-precond-gmres","label":"demo-precond-gmres","kind":"proof:example","position":{"start":{"line":885,"column":1},"end":{"line":885,"column":20}},"children":[{"type":"text","value":"Example ","key":"FrM0aHMs2P"},{"type":"text","value":"8.8.2","key":"VFbtyssunc"}],"template":"Example %s","enumerator":"8.8.2","resolved":true,"html_id":"demo-precond-gmres","remote":true,"url":"/precond","dataUrl":"/precond.json","key":"wHZrqqI5x1"}],"key":"rzeil8OmXs"},{"type":"paragraph","position":{"start":{"line":887,"column":1},"end":{"line":887,"column":1}},"children":[{"type":"text","value":"Here is a random nonsymmetric matrix.","position":{"start":{"line":887,"column":1},"end":{"line":887,"column":1}},"key":"wbkxvx7Krz"}],"key":"yDWF14yY3H"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import scipy.sparse as sp\nn = 8000\nA = 2.8 * sp.eye(n) + sp.rand(n, n, 0.002)","key":"opcWvgMpqI"},{"type":"output","id":"eWO8j88N1RxBoDnIAGpUy","data":[],"key":"ox9nFKS0Ts"}],"data":{},"key":"uwbZXOy6vi"},{"type":"paragraph","position":{"start":{"line":895,"column":1},"end":{"line":895,"column":1}},"children":[{"type":"text","value":"Without a preconditioner, GMRES can solve a system with this matrix.","position":{"start":{"line":895,"column":1},"end":{"line":895,"column":1}},"key":"FxhHEx7aR6"}],"key":"L3JFt6o6Ba"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import gmres\n\nb = random.rand(n)\nhist = lambda rvec: resid.append(norm(rvec))\nresid = [1.]\n\nstart = timer()\nx, flag = gmres(A, b, maxiter=300, rtol=1e-10, restart=50, callback=hist)\nprint(f\"time for plain GMRES: {timer() - start:.3f} sec\")\nresid_plain = resid.copy()","key":"VwOtAFBeZS"},{"type":"output","id":"oRQbMrgkZN_h8KnyZ4M--","data":[{"output_type":"stream","name":"stdout","text":"time for plain GMRES: 0.124 sec\n"}],"key":"AiTTpkaq2l"}],"data":{},"key":"J4ibRt2lYC"},{"type":"paragraph","position":{"start":{"line":913,"column":1},"end":{"line":913,"column":1}},"children":[{"type":"text","value":"The following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.","position":{"start":{"line":913,"column":1},"end":{"line":913,"column":1}},"key":"rEjBcsBgea"}],"indexEntries":[{"entry":"Python","subEntry":{"value":"spilu","kind":"entry"},"emphasis":true}],"label":"index-cxcWKDN3Yj","identifier":"index-cxcwkdn3yj","html_id":"index-cxcwkdn3yj","key":"shh6bu983k"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import spilu\niLU = spilu(A, drop_tol=0.2)\nprint(f\"Factors have {iLU.nnz} nonzeros, while A has {A.nnz}\")","key":"zyKL0gc2c6"},{"type":"output","id":"nLNBum8CD3WjiUkNG8h3N","data":[{"output_type":"stream","name":"stderr","text":"/var/folders/gc/0752xrm56pnf0r0dsrn5370c0000gr/T/ipykernel_74583/769705972.py:2: SparseEfficiencyWarning: spilu converted its input to CSC format\n  iLU = spilu(A, drop_tol=0.2)\n"},{"output_type":"stream","name":"stdout","text":"Factors have 95844 nonzeros, while A has 135978\n"}],"key":"C73UQUUTTQ"}],"data":{},"key":"Ry2Cuwi7be"},{"type":"paragraph","position":{"start":{"line":921,"column":1},"end":{"line":921,"column":1}},"children":[{"type":"text","value":"The result is not a true factorization of the original matrix. However, it’s close enough for an approximate inverse in a preconditioner.","position":{"start":{"line":921,"column":1},"end":{"line":921,"column":1}},"key":"scR0Uyweoj"}],"key":"HDvECQRH22"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from scipy.sparse.linalg import LinearOperator\nprec = LinearOperator((n, n), matvec=lambda y: iLU.solve(y))\n\nresid = [1.];  start = timer()\nx, flag = gmres(A, b, M=prec, maxiter=300, rtol=1e-10, restart=50, callback=hist)\nprint(f\"time for preconditioned GMRES: {timer() - start:.3f} sec\")\nresid_prec = resid","key":"srgzYQYGcH"},{"type":"output","id":"guKziOdvPyjKd498ozPOv","data":[{"output_type":"stream","name":"stdout","text":"time for preconditioned GMRES: 0.063 sec\n"}],"key":"Opuac1TlCv"}],"data":{},"key":"Umkf4SSU0H"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"semilogy(resid_plain, label=\"no prec.\")\nsemilogy(resid_prec, label=\"iLU prec.\")\nxlabel(\"iteration number\"),  ylabel(\"residual norm\")\nlegend()\ntitle(\"GMRES convergence compared\");","visibility":"hide","key":"n5NrG00aao"},{"type":"output","id":"ZC4eMZgLbqBZewCgg12U-","data":[{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 700x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"a8b3d745393d01d1d5e95b82bd26ce7d","path":"/build/a8b3d745393d01d1d5e95b82bd26ce7d.png"}}}],"visibility":"show","key":"lhNv4XcXLZ"}],"data":{"tags":[]},"visibility":"show","key":"se93g6zv8G"}],"label":"demo-precond-gmres-python","identifier":"demo-precond-gmres-python","html_id":"demo-precond-gmres-python","key":"krqHUNLhBX"}],"key":"q2Ts08Dw0G"}],"key":"VXhWoClBfH"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Chapter 7","url":"/chapter7-2","group":"Python codes"},"next":{"title":"Chapter 9","url":"/chapter9-2","group":"Python codes"}}},"domain":"http://localhost:3000"}