{"version":"1","records":[{"hierarchy":{"lvl1":"Glossary"},"type":"lvl1","url":"/glossary","position":0},{"hierarchy":{"lvl1":"Glossary"},"content":"adjacency matrix\n\nMatrix whose nonzero entries show the links between nodes in a graph. (\n\nFrom matrix to insight)\n\nadjoint\n\nConjugate transpose of a complex matrix. (\n\nComputing with matrices)\n\nadvection equation\n\nArchetypical PDE of hyperbolic type, representing transport phenomena. ()\n\nalgorithm\n\nList of instructions for transforming data into a result. (\n\nAlgorithms)\n\nArnoldi iteration\n\nStable algorithm for finding orthonormal bases of nested Krylov subspaces. (\n\nKrylov subspaces)\n\nasymptotic\n\nRelationship indicating that two functions have the same leading behavior in some limit. (\n\nEfficiency of matrix computations)\n\nbackward error\n\nChange to the input of a problem required to produce the result found by an inexact algorithm. (\n\nStability)\n\nbackward substitution\n\nSystematic method for solving a linear system with an upper triangular matrix. (\n\nLinear systems)\n\nbandwidth\n\nThe number of diagonals around the main diagonal that have nonzero elements. (\n\nExploiting matrix structure)\n\nbarycentric formula\n\nComputationally useful expression for the interpolating polynomial as a ratio of rational terms. ()\n\nbig-O\n\nRelationship indicating that one function is bounded above by a multiple of another in some limit. (\n\nEfficiency of matrix computations)\n\nboundary-value problem\n\nA differential equation with which partial information about the solution is given at multiple points on the boundary of the domain. ()\n\ncardinal function\n\nInterpolating function that is 1 at one node and 0 at all the others. (\n\nThe interpolation problem)\n\nCholesky factorization\n\nSymmetrized version of LU factorization for SPD matrices. (\n\nExploiting matrix structure)\n\ncollocation\n\nSolution of a differential equation by imposing it approximately at a set of nodes. ()\n\ncondition number\n\nRatio of the size of change in the output of a function to the size of change in the input that produced it. (\n\nProblems and conditioning)\n\ncubic spline\n\nPiecewise cubic function with two globally continuous derivatives, most often used for interpolation or approximation. (\n\nCubic splines)\n\ndiagonalizable\n\nMatrix that admits an eigenvalue decomposition. Also known as nondefective. (\n\nEigenvalue decomposition)\n\ndifferentiation matrix\n\nMatrix mapping a vector of function values to a vector of approximate derivative values. ()\n\nDirichlet condition\n\nBoundary condition specifying the value of the solution. ()\n\ndominant eigenvalue\n\nEigenvalue with the largest modulus (absolute value, in the real case). (\n\nPower iteration)\n\ndouble precision\n\nTypical standard in floating-point representation, using 64 bits to achieve about 16 decimal significant digits of precision. (\n\nFloating-point numbers)\n\neigenvalue\n\nScalar λ such that \\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x} for a square matrix \\mathbf{A} and nonzero vector \\mathbf{x}. (\n\nEigenvalue decomposition)\n\neigenvalue decomposition (EVD)\n\nExpression of a square matrix as the product of eigenvector and diagonal eigenvalue matrices. (\n\nEigenvalue decomposition)\n\neigenvector\n\nVector for which the action of a matrix is effectively one-dimensional.  (\n\nEigenvalue decomposition)\n\nEuler’s method\n\nPrototype of all IVP solution methods, obtained by assuming constant derivatives for the solution over short time intervals. (\n\nEuler’s method)\n\nevolutionary PDE\n\nA partial differential equation in which one of the independent variables is time or a close analog. ()\n\nextrapolation\n\nUse of multiple discretization values to cancel out leading terms in an error expansion. (\n\nNumerical integration)\n\nfinite difference\n\nLinear combination of function values that approximates the value of a derivative of the function at a point. (\n\nFinite differences)\n\nfinite element method (FEM)\n\nUse of piecewise integration to pose a linear system of equations for the approximate solution of a boundary-value problem. ()\n\nfixed point iteration\n\nRepeated application of a function in hopes of converging to a fixed point. (\n\nFixed-point iteration)\n\nfixed point problem\n\nFinding a value of a given function where the input and output values are the same; equivalent to rootfinding. (\n\nFixed-point iteration)\n\nfloating-point numbers\n\nA finite set that substitutes for the real numbers in machine calculations. Denoted by \\mathbb{F}. (\n\nFloating-point numbers)\n\nflops\n\nArithmetic operations on floating-point numbers, often counted as a proxy for computer runtime. (\n\nEfficiency of matrix computations)\n\nforward substitution\n\nSystematic method for solving a linear system with a lower triangular matrix. (\n\nLinear systems)\n\nFrobenius norm\n\nMatrix norm computed by applying the vector 2-norm to a vector interpretation of the matrix. (\n\nVector and matrix norms)\n\nGauss–Newton method\n\nGeneralization of Newton’s method for nonlinear least squares. (\n\nNonlinear least squares)\n\nGaussian elimination\n\nUse of row operations to transform a linear system to an equivalent one in triangular form. (\n\nLU factorization)\n\ngenerating polynomials\n\nA pair of polynomials whose coefficients match those of a multistep method for IVPs. (\n\nMultistep methods)\n\nglobal error\n\nError made by an IVP method over the entire time interval of the solution. (\n\nEuler’s method)\n\nGMRES\n\nIterative solution of a linear system through stable least-squares solutions on nested Krylov subspaces. (\n\nGMRES)\n\ngraph\n\nRepresentation of a network as a set of nodes and edges. (\n\nFrom matrix to insight)\n\nhat functions\n\nCardinal functions for piecewise linear interpolation. (\n\nPiecewise linear interpolation)\n\nheat equation\n\nArchetypical parabolic PDE that describes diffusion. ()\n\nhermitian\n\nCombination of transpose and elementwise complex conjugation. Also describes a matrix that equals its own hermitian. (\n\nSymmetry and definiteness)\n\nhermitian positive definite (HPD)\n\nMatrix that is hermitian with strictly positive eigenvalues; complex variant of symmetric positive definite. (\n\nSymmetry and definiteness)\n\nidentity matrix\n\nMatrix with ones on the diagonal and zeros elsewhere, acting as the multiplicative identity. (\n\nComputing with matrices)\n\nill-conditioned\n\nExhibiting a large condition number, indicating high sensitivity of a result to changes in the data. (\n\nProblems and conditioning)\n\nimplicit\n\nFormula that defines a quantity only indirectly, e.g., as the solution of a nonlinear equation. (\n\nMultistep methods)\n\ninduced matrix norm\n\nNorm computed using the interpretation of a matrix as a linear operator. (\n\nVector and matrix norms)\n\ninitial-value problem (IVP)\n\nAn ordinary differential equation (possibly vector-valued) together with an initial condition. (\n\nBasics of IVPs, \n\nIVP systems)\n\ninner product\n\nScalar or dot product of a pair of vectors, or its extension to a pair of functions. ()\n\ninterpolation\n\nConstruction of a function that passes through a given set of data points. (\n\nPolynomial interpolation, \n\nThe interpolation problem)\n\ninverse iteration\n\nSubtraction of a shift followed by matrix inversion, used in power iteration to transform the eigenvalue closest to a target value into a dominant one.  (\n\nInverse iteration)\n\nJacobian matrix\n\nMatrix of first partial derivatives that defines the linearization of a vector-valued function. (\n\nNewton for nonlinear systems)\n\nKronecker product\n\nAlternative type of matrix multiplication useful for problems on a tensor-product domain. ()\n\nKrylov subspace\n\nVector space generated by powers of a square matrix that is often useful for reducing the dimension of large problems. (\n\nKrylov subspaces)\n\nLagrange formula\n\nTheoretically useful expression for an interpolating polynomial. ()\n\nLanczos iteration\n\nSpecialization of the Arnoldi iteration to the case of a hermitian (or real symmetric) matrix. (\n\nMINRES and conjugate gradients)\n\nLaplace equation\n\nArchetypical elliptic PDE describing a steady state. ()\n\nlinear convergence\n\nSequence in which the difference between sequence value and limit asymptotically decreases by a constant factor at each term, making a straight line on a log-linear graph.\\\n(\n\nFixed-point iteration)\n\nlinear least-squares problem\n\nMinimization of the 2-norm of the residual for an overdetermined linear system. (\n\nFitting functions to data)\n\nlocal truncation error\n\nDiscretization error made in one time step of an IVP solution method. (\n\nEuler’s method, \n\nMultistep methods)\n\nLU factorization\n\nFactorization of a square matrix into the product of a unit lower triangular matrix and an upper triangular matrix. (\n\nLU factorization)\n\nmachine epsilon\n\nDistance from 1 to the next-largest floating-point number. Also called unit roundoff or machine precision, though the usages are not consistent across different references.\\\n(\n\nFloating-point numbers)\n\nmatrix condition number\n\nNorm of the matrix times the norm of its inverse, equivalent to the condition number for solving a linear system. (\n\nConditioning of linear systems)\n\nmethod of lines\n\nSolution technique for partial differential equations in which each independent variable is discretized separately. ()\n\nmultistep\n\nFormula using information over more than a single time step to advance the solution. (\n\nMultistep methods)\n\nNeumann condition\n\nBoundary condition specifying the derivative of the solution. ()\n\nNewton’s method\n\nRootfinding iteration that uses the linearization of the given function in order to define the next root approximation. (\n\nNewton’s method)\n\nnodes\n\nValues of the independent variable where an interpolant’s values are prescribed. (\n\nThe interpolation problem)\n\nnonlinear least-squares problem\n\nMinimization of the 2-norm of the residual of a function that depends nonlinearly on a vector. (\n\nNonlinear least squares)\n\nnorm\n\nMeans of defining the magnitude of a vector or matrix. (\n\nVector and matrix norms)\n\nnormal\n\nMatrix that has a unitary eigenvalue decomposition. (\n\nEigenvalue decomposition)\n\nnormal equations\n\nSquare linear system equivalent to the linear least-squares problem. (\n\nThe normal equations)\n\nnumerical integration\n\nEstimation of a definite integral by combining values of the integrand, rather than by finding an antiderivative. (\n\nNumerical integration)\n\none-step IVP method\n\nIVP solver that uses information from just one time level to advance to the next. (\n\nEuler’s method)\n\nONC matrix\n\nMatrix whose columns are orthonormal vectors. (\n\nThe QR factorization)\n\norder of accuracy\n\nLeading power of the truncation error as a function of a discretization size parameter. (\n\nConvergence of finite differences, \n\nNumerical integration, \n\nEuler’s method, \n\nMultistep methods)\n\northogonal vectors\n\nNonzero vectors that have an inner product of zero. (\n\nThe QR factorization)\n\northogonal matrix\n\nSquare ONC matrix, i.e., matrix whose transpose is its inverse. (\n\nThe QR factorization)\n\northogonal polynomials\n\nFamily of polynomials whose distinct members have an integral inner product equal to zero, as with Legendre and Chebyshev polynomials. ()\n\northonormal vectors\n\nVectors that are both mutually orthogonal and all of unit 2-norm. (\n\nThe QR factorization)\n\nouter product\n\nMultiplication of two vectors resulting in a rank-1 matrix. (\n\nLU factorization)\n\noverdetermined\n\nCharacterized by having more constraints than available degrees of freedom. (\n\nFitting functions to data)\n\npiecewise linear\n\nFunction that is linear between each consecutive pair of nodes, but whose slope may jump at the nodes. (\n\nPiecewise linear interpolation)\n\nPLU factorization\n\nLU factorization with row pivoting. (\n\nRow pivoting)\n\npower iteration\n\nRepeated application of a matrix to a vector, followed by normalization, resulting in convergence to an eigenvector for the dominant eigenvalue. (\n\nPower iteration)\n\npreconditioning\n\nUse of an approximate inverse to improve the convergence rate of Krylov iterations for a linear system. (\n\nPreconditioning)\n\npseudoinverse\n\nRectangular matrix that maps data to solution in the linear least-squares problem, generalizing the matrix inverse. (\n\nThe normal equations)\n\nQR factorization\n\nRepresentation of a matrix as the product of an orthogonal and an upper triangular matrix. (\n\nThe QR factorization)\n\nquadratic convergence\n\nSequence in which the difference between sequence value and limit asymptotically decreases by a constant times the square of the preceding difference. (\n\nNewton’s method)\n\nquasi-Newton methods\n\nRootfinding methods that overcome the issues of Jacobian computation and lack of global convergence in Newton’s method. (\n\nQuasi-Newton methods)\n\nquasimatrix\n\nCollection of functions (such as orthogonal polynomials) that have algebraic parallels to columns of a matrix. ()\n\nRayleigh quotient\n\nFunction of vectors that equals an eigenvalue when given its eigenvector as input. (\n\nSymmetry and definiteness)\n\nreduced QR factorization\n\nSee thin QR.\n\nreduced SVD\n\nSee thin SVD.\n\nresidual\n\nFor a linear system, the difference between \\mathbf{b} and \\mathbf{A}\\tilde{\\mathbf{x}} for a computed solution approximation \\tilde{\\mathbf{x}}. More generally, the actual value of a quantity that is made zero by an exact solution. (\n\nConditioning of linear systems, \n\nThe rootfinding problem)\n\nrestarting\n\nTechnique used in GMRES to prevent the work per iteration and overall storage from growing uncontrollably. (\n\nGMRES)\n\nrootfinding problem\n\nFinding the input value for a given function which makes that function zero. (\n\nThe rootfinding problem)\n\nrow pivoting\n\nReordering rows during LU factorization to ensure that the factorization exists and can be computed stably. (\n\nRow pivoting)\n\nRunge phenomenon\n\nManifestation of the instability of polynomial interpolation at equally spaced nodes as degree increases. ()\n\nRunge--Kutta\n\nOne-step method for IVPs that evaluates the derivative of the solution more than once to advance a single step. (\n\nRunge–Kutta methods)\n\nsecant method\n\nScalar quasi-Newton method that uses a secant line rather than a tangent line to define a root estimate. (\n\nInterpolation-based methods)\n\nshooting\n\nUnstable technique for solving a boundary-value problem in which an initial value is sought for by a rootfinding algorithm. ()\n\nsimple root\n\nRoot of a function at which the derivative of the function is nonzero. (\n\nThe rootfinding problem)\n\nsingular value decomposition (SVD)\n\nExpression of a matrix as a product of two orthogonal/unitary matrices and a nonnegative diagonal matrix. (\n\nSingular value decomposition)\n\nsparse\n\nDescribing a matrix that has mostly zero elements for structural reasons. (\n\nExploiting matrix structure, \n\nSparsity and structure)\n\nspectral convergence\n\nExponentially rapid decrease in error as the number of interpolation nodes increases, e.g., as observed in Chebyshev polynomial and trigonometric interpolation. ()\n\nstability region\n\nRegion of the complex plane describing when numerical solution of a linear IVP is bounded as t\\to\\infty. ()\n\nstep size\n\nIncrement in time between successive solution values in a numerical IVP solver. (\n\nEuler’s method)\n\nstiff\n\nDescribes an IVP in which stability is a greater restriction than accuracy for many solution methods, usually favoring the use of an implicit time stepping method. (\n\nImplementation of multistep methods, )\n\nsubtractive cancellation\n\nGrowth in relative error that occurs when two numbers are added/subtracted to get a result that is much smaller in magnitude than the operands; also called loss of significance or cancellation error. (\n\nProblems and conditioning)\n\nsuperlinear convergence\n\nSequence for which the convergence is asymptotically faster than any linear rate. (\n\nInterpolation-based methods)\n\nsymmetric matrix\n\nSquare matrix that is equal to its transpose. (\n\nComputing with matrices)\n\nsymmetric positive definite (SPD) matrix\n\nMatrix that is symmetric and positive definite, thereby permitting a Cholesky factorization. Correspondingly called hermitian positive definite in the complex case. (\n\nExploiting matrix structure)\n\ntensor-product domain\n\nA domain that can be parameterized using variables that lay in a logical rectangle or cuboid; i.e., each variable independently varies in an interval. ()\n\nthin QR factorization\n\nVariant of the QR factorization that discards information not needed to fully represent the original matrix. (\n\nThe QR factorization)\n\nthin SVD\n\nVariant of the singular value decomposition that discards information not needed to fully represent the original matrix. (\n\nSingular value decomposition)\n\ntrapezoid formula\n\nNumerical integration method resulting from integration of a piecewise linear interpolant. (\n\nNumerical integration, \n\nMultistep methods)\n\ntriangular matrix\n\nMatrix that is all zero either above (for lower triangular) or below (for upper triangular) the main diagonal. (\n\nLinear systems)\n\ntridiagonal matrix\n\nMatrix with nonzeros only on the main diagonal and the adjacent two diagonals. (\n\nExploiting matrix structure)\n\ntrigonometric interpolation\n\nInterpolation of a periodic function by a linear combination of real or complex trigonometric functions. ()\n\ntruncation error\n\nDifference between an exact value and an approximation, such as one that truncates an infinite series. (\n\nConvergence of finite differences, \n\nNumerical integration)\n\nunit triangular matrix\n\nTriangular matrix that has a 1 in every position on the main diagonal. (\n\nLU factorization)\n\nunit vector\n\nA vector whose norm equals 1. (\n\nVector and matrix norms)\n\nunitary\n\nSquare matrix with complex-valued entries whose columns are orthonormal. (\n\nEigenvalue decomposition)\n\nunstable\n\nAllowing perturbations of the data to have much larger effects on the results than can be explained by the problem’s condition number. (\n\nStability)\n\nupper Hessenberg\n\nDescribing a matrix that has nonzeros only in the upper triangle and first subdiagonal. (\n\nKrylov subspaces)\n\nVandermonde matrix\n\nMatrix whose columns are formed from elementwise powers of a given vector, important for polynomial interpolation and approximation of data. (\n\nPolynomial interpolation)\n\nweights\n\nCoefficients in a linear combination of function values in a finite-difference or integration method. (\n\nFinite differences, \n\nNumerical integration, )\n\nzero-stable\n\nBoundedness property of multistep methods that is required for convergence. (\n\nZero-stability of multistep methods)","type":"content","url":"/glossary","position":1},{"hierarchy":{"lvl1":"Review of linear algebra"},"type":"lvl1","url":"/linear-algebra","position":0},{"hierarchy":{"lvl1":"Review of linear algebra"},"content":"","type":"content","url":"/linear-algebra","position":1},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Terminology"},"type":"lvl2","url":"/linear-algebra#terminology","position":2},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Terminology"},"content":"An ordinary number in \\mathbb{R} or \\mathbb{C} may be called a scalar. An m\\times n matrix \\mathbf{A} is a rectangular m-by-n array of numbers called elements or entries.  The numbers m and n are called the row dimension and the column dimension, respectively; collectively they describe the size or shape of \\mathbf{A}. We say \\mathbf{A} belongs to the set \\mathbb{R}^{m\\times n} if its entries are real, or \\mathbb{C}^{m\\times n} if they are complex-valued.  A square matrix has equal row and column dimensions. A row vector has dimension 1\\times n, while a column vector has dimension m \\times 1.\n\nIn this text, all vectors are column vectors, and we use \\mathbb{R}^n or \\mathbb{C}^n to denote spaces of these vectors. When a row vector is needed, it is given an explicit transpose symbol (see below).\n\nWe use capital letters in bold to refer to matrices, and lowercase bold letters for vectors. The bold symbol \\boldsymbol{0} may refer to a vector of all zeros or to a zero matrix, depending on context; we use 0 as the scalar zero only.\n\nTo refer to a specific element of a matrix, we use the uppercase name of the matrix without boldface. For instance, A_{24} refers to the (2,4) element of \\mathbf{A}. To refer to an element of a vector, we use just one subscript, as in x_3. A boldface character with one or more subscripts, on the other hand, is a matrix (uppercase) or vector (lowercase) that belongs to a numbered collection.\n\nWe will have frequent need to refer to the individual columns of a matrix as vectors. We use a lowercase bold version of the matrix name with a subscript to represent the column number. For example, \\mathbf{a}_1,\\mathbf{a}_2,\\ldots,\\mathbf{a}_n are the columns of the m\\times n matrix \\mathbf{A}. Conversely, whenever we define a sequence of vectors \\mathbf{v}_1,\\ldots,\\mathbf{v}_p, we can implicitly consider them to be columns of a matrix \\mathbf{V}. Sometimes we might write\\mathbf{V}=\\bigl[ \\mathbf{v}_j \\bigr]\n\nto emphasize the connection between a matrix and its columns.\n\nThe diagonal (more specifically, main diagonal) of an n\\times n matrix \\mathbf{A} refers to the entries A_{ii}, i=1,\\ldots,n. The entries A_{ij} where j-i=k are on a superdiagonal if k>0 and a subdiagonal if k<0. The diagonals are numbered as indicated here:  \\begin{bmatrix}\n    0 & 1 & 2 & \\cdots & n-1 \\\\\n    -1 & 0 & 1 & \\cdots & n-2 \\\\\n    \\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n    -n+2 & \\cdots & -1 & 0 & 1\\\\\n    -n+1 & \\cdots & -2 & -1 & 0\n  \\end{bmatrix}.\n\nA diagonal matrix is one whose entries are all zero off the main diagonal.  An upper triangular matrix \\mathbf{U} has entries U_{ij} with U_{ij}=0 if i>j, and a lower triangular matrix \\mathbf{L} has L_{ij}=0 if i<j.\n\nThe transpose of \\mathbf{A}\\in\\mathbb{C}^{m\\times n} is the matrix \\mathbf{A}^T\\in\\mathbb{C}^{n\\times m} given by  \\mathbf{A}^T =\n  \\begin{bmatrix}\n    A_{11} & A_{21} & \\cdots & A_{m1}\\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    A_{1n} & A_{2n} & \\cdots & A_{mn}\n  \\end{bmatrix}.\n\nThe adjoint or hermitian of a matrix \\mathbf{A} is given by \\mathbf{A}^*=\\overline{\\mathbf{A}^T}, where the bar denotes taking a complex conjugate elementwise. If \\mathbf{A} is real, then \\mathbf{A}^*=\\mathbf{A}^T. A square matrix is symmetric if \\mathbf{A}^T=\\mathbf{A} and hermitian if \\mathbf{A}^*=\\mathbf{A}.","type":"content","url":"/linear-algebra#terminology","position":3},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Algebra"},"type":"lvl2","url":"/linear-algebra#algebra","position":4},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Algebra"},"content":"Matrices and vectors of the same size may be added elementwise.  Multiplication by a scalar is also defined elementwise. These operations obey the familiar laws of commutativity, associativity, and distributivity. The multiplication of two matrices, on the other hand, is less straightforward.\n\nThere are two ways for vectors to be multiplied together. If \\mathbf{v} and \\mathbf{w} are in \\mathbb{C}^n, their inner product is  \\mathbf{v}^* \\mathbf{w} = \\sum_{k=1}^n \\overline{v_k}\\, w_k.\n\nTrivially, one finds that \\mathbf{w}^* \\mathbf{v} = \\overline{(\\mathbf{v}^*\\mathbf{w})}.\n\nAdditionally, any two vectors \\mathbf{v}\\in\\mathbb{C}^m and \\mathbf{w}\\in\\mathbb{C}^n (with m\\neq n allowed) have an outer product, which is an m\\times n matrix:  \\mathbf{v} \\mathbf{w}^*\n  = \\bigl[ v_i \\overline{w_j} \\bigr]_{\\,i=1,\\ldots,m,\\, j=1,\\ldots,n }\n  = \\begin{bmatrix}\n    v_1\\,\\overline{w_1} & v_1\\,\\overline{w_2} & \\cdots & v_1\\,\\overline{w_n}\\\\\n    v_2\\,\\overline{w_1} & v_2\\,\\overline{w_2} & \\cdots & v_2\\,\\overline{w_n}\\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    v_m\\,\\overline{w_1} & v_m\\,\\overline{w_2} & \\cdots & v_m\\,\\overline{w_n}\n  \\end{bmatrix}.\n\nFor real vectors, the complex conjugates above have no effect and {}^* becomes {}^T.\n\nIn order for matrices \\mathbf{A} and \\mathbf{B} to be multiplied, it is necessary that their inner dimensions match. Thus, if \\mathbf{A} is m\\times p, then \\mathbf{B} must be p \\times n. In terms of scalar components, the (i,j) entry of \\mathbf{C}=\\mathbf{A}\\mathbf{B} is given by  C_{ij} = \\sum_{k=1}^p A_{ik} B_{kj}.\n\nNote that even if \\mathbf{A}\\mathbf{B} is defined, \\mathbf{B}\\mathbf{A} may not be. Moreover, even when both products are defined, they may not equal each other.\n\nMatrix multiplication is not commutative, i.e., the order of terms in a product matters to the result.\n\nMatrix multiplication is associative, however:\\mathbf{A}\\mathbf{B}\\mathbf{C}=(\\mathbf{A}\\mathbf{B})\\mathbf{C}=\\mathbf{A}(\\mathbf{B}\\mathbf{C}).\n\nHence while we cannot change the ordering of the terms, we can change the order of the operations. This is a property that we will use repeatedly. We also note here the important identity  (\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T.\n\nSpecifically, if either product is defined, then they both are defined and equal each other.","type":"content","url":"/linear-algebra#algebra","position":5},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear combinations"},"type":"lvl2","url":"/linear-algebra#linear-combinations","position":6},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear combinations"},"content":"It is worth reinterpreting \n\n(6) at a vector level. If \\mathbf{A} has dimensions m\\times n, it can be multiplied on the right by an n \\times 1 column vector \\mathbf{v} to produce an m \\times 1 column vector \\mathbf{A}\\mathbf{v}, which satisfies  \\mathbf{A}\\mathbf{v} =\n  \\begin{bmatrix}\n    \\displaystyle \\sum_k A_{1k}v_k \\\\[2mm]\n    \\displaystyle \\sum_k A_{2k}v_k \\\\\n    \\vdots\\\\\n    \\displaystyle \\sum_k A_{mk}v_k\n  \\end{bmatrix}\n  = v_1\n  \\begin{bmatrix}\n    A_{11}\\\\A_{21}\\\\\\vdots\\\\A_{m1}\n  \\end{bmatrix} +\n  v_2\n  \\begin{bmatrix}\n    A_{12}\\\\A_{22}\\\\\\vdots\\\\A_{m2}\n  \\end{bmatrix} +\n  \\cdots + v_n\n  \\begin{bmatrix}\n    A_{1n}\\\\A_{2n}\\\\\\vdots\\\\A_{mn}\n  \\end{bmatrix} = v_1 \\mathbf{a}_1 + \\cdots + v_n \\mathbf{a}_n.\n\nWe say that \\mathbf{A}\\mathbf{v} is a linear combination of the columns of \\mathbf{A}.\n\nMultiplying a matrix on the right by a column vector produces a linear combination of the columns of the matrix.\n\nThere is a similar interpretation of multiplying \\mathbf{A} on the left by a row vector. Keeping to our convention that boldface letters represent column vectors, we write, for \\mathbf{v}\\in\\mathbb{R}^m,  \\begin{split}\n  \\mathbf{v}^T \\mathbf{A} &=\n  \\begin{bmatrix}\n    \\displaystyle \\sum_k v_k A_{k1} & \\displaystyle \\sum_k v_k A_{k2} & \\cdots & \\displaystyle \\sum_k v_k A_{kn}\n  \\end{bmatrix} \\\\\n   & = v_1\n  \\begin{bmatrix}\n    A_{11} &  \\cdots & A_{1n}\n  \\end{bmatrix} +\n  v_2\n  \\begin{bmatrix}\n    A_{21} & \\cdots & A_{2n}\n  \\end{bmatrix} +\n  \\cdots + v_m\n  \\begin{bmatrix}\n    A_{m1} & \\cdots & A_{mn}\n  \\end{bmatrix}.\n  \\end{split}\n\nMultiplying a matrix on the left by a row vector produces a linear combination of the rows of the matrix.\n\nThese two observations extend to more general matrix-matrix multiplications. One can show that (assuming that \\mathbf{A} is m\\times p and \\mathbf{B} is p\\times n)  \\mathbf{A}\\mathbf{B} =\n  \\mathbf{A} \\begin{bmatrix}\n    \\mathbf{b}_1 & \\mathbf{b}_2 & \\cdots & \\mathbf{b}_n\n  \\end{bmatrix}\n  = \\begin{bmatrix}\n    \\mathbf{A}\\mathbf{b}_1 & \\mathbf{A}\\mathbf{b}_2 & \\cdots & A\\mathbf{b}_n\n  \\end{bmatrix}.\n\nEquivalently, if we write \\mathbf{A} in terms of rows, then  \\mathbf{A} =\n  \\begin{bmatrix}\n    \\mathbf{w}_1^T \\\\[2mm] \\mathbf{w}_2^T \\\\ \\vdots \\\\ \\mathbf{w}_m^T\n  \\end{bmatrix}\n  \\qquad \\Longrightarrow \\qquad\n    \\mathbf{A}\\mathbf{B} =\n  \\begin{bmatrix}\n    \\mathbf{w}_1^T \\mathbf{B} \\\\[2mm] \\mathbf{w}_2^T \\mathbf{B} \\\\ \\vdots \\\\ \\mathbf{w}_m^T \\mathbf{B}\n  \\end{bmatrix}.\n\nA matrix-matrix product is a horizontal concatenation of matrix-vector products involving the columns of the right-hand matrix. Equivalently, a matrix-matrix product is also a vertical concatenation of vector-matrix products involving the rows of the left-hand matrix.\n\nThe representations of matrix multiplication are interchangeable; whichever one is most convenient at any moment can be used.\n\nLet\\mathbf{A} = \\begin{bmatrix}\n      1 & -1 \\\\ 0 & 2 \\\\ -3 & 1\n    \\end{bmatrix}, \\qquad\n\\mathbf{B} = \\begin{bmatrix}\n      2 & -1 & 0 & 4 \\\\ 1 & 1 & 3 & 2\n    \\end{bmatrix}.\n\nThen, going by \n\n(6), we get\\begin{split}\n  \\mathbf{A}\\mathbf{B} &= \\begin{bmatrix}\n          (1)(2) + (-1)(1) & (1)(-1) + (-1)(1) & (1)(0) + (-1)(3) & (1)(4) + (-1)(2) \\\\\n          (0)(2) + (2)(1) & (0)(-1) + (2)(1) & (0)(0) + (2)(3) & (0)(4) + (2)(2) \\\\\n          (-3)(2) + (1)(1) & (-3)(-1) + (1)(1) & (-3)(0) + (1)(3) & (-3)(4) + (1)(2)\n        \\end{bmatrix} \\\\\n  &= \\begin{bmatrix}\n      1 & -2 & -3 & 2 \\\\ 2 & 2 & 6 & 4 \\\\ -5 & 4 & 3 & -10\n    \\end{bmatrix}.\n\\end{split}\n\nBut note also, for instance, that  \\mathbf{A} \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = 2 \\begin{bmatrix} 1 \\\\ 0 \\\\ -3\n    \\end{bmatrix} + 1 \\begin{bmatrix} -1 \\\\ 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\\\ -5 \\end{bmatrix},\n\nand so on, as according to \n\n(11).\n\nThere is also an interpretation, presented in \n\nLU factorization, of matrix products in terms of vector outer products.","type":"content","url":"/linear-algebra#linear-combinations","position":7},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Identity and inverse"},"type":"lvl2","url":"/linear-algebra#identity-and-inverse","position":8},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Identity and inverse"},"content":"The identity matrix of size n, called \\mathbf{I} (or sometimes \\mathbf{I}_n), is a diagonal n\\times n matrix with every diagonal entry equal to one. As can be seen from \n\n(11) and \n\n(12), it satisfies \\mathbf{A}\\mathbf{I}=\\mathbf{A} for \\mathbf{A}\\in\\mathbb{C}^{m\\times n} and \\mathbf{I}\\mathbf{B}=\\mathbf{B} for \\mathbf{B}\\in\\mathbb{C}^{n\\times p}. It is therefore the matrix analog of the number 1, the multiplicative identity.\n\nLet  \\mathbf{B} =\n  \\begin{bmatrix}\n    2 & 1 & 7 & 4\\\\\n    6 & 0 & -1 & 0\\\\\n    -4 & -4 & 0 & 1\n  \\end{bmatrix}.\n\nSuppose we want to create a zero in the (2,1) entry by adding -3 times the first row to the second row, leaving the other rows unchanged.\n\nWe can express this operation as a product \\mathbf{A}\\mathbf{B} as follows. From dimensional considerations alone, \\mathbf{A} will need to be 3\\times 3. According to \n\n(10), we get “-3 times row 1 plus row 2” from left-multiplying \\mathbf{B} by the column vector \\bigl[ -3,\\: 1,\\: 0 \\bigr]. Equation \n\n(12) tells us that this must be the second row of \\mathbf{A}.\n\nSince the first and third rows of \\mathbf{A}\\mathbf{B} are the same as those of \\mathbf{B}, similar logic tells us that the first and third rows of \\mathbf{A} are the same as the identity matrix:  \\begin{bmatrix}\n    1 & 0 & 0\\\\\n    -3 & 1 & 0\\\\\n    0 & 0 & 1\n  \\end{bmatrix} \\mathbf{B}  =\n  \\begin{bmatrix}\n    2 & 1 & 7 & 4\\\\\n    0 & -3 & -22 & -12\\\\\n    -4 & -4 & 0 & 1\n  \\end{bmatrix}.\n\nThis can be verified using \n\n(6).\n\nNote that a square matrix \\mathbf{A} can always be multiplied by itself to get a matrix of the same size. Hence we can define the integer powers \\mathbf{A}^2=(\\mathbf{A})(\\mathbf{A}), \\mathbf{A}^3=(\\mathbf{A}^2) \\mathbf{A} = (\\mathbf{A}) \\mathbf{A}^2 (by associativity), and so on. By definition, \\mathbf{A}^0=\\mathbf{I}.\n\nIf \\mathbf{A} is an n\\times n matrix, then there may be at most one matrix \\mathbf{Z} of the same size such that\\mathbf{Z}\\mathbf{A} = \\mathbf{A}\\mathbf{Z} = \\mathbf{I}.\n\nIf \\mathbf{Z} exists, it is called the inverse of \\mathbf{A} and is written as \\mathbf{A}^{-1}. In this situation we say that \\mathbf{A} is invertible.\n\nThe zero matrix has no inverse. For n>1 there are also nonzero matrices that have no inverse. Such matrices are called singular. The properties “invertible” and “singular” are exclusive opposites; thus, nonsingular means invertible and noninvertible means singular.","type":"content","url":"/linear-algebra#identity-and-inverse","position":9},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear systems"},"type":"lvl2","url":"/linear-algebra#linear-systems","position":10},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear systems"},"content":"Given a square, n\\times n matrix \\mathbf{A} and  n-vectors \\mathbf{x} and \\mathbf{b}, the equation \\mathbf{A}\\mathbf{x}=\\mathbf{b} is equivalent to\\begin{split}\n  a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n &= b_1 \\\\\n  a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n &= b_2 \\\\\n  \\vdots  \\\\\n  a_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nn}x_n &= b_n.\n\\end{split}\n\nThe following facts are usually proved in any elementary text on linear algebra.\n\nLinear algebra equivalence\n\nThe following statements are equivalent:\n\n\\mathbf{A} is nonsingular.\n\n(\\mathbf{A}^{-1})^{-1} = \\mathbf{A}.\n\n\\mathbf{A}\\mathbf{x}=\\boldsymbol{0} implies that \\mathbf{x}=\\boldsymbol{0}.\n\n\\mathbf{A}\\mathbf{x}=\\mathbf{b} has a unique solution, \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}, for any n-vector \\mathbf{b}.","type":"content","url":"/linear-algebra#linear-systems","position":11},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Exercises"},"type":"lvl2","url":"/linear-algebra#exercises","position":12},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Exercises"},"content":"✍ In racquetball, the winner of a rally serves the next rally. Generally, the server has an advantage. Suppose that when Ashley and Barbara are playing racquetball, Ashley wins 60% of the rallies she   serves and Barbara wins 70% of the rallies she serves. If \\mathbf{x}\\in\\mathbb{R}^2 is such that x_1 is the probability that Ashley serves first and x_2=1-x_1 is the probability that Barbara serves first, define a matrix \\mathbf{A} such that \\mathbf{A}\\mathbf{x} is a vector of the probabilities that Ashley and Barbara each serve the second rally. What is the meaning of \\mathbf{A}^{10}\\mathbf{x}?\n\n✍ Suppose we have lists of n terms and m documents. We can   define an m\\times n matrix \\mathbf{A} such that A_{ij}=1 if term j   appears in document i, and A_{ij}=0 otherwise. Now suppose that the term list is\"numerical\", \"analysis\", \"more\", \"cool\", \"accounting\"\n\nand that \\mathbf{x} = \\begin{bmatrix} 1 & 1 & 0 & 1 & 0  \\end{bmatrix}^T. Give an interpretation of the product \\mathbf{A}\\mathbf{x}.Entry $i$ of $A\\mathbf{x}$ is the sum of $a_{ij}x_j$, so the result is the number of the terms 'numerical', 'analysis', and 'cool' that appear in document $i$. (Note: this is not the same as the  total number of occurrences of the words; each term is counted only once.)\n\n✍ Let\\mathbf{A} =\n\\begin{bmatrix}\n  0 & 1 & 0 & 0 \\\\\n  0 & 0 & 0 & 1 \\\\\n  0 & 0 & 0 & 0 \\\\\n  0 & 0 & 1 & 0\n\\end{bmatrix}.\n\nShow that \\mathbf{A}^n=0 when n\\ge 4.\n\n✍  Find two matrices \\mathbf{A} and \\mathbf{B}, neither of which is the zero matrix, such that \\mathbf{A}\\mathbf{B}=\\boldsymbol{0}.\n\n✍ Prove that when \\mathbf{A} \\mathbf{B} is   defined, \\mathbf{B}^T\\mathbf{A}^T is defined too, and use Equation \n\n(6) to show that   (\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T.\n\n✍ Show that if \\mathbf{A} is invertible, then  (\\mathbf{A}^T)^{-1}=(\\mathbf{A}^{-1})^T. (This matrix is often just written as \\mathbf{A}^{-T}.)\n\n✍ Prove true, or give a counterexample: The product of upper triangular square matrices is upper triangular.\n\nThe conjugate of a complex number is found by  replacing all references to the imaginary unit i by -i. We do not use complex numbers until the second half of the book.","type":"content","url":"/linear-algebra#exercises","position":13},{"hierarchy":{"lvl1":"Algorithms"},"type":"lvl1","url":"/algorithms","position":0},{"hierarchy":{"lvl1":"Algorithms"},"content":"An idealized mathematical problem f(x) can usually only be approximated using a finite number of steps in finite precision. A complete set of instructions for transforming data into a result is called an algorithm. In most cases it is reasonable to represent an algorithm by another mathematical function, denoted here by \\tilde{f}(x).\n\nEven simple problems can be associated with multiple algorithms.\n\nSuppose we want to find an algorithm that maps a given x to the value of the polynomial f(x)= 5x^3 + 4x^2 + 3x + 2. Representing x^2 as (x)(x), we can find it with one multiplication. We can then find x^3=(x)(x^2) with one more multiplication. We can then apply all the coefficients (three more multiplications) and add all the terms (three additions), for a total of 8 arithmetic operations.\n\nThere is a more efficient algorithm, however: organize the polynomial according to Horner’s algorithm,f(x) = 2 + x \\bigl( 3 + x( 4 + 5x) \\bigr).\n\nIn this form you can see that evaluation takes only 3 additions and 3 multiplications. The savings represent 25% of the original computational effort, which could be significant if repeated billions of times.","type":"content","url":"/algorithms","position":1},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Algorithms as code"},"type":"lvl2","url":"/algorithms#algorithms-as-code","position":2},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Algorithms as code"},"content":"Descriptions of algorithms may be presented as a mixture of mathematics, words, and computer-style instructions called pseudocode, which varies in syntax and level of formality. In this book we use pseudocode to explain the outline of an algorithm, but the specifics are usually presented as working code.\n\nOf all the desirable traits of code, we emphasize clarity the most after correctness. We do not represent our programs as always being the shortest, fastest, or most elegant. Our primary goal is to illustrate and complement the mathematical underpinnings, while occasionally pointing out key implementation details.\n\nAs our first example, \n\nFunction 1.3.1 implements an algorithm that applies Horner’s algorithm to a general polynomial, using the identity\\begin{split}\np(x) &= c_1 + c_2 x + \\cdots + c_n x^{n-1} \\\\\n&= \\Bigl( \\bigl( (c_n x  + c_{n-1}) x + c_{n-2} \\bigr) x + \\cdots +c_{2} \\Bigr)x + c_{1}.\n\\end{split}\n\nhorner\n\nHorner’s algorithm for evaluating a polynomial\"\"\"\n    horner(c,x)\n\nEvaluate a polynomial whose coefficients are given in ascending\norder in `c`, at the point `x`, using Horner's rule.\n\"\"\"\nfunction horner(c,x)\n    n = length(c)\n    y = c[n]\n    for k in n-1:-1:1\n        y = x*y + c[k]\n    end\n    return y\nend\n\nAbout the code\n\nThe length function in line 8 returns the number of elements in vector c. Here, that value is one greater than the degree of the polynomial. The syntax c[i] accesses element i of a vector c. In Julia, the first index of a vector is 1 by default, so in line 9, the last element of c is accessed.\n\nThe for / end construct in lines 10–12 is a loop. The local variable k is assigned the value n-1, then the loop body is executed, then k is assigned n-2, the body is executed again, and so on until finally k is set to 1 and the body is executed for the last time.\n\nThe return statement in line 13 terminates the function and specifies one or more values to be returned to the caller.\n\nHorner’s algorithm for evaluating a polynomial\"\"\"\n    horner(c,x)\n\nEvaluate a polynomial whose coefficients are given in ascending\norder in `c`, at the point `x`, using Horner's rule.\n\"\"\"\nfunction horner(c,x)\n    n = length(c)\n    y = c[n]\n    for k in n-1:-1:1\n        y = x*y + c[k]\n    end\n    return y\nend\n\nAbout the code\n\nThe length function in line 9 returns the number of elements in vector c. Here, that value is one greater than the degree of the polynomial. The syntax c(i) accesses element i of a vector c. In MATLAB, the first index of a vector is 1 by default.\n\nThe for / end construct in lines 11–13 is a loop. The variable k is assigned the value n-1, then the loop body is executed, then k is assigned n-2, the body is executed again, and so on until finally k is set to 1 and the body is executed for the last time.\n\nThe final value assigned to y is returned to the caller.\n\nHorner’s algorithm for evaluating a polynomial\n\ndef horner(c,x):\n    \"\"\"\n    horner(c,x)\n\n    Evaluate a polynomial whose coefficients are given in descending order \n    in `c`, at the point `x`, using Horner's rule.\n    \"\"\"\n    n = len(c)\n    y = c[0]\n    for k in range(1, n):\n        y = x * y + c[k]   \n    return y\n\nAbout the code\n\nThe len function in line 8 returns the number of elements in list or vector c. Here, that value is one greater than the degree of the polynomial. The syntax c[i] accesses element i of a list or NumPy vector c. In both cases, the first index of a vector is 0.\n\nThe for construct in lines 10–11 is a loop. The local variable k is assigned the value 1, then the loop body is executed, then k is assigned 2, the body is executed again, and so on until finally k is set to n-1 and the body is executed for the last time.\n\nThe return statement in line 12 terminates the function and specifies one or more values to be returned to the caller.\n\nUsing a function\n\nHere we show how to use \n\nFunction 1.3.1 to evaluate a polynomial. It’s not a part of core Julia, so you need to download and install this text’s package once, and load it for each new Julia session. The download is done by the following lines.\n\nimport Pkg\nPkg.add(\"FundamentalsNumericalComputation\");\n\nOnce installed, any package can be loaded with the using command, as follows.\n\nMany Julia functions, including the ones in this text, are in packages that must be loaded via using or import in each session. Sometimes a using statement can take a few seconds or even minutes to execute, if packages have been installed or updated.\n\nusing FundamentalsNumericalComputation\n\nFor convenience, this package also imports many other packages used throughout the book and makes them available as though you had run a using command for each of them.:::{card}\n\nIf you are not sure where a particular function is defined, you can run `methods` on the function name to find all its definitions.\n\n\nReturning to horner, let us define a vector of the coefficients of p(x)=(x-1)^3=x^3-3x^2+3x-1, in ascending degree order.\n\nc = [-1, 3, -3, 1]\n\nIn order to avoid clashes between similarly named functions, Julia has boxed all the book functions into a namespace called FNC. We use this namespace whenever we invoke one of the functions.:::{card}\n\nYou must use the module name when a package is loaded by `import`, but when loaded via `using`, some functions may be available with no prefix.\n\n\nFNC.horner(c, 1.6)\n\nThe above is the value of p(1.6).\n\nWhile the namespace does lead to a little extra typing, a nice side effect of using this paradigm is that if you type FNC. (including the period) and hit the Tab key, you will see a list of all the functions known in that namespace.\n\nThe multi-line string at the start of \n\nFunction 1.3.1 is documentation, which we can access using ?FNC.horner.\n\nmatlab\n\nUsing a function\n\nHere we show how to use horner to evaluate a polynomial. First, we have to ensure that the FNC package is imported.\n\nimport FNC\n\nHere is the help string for the function:\n\nhelp(FNC.horner)\n\nWe now define a vector of the coefficients of p(x)=(x−1)^3=x^3−3x^2+3x−1, in descending degree order. Note that the textbook’s functions are all in a namespace called FNC, to help distinguish them from other Python commands and modules.\n\nc = array([1, -3, 3, -1])\nprint(FNC.horner(c, 1.6))\n\nThe above is the value of p(1.6), up to a rounding error.\n\nThe quoted lines at the beginning of \n\nFunction 1.3.1 are a documentation string. The function itself starts off with the keyword function, followed by a list of its input arguments. The first of these is presumed to be a vector, whose length can be obtained and whose individual components are accessed through square bracket notation. After the computation is finished, the return keyword indicates which value or values are to be returned to the caller.\n\nThe Polynomials package for Julia provides its own fast methods for polynomial evaluation that supersede our simple \n\nFunction 1.3.1 function. This will be the case for all the codes in this book because the problems we study are well-known and important. In a more practical setting, you would take implementations of basic methods for granted and build on top of them.","type":"content","url":"/algorithms#algorithms-as-code","position":3},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Writing your own functions"},"type":"lvl2","url":"/algorithms#writing-your-own-functions","position":4},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Writing your own functions"},"content":"Any collection of statements organized around solving a type of problem should probably be wrapped in a function. One clue is that if you find yourself copying and pasting code, perhaps with small changes in each instance, you should probably be writing a function instead.\n\nFunctions can be defined in text files with the extension .jl, at the command line (called the REPL prompt), or in notebooks.\n\nAs seen in \n\nFunction 1.3.1, one way to start a function definition is with the function keyword, followed by the function name and the input arguments in parentheses. For example, to represent the mathematical function e^{\\sin x}, we could usefunction myfun(x)\n    s = sin(x)\n    return exp(s)\nend\n\nThe return statement is used to end execution of the function and return one or more (comma-separated) values to the caller of the function. If an executing function reaches its end statement without encountering a return statement, then it returns the result of the most recent statement, but this is considered poor style.\n\nFor a function with a short definition like the one above, there is a more compact syntax to do the same thing:myfun(x) = exp(sin(x))\n\nYou can also define anonymous functions or lambda functions, which are typically simple functions that are provided as inputs to other functions. This is done with an arrow notation. For example, to plot the function above (in the Plots package) without permanently creating it, you could enterplot(x -> exp(sin(x)), 0, 6)\n\nAs in most languages, input arguments and variables defined within a function have scope limited to the function itself. However, they can access values defined within an enclosing scope. For instance:mycfun(x) = exp(c*sin(x))\nc = 1;  mycfun(3)   # returns exp(1*sin(3))\nc = 2;  mycfun(3)   # returns exp(2*sin(3))\n\nThere’s a lot more to be said about functions in Julia, but this is enough to get started.\n\nFunctions can be defined in text files with the extension .m, at the command line, or in Live Scripts.\n\nAs seen in \n\nFunction 1.3.1, one way to start a function definition is with the function keyword, followed one or more output arguments in brackets, the function name, and the input arguments in parentheses. For example, to represent the mathematical function e^{\\sin x}, we could use the following in a file called myfun.m:function [y] = myfun(x)\n    s = sin(x);\n    y = exp(s);\nend\n\nWhatever value is assigned to y when the function terminates will be returned as the output of the function.\n\nFor a function with a short definition like the one above, there is a more compact syntax to do the same thing:myfun = @(x) exp(sin(x));\n\nThe syntax on the right of the = above defines an anonymous function (called a lambda function in computer science), which can be used in place without giving it a name as we did here. We’ll have examples of doing this later on.\n\nAs in most languages, input arguments and variables defined within a function have scope limited to the function itself. However, they can access values defined within an enclosing scope, with those values being locked in at the time of creation. For instance:c = 1;\nmycfun = @(x) exp(c*sin(x));\nmycfun(3)   % returns exp(1*sin(3))\nc = 2;  \nmycfun(3)   % also returns exp(1*sin(3))\nmycfun = @(x) exp(c*sin(x));   % redefines mycfun\nmycfun(3)   % now returns exp(2*sin(3))\n\n\nThere’s a lot more to be said about functions, but this is enough to get started.\n\nFunctions can be defined in text files with the extension .py, at the command line (called the REPL prompt), or in notebooks.\n\nAs seen in \n\nFunction 1.3.1, one way to start a function definition is with the def keyword, followed by the function name and the input arguments in parentheses, ending with a colon. The statements for the body of the function must then all be indented. For example, to represent the mathematical function e^{\\sin x}, we could usedef myfun(x):\n    s = np.sin(x)\n    return np.exp(s)\n\nThe return statement is used to end execution of the function and return one or more (comma-separated) values to the caller of the function.\n\nTip\n\nIf an executing function reaches its end statement without encountering a return statement, then the output is undefined, which is a common source of bugs.\n\nFor a function with a short definition like the one above, there is a more compact syntax to do the same thing:myfun = lambda x : np.exp(np.sin(x))\n\nThe syntax on the right of the = above defines an anonymous function (called a lambda function in computer science), which can be used in place without giving it a name as we did here. We’ll have examples of doing this later on.\n\nAs in most languages, input arguments and variables defined within a function have scope limited to the function itself. However, they can access values defined within an enclosing scope. For instance:mycfun = lambda x : np.exp(c * np.sin(x))\nc = 1;  print(mycfun(3))   # exp(1*sin(3))\nc = 2;  print(mycfun(3))   # exp(2*sin(3))\n\nThere’s a lot more to be said about functions in Python, but this is enough to get started.","type":"content","url":"/algorithms#writing-your-own-functions","position":5},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Exercises"},"type":"lvl2","url":"/algorithms#exercises","position":6},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Exercises"},"content":"Note\n\nThe exercises marked with a computer icon require the use of a computer. The others can be done by hand.\n\nWarning\n\nA polynomial is represented as a vector of coefficients in all three languages covered by this book. However, in Julia they are given in ascending degree order, which is most convenient programmatically, while in MATLAB and NumPy they are given in descending order, which is the way we usually write them. This difference makes writing the exercises universally a little awkward, so be advised.\n\n⌨ Write a function poly1(p) that returns the value of a polynomial p(x) = c_1 + c_2 x + \\cdots + c_n x^{n-1} at x=-1. You should do this directly, not by a call to or imitation of \n\nFunction 1.3.1. Test your function on r(x)=3x^3-x+1 and s(x)=2x^2-x.\n\n⌨  In statistics, one defines the variance of sample values x_1,\\ldots,x_n bys^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\overline{x})^2,\n\\qquad \\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n\nWrite a function samplevar(x) that takes as input a vector x of any length and returns s^2 as calculated by the formula. You should test your function on the vectors ones(100) and rand(200). If you enter using Statistics in Julia, then you can compare to the results of the var function.\n\n⌨  Let x and y be vectors whose entries give the coordinates of the n vertices of a polygon, given in counterclockwise order. Write a function polygonarea(x,y) that computes and returns the area of the polygon using this formula based on Green’s theorem:A = \\frac{1}{2} \\left| \\sum_{k=1}^n x_k y_{k+1} - x_{k+1}y_k \\right|.\n\nHere n is the number of polygon vertices, and it’s understood that x_{n+1}=x_1 and y_{n+1}=y_1. (Note: The function abs computes absolute value.) Test your functions on a square and an equilateral triangle.","type":"content","url":"/algorithms#exercises","position":7},{"hierarchy":{"lvl1":"Problems and conditioning"},"type":"lvl1","url":"/conditioning","position":0},{"hierarchy":{"lvl1":"Problems and conditioning"},"content":"Let’s think a bit about what must be the easiest math problem you’ve dealt with in quite some time: adding 1 to a number. Formally, we describe this problem as a function f(x)=x+1, where x is any real number.\n\nOn a computer, x will be represented by its floating-point counterpart, \\fl(x). Given the property \n\n(1.1.5), we have \\fl(x)=x(1+\\epsilon) for some ε satisfying |\\epsilon| < \\macheps/2.  There is no error in representing the value 1.\n\nLet’s suppose that we are fortunate and that the addition proceeds exactly, with no additional errors. Then the machine result is just  {y} = x(1+\\epsilon)+1.\n\nWe can derive the relative error in this result:  \\frac{ |{y}-f(x)| }{ |f(x)| } = \\frac{ |(x+\\epsilon x+1) - (x+1)| }{ |x+1| }\n  = \\frac{ |\\epsilon x| }{ |x+1| } .\n\nThis error could be quite large if the denominator is small. In fact, we can make the relative error as large as we please by taking x very close to -1. This is essentially what happened in \n\nDemo 1.1.4.\n\nYou may have encountered this situation before when using significant digits for scientific calculations. Suppose we round all results to five decimal digits, and we add -1.0012 to 1.0000. The result is -0.0012, or -1.2\\times 10^{-3} in scientific notation. Notice that even though both operands are specified to five digits, it makes no sense to write more than two digits in the answer because there is no information in the problem beyond their decimal places.\n\nThis phenomenon is known as subtractive cancellation, or loss of significance. We may say that three digits were “lost” in the mapping from -1.0012 to -0.0012. There’s no way the loss could be avoided, regardless of the algorithm, once we decided to round off everything to a fixed number of digits.\n\nSubtractive cancellation\n\nSubtractive cancellation is a loss of accuracy that occurs when two numbers add or subtract to give a result that is much smaller in magnitude. It is one of the most common mechanisms introducing dramatic growth of errors in floating-point computation.\n\nIn double precision, all  the values are represented to about 16 significant decimal digits of precision, but it’s understood that subtractive cancellation may render some of those digits essentially meaningless.","type":"content","url":"/conditioning","position":1},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Condition numbers"},"type":"lvl2","url":"/conditioning#condition-numbers","position":2},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Condition numbers"},"content":"Now we consider problems more generally. As above, we represent a problem as a function f that maps a real data value x to a real result f(x). We abbreviate this situation by the notation f:\\real \\mapsto \\real, where \\real represents the real number set.\n\nWhen the problem f is approximated in floating point on a computer, the data x is represented as a floating-point value \\tilde{x}=\\fl(x). Ignoring all other sources of error, we define the quantitative measure   \\frac{ \\vphantom{\\dfrac{\\bigl|}{\\bigl|}}\\dfrac{|f(x)-f(\\tilde{x})|}{|f(x)|} }{%\n     \\vphantom{\\dfrac{\\bigl|}{\\bigl|}}\\dfrac{|x-\\tilde{x}|}{|x|} },\n\nwhich is the ratio of the relative changes in result and data. We make this expression more convenient if we recall that floating-point arithmetic gives \\tilde{x}=x(1+\\epsilon) for some value |\\epsilon|\\le \\macheps/2. Hence   \\dfrac{\\left|f(x)-f(x+\\epsilon x)\\right| } {|\\epsilon f(x)|}.\n\nFinally, we idealize what happens in a perfect computer by taking a limit as \\macheps\\to 0.\n\nCondition number (scalar function)\n\nThe relative condition number of a scalar function f(x) is   \\kappa_f(x) = \\lim_{\\epsilon\\to 0} \\dfrac{ |f(x)-f(x(1+\\epsilon))| }{ |\\epsilon f(x)| }.\n\nThe condition number is a ratio of the relative error of the output to the relative error of the input. It depends only on the problem and the data, not the computer or the algorithm.\n\nAssuming that f has at least one continuous derivative, we can simplify the expression \n\n(1.2.5) through some straightforward manipulations:\\begin{split}\n   \\kappa_f(x) &= \\lim_{\\epsilon\\to 0} \\left| \\dfrac{ f(x+\\epsilon x) - f(x) }{ \\epsilon f(x)}\n   \\right| \\\\\n  &= \\lim_{\\epsilon\\to 0}  \\left| \\dfrac{ f(x+\\epsilon x) - f(x) }{ \\epsilon x} \\cdot  \\frac{x}{f(x)}  \\right| \\\\\n   &= \\left| \\dfrac{ x f'(x)} {f(x)}  \\right|.\n\\end{split}\n\nIn retrospect, it should come as no surprise that the change in values of f(x) due to small changes in x involves the derivative of f. In fact, if we were making measurements of changes in absolute rather than relative terms, the condition number would be simply |f'(x)|.\n\nLet’s return to our “add 1” problem and generalize it slightly to f(x)=x-c for constant c. We compute, using \n\n(1.2.6),\\kappa_f(x)=\\left| \\frac{(x)(1)}{x-c} \\right| = \\left| \\frac{x}{x-c}\\right|.\n\nThe result is the relative change \n\n(1.2.2) normalized by the size of the perturbation ε. The condition number is large when |x|\\gg |x-c|. Considering that c can be negative, this result applies to both addition and subtraction. Furthermore, the situation is symmetric in x and c; that is, if we perturbed c and not x, the result would be |c|/|x-c|.\n\nAnother elementary operation is to multiply by a constant: f(x)=cx for nonzero c. We compute\\kappa_f(x) = \\left| \\dfrac{ x f'(x)} {f(x)}  \\right| = \\left| \\frac{(x)(c)}{cx} \\right| = 1.\n\nWe conclude that multiplication by a real number leads to the same  relative error in the result as in the data. In other words,  multiplication does not have the potential for cancellation error that addition does.\n\nCondition numbers of the major elementary functions are given in \n\nTable 1.2.1.\n\nTable 1.2.1:Relative condition numbers of elementary functions\n\nFunction\n\nCondition number\n\nf(x) = x + c\n\n\\kappa_f(x) = \\dfrac{\\lvert x \\rvert}{\\lvert x+c\\rvert}\n\nf(x) = cx\n\n\\kappa_f(x) = 1\n\nf(x) = x^p\n\n\\kappa_f(x) = \\lvert p \\rvert\n\nf(x) = e^x\n\n\\kappa_f(x) = \\lvert x \\rvert\n\nf(x) = \\sin(x)\n\n\\kappa_f(x) = \\lvert x\\cot(x) \\rvert\n\nf(x) = \\cos(x)\n\n\\kappa_f(x) = \\lvert x\\tan(x) \\rvert\n\nf(x) = \\log(x)\n\n\\kappa_f(x) = \\dfrac{1}{\\lvert \\log(x) \\rvert}\n\nAs you are asked to show in \n\nExercise 4, when two functions f and g are combined in a chain as h(x)=f(g(x)), the composite condition number is\\kappa_h(x) = \\kappa_f(g(x)) \\cdot \\kappa_g(x).","type":"content","url":"/conditioning#condition-numbers","position":3},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Estimating errors"},"type":"lvl2","url":"/conditioning#estimating-errors","position":4},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Estimating errors"},"content":"Refer back to the definition of \\kappa_f as a limit in \n\n(1.2.5). Approximately speaking, if |\\epsilon| is small, we expect\\left| \\dfrac{ f(x+\\epsilon x) - f(x) }{ f(x)}  \\right| \\approx \\kappa_f(x)\\, |\\epsilon|.\n\nThat is, whenever the data x is perturbed by a small amount, we expect that relative perturbation to be magnified by a factor of \\kappa_f(x) in the result.\n\nIf \\kappa_f \\approx 10^d, then we expect to lose up to d decimal digits of accuracy in computing f(x) from x.\n\nLarge condition numbers signal when errors cannot be expected to remain comparable in size to roundoff error. We call a problem poorly conditioned or ill-conditioned when \\kappa_f(x) is large, although there is no fixed threshold for the term.\n\nIf \\kappa_f \\approx 1/\\macheps, then we can expect the result to have a relative error of as much as 100% simply by expressing the data x in finite precision. Such a function is essentially not computable at this machine epsilon.\n\nConsider the problem f(x)= \\cos(x). By the table above, \\kappa_f(x) = |x \\tan x|. There are two different ways in which κ might become large:\n\nIf |x| is very large, then perturbations that are small relative to x may still be large compared to 1. Because |f(x)|\\le 1 for all x, this implies that the perturbation will be large relative to the result, too.\n\nThe condition number grows without bound as x approaches an odd integer multiple of \\pi/2, where f(x)=0. A perturbation which is small relative to a nonzero x may not be small relative to f(x) in such a case.\n\nYou may have noticed that for some functions, such as the square root, the condition number can be less than 1. This means that relative changes get smaller in the passage from input to output. However, every result in floating-point arithmetic is still subject to rounding error at the relative level of \\macheps. In practice, \\kappa_f<1 is no different from \\kappa_f=1.","type":"content","url":"/conditioning#estimating-errors","position":5},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Polynomial roots"},"type":"lvl2","url":"/conditioning#polynomial-roots","position":6},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Polynomial roots"},"content":"Most problems have multiple input and output values. These introduce complications into the formal definition of the condition number. Rather than worry over those details here, we can still look at variations in only one output value with respect to one data value at a time.\n\nConsider the problem of finding the roots of a quadratic polynomial; that is, the values of t for which at^2+bt+c=0. Here the data are the coefficients a, b, and c that define the polynomial, and the solution to the problem are the two (maybe complex-valued) roots r_1 and r_2. Formally, we might write f([a,b,c])=[r_1,r_2] using vector notation.\n\nLet’s pick one root r_1 and consider what happens to it as we vary just the leading coefficient a. This suggests a scalar function f(a)=r_1. Starting from ar_1^2 + br_1 + c = 0, we differentiate implicitly with respect to a while holding b and c fixed:r_1^2 + 2a r_1 \\left(\\frac{dr_1}{da}\\right) + b \\,\\frac{dr_1}{da} = 0.\n\nSolving for the derivative, we obtain\\frac{dr_1}{da} = \\frac{-r_1^2}{2a r_1 + b}.\n\nHence the condition number for the problem f(a)=r_1 is\\kappa_f(a)  = \\left|\\frac{a}{r_1} \\cdot \\frac{dr_1}{da} \\right| = \\left| \\frac{a r_1}{ 2a r_1 + b} \\right|\n= \\left| \\frac{r_1}{ r_1-r_2} \\right|,\n\nwhere in the last step we used the quadratic formula:|2ar_1 + b | = \\left| \\sqrt{b^2-4ac} \\, \\right| = |a(r_1 - r_2)|.\n\nBased on \n\n(1.2.13), we can expect poor conditioning in the rootfinding problem if and only if |r_1| \\gg |r_1-r_2|. Similar conclusions apply for r_2 and for variations with respect to the coefficients b and c.\n\nThe calculation in \n\nExample 1.2.4 generalizes to polynomials of higher degree.\n\nRoots of polynomials are ill-conditioned with respect to changes in the polynomial coefficients when they are much closer to each other than to the origin.\n\nThe condition number of a root can be arbitrarily large. In the extreme case of a repeated root, the condition number is formally infinite, which implies that the ratio of changes in the root to changes in the coefficients cannot be bounded.\n\nConditioning of polynomial roots\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nThe statement x,y = 10,20 makes individual assignments to both x and y.\n\nϵ = 1e-6   # type \\epsilon and then press Tab\na,b,c = 1/3,(-2-ϵ)/3,(1+ϵ)/3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4a*c)\nr₁ = (-b - d) / (2a)   # type r\\_1 and then press Tab\nr₂ = (-b + d) / (2a)\n(r₁, r₂)\n\nThe relative errors in these values are\n\n@show abs(r₁ - 1) / abs(1);\n@show abs(r₂ - (1+ϵ)) / abs(1+ϵ);\n\nThe condition number of each root is\n\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}. \n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps() / ϵ\n\nThis matches the observation pretty well.\n\nConditioning of polynomial roots\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nep = 1e-6;\na = 1/3;             % coefficients of p...\nb = (-2 - ep) / 3;   % ...\nc = (1 + ep) / 3;    % ...in ascending order\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4*a*c);\nformat long   % show all digits\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative errors are\n\nPutting values inside square brackets creates a vector.\n\nformat short e\nerr = abs(r1 - 1) ./ abs(1)\nerr = abs(r2 - (1 + ep)) ./ abs(1 + ep)\n\nThe condition number of each root is\n\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}. \n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps / ep\n\nThis matches the observation pretty well.\n\nConditioning of polynomial roots\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nThe statement x, y = 10, 20 makes individual assignments to both x and y.\n\nep = 1e-6   \na, b, c = 1/3, (-2 - ep) / 3, (1 + ep) / 3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b**2 - 4*a*c)\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\nprint(r1, r2)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative error in the value is\n\nprint(abs(r1 - 1) / abs(1))\nprint(abs(r2 - (1 + ep)) / abs(1 + ep))\n\nThe condition number of each root is\n\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}. \n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\nprint(finfo(float).eps / ep)\n\nThis matches the observation pretty well.","type":"content","url":"/conditioning#polynomial-roots","position":7},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Exercises"},"type":"lvl2","url":"/conditioning#exercises","position":8},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Exercises"},"content":"✍ Use \n\n(1.2.6) to derive the relative condition numbers of the following functions appearing in \n\nTable 1.2.1.\n\n(a) f(x) = x^p,\\quad\n(b) f(x) = \\log(x),\\quad\n(c) f(x) = \\cos(x),\\quad\n(d) f(x) = e^x.\n\n✍ Use the chain rule \n\n(1.2.9) to find the relative condition number of the given function. Then check your result by applying \n\n(1.2.6) directly.\n\n(a) f(x) = \\sqrt{x+5},\\quad\n(b) f(x) = \\cos(2\\pi x),\\quad\n(c) f(x) = e^{-x^2}.\n\n✍ Calculate the relative condition number of each function, and identify all values of x at which \\kappa_{f}(x)\\to\\infty (including limits as x\\to\\pm\\infty).\n\n(a) f(x) = \\tanh(x),\\quad\n(b) f(x) = \\dfrac{e^x-1}{x},\\quad\n(c) f(x) = \\dfrac{1-\\cos(x)}{x}.\n\n✍ Suppose that f and g are real-valued functions that have relative condition numbers \\kappa_f and \\kappa_g, respectively. Define a new function h(x)=f\\bigl(g(x)\\bigr). Show that for x in the domain of h, the relative condition number of h satisfies \n\n(1.2.9).\n\n✍ Suppose that f is a function with relative condition number \\kappa_f, and that f^{-1} is its inverse function. Show that the relative condition number of f^{-1} satisfies\\kappa_{f^{-1}}(x) = \\frac{1}{\\kappa_f\\Bigl( f^{-1}(x) \\Bigr)},\n\nprovided the denominator is nonzero.\n\n✍  Referring to the derivation of \n\n(1.2.13), derive an expression for the relative condition number of a root of ax^2+bx+c=0 due to perturbations in b only.\n\nThe polynomial x^2-2x+1 has a double root at 1. Let r_1(\\epsilon) and r_2(\\epsilon) be the roots of the perturbed polynomial x^2-(2+\\epsilon)x+1.\n\n(a) ✍/⌨ Using a computer or calculator, make a table with rows for \\epsilon = 10^{-2}, \n\n10-4, \n\n10-6, \\ldots, \n\n10-12 and columns for ε, r_1(\\epsilon), r_2(\\epsilon), |r_1(\\epsilon)-1|, and |r_2(\\epsilon)-1|.\n\n(b) ✍ Show that the observations of part (a) satisfy\\max\\{\\, |r_1(\\epsilon)-1|, |r_2(\\epsilon)-1| \\,\\} \\approx C \\epsilon^q\n\nfor some 0<q<1. (This supports the conclusion that \\kappa=\\infty at the double root.)\n\n✍ Generalize \n\n(1.2.13) to finding a root of the nth degree polynomial p(x) = a_nx^n + \\cdots + a_1 x + a_0, and show that the relative condition number of a root r with respect to perturbations only in a_k is\\kappa_r(a_k) = \\left| \\frac{a_k r^{k-1}}{p'(r)} \\right|.","type":"content","url":"/conditioning#exercises","position":9},{"hierarchy":{"lvl1":"Floating-point numbers"},"type":"lvl1","url":"/floating-point","position":0},{"hierarchy":{"lvl1":"Floating-point numbers"},"content":"The real number set \\real is infinite in two ways: it is unbounded and continuous. In most practical computing, the latter kind of infiniteness is much more consequential than the former, so we turn our attention there first.\n\nFloating-point numbers\n\nThe set \\float of floating-point numbers consists of zero and all numbers of the form  \\pm (1 + f) \\times 2^n,\n\nwhere n is an integer called the exponent, and 1+f is the significand, in which  f = \\sum_{i=1}^d b_i \\, 2^{-i}, \\qquad b_i\\in\\{0,1\\},\n\nfor a fixed integer d called the binary precision.\n\nEquation \n\n(1.1.2) represents the significand as a number in [1,2) in base-2 form. Equivalently,f = 2^{-d}\\, \\sum_{i=1}^{d} b_{i} \\, 2^{d-i} = 2^{-d} z\n\nfor an integer z in the set \\{0,1,\\ldots,2^d-1\\}. Consequently, starting at 2^n and ending just before 2^{n+1} there are exactly 2^d evenly spaced numbers belonging to \\float.\n\nSuppose d=2. Taking n=0 in \n\n(1.1.1), we enumerate1 + \\frac{0}{4}, \\: 1 + \\frac{1}{4}, \\: 1 + \\frac{2}{4}, \\: 1 + \\frac{3}{4}.\n\nThese are the only members of \\float in the semi-closed interval [1,2), and they are separated by spacing \\tfrac{1}{4}.\n\nTaking n=1 doubles each of the values in the list above, and n=-1 halves them. These give the floating-point numbers in [2,4) and [1/2,1), respectively. The spacing between them also is doubled and halved, respectively.\n\nObserve that the smallest element of \\float that is greater than 1 is 1+2^{-d}, and we call the difference machine epsilon.\n\nMachine epsilon\n\nFor a floating-point set with d binary digits of precision, machine epsilon (or machine precision) is \\macheps = 2^{-d}.\n\nWe define the rounding function \\fl(x) as the map from real number x to the nearest member of \\float. The distance between the floating-point numbers in [2^n,2^{n+1}) is 2^n\\macheps=2^{n-d}. As a result, every real x \\in [2^n,2^{n+1}) is no farther than 2^{n-d-1} away from a member of \\float. Therefore we conclude that |\\fl(x)-x| \\le \\tfrac{1}{2}(2^{n-d}), which leads to the bound\\frac{|\\fl(x)-x|}{|x|} \\le \\frac{2^{n-d-1}}{2^n} \\le  \\tfrac{1}{2}\\macheps.\n\nIn words, every real number is represented with a uniformly bounded relative precision. Inequality \n\n(1.1.5) holds true for negative x as well. In \n\nExercise 2 you are asked to show that an equivalent statement is that  \\fl(x)=x(1+\\epsilon) \\quad \\text{for some $|\\epsilon|\\le \\tfrac{1}{2}\\macheps$.}\n\nThe value of ε depends on x, but this dependence is not usually shown explicitly.","type":"content","url":"/floating-point","position":1},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Precision and accuracy"},"type":"lvl2","url":"/floating-point#precision-and-accuracy","position":2},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Precision and accuracy"},"content":"It may help to recast \n\n(1.1.1) and \n\n(1.1.2) in terms of base 10:\\pm \\left(b_0 + \\sum_{i=1}^d b_i \\, 10^{-i} \\right) \\times 10^n = \\pm (b_0.b_1b_2\\cdots b_d) \\times 10^n,\n\nwhere each b_i is in \\{0,1,\\ldots,9\\} and b_0\\neq 0. This is simply scientific notation with d+1 significant digits. For example, Planck’s constant is 6.626068\\times 10^{-34} m{}^2\\cdotkg/sec to seven digits. If we alter just the last digit from 8 to 9, the relative change is\\frac{0.000001\\times 10^{-34}}{6.626068\\times 10^{-34}} \\approx 1.51\\times 10^{-7}.\n\nWe therefore say that the constant is given with 7 decimal digits of precision. That’s in contrast to noting that the value is given to 40 decimal places. A major advantage of floating point is that the relative precision does not depend on the choice of physical units. For instance, when expressed in eV•sec, Planck’s constant is 4.135668\\times 10^{-15}, which still has 7 digits but only 21 decimal places.\n\nFloating-point precision functions the same way, except that computers prefer base 2 to base 10. The precision of a floating-point number is always d binary digits, implying a resolution of the real numbers according to \n\n(1.1.5).\n\nIt can be easy to confuse precision with accuracy, especially when looking at the result of a calculation on the computer. Every result is computed and represented using d binary digits, but not all of those digits may accurately represent an intended value. Suppose x is a number of interest and \\tilde{x} is an approximation to it. The absolute accuracy of \\tilde{x} is|\\tilde{x} - x|,\n\nwhile the relative accuracy is\\frac{|\\tilde{x} - x|}{|x|}.\n\nAbsolute accuracy has the same units as x, while relative accuracy is dimensionless. We can also express the relative accuracy as the number of accurate digits, computed in base 10 as-\\log_{10} \\left| \\frac{\\tilde{x}-x}{x} \\right|.\n\nWe often round this value down to an integer, but it does make sense to speak of “almost seven digits” or “ten and a half digits.”\n\nAbsolute and relative accuracy\n\nRecall the grade-school approximation to the number π.\n\n@show p = 22/7;\n\nNot all the digits displayed for p are the same as those of π.\n\nThe value of pi is predefined and equivalent to π, which is entered by typing \\pi followed immediately by the Tab key.\n\n@show float(π);\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nA dollar sign $ in a string substitutes (or interpolates) the named variable or expression into the string.\n\nacc = abs(p-π)\nprintln(\"absolute accuracy = $acc\")\nprintln(\"relative accuracy = $(acc/π)\")\n\nHere we calculate the number of accurate digits in p.\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprintln(\"Number of accurate digits = $(-log10(acc/π))\")\n\nThis last value could be rounded down by using floor.\n\nAbsolute and relative accuracy\n\nRecall the grade-school approximation to the number π.\n\n```{index} MATLAB; format\n```{card}\nThe number of digits displayed is controlled by `format`, but the underlying values are not affected by it.\n\nformat long\np = 22/7\n\nNot all the digits displayed for p are the same as those of π.\n\nThe value of pi is predefined.\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nabs_accuracy = abs(p - pi)\nrel_accuracy = abs(p - pi) / pi\n\nHere we calculate the number of accurate digits in p.\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nformat short\naccurate_digits = -log10(rel_accuracy)\n\nAbsolute and relative accuracy\n\nRecall the grade-school approximation to the number π.\n\np = 22/7\nprint(p)\n\nNot all the digits displayed for p are the same as those of π.\n\nThe value of pi is predefined in the numpy package.\n\nprint(pi)\n\nThe absolute and relative accuracies of the approximation are as follows:\n\nWe often use \n\nPython f-strings to format numerical output.\n\nprint(f\"absolute accuracy: {abs(p - pi)}\")\n\nrel_acc = abs(p - pi) / pi\nprint(\"relative accuracy: {rel_acc:.4e}\")\n\nHere we calculate the number of accurate digits in p:\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprint(f\"accurate digits: {-log10(rel_acc):.1f}\")","type":"content","url":"/floating-point#precision-and-accuracy","position":3},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Double precision"},"type":"lvl2","url":"/floating-point#double-precision","position":4},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Double precision"},"content":"Most numerical computing today is done in the IEEE 754 standard. This defines single precision with d=23 binary digits for the fractional part f, and the more commonly used double precision with d=52. In double precision,\\macheps = 2^{-52} \\approx 2.2\\times 10^{-16}.\n\nWe often speak of double-precision floating-point numbers as having about 16 decimal digits. The 52-bit significand is paired with a sign bit and 11 binary bits to represent the exponent n in \n\n(1.1.1), for a total of 64 binary bits per floating-point number.\n\nFloating-point representation\n\nIn Julia, 1 and 1.0 are different values, because they have different types:\n\n@show typeof(1);\n@show typeof(1.0);\n\nThe standard choice for floating-point values is Float64, which is double precision using 64 binary bits. We can see all the bits by using bitstring.\n\nbitstring(1.0)\n\nThe first bit determines the sign of the number::::{card}\n\nSquare brackets concatenate the contained values into vectors.\n\n\n[bitstring(1.0), bitstring(-1.0)]\n\nThe next 11 bits determine the exponent (scaling) of the number, and so on.\n\n[bitstring(1.0), bitstring(2.0)]\n\nThe sign bit, exponent, and significand in \n\n(1.1.1) are all directly accessible.\n\nx = 3.14\n@show sign(x), exponent(x), significand(x);\n\nx = x / 8\n@show sign(x), exponent(x), significand(x);\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. You can get its value from the eps function in Julia. By default, it returns the value for double precision.\n\nTo call a function, including eps, you must use parentheses notation, even when there are no input arguments.\n\neps()\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps())\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nnextfloat(161.8)\n\nans - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\n@show floatmin(),floatmax();\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2^(-4)\n\nThere are some exceptions. A floating-point value can’t be used as an index into an array, for example, even if it is numerically equal to an integer. In such cases you use Int to convert it.\n\n@show 5.0, Int(5.0);\n\nIf you try to convert a noninteger floating-point value into an integer you get an InexactValue error. This occurs whenever you try to force a type conversion that doesn’t make clear sense.\n\nFloating-point representation\n\nIn MATLAB, values are double-precision floats unless declared otherwise.\n\nfprintf('1 has type: %s', class(1))\nfprintf('1.0 has type: %s', class(1.0))\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. Its value is predefined as eps.\n\nWhile you can assign a different value to eps, doing so does not change any arithmetic. It’s generally a bad idea.\n\neps\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps)\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nx = 161.8 + 0.1*eps(161.8);\nx - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\nformat short e\n[realmin, realmax]\n\nFloating-point representation\n\nPython has native int and float types.\n\nprint(f\"The type of {1} is {type(1)}\")\nprint(f\"The type of {float(1)} is {type(1.0)}\")\n\nThe numpy package has its own float types:\n\none = float64(1)\nprint(f\"The type of {one} is {type(one)}\")\n\nBoth float and float64 are double precision, using 64 binary bits per value. Although it is not normally necessary to do so, we can deconstruct a float into its significand and exponent:\n\nx = 3.14\nmantissa, exponent = frexp(x)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nmantissa, exponent = frexp(x / 8)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon, given here for double precision:\n\nmach_eps = finfo(float).eps\nprint(f\"machine epsilon is {mach_eps:.4e}\")\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nprint(f\"machine epsilon is 2 to the power {log2(mach_eps)}\")\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the significand. The actual range of positive values in double precision is\n\nfinf = finfo(float)\nprint(f\"range of positive values: [{finf.tiny}, {finf.max}]\")\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2**(-4)\n\nYou can convert a floating value to an integer by wrapping it in int.\n\nint(3.14)\n\nOur theoretical description of \\float did not place limits on the exponent, but in double precision its range is limited to -1022\\le n \\le 1023. Thus, the largest number is just short of 2^{1024}\\approx 2\\times 10^{308}, which is enough in most applications. Results that should be larger are said to overflow and will actually result in the value Inf. Similarly, the smallest positive number is 2^{-1022}\\approx 2\\times 10^{-308}, and smaller values are said to underflow to zero.\n\nNote the crucial difference between \\macheps=2^{-52}, which is the distance between 1 and the next larger double-precision number, and \n\n2-1022, which is the smallest positive double-precision number. The former has to do with relative precision, while the latter is about absolute precision. Getting close to zero always requires a shift in thinking to absolute precision because any finite error is infinite relative to zero.\n\nOne more double-precision value is worthy of note: NaN, which stands for Not a Number. It is the result of an undefined arithmetic operation such as 0/0.","type":"content","url":"/floating-point#double-precision","position":5},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Floating-point arithmetic"},"type":"lvl2","url":"/floating-point#floating-point-arithmetic","position":6},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Floating-point arithmetic"},"content":"Computer arithmetic is performed on floating-point numbers and returns floating-point results. We assume the existence of machine-analog operations for real functions such as +, -, ×, /, \\sqrt{\\quad}, and so on. Without getting into the details, we will suppose that each elementary machine operation creates a floating-point result whose relative error is bounded by \\macheps. For example, if x and y are in \\float, then for machine addition \\oplus we have the bound\\frac{ |(x \\oplus y)-(x+y)| }{ |x+y| } \\le \\macheps.\n\nHence the relative error in arithmetic is essentially the same as for the floating-point representation itself. However, playing by these rules can lead to disturbing results.\n\nFloating-point arithmetic oddity\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\ne = eps()/2\n(1.0 + e) - 1.0\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1.0 + (e - 1.0)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!\n\nFloating-point arithmetic oddity\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\n( 1 + eps / 2 ) - 1\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1 - (1 - eps / 2)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!\n\nFloating-point arithmetic oddity\n\nThere is no double precision number between 1 and 1+\\varepsilon_\\text{mach}. Thus, the following difference is zero despite its appearance.\n\neps = finfo(float).eps\ne = eps/2\nprint((1.0 + e) - 1.0)\n\nHowever, 1-\\varepsilon_\\text{mach}/2 is a double precision number, so it and its negative are represented exactly:\n\nprint(1.0 + (e - 1.0))\n\nThis is now the “correct” result. But we have found a rather shocking breakdown of the associative law of addition!\n\nThere are two ways to look at \n\nDemo 1.1.4. On one hand, its two versions of the result differ by less than 1.2\\times 10^{-16}, which is very small — not just in everyday terms, but with respect to the operands, which are all close to 1 in absolute value. On the other hand, the difference is as large as the exact result itself! We formalize and generalize this observation in the next section. In the meantime, keep in mind that exactness cannot be taken for granted in floating-point computation.\n\nWe should not expect that two mathematically equivalent results will be equal when computed in floating point, only that they be relatively close together.","type":"content","url":"/floating-point#floating-point-arithmetic","position":7},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Exercises"},"type":"lvl2","url":"/floating-point#exercises","position":8},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Exercises"},"content":"Note\n\nExercises marked with ✍ are intended to be done by hand or with the aid of a simple calculator. Exercises marked with ⌨ are intended to be solved using a computer.\n\n✍ Consider a floating-point set \\float defined by \n\n(1.1.1) and \n\n(1.1.2) with d=4.\n\n(a) How many elements of \\float are there in the real interval [1/2,4], including the endpoints?\n\n(b) What is the element of \\float closest to the real number 1/10? (Hint: Find the interval [2^n,2^{n+1}) that contains 1/10, then enumerate all the candidates in \\float.)\n\n(c) What is the smallest positive integer not in \\float? (Hint: For what value of the exponent does the spacing between floating-point numbers become larger than 1?)\n\n✍ Prove that \n\n(1.1.5) is equivalent to \n\n(1.1.6). This means showing first that \n\n(1.1.5) implies \n\n(1.1.6), and then separately that \n\n(1.1.6) implies \n\n(1.1.5).\n\n⌨ There are much better rational approximations to π than 22/7 as used in \n\nDemo 1.1.2. For each one below, find its absolute and relative accuracy, and (rounding down to an integer) the number of accurate digits.\n\n(a) 355/113\n\n(b) 103638/32989\n\n✍ IEEE 754 single precision specifies that 23 binary bits are used for the value f in the significand 1+f in \n\n(1.1.2). Because they need less storage space and can be operated on more quickly than double-precision values, single-precision values can be useful in low-precision applications. (They are supported as type Float32 in Julia.)\n\n(a) In base-10 terms, what is the first single-precision number greater than 1 in this system?\n\n(b) What is the smallest positive integer that is not a single-precision number? (See the hint to Exercise 1.)\n\n⌨ Julia defines a function nextfloat that gives the next-larger floating-point value of a given number. What is the next float past floatmax()? What is the next float past -Inf?\n\nThe terms machine epsilon, machine precision, and unit roundoff aren’t used consistently across references, but the differences are not consequential for our purposes.\n\nActually, there are some still-smaller denormalized numbers that have less precision, but we won’t use that level of detail.","type":"content","url":"/floating-point#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"An accessible but more advanced discussion of machine arithmetic and roundoff error can be found in Higham \n\nHigham (2002).\n\nInteresting and more advanced discussion of the numerical difficulties of finding the roots of polynomials can be found in the article by Wilkinson, “The Perfidious Polynomial” \n\nWilkinson (1984) and in the ripostes from Cohen, “Is the Polynomial so Perfidious?” \n\nCohen (1994) and from Trefethen,  “Six myths of polynomial interpolation and quadrature,” (Myth 6) \n\nTrefethen (2013).","type":"content","url":"/next","position":1},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/overview","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"You must unlearn what you have learned.\n\nYoda, The Empire Strikes Back\n\nOur first step is to discretize the real numbers—specifically, to replace them with a finite surrogate set of numbers. This step keeps the time and storage requirements for operating with each number at constant levels, but virtually every data set and arithmetic operation is perturbed slightly away from its idealized mathematical value. We can easily keep the individual roundoff errors very small, so small that simple random accumulation is unlikely to bother us. However, some problems are extremely sensitive to these perturbations, a trait we quantify using a condition number. Problems with large condition numbers are difficult to solve accurately using finite precision. Furthermore, even when the condition number of a problem is not large, some algorithms for solving it allow errors to grow enormously. We call these algorithms unstable. In this chapter we discuss these ideas in simple settings before moving on to the more realistic problems in the rest of the book.\n\nSoftware\n\nInstructions for obtaining Julia and the codes used throughout the text can be found at\n\nhttps://​github​.com​/fncbook​/FundamentalsNumericalComputation​.jl\n\nThe installation process, which can take 5-10 minutes, only needs to be performed once.","type":"content","url":"/overview","position":1},{"hierarchy":{"lvl1":"Stability"},"type":"lvl1","url":"/stability","position":0},{"hierarchy":{"lvl1":"Stability"},"content":"If we solve a problem using a computer algorithm and see a large error in the result, we might suspect poor conditioning in the original mathematical problem. But algorithms can also be sources of errors. When error in the result of an algorithm exceeds what conditioning can explain, we call the algorithm unstable.","type":"content","url":"/stability","position":1},{"hierarchy":{"lvl1":"Stability","lvl2":"Case study"},"type":"lvl2","url":"/stability#case-study","position":2},{"hierarchy":{"lvl1":"Stability","lvl2":"Case study"},"content":"In \n\nExample 1.2.4 we showed that finding the roots of a quadratic polynomial ax^2 + b x+c is poorly conditioned if and only if the roots are close to each other relative to their size. Hence, for the polynomialp(x) = (x-10^6)(x-10^{-6}) = x^2 - (10^6+10^{-6})x + 1,\n\nfinding roots is a well-conditioned problem. An obvious algorithm for finding those roots is to directly apply the familiar quadratic formula,x_1 = \\frac{-b + \\sqrt{b^2-4ac}}{2a}, \\qquad\nx_2 = \\frac{-b - \\sqrt{b^2-4ac}}{2a}.\n\nInstability of the quadratic formula\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6+1e-6);  c = 1;\n@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n@show x₂ = (-b - sqrt(b^2 - 4a*c)) / 2a;\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6-x₂)/1e-6 \n@show accurate_digits = -log10(error);\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nInstability of the quadratic formula\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23 * 10^4.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a)\nx2 = (-b - sqrt(b^2 - 4*a*c)) / (2*a)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(x2 - 1e-6) / 1e-6 \naccurate_digits = -log10(error)\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nInstability of the quadratic formula\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\nx2 = (-b - sqrt(b**2 - 4*a*c)) / 2*a\nprint(x1, x2)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6 - x2) / 1e-6 \nprint(f\"There are {-log10(error):.2f} accurate digits.\")\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nDemo 1.4.1 suggests that the venerable quadratic formula is an unstable means of computing roots in finite precision. The roots themselves were not sensitive to the data or arithmetic—it’s the specific computational path we chose that caused the huge growth in errors.\n\nWe can confirm this conclusion by finding a different path that avoids subtractive cancellation. A little algebra using \n\n(1.4.2) confirms the additional formula x_1x_2=c/a.  So given one root r, we compute the other root using c/ar, which has only multiplication and division and therefore creates no numerical trouble.\n\nStable alternative to the quadratic formula\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6+1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\n@show x₁ = (-b + sqrt(b^2-4a*c)) / 2a;\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\n@show x₂ = c / (a*x₁);\n\nAs you see in this output, Julia often suppresses trailing zeros in a decimal expansion. To be sure we have an accurate result, we compute its relative error.\n\nabs(x₂-1e-6) / 1e-6\n\nStable alternative to the quadratic formula\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a);\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a*x1)\n\nThis matches the exact root to the displayed digits; to be sure we have an accurate result, we compute its relative error.\n\nabs(x2 - 1e-6) / 1e-6\n\nStable alternative to the quadratic formula\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a * x1)\nprint(x1, x2)\n\nTo be sure we have an accurate result, we compute its relative error.\n\nprint(abs(x2 - 1e-6) / 1e-6)\n\nThe algorithms in \n\nDemo 1.4.1 and \n\nDemo 1.4.2 are equivalent when using real numbers and exact arithmetic. When results are perturbed by machine representation at each step, though, the effects may depend dramatically on the specific sequence of operations, thanks to the chain rule \n\n(1.2.9).\n\nThe sensitivity of a problem f(x) is governed only by \\kappa_f, but the sensitivity of an algorithm depends on the condition numbers of all of its individual steps.\n\nThis situation may seem hopelessly complicated. But the elementary operations we take for granted, such as those in \n\nTable 1.2.1, are well-conditioned in most circumstances. Exceptions usually occur when |f(x)| is much smaller than |x|, although not every such case signifies trouble. The most common culprit is simple subtractive cancellation.\n\nA practical characterization of instability is that results are much less accurate than the conditioning of the problem can explain. Typically one should apply an algorithm to test problems whose answers are well-known, or for which other programs are known to work well, in order to spot possible instabilities. In the rest of this book we will see some specific ways in which instability is manifested for different types of problems.","type":"content","url":"/stability#case-study","position":3},{"hierarchy":{"lvl1":"Stability","lvl2":"Backward error"},"type":"lvl2","url":"/stability#backward-error","position":4},{"hierarchy":{"lvl1":"Stability","lvl2":"Backward error"},"content":"In the presence of poor conditioning for a problem f(x), even just the act of rounding the data to floating point may introduce a large change in the result. It’s not realistic, then, to expect any algorithm \\tilde{f} to have a small error in the sense \\tilde{f}(x)\\approx f(x). There is another way to characterize the error, though, that can be a useful alternative measurement. Instead of asking, “Did you get nearly the right answer?”, we ask, “Did you answer nearly the right question?”\n\nBackward error\n\nLet \\tilde{f} be an algorithm for the problem f. Let y=f(x) be an exact result and \\tilde{y}=\\tilde{f}(x) be its approximation by the algorithm. If there is a value \\tilde{x} such that f(\\tilde{x}) = \\tilde{y}, then the relative backward error in \\tilde{y} is\\frac{ |\\tilde{x}-x| } { |x| }.\n\nThe absolute backward error is |\\tilde{x}-x|.\n\nBackward error measures the change to the original data that reproduces the result that was found by the algorithm. The situation is illustrated in \n\nFigure 1.4.1.\n\n\n\nFigure 1.4.1:Backward error is the difference between the original data and the data that exactly produces the computed value.\n\nBackward error\n\nFor this example we will use the Polynomials package, which is installed by the FNC package.\n\nIn the rest of the book, we do not show the using statement needed to load the book’s package, but you will need to enter it if you want to run the codes yourself.\n\nusing FundamentalsNumericalComputation\n\nOur first step is to construct a polynomial with six known roots.\n\nr = [-2.0,-1,1,1,3,6]\np = fromroots(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr̃ = sort(roots(p))   # type r\\tilde and then press Tab\n\nHere are the relative errors in each of the computed roots.\n\nThe @. notation at the start means to do the given operations on each element of the given vectors.\n\nprintln(\"Root errors:\") \n@. abs(r-r̃) / r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply fromroots to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np̃ = fromroots(r̃)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nc,c̃ = coeffs(p),coeffs(p̃)\nprintln(\"Coefficient errors:\") \n@. abs(c-c̃) / c\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.\n\nBackward error\n\nOur first step is to construct a polynomial with six known roots.\n\nThe ' operator is used for transposition. Here, we want to make r a column vector.\n\nr = [-2 ,-1, 1, 1, 3, 6]';\np = poly(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nrr = sort(roots(p))\n\nHere are the relative errors in each of the computed roots.\n\nThe ./ operator is used for element-wise division.\n\ndisp(\"Root errors:\") \nabs(r - rr) ./ r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\npp = poly(rr)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\ndisp(\"Coefficient errors:\") \nabs(p - pp) ./ abs(p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.\n\nBackward error\n\nOur first step is to construct a polynomial with six known roots.\n\nr = [-2, -1, 1, 1, 3, 6]\np = poly(r)\nprint(p)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr_computed = sort(roots(p))\nprint(r_computed)\n\nHere are the relative errors in each of the computed roots.\n\nprint(abs(r - r_computed) / r)\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np_computed = poly(r_computed)\nprint(p_computed)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nprint(abs(p - p_computed) / p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.\n\nSmall backward error is the best we can hope for in a poorly conditioned problem. Without getting into the formal details, know that if an algorithm always produces small backward errors, then it is stable. But the converse is not always true: some stable algorithms may produce a large backward error.\n\nOne stable algorithm that is not backward stable is floating-point evaluation for our old friend, f(x)=x+1. If |x|<\\epsilon_\\text{mach}/2, then the computed result is \\tilde{f}(x)=1, since there are no floating-point numbers between 1 and 1+\\epsilon_\\text{mach}. Hence the only possible choice for a real number \\tilde{x} satisfying \n\n(1.4.3) is \\tilde{x}=0. But then |\\tilde{x}-x|/|x|=1, which indicates 100% backward error!","type":"content","url":"/stability#backward-error","position":5},{"hierarchy":{"lvl1":"Stability","lvl2":"Exercises"},"type":"lvl2","url":"/stability#exercises","position":6},{"hierarchy":{"lvl1":"Stability","lvl2":"Exercises"},"content":"The formulasf(x)=\\frac{1-\\cos(x)}{\\sin(x)}, \\quad g(x) = \\frac{2\\sin^2(x/2)}{\\sin(x)},\n\nare mathematically equivalent, but they suggest evaluation algorithms that can behave quite differently in floating point.\n\n(a) ✍ Using \n\n(1.2.6), find the relative condition number of f. (Because f and g are equivalent, the condition number of g is the same.) Show that it approaches 1 as x\\to 0. (Hence it should be possible to compute the function accurately near zero.)\n\n(b) ⌨ Compute f(10^{-6}) using a sequence of four elementary operations. Using \n\nTable 1.2.1, make a table like the one in \n\nDemo 1.4.1 that shows the result of each elementary result and the numerical value of the condition number of that step.\n\n(c) ⌨ Repeat part (b) for g(10^{-6}), which has six elementary steps.\n\n(d) ✍ Based on parts (b) and (c), is the numerical value of f(10^{-6}) more accurate, or is g(10^{-6}) more accurate?\n\nLet f(x) = \\frac{e^x-1}{x}.\n\n(a) ✍ Find the condition number \\kappa_f(x). What is the maximum of \\kappa_f(x) over -1\\le x \\le 1?\n\n(b) ⌨  Use the “obvious” algorithm(exp(x) - 1) / x\n\nto compute f(x) at x=10^{-2},10^{-3},10^{-4},\\ldots,10^{-11}.\n\n(c) ⌨ Create a second algorithm from the first 8 terms of the Maclaurin series, i.e.,p(x) = 1 + \\frac{1}{2!}x + \\frac{1}{3!}x^2 + \\cdots + \\frac{1}{8!}x^8.\n\nEvaluate it at the same values of x as in part (b).\n\n(d) ⌨  Make a table of the relative difference between the two algorithms as a function of x. Which algorithm is more accurate, and why?\n\n⌨ The functionx = \\cosh(y) = \\frac{e^y + e^{-y}}{2}\n\ncan be inverted to yield a formula for \\operatorname{acosh}(x):\\operatorname{acosh}(x) = y = \\log\\bigl(x-\\sqrt{x^2-1}\\bigr).\n\nFor the steps below, define y_i=-4i and x_i=\\cosh(y_i) for i=1,\\dots,4. Hence y_i=\\operatorname{acosh}(x_i).\n\n(a) Find the relative condition number of evaluating f(x) = \\operatorname{acosh}(x). (You can use \n\n(1.4.7) or look up a formula for f' in a calculus book.)  Evaluate \\kappa_f at all the x_i. (You will find that the problem is well-conditioned at these inputs.)\n\n(b) Use \n\n(1.4.7) to approximate f(x_i) for all i. Compute the relative accuracy of the results. Why are some of the results so inaccurate?\n\n(c) An alternative formula isy = -2\\log\\left(\\sqrt{\\frac{x+1}{2}} + \\sqrt{\\frac{x-1}{2}}\\right).\n\nApply \n\n(1.4.8) to approximate f(x_i) for all i, again computing the relative accuracy of the results.\n\n⌨ (Continuation of \n\nExercise 1.3.2. Adapted from \n\nHigham (2002).) One drawback of the formula \n\n(1.3.3) for sample variance is that you must compute a sum for \\overline{x} before beginning another sum to find s^2. Some statistics textbooks quote a single-loop formula\\begin{split}\ns^2 &= \\frac{1}{n-1} \\left( u - \\tfrac{1}{n}v^2 \\right),\\\\\nu & = \\sum_{i=1}^n x_i^2, \\\\\nv &= \\sum_{i=1}^n x_i.\n\\end{split}\n\nTry this formula for these three datasets, each of which has a variance exactly equal to 1:x = [ 1e6, 1+1e6, 2+1e6 ]\nx = [ 1e7, 1+1e7, 2+1e7 ]\nx = [ 1e8, 1+1e8, 2+1e8 ]\n\nExplain the results.","type":"content","url":"/stability#exercises","position":7},{"hierarchy":{"lvl1":"Conditioning of linear systems"},"type":"lvl1","url":"/condition-number","position":0},{"hierarchy":{"lvl1":"Conditioning of linear systems"},"content":"We are ready to consider the conditioning of solving the square linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}. In this problem, the data are \\mathbf{A} and \\mathbf{b}, and the solution is \\mathbf{x}. Both data and result are multidimensional, so we will use norms to measure their magnitudes.\n\nThe motivation for the definition of relative condition number in Chapter 1 was to quantify the response of the result to perturbations of the data. For simplicity, we start by allowing perturbations to \\mathbf{b} only while \\mathbf{A} remains fixed.\n\nLet \\mathbf{A}\\mathbf{x}=\\mathbf{b} be perturbed to  \\mathbf{A}(\\mathbf{x}+\\mathbf{h}) = \\mathbf{b}+\\mathbf{d}.\n\nThe condition number should be the relative change in the solution divided by relative change in the data,  \\frac{\\quad\\dfrac{\\| \\mathbf{h} \\| }{\\| \\mathbf{x} \\| }\\quad}{\\dfrac{\\| \\mathbf{d} \\| }{\\| \\mathbf{b} \\|}} \n  = \\frac{\\| \\mathbf{h} \\|\\;\\| \\mathbf{b} \\| }{\\| \\mathbf{d} \\|\\; \\| \\mathbf{x} \\| }.\n\nWe can bound \\| \\mathbf{h} \\| in terms of \\| \\mathbf{d} \\|:\\begin{split}\n  \\mathbf{A}\\mathbf{x} +  \\mathbf{A} \\mathbf{h} &= \\mathbf{b} + \\mathbf{d}, \\\\\n  \\mathbf{A} \\mathbf{h} &= \\mathbf{d},\\\\\n  \\mathbf{h} &= \\mathbf{A}^{-1} \\mathbf{d},\\\\\n  \\| \\mathbf{h} \\| &\\le \\| \\mathbf{A}^{-1}\\| \\,\\| \\mathbf{d} \\|,\n\\end{split}\n\nwhere we have applied \\mathbf{A}\\mathbf{x}=\\mathbf{b} and \n\n(2.7.8).\nSince also \\mathbf{b}=\\mathbf{A}\\mathbf{x} implies \\| \\mathbf{b} \\|\\le\n\\| \\mathbf{A} \\|\\, \\| \\mathbf{x} \\|, we derive   \\frac{\\| \\mathbf{h} \\|\\; \\| \\mathbf{b} \\|}{\\| \\mathbf{d} \\|\\; \\| \\mathbf{x} \\|} \n   \\le \\frac{\\bigl(\\| \\mathbf{A}^{-1} \\|\\, \\| \\mathbf{d} \\|\\bigr)\n    \\bigl(\\| \\mathbf{A} \\|\\,\\| \\mathbf{x} \\|\\bigr)}{\\| \\mathbf{d} \\|\\,\\| \\mathbf{x} \\|} \n    = \\| \\mathbf{A}^{-1}\\| \\, \\| \\mathbf{A} \\|.\n\nIt is possible to show that this bound is tight, in the sense that the inequalities are in fact equalities for some choices of \\mathbf{b} and \\mathbf{d}. This result motivates a new definition.\n\nMatrix condition number\n\nThe matrix condition number of an invertible square matrix \\mathbf{A} is\\kappa(\\mathbf{A}) = \\| \\mathbf{A}^{-1}\\| \\, \\| \\mathbf{A} \\|.\n\nThis value depends on the choice of norm; a subscript on κ such as 1, 2, or ∞ is used if clarification is needed. If \\mathbf{A} is singular, we define \\kappa(\\mathbf{A}) = \\infty.","type":"content","url":"/condition-number","position":1},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Main result"},"type":"lvl2","url":"/condition-number#main-result","position":2},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Main result"},"content":"The matrix condition number \n\n(2.8.5) is equal to the condition number of solving a linear system of equations. Although we derived this fact above only for perturbations of \\mathbf{b}, a similar statement holds when \\mathbf{A} is perturbed.\n\nUsing a traditional Δ notation for the perturbation in a quantity, we can write the following.\n\nConditioning of linear systems\n\nIf \\mathbf{A}(\\mathbf{x} + \\Delta \\mathbf{x}) = \\mathbf{b} + \\Delta \\mathbf{b}, then\\frac{\\| \\Delta \\mathbf{x} \\|}{\\| \\mathbf{x} \\|} \\le \\kappa(\\mathbf{A}) \\frac{\\| \\Delta \\mathbf{b} \\|}{\\| \\mathbf{b} \\|}.\n\nIf (\\mathbf{A}+\\Delta \\mathbf{A}) (\\mathbf{x} + \\Delta \\mathbf{x}) = \\mathbf{b}, then\\frac{\\| \\Delta \\mathbf{x} \\|}{\\| \\mathbf{x} \\|} \\le \\kappa(\\mathbf{A}) \\frac{\\| \\Delta \\mathbf{A} \\|}{\\| \\mathbf{A} \\|},\n\nin the limit \\| \\Delta \\mathbf{A} \\| \\to 0.\n\nNote that for any induced matrix norm,  1 = \\| \\mathbf{I} \\| = \\| \\mathbf{A} \\mathbf{A}^{-1} \\| \\le \\| \\mathbf{A} \\|\\, \\| \\mathbf{A}^{-1} \\| = \\kappa(\\mathbf{A}).\n\nA condition number of 1 is the best we can hope for—in that case, the relative perturbation of the solution has the same size as that of the data.  A condition number of size 10^t indicates that in floating-point arithmetic, roughly t digits are lost (i.e., become incorrect) in computing the solution \\mathbf{x}. And if \\kappa(\\mathbf{A}) > \\epsilon_\\text{mach}^{-1}, then for computational purposes the matrix is effectively singular.\n\nMatrix condition number\n\nJulia has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nType \\kappa followed by Tab to get the Greek letter κ.\n\nA = [ 1 / (i + j) for i in 1:6, j in 1:6 ]\nκ = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = 1:6\nb = A * x\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\n# type \\Delta then Tab to get Δ\nΔA = randn(size(A));  ΔA = 1e-10 * (ΔA / opnorm(ΔA));\nΔb = randn(size(b));  Δb = 1e-10 * normalize(Δb);\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + ΔA) \\ (b + Δb))\nΔx = new_x - x\n\nHere is the relative error in the solution.\n\n@show relative_error = norm(Δx) / norm(x);\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprintln(\"Upper bound due to b: $(κ * norm(Δb) / norm(b))\")\nprintln(\"Upper bound due to A: $(κ * opnorm(ΔA) / opnorm(A))\")\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n@show rounding_bound = κ * eps();\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = [ 1 / (i + j) for i=1:14, j=1:14 ];\nκ = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = κ*eps()\n\nLet’s put that prediction to the test.\n\nx = 1:14\nb = A * x  \nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.\n\nMatrix condition number\n\nMATLAB has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6 case.\n\nA = hilb(6)\nkappa = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = (1:6)';\nb = A * x;\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\ndA = randn(size(A));  dA = 1e-10 * (dA / norm(dA));\ndb = randn(size(b));  db = 1e-10 * (db / norm(db));\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + dA) \\ (b + db));\ndx = new_x - x;\n\nHere is the relative error in the solution.\n\nrelative_error = norm(dx) / norm(x)\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nupper_bound_b = (kappa * norm(db) / norm(b))\nupper_bound_A = (kappa * norm(dA) / norm(A))\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\nrounding_bound = kappa * eps\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = hilb(14);\nkappa = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = kappa * eps\n\nLet’s put that prediction to the test.\n\nx = (1:14)';  b = A * x;\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.\n\nMatrix condition number\n\nThe function cond from numpy.linalg is used to computes matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nA = array([ \n    [1/(i + j + 2) for j in range(6)] \n    for i in range(6) \n    ])\nprint(A)\n\nfrom numpy.linalg import cond\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nNext we engineer a linear system problem to which we know the exact answer.\n\nx_exact = 1.0 + arange(6)\nb = A @ x_exact\n\nNow we perturb the data randomly with a vector of norm \n\n10-12.\n\ndA = random.randn(6, 6)\ndA = 1e-12 * (dA / norm(dA, 2))\ndb = random.randn(6)\ndb = 1e-12 * (db / norm(db, 2))\n\nWe solve the perturbed problem using built-in pivoted LU and see how the solution was changed.\n\nx = solve(A + dA, b + db) \ndx = x - x_exact\n\nHere is the relative error in the solution.\n\nprint(f\"relative error is {norm(dx) / norm(x_exact):.2e}\")\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprint(f\"b_bound: {kappa * 1e-12 / norm(b):.2e}\")\nprint(f\"A_bound: {kappa * 1e-12 / norm(A, 2):.2e}\")\n\nEven if we don’t make any manual perturbations to the data, machine epsilon does when we solve the linear system numerically.\n\nx = solve(A, b)\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nBecause \\kappa\\approx 10^8, it’s possible to lose 8 digits of accuracy in the process of passing from A and b to x. That’s independent of the algorithm; it’s inevitable once the data are expressed in double precision.\n\nLarger Hilbert matrices are even more poorly conditioned.\n\nA = array([ [1/(i+j+2) for j in range(14)] for i in range(14) ])\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nBefore we compute the solution, note that κ exceeds 1/eps. In principle we therefore might end up with an answer that is completely wrong (i.e., a relative error greater than 100%).\n\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nx_exact = 1.0 + arange(14)\nb = A @ x_exact  \nx = solve(A, b)\n\nWe got an answer. But in fact, the error does exceed 100%:\n\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")","type":"content","url":"/condition-number#main-result","position":3},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Residual and backward error"},"type":"lvl2","url":"/condition-number#residual-and-backward-error","position":4},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Residual and backward error"},"content":"Suppose that \\mathbf{A}\\mathbf{x}=\\mathbf{b} and \\tilde{\\mathbf{x}} is a computed estimate of the solution \\mathbf{x}. The most natural quantity to study is the error, \\mathbf{x}-\\tilde{\\mathbf{x}}. Normally we can’t compute it because we don’t know the exact solution. However, we can compute something related.\n\nResidual of a linear system\n\nFor the problem \\mathbf{A}\\mathbf{x}=\\mathbf{b}, the residual at a solution estimate \\tilde{\\mathbf{x}} is  \\mathbf{r} = \\mathbf{b} - \\mathbf{A}\\tilde{\\mathbf{x}}.\n\nObviously, a zero residual means that \\tilde{\\mathbf{x}}=\\mathbf{x}, and we have the exact solution. What happens more generally? Note that \\mathbf{A}\\tilde{\\mathbf{x}}=\\mathbf{b}-\\mathbf{r}. That is, \\tilde{\\mathbf{x}} solves the linear system problem for a right-hand side that is changed by -\\mathbf{r}. This is precisely what is meant by backward error.\n\nHence residual and backward error are the same thing for a linear system. What is the connection to the (forward) error? We can reconnect with \n\n(2.8.6) by the definition \\mathbf{h} = \\tilde{\\mathbf{x}}-\\mathbf{x}, in which case\\mathbf{d} = \\mathbf{A}(\\mathbf{x}+\\mathbf{h})-\\mathbf{b}=\\mathbf{A}\\mathbf{h} = -\\mathbf{r}.\n\nThus \n\n(2.8.6) is equivalent to  \\frac{\\| \\mathbf{x}-\\tilde{\\mathbf{x}} \\|}{\\| \\mathbf{x} \\|} \\le\n  \\kappa(\\mathbf{A}) \\frac{\\| \\mathbf{r} \\|}{\\| \\mathbf{b} \\|}.\n\nEquation \n\n(2.8.11) says that the gap between relative error and the relative residual is a multiplication by the matrix condition number.\n\nWhen solving a linear system, all that can be expected is that the backward error, not the error, is small.","type":"content","url":"/condition-number#residual-and-backward-error","position":5},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Exercises"},"type":"lvl2","url":"/condition-number#exercises","position":6},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Exercises"},"content":"⌨ Refer to \n\nDemo 2.8.1 for the definition of a Hilbert matrix. Make a table of the values of \\kappa(\\mathbf{H}_n) in the 2-norm for n=2,3,\\ldots,16. Speculate as to why the growth of κ appears to slow down at n=13.\n\n⌨ The purpose of this problem is to verify, like in \n\nDemo 2.8.1, the error bound\\frac{\\| \\mathbf{x}-\\tilde{\\mathbf{x} \\|}}{\\| \\mathbf{x} \\|} \\le \\kappa(\\mathbf{A})\n\\frac{\\| \\mathbf{h} \\|}{\\| \\mathbf{b} \\|}.\n\nHere \\tilde{\\mathbf{x}} is a numerical approximation to the exact solution \\mathbf{x}, and \\mathbf{h} is an unknown perturbation caused by machine roundoff. We will assume that \\| \\mathbf{d} \\|/\\| \\mathbf{b} \\| is roughly eps().\n\nFor each n=10,20,\\ldots,70 let A = matrixdepot(\"prolate\",n,0.4) and let \\mathbf{x} have components x_k=k/n for k=1,\\ldots,n. Define b=A*x and let \\tilde{\\mathbf{x}} be the solution produced numerically by backslash.\n\nMake a table including columns for n, the condition number of \\mathbf{A}, the observed relative error in \\tilde{\\mathbf{x}}, and the right-hand side of the inequality above. You should find that the inequality holds in every case.\n\n⌨ \n\nExercise 2.3.7 suggests that the solutions of linear systems\\mathbf{A} = \\begin{bmatrix} 1 & -1 & 0 & \\alpha-\\beta & \\beta \\\\ 0 & 1 & -1 &\n  0 & 0 \\\\ 0 & 0 & 1 & -1 & 0 \\\\ 0 & 0 & 0 & 1 & -1  \\\\ 0 & 0 & 0 & 0 & 1\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix} \\alpha \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\n\nbecome less accurate as β increases. Using \\alpha=0.1 and \\beta=10,100,\\ldots,10^{12}, make a table with columns for β, |x_1-1|, and the condition number of the matrix.\n\n⌨ Let \\mathbf{A}_n denote the (n+1)\\times(n+1) version of the Vandermonde matrix in Equation \n\n(2.1.3) based on the equally spaced interpolation nodes t_i=i/n for i=0,\\ldots,n. Using the 1-norm, graph \\kappa(\\mathbf{A}_n) as a function of n for n=4,5,6,\\ldots,20, using a log scale on the y-axis. (The graph is nearly a straight line.)\n\n⌨ The matrix \\mathbf{A} in \n\n(2.6.2) has unpivoted LU factors given in \n\n(2.6.3) as a function of parameter ε. For \\epsilon = 10^{-2},10^{-4},\\ldots,10^{-10}, make a table with columns for ε, \\kappa(\\mathbf{A}), \\kappa(\\mathbf{L}), and \\kappa(\\mathbf{U}). (This shows that solution via unpivoted LU factorization is arbitrarily unstable.)\n\n✍  Define \\mathbf{A}_n as the n\\times n matrix \\displaystyle\\begin{bmatrix}\n   1 & -2 & & &\\\\\n   & 1 & -2 & & \\\\\n   & & \\ddots & \\ddots & \\\\\n   & & & 1 & -2 \\\\\n   & & & & 1\n \\end{bmatrix}.\n\n(a) Write out \\mathbf{A}_2^{-1} and \\mathbf{A}_3^{-1}.\n\n(b) Write out \\mathbf{A}_n^{-1} in the general case n>1. (If necessary, look at a few more cases in Julia until you are certain of the pattern.) Make a clear argument why it is correct.\n\n(c) Using the ∞-norm, find \\kappa(\\mathbf{A}_n).\n\n✍ (a) Prove that for n\\times n nonsingular matrices \\mathbf{A} and \\mathbf{B}, \\kappa(\\mathbf{A}\\mathbf{B})\\le \\kappa(\\mathbf{A})\\kappa(\\mathbf{B}).\n\n(b) Show by means of an example that the result of part (a) cannot be an equality in general.\n\n✍  Let \\mathbf{D} be a diagonal n\\times n matrix, not necessarily invertible. Prove that in the 1-norm,\\kappa(\\mathbf{D}) = \\frac{\\max_i |D_{ii}|}{\\min_i |D_{ii}|}.\n\n(Hint: See \n\nExercise 2.7.10.)","type":"content","url":"/condition-number#exercises","position":7},{"hierarchy":{"lvl1":"Efficiency of matrix computations"},"type":"lvl1","url":"/efficiency","position":0},{"hierarchy":{"lvl1":"Efficiency of matrix computations"},"content":"Predicting how long an algorithm will take to solve a particular problem, on a particular computer, as written in a particular way in a particular programming language, is an enormously difficult undertaking. It’s more practical to predict how the required time will scale as a function of the size of the problem. In the case of a linear system of equations, the problem size is n, the number of equations and variables in the system.  Because expressions of computational time are necessarily approximate, it’s customary to suppress all but the term that is dominant as n\\to\\infty. We first need to build some terminology for these expressions.","type":"content","url":"/efficiency","position":1},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Asymptotic analysis"},"type":"lvl2","url":"/efficiency#asymptotic-analysis","position":2},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Asymptotic analysis"},"content":"Asymptotic notation\n\nLet f(n) and g(n) be positive-valued functions. We say f(n)=O(g(n)) (read “f is big-O of g”) as n\\rightarrow \\infty if f(n)/g(n) is bounded above as n\\to\\infty.\n\nWe say f(n)\\sim g(n) (read “f is asymptotic to g”) as n\\rightarrow \\infty if f(n)/g(n)\\rightarrow 1 as n\\rightarrow\\infty.\n\nOne immediate consequence is that f\\sim g implies f=O(g).\n\nConsider the functions f(n) = a_1 n^3 + b_1 n^2 + c_1 n and g(n) = a_2 n^3 in the limit n\\to \\infty.  Then    \\lim_{n \\to \\infty} \\frac{f(n)}{g(n)}\n    = \\lim_{n \\to \\infty} \\frac{a_1 + b_1n^{-1} + c_1n^{-2}}{a_2} =\n    \\frac{a_1}{a_2} .\n\nSince a_1/a_2 is a constant, f(n) = O(g(n)); if a_1=a_2, then f \\sim g.\n\nConsider f(n) = \\sin (1/n), g(n)=1/n and h(n) = 1/n^2. For large n, Taylor’s theorem with remainder implies thatf(n) = \\frac{1}{n} - \\cos(1/\\xi)\\frac{1}{6 n^3},\n\nwhere n<\\xi<\\infty.  But\\lim_{n\\to \\infty} \\frac{f}{g} = \\lim_{n\\to \\infty} 1-\\cos(1/\\xi)\\frac{1}{6 n^2} = 1,\n\nand so f \\sim g.  On the other hand, comparing f and h, we find\\lim_{n\\to \\infty} \\frac{f}{h} = \\lim_{n\\to \\infty}  n-\\cos(1/\\xi)\\frac{1}{6 n} = \\infty,\n\nso we cannot say that f = O(h). A consideration of h/f will show that h = O(f), however.\n\nIt’s conventional to use asymptotic notation that is as specific as possible. For instance, while it is true that n^2+n=O(n^{10}), it’s more informative, and usually expected, to say n^2+n=O(n^2). There are additional notations that enforce this requirement strictly, but we will just stick to the informal understanding.\n\nThere is a memorable way to use asymptotic notation to simplify sums:\\begin{split}\n  \\sum_{k=1}^n k&\\sim \\frac{n^2}{2} = O(n^2), \\text{ as $n\\to\\infty$}, \\\\\n  \\sum_{k=1}^n k^2 &\\sim \\frac{n^3}{3} = O(n^3), \\text{ as $n\\to\\infty$}, \\\\\n  &\\vdots \\\\\n  \\sum_{k=1}^n k^p &\\sim \\frac{n^{p+1}}{p+1} = O(n^{p+1}), \\text{ as $n\\to\\infty$}.\n\\end{split}\n\nThese formulas greatly resemble the definite integral of x^p.\n\n\\begin{align*}\n\\sum_{k=1}^{n-1} 4k^2 + 3 & = 4 \\left( \\sum_{k=1}^{n-1} k^2\\right)  + 3 \\sum_{k=1}^{n-1} 1\\\\ \n&\\sim 4 \\left( \\frac{1}{3} (n-1)^3 \\right) + 3(n-1) \\\\ \n& = \\frac{4}{3} (n^3 - 3n^2 + 3n - 1)  + 3n - 3 \\\\ \n&\\sim \\frac{4}{3} n^3.\n\\end{align*}","type":"content","url":"/efficiency#asymptotic-analysis","position":3},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Flop counting"},"type":"lvl2","url":"/efficiency#flop-counting","position":4},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Flop counting"},"content":"Traditionally, in numerical linear algebra we count floating-point operations, or flops for short. In our interpretation each scalar addition, subtraction, multiplication, division, and square root counts as one flop. Given any algorithm, we simply add up the number of scalar flops and ignore everything else.\n\nFloating-point operations in matrix-vector multiplication\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = randn(n, n)\nx = rand(n)\ny = zeros(n)\nfor i in 1:n\n    for j in 1:n\n        y[i] += A[i, j] * x[j]    # 1 multiply, 1 add\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. Note that Julia is unusual in that loops have a variable scope separate from its enclosing code. Thus, for n in n below means that inside the loop, the name n will take on each one of the values that were previously assigned to the vector n.\n\nThe push! function attaches a new value to the end of a vector.\n\nn = 1000:1000:5000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:80; A * x; end\n    push!(t, time)\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\npretty_table([n t], header=([\"size\", \"time\"], [\"\", \"(sec)\"]))\n\nLooking at the timings just for n=2000 and n=4000, they have ratio\n\nThe expression n.==4000 here produces a vector of Boolean (true/false) values the same size as n. This result is used to index within t, accessing only the value for which the comparison is true.\n\n@show t[n.==4000] ./ t[n.==2000];\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nFloating-point operations in matrix-vector multiplication\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6;\nA = magic(n);\nx = ones(n,1);\ny = zeros(n,1);\nfor i = 1:n\n    for j = 1:n\n        y(i) = y(i) + A(i,j)*x(j);   % 2 flops\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication, using tic and toc to time the operation.\n\nn_ = (400:400:4000)';\nt_ = zeros(size(n_));\nfor i = 1:length(n_)\n    n = n_(i);\n    A = randn(n, n);  x = randn(n, 1);\n    tic    % start a timer\n    for j = 1:100      % repeat 100 times\n        A*x;\n    end\n    t = toc;           % read the timer\n    t_(i) = t / 100;   % seconds per instance\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\ntable(n_, t_, 'variablenames', {'size', 'time'})\n\nLooking at the timings just for n=2000 and n=4000, they have ratio\n\nThe expression n_==4000 here produces a vector of Boolean (true/false) values the same size as n_. This result is used to index within t_, accessing only the value for which the comparison is true.\n\nt_(n_==4000) / t_(n_==2000)\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nFloating-point operations in matrix-vector multiplication\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = random.rand(n, n)\nx = ones(n)\ny = zeros(n)\nfor i in range(n):\n    for j in range(n):\n        y[i] += A[i, j] * x[j]   # 2 flops\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. We assume that flops dominate the computation time and thus measure elapsed time.\n\nN = 400 * arange(1, 11)\nt = []\nprint(\"  n           t\")\nfor i, n in enumerate(N):\n    A = random.randn(n, n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(50): A @ x\n    t.append(timer() - start)\n    print(f\"{n:5}   {t[-1]:10.3e}\")\n\nThe reason for doing multiple repetitions at each value of n above is to avoid having times so short that the resolution of the timer is a factor.\n\nLooking at the timings just for n=2000 and n=4000, they have ratio:\n\nprint(t[9] / t[4])\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nSuppose that the running time t of an algorithm obeys a function that is O(n^p). For sufficiently large n, t\\approx Cn^p for a constant C should be a good approximation. Hence  t \\approx Cn^p \\qquad \\Longleftrightarrow \\qquad \\log t \\approx p(\\log n) + \\log C.\n\nSo we expect that a graph of \\log t as a function of \\log n will be a straight line of slope p.\n\nAsymptotics in log-log plots\n\nLet’s repeat the experiment of the previous figure for more, and larger, values of n.\n\nrandn(5,5)*randn(5);  # throwaway to force compilation\n\nn = 400:200:6000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:50; A * x; end\n    push!(t, time)\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nscatter(n, t, label=\"data\", legend=false,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time (sec)\"),\n    title=\"Timing of matrix-vector multiplications\")\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nplot!(n, t[end] * (n/n[end]).^2, l=:dash,\n    label=L\"O(n^2)\", legend=:topleft)\n\nAsymptotics in log-log plots\n\nLet’s repeat the previous experiment for more, and larger, values of n.\n\nn_ = (400:400:6000)';\nt_ = zeros(size(n_));\nfor i = 1:length(n_)\n    n = n_(i);\n    A = randn(n, n);  x = randn(n, 1);\n    tic    % start a timer\n    for j = 1:100      % repeat ten times\n        A*x;\n    end\n    t = toc;          % read the timer\n    t_(i) = t / 100;   % seconds per instance\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nclf    % clear any existing figure\nloglog(n_, t_, '.-')\nxlabel('size of matrix')\nylabel('time (sec)')\ntitle('Timing of matrix-vector multiplications')\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nhold on\nloglog(n_, t_(1) * (n_ / n_(1)).^2, '--')\naxis tight\nlegend('data', 'O(n^2)', 'location', 'southeast')\n\nAsymptotics in log-log plots\n\nLet’s repeat the experiment of the previous example for more, and larger, values of n.\n\nN = arange(400, 6200, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(20): A@x\n    t[i] = timer() - start\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables, but is formatted more neatly.\n\nfig, ax = subplots()\nax.loglog(N, t, \"-o\", label=\"observed\")\nylabel(\"elapsed time (sec)\");\nxlabel(\"$n$\");\ntitle(\"Timing of matrix-vector multiplications\");\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nax.loglog(N, t[-1] * (N/N[-1])**2, \"--\", label=\"$O(n^2)$\")\nax.legend();  fig","type":"content","url":"/efficiency#flop-counting","position":5},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Solution of linear systems"},"type":"lvl2","url":"/efficiency#solution-of-linear-systems","position":6},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Solution of linear systems"},"content":"Recall the steps of \n\nAlgorithm 2.4.2 for the system \\mathbf{A}\\mathbf{x}=\\mathbf{b}:\n\nFactor \\mathbf{L}\\mathbf{U}=\\mathbf{A} using Gaussian elimination.\n\nSolve \\mathbf{L}\\mathbf{z}=\\mathbf{b} for \\mathbf{z} using forward substitution.\n\nSolve \\mathbf{U}\\mathbf{x}=\\mathbf{z} for \\mathbf{x} using backward substitution.\n\nThe second and third steps are solved by \n\nFunction 2.3.1 and \n\nFunction 2.3.2. Only one line in each of these functions dominates the arithmetic. Take forwardsub, for instance. It has a single flop in line 11.  Line 13 computessum( L[i,j]*x[j] for j in 1:i-1 )\n\nThis line requires i-1 multiplications and (i-2) additions, for a total of 2i-3 flops. Line 14 adds two more flops. These lines are performed within a loop as i ranges from 1 to n, so the total count is  1 + \\sum_{i=1}^n (2i-3) = 1 - 3n + 2 \\sum_{i=1}^n i.\n\nIt is not hard to find an exact formula for the sum, but we use \n\n(2.5.5) to simplify it to \\sim n^2. After all, since flop counting is only an approximation of true running time, why bother with the more complicated exact expression? An analysis of backward substitution yields the same result.\n\nSolving a triangular n\\times n system by forward or backward substitution takes \\sim n^2 flops asymptotically.\n\nBefore counting flops for the LU factorization, we have to admit that \n\nFunction 2.4.1 is not written as economically as it could be. Recall from our motivating example in \n\nDemo 2.4.3 that we zero out the first row and column of \\mathbf{A} with the first outer product, the second row and column with the second outer product, and so on. There is no good reason to do multiplications and additions with values known to be zero, so we could replace lines 15–19 of lufact withfor k in 1:n-1\n    U[k,k:n] = Aₖ[k,k:n]\n    L[k:n,k] = Aₖ[k:n,k]/U[k,k]\n    Aₖ[k:n,k:n] -= L[k:n,k]*U[k,k:n]'\nend\n\nWe will use the following handy fact.\n\nThe range k:n, where k\\le n, has n-k+1 elements.\n\nLine 17 above divides each element of the vector Aₖ[k:n,k] by a scalar. Hence the number of flops equals the length of the vector, which is n-k+1.\n\nLine 18 has an outer product followed by a matrix subtraction. The definition \n\n(5) of the outer product makes it clear that that computation takes one flop (multiplication) per element of the result, which here results in (n-k+1)^2 flops. The number of subtractions is identical.\n\nAltogether the factorization takes\\sum_{k=1}^{n-1} n-k + 1 + 2(n-k+1)^2.\n\nThere are different ways to simplify this expression. We will make a change of summation index using j=n-k. The endpoints of the sum are j=n-1 when k=1 and j=1 when k=n-1. Since the order of terms in a sum doesn’t matter, we get\\begin{align*}\n\\sum_{j=1}^{n-1} 1+j+2(j+1)^2 &=  \\sum_{j=1}^{n-1} 3 + 5j + 2j^2 \\\\\n  & \\sim  3(n-1) + \\frac{5}{2}(n-1)^2 + \\frac{2}{3}(n-1)^3 \\\\\n  & \\sim \\frac{2}{3}n^3.\n\\end{align*}\n\nWe have proved the following.\n\nEfficiency of LU factorization\n\nThe LU factorization of an n\\times n matrix takes \\sim\\frac{2}{3}n^3 flops as n\\to \\infty. This dominates the flops for solving an n\\times n linear system.\n\nFloating-point operations in LU factorization\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nlu(randn(3, 3));   # throwaway to force compilation\n\nn = 400:400:4000\nt = []\nfor n in n\n    A = randn(n, n)  \n    time = @elapsed for j in 1:12; lu(A); end\n    push!(t, time)\nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nscatter(n, t, label=\"data\", legend=:topleft,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time\"))\nplot!(n, t[end ]* (n/n[end]).^3, l=:dash, label=L\"O(n^3)\")\n\nFloating-point operations in LU factorization\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nn_ = (200:100:2400)';\nt_ = zeros(size(n_));\nfor i = 1:length(n_)\n    n = n_(i);\n    A = randn(n, n);  \n    tic    % start a timer\n    for j = 1:6,  [L, U] = lu(A);  end\n    t = toc;\n    t_(i) = t / 6;  \nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nclf\nloglog(n_,t_,'.-')\nhold on, loglog(n_,t_(end)*(n_/n_(end)).^3,'--')\naxis tight\nxlabel('size of matrix'), ylabel('time (sec)')\ntitle('Timing of LU factorization')\nlegend('lu','O(n^3)','location','southeast')\n\nFloating-point operations in LU factorization\n\nWe’ll test the conclusion of O(n^3) flops experimentally using the lu function imported from scipi.linalg.\n\nfrom scipy.linalg import lu\nN = arange(200, 2600, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    start = timer()\n    for j in range(5): lu(A)\n    t[i] = timer() - start\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nloglog(N, t, \"-o\", label=\"obseved\")\nloglog(N, t[-1] * (N / N[-1])**3, \"--\", label=\"$O(n^3)$\")\nlegend();\nxlabel(\"$n$\");\nylabel(\"elapsed time (sec)\");\ntitle(\"Timing of LU factorizations\");\n\nIn practice, flops are not the only aspect of an implementation that occupies significant time. Our position is that counting flops as a measure of performance is a useful oversimplification. We will assume that LU factorization (and as a result, the solution of a linear system of n equations) requires a real-world time that is roughly O(n^3). This growth rate is a great deal more tolerable than, say, O(2^n), but it does mean that for (at this writing) n greater than 10,000 or so, something other than general LU factorization will have to be used.","type":"content","url":"/efficiency#solution-of-linear-systems","position":7},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Exercises"},"type":"lvl2","url":"/efficiency#exercises","position":8},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Exercises"},"content":"✍ The following are asymptotic assertions about the limit n\\rightarrow\\infty. In each case, prove the statement true or false.\n\n(a) n^2 = O(\\log n),\\quad\n(b) n^{a} = O(n^b) if a\\le b,\\quad\n(c) e^n \\sim e^{2n},\\quad\n(d) n+\\sqrt{n}\\sim n+2\\sqrt{n}.\n\n✍ The following are asymptotic assertions about the limit h\\to 0. In each case, prove the statement true or false.\n\n(a) h^2\\log(h) = O(h^3),\\quad\n(b) h^{a} = O(h^b) if a < b,\\quad\n(c) \\sin(h) \\sim h,\\quad\n(d) (e^{2h}-1)\\sim h.\n\n✍ Show that the inner product of two n-vectors takes exactly 2n-1 flops.\n\n✍ Show that the multiplication of two n\\times n matrices takes \\sim 2n^3 flops.\n\n✍ This problem is about evaluation of a polynomial c_1 + c_2 x + \\cdots + c_{n}x^{n-1}.\n\n(a) Here is a little code to do the evaluation.y = c[1]\nxpow = 1\nfor i in 2:n\n    xpow *= x\n    y += c[i]*xpow\nend\n\nAssuming that x is a scalar, how many flops does this function take, as a function of n?\n\n(b) Compare the count from (a) to the flop count for Horner’s algorithm, \n\nFunction 1.3.1.\n\nThe exact sums for p=1,2 in \n\n(2.5.5) are as follows:\\sum_{k=1}^{n} k = \\frac{n(n+1)}{2}, \\qquad \n\\sum_{k=1}^{n} k^2 = \\frac{n(n+1)(2n+1)}{6}.\n\n(a) ✍  Use these to find the exact result for \n\n(2.5.9).\n\n(b) ⌨ Plot the ratio of your result from (a) and the asymptotic result 2n^3/3 for all n=10^{1+0.03i}, i=0,\\dots,100, using a log scale for n and a linear scale for the ratio. (The curve should approach 1 asymptotically.)\n\n✍ Show that for any nonnegative constant integer m,\\sum_{k=0}^{n-m} k^p \\sim \\frac{n^{p+1}}{p+1}.\n\n⌨ The UpperTriangular and LowerTriangular matrix types cause specialized algorithms to be invoked by the backslash. DefineA = rand(1000,1000)\nB = tril(A)\nC = LowerTriangular(B)\nb = rand(1000)\n\nUsing @elapsed with the backslash solver, time how long it takes to solve the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b} 100 times; then, do the same for matrices \\mathbf{B} and \\mathbf{C}. Is the timing for \\mathbf{B} closer to \\mathbf{A} or to \\mathbf{C}? (Hint: Remember to make one timing run without recording results, so that compilation time is not counted.)\n\nMore precisely, O(g) and \\sim g are sets of functions, and \\sim g is a subset of O(g). That we write f=O(g) rather than f\\in O(g) is a quirk of convention.","type":"content","url":"/efficiency#exercises","position":9},{"hierarchy":{"lvl1":"Linear systems"},"type":"lvl1","url":"/linear-systems","position":0},{"hierarchy":{"lvl1":"Linear systems"},"content":"We now attend to the central problem of this chapter: Given a square, n\\times n matrix \\mathbf{A} and an n-vector \\mathbf{b}, find an n-vector \\mathbf{x} such that \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Writing out these equations, we obtain\\begin{split}\n  A_{11}x_1 + A_{12}x_2 + \\cdots + A_{1n}x_n &= b_1, \\\\\n  A_{21}x_1 + A_{22}x_2 + \\cdots + A_{2n}x_n &= b_2, \\\\\n  \\vdots  \\\\\n  A_{n1}x_1 + A_{n2}x_2 + \\cdots + A_{nn}x_n &= b_n.\n\\end{split}\n\nIf \\mathbf{A} is invertible, then the mathematical expression of the solution is \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b} because\\begin{split}\n  \\mathbf{A}^{-1}\\mathbf{b} = \\mathbf{A}^{-1} (\\mathbf{A} \\mathbf{x}) = (\\mathbf{A}^{-1}\\mathbf{A}) \\mathbf{x} = \\mathbf{I} \\mathbf{x}\n  = \\mathbf{x}.\n\\end{split}\n\nWhen \\mathbf{A} is singular, then \\mathbf{A}\\mathbf{x}=\\mathbf{b} may have no solution or\ninfinitely many solutions.\n\nIf we define\\mathbf{S} =  \\begin{bmatrix}\n\t0 & 1\\\\0 & 0\n\\end{bmatrix},\n\nthen it is easy to check that for any real value of α we have\\mathbf{S}\n\\begin{bmatrix}\n\t\\alpha \\\\ 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\t1 \\\\ 0\n\\end{bmatrix}.\n\nHence the linear system \\mathbf{S}\\mathbf{x}=\\mathbf{b} with \\mathbf{b}=\\begin{bmatrix} 1\\\\0\\end{bmatrix} has infinitely many solutions. For most other choices of \\mathbf{b}, the system has no solution.","type":"content","url":"/linear-systems","position":1},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Don’t use the inverse"},"type":"lvl2","url":"/linear-systems#dont-use-the-inverse","position":2},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Don’t use the inverse"},"content":"Matrix inverses are indispensable for mathematical discussion and derivations. However, as you may remember from a linear algebra course, they are not trivial to compute from the entries of the original matrix. You might be surprised to learn that matrix inverses play almost no role in scientific computing.\n\nImportant\n\nComputing the inverse of a matrix is not a good way to solve a linear system of equations.\n\nIn fact, when we encounter an expression such as \\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b} in computing, we interpret it as “solve the linear system \\mathbf{A} \\mathbf{x} = \\mathbf{b}” and apply whatever algorithm is most expedient based on what we know about \\mathbf{A}.\n\nAs demonstrated in \n\nDemo 2.1.1, the backslash (the \\ symbol, not to be confused with the slash / used in web addresses) invokes a linear system solution.\n\nIn MATLAB, the backslash operator \\ is used to solve linear systems.\n\nIn Python, the numpy.linalg.solve function is used to solve linear systems.\n\nSolving linear systems\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1, 2, 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A*x\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = [0 1; 0 0]\nb = [1, -1]\nx = A \\ b\n\nIn this case we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nSolving linear systems\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1; 2; 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A*x\n\nIf the matrix \\mathbf{A} is singular, you may get a warning and nonsense result.\n\nA = [0 1; 0 0]\nb = [1; -1]\nx = A \\ b\n\nIn this case, we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nSolving linear systems\n\nFor a square matrix A, the command solve(A, B) is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = array([[1, 0, -1], [2, 2, 1], [-1, -3, 0]])\nb = array([1, 2, 3])\n\nx = solve(A, b)\nprint(x)\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision(relative to the elements in the data).\n\nresidual = b - A @ x\nprint(residual)\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = array([[0, 1], [0, 0]])\nb = array([1, -1])\nsolve(A, b)    # error, singular matrix\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, a numerical solution becomes trickier. Detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. We’re headed toward a more robust way to fully describe this situation.","type":"content","url":"/linear-systems#dont-use-the-inverse","position":3},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Triangular systems"},"type":"lvl2","url":"/linear-systems#triangular-systems","position":4},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Triangular systems"},"content":"The solution process is especially easy to demonstrate for a system with a triangular matrix. For example, consider the lower triangular system  \\begin{bmatrix}\n    4 & 0 & 0 & 0 \\\\\n    3 & -1 & 0 & 0 \\\\\n    -1 & 0 & 3 & 0 \\\\\n    1 & -1 & -1 & 2\n  \\end{bmatrix} \\mathbf{x} =\n  \\begin{bmatrix}\n    8 \\\\ 5 \\\\ 0 \\\\ 1\n  \\end{bmatrix}.\n\nThe first row of this system states simply that 4x_1=8, which is easily solved as x_1=8/4=2. Now, the second row states that 3x_1-x_2=5. As x_1 is already known, it can be replaced to find that x_2 = -(5-3\\cdot 2)=1. Similarly, the third row gives x_3=(0+1\\cdot 2)/3 = 2/3, and the last row yields x_4=(1-1\\cdot 2 + 1\\cdot 1 + 1\\cdot 2/3)/2 = 1/3. Hence the solution is  \\mathbf{x} =\n  \\begin{bmatrix} 2 \\\\ 1 \\\\ 2/3 \\\\ 1/3\n  \\end{bmatrix}.\n\nThe process just described is called forward substitution. In the 4\\times 4 lower triangular case of \\mathbf{L}\\mathbf{x}=\\mathbf{b} it leads to the formulas\\begin{split}\n  x_1 &= \\frac{b_1}{L_{11}}, \\\\\n  x_2 &= \\frac{b_2 - L_{21}x_1}{L_{22}}, \\\\\n  x_3 &= \\frac{b_3 - L_{31}x_1 - L_{32}x_2}{L_{33}}, \\\\\n  x_4 &= \\frac{b_4 - L_{41}x_1 - L_{42}x_2 - L_{43}x_3}{L_{44}}.\n\\end{split}\n\nFor upper triangular systems \\mathbf{U}\\mathbf{x}=\\mathbf{b} an analogous process of backward substitution begins by solving for the last component x_n=b_n/U_{nn} and working backward. For the 4\\times 4 case we have  \\begin{bmatrix}\n    U_{11} & U_{12} & U_{13} & U_{14} \\\\\n    0 & U_{22} & U_{23} & U_{24} \\\\\n    0 & 0 & U_{33} & U_{34} \\\\\n    0 & 0 & 0 & U_{44}\n  \\end{bmatrix} \\mathbf{x} =\n  \\begin{bmatrix}\n    b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4\n  \\end{bmatrix}.\n\nSolving the system backward, starting with x_4 first and then proceeding in descending order, gives\\begin{split}\n  x_4 &= \\frac{b_4}{U_{44}}, \\\\\n  x_3 &= \\frac{b_3 - U_{34}x_4}{U_{33}}, \\\\\n  x_2 &= \\frac{b_2 - U_{23}x_3 - U_{24}x_4}{U_{22}}, \\\\\n  x_1 &= \\frac{b_1 - U_{12}x_2 - U_{13}x_3 - U_{14}x_4}{U_{11}}.\n\\end{split}\n\nIt should be clear that forward or backward substitution fails if and only if one of the diagonal entries of the system matrix is zero. We have essentially proved the following theorem.\n\nTriangular singularity\n\nA triangular matrix is singular if and only if at least one of its diagonal elements is zero.","type":"content","url":"/linear-systems#triangular-systems","position":5},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Implementation"},"type":"lvl2","url":"/linear-systems#implementation","position":6},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Implementation"},"content":"Consider how to implement the sequential process implied by Equation \n\n(2.3.7). It seems clear that we want to loop through the elements of \\mathbf{x} in order. Within each iteration of that loop, we have an expression whose length depends on the iteration number. This leads to a nested loop structure.\n\nforwardsub\n\nForward substitution\n\n\"\"\"\n    forwardsub(L,b)\n\nSolve the lower-triangular linear system with matrix `L` and\nright-hand side vector `b`.\n\"\"\"\nfunction forwardsub(L,b)\n    n = size(L,1)\n    x = zeros(n)\n    x[1] = b[1]/L[1,1]\n    for i in 2:n\n        s = sum( L[i,j]*x[j] for j in 1:i-1 )\n        x[i] = ( b[i] - s ) / L[i,i]\n    end\n    return x\nend\n\nAbout the code\n\nThe sum in line 12 gives an error if i equals 1, so that case is taken care of before the loop starts.\n\nForward substitution\n\n\"\"\"\n    forwardsub(L,b)\n\nSolve the lower-triangular linear system with matrix `L` and\nright-hand side vector `b`.\n\"\"\"\nfunction forwardsub(L,b)\n    n = size(L,1)\n    x = zeros(n)\n    x[1] = b[1]/L[1,1]\n    for i in 2:n\n        s = sum( L[i,j]*x[j] for j in 1:i-1 )\n        x[i] = ( b[i] - s ) / L[i,i]\n    end\n    return x\nend\n\nAbout the code\n\nThe sum in line 12 gives an error if i equals 1, so that case is taken care of before the loop starts.\n\nForward substitution\n\ndef forwardsub(L,b):\n    \"\"\"\n     forwardsub(L,b)\n\n    Solve the lower-triangular linear system with matrix L and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n):\n        s = L[i,:i] @ x[:i]\n        x[i] = ( b[i] - s ) / L[i, i]\n    return x\n\nThe implementation of backward substitution is much like forward substitution and is given in \n\nFunction 2.3.2.\n\nbacksub\n\nBackward substitution\n\n\"\"\"\n    backsub(U,b)\n\nSolve the upper-triangular linear system with matrix `U` and\nright-hand side vector `b`.\n\"\"\"\nfunction backsub(U,b)\n    n = size(U,1)\n    x = zeros(n)\n    x[n] = b[n]/U[n,n]\n    for i in n-1:-1:1\n        s = sum( U[i,j]*x[j] for j in i+1:n )\n        x[i] = ( b[i] - s ) / U[i,i]\n    end\n    return x\nend\n\nBackward substitution\n\n\"\"\"\n    backsub(U,b)\n\nSolve the upper-triangular linear system with matrix `U` and\nright-hand side vector `b`.\n\"\"\"\nfunction backsub(U,b)\n    n = size(U,1)\n    x = zeros(n)\n    x[n] = b[n]/U[n,n]\n    for i in n-1:-1:1\n        s = sum( U[i,j]*x[j] for j in i+1:n )\n        x[i] = ( b[i] - s ) / U[i,i]\n    end\n    return x\nend\n\nBackward substitution\n\ndef backsub(U,b):\n    \"\"\"\n    backsub(U,b)\n\n    Solve the upper-triangular linear system with matrix U and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n-1, -1, -1):\n        s = U[i, i+1:] @ x[i+1:]\n        x[i] = ( b[i] - s ) / U[i, i]\n    return x\n\nTriangular systems of equations\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = rand(1.:9., 5, 5)\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L,b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext we’ll engineer a problem to which we know the exact answer. Use \\alpha Tab and \\beta Tab to get the Greek letters.\n\nThe notation 0=>ones(5) creates a Pair. In diagm, pairs indicate the position of a diagonal and the elements that are to be placed on it.\n\nα = 0.3;\nβ = 2.2;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nU\n\nx_exact = ones(5)\nb = [α, 0, 0, 0, 1]\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nα = 0.3;\nβ = 1e12;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nb = [α, 0, 0, 0, 1]\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with 16! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.\n\nTriangular systems of equations\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = randi(9, 5, 5);\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5);\nx = forwardsub(L, b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext, we’ll engineer a problem to which we know the exact answer.\n\nThe eye function creates an identity matrix. The diag function uses 0 as the main diagonal, positive integers as superdiagonals, and negative integers as subdiagonals.\n\nalpha = 0.3;\nbeta = 2.2;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta]\n\nx_exact = ones(5);\nb = [alpha; 0; 0; 0; 1];\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = backsub(U, b);\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta];\nb = [alpha; 0; 0; 0; 1];\n\nx = backsub(U, b);\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.\n\nTriangular systems of equations\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nA = 1 + floor(9 * random.rand(5, 5))\nL = tril(A)\nprint(L)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L, b)\nprint(x)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L @ x\n\nNext we’ll engineer a problem to which we know the exact answer.\n\nalpha = 0.3;\nbeta = 2.2;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nprint(U)\n\nx_exact = ones(5)\nb = array([alpha, 0, 0, 0, 1])\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nb = array([alpha, 0, 0, 0, 1])\n\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! But the source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.\n\nThe example in \n\nDemo 2.3.3 is our first clue that linear system problems may have large condition numbers, making inaccurate solutions inevitable in floating-point arithmetic. We will learn how to spot such problems in \n\nConditioning of linear systems. Before reaching that point, however, we need to discuss how to solve general linear systems, not just triangular ones.","type":"content","url":"/linear-systems#implementation","position":7},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Exercises"},"type":"lvl2","url":"/linear-systems#exercises","position":8},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Exercises"},"content":"✍ Find a vector \\mathbf{b} such that the system \\begin{bmatrix} 0&1\\\\0&0 \\end{bmatrix} \\mathbf{x}=\\mathbf{b} has no solution.\n\n✍ Solve the following triangular systems by hand.\n\n(a) \\displaystyle \\begin{aligned}\n   -2x_1  &= -4 \\\\\n     x_1  - x_2        &= 2 \\\\\n    3x_1 + 2x_2  + x_3 &= 1\n   \\end{aligned} \\quad\n(b) \\displaystyle \\begin{bmatrix}\n     4 & 0 & 0 & 0 \\\\\n     1 & -2 & 0 & 0 \\\\\n     -1 & 4 & 4 & 0 \\\\\n     2 & -5 & 5 & 1\n   \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix}\n     -4 \\\\ 1 \\\\ -3 \\\\ 5\n   \\end{bmatrix}\\quad\n(c) \\displaystyle \\begin{aligned}\n    3x_1 +  2x_2  +  x_3      &= 1 \\\\\n            x_2   -  x_3      &= 2 \\\\\n                     2 x_3    &= -4\n   \\end{aligned}\n\n⌨ Use \n\nFunction 2.3.1 or \n\nFunction 2.3.2 to solve each system from the preceding exercise. Verify that the solution is correct by computing \\mathbf{L}\\mathbf{x} and subtracting \\mathbf{b}.\n\n⌨  Use \n\nFunction 2.3.2 to solve the following systems.  Verify that the solution is correct by computing \\mathbf{U}\\mathbf{x} and subtracting \\mathbf{b}.\n\n(a) \\;\\begin{bmatrix}\n   3 & 1 & 0  \\\\\n   0 & -1 & -2  \\\\\n   0 & 0 & 3  \\\\\n \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix}\n   1 \\\\ 1 \\\\ 6\n \\end{bmatrix}\\qquad\n(b) \\;\\begin{bmatrix}\n   3 & 1 & 0 & 6 \\\\\n   0 & -1 & -2 & 7 \\\\\n   0 & 0 & 3 & 4 \\\\\n   0 & 0 & 0 & 5\n \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix}\n   4 \\\\ 1 \\\\ 1 \\\\ 5\n \\end{bmatrix}\n\nSuppose a string is stretched with tension τ horizontally between two anchors at x=0 and x=1. At each of the n-1 equally spaced positions x_k=k/n, k=1,\\ldots,n-1, we attach a little mass m_i and allow the string to come to equilibrium. This causes vertical displacement of the string. Let q_k be the amount of displacement at x_k. If the displacements are not too large, then an approximate force balance equation isn \\tau (q_k - q_{k-1}) + n\\tau (q_k - q_{k+1}) =\nm_k g, \\qquad k=1,\\ldots,n-1,\n\nwhere g=-9.8 m/s2 is the acceleration due to gravity, and we define q_0=0 and q_n=0 due to the anchors. This defines a linear system for q_1,\\ldots,q_{n-1}.\n\n(a) ✍ Show that the force balance equations can be written as a linear system \\mathbf{A}\\mathbf{q}=\\mathbf{f}, where \\mathbf{q} is a vector of the unknown displacements and \\mathbf{A} is a tridiagonal matrix (i.e., A_{ij}=0 if |i-j|>1) of size (n-1)\\times(n-1).\n\n(b) ⌨  Let \\tau=10 N, and m_k=(1/10n) kg for every k. Using backslash, find the displacements when n=8 and n=40, and superimpose plots of \\mathbf{q} over 0\\le x \\le 1 for the two cases. (Be sure to include the zero values at x=0 and x=1 in your plots.)\n\n(c) ⌨  Repeat (b) for the case m_k = (k/5n^2) kg.\n\n⌨  If \\mathbf{B}\\in\\mathbb{R}^{n \\times p} has columns \\mathbf{b}_1,\\ldots,\\mathbf{b}_p, then we can pose p linear systems at once by writing \\mathbf{A} \\mathbf{X} = \\mathbf{B}, where \\mathbf{X} is n\\times p. Specifically, this equation implies \\mathbf{A} \\mathbf{x}_j = \\mathbf{b}_j for j=1,\\ldots,p.\n\n(a) Modify \n\nFunction 2.3.1 and \n\nFunction 2.3.2 so that they solve the case where the second input is n\\times p for p\\ge 1.\n\n(b) If \\mathbf{A} \\mathbf{X}=\\mathbf{I}, then \\mathbf{X}=\\mathbf{A}^{-1}. Use this fact to write a function ltinverse that uses your modified forwardsub to compute the inverse of a lower triangular matrix. Test your function on at least two nontrivial matrices. (We remind you here that this is just an exercise; matrix inverses are rarely a good idea in numerical practice!)\n\n⌨ \n\nDemo 2.3.3 showed solutions of \\mathbf{A}\\mathbf{x}=\\mathbf{b}, where\\mathbf{A} = \\begin{bmatrix} 1 & -1 & 0 & \\alpha-\\beta & \\beta \\\\ 0 & 1 & -1 &\n  0 & 0 \\\\ 0 & 0 & 1 & -1 & 0 \\\\ 0 & 0 & 0 & 1 & -1  \\\\ 0 & 0 & 0 & 0 & 1\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix} \\alpha \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}.\n\nUse \n\nFunction 2.3.2 to solve with \\alpha=0.1 and \\beta=10,100,10^3,\\ldots,10^{12}, tabulating the values of β and |x_1-1|. (This kind of behavior is explained in \n\nConditioning of linear systems.)","type":"content","url":"/linear-systems#exercises","position":9},{"hierarchy":{"lvl1":"LU factorization"},"type":"lvl1","url":"/lu","position":0},{"hierarchy":{"lvl1":"LU factorization"},"content":"A major tool in numerical linear algebra is to factor a given matrix into terms that are individually easier to deal with than the original. In this section we derive a means to express a square matrix using triangular factors, which will allow us to solve a linear system using forward and backward substitution.","type":"content","url":"/lu","position":1},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Outer products"},"type":"lvl2","url":"/lu#outer-products","position":2},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Outer products"},"content":"Our derivation of the factorization hinges on an expression of matrix products in terms of vector outer products. If  \\mathbf{u}\\in\\real^m and \\mathbf{v}\\in\\real^n, then the outer product of these vectors is the m\\times n matrix\\mathbf{u} \\mathbf{v}^T =\n\\begin{bmatrix}\nu_1 v_1 & u_1 v_2 & \\cdots & u_1 v_n \\\\u_2 v_1 & u_2 v_2 & \\cdots & u_2 v_n \\\\ \\vdots & \\vdots & & \\vdots \\\\ u_m v_1 & u_m v_2 & \\cdots & u_m v_n\n\\end{bmatrix}.\n\nWe illustrate the connection of outer products to matrix multiplication by a small example.\n\nAccording to the usual definition of matrix multiplication,\\begin{align*}\n\t\\small\n\t\\begin{bmatrix}\n\t\t4 & -1  \\\\ -3 & 5 \\\\ -2 &  6\t  \n\t\\end{bmatrix}\n\t\\begin{bmatrix}\n\t\t2 & -7 \\\\ -3 & 5 \t  \n\t\\end{bmatrix}\n\t& = \n\t\\small\n\t\\begin{bmatrix}\n\t\t(4)(2) + (-1)(-3)  &  (4)(-7) + (-1)(5)   \\\\ \n\t\t(-3)(2) + (5)(-3)  &  (-3)(-7) + (5)(5)  \\\\ \n\t\t(-2)(2) + (6)(-3)  &  (-2)(-7) + (6)(5)  \n\t\\end{bmatrix}.  \n\\end{align*}\n\nIf we break this up into the sum of two matrices, however, each is an outer product.\\begin{align*}\n\t& = \n\t\\small\n\t\\begin{bmatrix}\n\t\t(4)(2)   &  (4)(-7)    \\\\ \n\t\t(-3)(2)   &  (-3)(-7)    \\\\ \n\t\t(-2)(2) &  (-2)(-7) \n\t\\end{bmatrix} + \n\t\\begin{bmatrix}\n\t\t(-1)(-3)  &  (-1)(5)  \\\\ \n\t\t(5)(-3)  &  (5)(5)  \\\\ \n\t\t(6)(-3)  &  (6)(5) \n\t\\end{bmatrix}\\\\[2mm]\n\t& = \n\t\\small\n\t\\begin{bmatrix}\n\t\t4 \\\\ -3 \\\\ -2 \n\t\\end{bmatrix} \n\t\\begin{bmatrix}\n\t\t2 & -7 \n\t\\end{bmatrix} \\: + \\:\n\t\\begin{bmatrix}\n\t\t-1 \\\\ 5 \\\\ 6 \n\t\\end{bmatrix} \n\t\\begin{bmatrix}\n\t\t-3 & 5 \n\t\\end{bmatrix}.\n\\end{align*}\n\nNote that the vectors here are columns of the left-hand matrix and rows of the right-hand matrix. The matrix product is defined only if there are equal numbers of these.\n\nIt is not hard to derive the following generalization of \n\nExample 2.4.1 to all matrix products.\n\nMatrix multiplication by outer products\n\nWrite the columns of \\mathbf{A} as \\mathbf{a}_1,\\dots,\\mathbf{a}_n and the rows of \\mathbf{B} as \\mathbf{b}_1^T,\\dots,\\mathbf{b}_n^T. Then\\mathbf{A}\\mathbf{B} = \\sum_{k=1}^n \\mathbf{a}_k \\mathbf{b}_k^T.","type":"content","url":"/lu#outer-products","position":3},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular product"},"type":"lvl2","url":"/lu#triangular-product","position":4},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular product"},"content":"Equation \n\n(2.4.4) has some interesting structure for the product \\mathbf{L}\\mathbf{U}, where \\mathbf{L} is n\\times n and lower triangular (i.e., zero above the main diagonal) and \\mathbf{U} is n\\times n and upper triangular (zero below the diagonal).\n\nTriangular outer products\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( rand(1:9, 3, 3) )\n\nU = triu( rand(1:9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nAlthough U[1,:] is a row of U, it is a vector, and as such it has a default column interpretation.\n\nL[:, 1] * U[1, :]'\n\nL[:, 2] * U[2, :]'\n\nL[:, 3] * U[3, :]'\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nTriangular outer products\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( randi(9, 3, 3) )\n\nU = triu( randi(9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nL(:, 1) * U(1, :)\n\nL(:, 2) * U(2, :)\n\nL(:, 3) * U(3, :)\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nTriangular outer products\n\nWe explore the outer product formula for two random triangular matrices.\n\nfrom numpy.random import randint\nL = tril(randint(1, 10, size=(3, 3)))\nprint(L)\n\nU = triu(randint(1, 10, size=(3, 3)))\nprint(U)\n\nHere are the three outer products appearing in the sum in \n\n(2.4.4):\n\nprint(outer(L[:, 0], U[0, :]))\n\nprint(outer(L[:, 1], U[1, :]))\n\nprint(outer(L[:, 2], U[2, :]))\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nLet the columns of \\mathbf{L} be written as \\boldsymbol{\\ell}_k and the rows of \\mathbf{U} be written as \\mathbf{u}_k^T. Then the first row of \\mathbf{L}\\mathbf{U} is\\mathbf{e}_1^T \\sum_{k=1}^n  \\boldsymbol{ℓ}_k \\mathbf{u}_k^T = \\sum_{k=1}^n (\\mathbf{e}_1^T \\boldsymbol{\\ell}_k) \\mathbf{u}_k^T = L_{11} \\mathbf{u}_1^T.\n\nLikewise, the first column of \\mathbf{L}\\mathbf{U} is\\left( \\sum_{k=1}^n \\mathbf{ℓ}_k \\mathbf{u}_k^T\\right) \\mathbf{e}_1 = \\sum_{k=1}^n \\mathbf{\\ell}_k (\\mathbf{u}_k^T \\mathbf{e}_1) = U_{11}\\boldsymbol{\\ell}_1.\n\nThese two calculations are enough to derive one of the most important algorithms in scientific computing.","type":"content","url":"/lu#triangular-product","position":5},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular factorization"},"type":"lvl2","url":"/lu#triangular-factorization","position":6},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular factorization"},"content":"Our goal is to factor a given n\\times n matrix \\mathbf{A} as the triangular product \\mathbf{A}=\\mathbf{L}\\mathbf{U}. It turns out that we have n^2+n total nonzero unknowns in the two triangular matrices, so we set L_{11}=\\cdots = L_{nn}=1, making \\mathbf{L} a unit lower triangular matrix.\n\nLU factorization\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA₁ = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = diagm(ones(4))\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[1, :] = A₁[1, :]\nU\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 1] = A₁[:, 1] / U[1, 1]\nL\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[2, :] = A₂[2, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nL\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[3, :] = A₃[3, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\nFinally, we pick up the last unknown in the factors.\n\nU[4, 4] = A₄[4, 4];\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA₁ - L * U\n\nIIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nLU factorization\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = eye(4);\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU(1, :) = A_1(1, :)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL(:, 1) = A_1(:, 1) / U(1, 1)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU(2, :) = A_2(2, :)\nL(:, 2) = A_2(:, 2) / U(2, 2)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU(3, :) = A_3(3, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\nFinally, we pick up the last unknown in the factors.\n\nU(4, 4) = A_4(4, 4);\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L * U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nLU factorization\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = array([\n     [2,    0,    4,    3], \n     [-4,    5,   -7,  -10], \n     [1,   15,    2,   -4.5],\n     [-2,    0,    2,  -13]\n        ])\nL = eye(4)\nU = zeros((4, 4));\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[0, :] = A_1[0, :]\nprint(U)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 0] = A_1[:, 0] / U[0, 0]\nprint(L)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - outer(L[:, 0],  U[0, :])\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[1, :] = A_2[1, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nprint(L)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - outer(L[:, 1], U[1, :])\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[2, :] = A_3[2, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\n\nFinally, we pick up the last unknown in the factors.\n\nU[3, 3] = A_4[3, 3]\n\nWe now have all of \\mathbf{L},\n\nprint(L)\n\nand all of \\mathbf{U},\n\nprint(U)\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L @ U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nWe have arrived at the linchpin of solving linear systems.\n\nLU factorization\n\nGiven n\\times n matrix \\mathbf{A}, its LU factorization is\\mathbf{A} = \\mathbf{L}\\mathbf{U},\n\nwhere \\mathbf{L} is a unit lower triangular matrix and \\mathbf{U} is an upper triangular matrix.\n\nThe outer product algorithm for LU factorization seen in \n\nDemo 2.4.3 is coded as \n\nFunction 2.4.1.\n\nlufact\n\nLU factorization (not stable)\n\n\"\"\"\n    lufact(A)\n\nCompute the LU factorization of square matrix `A`, returning the\nfactors.\n\"\"\"\nfunction lufact(A)\n    n = size(A,1)        # detect the dimensions from the input\n    L = diagm(ones(n))   # ones on main diagonal, zeros elsewhere\n    U = zeros(n,n)\n    Aₖ = float(copy(A))  # make a working copy \n\n    # Reduction by outer products\n    for k in 1:n-1\n        U[k,:] = Aₖ[k,:]\n        L[:,k] = Aₖ[:,k]/U[k,k]\n        Aₖ -= L[:,k]*U[k,:]'\n    end\n    U[n,n] = Aₖ[n,n]\n    return LowerTriangular(L),UpperTriangular(U)\nend\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out two subtle Julia issues. First, vectors and matrix variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement Aₖ=A just clones the array reference of A into the variable Aₖ. Any changes made to entries of Aₖ would then also be made to entries of A because they refer to the same location in memory. In this context we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nThe second issue is that even when A has all integer entries, its LU factors may not. So we convert Aₖ to floating point so that line 17 will not fail due to the creation of floating-point values in an integer matrix. An alternative would be to require the caller to provide a floating-point array in the first place.\n\nLU factorization (not stable)\n\n\"\"\"\n    lufact(A)\n\nCompute the LU factorization of square matrix `A`, returning the\nfactors.\n\"\"\"\nfunction lufact(A)\n    n = size(A,1)        # detect the dimensions from the input\n    L = diagm(ones(n))   # ones on main diagonal, zeros elsewhere\n    U = zeros(n,n)\n    Aₖ = float(copy(A))  # make a working copy \n\n    # Reduction by outer products\n    for k in 1:n-1\n        U[k,:] = Aₖ[k,:]\n        L[:,k] = Aₖ[:,k]/U[k,k]\n        Aₖ -= L[:,k]*U[k,:]'\n    end\n    U[n,n] = Aₖ[n,n]\n    return LowerTriangular(L),UpperTriangular(U)\nend\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out two subtle Julia issues. First, vectors and matrix variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement Aₖ=A just clones the array reference of A into the variable Aₖ. Any changes made to entries of Aₖ would then also be made to entries of A because they refer to the same location in memory. In this context we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nThe second issue is that even when A has all integer entries, its LU factors may not. So we convert Aₖ to floating point so that line 17 will not fail due to the creation of floating-point values in an integer matrix. An alternative would be to require the caller to provide a floating-point array in the first place.\n\nLU factorization (not stable)\n\ndef lufact(A):\n    \"\"\"\n    lufact(A)\n\n    Compute the LU factorization of square matrix `A`, returning the\n    factors.\n    \"\"\"\n    n = A.shape[0]     # detect the dimensions from the input\n    L = np.eye(n)      # ones on main diagonal, np.zeros elsewhere\n    U = np.zeros((n, n))\n    A_k = np.copy(A)   # make a working np.copy \n\n    # Reduction by np.outer products\n    for k in range(n-1):\n        U[k, :] = A_k[k, :]\n        L[:, k] = A_k[:, k] / U[k,k]\n        A_k -= np.outer(L[:,k], U[k,:])\n    U[n-1, n-1] = A_k[n-1, n-1]\n    return L, U\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out a subtle issue. Array variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement A_k = A would just clone the array reference of A into the new variable. Any changes made to entries of A_k would then also be made to entries of A, because they refer to the same location in memory. In this context, we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.","type":"content","url":"/lu#triangular-factorization","position":7},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Gaussian elimination and linear systems"},"type":"lvl2","url":"/lu#gaussian-elimination-and-linear-systems","position":8},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Gaussian elimination and linear systems"},"content":"In your first matrix algebra course, you probably learned a triangularization technique called Gaussian elimination or row elimination to solve a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}. In most presentations, you form an augmented matrix [\\mathbf{A}\\;\\mathbf{b}] and do row operations until the system reaches an upper triangular form, followed by backward substitution. LU factorization is equivalent to Gaussian elimination in which no row swaps are performed, and the elimination procedure produces the factors if you keep track of the row multipliers appropriately.\n\nLike Gaussian elimination, the primary use of LU factorization is to solve a linear system. It reduces a given linear system to two triangular ones. From this, solving \\mathbf{A}\\mathbf{x}=\\mathbf{b} follows immediately from associativity:\\mathbf{b} = \\mathbf{A} \\mathbf{x} = (\\mathbf{L} \\mathbf{U}) \\mathbf{x} = \\mathbf{L} (\\mathbf{U} \\mathbf{x}).\n\nDefining \\mathbf{z} = \\mathbf{U} \\mathbf{x} leads to the following.\n\nSolution of linear systems by LU factorization (unstable)\n\nFactor \\mathbf{L}\\mathbf{U}=\\mathbf{A}.\n\nSolve \\mathbf{L}\\mathbf{z}=\\mathbf{b} for \\mathbf{z} using forward substitution.\n\nSolve \\mathbf{U}\\mathbf{x}=\\mathbf{z} for \\mathbf{x} using backward substitution.\n\nA key advantage of the factorization point of view is that it depends only on the matrix \\mathbf{A}. If systems are to be solved for a single \\mathbf{A} but multiple different versions of \\mathbf{b}, then the factorization approach is more efficient, as we’ll see in \n\nEfficiency of matrix computations.\n\nSolving a linear system by LU factors\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4,9,9,4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A*x\n\nSolving a linear system by LU factors\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4; 9; 9; 4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\n[L, U] = lufact(A)\nz = forwardsub(L, b);\nx = backsub(U, z);\n\nA check on the residual assures us that we found the solution.\n\nb - A * x\n\nSolving a linear system by LU factors\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = array([\n    [2, 0, 4, 3], \n    [-4, 5, -7, -10], \n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nb = array([4, 9, 9, 4])\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A @ x\n\nAs noted in the descriptions of \n\nFunction 2.4.1 and \n\nAlgorithm 2.4.2, the LU factorization as we have seen it so far is not stable for all matrices. In fact, it does not always even exist. The missing element is the row swapping allowed in Gaussian elimination. We will address these issues in \n\nRow pivoting.","type":"content","url":"/lu#gaussian-elimination-and-linear-systems","position":9},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Exercises"},"type":"lvl2","url":"/lu#exercises","position":10},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Exercises"},"content":"✍ For each matrix, produce an LU factorization by hand.\n\n(a) \\quad \\displaystyle \\begin{bmatrix}\n 2 & 3 & 4 \\\\\n 4 & 5 & 10 \\\\\n 4 & 8 & 2\n \\end{bmatrix}\\qquad\n(b) \\quad \\displaystyle \\begin{bmatrix}\n 6 & -2 & -4 & 4\\\\\n 3 & -3 & -6 & 1 \\\\\n -12 & 8 & 21 & -8 \\\\\n -6 & 0 & -10 & 7\n \\end{bmatrix}\n\n⌨ The matrices\\mathbf{T}(x,y) = \\begin{bmatrix}\n  1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ x & y & 1\n\\end{bmatrix},\\qquad\n\\mathbf{R}(\\theta) = \\begin{bmatrix}\n  \\cos\\theta & \\sin \\theta & 0 \\\\ -\\sin\\theta & \\cos \\theta & 0 \\\\ 0 & 0 & 1\n\\end{bmatrix}\n\nare used to represent translations and rotations of plane points in computer graphics. For the following, let\\mathbf{A} = \\mathbf{T}(3,-1)\\mathbf{R}(\\pi/5)\\mathbf{T}(-3,1), \\qquad \\mathbf{z} = \\begin{bmatrix}\n  2 \\\\ 2 \\\\ 1\n\\end{bmatrix}.\n\n(a) Find \\mathbf{b} = \\mathbf{A}\\mathbf{z}.\n\n(b) Use \n\nFunction 2.4.1 to find the LU factorization of \\mathbf{A}.\n\n(c) Use the factors with triangular substitutions in order to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}, and find \\mathbf{x}-\\mathbf{z}.\n\n⌨ Define\\mathbf{A}= \\begin{bmatrix}\n  1 & 0 & 0 & 0 & 10^{12} \\\\\n  1 & 1 & 0 & 0 & 0 \\\\\n  0 & 1 & 1 & 0 & 0 \\\\\n  0 & 0 & 1 & 1 & 0 \\\\\n  0 & 0 & 0 & 1 & 0\n\\end{bmatrix},\n\\quad \\hat{\\mathbf{x}} = \\begin{bmatrix}\n  0 \\\\ 1/3 \\\\ 2/3 \\\\ 1 \\\\ 4/3\n\\end{bmatrix},\n\\quad \\mathbf{b} = \\mathbf{A}\\hat{\\mathbf{x}}.\n\n(a) Using \n\nFunction 2.4.1 and triangular substitutions, solve the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, showing the result. To the nearest integer, how many accurate digits are in the result? (The answer is much less than the full 16 of double precision.)\n\n(b) Repeat part (a) with \n\n1020 as the element in the upper right corner. (The result is even less accurate. We will study the causes of such low accuracy in \n\nConditioning of linear systems.)\n\n⌨ Let\\mathbf{A} = \n\t\\begin{bmatrix}\n     1 & 1 & 0 & 1 & 0 & 0 \\\\\n     0 & 1 & 1 & 0 & 1 & 0 \\\\\n     0 & 0 & 1 & 1 & 0 & 1 \\\\\n     1 & 0 & 0 & 1 & 1 & 0 \\\\\n     1 & 1 & 0 & 0 & 1 & 1 \\\\\n     0 & 1 & 1 & 0 & 0 & 1\n    \\end{bmatrix}.\n\nVerify computationally that if \\mathbf{A}=\\mathbf{L}\\mathbf{U} is the LU factorization, then the elements of \\mathbf{L}, \\mathbf{U}, \\mathbf{L}^{-1}, and \\mathbf{U}^{-1} are all integers. Do not rely just on visual inspection of the numbers; perform a more definitive test.\n\n⌨ \n\nFunction 2.4.1 factors \\mathbf{A}=\\mathbf{L}\\mathbf{U} in such a way that \\mathbf{L} is a unit lower triangular matrix—that is, has all ones on the diagonal. It is also possible to define the factorization so that \\mathbf{U} is a unit upper triangular matrix instead. Write a function lufact2 that uses \n\nFunction 2.4.1 without modification to produce this version of the factorization. (Hint: Begin with the standard LU factorization of \\mathbf{A}^T.) Demonstrate on a nontrivial 4\\times 4 example.\n\nWhen computing the determinant of a matrix by hand, it’s common to use cofactor expansion and apply the definition recursively. But this is terribly inefficient as a function of the matrix size.\n\n(a) ✍ Explain using determinant properties why, if \\mathbf{A}=\\mathbf{L}\\mathbf{U} is an LU factorization,  \\det(\\mathbf{A}) = U_{11}U_{22}\\cdots U_{nn}=\\prod_{i=1}^n U_{ii}.\n\n(b) ⌨ Using the result of part (a), write a function determinant(A) that computes the determinant using \n\nFunction 2.4.1. Test your function on at least two nontriangular 5\\times 5 matrices, comparing your result to the result of the standard det function.","type":"content","url":"/lu#exercises","position":11},{"hierarchy":{"lvl1":"Computing with matrices"},"type":"lvl1","url":"/matrices","position":0},{"hierarchy":{"lvl1":"Computing with matrices"},"content":"Attention\n\nWe recommend that you review the linear algebra material in \n\nReview of linear algebra before reading this section.\n\nAt a reductive level, a matrix is a table of numbers that obeys certain algebraic laws. But matrices are pervasive in scientific computation, mainly because they represent linear operations on vectors. Moreover, vectors go far beyond the three-dimensional representations of physical quantities you learned about in calculus.","type":"content","url":"/matrices","position":1},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Notation"},"type":"lvl2","url":"/matrices#notation","position":2},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Notation"},"content":"We use capital letters in bold to refer to matrices, and lowercase bold letters for vectors. All named vectors in this book are column vectors. The bold symbol \\boldsymbol{0} may refer to a vector of all zeros or to a zero matrix, depending on context; we use 0 as the scalar zero only.\n\nTo refer to a specific element of a matrix, we use the uppercase name of the matrix without boldface, as in A_{24} to mean the (2,4) element of \\mathbf{A}. To refer to an element of a vector, we use just one subscript, as in x_3. If you see a boldface character with one or more subscripts, then you know that it is a matrix or vector that belongs to a sequence or indexed collection.\n\nWe will have frequent need to refer to the individual columns of a matrix as vectors. Our convention is to use a lowercase bold version of the matrix name with a subscript to represent the column number. Thus, \\mathbf{a}_1,\\mathbf{a}_2,\\ldots,\\mathbf{a}_n are the columns of the m\\times n matrix \\mathbf{A}. Conversely, whenever we define a sequence of vectors \\mathbf{v}_1,\\ldots,\\mathbf{v}_p, we can implicitly consider them to be columns of a matrix \\mathbf{V}. Sometimes we might write \\mathbf{V}=\\bigl[ \\mathbf{v}_j \\bigr] to emphasize the connection.\n\nThe notation \\mathbf{A}^T is used for the transpose of a matrix, whether it is real or complex. In the case of complex matrices, it’s almost always more desirable to use the adjoint \\mathbf{A}^*, which is the transpose with the complex conjugate of each element.  If \\mathbf{A} is real, then \\mathbf{A}^*=\\mathbf{A}^T. A symmetric matrix is a square matrix such that \\mathbf{A}^T=\\mathbf{A}.\n\nThe identity matrix of size n is denoted \\mathbf{I}, or sometimes \\mathbf{I}_n if emphasizing the size is important in context. For columns of the identity we break with our usual naming convention and denote them by \\mathbf{e}_j.","type":"content","url":"/matrices#notation","position":3},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Block matrix expressions"},"type":"lvl2","url":"/matrices#block-matrix-expressions","position":4},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Block matrix expressions"},"content":"We will often find it useful to break a matrix into separately named pieces. For example, we might write  \\mathbf{A} =\n  \\begin{bmatrix}\n    \\mathbf{A}_{11} & \\mathbf{A}_{12} & \\mathbf{A}_{13} \\\\\n    \\mathbf{A}_{21} & \\mathbf{A}_{22} & \\mathbf{A}_{23}\n  \\end{bmatrix}, \\qquad\n  \\mathbf{B} =\n  \\begin{bmatrix}\n    \\mathbf{B}_1 \\\\ \\mathbf{B}_2 \\\\ \\mathbf{B}_3\n  \\end{bmatrix}.\n\nIt’s understood that blocks that are on top of one another have the same number of columns, and blocks that are side by side have the same number of rows. Typically, if the blocks all have compatible dimensions, then they can be multiplied as though the blocks were scalars. For instance, continuing with the definitions above, we say that \\mathbf{A} is block-2\\times 3 and \\mathbf{B} is block-3\\times 1, so we can write  \\mathbf{A} \\mathbf{B} =\n  \\begin{bmatrix}\n    \\mathbf{A}_{11}\\mathbf{B}_1 + \\mathbf{A}_{12}\\mathbf{B}_2 + \\mathbf{A}_{13}\\mathbf{B}_3 \\\\\n    \\mathbf{A}_{21}\\mathbf{B}_1 + \\mathbf{A}_{22}\\mathbf{B}_2 + \\mathbf{A}_{23}\\mathbf{B}_3\n  \\end{bmatrix},\n\nprovided that the individual block products are well-defined. For transposes we have, for example,  \\mathbf{A}^T =\n  \\begin{bmatrix}\n    \\mathbf{A}_{11}^T & \\mathbf{A}_{21}^T \\\\[2mm]\n    \\mathbf{A}_{12}^T & \\mathbf{A}_{22}^T \\\\[2mm]\n    \\mathbf{A}_{13}^T & \\mathbf{A}_{23}^T\n  \\end{bmatrix}.","type":"content","url":"/matrices#block-matrix-expressions","position":5},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Vector and matrix basics"},"type":"lvl2","url":"/matrices#vector-and-matrix-basics","position":6},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Vector and matrix basics"},"content":"Vectors and matrices are integral to scientific computing. All modern languages provide ways to work with them beyond manipulation of individual elements.\n\nMatrix operations\n\nIn Julia, vectors and matrices are one-dimensional and two-dimensional arrays, respectively. Square brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ 1 2 3 4 5; 50 40 30 20 10\n    π sqrt(2) exp(1) (1+sqrt(5))/2 log(3) ]\n\nm, n = size(A)\n\nA vector is not quite the same thing as a matrix: it has only one dimension, not two. Separate its elements by commas or semicolons:\n\nx = [ 3, 3, 0, 1, 0 ]\nsize(x)\n\nFor some purposes, however, an n-vector in Julia is treated like having a column shape. Note the difference if we use spaces instead of commas inside the brackets:\n\ny = [ 3 3 0 1 0 ]\nsize(y)\n\nThis 1\\times 5 matrix is not equivalent to a vector.\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nIf x is simply a vector, then its transpose has a row shape.\n\nx'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              # start:stop\n\nz = 0:3:12           # start:step:stop\n\n(Ranges are not strictly considered vectors, but they behave identically in most circumstances.) Instead of specifying the step size, you can give the number of points in the range if you use range.\n\ns = range(-1, 1, 5)\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within square brackets.\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A[2, end-1]\n\nx[2]\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA[1:2, end-2:end]    # first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA[:, 1:2:end]        # all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nUse diagm to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diagm( [-1, 0, -5] )   # create a diagonal matrix\n\n@show size(A), size(B);\nBA = B * A     # matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nErrors are formally called exceptions in Julia.\n\nA * B    # throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    # same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x.^2\n\ntwo_to_x = 2 .^ x\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, expect scalars as operands. However, you can broadcast any function, including ones that you have defined, across a vector or array by using a special dot syntax.\n\nA dot added to the end of a function name means to apply the function elementwise to an array.\n\nshow(cos.(π*x))    # broadcast to a function\n\nRather than dotting multiple individual functions, you can use @. before an expression to broadcast everything within it.\n\nshow(@. cos(π*(x+1)^3))    # broadcast an entire expression\n\nMatrix operations\n\nIn MATLAB, every numerical value is treated like a matrix. A matrix with one row or one column is interpreted as a vector, and a 1\\times 1 matrix is interpreted as a scalar.\n\nSquare brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ \n    1       2      3             4      5; \n    50     40     30            20     10\n    pi sqrt(2) exp(1) (1+sqrt(5))/2 log(3) \n    ]\n\nm, n = size(A)\n\nx = [ 3, 3, 0, 1, 0 ];   % row vector\nsize(x)\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              % start:stop\n\nz = 0:3:12           % start:step:stop\n\nInstead of specifying the step size, you can give the number of points in the range if you use linspace.\n\ns = linspace(-1, 1, 5)    % row result\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within parentheses.\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A(2, end-1)\n\nx(2)\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA(1:2, end-2:end)    % first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA(:, 1:2:end)        % all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nUse diag to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diag([-1, 0, -5])   % create a diagonal matrix\n\nsize(A)\nsize(B)\n\nBA = B * A     % matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nErrors are formally called exceptions in Julia.\n\nA * B    % throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    % same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x .^ 2\n\ntwo_to_x = 2 .^ x\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, can operate elementwise on vectors and matrices.\n\ncos(pi * x)\n\nMatrix operations\n\nNote\n\nWhile NumPy does have distinct representations for matrices and 2D arrays, use of the explicit matrix class is officially discouraged. We follow this advice here and use arrays to represent both matrices and vectors. :::{index}\nsee: Python; size, Python; shape\n::: \n\nA vector is created using square brackets and commas to enclose and separate its entries.\n\nx = array([3, 3, 0, 1, 0 ])\nprint(x.shape)\n\nTo construct a matrix, you nest the brackets to create a “vector of vectors”. The inner vectors are the rows.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    [pi, sqrt(2), exp(1), (1+sqrt(5))/2, log(3)] \n    ])\n\nprint(A)\nprint(A.shape)\n\nIn this text, we treat all vectors as equivalent to matrices with a single column. That isn’t true in NumPy, because even an n \\times 1 array has two dimensions, unlike a vector.\n\narray([[3], [1], [2]]).shape\n\nYou can concatenate arrays with compatible dimensions using hstack and vstack.\n\nprint( hstack([A, A]) )\n\nprint( vstack([A, A]) )\n\nTransposing a matrix is done by appending .T to it.\n\nprint(A.T)\n\nFor matrices with complex values, we usually want instead the adjoint or hermitian, which is .conj().T.\n\nprint((x + 1j).conj().T)\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a vector with evenly spaced entries between two endpoints, you have two options.\n\nprint(arange(1, 7, 2))   # from 1 to 7 (not inclusive), step by 2\n\nprint(linspace(-1, 1, 5))   # from -1 to 1 (inclusive), with 5 total values\n\nThe practical difference between these is whether you want to specify the step size in arange or the number of points in linspace.\n\nAccessing an element is done by giving one (for a vector) or two index values in square brackets. In Python, indexing always starts with zero, not 1.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    linspace(-5, 5, 5) \n    ])\nx = array([3, 2, 0, 1, -1 ])\n\nprint(\"row 2, col 3 of A:\", A[1, 2])\nprint(\"first element of x:\", x[0])\n\nThe indices can be ranges, in which case a slice or block of the matrix is accessed. You build these using a colon in the form start:stop. However, the last value of this range is stop-1, not stop.\n\nprint(A[1:3, 0:2])    # rows 2 and 3, cols 1 and 2\n\nIf start or stop is omitted, the range extends to the first or last index.\n\nprint(x[1:])  # elements 2 through the end\n\nprint(A[:2, 0])  # first two rows in column 1\n\nNotice in the last case above that even when the slice is in the shape of a column vector, the result is just a vector with one dimension and neither row nor column shape.\n\nThere are more variations on the colon ranges. A negative value means to count from the end rather than the beginning. And a colon by itself means to include everything from the relevant dimension.\n\nprint(A[:-1, :])    # all rows up to the last, all columns\n\nFinally, start:stop:step means to step size or stride other than one. You can mix this with the other variations.\n\nprint(x[::2])  # all the odd indexes\n\nprint(A[:, ::-1])  # reverse the columns\n\nThe matrix and vector senses of addition, subtraction, and scalar multiplication and division are all handled by the usual symbols. Two matrices of the same size (what NumPy calls shape) are operated on elementwise.\n\nprint(A - 2 * ones([3, 5]))  # subtract two from each element\n\nIf one operand has a smaller number of dimensions than the other, Python tries to broadcast it in the “missing” dimension(s), and the operation proceeds if the resulting shapes are identical.\n\nprint(A - 2)    # subtract two from each element\n\nu = array([1, 2, 3, 4, 5])\nprint(A - u)    # repeat this row for every row of A\n\nv = array([1, 2, 3])\nprint(A - v)  # broadcasting this would be 3x3, so it's an error\n\nprint(A - v.reshape([3, 1]))    # broadcasts to each column of A ```{index} \nsee: Python; matrix multiplication, Python; \\@\n``` \n\nMatrix–matrix and matrix–vector products are computed using @ or matmul.\n\nB = diag([-1, 0, -5])    # create a diagonal 3x3\nprint(B @ A)    # matrix product\n\nAB is undefined for these matrix sizes.\n\nprint(A @ B)    # incompatible sizes\n\nThe multiplication operator * is reserved for elementwise multiplication. Both operands have to be the same size, after any potential broadcasts.\n\nprint(B * A)    # not the same size, so it's an error\n\nprint((A / 2) * A)    # elementwise\n\nTo raise to a power elementwise, use a double star. This will broadcast as well.\n\nprint(B)\nprint(B**3)\n\nprint(x)\nprint(2.0**x)\n\nDanger\n\nIf A is a matrix, A**2 is not the same as mathematically raising it to the power 2.\n\nMost of the mathematical functions, such as cos, sin, log, exp and sqrt, expecting scalars as operands will be broadcast to arrays.\n\nprint(cos(pi * x))","type":"content","url":"/matrices#vector-and-matrix-basics","position":7},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Row and column operations"},"type":"lvl2","url":"/matrices#row-and-column-operations","position":8},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Row and column operations"},"content":"A critical identity in matrix multiplication is  \\mathbf{A} \\mathbf{e}_j = \\mathbf{a}_j.\n\nMultiplication on the right by column j of the identity reproduces the jth column of a matrix.\n\nFurthermore, the expression  \\mathbf{A}\n  \\begin{bmatrix}\n    \\mathbf{e}_1 & \\mathbf{e}_3 & \\mathbf{e}_5\n  \\end{bmatrix}\n\nreproduces three columns. An equivalent expression in Julia would be A[:,1:2:5].\n\nWe can extend the same idea to rows by using the general identity (\\mathbf{R}\\mathbf{S})^T=\\mathbf{S}^T\\mathbf{R}^T. Let \\mathbf{B}=\\mathbf{A}^T have columns \\bigl[ \\mathbf{b}_j \\bigr], and note  (\\mathbf{b}_j)^T = (\\mathbf{B} \\mathbf{e}_j)^T = \\mathbf{e}_j^T \\mathbf{B}^T = \\mathbf{e}_j^T \\mathbf{A}.\n\nBut \\mathbf{e}_j^T is the jth row of \\mathbf{I}, and \\mathbf{b}_j^T is the transpose of the jth column of \\mathbf{B}, which is the jth row of \\mathbf{A} by \\mathbf{B}=\\mathbf{A}^T. Thus, multiplication on the left by row j of the identity extracts the jth row. Extracting the single element (i,j) from the matrix is, therefore, \\mathbf{e}_i^T \\mathbf{A} \\mathbf{e}_j.\n\nBeing able to extract specific rows and columns of a matrix via algebra makes it straightforward to do row- and column-oriented operations, such as linear combinations.\n\nSay that \\mathbf{A} has five columns. Adding twice the third column of \\mathbf{A} to its first column is done by\\mathbf{A}(\\mathbf{e}_1+2\\mathbf{e}_3).\n\nSuppose we want to do this operation “in place,” meaning replacing the first column of \\mathbf{A} with this value and leaving the other four columns of \\mathbf{A} alone. We can replace \\mathbf{A} with  \\mathbf{A}\n  \\begin{bmatrix}\n    \\mathbf{e}_1+2\\mathbf{e}_3 & \\mathbf{e}_2 & \\mathbf{e}_3 & \\mathbf{e}_4 & \\mathbf{e}_5\n  \\end{bmatrix}.\n\nThe Julia equivalent isA[:, 1] += 2A[:, 3]\n\nThe += operator means to increment the item on the left-hand side. There are similar interpretations for -= and *=.\n\nThe MATLAB equivalent isA(:, 1) = A(:, 1) + 2 * A(:, 3)\n\nThe NumPy equivalent isA[:, 0] += 2 * A[:, 2]\n\nThe += operator means to increment the item on the left-hand side. There are similar interpretations for -= and *=","type":"content","url":"/matrices#row-and-column-operations","position":9},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Exercises"},"type":"lvl2","url":"/matrices#exercises","position":10},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Exercises"},"content":"✍ Suppose\\mathbf{C} =\n    \\begin{bmatrix}\n      \\mathbf{I} & \\mathbf{A} \\\\ -\\mathbf{I} & \\mathbf{B}\n    \\end{bmatrix}.\n\nUsing block notation, find \\mathbf{C}^2 and \\mathbf{C}^3.\n\n⌨  Let\\mathbf{A} =\n\\begin{bmatrix}\n  2 & 1 & 1 & 0 \\\\ 0 & -1 & 4 & 1 \\\\ 2 & 2 & 0 & -2 \\\\ 1 & 3 & -1\n  & 5\n\\end{bmatrix},\n\\quad\n\\mathbf{B} =\n\\begin{bmatrix}\n  3 & -1 & 0 & 2 \\\\ 7 & 1 & 0 & 2\n\\end{bmatrix},\\mathbf{u} =\n\\begin{bmatrix}\n  2 \\\\ -1 \\\\ 3 \\\\ 1\n\\end{bmatrix},\n\\quad\n\\mathbf{v} =\n\\begin{bmatrix}\n  \\pi \\\\ e\n\\end{bmatrix}.\n\n(Do not round off the values in \\mathbf{v}—find them using native Julia commands.) For each expression below, use Julia to find the result, or explain why the result does not exist.\n\n(a) \\mathbf{A}\\mathbf{B},\\quad\n(b) \\mathbf{B} \\mathbf{A},\\quad\n(c) \\mathbf{v}^T \\mathbf{B},\\quad\n(d) \\mathbf{B} \\mathbf{u},\\quad\n(e) \\bigl[ \\, \\mathbf{u}\\:\\: \\mathbf{A}\\mathbf{u} \\:\\: \\mathbf{A}^2 \\mathbf{u} \\:\\: \\mathbf{A}^3 \\mathbf{u} \\bigr].\n\n⌨  Let\\mathbf{u} =\n\\begin{bmatrix}\n  1\\\\3\\\\5\\\\7\\\\9\\\\11\n\\end{bmatrix}, \\qquad\n\\mathbf{v} =\n\\begin{bmatrix}\n  -60 \\\\ -50 \\\\ -40 \\\\ -30 \\\\ -20 \\\\ -10\n\\end{bmatrix}.\n\nFind the inner products \\mathbf{u}^T\\mathbf{v} and \\mathbf{v}^T\\mathbf{u} and the outer products \\mathbf{u}\\mathbf{v}^T and \\mathbf{v}\\mathbf{u}^T.\n\n⌨ In Julia, give a demonstration of the identity (\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T for some arbitrarily chosen 3\\times 4 matrix \\mathbf{A} and 4\\times 2 matrix \\mathbf{B}.\n\n✍ Prove that if \\mathbf{A} and \\mathbf{B} are invertible, then (\\mathbf{A}\\mathbf{B})^{-1}=\\mathbf{B}^{-1}\\mathbf{A}^{-1}. (In producing the inverse, it follows that \\mathbf{A}\\mathbf{B} is invertible as well.)\n\n✍ Suppose \\mathbf{B} is an arbitrary 4\\times 3 matrix. In each part below a matrix \\mathbf{A} is described in terms of \\mathbf{B}. Express \\mathbf{A} as a product of \\mathbf{B} with one or more other matrices.\n\n(a) \\mathbf{A}\\in\\mathbb{R}^{4 \\times 1} is the result of adding the first column of \\mathbf{B} to -2 times the last column of \\mathbf{B}.\n\n(b) The rows of \\mathbf{A}\\in\\mathbb{R}^{4 \\times 3} are the rows of \\mathbf{B} in order 4,3,2,1.\n\n(c) The first column of \\mathbf{A}\\in\\mathbb{R}^{4 \\times 3} is 1 times the first column of \\mathbf{B}, the second column of \\mathbf{A} is 2 times the second column of \\mathbf{B},\nand the third column of \\mathbf{A} is 3 times the third column of \\mathbf{B}.\n\n(d) A is the scalar sum of all elements of \\mathbf{B}.\n\n(a) ✍ Prove that for real vectors \\mathbf{v} and \\mathbf{w} of the same length, the inner products \\mathbf{v}^T\\mathbf{w} and \\mathbf{w}^T\\mathbf{v} are equal.\n\n(b) ✍ Prove true, or give a counterexample for, the equivalent statement about outer products, \\mathbf{v}\\mathbf{w}^T and \\mathbf{w}\\mathbf{v}^T.\n\nThis aspect of our notation is slightly unusual. More frequently one would see the lowercase a_{24} in this context. We feel that our notation lends more consistency and clarity to expressions with mixed symbols, and it is more like how computer code is written.\n\nThe conjugate of a complex number is found by replacing all references to the imaginary unit i by -i.","type":"content","url":"/matrices#exercises","position":11},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-1","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The underlying theory for linear systems is covered in numerous linear algebra textbooks.  Some popular choices include those by Strang \n\nStrang (2016), Lay \n\nLay (2012), and Leon \n\nLeon (2006), but there are many other good choices.\n\nMore advanced texts specifically on numerical linear algebra include the classic texts by Trefethen and Bau \n\nTrefethen & III (1997) and Golub and Van Loan \n\nGolub & Van Loan (1996).\n\nNumerical analysis of the fundamental algorithms is emphasized in Higham \n\nHigham (2002); there are many interesting quotations there as well.  Here is a sample:\n\nMany years ago we made out of half a dozen transformers a simple and rather inaccurate machine for solving simultaneous equations—the solutions being represented as flux in the cores of the transformers.  During the course of our experiments we set the machine to solve the equations—\\begin{split}\n& X+Y+Z=1 \\\\\n& X+Y+Z=2 \\\\\n& X+Y+Z=3\n\\end{split}\n\nThe machine reacted sharply—it blew the main fuse and put all the lights out. (B. V. Bowden, The Organization of a Typical Machine, 1953)\n\nThe reader may find historical information on numerical linear algebra of interest at the SIAM website, \n\nhttp://​history​.siam​.org.  The materials include presentations, oral histories, articles and links on a wide range of topics in numerical analysis and scientific computing including numerical linear algebra.","type":"content","url":"/next-1","position":1},{"hierarchy":{"lvl1":"Vector and matrix norms"},"type":"lvl1","url":"/norms","position":0},{"hierarchy":{"lvl1":"Vector and matrix norms"},"content":"The manipulations on matrices and vectors so far in this chapter have been algebraic, much like those in an introductory linear algebra course. In order to progress to the analysis of the algorithms we have introduced, we need a way to measure the size of vectors and matrices—size in the sense of magnitude or distance, not the number of rows and columns.","type":"content","url":"/norms","position":1},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Vector norms"},"type":"lvl2","url":"/norms#vector-norms","position":2},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Vector norms"},"content":"For vectors, we use a norm \\| \\cdot \\|, which is a function from \\real^n to \\real with the following properties for all n-vectors \\mathbf{x},\\mathbf{y} and scalars α:\\begin{align*}\n\n\\norm{\\mathbf{x}} &\\ge 0, \\\\\n\\norm{\\mathbf{x}} &=0 \\;\\Leftrightarrow \\; \\mathbf{x}=\\boldsymbol{0}, \\\\\n\\norm{\\alpha \\mathbf{x}} &= \\abs{\\alpha}\\, \\norm{\\mathbf{x}}, \\\\\n\\norm{\\mathbf{x}+\\mathbf{y}} & \\le \\norm{\\mathbf{x}} + \\norm{\\mathbf{y}}.\n\\end{align*}\n\nThe last of these properties is known as the triangle inequality. It is natural to interpret \\| \\mathbf{x} \\|=\\| \\mathbf{x}-\\boldsymbol{0} \\| as the distance from \\mathbf{x} to the origin and \\| \\mathbf{x}-\\mathbf{y} \\| as the distance from \\mathbf{x} to \\mathbf{y}. We will be using only the three most important vector norms, defined as follows.\n\nCommon vector norms\n\n2-norm: \\quad \\twonorm{\\mathbf{x}} = \\left( \\displaystyle \\sum_{i=1}^n |x_i|^2 \\right)^{\\frac{1}{2}} = \\sqrt{\\rule[1mm]{0pt}{0.75em}\\mathbf{x}^T \\mathbf{x}}\n\n∞-norm or max-norm:  \\quad \\infnorm{ \\mathbf{x}} = \\displaystyle \\max_{i=1,\\dots,n} |x_i|\n\n1-norm: \\quad \\onenorm{\\mathbf{x}} = \\displaystyle \\sum_{i=1}^n |x_i| \n\nThe 2-norm corresponds to ordinary Euclidean distance.\n\nIn any norm, we refer to a vector \\mathbf{x} satisfying \\| \\mathbf{x} \\|=1 as a unit vector. For any nonzero vector \\mathbf{v} we can find a unit vector through the normalization \\mathbf{x}=\\mathbf{v}/\\|\\mathbf{v}\\|. Thus, we can interpret  \\mathbf{v} = \\| \\mathbf{v} \\| \\,\\cdot\\, \\frac{\\mathbf{v}}{\\| \\mathbf{v} \\|}\n\nas writing a nonzero vector \\mathbf{v} in magnitude–direction form.\n\nGiven the vector \\mathbf{x}= \\bigl[ 2 ,\\, -3 ,\\, 1 ,\\, -1 \\bigr]^T, we have\\begin{align*}\n    \\| \\mathbf{x} \\|_2 &= \\sqrt{ 4 + 9 + 1 + 1 } = \\sqrt{15}, \\\\[1ex]\n    \\| \\mathbf{x} \\|_\\infty &= \\max\\{ 2,3,1,1 \\} = 3,\\\\[1ex]\n    \\| \\mathbf{x} \\|_1 &= 2 + 3 + 1 + 1 = 7.\n\\end{align*}\n\nVector norms\n\nIn Julia the LinearAlgebra package has a norm function for vector norms.\n\nx = [2, -3, 1, -1]\ntwonorm = norm(x)         # or norm(x,2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nThere is also a normalize function that divides a vector by its norm, making it a unit vector.\n\nnormalize(x, Inf)\n\nVector norms\n\nx = [2; -3; 1; -1];\ntwonorm = norm(x)    % or norm(x, 2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nVector norms\n\nThe norm function from numpy.linalg computes vector norms.\n\nfrom numpy.linalg import norm\nx = array([2, -3, 1, -1])\nprint(norm(x))       # 2-norm by default\n\nprint(norm(x, inf))\n\nprint(norm(x, 1))\n\nNote\n\nMost of the time, when just \\| \\mathbf{x} \\| is written, the 2-norm is implied. However, in this section we use it to mean a generic, unspecified vector norm.\n\nWe say that a sequence of vectors \\mathbf{x}_1,\\mathbf{x}_2,\\ldots converges to \\mathbf{x} if  \\lim_{k\\rightarrow\\infty} \\norm{\\mathbf{x}_k - \\mathbf{x}} = 0.\n\nBy definition, a sequence is convergent in the infinity norm if and only if it converges componentwise. The same is true for a convergent sequence in any norm.\n\nNorm equivalence\n\nIn a finite-dimensional space, convergence in any norm implies convergence in all norms.","type":"content","url":"/norms#vector-norms","position":3},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Matrix norms"},"type":"lvl2","url":"/norms#matrix-norms","position":4},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Matrix norms"},"content":"Although we view matrices as two-dimensional, we can also interpret them as vectors: simply stack the columns on top of one another. Hence we can define matrix norms via vector norms. This is sometimes done with the vector 2-norm and leads to the matrix Frobenius norm:\\| \\mathbf{A} \\|_F = \\left( \\sum_{i,j} |A_{ij}|^2 \\right)^{1/2}. This is the norm computed by the `norm` function in Julia. \n\nHowever, it often proves to be more useful to define matrix norms differently.\n\nInduced matrix norm\n\nGiven a vector norm \\| \\cdot \\|_p, we define an induced matrix norm for any m\\times n matrix \\mathbf{A} as\\| \\mathbf{A} \\|_{p} = \\max_{\\| \\mathbf{x} \\|_p=1} \\| \\mathbf{A}\\mathbf{x} \\|_p =\n\\max_{\\mathbf{x}\\neq \\boldsymbol{0}} \\frac{\\| \\mathbf{A}\\mathbf{x} \\|_p}{\\| \\mathbf{x} \\|_p}.\n\nThe last equality above follows from linearity (as shown in \n\nExercise 5).  It is derived from the interpretation of a matrix as a linear operator between \\real^n and \\real^m. Thus in the 2-norm, for instance,\\| \\mathbf{A} \\|_2 = \\max_{\\| \\mathbf{x} \\|_2=1} \\| \\mathbf{A}\\mathbf{x} \\|_2.\n\nFor the rest of this section we will continue to omit subscripts when we want to refer to an unspecified induced norm; after this section, an unsubscripted norm is understood to be the 2-norm.\n\nThe definition of an induced matrix norm may seem oddly complicated. However, there are some key properties that follow directly from the definition.\n\nNorm inequalities\n\nLet \\| \\cdot \\| designate a matrix norm and the vector norm that induced it. Then for all matrices and vectors of compatible sizes,\\| \\mathbf{A}\\mathbf{x} \\| \\le \\| \\mathbf{A} \\|\\cdot \\| \\mathbf{x} \\|.\n\nFor all matrices of compatible sizes,\\| \\mathbf{A}\\mathbf{B} \\| \\le \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\|.\n\nFor a square matrix \\mathbf{A},\\| \\mathbf{A}^k \\| \\le \\| \\mathbf{A} \\|^k \\text{ for any integer $k\\ge 0$.}\n\nThe first result is trivial if \\mathbf{x}=\\boldsymbol{0}; otherwise,\\frac{ \\| \\mathbf{A}\\mathbf{x} \\| }{\\| \\mathbf{x} \\|} \\le\n\\max_{\\mathbf{x}\\neq \\boldsymbol{0}}  \\frac{\\| \\mathbf{A}\\mathbf{x} \\|}{\\| \\mathbf{x} \\|} = \\| \\mathbf{A} \\|.\n\nInequality \n\n(2.7.9) then follows because\\| \\mathbf{A}\\mathbf{B}\\mathbf{x} \\| =\\| \\mathbf{A}(\\mathbf{B}\\mathbf{x}) \\|\\le \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B}\\mathbf{x} \\| \\le\n\\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\|\\cdot\\| \\mathbf{x} \\|,\n\nand then\\| \\mathbf{A}\\mathbf{B} \\| = \\max_{\\mathbf{x}\\neq \\boldsymbol{0}} \\frac{\\| \\mathbf{A}\\mathbf{B}\\mathbf{x} \\|}{\\| \\mathbf{x} \\|} \\le\n\\max_{\\mathbf{x}\\neq \\boldsymbol{0}} \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\| = \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\|.\n\nFinally,  \n\n(2.7.10) results from repeated application of \n\n(2.7.9).\n\nOne can interpret the definition of an induced norm geometrically.  Each vector \\mathbf{x} on the unit “sphere” (as defined by the chosen vector norm) is mapped to its image \\mathbf{A}\\mathbf{x}, and the norm of \\mathbf{A} is the radius of the smallest “sphere” that encloses all such images.\n\nIn addition, two of the vector norms we have encountered lead to equivalent formulas that are easy to compute from the matrix elements.\n\nMatrix ∞-norm and 1-norm\\| \\mathbf{A} \\|_\\infty = \\max_{1\\le \\,i \\,\\le n} \\sum_{j=1}^n |A_{ij}|,\\| \\mathbf{A} \\|_1 = \\max_{1\\le \\,j\\, \\le n} \\sum_{i=1}^n |A_{ij}|.\n\nA mnemonic for these is that the ∞ symbol extends horizontally while the 1 character extends vertically, each indicating the direction of the summation in its formula. Also, both formulas give the same result for m\\times 1 matrices as the vector norm. In both cases you must take absolute values of the matrix elements first.\n\nMatrix norms\n\nA = [ 2 0; 1 -1 ]\n\nIn Julia, one uses norm for vector norms and for the Frobenius norm of a matrix, which is like stacking the matrix into a single vector before taking the 2-norm.\n\nFronorm = norm(A)\n\nMost of the time we want to use opnorm, which is an induced matrix norm. The default is the 2-norm.\n\ntwonorm = opnorm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = opnorm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nUse sum to sum along a dimension of a matrix. You can also sum over the entire matrix by omitting the dims argument.\n\nThe maximum and minimum functions also work along one dimension or over an entire matrix. To get both values at once, use extrema.\n\n# Sum down the rows (1st matrix dimension):\nmaximum( sum(abs.(A), dims=1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = opnorm(A, Inf)\n\n # Sum across columns (2nd matrix dimension):\nmaximum( sum(abs.(A), dims=2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nYou can use functions as values, e.g., as elements of a vector.\n\n# Construct 601 unit column vectors.\nθ = 2π * (0:1/600:1)   # type \\theta then Tab\nx = [ fun(t) for fun in [cos, sin], t in θ ];\n\nTo create an array of plots, start with a plot that has a layout argument, then do subsequent plot! calls with a subplot argument.\n\nplot(aspect_ratio=1, layout=(1, 2),\n    xlabel=L\"x_1\",  ylabel=L\"x_2\")\nplot!(x[1, :], x[2, :], subplot=1, title=\"Unit circle\")\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse.\n\nplot!(Ax[1, :], Ax[2, :], \n    subplot=2, title=\"Image under x → Ax\")\n\nThat ellipse just touches the circle of radius \\|\\mathbf{A}\\|_2.\n\nplot!(twonorm*x[1, :], twonorm*x[2, :], subplot=2, l=:dash)\n\nMatrix norms\n\nA = [ 2 0; 1 -1 ]\n\nThe default matrix norm is the 2-norm.\n\ntwonorm = norm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = norm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nUse sum to sum along a dimension of a matrix. The max and min functions also work along one dimension.\n\n% Sum down the rows (1st matrix dimension):\nmax( sum(abs(A), 1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = norm(A, Inf)\n\n% Sum across columns (2nd matrix dimension):\nmax( sum(abs(A), 2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nYou can use functions as values, e.g., as elements of a vector.\n\ntheta = linspace(0, 2*pi, 601);\nx = [ cos(theta); sin(theta) ];    % 601 unit column vectors\nclf\nsubplot(1, 2, 1)\nplot(x(1, :), x(2, :)), axis equal\ntitle('Unit circle in 2-norm')\nxlabel('x_1')\nylabel('x_2')\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2:\n\nsubplot(1,2,2), plot(Ax(1,:), Ax(2,:)), axis equal\nhold on, plot(twonorm * x(1,:), twonorm * x(2,:), '--')\ntitle('Image of Ax, with ||A||')\nxlabel('x_1')\nylabel('x_2')\n\nMatrix norms\n\nfrom numpy.linalg import norm\nA = array([ [2, 0], [1, -1] ])\n\nThe default matrix norm is not the 2-norm. Instead, you must provide the 2 explicitly.\n\nprint(norm(A, 2))\n\nYou can get the 1-norm as well.\n\nprint(norm(A, 1))\n\nThe 1-norm is equivalent to\n\nprint(max( sum(abs(A), axis=0)) )  # sum down the rows\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\nprint(norm(A, inf))\n\nprint(max( sum(abs(A), axis=1)) )  # sum across columns\n\nHere we illustrate the geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\ntheta = linspace(0, 2*pi, 601)\nx = vstack([cos(theta), sin(theta)])  # 601 unit columns\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x simply by using a matrix multiplication.\n\ny = A @ x\n\nWe plot the unit circle on the left and the image of all mapped vectors on the right:\n\nsubplot(1,2,1)\nplot(x[0, :], x[1, :])\naxis(\"equal\")\ntitle(\"Unit circle\")\nxlabel(\"$x_1$\")\nylabel(\"$x_2$\")\n\nsubplot(1,2,2)\nplot(y[0, :], y[1, :])\nplot(norm(A, 2) * x[0, :], norm(A,2) * x[1, :],\"--\")\naxis(\"equal\")\ntitle(\"Image under map\")\nxlabel(\"$y_1$\")\nylabel(\"$y_2$\");\n\nAs seen on the right-side plot, the image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2.\n\nThe geometric interpretation of the matrix 2-norm shown in \n\nDemo 2.7.2, as the radius of the smallest circle (or sphere or hypersphere in higher dimensions) containing the images of all unit vectors, is not a practical means of computing the norm. Nor is there a simple formula like \n\n(2.7.14) or \n\n(2.7.15) for it. The computation of the matrix 2-norm is discussed further in Chapter 7.","type":"content","url":"/norms#matrix-norms","position":5},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Exercises"},"type":"lvl2","url":"/norms#exercises","position":6},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Exercises"},"content":"✍ Why is the vector 1-norm also called the taxicab norm?\n\n✍ (a) Draw the unit “circle” in the ∞-norm, i.e., the set of all vectors \\mathbf{x}\\in\\real^2 such that \\| \\mathbf{x} \\|_\\infty=1.\n\n(b) Draw the unit “circle” in the 1-norm.\n\n✍ Prove that for all vectors \\mathbf{x}\\in\\real^n,\n\n(a) \\| \\mathbf{x} \\|_\\infty \\le \\| \\mathbf{x} \\|_2; \\qquad\n(b) \\| \\mathbf{x} \\|_2 \\le \\| \\mathbf{x} \\|_1.\n\n✍ Prove that for any vectors \\mathbf{x}, \\mathbf{y} in \\real^n, |\\mathbf{x}^T\\mathbf{y}| \\le \\| \\mathbf{x} \\|_1\\| \\mathbf{y} \\|_\\infty.\n\n✍ Prove using \n\nDefinition 2.7.2 that for any induced matrix norm, matrix \\mathbf{A}, and scalar c, \\| c\\mathbf{A} \\| = |c|\\cdot \\| \\mathbf{A} \\|.\n\n✍ Let \\mathbf{A} =\n \\displaystyle \\begin{bmatrix}\n   -1 & 1 \\\\ 2 & 2\n \\end{bmatrix}.\n\n(a) Find all vectors satisfying \\|\\mathbf{x}\\|_\\infty=1 and \\| \\mathbf{A}\\mathbf{x} \\|_\\infty=\\| \\mathbf{A} \\|_\\infty.\n\n(b) Find a vector satisfying \\|\\mathbf{x}\\|_1=1 and \\| \\mathbf{A}\\mathbf{x} \\|_1=\\| \\mathbf{A} \\|_1.\n\n(c) Find a vector satisfying \\|\\mathbf{x}\\|_2=1 such that \\| \\mathbf{A}\\mathbf{x} \\|_2=\\| \\mathbf{A} \\|_2. (Hint: A unit two-dimensional vector is a function only of its angle with the x_1-axis. Use the definition of \\|\\mathbf{A}\\|_2 as the maximum of \\|\\mathbf{A}\\mathbf{x}\\|_2, which is a also a function of the angle.)\n\n✍ Prove the equivalence of the two formulas for a matrix norm in \n\n(2.7.6).\n\n✍ Prove that for any induced matrix norm and nonsingular matrix \\mathbf{A}, \\| \\mathbf{A}^{-1} \\| \\ge (\\| \\mathbf{A} \\|)^{-1}. (Hint: Apply \n\nTheorem 2.7.2.)\n\n✍ (a) Prove that for any \\mathbf{v}\\in \\real^n,\\| \\mathbf{v} \\|_p \\ge \\max_{i=1,\\ldots,n} |v_i|,\n\nwhere p=1, 2, or ∞.\n\n(b) Prove that for any \\mathbf{A}\\in\\real^{n \\times n},\\| \\mathbf{A} \\|_p \\ge \\max_{i,j=1,\\ldots,n} |A_{ij}|,\n\nwhere p=1, 2, or ∞. (Hint: For p=2, rearrange \n\n(2.7.8) for a well-chosen particular value of \\mathbf{x}.)\n\n✍ Prove using \n\nDefinition 2.7.2 that if \\mathbf{D} is a diagonal matrix, then \\|\\mathbf{D}\\|_2 = \\max_{i} |D_{ii}|. You may assume the matrix is real and square, but that does not affect the result or the proof in any significant way. (Hint: Let M=\\max_{i} |D_{ii}|. Proceed in two stages, showing that \\|\\mathbf{D}\\|_2\\ge M and separately that \\|\\mathbf{D}\\|_2\\le M.)\n\n✍ Suppose that \\mathbf{A} is {n\\times n} and that \\| \\mathbf{A} \\|<1 in some induced matrix norm.\n\n(a) Show that (\\mathbf{I}-\\mathbf{A}) is nonsingular. (Hint: Use the definition of an induced matrix norm to show that if (\\mathbf{I}-\\mathbf{A})\\mathbf{x}=\\boldsymbol{0} for all nonzero \\mathbf{x}, then \\| \\mathbf{A} \\|\\ge 1.)\n\n(b) Show that \\lim_{m\\rightarrow \\infty} \\mathbf{A}^m = \\boldsymbol{0}. (For matrices as with vectors, we say \\mathbf{B}_m \\rightarrow \\mathbf{L} if \\| \\mathbf{B}_m-\\mathbf{L} \\| \\rightarrow 0.)\n\n(c) Use (a) and (b) to show that we may obtain the geometric series(\\mathbf{I}-\\mathbf{A})^{-1} = \\sum_{k=0}^\\infty \\mathbf{A}^k.\n\n(Hint: Start with \\left(\\sum_{k=0}^m \\mathbf{A}^k\\right)(\\mathbf{I}-\\mathbf{A}) and take the limit.)\n\nThe same statements work for vectors with complex entries, with complex modulus in place of absolute values.\n\nColumn stacking is actually how matrices are stored in memory within Julia and is known as column-major order. MATLAB and FORTRAN also use column-major order, while C and Python use row-major order, in which the rows are stacked.","type":"content","url":"/norms#exercises","position":7},{"hierarchy":{"lvl1":"Linear systems of equations"},"type":"lvl1","url":"/overview-1","position":0},{"hierarchy":{"lvl1":"Linear systems of equations"},"content":"It’s all a lot of simple tricks and nonsense.\n\nHan Solo, Star Wars: A New Hope\n\nOne of the most frequently encountered tasks in scientific computation is the solution of the linear system of equations \\mathbf{A} \\mathbf{x}=\\mathbf{b} for a given square matrix \\mathbf{A} and vector \\mathbf{b}.  This problem can be solved in a finite number of steps, using an algorithm equivalent to Gaussian elimination. Describing the algorithm is mostly an exercise in organizing some linear algebra.\n\nAnalyzing the algorithm requires new tools. Because the computations will take place in floating point, we must first discuss a system for measuring the “size” of a perturbation to a vector or matrix data. Once that is understood, we find that the conditioning of the square linear system problem is quite straightforward to describe. Finally, we will see that the algorithm may change when certain things are known about the matrix \\mathbf{A}.","type":"content","url":"/overview-1","position":1},{"hierarchy":{"lvl1":"Row pivoting"},"type":"lvl1","url":"/pivoting","position":0},{"hierarchy":{"lvl1":"Row pivoting"},"content":"As mentioned in \n\nLU factorization, the \\mathbf{A}=\\mathbf{L}\\mathbf{U} factorization is not stable for every nonsingular \\mathbf{A}. Indeed, the factorization does not always even exist.\n\nFailure of naive LU factorization\n\nHere is a previously encountered matrix that factors well.\n\nA = [2 0 4 3 ; -4 5 -7 -10 ; 1 15 2 -4.5 ; -2 0 2 -13];\nL, U = FNC.lufact(A)\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[2, 4], :] = A[[4, 2], :]  \nL, U = FNC.lufact(A)\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[1, :] = A[1, :]\nL[:, 1] = A[:, 1] / U[1, 1]\nA -= L[:, 1] * U[1, :]'\n\nThe next step is U[2, :] = A[2, :], which is also OK. But then we are supposed to divide by U[2, 2], which is zero. The algorithm cannot continue.\n\nFailure of naive LU factorization\n\nHere is a previously encountered matrix that factors well.\n\nA = [\n    2 0 4 3\n    -4 5 -7 -10\n    1 15 2 -4.5\n    -2 0 2 -13\n    ];\n[L, U] = lufact(A);\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA([2, 4], :) = A([4, 2], :);    % swap rows 2 and 4\n[L, U] = lufact(A);\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU(1, :) = A(1, :);\nL(:, 1) = A(:, 1) / U(1, 1)\nA = A - L(:, 1) * U(1, :)\n\nThe next step is U(2, :) = A(2, :), which is also OK. But then we are supposed to divide by U(2, 2), which is zero. The algorithm cannot continue.\n\nFailure of naive LU factorization\n\nHere is a previously encountered matrix that factors well.\n\nA = array([\n    [2, 0, 4, 3],\n    [-4, 5, -7, -10],\n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nL, U = FNC.lufact(A)\nprint(L)\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[1, 3], :] = A[[3, 1], :]  \nL, U = FNC.lufact(A)\nprint(L)\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[0, :] = A[0, :]\nL[:, 0] = A[:, 0] / U[0, 0]\nA -= outer(L[:, 0],  U[0, :])\nprint(A)\n\nThe next step is U[1, :] = A[1, :], which is also OK. But then we are supposed to divide by U[1, 1], which is zero. The algorithm cannot continue.\n\nIn \n\nLU factorization we remarked that LU factorization is equivalent to Gaussian elimination with no row swaps. However, those swaps are necessary in situations like those encountered in \n\nDemo 2.6.1, in order to avoid division by zero. We will find a modification of the outer product procedure that allows us to do the same thing.","type":"content","url":"/pivoting","position":1},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Choosing a pivot"},"type":"lvl2","url":"/pivoting#choosing-a-pivot","position":2},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Choosing a pivot"},"content":"The diagonal element of \\mathbf{U} that appears in the denominator of line 17 of \n\nFunction 2.4.1 is called the pivot element of its column. In order to avoid a zero pivot, we will use the largest available element in the column we are working on as the pivot. This technique is known as row pivoting.\n\nRow pivoting\n\nWhen performing elimination in column j, choose as the pivot the element in column j that is largest in absolute value. (In case of ties, choose the lowest row index.)\n\nRow pivoting in LU factorization\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA₁ = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs.(A₁[:, 1]) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = zeros(4,4),zeros(4,4)\nU[1, :] = A₁[i, :]\nL[:, 1] = A₁[:, 1] / U[1, 1]\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n@show i = argmax( abs.(A₂[:, 2]) ) \nU[2, :] = A₂[i, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n@show i = argmax( abs.(A₃[:, 3]) ) \nU[3, :] = A₃[i, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\n@show i = argmax( abs.(A₄[:, 4]) ) \nU[4, :] = A₄[i, :]\nL[:, 4] = A₄[:, 4] / U[4, 4];\n\nWe do have a factorization of the original matrix:\n\nA₁ - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nRow pivoting in LU factorization\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nThe second output of max returns the location of the largest element of a vector. The ~ symbol is used to ignore the value of the first output.\n\n[~, i] = max( abs(A_1(:, 1)) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL = zeros(4, 4);\nU = zeros(4, 4);\nU(1, :) = A_1(i, :);\nL(:, 1) = A_1(:, 1) / U(1, 1);\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n[~, i] = max( abs(A_2(:, 2)) )\nU(2, :) = A_2(i, :);\nL(:, 2) = A_2(:, 2) / U(2, 2);\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n[~, i] = max( abs(A_3(:, 3)) ) \nU(3, :) = A_3(i, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\n[~, i] = max( abs(A_4(:, 4)) ) \nU(4, :) = A_4(i, :);\nL(:, 4) = A_4(:, 4) / U(4, 4);\n\nWe do have a factorization of the original matrix:\n\nA_1 - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nRow pivoting in LU factorization\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs(A_1[:, 0]) )\nprint(i)\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = eye(4), zeros((4, 4))\nU[0, :] = A_1[i, :]\nL[:, 0] = A_1[:, 0] / U[0, 0]\nA_2 = A_1 - outer(L[:, 0], U[0, :])\nprint(A_2)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\ni = argmax( abs(A_2[:, 1]) ) \nprint(f\"new pivot row is {i}\")\nU[1, :] = A_2[i, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nA_3 = A_2 - outer(L[:, 1], U[1, :])\nprint(A_3)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\ni = argmax( abs(A_3[:, 2]) ) \nprint(f\"new pivot row is {i}\")\nU[2, :] = A_3[i, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\nprint(A_4)\n\ni = argmax( abs(A_4[:, 3]) ) \nprint(f\"new pivot row is {i}\")\nU[3, :] = A_4[i, :]\nL[:, 3] = A_4[:, 3] / U[3, 3];\n\nWe do have a factorization of the original matrix:\n\nA_1 - L @ U\n\nAnd \\mathbf{U} has the required structure:\n\nprint(U)\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nprint(L)\n\nWe will return to the loss of triangularity in \\mathbf{L} momentarily. First, though, there is a question left to answer: what if at some stage, all the elements of the targeted column are zero, i.e., there are no available pivots? Fortunately that loose end ties up nicely, although a proof is a bit beyond our scope here.\n\nRow pivoting\n\nThe row-pivoted LU factorization runs to completion if and only if the original matrix is invertible.\n\nA linear system with a singular matrix has either no solution or infinitely many solutions. Either way, a technique other than LU factorization is needed to handle it.","type":"content","url":"/pivoting#choosing-a-pivot","position":3},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Permutations"},"type":"lvl2","url":"/pivoting#permutations","position":4},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Permutations"},"content":"Even though the resulting \\mathbf{L} in \n\nDemo 2.6.2 is no longer of unit lower triangular form, it is close. In fact, all that is needed is to reverse the order of its rows.\n\nIn principle, if the permutation of rows implied by the pivot locations is applied all at once to the original \\mathbf{A}, no further pivoting is needed. In practice, this permutation cannot be determined immediately from the original \\mathbf{A}; the only way to find it is to run the algorithm. Having obtained it at the end, though, we can use it to state a simple relationship.\n\nPLU factorization\n\nGiven n\\times n matrix \\mathbf{A}, the PLU factorization is a unit lower triangular \\mathbf{L}, an upper triangular \\mathbf{U}, and a permutation i_1,\\ldots,i_n of the integers 1,\\ldots,n, such that\\tilde{\\mathbf{A}} = \\mathbf{L}\\mathbf{U},\n\nwhere rows 1,\\ldots,n of \\tilde{\\mathbf{A}} are rows i_1,\\ldots,i_n of \\mathbf{A}.\n\nFunction 2.6.2 shows our implementation of PLU factorization.\n\nplufact\n\nLU factorization with partial pivoting\n\n\"\"\"\n    plufact(A)\n\nCompute the PLU factorization of square matrix `A`, returning the\ntriangular factors and a row permutation vector.\n\"\"\"\nfunction plufact(A)\n    n = size(A,1)\n    L = zeros(n,n)\n    U = zeros(n,n)\n    p = fill(0,n)\n    Aₖ = float(copy(A))\n\n    # Reduction by outer products\n    for k in 1:n-1\n        p[k] = argmax(abs.(Aₖ[:,k]))\n        U[k,:] = Aₖ[p[k],:]\n        L[:,k] = Aₖ[:,k]/U[k,k]\n        Aₖ -= L[:,k]*U[k,:]'\n    end\n    p[n] = argmax(abs.(Aₖ[:,n]))\n    U[n,n] = Aₖ[p[n],n]\n    L[:,n] = Aₖ[:,n]/U[n,n]\n    return LowerTriangular(L[p,:]),U,p\nend\n\nLU factorization with partial pivoting\n\n\"\"\"\n    plufact(A)\n\nCompute the PLU factorization of square matrix `A`, returning the\ntriangular factors and a row permutation vector.\n\"\"\"\nfunction plufact(A)\n    n = size(A,1)\n    L = zeros(n,n)\n    U = zeros(n,n)\n    p = fill(0,n)\n    Aₖ = float(copy(A))\n\n    # Reduction by outer products\n    for k in 1:n-1\n        p[k] = argmax(abs.(Aₖ[:,k]))\n        U[k,:] = Aₖ[p[k],:]\n        L[:,k] = Aₖ[:,k]/U[k,k]\n        Aₖ -= L[:,k]*U[k,:]'\n    end\n    p[n] = argmax(abs.(Aₖ[:,n]))\n    U[n,n] = Aₖ[p[n],n]\n    L[:,n] = Aₖ[:,n]/U[n,n]\n    return LowerTriangular(L[p,:]),U,p\nend\n\nLU factorization with partial pivoting\n\ndef plufact(A):\n    \"\"\"\n        plufact(A)\n\n    Compute the PLU factorization of square matrix `A`, returning the\n    triangular factors and a row permutation vector.\n    \"\"\"\n    n = A.shape[0]\n    L = np.zeros((n, n))\n    U = np.zeros((n, n))\n    p = np.zeros(n, dtype=int)\n    A_k = np.copy(A)\n\n    # Reduction by np.outer products\n    for k in range(n):\n        p[k] = np.argmax(abs(A_k[:, k]))\n        U[k, :] = A_k[p[k], :]\n        L[:, k] = A_k[:, k] / U[k, k]\n        if k < n-1:\n            A_k -= np.outer(L[:, k], U[k, :])\n    return L[p, :], U, p\n\nIdeally, the PLU factorization takes \\sim \\frac{2}{3}n^3 flops asymptotically, just like LU without pivoting. The implementation in \n\nFunction 2.6.2 does not achieve this optimal flop count, however. Like \n\nFunction 2.4.1, it does unnecessary operations on structurally known zeros for the sake of being easier to understand.","type":"content","url":"/pivoting#permutations","position":5},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Linear systems"},"type":"lvl2","url":"/pivoting#linear-systems","position":6},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Linear systems"},"content":"The output of \n\nFunction 2.6.2 is a factorization of a row-permuted \\mathbf{A}. Therefore, given a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, we have to permute \\mathbf{b} the same way before applying forward and backward substitution. This is equivalent to changing the order of the equations in a linear system, which does not affect its solution.\n\nPLU factorization for solving linear systems\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = rand(1:20, 4, 4)\nL, U, p = FNC.plufact(A)\nA[p,:] - L * U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4)\nz = FNC.forwardsub(L,b[p])\nx = FNC.backsub(U,z)\n\nA residual check is successful:\n\nb - A*x\n\nPLU factorization for solving linear systems\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = randi(20, 4, 4);\n[L, U, p] = plufact(A);\nA(p, :) - L * U    % should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4, 1);\nz = forwardsub(L, b(p));\nx = backsub(U, z)\n\nA residual check is successful:\n\nb - A*x\n\nPLU factorization for solving linear systems\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = random.randn(4, 4)\nL, U, p = FNC.plufact(A)\nA[p, :] - L @ U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = random.randn(4)\nz = FNC.forwardsub(L, b[p])\nx = FNC.backsub(U, z)\n\nA residual check is successful:\n\nb - A @ x\n\nThe lu function from the built-in package LinearAlgebra returns the same three outputs as \n\nFunction 2.6.2. If you only request one output, it will be a factorization object that can be used with a backslash. This is useful when you want to solve with multiple versions of \\mathbf{b} but do the factorization only once.\n\nBuilt-in PLU factorization\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500)   # 500x500 with normal random entries\nA \\ rand(500)          # force compilation\n@elapsed for k=1:50; A \\ rand(500); end\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\nfactored = lu(A)     # store factorization result\nfactored \\ rand(500)   # force compilation\n@elapsed for k=1:50; factored \\ rand(500); end\n\nBuilt-in PLU factorization\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500);    % 500x500 with normal random entries\ntic; for k=1:50; A \\ rand(500, 1); end; toc\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\n[L, U, p] = lu(A, 'vector');    % keep factorization result\ntic\nfor k=1:50\n    b = rand(500, 1);\n    U \\ (L \\ b(p));\nend\ntoc\n\nBuilt-in PLU factorization\n\nIn linalg.solve, the matrix A is PLU-factored, followed by two triangular solves. If we want to do those steps seamlessly, we can use the lu_factor and lu_solve from scipy.linalg.\n\nfrom scipy.linalg import lu_factor, lu_solve\nA = random.randn(500, 500) \nb = ones(500)  \nLU, perm = lu_factor(A)\nx = lu_solve((LU, perm), b)\n\nWhy would we ever bother with this? In \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per matrix, but solve with multiple right-hand sides.\n\nstart = timer()\nfor k in range(50): linalg.solve(A, random.rand(500))\nprint(f\"elapsed time for 50 full solves: {timer() - start}\")\n\nstart = timer()\nLU, perm = lu_factor(A)\nfor k in range(50): lu_solve((LU, perm), random.rand(500))\nprint(f\"elapsed time for 50 shortcut solves: {timer() - start}\")","type":"content","url":"/pivoting#linear-systems","position":7},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Stability"},"type":"lvl2","url":"/pivoting#stability","position":8},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Stability"},"content":"There is one detail of the row pivoting algorithm that might seem arbitrary: why choose the pivot of largest magnitude in a column, rather than, say, the uppermost nonzero in the column? The answer is numerical stability.\n\nLet\\mathbf{A} =\n  \\begin{bmatrix}\n    -\\epsilon & 1 \\\\ 1 & -1\n  \\end{bmatrix}.\n\nIf \\epsilon=0, LU factorization without pivoting fails for \\mathbf{A}. But if \\epsilon\\neq 0, we can go without pivoting, at least in principle.\n\nStability of PLU factorization\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nϵ = 1e-12\nA = [-ϵ 1; 1 -1]\nb = A * [1, 1]\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nϵ = 1e-20; A = [-ϵ 1; 1 -1]\nb = A * [1, 1]\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b\n\nStability of PLU factorization\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1, 1]:\n\nep = 1e-12\nA = [-ep 1; 1 -1];\nb = A * [1; 1];\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20; A = [-ep 1; 1 -1];\nb = A * [1; 1];\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b\n\nStability of PLU factorization\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nep = 1e-12\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20;\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nprint(solve(A, b))\n\nThe factors of this \\mathbf{A} without pivoting are found to be  \\mathbf{L} = \n  \\begin{bmatrix}\n    1 & 0 \\\\ -\\epsilon^{-1} & 1 \n  \\end{bmatrix}, \\qquad \n  \\mathbf{U} = \n  \\begin{bmatrix}\n    -\\epsilon & 1 \\\\ 0 & \\epsilon^{-1}-1 \n  \\end{bmatrix}.\n\nFor reasons we will quantify in \n\nConditioning of linear systems, the solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b} is well-conditioned, but the problems of solving \\mathbf{L}\\mathbf{z}=\\mathbf{b} and \\mathbf{U}\\mathbf{x}=\\mathbf{z} have condition numbers essentially 1/\\epsilon^2 each. Thus, for small ε, solution of the original linear system by unpivoted LU factorization is highly unstable.\n\nSomewhat surprisingly, solving \\mathbf{A}\\mathbf{x}=\\mathbf{b} via PLU factorization is technically also unstable. In fact, examples of unstable solutions are well-known, but they have been nonexistent in practice. While there is a lot of evidence and some reasoning about why this is the case, the situation is not completely understood. Yet PLU factorization remains the algorithm of choice for general linear systems.","type":"content","url":"/pivoting#stability","position":9},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Exercises"},"type":"lvl2","url":"/pivoting#exercises","position":10},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Exercises"},"content":"✍ Perform by hand the pivoted LU factorization of each matrix.\n\n(a) \\quad \\displaystyle \\begin{bmatrix}\n 2 & 3 & 4 \\\\\n 4 & 5 & 10 \\\\\n 4 & 8 & 2\n \\end{bmatrix},\\qquad\n(b) \\quad \\displaystyle \\begin{bmatrix}\n 1 & 4 & 5 & -5 \\\\\n -1 & 0 & -1 & -5 \\\\\n 1 & 3 & -1 & 2 \\\\\n 1 & -1 & 5 & -1 \n \\end{bmatrix}.\n\n✍ Let \\mathbf{A} be a square matrix and \\mathbf{b} be a column vector of compatible length. Here is correct Julia code to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}:L,U,p = lu(A)\nx = U \\ (L\\b[p])\n\nSuppose instead you replace the last line above withx = U \\ L \\ b[p]\n\nMathematically in terms of \\mathbf{L}, \\mathbf{U}, \\mathbf{p}, and \\mathbf{b}, what vector is found?\n\n✍ Suppose that A is a 4\\times 6 matrix in Julia and you defineB = A[end:-1:1,end:-1:1]\n\nShow that \\mathbf{B} = \\mathbf{P} \\mathbf{A} \\mathbf{Q} for certain matrices \\mathbf{P} and \\mathbf{Q}.\n\n✍ An n\\times n permutation matrix \\mathbf{P} is a reordering of the rows of an identity matrix such that \\mathbf{P} \\mathbf{A}  has the effect of moving rows 1,2,\\ldots,n of \\mathbf{A} to new positions i_1,i_2,\\ldots,i_n. Then \\mathbf{P} can be expressed as\\mathbf{P} = \\mathbf{e}_{i_1}\\mathbf{e}_1^T + \\mathbf{e}_{i_2}\\mathbf{e}_2^T + \\cdots + \\mathbf{e}_{i_n}\\mathbf{e}_n^T.\n\n(a) For the case n=4 and i_1=3, i_2=2, i_3=4, i_4=1, write out separately, as matrices, all four of the terms in the sum. Then add them together to find \\mathbf{P}.\n\n(b) Use the formula in the general case to show that \\mathbf{P}^{-1}=\\mathbf{P}^T.\n\nBecause unpivoted LU factorization is not useful, in practice the term LU factorization mostly refers to pivoted LU.","type":"content","url":"/pivoting#exercises","position":11},{"hierarchy":{"lvl1":"Polynomial interpolation"},"type":"lvl1","url":"/polyinterp","position":0},{"hierarchy":{"lvl1":"Polynomial interpolation"},"content":"The United States carries out a census of its population every 10 years. Suppose we want to know the population at times in between the census years, or to estimate future populations. One technique is to find a polynomial that passes through all of the data points.\n\nPolynomial interpolation\n\nGiven n points (t_1,y_1),\\ldots,(t_n,y_n), where the t_i are all distinct, the polynomial interpolation problem is to find a polynomial p of degree less than n such that p(t_i)=y_i for all i.\n\nAs posed in \n\nDefinition 2.1.1, the polynomial interpolation problem has a unique solution. Once the interpolating polynomial is found, it can be evaluated anywhere to estimate or predict values.","type":"content","url":"/polyinterp","position":1},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Interpolation as a linear system"},"type":"lvl2","url":"/polyinterp#interpolation-as-a-linear-system","position":2},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Interpolation as a linear system"},"content":"Given data (t_i,y_i) for i=1,\\ldots,n, we seek a polynomialp(t) = c_1 + c_{2} t + c_3t^2 +  \\cdots + c_{n} t^{n-1},\n\nsuch that y_i=p(t_i) for all i. These conditions are used to determine the coefficients c_1\\ldots,c_n:\\begin{split}\n c_1 + c_2 t_1 + \\cdots + c_{n-1}t_1^{n-2} + c_nt_1^{n-1} &= y_1, \\\\\n c_1 + c_2 t_2 + \\cdots + c_{n-1}t_2^{n-2} + c_nt_2^{n-1} &= y_2, \\\\\n c_1 + c_2 t_3 + \\cdots + c_{n-1}t_3^{n-2} + c_nt_3^{n-1} &= y_3, \\\\\n \\vdots \\qquad & \\\\\n c_1 + c_2 t_n + \\cdots + c_{n-1}t_n^{n-2} + c_nt_n^{n-1} &= y_n.\n \\end{split}\n\nThese equations form a linear system for the coefficients c_i:  \\begin{bmatrix}\n    1 & t_1 & \\cdots & t_1^{n-2} & t_1^{n-1} \\\\\n    1 & t_2 & \\cdots & t_2^{n-2} & t_2^{n-1} \\\\\n    1 & t_3 & \\cdots & t_3^{n-2} & t_3^{n-1} \\\\\n    \\vdots & \\vdots &  & \\vdots & \\vdots \\\\\n    1 & t_n & \\cdots & t_n^{n-2} & t_n^{n-1} \\\\\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    c_1  \\\\\n    c_2  \\\\\n    c_3 \\\\\n    \\vdots \\\\\n    c_n\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    y_1  \\\\\n    y_2  \\\\\n    y_3 \\\\\n    \\vdots \\\\\n    y_n\n  \\end{bmatrix},\n\nor more simply, \\mathbf{V} \\mathbf{c} = \\mathbf{y}. The matrix \\mathbf{V} is of a\nspecial type.\n\nVandermonde matrix\n\nGiven distinct values t_1,\\ldots,t_n, a Vandermonde matrix for these values is the n\\times n matrix appearing in \n\n(2.1.3).\n\nPolynomial interpolation can therefore be posed as a linear system of equations with a Vandermonde matrix.\n\nAttention\n\nRecall that the demos in this and later chapters omit the statementusing FundamentalsNumericalComputation\n\nthat is needed to run some of the statements.\n\nLinear system for polynomial interpolation\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982, 2000, 2010, 2015]; \npop = [1008.18, 1262.64, 1337.82, 1374.62];\n\nIt’s convenient to measure time in years since 1980. We use .- to subtract a scalar from every element of a vector. We will also use a floating-point value in the subtraction, so the result is also in double precision.\n\nA dotted operator such as .- or .* acts elementwise, broadcasting scalar values to match up with elements of an array.\n\nt = year .- 1980.0\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nAn expression inside square brackets and ending with a for statement is called a comprehension. It’s often an easy and readable way to construct vectors and matrices.\n\nV = [ t[i]^j for i=1:4, j=0:3 ]\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V*c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in ascending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\nThe Polynomials package has functions to make working with polynomials easy and efficient.\n\np = Polynomial(c)    # construct a polynomial\np(2005-1980)         # include the 1980 time shift\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nscatter(t,y, label=\"actual\", legend=:topleft,\n    xlabel=\"years since 1980\", ylabel=\"population (millions)\", \n    title=\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval. The dot after the name of the polynomial is a universal way to apply a function to every element of an array, a technique known as broadcasting.\n\nThe range function constructs evenly spaced values given the endpoints and either the number of values, or the step size between them.\n\nAdding a dot to the end of a function name causes it to be broadcast, i.e., applied to every element of a vector or matrix.\n\n# Choose 500 times in the interval [0,35].\ntt = range(0,35,length=500)   \n# Evaluate the polynomial at all the vector components.\nyy = p.(tt)\nforeach(println,yy[1:4])\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\n\nBy convention, functions whose names end with the bang ! change the value or state of something, in addition to possibly returning output.\n\nplot!(tt,yy,label=\"interpolant\")\n\nLinear system for polynomial interpolation\n\nWe create two column vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982; 2000; 2010; 2015]; \npop = [1008.18; 1262.64; 1337.82; 1374.62];\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980;\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V * c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in descending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\np = @(t) polyval(c, t - 1980);  % include the 1980 time shift\np(2005)\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nscatter(year, y)\nxlabel(\"years since 1980\")\nylabel(\"population (millions)\")\ntitle(\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval.\n\nThe linspace function constructs evenly spaced values given the endpoints and the number of values.\n\ntt = linspace(1980, 2015, 500);    % 500 times in the interval [1980, 2015]\nyy = p(tt);                        % evaluate p at all the vector elements\nyy(1:4)\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nUse hold on to add to an existing plot rather than replacing it.\n\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\n\nhold on \nplot(tt, yy)\nlegend(\"data\", \"interpolant\", \"location\", \"northwest\")\n\nLinear system for polynomial interpolation\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = arange(1980, 2020, 10)   # from 1980 to 2020 by 10\npop = array([984.736, 1148.364, 1263.638, 1330.141])\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980\ny = pop\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\nprint(V)\n\nTo solve a linear system \\mathbf{V} \\mathbf{c} = \\mathbf{y} for the vector of polynomial coefficients, we use solve (imported from numpy.linalg):\n\nc = solve(V, y)\nprint(c)\n\nThe algorithms used by solve are the main topic of this chapter. As a check on the solution, we can compute the residual \\mathbf{y} - \\mathbf{V} \\mathbf{c}, which should be small (near machine precision).\n\nMatrix multiplication in NumPy is done with @ or matmul.\n\nprint(y - V @ c)\n\nBy our definitions, the coefficients in c are given in descending order of power in t. We can use the resulting polynomial to estimate the population of China in 2005:\n\np = poly1d(c)          # construct a polynomial\nprint(p(2005 - 1980))     # apply the 1980 time shift\n\nThe official figure was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points. Then we add a plot of the interpolant, taking care to shift the t variable back to actual years.\n\nscatter(year, y, color=\"k\", label=\"data\");\ntt = linspace(0, 30, 300)   # 300 times from 1980 to 2010\nplot(1980 + tt, p(tt), label=\"interpolant\");\nxlabel(\"year\");\nylabel(\"population (millions)\");\ntitle(\"Population of China\");\nlegend();","type":"content","url":"/polyinterp#interpolation-as-a-linear-system","position":3},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/polyinterp#exercises","position":4},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Exercises"},"content":"Suppose you want to interpolate the points (-1,0), (0,1), (2,0), (3,1), and (4,2) by a polynomial of as low a degree as possible.\n\n(a) ✍ What is the maximum necessary degree of this polynomial?\n\n(b) ✍ Write out a linear system of equations for the coefficients of the interpolating polynomial.\n\n(c) ⌨ Solve the system in (b) numerically.\n\n(a) ✍ Say you want to find a cubic polynomial p such that p(-1) =-2, p'(-1) =1, p(1) = 0, and p'(1) =-1. (This is known as a Hermite interpolant.) Write out a linear system of equations for the coefficients of p.\n\n(b) ⌨ Numerically solve the linear system in part (a) and make a plot of p over -1 \\le x \\le 1.\n\n⌨ Here are population figures (in millions) for three countries over a 30-year period (from United Nations World Population Prospects, 2019).\n\n\n\n1990\n\n2000\n\n2010\n\n2020\n\nUnited States\n\n252.120\n\n281.711\n\n309.011\n\n331.003\n\nIndia\n\n873.278\n\n1,056.576\n\n1,234.281\n\n1,380.004\n\nPoland\n\n37.960\n\n38.557\n\n38.330\n\n37.847\n\n(a) Use cubic polynomial interpolation to estimate the population of the USA in 2005.\n\n(b) Use cubic polynomial interpolation to estimate when the population of Poland peaked during this time period.\n\n(c) Use cubic polynomial interpolation to make a plot of the Indian population over this period. Your plot should be well labeled and show a smooth curve as well as the original data points.\n\n⌨ Here are the official population figures for the state of Delaware, USA, every ten years from 1790 to 1900: 59096, 64273, 72674, 72749, 76748, 78085, 91532, 112216, 125015, 146608, 168493, 184735. For this problem, uset = \\frac{\\text{year} - 1860}{10}\n\nas the independent (time) variable.\n\n(a) Using only the data from years 1860 to 1900, plot the interpolating polynomial over the same range of years. Add the original data points to your plot as well.\n\n(b) You might assume that adding more data will make the interpolation better. But this is not always the case. Use all the data above to create an interpolating polynomial of degree 11, and then plot that polynomial over the range 1860 to 1900. In what way is this fit clearly inferior to the previous one? (This phenomenon is studied in \n\nChapter 9.)\n\nWe’re quite certain that the U.S. Census Bureau uses more sophisticated modeling techniques than the one we present here!","type":"content","url":"/polyinterp#exercises","position":5},{"hierarchy":{"lvl1":"Exploiting matrix structure"},"type":"lvl1","url":"/structure","position":0},{"hierarchy":{"lvl1":"Exploiting matrix structure"},"content":"A common situation in computation is that a problem has certain properties or structure that can be used to get a faster or more accurate solution. There are many properties of a matrix that can affect LU factorization. For example, an n \\times n matrix A is diagonally dominant if  |A_{ii}| > \\sum_{\\substack{j=1\\\\ j \\neq i}}^{n} |A_{ij}| \\hskip 0.25in \\text{for each } i=1,\\ldots,n.\n\nIt turns out that a diagonally dominant matrix is guaranteed to be invertible, and row pivoting is not required for stability.\n\nWe next consider three important types of matrices that cause the LU factorization to be specialized in some important way.","type":"content","url":"/structure","position":1},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Banded matrices"},"type":"lvl2","url":"/structure#banded-matrices","position":2},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Banded matrices"},"content":"Bandwidth\n\nA matrix \\mathbf{A} has upper bandwidth b_u if j-i > b_u implies A_{ij}=0, and lower bandwidth b_\\ell if i-j > b_\\ell implies A_{ij}=0. We say the total bandwidth is b_u+b_\\ell+1. When b_u=b_\\ell=1, we have the important case of a tridiagonal matrix.\n\nBanded matrices\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nUse fill to create an array of a given size, with each element equal to a provided value.\n\nA = diagm( -1 => [4, 3, 2, 1, 0], \n    0 => [2, 2, 0, 2, 1, 2], \n    1 => fill(-1, 5) )\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\n@show diag_main = diag(A);\n@show diag_minusone = diag(A, -1);\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\nL, U = FNC.lufact(A)\nL\n\nU\n\nBanded matrices\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nA = [ 2 -1  0  0  0  0\n      4  2 -1  0  0  0\n      0  3  0 -1  0  0\n      0  0  2  2 -1  0\n      0  0  0  1  1 -1\n      0  0  0  0  0  2 ];\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\ndiag_main = diag(A, 0)'\ndiag_plusone = diag(A, 1)'\ndiag_minusone = diag(A,-1)'We can also put whatever numbers we like onto any diagonal with `diag`.\n\nA = A + diag([5 8 6 7], 2)\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\n[L, U] = lufact(A)\n\nBanded matrices\n\nHere is a matrix with both lower and upper bandwidth equal to one. Such a matrix is called tridiagonal.\n\nA = array([ \n    [2, -1,  0,  0,  0,  0],\n    [4,  2, -1,  0,  0,  0],\n    [0,  3,  0, -1,  0,  0],\n    [0,  0,  2,  2, -1,  0],\n    [0,  0,  0,  1,  1, -1],\n    [0,  0,  0,  0,  0,  2 ]\n    ])\n\nWe can extract the elements on any diagonal using the diag command. The “main” or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nprint( diag(A) )\n\nprint( diag(A, 1) )\n\nprint( diag(A, -1) )\n\nWe can also construct matrices by specifying a diagonal with the diag function.\n\nA = A + diag([pi, 8, 6, 7], 2)\nprint(A)\n\nL, U = FNC.lufact(A)\nprint(L)\n\nprint(U)\n\nObserve above that the lower and upper bandwidths of \\mathbf{A} are preserved in the factor matrices.\n\nIf row pivoting is not used, the \\mathbf{L} and \\mathbf{U} factors preserve the lower and upper bandwidths of \\mathbf{A}. This fact implies computational savings in both the factorization and the triangular substitutions because the zeros appear predictably and we can skip multiplication and addition with them.\n\nThe number of flops needed by LU factorization without pivoting is O(b_u b_\\ell n) when the upper and lower bandwidths are b_u and b_\\ell.\n\nIn order to exploit the savings offered by sparsity, we would need to make modifications to \n\nFunction 2.4.1 and the triangular substitution routines. Alternatively, we can get Julia to take advantage of the structure automatically by converting the matrix into a special type called sparse. Sparse matrices are covered in more detail in Chapters 7 and 8.","type":"content","url":"/structure#banded-matrices","position":3},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric matrices"},"type":"lvl2","url":"/structure#symmetric-matrices","position":4},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric matrices"},"content":"Symmetric matrix\n\nA square matrix \\mathbf{A} satisfying \\mathbf{A}^T = \\mathbf{A} is called symmetric.\n\nSymmetric matrices arise frequently in applications because many types of interactions, such as gravitation and social-network befriending, are inherently symmetric. Symmetry in linear algebra simplifies many properties and algorithms. As a rule of thumb, if your matrix has symmetry, you want to exploit and preserve it.\n\nIn \\mathbf{A}=\\mathbf{L}\\mathbf{U} we arbitrarily required the diagonal elements of \\mathbf{L}, but not \\mathbf{U}, to be one. That breaks symmetry, so we need to modify the goal to\\mathbf{A}=\\mathbf{L}\\mathbf{D}\\mathbf{L}^T,\n\nwhere \\mathbf{L} is unit lower triangular and \\mathbf{D} is diagonal. To find an algorithm for this factorization, we begin by generalizing \n\n(2.4.4) a bit without furnishing proof.\n\nLinear combination of outer products\n\nLet \\mathbf{D} be an n\\times n diagonal matrix with diagonal elements d_1,d_2,\\ldots,d_n, and suppose \\mathbf{A} and \\mathbf{B} are n\\times n as well. Write the columns of \\mathbf{A} as \\mathbf{a}_1,\\dots,\\mathbf{a}_n and the rows of \\mathbf{B} as \\mathbf{b}_1^T,\\dots,\\mathbf{b}_n^T. Then\\mathbf{A}\\mathbf{D}\\mathbf{B} = \\sum_{k=1}^n d_k \\mathbf{a}_k \\mathbf{b}_k^T.\n\nLet’s derive the LDLT factorization for a small example.\n\nSymmetric LDLT factorization\n\nWe begin with a symmetric \\mathbf{A}.\n\nA₁ = [  2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = diagm(ones(4))\nd = zeros(4)\nd[1] = A₁[1, 1]\nL[:, 1] = A₁[:, 1] / d[1]\nA₂ = A₁ - d[1] * L[:, 1] * L[:, 1]'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[2] = A₂[2, 2]\nL[:, 2] = A₂[:, 2] / d[2]\nA₃ = A₂ - d[2] * L[:, 2] * L[:, 2]'\n\nWe continue working our way down the diagonal.\n\nd[3] = A₃[3, 3]\nL[:, 3] = A₃[:, 3] / d[3]\nA₄ = A₃ - d[3] * L[:, 3] * L[:, 3]'\nd[4] = A₄[4, 4]\n@show d;\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nopnorm(A₁ - (L * diagm(d) * L'))\n\nSymmetric LDLT factorization\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = [ 2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4);\nd = zeros(4, 1);\nd(1) = A_1(1, 1);\nL(:, 1) = A_1(:, 1) / d(1);\nA_2 = A_1 - d(1) * L(:, 1) * L(:, 1)'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd(2) = A_2(2, 2);\nL(:, 2) = A_2(:, 2) / d(2);\nA_3 = A_2 - d(2) * L(:, 2) * L(:, 2)'\n\nWe continue working our way down the diagonal.\n\nd(3) = A_3(3, 3);\nL(:, 3) = A_3(:, 3) / d(3);\nA_4 = A_3 - d(3) * L(:, 3) * L(:, 3)'\nd(4) = A_4(4, 4);\nd\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nnorm(A_1 - (L * diag(d) * L'))\n\nSymmetric LDLT factorization\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = array([\n    [2,     4,     4,     2],\n    [4,     5,     8,    -5],\n    [4,     8,     6,     2],\n    [2,    -5,     2,   -26]\n    ])\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4)\nd = zeros(4)\nd[0] = A_1[0, 0]\nL[:, 0] = A_1[:, 0] / d[0]\nA_2 = A_1 - d[0] * outer(L[:, 0], L[:, 0])\nprint(A_2)\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[1] = A_2[1, 1]\nL[:, 1] = A_2[:, 1] / d[1]\nA_3 = A_2 - d[1] * outer(L[:, 1], L[:, 1])\nprint(A_3)\n\nWe continue working our way down the diagonal.\n\nd[2] = A_3[2, 2]\nL[:, 2] = A_3[:, 2] / d[2]\nA_4 = A_3 - d[2] * outer(L[:, 2], L[:, 2])\nprint(A_4)\n\nWe have arrived at the desired factorization.\n\nd[3] = A_4[3, 3]\nprint(\"diagonal of D:\")\nprint(d)\nprint(\"L:\")\nprint(L)\n\nThis should be comparable to machine roundoff:\n\nprint(norm(A_1 - (L @ diag(d) @ L.T), 2) / norm(A_1))\n\nIn practice we don’t actually have to carry out any arithmetic in the upper triangle of \\mathbf{A} as we work, since the operations are always the mirror image of those in the lower triangle. As a result, it can be shown that LDLT factorization takes about half as much work as the standard LU.\n\nLDLT factorization on an n \\times n symmetric matrix, when successful, takes \\sim \\frac{1}{3}n^3 flops.\n\nJust as pivoting is necessary to stabilize LU factorization, the LDLT factorization without pivoting may be unstable or even fail to exist. We won’t go into the details, because our interest is in specializing the factorization to matrices that also possess another important property.","type":"content","url":"/structure#symmetric-matrices","position":5},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric positive definite matrices"},"type":"lvl2","url":"/structure#sec-spd","position":6},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric positive definite matrices"},"content":"Suppose that \\mathbf{A} is n\\times n and \\mathbf{x}\\in\\mathbb{R}^n. Observe that \\mathbf{x}^T\\mathbf{A}\\mathbf{x} is the product of 1\\times n, n\\times n, and n\\times 1 matrices, so it is a scalar, sometimes referred to as a quadratic form. It can be expressed as  \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = \\sum_{i=1}^n \\sum_{j=1}^n A_{ij}x_ix_j.\n\nSymmetric positive definite matrix\n\nA real n\\times n matrix \\mathbf{A} is called a symmetric positive definite matrix (or SPD matrix) if it is symmetric and, for all nonzero \\mathbf{x}\\in\\mathbb{R}^n,  \\mathbf{x}^T \\mathbf{A} \\mathbf{x} > 0.\n\nThe definiteness property is usually difficult to check directly from the definition. There are some equivalent conditions, though. For instance, a symmetric matrix is positive definite if and only if its eigenvalues are all real positive numbers. SPD matrices have important properties and appear in applications in which the definiteness is known for theoretical reasons.\n\nLet us consider what definiteness means to the LDLT factorization. We compute  0 < \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = \\mathbf{x}^T \\mathbf{L} \\mathbf{D} \\mathbf{L}^T \\mathbf{x} = \\mathbf{z}^T \\mathbf{D} \\mathbf{z},\n\nwhere \\mathbf{z}=\\mathbf{L}^T \\mathbf{x}. Note that since \\mathbf{L} is unit lower triangular, it is nonsingular, so \\mathbf{x}=\\mathbf{L}^{-T}\\mathbf{z}. By taking \\mathbf{z}=\\mathbf{e}_k for k=1,\\ldots,n, we can read the equalities from right to left and conclude that D_{kk}>0 for all k. That permits us to write a kind of square root formula:  \\mathbf{D} =\n  \\begin{bmatrix}\n    D_{11} &        &        & \\\\\n           & D_{22} &        & \\\\\n           &        & \\ddots & \\\\\n           &        &        & D_{nn}\n  \\end{bmatrix}\n=   \\begin{bmatrix}\n    \\sqrt{D_{11}} &        &        & \\\\\n           & \\sqrt{D_{22}} &        & \\\\\n           &        & \\ddots & \\\\\n           &        &        & \\sqrt{D_{nn}}\n  \\end{bmatrix}^{\\,2}\n= \\bigl( \\mathbf{D}^{1/2} \\bigr)^2.\n\nNow we have \\mathbf{A}=\\mathbf{L}\\mathbf{D}^{1/2}\\mathbf{D}^{1/2}\\mathbf{L}^T= \\mathbf{R}^T \\mathbf{R}, where \\mathbf{R} =\\mathbf{D}^{1/2}\\mathbf{L}^T is an upper triangular matrix whose diagonal entries are positive.\n\nCholesky factorization\n\nAny SPD matrix \\mathbf{A} may be factored as\\mathbf{A} = \\mathbf{R}^T \\mathbf{R},\n\nwhere \\mathbf{R} is an upper triangular matrix with positive diagonal elements. This is called the Cholesky factorization.\n\nWhile the unpivoted LDLT factorization is not stable and not even always possible, in the SPD case one can prove that pivoting is not necessary for the existence nor the stability of the Cholesky factorization.\n\nCholesky factorization of an n \\times n SPD matrix takes \\sim \\frac{1}{3}n^3 flops.\n\nThe speed and stability of the Cholesky factorization make it the top choice for solving linear systems with SPD matrices. As a side benefit, the Cholesky algorithm fails (in the form of an imaginary square root or division by zero) if and only if the matrix \\mathbf{A} is not positive definite. This is often the best way to test the definiteness of a symmetric matrix about which nothing else is known.\n\nCholesky factorization\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = rand(1.0:9.0, 4, 4)\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nThe cholesky function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix. However, it does not check for symmetry.\n\ncholesky(B)    # throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A\ncf = cholesky(B)\n\nWhat’s returned is a factorization object. Another step is required to extract the factor as a matrix:\n\nR = cf.U\n\nHere we validate the factorization:\n\nopnorm(R' * R - B) / opnorm(B)\n\nCholesky factorization\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = magic(4) + eye(4);\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nThe chol function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix.\n\nWarning\n\nThe chol function does not check for symmetry. It may give a nonsensical result if the input is not symmetric.\n\nchol(B)    % throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A;\nR = chol(B)\n\nHere we validate the factorization:\n\nnorm(R' * R - B) / norm(B)\n\nCholesky factorization\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = 1.0 + floor(9 * random.rand(4, 4))\nB = A + A.T\nprint(B)\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nfrom numpy.linalg import cholesky\ncholesky(B)\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization:\n\nB = A.T @ A\nR = cholesky(B)\nprint(R)\n\nprint(norm(R @ R.T - B) / norm(B))","type":"content","url":"/structure#sec-spd","position":7},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Exercises"},"type":"lvl2","url":"/structure#exercises","position":8},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Exercises"},"content":"✍  For each matrix, use \n\n(2.9.1) to determine whether it is diagonally dominant.\\mathbf{A} =\n\\begin{bmatrix}\n3  & 1  & 0 & 1  \\\\\n0  & -2 & 0 & 1  \\\\\n-1 & 0  & 4 & -1 \\\\\n0  & 0  & 0 & 6\n\\end{bmatrix},\n\\quad\n\\mathbf{B} =\n\\begin{bmatrix}\n1  & 0  & 0  & 0 & 0  \\\\\n0  & 1  & 0  & 0 & 0  \\\\\n0  & 0  & 1  & 0 & 0  \\\\\n0  & 0  & 0  & 1 & 0  \\\\\n0  & 0  & 0  & 0 & 0\n\\end{bmatrix},\n\\quad \\mathbf{C} =\n\\begin{bmatrix}\n2  & -1 & 0  & 0      \\\\\n-1 & 2  & -1 & 0      \\\\\n0  & -1 & 2  & -1     \\\\\n0  & 0  & -1 & 2\n\\end{bmatrix}.\n\n⌨ For each matrix, use inspection or cholesky in Julia to determine whether it is SPD.\\mathbf{A} =\n\\begin{bmatrix}\n1 & 0 & -1 \\\\ 0 & 4 & 5 \\\\ -1 & 5 & 10\n\\end{bmatrix},\n\\qquad\n\\mathbf{B} =\n\\begin{bmatrix}\n1 & 0 & 1 \\\\ 0 & 4 & 5 \\\\ -1 & 5 & 10\n\\end{bmatrix},\n\\qquad\n\\mathbf{C} =\n\\begin{bmatrix}\n1 & 0 & 1 \\\\ 0 & 4 & 5 \\\\ 1 & 5 & 1\n\\end{bmatrix}.\n\n✍ Show that the diagonal entries of a symmetric positive definite matrix are positive numbers. (Hint: Apply certain special cases of \n\n(2.9.5).)\n\n⌨ Using \n\nFunction 2.4.1 as a guide, write a functionfunction luband(A,upper,lower)\n\nthat accepts upper and lower bandwidth values and returns LU factors (without pivoting) in a way that avoids doing arithmetic using the locations that are known to stay zero. (Hint: Refer to the more efficient form of lufact given in \n\nEfficiency of matrix computations.)\n\nTest your function on the matrix with elementsA_{ij} = \\begin{cases} \\frac{1}{i+j}, & -1 \\le i-j \\le 2,\\\\ \n    0 & \\text{otherwise.} \\end{cases}\n\n⌨ The Tridiagonal matrix type invokes a specialized algorithm for solving a linear system.\n\n(a) Set n=1000 and t=0.  In a loop that runs 50 times, generate a linear system viaA = triu( tril(rand(n,n),1), -1)\nb = ones(n)\n\nUsing @elapsed, increment t by the time it takes to perform A\\b. Print out the final value of t.\n\n(b) Repeat the experiment of part (a), but generate the matrix viaA = Tridiagonal(rand(n,n))\n\nWhat is the ratio of running times for part (a) and (b)?\n\n(c) Now perform the experiment of part (b) for n=1000,1200,1400,\\ldots,3000, keeping the total time for each value of n in a vector. Plot running time as a function of n on a log-log scale. Is the time most like O(n), O(n^2), or O(n^3)? (If the answer is unclear, try increasing the number of solves per value of n to 100 or more.)\n\n✍ Prove that if \\mathbf{A} is any real invertible square matrix, then \\mathbf{A}^T\\mathbf{A} is SPD. (Hint: First show that \\mathbf{x}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{x} \\ge 0 for all \\mathbf{x}. Then explain why zero is ruled out if \\mathbf{x}\\neq \\boldsymbol{0}.)\n\nExcept for this diagonal, positive definite case, it’s not trivial to define the square root of a matrix, so don’t generalize the notation used here.","type":"content","url":"/structure#exercises","position":9},{"hierarchy":{"lvl1":"Fitting functions to data"},"type":"lvl1","url":"/fitting","position":0},{"hierarchy":{"lvl1":"Fitting functions to data"},"content":"In \n\nPolynomial interpolation we saw how a polynomial can be used to interpolate data—that is, derive a continuous function that evaluates to give a set of prescribed values. But interpolation may not be appropriate in many applications.\n\nInterpolating temperature data\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = 1955:5:2000\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n       0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n    \nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", leg=:bottomright)\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = @. (year - 1950) / 10\nn = length(t)\nV = [ t[i]^j for i in 1:n, j in 0:n-1 ]\nc = V \\ temp\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\nIf you plot a function, then the points are chosen automatically to make a smooth curve.\n\np = Polynomial(c)\nf = yr -> p((yr - 1950) / 10)\nplot!(f, 1955, 2000, label=\"interpolant\")\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nInterpolating temperature data\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nt = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\nscatter(t, y), axis tight\nxlabel('year')\nylabel('anomaly ({\\circ}C)')\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (t - 1950) / 10;  \nn = length(t);\nV = ones(n, 1);    % t^0\nfor j = 1:n-1\n    V(:, j+1) = t .* V(:,j);\nend\nc = V \\ y;    % solve for coefficients\n\nWe created the Vandermonde matrix columns in increasing-degree order. Thus, the coefficients in c also follow that ordering, which is the opposite of what MATLAB uses. We need to flip the coefficients before using them in polyval.\n\np = @(year) polyval(c(end:-1:1), (year - 1950) / 10);\nhold on\nfplot(p, [1955, 2000])    % plot the interpolating function\n\nInterpolating temperature data\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = arange(1955,2005,5)\ny = array([ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ])\n\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (year - 1950) / 10\nV = vander(t)\nc = solve(V, y)\nprint(c)\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\np = poly1d(c)    # convert to a polynomial\ntt = linspace(1955, 2000, 500)\nax.plot(tt, p((tt - 1950) / 10), label=\"interpolant\")\nax.legend();\nfig\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nIn many cases we can get better results by relaxing the interpolation requirement. In the polynomial case this allows us to lower the degree of the polynomial, which limits the number of local max and min points. Let (t_i,y_i) for i=1,\\ldots,m be the given points. We will represent the data by the polynomialy \\approx f(t) = c_1 + c_2t + \\cdots + c_{n-1} t^{n-2} + c_n t^{n-1},\n\nwith n<m. Just as in \n\n(2.1.3), we can express a vector of f-values by a matrix-vector multiplication. In other words, we seek an approximation\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_m \\end{bmatrix} \\approx\n\\begin{bmatrix}\nf(t_1)                               \\\\\nf(t_2)                               \\\\\nf(t_3)                               \\\\\n\\vdots                               \\\\\nf(t_m)\n\\end{bmatrix} =\n\\begin{bmatrix}\n1      & t_1    & \\cdots & t_1^{n-1} \\\\\n1      & t_2    & \\cdots & t_2^{n-1} \\\\\n1      & t_3    & \\cdots & t_3^{n-1} \\\\\n\\vdots & \\vdots &        & \\vdots    \\\\\n1      & t_m    & \\cdots & t_m^{n-1} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1                                  \\\\\nc_2                                  \\\\\n\\vdots                               \\\\\nc_n\n\\end{bmatrix}\n= \\mathbf{V} \\mathbf{c}.\n\nNote that \\mathbf{V} has the same structure as the Vandermonde matrix in \n\n(2.1.3) but is m\\times n, thus taller than it is wide. It’s impossible in general to satisfy m conditions with n<m variables, and we say the system is overdetermined. Rather than solving the system exactly, we have to find a best approximation. Below we specify precisely what is meant by this, but first we note that Julia uses the same backslash notation to solve the problem in both the square and overdetermined cases.\n\nFitting temperature data\n\nHere are the 5-year temperature averages again.\n\nyear = 1955:5:2000\nt = @. (year-1950)/10\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n          0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = [ t.^0 t ]    # Vandermonde-ish matrix\n@show size(V)\nc = V \\ temp\np = Polynomial(c)\n\nf = yr -> p((yr - 1955) / 10)\nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", leg=:bottomright)\nplot!(f, 1955, 2000, label=\"linear fit\")\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [ t[i]^j for i in 1:length(t), j in 0:3 ]   \n@show size(V);\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nThe definition of f above is in terms of p. When p is changed, then f calls the new version.\n\np = Polynomial( V \\ temp )\nplot!(f, 1955, 2000, label=\"cubic fit\")\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nFitting temperature data\n\nHere are the 5-year temperature averages again.\n\nyear = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nt = (year - 1955) / 10;    % better matrix conditioning later\nV = [ t.^0 t ];            % Vandermonde-ish matrix\nsize(V)\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\n\nclf\nscatter(year, y), axis tight\nxlabel('year'), ylabel('anomaly ({\\circ}C)')\nhold on\nfplot(f, [1955, 2000])\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [t.^0, t.^1, t.^2, t.^3];    % Vandermonde-ish matrix  \nsize(V)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nThe definition of f above is in terms of c. When c is changed, then f has to be redefined.\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\nfplot(f, [1955, 2000]) \nlegend('data', 'linear', 'cubic', 'Location', 'northwest')\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nFitting temperature data\n\nHere are the 5-year temperature averages again.\n\nyear = arange(1955, 2005, 5)\ny = array([-0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560])\nt = (year - 1950) / 10\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = array([ [t[i], 1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nfrom numpy.linalg import lstsq\nc, res, rank, sv = lstsq(V, y)\np = poly1d(c)\nf = lambda year: p((year - 1950) / 10)\n```{code-cell}\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"linear fit\")\n\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\nax.legend();\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = array([ [t[i]**3,t[i]**2,t[i],1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nThe definition of f above is in terms of c. When c is changed, f is updated with it.\n\nc, res, rank, sv = lstsq(V, y, rcond=None)\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"cubic fit\")\nfig\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.","type":"content","url":"/fitting","position":1},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"The least-squares formulation"},"type":"lvl2","url":"/fitting#the-least-squares-formulation","position":2},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"The least-squares formulation"},"content":"In the most general terms, our fitting functions take the formf(t) = c_1 f_1(t) + \\cdots + c_n f_n(t)\n\nwhere f_1,\\ldots,f_n are all known functions with no undetermined parameters. This leaves only c_1,\\ldots,c_n to be determined. The essential feature of a linear least-squares problem is that the fit depends only linearly on the unknown parameters. For instance, a function of the form f(t)=c_1 + c_2 e^{c_3 t} is not of this type.\n\nAt each observation (t_i,y_i), we define a residual, y_i - f(t_i). A sensible formulation of the fitting criterion is to minimize  R(c_1,\\ldots,c_n) = \\sum_{i=1}^m\\, [ y_i - f(t_i) ]^2,\n\nover all possible choices of parameters c_1,\\ldots,c_n. We can apply linear algebra to write the problem in the form R=\\mathbf{r}^T \\mathbf{r}, where\\mathbf{r} =\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\y_{m-1} \\\\ y_m\n\\end{bmatrix} -\n\\begin{bmatrix}\nf_1(t_1) & f_2(t_1) & \\cdots & f_n(t_1) \\\\[1mm]\nf_1(t_2) & f_2(t_2) & \\cdots & f_n(t_2) \\\\[1mm]\n& \\vdots \\\\\nf_1(t_{m-1}) & f_2(t_{m-1}) & \\cdots & f_n(t_{m-1}) \\\\[1mm]\nf_1(t_m) & f_2(t_m) & \\cdots & f_n(t_m) \\\\[1mm]\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n\n\\end{bmatrix}.\n\nRecalling that \\mathbf{r}^T\\mathbf{r}=\\| \\mathbf{r} \\|_2^2, and renaming the variables to standardize the statement, we arrive at the general linear least-squares problem.\n\nLinear least-squares problem\n\nGiven \\mathbf{A}\\in\\mathbb{R}^{m \\times n} and \\mathbf{b}\\in\\mathbb{R}^m, with m>n, find\\argmin_{{\\mathbf{x}\\in \\mathbb{R}^n}} \\, \\twonorm{\\mathbf{b}-\\mathbf{A} \\mathbf{x}}^2.\n\nThe notation argmin above means to find an \\mathbf{x} that produces the minimum value.\n\nWhile we could choose to minimize in any vector norm, the 2-norm is the most common and convenient choice. For the rest of this chapter we exclusively use the 2-norm. In the edge case m=n for a nonsingular \\mathbf{A}, the definitions of the linear least-squares and linear systems problems coincide: the solution of  \\mathbf{A}\\mathbf{x}=\\mathbf{b}  implies \\mathbf{r}=\\boldsymbol{0}, which is a global minimum of \\| \\mathbf{r} \\|_2^2 \\ge 0.","type":"content","url":"/fitting#the-least-squares-formulation","position":3},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Change of variables"},"type":"lvl2","url":"/fitting#change-of-variables","position":4},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Change of variables"},"content":"The most familiar and common case of a polynomial least-squares fit is the straight line, f(t) = c_1 + c_2 t. Certain other fit functions can be transformed into this situation. For example, suppose we want to fit data using g(t)= a_1 e^{a_2 t}. Then\\log y \\approx \\log g(t) = (\\log a_1) + a_2 t = c_1 + c_2 t.\n\nWhile the fit of the y_i to g(t) is nonlinearly dependent on fitting parameters, the fit of \\log y to a straight line is a linear problem. Similarly, the power-law relationship y\\approx f(t)=a_1 t^{a_2} is equivalent to\\log y \\approx (\\log a_1) + a_2 (\\log t).\n\nThus, the variable z=\\log y can be fit linearly in terms of the variable s=\\log t. In practice these two cases—exponential fit and power law—are easily detected by using log-linear or log-log plots, respectively.\n\nFinding numerical approximations to π has fascinated people for millennia. One famous formula is\\displaystyle \\frac{\\pi^2}{6} = 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\cdots.\n\nSay s_k is the sum of the first k terms of the series above, and p_k = \\sqrt{6s_k}. Here is a fancy way to compute these sequences in a compact code.\n\nFitting a power law\n\na = [1/k^2 for k=1:100] \ns = cumsum(a)        # cumulative summation\np = @. sqrt(6*s)\n\nscatter(1:100, p, title=\"Sequence convergence\",\n    xlabel=L\"k\", ylabel=L\"p_k\")\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nϵ = @. abs(π - p)    # error sequence\nscatter(1:100, ϵ, title=\"Convergence of errors\",\n    xaxis=(:log10,L\"k\"), yaxis=(:log10,\"error\"))\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nk = 1:100\nV = [ k.^0 log.(k) ]     # fitting matrix\nc = V \\ log.(ϵ)          # coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[1]), c[2];\n@show b;\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nplot!(k, a * k.^b, l=:dash, label=\"power-law fit\")\n\nFitting a power law\n\nk = (1:100)';\na = 1./k.^2;      % sequence\ns = cumsum(a);    % cumulative summation\np = sqrt(6*s);\nclf\nplot(k, p, 'o-')\nxlabel('k'), ylabel('p_k')\ntitle('Sequence converging to \\pi')\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p);    % error sequence\nloglog(k, ep, 'o')\ntitle('Convergence')\nxlabel('k'), ylabel('|p_k - \\pi|'), axis tight\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = [ k.^0, log(k) ];    % fitting matrix\nc = V \\ log(ep)          % coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na = exp(c(1)),  b = c(2)\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nhold on\nloglog(k, a * k.^b)\nlegend('sequence', 'power-law fit')\n\nFitting a power law\n\na = array([1 / (k+1)**2 for k in range(100)])\ns = cumsum(a)        # cumulative summation\np = sqrt(6*s)\n\nplot(range(100), p, \"o\")\nxlabel(\"$k$\") \nylabel(\"$p_k$\") \ntitle(\"Sequence convergence\");\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p)    # error sequence\nloglog(range(100), ep, \"o\")\nxlabel(\"$k$\") \nylabel(\"error\") \ntitle(\"Sequence convergence\");\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = array([ [1, log(k+1)] for k in range(100) ])     # fitting matrix\nc = lstsq(V, log(ep), rcond=None)[0]           # coefficients of linear fit\nprint(c)\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[0]), c[1]\nprint(f\"b: {b:.3f}\")\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nloglog(range(100), ep, \"o\", label=\"sequence\")\nk = arange(1,100)\nplot(k, a*k**b, \"--\", label=\"power fit\")\nxlabel(\"$k$\");  ylabel(\"error\"); \nlegend(); title(\"Sequence convergence\");","type":"content","url":"/fitting#change-of-variables","position":5},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Exercises"},"type":"lvl2","url":"/fitting#exercises","position":6},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Exercises"},"content":"✍ Suppose f is a twice-differentiable, nonnegative real function. Show that if there is an x^* such that f'(x^*)=0 and f''(x^*)>0, then x^* is a local minimizer of the function [f(x)]^2.\n\n⌨  Here are counts of the U.S. population in millions from the census performed every ten years, beginning with 1790 and ending with 2010.3.929, 5.308, 7.240, 9.638, 12.87, 17.07, 23.19, 31.44, 39.82, 50.19, 62.95, 76.21,\n92.22, 106.0, 122.8, 132.2, 150.7, 179.3, 203.3, 226.5, 248.7, 281.4, 308.7\n\n(a) Find a best-fitting cubic polynomial for the data. Plot the data as points superimposed on a (smooth) graph of the cubic over the full range of time. Label the axes. What does the fit predict for the population in the years 2000, 2010, and 2020?\n\n(b) Look up the actual U.S. population in 2000, 2010, and 2020 and compare to the predictions of part (a).\n\n⌨  The following are weekly box office earnings (in dollars) in the U.S. for the 2012 film The Hunger Games. (Source: \n\nboxofficemojo.com.)189_932_838, 79_406_327, 46_230_374, 26_830_921, 18_804_290,\n13_822_248, 7_474_688, 6_129_424, 4_377_675, 3_764_963, 2_426_574,\n1_713_298, 1_426_102, 1_031_985, 694_947, 518_242, 460_578, 317_909\n\n(Note that Julia lets you use _ where you would normally put a comma in a long number.) Fit these values to a function of the form y(t)\\approx a e^{b t}. Plot the data together with the fit using standard linear scales on the axes, and then plot them again using a log scale on the vertical axis.\n\n⌨  In this problem you are trying to find an approximation to the periodic function g(t)=e^{\\sin(t-1)} over one period, 0 < t \\le 2\\pi. As data, definet_i = \\frac{2\\pi i}{60}, \\; y_i = g(t_i), \\quad i=1,\\ldots,60.\n\n(a) Find the coefficients of the least-squares fit  y(t) \\approx c_1 + c_2t + \\cdots + c_7 t^6.\n\nSuperimpose a plot of the data values as points with a curve showing the fit.\n\n(b) Find the coefficients of the least-squares fity \\approx d_1 + d_2\\cos(t) + d_3\\sin(t) + d_4\\cos(2t) + d_5\\sin(2t).\n\nUnlike part (a), this fitting function is itself periodic. Superimpose a plot of the data values as points with a curve showing the fit.\n\n⌨ Define the following data in Julia.t = 0:.5:10\ny = tanh.(t)\n\n(a) Fit the data to a cubic polynomial. Plot the data together with the polynomial fit over the interval 0 \\le t \\le 10.\n\n(b) Fit the data to the function c_1 + c_2z + c_3z^2 + c_4z^3, where z=t^2/(1+t^2). Plot the data together with the fit. What feature of z makes this fit much better than the original cubic?\n\n⌨  One series for finding π is\\frac{\\pi}{2} = 1 + \\frac{1}{3} + \\frac{1\\cdot 2}{3\\cdot5} + \\frac{1\\cdot 2\\cdot 3}{3\\cdot 5\\cdot 7} + \\cdots.\n\nDefine s_k to be the sum of the first k terms on the right-hand side, and let e_k=|s_k-\\pi/2|.\n\n(a) Calculate e_k for k=1,\\ldots,20, and plot the sequence on a log-linear scale.\n\n(b) Determine a and b in a least-squares fit e_k \\approx a \\cdot b^k, and superimpose the fit on the plot from part (a).\n\n⌨  Kepler found that the orbital period τ of a planet depends on its mean distance R from the sun according to \\tau=c R^{\\alpha} for a simple rational number α. Perform a linear least-squares fit from the following table in order to determine the most likely simple rational value of α.\n\nPlanet\n\nDistance from sun in Mkm\n\nOrbital period in days\n\nMercury\n\n57.59\n\n87.99\n\nVenus\n\n108.11\n\n224.7\n\nEarth\n\n149.57\n\n365.26\n\nMars\n\n227.84\n\n686.98\n\nJupiter\n\n778.14\n\n4332.4\n\nSaturn\n\n1427\n\n10759\n\nUranus\n\n2870.3\n\n30684\n\nNeptune\n\n4499.9\n\n60188\n\n✍ Show that finding a fit of the formy(t) \\approx \\frac{a}{t+b}\n\ncan be transformed into a linear fitting problem (with different undetermined coefficients) by rewriting the equation.\n\n✍ Show how to find the constants a and b in a data fitting problem of the form y(t)\\approx t/(at+b) for t>1 by transforming it into a linear least-squares fitting problem.","type":"content","url":"/fitting#exercises","position":7},{"hierarchy":{"lvl1":"Computing QR factorizations"},"type":"lvl1","url":"/house","position":0},{"hierarchy":{"lvl1":"Computing QR factorizations"},"content":"It is possible to compute a thin QR factorization using the outer product formula \n\n(2.4.4), as we did with LU. However, to stably compute the factorization, a better strategy is to introduce zeros into the lower triangle, one column at a time, using orthogonal matrices. Thanks to \n\nTheorem 3.3.2, the product of orthogonal matrices will also be orthogonal.","type":"content","url":"/house","position":1},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Householder reflections"},"type":"lvl2","url":"/house#householder-reflections","position":2},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Householder reflections"},"content":"We will use a particular type of orthogonal matrix.\n\nHouseholder reflector\n\nA Householder reflector is a matrix of the form  \\mathbf{P} = \\mathbf{I} - 2 \\mathbf{v} \\mathbf{v}^T,\n\nwhere \\mathbf{v} is any unit vector (in the 2-norm).\n\nIn \n\nExercise 2 you are asked to show that such a \\mathbf{P} is necessarily orthogonal. Note that for any vector \\mathbf{x} of appropriate dimension,  \\mathbf{P}\\mathbf{x} = \\mathbf{x} - 2 \\mathbf{v} (\\mathbf{v}^T\\mathbf{x}).\n\nThe reason \\mathbf{P} is called a reflector is sketched in \n\nFigure 3.4.1.\n\n\n\nFigure 3.4.1:A Householder reflector. Because \\mathbf{v} is a unit vector, \\mathbf{v}^T\\mathbf{x} is the component of \\mathbf{x} in the direction of \\mathbf{v}. Hence subtracting (\\mathbf{v}^T\\mathbf{x})\\mathbf{v} projects \\mathbf{x} into a hyperplane orthogonal to \\mathbf{v}. By subtracting off twice as much, we get the reflection of \\mathbf{x} through the hyperplane instead.\n\nGiven a vector \\mathbf{z}, we can choose \\mathbf{v} so that \\mathbf{P} reflects \\mathbf{z} onto the x_1-axis—i.e., so that \\mathbf{P}\\mathbf{z} is nonzero only in the first element. Because orthogonal matrices preserve the 2-norm, we must have\\mathbf{P}\\mathbf{z} =\n\\begin{bmatrix}\n\\pm \\| \\mathbf{z} \\|\\\\0 \\\\ \\vdots \\\\ 0\n\\end{bmatrix} = \\pm \\| \\mathbf{z} \\| \\mathbf{e}_1.\n\n(Recall that \\mathbf{e}_k is the kth column of the identity matrix.) We choose the positive sign above for our discussion, but see \n\nFunction 3.4.1 and \n\nExercise 4 for important computational details. Let  \\mathbf{w} = \\| \\mathbf{z} \\| \\mathbf{e}_1-\\mathbf{z}, \\quad \\mathbf{v} = \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|}.\n\nIf it turns out that \\mathbf{w}=\\boldsymbol{0}, then \\mathbf{z} is already in the target form and we can take \\mathbf{P}=\\mathbf{I}.  Otherwise, we have the following.\n\nHouseholder reflector\n\nLet \\mathbf{v} be defined by \n\n(3.4.4) and let \\mathbf{P} be given by \n\n(3.4.1). Then \\mathbf{P} is symmetric and orthogonal, and \\mathbf{P}\\mathbf{z}=\\| \\mathbf{z} \\|\\mathbf{e}_1.\n\nThe proofs of symmetry and orthogonality are left to \n\nExercise 2. For the last fact, we use \n\n(3.4.2) to compute\\mathbf{P}\\mathbf{z} = \\mathbf{z} - 2 \\frac{\\mathbf{w}^T \\mathbf{z}}{\\mathbf{w}^T\\mathbf{w}} \\mathbf{w}.\n\nSince \\mathbf{e}_1^T\\mathbf{z}=z_1,\\begin{split}\n    \\mathbf{w}^T\\mathbf{w} &= \\| \\mathbf{z} \\|^2 - 2 \\| \\mathbf{z} \\| z_1 + \\mathbf{z}^T\\mathbf{z}\n    = 2\\| \\mathbf{z} \\|(\\| \\mathbf{z} \\|-z_1),\\\\\n    \\mathbf{w}^T\\mathbf{z} &= \\| \\mathbf{z} \\|z_1 - \\mathbf{z}^T\\mathbf{z} = -\\| \\mathbf{z} \\|\\bigl(\\| \\mathbf{z} \\|-z_1\\bigr),\n\\end{split}\n\nleading finally to\\mathbf{P}\\mathbf{z} = \\mathbf{z} - 2\\cdot\n\\frac{-\\| \\mathbf{z} \\| \\bigl(\\| \\mathbf{z} \\|-z_1\\bigr)}{2\\| \\mathbf{z} \\| \\bigl(\\| \\mathbf{z} \\|-z_1\\bigr)} \\mathbf{w}\n= \\mathbf{z} + \\mathbf{w} = \\| \\mathbf{z} \\|\\mathbf{e}_1.","type":"content","url":"/house#householder-reflections","position":3},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Factorization algorithm"},"type":"lvl2","url":"/house#factorization-algorithm","position":4},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Factorization algorithm"},"content":"The QR factorization is computed by using successive Householder reflections to introduce zeros in one column at a time. We first show the process for a small numerical example in \n\nDemo 3.4.1.\n\nHouseholder QR factorization\n\nWe will use Householder reflections to produce a QR factorization of a random matrix.\n\nThe rand function can select randomly from within the interval [0,1], or from a vector or range that you specify.\n\nA = rand(float(1:9),6,4)\nm,n = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).:::{card}\n`I` can stand for an identity matrix of any size, inferred from the context when needed.\n\nz = A[:, 1];\nv = normalize(z - norm(z) * [1; zeros(m-1)])\nP₁ = I - 2v * v'   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nP₁ * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}\\mathbf{A}.\n\nA = P₁ * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[2:m, 2]\nv = normalize(z - norm(z) * [1; zeros(m-2)])\nP₂ = I - 2v * v'\n\nWe now apply this reflector to rows 2 and below only.\n\nA[2:m, :] = P₂ * A[2:m, :]\nA\n\nWe need to iterate the process for the last two columns.\n\nfor j in 3:n\n    z = A[j:m, j]\n    v = normalize(z - norm(z) * [1; zeros(m-j)])\n    P = I - 2v * v'\n    A[j:m, :] = P * A[j:m, :]\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)\n\nHouseholder QR factorization\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = magic(6);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A(:, 1);\nv = z - norm(z) * eye(m,1);\nP_1 = eye(m) - 2 / (v' * v) * (v * v');\n\nWe check that this reflector introduces zeros as it should:\n\nP_1 * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A(2:m, 2);\nv = z - norm(z) * eye(m-1, 1);\nP_2 = eye(m-1) - 2 / (v' * v) * (v * v');\n\nWe now apply this reflector to rows 2 and below only.\n\nA(2:m, 2:n) = P_2 * A(2:m, 2:n)\n\nWe need to iterate the process for the last two columns.\n\nfor j = 3:n\n    z = A(j:m,j);\n    k = m-j+1;\n    v = z - norm(z) * eye(k, 1);\n    P = eye(k) - 2 / (v' * v) * (v * v');\n    A(j:m, j:n) = P * A(j:m, j:n);\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = A\n\nHouseholder QR factorization\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nm, n = A.shape\nprint(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A[:, 0]\nv = z - norm(z) * hstack([1, zeros(m-1)])\nP_1 = eye(m) - (2 / dot(v, v)) * outer(v, v)   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nprint(P_1 @ z)\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 @ A\nprint(A)\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[1:, 1]\nv = z - norm(z) * hstack([1, zeros(m-2)])\nP_2 = eye(m-1) - (2 / dot(v, v)) * outer(v, v)\n\nWe now apply this reflector to rows 2 and below only.\n\nA[1:, 1:] = P_2 @ A[1:, 1:]\nprint(A)\n\nWe need to iterate the process for the last two columns.\n\nfor j in [2, 3]:\n    z = A[j:, j]\n    v = z - norm(z) * hstack([1, zeros(m-j-1)])\n    P = eye(m-j) - (2 / dot(v, v)) * outer(v, v)\n    A[j:, j:] = P @ A[j:, j:]\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)\nprint(R)\n\nYou may be wondering what happened to \\mathbf{Q} in \n\nDemo 3.4.1. Each Householder reflector is orthogonal but not full-size. We have to pad it out to represent algebraically the fact that a block of the first rows is left alone. Given a reflector \\mathbf{P}_k that is of square size m-k+1, we define\\mathbf{Q}_k =\n\\begin{bmatrix}\n\\mathbf{I}_{k-1} & \\boldsymbol{0} \\\\ \\boldsymbol{0} & \\mathbf{P}_k\n\\end{bmatrix}.\n\nIt is easy to show that \\mathbf{Q}_k is also orthogonal. Then the algorithm produces  \\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1 \\mathbf{A} = \\mathbf{R}.\n\nBut \\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1 is orthogonal too, and we multiply on the left by its transpose to get \\mathbf{A}=\\mathbf{Q}\\mathbf{R}, where \\mathbf{Q} =  (\\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1)^T. We don’t even need to form these matrices explicitly. Writing\\mathbf{Q}^T = \\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1 = \\mathbf{Q}_n \\Bigl( \\mathbf{Q}_{n-1}\\bigl(\\cdots (\\mathbf{Q}_1\\mathbf{I})\\cdots\\bigr)\\Bigr),\n\nwe can build \\mathbf{Q}^T iteratively by starting with the identity and doing the same row operations as on \\mathbf{A}. That process uses much less memory than building the \\mathbf{Q}_k matrices explicitly.\n\nThe algorithm we have described is encapsulated in \n\nFunction 3.4.1. There is one more refinement in it, however. As indicated by \n\n(3.4.2), the application of a reflector \\mathbf{P} to a vector does not require the formation of the matrix \\mathbf{P} explicitly.\n\nqrfact\n\nQR factorization by Householder reflections\n\n\"\"\"\n    qrfact(A)\n\nQR factorization by Householder reflections. Returns Q and R.\n\"\"\"\nfunction qrfact(A)\n    m,n = size(A)\n    Qt = diagm(ones(m))\n    R = float(copy(A))\n    for k in 1:n\n        z = R[k:m,k]\n        w = [ -sign(z[1])*norm(z) - z[1]; -z[2:end] ]\n        nrmw = norm(w)\n        if nrmw < eps() continue; end    # skip this iteration\n        v = w / nrmw;\n        # Apply the reflection to each relevant column of R and Q\n        for j in k:n\n            R[k:m,j] -= v*( 2*(v'*R[k:m,j]) )\n        end\n        for j in 1:m\n            Qt[k:m,j] -= v*( 2*(v'*Qt[k:m,j]) )\n        end\n    end\n    return Qt',triu(R)\nend\n\nQR factorization by Householder reflections\n\nfunction [Q,R] = qrfact(A)\r\n% QRFACT   QR factorization by Householder reflections.\r\n% (demo only--not efficient)\r\n% Input:\r\n%   A      m-by-n matrix\r\n% Output:\r\n%   Q,R    A=QR, Q m-by-m orthogonal, R m-by-n upper triangular\r\n\r\n[m,n] = size(A);\r\nQ = eye(m);\r\nfor k = 1:n\r\n  z = A(k:m,k);\r\n  v = [ -sign(z(1))*norm(z) - z(1); -z(2:end) ];\r\n  nrmv = norm(v);\r\n  if nrmv < eps, continue, end       % nothing is done in this iteration\r\n  v = v / nrmv;                      % removes v'*v in other formulas\r\n  % Apply the reflection to each relevant column of A and Q\r\n  for j = 1:n\r\n    A(k:m,j) = A(k:m,j) - v*( 2*(v'*A(k:m,j)) );\r\n  end\r\n  for j = 1:m\r\n    Q(k:m,j) = Q(k:m,j) - v*( 2*(v'*Q(k:m,j)) );\r\n  end\r\nend\r\n\r\nQ = Q';\r\nR = triu(A);                         % enforce exact triangularity\n\nQR factorization by Householder reflections\n\n        qrfact(A)\n\n    QR factorization by Householder reflections. Returns Q and R.\n    \"\"\"\n    m, n = A.shape\n    Qt = np.eye(m)\n    R = np.copy(A)\n    for k in range(n):\n        z = R[k:, k]\n        w = np.stack((-np.sign(z[0]) * np.linalg.norm(z) - z[0], -z[1:]))\n        nrmw = np.linalg.norm(w)\n        if nrmw < np.finfo(float).eps: continue    # skip this iteration\n        v = w / nrmw\n        # Apply the reflection to each relevant column of R and Q\n        for j in range(k, n):\n            R[k:, j] -= 2 * np.dot(v, R[k:, j]) * v\n        for j in range(m):\n            Qt[k:, j] -= 2 * np.dot(v, Qt[k:, j]) * v \n    return Qt.T, np.triu(R)\n","type":"content","url":"/house#factorization-algorithm","position":5},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Q-less QR and least squares"},"type":"lvl2","url":"/house#q-less-qr-and-least-squares","position":6},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Q-less QR and least squares"},"content":"In \n\nDemo 3.3.1 it was seen that the \\mathbf{Q} output of Julia’s qr function is not a standard matrix. The reason is that Equation \n\n(3.3.8) shows that in order to solve the linear least-squares problem, all we need from \\mathbf{Q} is the computation of \\hat{\\mathbf{Q}}^T\\mathbf{b}. Referring again to \n\n(3.4.10) and \n\n(3.4.2), the special structure of the reflectors is such that for this computation, we only need to apply code similar to lines 18 and 21 of \n\nFunction 3.4.1 for each of the Householder vectors \\mathbf{v} that is constructed.\n\nThis observation leads to the idea of the Q-less QR factorization, in which the full or thin \\mathbf{Q} is never computed explicitly. This is the variant used by Julia’s qr. The returned value Q used within \n\nFunction 3.3.2 is of a special type that allows Julia to perform Q'*b efficiently for the least-squares solution.\n\nIn \n\nExercise 8 you are asked to derive the following result about the Q-less factorization.\n\nQ-less QR factorization by Householder reflections takes \\sim(2mn^2-\\frac{2}{3}n^3) flops.\n\nThe flop count quoted in \n\nTheorem 3.4.2 dominates the running time for least-squares solution via QR. Compared to the count from \n\nTheorem 3.2.3 for solution by the normal equations, the flops are essentially identical when m=n, but the QR solution is about twice the cost when m\\gg n. The redeeming quality of the QR route is better stability, which we do not discuss here.","type":"content","url":"/house#q-less-qr-and-least-squares","position":7},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Exercises"},"type":"lvl2","url":"/house#exercises","position":8},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Exercises"},"content":"⌨ Find a Householder reflector \\mathbf{P} such that\\mathbf{P}\n\\begin{bmatrix}\n  2 \\\\ 9 \\\\ -6\n\\end{bmatrix} =\n\\begin{bmatrix}\n  11\\\\0\\\\0\n\\end{bmatrix}.\n\n✍ Prove the unfinished items in \n\nTheorem 3.4.1, namely that a Householder reflector \\mathbf{P} is symmetric and orthogonal.\n\n✍ Let \\mathbf{P} be a Householder reflector as in \n\n(3.4.1).\n\n(a) Find a vector \\mathbf{u} such that \\mathbf{P}\\mathbf{u} = -\\mathbf{u}. (\n\nFigure 3.4.1 may be of help.)\n\n(b) What algebraic condition is necessary and sufficient for a vector \\mathbf{x} to satisfy \\mathbf{P}\\mathbf{x}=\\mathbf{x}? In n dimensions, how many such linearly independent vectors are there?\n\n✍ Under certain circumstances, computing the vector \\mathbf{v} in \n\n(3.4.4) could lead to subtractive cancellation, which is why line 12 of \n\nFunction 3.4.1 reads as it does. Devise an example that causes subtractive cancellation if \n\n(3.4.4) is used.\n\n✍ Suppose QR factorization is used to compute the solution of a square linear system, \\mathbf{A}\\mathbf{x}=\\mathbf{b}, i.e., let m=n.\n\n(a) Find an asymptotic flop count for this procedure, and compare it to the LU factorization algorithm.\n\n(b) Show that \\kappa_2(\\mathbf{A}) = \\kappa_2(\\mathbf{R}).\n\n✍ Prove that \\kappa_2(\\mathbf{A})=\\kappa_2(\\mathbf{R}) when \\mathbf{A} is not square.  (Be careful! You can’t take an inverse of \\mathbf{A} or \\mathbf{R}.)\n\nAnother algorithmic technique for orthogonally introducing zeros into a matrix is the   Givens rotation. Given a 2-vector [\\alpha,\\, \\beta], it defines an angle θ such that\\begin{bmatrix}\n  \\cos(\\theta) & \\sin(\\theta) \\\\ -\\sin(\\theta) & \\cos(\\theta)\n\\end{bmatrix}\n\\begin{bmatrix}\n  \\alpha \\\\ \\beta\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  \\sqrt{\\alpha^2 + \\beta^2} \\\\ 0\n\\end{bmatrix}.\n\n(a) ✍ Given α and β, show how to compute \\cos \\theta and \\sin \\theta without evaluating any trig functions.\n\n(b) ⌨ Given the vector \\mathbf{z}=[1\\;2\\;3\\;4\\;5]^T, use Julia to find a sequence of Givens rotations that transforms \\mathbf{z} into the vector \\| \\mathbf{z} \\|\\mathbf{e}_1. (Hint: You can operate only on pairs of elements at a time, introducing a zero at the lower of the two positions.)\n\n✍ Derive the result of \n\nTheorem 3.4.2 by analyzing \n\nFunction 3.4.1 without lines 20–22.\n\n✍ Suppose m=Kn for constant K \\ge 1 as both m and n go to infinity. Show that the flop counts from \n\nTheorem 3.4.2  and \n\nTheorem 3.2.3 have a ratio of 1 when K=1 and approaches 2 as K\\to \\infty.","type":"content","url":"/house#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-2","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The least-squares problem has been widely studied and used, and only seems to become more important in this era of ever-increasing amounts of data.  A good reference for numerical methods is the monograph by Björck \n\nBjörck (1996).  Some theoretical results can be found in Higham \n\nHigham (2002); a brief and advanced discussion can be found in Golub and Van Loan \n\nGolub & Van Loan (1996).\n\nNote that a vast literature can also be found in statistics for what is referred to as data regression, or simply regression. Nonlinear methods for least-squares fitting of data will be discussed in the following chapter.\n\nIn modern applications one may have to deal with so-called online fitting, in which new data must continually be incorporated with old. More recent sources address related issues, e.g., in  Hansen, Pereyra, and Scherer \n\nHansen et al. (2013) and in Teunissen \n\nTeunissen (2001).  The problem of geodesy and GPS positioning are discussed in some detail in Strang and Borre \n\nStrang & Borre (1997); for these applications, they describe how the updating of least squares leads to Kalman filtering.","type":"content","url":"/next-2","position":1},{"hierarchy":{"lvl1":"The normal equations"},"type":"lvl1","url":"/normaleqns","position":0},{"hierarchy":{"lvl1":"The normal equations"},"content":"We now solve the general linear least-squares problem in \n\nDefinition 3.1.1. That is, given \\mathbf{A}\\in\\mathbb{R}^{m \\times n} and \\mathbf{b}\\in\\mathbb{R}^m, with m>n, find the \\mathbf{x}\\in\\mathbb{R}^n that minimizes \\| \\mathbf{b} - \\mathbf{A}\\mathbf{x} \\|_2.\n\nThere is a concise explicit solution. In the following proof we make use of the elementary algebraic fact that for two vectors \\mathbf{u} and \\mathbf{v},  (\\mathbf{u}+\\mathbf{v})^T(\\mathbf{u}+\\mathbf{v}) = \\mathbf{u}^T\\mathbf{u} + \\mathbf{u}^T\\mathbf{v} + \\mathbf{v}^T\\mathbf{u}\n  + \\mathbf{v}^T\\mathbf{v} = \\mathbf{u}^T\\mathbf{u} + 2\\mathbf{v}^T\\mathbf{u} + \\mathbf{v}^T\\mathbf{v}.\n\nIf \\mathbf{x} satisfies \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=\\boldsymbol{0}, then \\mathbf{x} solves the linear least-squares problem, i.e., \\mathbf{x} minimizes \\| \\mathbf{b}-\\mathbf{A}\\mathbf{x} \\|_2.\n\nLet \\mathbf{y}\\in \\mathbb{R}^n be any vector. Then\n\\mathbf{A}(\\mathbf{x}+\\mathbf{y})-\\mathbf{b}=\\mathbf{A}\\mathbf{x}-\\mathbf{b}+\\mathbf{A}\\mathbf{y}, and\\begin{split}\n    \\| \\mathbf{A}(\\mathbf{x}+\\mathbf{y})-\\mathbf{b} \\|_2^2 &=\n    [(\\mathbf{A}\\mathbf{x}-\\mathbf{b})+(\\mathbf{A}\\mathbf{y})]^T[(\\mathbf{A}\\mathbf{x}-\\mathbf{b})+(\\mathbf{A}\\mathbf{y})]\\\\\n    &= (\\mathbf{A}\\mathbf{x}-\\mathbf{b})^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b}) + 2(\\mathbf{A}\\mathbf{y})^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b}) + (\\mathbf{A}\\mathbf{y})^T(\\mathbf{A}\\mathbf{y})\\\\\n    &= \\| \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|_2^2 + 2\\mathbf{y}^T \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b}) + \\| \\mathbf{A}\\mathbf{y} \\|_2^2 \\\\\n    &= \\| \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|_2^2 + \\| \\mathbf{A}\\mathbf{y} \\|_2^2 \\\\\n    & \\ge \\| \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|_2^2.\n  \\end{split}\n\nNormal equations\n\nGiven \\mathbf{A}\\in \\real^{m\\times n} and \\mathbf{b}\\in \\real^{m}, the normal equations for the linear least-squares problem \\operatorname{argmin}\\| \\mathbf{b}- \\mathbf{A} \\mathbf{x}\\| are \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=\\boldsymbol{0}, or equivalently,\\mathbf{A}^T\\mathbf{A}\\mathbf{x}=\\mathbf{A}^T\\mathbf{b}.\n\nThe normal equations have a geometric interpretation, as shown in \n\nFigure 3.2.1. The vector in the range (column space) of \\mathbf{A} that lies closest to \\mathbf{b} makes the vector difference \\mathbf{A}\\mathbf{x}-\\mathbf{b} perpendicular to the range. Thus for any \\mathbf{z}, we must have (\\mathbf{A} \\mathbf{z})^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=0, which is satisfied if \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=\\boldsymbol{0}.\n\n\n\nFigure 3.2.1:Geometry of the normal equations. The smallest residual is orthogonal to the range of the matrix \\mathbf{A}.","type":"content","url":"/normaleqns","position":1},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Pseudoinverse and definiteness"},"type":"lvl2","url":"/normaleqns#pseudoinverse-and-definiteness","position":2},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Pseudoinverse and definiteness"},"content":"If we associate the left-hand side of the normal equations as (\\mathbf{A}^T\\mathbf{A})\\,\\mathbf{x}, we recognize \n\n(3.2.3) as a square n\\times n linear system to solve for \\mathbf{x}.\n\nPseudoinverse\n\nIf \\mathbf{A}\\in\\real^{m\\times n}  with m>n, its pseudoinverse is the n\\times m matrix\\mathbf{A}^+ = (\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T.\n\nMathematically, the overdetermined least-squares problem \\mathbf{A}\\mathbf{x}\\approx \\mathbf{b} has the solution \\mathbf{x}=\\mathbf{A}^+\\mathbf{b}.\n\nComputationally we can generalize the observation about Julia from Chapter 2: backslash is equivalent mathematically to left-multiplication by the inverse (in the square case) or pseudoinverse (in the rectangular case) of a matrix. One can also compute the pseudoinverse directly using pinv, but as with matrix inverses, this is rarely necessary in practice.\n\nThe matrix \\mathbf{A}^T\\mathbf{A} appearing in the pseudoinverse has some important properties.\n\nFor any real m\\times n matrix \\mathbf{A} with m\\ge n, the following are true:\n\n\\mathbf{A}^T\\mathbf{A} is symmetric.\n\n\\mathbf{A}^T \\mathbf{A} is singular if and only if the columns of \\mathbf{A} are linearly dependent. (Equivalently, if and only if the rank of \\mathbf{A} is less than n.)\n\nIf \\mathbf{A}^T\\mathbf{A} is nonsingular, then it is positive definite.\n\nThe first part is left as \n\nExercise 3. For the second part, suppose that \\mathbf{A}^T\\mathbf{A}\\mathbf{z}=\\boldsymbol{0}. Note that \\mathbf{A}^T\\mathbf{A} is singular if and only if \\mathbf{z} may be nonzero. Left-multiplying by \\mathbf{z}^T, we find that0 = \\mathbf{z}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{z}=(\\mathbf{A}\\mathbf{z})^T(\\mathbf{A}\\mathbf{z}) = \\| \\mathbf{A}\\mathbf{z} \\|_2^2,\n\nwhich is equivalent to \\mathbf{A}\\mathbf{z}=\\boldsymbol{0}. Then \\mathbf{z} may be nonzero if and only if the columns of \\mathbf{A} are linearly dependent.\n\nFinally, we can repeat the manipulations above to show that for any nonzero n-vector \\mathbf{v}, \\mathbf{v}^T(\\mathbf{A}^T\\mathbf{A})\\mathbf{v}=\\| \\mathbf{A}\\mathbf{v} \\|_2^2\\ge 0, and equality is not possible thanks to the second part of the theorem.","type":"content","url":"/normaleqns#pseudoinverse-and-definiteness","position":3},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Implementation"},"type":"lvl2","url":"/normaleqns#implementation","position":4},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Implementation"},"content":"The definition of the pseudoinverse involves taking the inverse of a matrix, so it is not advisable to use the pseudoinverse computationally. Instead, we use the definition of the normal equations to set up a linear system, which we already know how to solve. In summary, the steps for solving the linear least squares problem \\mathbf{A}\\mathbf{x}\\approx\\mathbf{b} are:\n\nSolution of linear least squares by the normal equations\n\nCompute \\mathbf{N}=\\mathbf{A}^T\\mathbf{A}.\n\nCompute \\mathbf{z} = \\mathbf{A}^T\\mathbf{b}.\n\nSolve the n\\times n linear system \\mathbf{N}\\mathbf{x} = \\mathbf{z} for \\mathbf{x}.\n\nSteps 1 and 3 of \n\nAlgorithm 3.2.1 dominate the flop count.\n\nIn the last step we can exploit the fact, proved in \n\nTheorem 3.2.2, that \\mathbf{N} is symmetric and positive definite, and use Cholesky factorization as in \n\nExploiting matrix structure. This detail is included in \n\nFunction 3.2.2.\n\nlsnormal\n\nSolution of least squares by the normal equations\n\n\"\"\"\n    lsnormal(A,b)\n\nSolve a linear least-squares problem by the normal equations.\nReturns the minimizer of ||b-Ax||.\n\"\"\"\nfunction lsnormal(A,b)\n    N = A'*A;  z = A'*b;\n    R = cholesky(N).U\n    w = forwardsub(R',z)                   # solve R'z=c\n    x = backsub(R,w)                       # solve Rx=z\n    return x\nend\n\nAbout the code\n\nThe syntax on line 9 is a field reference to extract the matrix we want from the structure returned by cholesky.\n\nSolution of least squares by the normal equations\n\nfunction x = lsnormal(A,b)\r\n% LSNORMAL   Solve linear least squares by normal equations.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\nN = A'*A;  z = A'*b;\r\nR = chol(N);\r\nw = forwardsub(R',z);                   % solve R'z=c\r\nx = backsub(R,w);                       % solve Rx=z\n\nSolution of least squares by the normal equations\n\n    lsnormal(A,b)\n    \n    Solve a linear least squares problem by the normal equations. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    N = A.T @ A\n    z = A.T @ b\n    R = scipy.linalg.cholesky(N)\n    w = forwardsub(R.T, z)                   # solve R'z=c\n    x = backsub(R, w)                        # solve Rx=z\n    return x\n\ndef lsqrfact(A,b):\n\nAbout the code\n\ncholesky is imported from scipy.linalg.\n\nSolution of linear least squares by the normal equations takes \\sim (mn^2 + \\frac{1}{3}n^3) flops.","type":"content","url":"/normaleqns#implementation","position":5},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Conditioning and stability"},"type":"lvl2","url":"/normaleqns#conditioning-and-stability","position":6},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Conditioning and stability"},"content":"We have already used A\\b as the native way to solve the linear least-squares problem \\mathbf{A}\\mathbf{x}\\approx\\mathbf{b} in Julia. The algorithm employed by the backslash does not proceed through the normal equations, because of instability.\n\nThe conditioning of the linear least-squares problem relates changes in the solution \\mathbf{x} to those in the data, \\mathbf{A} and \\mathbf{b}. A full accounting of the condition number is too messy to present here, but we can get the main idea. We start by generalizing our previous definition of the matrix condition number.\n\nMatrix condition number (rectangular case)\n\nIf \\mathbf{A} is m\\times n with m > n, then its condition number is defined to be\\kappa(\\mathbf{A}) = \\|\\mathbf{A}\\|_2 \\cdot \\|\\mathbf{A}^{+}\\|_2.\n\nIf the rank of  \\mathbf{A} is less than n (i.e., if it has linearly dependent columns), then \\kappa(\\mathbf{A})=\\infty.\n\nProvided that the minimum residual norm \\|\\mathbf{b}-\\mathbf{A}\\mathbf{x}\\| is relatively small, the conditioning of the linear least-squares problem is close to \\kappa(\\mathbf{A}).\n\nAs an algorithm, the normal equations begin by computing the data for the n\\times n system (\\mathbf{A}^T\\mathbf{A})\\mathbf{x} = \\mathbf{A}^T \\mathbf{b}. When these equations are solved, perturbations to the data can be amplified by a factor \\kappa(\\mathbf{A}^T\\mathbf{A}).\n\nThe following can be proved using results in Chapter 7.\n\nCondition number in the normal equations\n\nIf \\mathbf{A} is m\\times n with m > n, then\\kappa(\\mathbf{A}^T\\mathbf{A}) = \\kappa(\\mathbf{A})^2.\n\nThis squaring of the condition number in the normal equations is the cause of instability. If \\kappa(\\mathbf{A}) is large, the squaring of it can destabilize the normal equations: while the solution of the least-squares problem is sensitive, finding it via the normal equations makes it doubly so.\n\nInstability in the normal equations\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = range(0, 3, 400)\nf = [ x->sin(x)^2, x->cos((1+1e-7)*x)^2, x->1. ]\nA = [ f(t) for t in t, f in f ]\n@show κ = cond(A);\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1., 2, 1]\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b\n@show observed_error = norm(x_BS - x) / norm(x);\n@show error_bound = κ * eps();\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A' * A\nx_NE = N \\ (A'*b)\n@show observed_err = norm(x_NE - x) / norm(x);\n@show digits = -log10(observed_err);\n\nInstability in the normal equations\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nkappa = cond(A)\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1; 2; 1];\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b;\nobserved_err = norm(x_BS - x) / norm(x)\nmax_err = kappa * eps\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A'*A;\nx_NE = N\\(A'*b);\nobserved_err = norm(x_NE - x) / norm(x)\ndigits = -log10(observed_err)\n\nInstability in the normal equations\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nfrom numpy.linalg import cond\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nkappa = cond(A)\nprint(f\"cond(A) is {kappa:.3e}\")\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = array([1, 2, 1])\nb = A @ x\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nfrom numpy.linalg import lstsq\nx_BS = lstsq(A, b, rcond=None)[0]\nprint(f\"observed error: {norm(x_BS - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {kappa * finfo(float).eps:.3e}\")\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A.T @ A\nx_NE = solve(N, A.T @ b)\nrelative_err = norm(x_NE - x) / norm(x)\nprint(f\"observed error: {relative_err:.3e}\")\nprint(f\"accurate digits: {-log10(relative_err):.2f}\")","type":"content","url":"/normaleqns#conditioning-and-stability","position":7},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Exercises"},"type":"lvl2","url":"/normaleqns#exercises","position":8},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Exercises"},"content":"✍ Work out the least-squares solution when\\mathbf{A} = \\begin{bmatrix}\n  2 & -1 \\\\\n  0 & 1 \\\\\n  -2 & 2\n\\end{bmatrix}, \\qquad \\mathbf{b} =\n\\begin{bmatrix}\n  1\\\\-5\\\\6\n\\end{bmatrix}.\n\n✍ Use \n\n(3.2.4) to find the pseudoinverse \\mathbf{A}^+ of the matrix \\mathbf{A}=\\begin{bmatrix}1&-2&3\\end{bmatrix}^T.\n\n✍ Prove the first statement of \n\nTheorem 3.2.2: \\mathbf{A}^T\\mathbf{A} is symmetric for any m\\times n matrix \\mathbf{A} with m \\ge n.\n\n✍ Prove that if \\mathbf{A} is an invertible square matrix, then \\mathbf{A}^+=\\mathbf{A}^{-1}.\n\n(a) ✍ Show that for any m\\times n \\mathbf{A} with m>n for which \\mathbf{A}^T\\mathbf{A} is nonsingular, \\mathbf{A}^+\\mathbf{A} is the n\\times n identity.\n\n(b) ⌨ Show using an example in Julia that \\mathbf{A}\\mathbf{A}^+ is not an identity matrix. (This matrix has rank no greater than n, so it can’t be an m\\times m identity.)\n\n✍ Prove that the vector \\mathbf{A}\\mathbf{A}^+\\mathbf{b} is the vector in the column space (i.e., range) of \\mathbf{A} that is closest to \\mathbf{b} in the sense of the 2-norm.\n\n✍ Show that the flop count for \n\nFunction 3.2.2 is asymptotically \\sim 2m n^2 + \\tfrac{1}{3}n^3. (In finding the asymptotic count you can ignore terms like m n whose total degree is less than 3.)\n\n⌨ Let t_1,\\ldots,t_m be m equally spaced points in [0,2\\pi]. In this exercise, use m=500.\n\n(a) Let \\mathbf{A}_\\beta be the matrix in \n\n(3.1.2) that corresponds to fitting data with the function c_1 + c_2 \\sin(t) + c_3 \\cos(\\beta t). Using the identity \n\n(3.2.7), make a table of the condition numbers of \\mathbf{A}_\\beta for \\beta = 2,1.1,1.01,\\ldots,1+10^{-8}.\n\n(b) Repeat part (a) using the fitting function c_1 + c_2 \\sin^2(t) + c_3 \\cos^2(\\beta t).\n\n(c) Why does it make sense that \\kappa\\bigl(\\mathbf{A}_\\beta\\bigr)\\to \\infty as \\beta\\to 1 in part (b) but not in part (a)?\n\n✍ ⌨  When \\mathbf{A} is m\\times n with rank less than n, the pseudoinverse is still defined and can be computed using pinv from LinearAlgebra. However, the behavior in this case is not always intuitive. Let\\mathbf{A}_s =\n\\begin{bmatrix}\n  1 & 1 \\\\ 0 & 0 \\\\ 0 & s\n\\end{bmatrix}.\n\nThen \\mathbf{A}_0 has rank equal to 1. Demonstrate experimentally that \\mathbf{A}_0^+\\neq \\lim_{s\\to 0} \\mathbf{A}_s^+.","type":"content","url":"/normaleqns#exercises","position":9},{"hierarchy":{"lvl1":"Overdetermined linear systems"},"type":"lvl1","url":"/overview-2","position":0},{"hierarchy":{"lvl1":"Overdetermined linear systems"},"content":"I must have hit her pretty close to the mark to get her all riled up like that, huh, kid?\n\nHan Solo, The Empire Strikes Back\n\nSo far we have considered \\mathbf{A}\\mathbf{x}=\\mathbf{b} only when \\mathbf{A} is a square matrix. In this chapter we consider how to interpret and solve the problem for an m\\times n matrix where m>n—and in practice, m is often much larger than n. This is called an overdetermined linear system because, in general, the system has more equations to satisfy than the variables allow. The complementary underdetermined case m<n turns up less frequently and will not be considered in this book.\n\nSince we cannot solve all of the system’s equations, we need to define what the “best possible” answer is. There are multiple useful options, but the most important version of the overdetermined problem occurs using the least squares—the sum of the squares of the equation residuals is minimized. This is far from an arbitrary choice. Mathematically, we recognize the sum-of-squares as a vector 2-norm and therefore tied to inner products; physically, the 2-norm may coincide with energy, which is often minimized by natural systems; and statistically, least squares leads to the estimates of maximum likelihood for certain models. Furthermore, the solution of the least-squares problem requires only linear algebra and is about as easily to compute as in the square case.\n\nThe linear least-squares problem serves as our introduction to the vast field of optimization. It is one of the simplest problems of this type. We will see an extension to a nonlinear version in the next chapter.","type":"content","url":"/overview-2","position":1},{"hierarchy":{"lvl1":"The QR factorization"},"type":"lvl1","url":"/qr","position":0},{"hierarchy":{"lvl1":"The QR factorization"},"content":"Sets of vectors satisfying a certain property are useful both theoretically and computationally.\n\nOrthogonal vectors\n\nTwo vectors \\mathbf{u} and \\mathbf{v} in \\mathbb{R}^n are orthogonal if \\mathbf{u}^T\\mathbf{v}=0. We say that a collection of vectors \\mathbf{q}_1,\\ldots,\\mathbf{q}_k is orthogonal ifi \\neq j \\quad \\Rightarrow \\quad \\mathbf{q}_i^T\\mathbf{q}_j = 0.\n\nIf \n\n(3.3.1) applies and also \\mathbf{q}_i^T\\mathbf{q}_i=1 for all i=1,\\ldots,n, we say the vectors are orthonormal.\n\nIn two and three dimensions, orthogonality is the same as perpendicularity.\n\nOrthogonal vectors simplify inner products. For example, if \\mathbf{q}_1 and \\mathbf{q}_2 are orthogonal, then\\| \\mathbf{q}_1 - \\mathbf{q}_2 \\|_2^2 = (\\mathbf{q}_1-\\mathbf{q}_2)^T(\\mathbf{q}_1-\\mathbf{q}_2)\n= \\mathbf{q}_1^T\\mathbf{q}_1 - 2 \\mathbf{q}_1^T\\mathbf{q}_2 + \\mathbf{q}_2^T\\mathbf{q}_2\n= \\|\\mathbf{q}_1\\|_2^2 + \\|\\mathbf{q}_2\\|_2^2.\n\nAs in the rest of this chapter, we will be using the 2-norm exclusively.\n\nEquation \n\n(3.3.2) is the key to the computational attractiveness of orthogonality. \n\nFigure 3.3.1 shows how nonorthogonal vectors can allow a multidimensional version of subtractive cancellation, in which \\|\\mathbf{x}-\\mathbf{y}\\| is much smaller than \\|\\mathbf{x}\\| and \\|\\mathbf{y}\\|. As the figure illustrates, orthogonal vectors do not allow this phenomenon. By \n\n(3.3.2), the magnitude of a vector difference or sum is larger than the magnitudes of the original vectors.\n\n\n\nFigure 3.3.1:Nonorthogonal vectors can cause cancellation when subtracted, but orthogonal vectors never do.\n\nAddition and subtraction of vectors are guaranteed to be well conditioned when the vectors are orthogonal.","type":"content","url":"/qr","position":1},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal and ONC matrices"},"type":"lvl2","url":"/qr#orthogonal-and-onc-matrices","position":2},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal and ONC matrices"},"content":"Statements about orthogonal vectors are often made more easily in matrix form. Let \\mathbf{Q} be an n\\times k matrix whose columns \\mathbf{q}_1, \\ldots, \\mathbf{q}_k are orthogonal vectors. The orthogonality conditions \n\n(3.3.1) become simply that \\mathbf{Q}^T\\mathbf{Q} is a diagonal matrix, since\\mathbf{Q}^T \\mathbf{Q} =\n\\begin{bmatrix}\n\\mathbf{q}_1^T \\\\[1mm] \\mathbf{q}_2^T \\\\ \\vdots \\\\ \\mathbf{q}_k^T\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{q}_1 & \\mathbf{q}_2 &  \\cdots & \\mathbf{q}_k\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{q}_1^T\\mathbf{q}_1 & \\mathbf{q}_1^T\\mathbf{q}_2 & \\cdots & \\mathbf{q}_1^T\\mathbf{q}_k \\\\[1mm]\n\\mathbf{q}_2^T\\mathbf{q}_1 & \\mathbf{q}_2^T\\mathbf{q}_2 & \\cdots & \\mathbf{q}_2^T\\mathbf{q}_k \\\\\n\\vdots & \\vdots & & \\vdots \\\\\n\\mathbf{q}_k^T\\mathbf{q}_1 & \\mathbf{q}_k^T\\mathbf{q}_2 & \\cdots & \\mathbf{q}_k^T\\mathbf{q}_k\n\\end{bmatrix}.\n\nIf the columns of \\mathbf{Q} are orthonormal, then \\mathbf{Q}^T\\mathbf{Q} is the k\\times k identity matrix. This is such an important property that we will break with common practice here and give this type of matrix a name.\n\nONC matrix\n\nAn ONC matrix is one whose columns are an orthonormal set of vectors.\n\nONC matrix\n\nSuppose \\mathbf{Q} is a real n\\times k ONC matrix (matrix with orthonormal columns). Then:\n\n\\mathbf{Q}^T\\mathbf{Q} = \\mathbf{I} (k\\times k identity).\n\n\\| \\mathbf{Q}\\mathbf{x} \\|_2 = \\| \\mathbf{x} \\|_2 for all k-vectors \\mathbf{x}.\n\n\\| \\mathbf{Q} \\|_2=1.\n\nThe first part is derived above. The second part follows a pattern that has become well established by now:\\| \\mathbf{Q}\\mathbf{x} \\|_2^2 = (\\mathbf{Q}\\mathbf{x})^T(\\mathbf{Q}\\mathbf{x}) = \\mathbf{x}^T \\mathbf{Q}^T \\mathbf{Q} \\mathbf{x} = \\mathbf{x}^T \\mathbf{I} \\mathbf{x} = \\| \\mathbf{x} \\|_2^2.\n\nThe last part of the theorem is left to the exercises.\n\nOf particular interest is a square ONC matrix.\n\nAn orthogonal matrix is a square matrix with orthonormal columns.\n\nOrthogonal matrices have properties beyond \n\nTheorem 3.3.1.\n\nOrthogonal matrix\n\nSuppose \\mathbf{Q} is an n\\times n real orthogonal matrix. Then:\n\n\\mathbf{Q}^T = \\mathbf{Q}^{-1}.\n\n\\mathbf{Q}^T is also an orthogonal matrix.\n\n\\kappa(\\mathbf{Q})=1 in the 2-norm.\n\nFor any other n\\times n matrix \\mathbf{A}, \\| \\mathbf{A}\\mathbf{Q} \\|_2=\\| \\mathbf{A} \\|_2.\n\nIf \\mathbf{U} is another n\\times n orthogonal matrix, then \\mathbf{Q}\\mathbf{U} is also orthogonal.\n\nSince \\mathbf{Q} is an ONC matrix, \\mathbf{Q}^T\\mathbf{Q}=\\mathbf{I}. All three matrices are n\\times n, so \\mathbf{Q}^{-1}=\\mathbf{Q}^T. The proofs of the other statements are left to the exercises.","type":"content","url":"/qr#orthogonal-and-onc-matrices","position":3},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal factorization"},"type":"lvl2","url":"/qr#orthogonal-factorization","position":4},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal factorization"},"content":"Now we come to another important way to factor a matrix: the QR factorization. As we will show below, the QR factorization plays a role in linear least squares analogous to the role of LU factorization in linear systems.\n\nQR factorization\n\nEvery real m\\times n matrix \\mathbf{A} (m\\ge n) can be written as \\mathbf{A}=\\mathbf{Q}\\mathbf{R}, where \\mathbf{Q} is an m\\times m orthogonal matrix and \\mathbf{R} is an m\\times n upper triangular matrix.\n\nIn most introductory books on linear algebra, the QR factorization is derived through a process known as Gram–Schmidt orthogonalization. However, while it is an important tool for theoretical work, the Gram–Schmidt process is numerically unstable. We will consider an alternative construction in \n\nComputing QR factorizations.\n\nWhen m is much larger than n, which is often the case, there is a compressed form of the factorization that is more efficient. In the product\\mathbf{A} =\n\\begin{bmatrix}\n\\mathbf{q}_1 & \\mathbf{q}_2 & \\cdots & \\mathbf{q}_m\n\\end{bmatrix}\n\\begin{bmatrix}\nr_{11} & r_{12} & \\cdots & r_{1n} \\\\\n0 & r_{22} & \\cdots &  r_{2n} \\\\\n\\vdots & & \\ddots & \\vdots\\\\\n0 & 0 & \\cdots & r_{nn} \\\\\n0 & 0 & \\cdots & 0 \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\n0 & 0 & \\cdots & 0\n\\end{bmatrix},\n\nthe vectors \\mathbf{q}_{n+1},\\ldots,\\mathbf{q}_m always get multiplied by zero. Nothing about \\mathbf{A} is lost if we delete them and reduce the factorization to the equivalent form\\mathbf{A} =\n\\begin{bmatrix}\n\\mathbf{q}_1 & \\mathbf{q}_2 & \\cdots & \\mathbf{q}_n\n\\end{bmatrix}\n\\begin{bmatrix}\nr_{11} & r_{12} & \\cdots & r_{1n} \\\\\n0 & r_{22} & \\cdots &  r_{2n} \\\\\n\\vdots & & \\ddots & \\vdots\\\\\n0 & 0 & \\cdots & r_{nn}\n\\end{bmatrix} = \\hat{\\mathbf{Q}} \\hat{\\mathbf{R}}.\n\nThin QR factorization\n\nThe thin QR factorization is \\mathbf{A} = \\hat{\\mathbf{Q}} \\hat{\\mathbf{R}}, where \\hat{\\mathbf{Q}} is m\\times n and ONC, and \\hat{\\mathbf{R}} is n\\times n and upper triangular.\n\nQR factorization\n\nJulia provides access to both the thin and full forms of the QR factorization.\n\nA = rand(1.:9., 6, 4)\n@show m,n = size(A);\n\nHere is a standard call:\n\nQ,R = qr(A);\nQ\n\nR\n\nIf you look carefully, you see that we seemingly got a full \\mathbf{Q} but a thin \\mathbf{R}. However, the \\mathbf{Q} above is not a standard matrix type. If you convert it to a true matrix, then it reverts to the thin form.\n\nTo enter the accented character Q̂, type Q\\hat followed by Tab.\n\nQ̂ = Matrix(Q)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nopnorm(Q' * Q - I)\n\nThe thin \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC:\n\nQ̂' * Q̂ - I\n\nQR factorization\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = magic(5);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nHere is the full form:\n\n[Q, R] = qr(A);\nszQ = size(Q), szR = size(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nQTQ = Q' * Q\nnorm(QTQ - eye(m))\n\nWith a second input argument given to qr, the thin form is returned. (This is usually the one we want in practice.)\n\n[Q_hat, R_hat] = qr(A, 0);\nszQ_hat = size(Q_hat), szR_hat = size(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nQ_hat' * Q_hat - eye(n)\n\nQR factorization\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nA.shape\n\nHere is the full form:\n\nfrom numpy.linalg import qr\nQ, R = qr(A, \"complete\")\nprint(f\"size of Q is {Q.shape}\")\nprint(\"R:\")\nprint(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nprint(f\"norm of (Q^T Q - I) is {norm(Q.T @ Q - eye(6)):.3e}\")\n\nThe default for qr, and the one you usually want, is the thin form.\n\nQ_hat, R_hat = qr(A)\nprint(f\"size of Q_hat is {Q_hat.shape}\")\nprint(\"R_hat:\")\nprint(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nprint(f\"norm of (Q_hat^T Q_hat - I) is {norm(Q_hat.T @ Q_hat - eye(4)):.3e}\")","type":"content","url":"/qr#orthogonal-factorization","position":5},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Least squares and QR"},"type":"lvl2","url":"/qr#least-squares-and-qr","position":6},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Least squares and QR"},"content":"If we substitute the thin factorization \n\n(3.3.6) into the normal equations \n\n(3.2.3), we can simplify expressions a great deal.\\begin{split}\n  \\mathbf{A}^T\\mathbf{A} \\mathbf{x} &= \\mathbf{A}^T \\mathbf{b}, \\\\\n  \\hat{\\mathbf{R}}^T \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} \\hat{\\mathbf{R}} \\mathbf{x} &= \\hat{\\mathbf{R}}^T \\hat{\\mathbf{Q}}^T \\mathbf{b}, \\\\\n  \\hat{\\mathbf{R}}^T \\hat{\\mathbf{R}} \\mathbf{x}& = \\hat{\\mathbf{R}}^T \\hat{\\mathbf{Q}}^T \\mathbf{b}.\n\\end{split}\n\nIn order to have the normal equations be well posed, we require that \\mathbf{A} is not rank-deficient (as proved in \n\nTheorem 3.2.2). This is enough to guarantee that \\hat{\\mathbf{R}} is nonsingular (see \n\nExercise 4). Therefore, its transpose is nonsingular as well, and we arrive at\\hat{\\mathbf{R}} \\mathbf{x}=\\hat{\\mathbf{Q}}^T \\mathbf{b}.\n\nSolution of linear least squares by thin QR\n\nCompute the thin QR factorization \\hat{\\mathbf{Q}}\\hat{\\mathbf{R}}=\\mathbf{A}.\n\nCompute \\mathbf{z} = \\hat{\\mathbf{Q}}^T\\mathbf{b}.\n\nSolve the n\\times n linear system \\hat{\\mathbf{R}}\\mathbf{x} = \\mathbf{z} for \\mathbf{x}.\n\nThis algorithm is implemented in \n\nFunction 3.3.2. It is essentially the algorithm used internally by Julia when A\\b is called. The execution time is dominated by the factorization, the most common method for which is described in \n\nComputing QR factorizations.\n\nlsqrfact\n\nSolution of least squares by QR factorization\n\n\"\"\"\n    lsqrfact(A,b)\n\nSolve a linear least-squares problem by QR factorization. Returns\nthe minimizer of ||b-Ax||.\n\"\"\"\nfunction lsqrfact(A,b)\n    Q,R = qr(A)\n    c = Q'*b\n    x = backsub(R,c)\n    return x\nend\n\nSolution of least squares by QR factorization\n\nfunction x = lsqrfact(A,b)\r\n% LSQRFACT   Solve linear least squares by QR factorization.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\n[Q,R] = qr(A,0);                        % compressed factorization\r\nc = Q'*b;\r\nx = backsub(R,c);                       \n\nSolution of least squares by QR factorization\n\n    lsqrfact(A,b)\n    \n    Solve a linear least squares problem by QR factorization. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    Q, R = np.linalg.qr(A)\n    c = Q.T @ b\n    x = backsub(R, c)\n    return x\n\ndef qrfact(A):\n\nThe solution of least-squares problems via QR factorization is more stable than when the normal equations are formulated and solved directly.\n\nStability of least-squares via QR\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = range(0, 3, 400)\nf = [ x->sin(x)^2, x->cos((1+1e-7)*x)^2, x->1. ]\nA = [ f(t) for t in t, f in f ]\nx = [1., 2, 1]\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(FNC.lsqrfact(A,b) - x) / norm(x);\n@show observed_error;\n@show error_bound = cond(A) * eps();\n\nStability of least-squares via QR\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nx = [1; 2; 1];\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(lsqrfact(A, b) - x) / norm(x)\nerror_bound = cond(A) * eps\n\nStability of least-squares via QR\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nx = array([1, 2, 1])\nb = A @ x\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nprint(f\"observed error: {norm(FNC.lsqrfact(A, b) - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {cond(A) * finfo(float).eps:.3e}\")","type":"content","url":"/qr#least-squares-and-qr","position":7},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Exercises"},"type":"lvl2","url":"/qr#exercises","position":8},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Exercises"},"content":"✍ Prove part 3 of \n\nTheorem 3.3.1.\n\n✍ Prove \n\nTheorem 3.3.2. For the third part, use the definition of the 2-norm as an induced matrix norm, then apply some of our other results as needed.\n\n⌨ Let t_0,\\ldots,t_m be m+1 equally spaced points in [-1,1]. Let \\mathbf{A} be the matrix in \n\n(3.1.2) for m=400 and fitting by polynomials of degree less than 5. Find the thin QR factorization of \\mathbf{A}, and, on a single graph, plot every column of \\hat{\\mathbf{Q}} as a function of the vector t.\n\n✍ Prove that if the m\\times n (m\\ge n) matrix \\mathbf{A} is not rank-deficient, then the factor \\hat{\\mathbf{R}} of the thin QR factorization is invertible. (Hint: Suppose on the contrary that \\hat{\\mathbf{R}} is singular. Show using the factored form of \\mathbf{A} that this would imply that \\mathbf{A} is rank-deficient.)\n\n✍ Let \\mathbf{A} be m\\times n with m>n. Show that if \\mathbf{A}=\\mathbf{Q}\\mathbf{R} is a QR factorization and \\mathbf{R} has rank n, then \\mathbf{A}^+=\\mathbf{R}^+\\mathbf{Q}^T.\n\n✍ Let \\mathbf{A} be m\\times n with m>n. Show that if \\mathbf{A}=\\hat{\\mathbf{Q}}\\hat{\\mathbf{R}} is a thin QR factorization and \\hat{\\mathbf{R}} is invertible, then \\mathbf{A}^+=\\hat{\\mathbf{R}}^{-1}\\hat{\\mathbf{Q}}^T.\n\n⌨ Repeat \n\nExercise 3.1.2, but use thin QR factorization rather than the backslash to solve the least-squares problem.\n\n✍ The matrix \\mathbf{P}=\\hat{\\mathbf{Q}} \\hat{\\mathbf{Q}}^T derived from the thin QR factorization has some interesting and important properties.\n\n(a) Prove that \\mathbf{P}=\\mathbf{A}\\mathbf{A}^+.\n\n(b) Prove that \\mathbf{P}^2=\\mathbf{P}. (This property defines a projection matrix.)\n\n(c) Any vector \\mathbf{x} may be written trivially as \\mathbf{x}=\\mathbf{u}+\\mathbf{v}, where \\mathbf{u}=\\mathbf{P}\\mathbf{x} and \\mathbf{v}=(\\mathbf{I}-\\mathbf{P})\\mathbf{x}. Prove that \\mathbf{u} and \\mathbf{v} are orthogonal. (Together with part (b), this means that \\mathbf{P} is an orthogonal projector.)\n\nConfusingly, a square matrix whose columns are orthogonal is not necessarily an orthogonal matrix; the columns must be orthonormal, which is a stricter condition.","type":"content","url":"/qr#exercises","position":9},{"hierarchy":{"lvl1":"Fixed-point iteration"},"type":"lvl1","url":"/fixed-point","position":0},{"hierarchy":{"lvl1":"Fixed-point iteration"},"content":"In this section, we consider the alternative form of the rootfinding problem known as the fixed-point problem.\n\nFixed-point problem\n\nGiven a function g, the fixed-point problem is to find a value p, called a fixed point, such that g(p)=p.\n\nGiven f for rootfinding, we could define g(x)=x-f(x), and then f(r)=0 implies g(r)=r and vice versa. There are infinitely many ways to make this transformation, such as g(x)=x+cf(x) for any constant c. The process can be reversed, too. Given g(x), we could define f(x)=x-g(x), and then g(p)=p implies f(p)=0.\n\nThere is an extraordinarily simple way to try to find a fixed point of any given g(x).\n\nFixed-point iteration\n\nGiven function g and initial value x_1, define  x_{k+1} = g(x_k), \\qquad k=1,2,\\ldots.\n\nThis is our first example of an iterative algorithm that never quite gets to the answer, even if we use exact numbers. The idea is to generate a sequence of values that one hopes will converge to the correct result, and stop when we are satisfied that we are close enough to the limit.\n\nFixed-point iteration\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\np = Polynomial([3.5, -4,1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nWe define g(x)=x-p(x).\n\ng(x) = x - p(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nplt = plot([g x->x], 2, 3, l=2, label=[L\"y=g(x)\" L\"y=x\"],\n    xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=1,\n    title=\"Finding a fixed point\", legend=:bottomright)\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot!([x, y], [y, y], arrow=true, color=3)\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y;  y = g(x)\nplot!([x, x], [x, y], arrow=true, color=4)\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot!([x, y], [y, y], color=3);  \n    x = y       # y becomes the new x\n    y = g(x)    # g(x) becomes the new y\n    plot!([x, x], [x, y], color=4)  \nend\nplt\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - rmax) / rmax\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nplt = plot([g x->x], 1, 2, l=2, label=[\"y=g(x)\" \"y=x\"], aspect_ratio=1, \n    xlabel=L\"x\", ylabel=L\"y\", title=\"Divergence\", legend=:bottomright)\n\nx = 1.3; y = g(x);\narrow = false\nfor k = 1:5\n    plot!([x, y], [y, y], arrow=arrow, color=3)  \n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    plot!([x, x], [x, y], arrow=arrow, color=4)\n    if k > 2; arrow = true; end\nend\nplt\n\nThis time, the iteration is pushing us away from the correct answer.\n\nFixed-point iteration\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5])\n\nWe define g(x)=x-p(x).\n\ng = @(x) x - f(x);\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nclf\nfplot(g, [2, 3])\nhold on,  plot([2, 3], [2, 3], 'k')\ntitle('Finding a fixed point'),  axis equal  \nxlabel('x'),  ylabel('y')\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot([x, y], [y, y], '-')\nx = y;\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\ny = g(x)\nplot([x, x],[x, y], '-')\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot([x, y], [y, y], '-')\n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-')  \nend\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - r(1)) / r(1)\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\ncla\nfplot(g, [1, 2])\nhold on, plot([1, 2], [1, 2], 'k')\nylim([1, 2])\nx = 1.3;  y = g(x);\nfor k = 1:5\n    plot([x, y], [y, y], '-'),  \n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-') \nend\ntitle('No convergence')\n\nThis time, the iteration is pushing us away from the correct answer.\n\nFixed-point iteration\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nWe define g(x)=x - f(x).\n\ng = lambda x: x - f(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nfig, ax = subplots()\ng = lambda x: x - f(x)\nxx = linspace(2, 3, 400)\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\naxis(\"equal\"), legend()\ntitle(\"Finding a fixed point\")\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1\ny = g(x)\nprint(y)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nax.plot([x, y], [y, y], \"r:\", label=\"\")\nfig\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y\ny = g(x)\nprint(\"y:\", y)\nax.plot([x, x], [x, y], \"k:\")\nfig\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    ax.plot([x, x], [x, y], \"k:\")  \nfig\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nprint(abs(y - max(r)) / max(r))\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nxx = linspace(1, 2, 400)\nfig, ax = subplots()\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\nax.set_aspect(1.0)\nax.legend()\n\nx = 1.3\ny = g(x)\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y\n    y = g(x)\n    ax.plot([x, x], [x, y], \"k:\")\nylim(1, 2.5)\ntitle(\"No convergence\")\n\nThis time, the iteration is pushing us away from the correct answer.","type":"content","url":"/fixed-point","position":1},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Series analysis"},"type":"lvl2","url":"/fixed-point#series-analysis","position":2},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Series analysis"},"content":"In \n\nDemo 4.2.1, the two computed iterations differ only in the choice of x_1. In the first case we evidently generated a sequence that converged to one of the fixed points. In the second case, however, the generated sequence diverged. The easiest way to uncover the essential difference between the two cases is to use a Taylor series expansion.\n\nSuppose a fixed point p is the desired limit of an iteration x_1,x_2,\\ldots. It’s often easier to express quantities in terms of the error sequence \\epsilon_1,\\epsilon_2,\\ldots, where \\epsilon_k=x_k-p. Starting from \n\n(4.2.1), we have\\begin{split}\n  \\epsilon_{k+1}+p = g( \\epsilon_{k}+p ) = g(p) + g'(p) \\epsilon_k + \\frac{1}{2}g''(p) \\epsilon_k^2 + \\cdots,\n\\end{split}\n\nassuming that g has at least two continuous derivatives. But by definition, g(p)=p, so  \\epsilon_{k+1} = g'(p) \\epsilon_k + O(\\epsilon_k^2).\n\nIf the iteration is to converge to p, the errors must approach zero. In this case we can neglect the second-order term and conclude that \\epsilon_{k+1} \\approx g'(p) \\epsilon_k. This is consistent with convergence if |g'(p)|<1. However, if |g'(p)| >1, we are led to the conclusion that the errors must grow, not vanish, even if they start quite small.\n\nFixed point iteration for a differentiable g(x) converges to a fixed point p if the initial error is sufficiently small and |g'(p)|< 1. The iteration diverges for all initial values if |g'(p)| > 1.\n\nThe role of g'(p) is clear in \n\nDemo 4.2.1. We have g(x) = -x^2+5x-3.5 and g'(x)=-2x+5. For the first fixed point, near 2.71, we get g'(p)\\approx-0.42, indicating convergence. For the second fixed point, near 1.29, we get g'(p)\\approx 2.42, which is consistent with the observed divergence.","type":"content","url":"/fixed-point#series-analysis","position":3},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Linear convergence"},"type":"lvl2","url":"/fixed-point#linear-convergence","position":4},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Linear convergence"},"content":"In computation we usually want to know not just whether an iteration converges but also the rate at which convergence occurs, i.e., how quickly the errors approach zero. Other things being equal, faster convergence is preferred to slower convergence, as it usually implies that the computation will take less time to achieve a desired accuracy.\n\nThe prediction of the series analysis above is that if the fixed point iteration converges, the errors approximately satisfy |\\epsilon_{k+1}| = \\sigma|\\epsilon_k|, for \\sigma = |g'(p)| < 1. This is a well-known type of convergence.\n\nLinear convergence\n\nSuppose a sequence x_k approaches limit x^*. If the error sequence \\epsilon_k=x_k - x^* satisfies  \\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|} = \\sigma < 1,\n\nthen the sequence displays linear convergence. The number σ is called the convergence rate.\n\nIf we suppose that the ratios in \n\n(4.2.4) all equal σ (i.e., perfect linear convergence), then |\\epsilon_k| = C \\sigma^k. Taking logs, we get  \\log |\\epsilon_k| = k(\\log \\sigma) + (\\log C).\n\nThis is in the form \\log |\\epsilon_k| = \\alpha k + \\beta, which is a linear relationship.\n\nLinear convergence in practice\n\nLinear convergence is marked by an approximate reduction of the error at each iteration by a constant factor, the convergence rate σ. When graphed on a log-linear scale, the errors lie on a straight line whose slope is the log of the convergence rate. Both phenomena manifest most strongly at the latest iterations.\n\nConvergence of fixed-point iteration\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\np = Polynomial([3.5, -4, 1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nHere is the fixed point iteration. This time we keep track of the whole sequence of approximations.\n\ng(x) = x - p(x)\nx = [2.1]\nfor k = 1:12\n    push!(x, g(x[k]))\nend\nx\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = @. abs(x - rmax)\nplot(0:12, err, m=:o,\n    xaxis=(\"iteration number\"), yaxis=(\"error\", :log10),\n    title=\"Convergence of fixed point iteration\")\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log.(err[5:12])\np = Polynomials.fit(5:12, y, 1)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nσ = exp(p.coeffs[2])\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\n[err[i+1] / err[i] for i in 8:11]\n\nThe methods for finding σ agree well.\n\nConvergence of fixed-point iteration\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5]);\n\nHere is the fixed point iteration. This time we keep track of the whole sequence of approximations.\n\ng = @(x) x - f(x);\nx = 2.1; \nfor k = 1:12\n    x(k+1) = g(x(k));\nend\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - r(1));\nclf\nsemilogy(err, 'o-'), axis tight\nxlabel('iteration'),  ylabel('error')\ntitle('Convergence of fixed point iteration')\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log(err(5:12));\np = polyfit(5:12, y, 1);\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nsigma = exp(p(1))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr(9:12) ./ err(8:11)\n\nThe methods for finding σ agree well.\n\nConvergence of fixed-point iteration\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nHere is the fixed point iteration. This time we keep track of the whole sequence of approximations.\n\ng = lambda x: x - f(x)\nx = zeros(12)\nx[0] = 2.1\nfor k in range(11):\n    x[k + 1] = g(x[k])\n\nprint(x)\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - max(r))\nsemilogy(err, \"-o\")\nxlabel(\"iteration number\"), ylabel(\"error\")\ntitle(\"Convergence of fixed point iteration\")\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\np = polyfit(arange(5, 13), log(err[4:]), 1)\nprint(p)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nprint(\"sigma:\", exp(p[0]))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr[8:] / err[7:-1]\n\nThe methods for finding σ agree well.","type":"content","url":"/fixed-point#linear-convergence","position":5},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Contraction maps"},"type":"lvl2","url":"/fixed-point#contraction-maps","position":6},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Contraction maps"},"content":"The convergence condition \\sigma=|g'(p)|<1 derived by series expansion is a special case of a more general condition.\n\nA function g is said to satisfy a Lipschitz condition with constant L on the interval S\\subset\\mathbb{R} if, for all s,t\\in S,    \\bigl| g(s)-g(t) \\bigr| \\le L \\bigl| s-t \\bigr|.\n\nIt can be shown that a function satisfying \n\n(4.2.6) is continuous in S. If L<1, we call g a contraction mapping because distances between points all decrease after an application of g. This situation leads to a major result about fixed points.\n\nContraction mapping\n\nSuppose that g satisfies \n\n(4.2.6) with L<1 on an interval S. Then S contains exactly one fixed point p of g. If x_1,x_2,\\ldots are generated by the fixed point iteration \n\n(4.2.1), and x_1,x_2,\\ldots all lie in S, then |x_k-p|\\le L^{k-1} |x_1-p| for all k>1.\n\n(partial proof)  First we show there is at most one fixed point in S. Suppose g(t)=t and g(s)=s in S. Then by \n\n(4.2.6), |s-t|=|g(s)-g(t)|\\le L|s-t|, which for L<1 is possible only if |s-t|=0, so s=t.\n\nNow suppose that for some p\\in S, g(p)=p. By the definition of the fixed point iteration and the Lipschitz condition,|x_{k+1} - p | = |g(x_k) - g(p)| \\le L |x_k-p|,\n\nwhich shows that x_k\\to p as k\\to \\infty. To show that p must exist and complete the proof, one needs to apply the Cauchy theory of convergence of a sequence, which is beyond the scope of this text.\n\nFrom the Fundamental Theorem of Calculus, which asserts that g(s)-g(t)=\\int_s^t g'(x)\\, dx, it’s easy to conclude that an upper bound of |g'(x)|\\le L for all x results in \n\n(4.2.6). Hence:\n\nIf |g'(x)|\\le L < 1 for all x in an interval S, then the conclusions of \n\nTheorem 4.2.1 apply.\n\nThere are stronger and more general statements of \n\nTheorem 4.2.1. For instance, it’s possible to show that all initial x_1 that are sufficiently close to the fixed point will lead to convergence of the iteration. Algorithmically the main virtue of the fixed point iteration is that it is incredibly easy to apply. However, as we are about to discover, it’s far from the fastest option.","type":"content","url":"/fixed-point#contraction-maps","position":7},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Exercises"},"type":"lvl2","url":"/fixed-point#exercises","position":8},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Exercises"},"content":"✍ In each case, show that the given g(x) has a fixed point at the given p and use \n\n(4.2.3) to show that fixed point iteration can converge to it.\n\n(a) g(x) = 1 + x - \\frac{1}{9}x^2, p=3\n\n(b) g(x) = \\pi + \\frac{1}{4}\\sin(x), p=\\pi\n\n(c) g(x) = x+1-\\tan(x/4), p=\\pi\n\n⌨ For each case in the preceding problem, apply 25 fixed point iterations and use a log-linear graph of the error to verify linear convergence. Then use numerical values of the error to determine an approximate value for σ in \n\n(4.2.4).\n\n✍  In each case, show that the given g(x) has a fixed point at the given p. Then determine analytically whether the fixed point iteration could converge to that point given a close enough starting value.\n\n(a) g(x) = 3+x-x^2, p=\\sqrt{3}\n\n(b) g(x) = \\sqrt{1+x}, p=(1+\\sqrt{5})/2\n\n(c) g(x) = -\\sqrt{1+x}, p=(1-\\sqrt{5})/2\n\n(d) g(x) = x+1-\\tan(\\pi x), p=1/4\n\nIn \n\nDemo 4.2.1 we defined g(x)=x-f(x) to find a fixed point of the polynomial f(x)=x^2 - 4x + 3.5.\n\n(a) ✍ Why does the iteration spiral in to the fixed point, instead of approaching it monotonically? (Refer to the series analysis.)\n\n(b) ✍ Show that if \\hat{g}(x) = (x^2+3.5)/4, then any fixed point of \\hat{g} is a root of f.\n\n(c) ⌨ Use fixed point iteration on \\hat{g} to try to find both roots of f, and note which case(s), if either, converge.\n\n(d) ✍ Use \n\n(4.2.3) to explain the success/failure in part (c) for each fixed point.\n\n✍ The mth root of a positive real number a is a fixed point of the functiong(x) = \\frac{a}{x^{m-1}}.\n\nFor what integer values of m>1 will the fixed point iteration for g converge (for close enough initial guesses)?\n\n(a) ✍ Show that p=1/3 is a fixed point of g(x) = 2x-3x^2.\n\n(b) ✍ Find g'(1/3). How does this affect \n\n(4.2.3)?\n\n(c) ⌨ Do an experiment with fixed point iteration on g to converge to p=1/3. Is the convergence a straight line on a log-linear plot?\n\n✍  Consider the iterationx_{k+1} = x_k - \\frac{f(x_k)}{c}, \\qquad k=0,1,\\ldots.\n\nSuppose f(p)=0 and that f'(p)>0 exists. Find one or more conditions on c such that the iteration converges to p.\n\nWe can only ever generate a finite sample from an infinite sequence, which in principle does not guarantee anything whatsoever about the limit or divergence of that sequence. However, in practical computing one usually assumes that well-established trends in the sequence will continue, and we complement observed experience with rigorous theory where possible.","type":"content","url":"/fixed-point#exercises","position":9},{"hierarchy":{"lvl1":"Newton’s method"},"type":"lvl1","url":"/newton","position":0},{"hierarchy":{"lvl1":"Newton’s method"},"content":"Newton’s method is the cornerstone of rootfinding. We introduce the key idea with an example in \n\nDemo 4.3.1.\n\nGraphical interpretation of Newton’s method\n\nSuppose we want to find a root of the function\n\nf(x) = x * exp(x) - 2\n\nplot(f, 0, 1.5, label=\"function\",\n    grid=:y, ylim=[-2, 4], xlabel=L\"x\", ylabel=L\"y\", legend=:topleft)\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx₁ = 1\ny₁ = f(x₁)\nscatter!([x₁], [y₁], label=\"initial point\")\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx(x) = exp(x) * (x + 1)\nm₁ = df_dx(x₁)\ntangent = x -> y₁ + m₁ * (x - x₁)\n\nplot!(tangent, 0, 1.5, l=:dash, label=\"tangent line\",\n    title=\"Tangent line approximation\")\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\n@show x₂ = x₁ - y₁ / m₁\nscatter!([x₂], [0], label=\"tangent root\", title=\"First iteration\")\n\ny₂ = f(x₂)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nplot(f, 0.82, 0.87, label=\"function\", legend=:topleft,\n    xlabel=L\"x\", ylabel=L\"y\", title=\"Second iteration\")\n\nscatter!([x₂], [y₂], label=\"starting point\")\n\nm₂ = df_dx(x₂)\ntangent = x -> y₂ + m₂ * (x - x₂)\nplot!(tangent, 0.82, 0.87, l=:dash, label=\"tangent line\")\n\n@show x₃ = x₂ - y₂ / m₂\nscatter!([x₃], [0], label=\"tangent root\")\n\ny₃ = f(x₃)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nGraphical interpretation of Newton’s method\n\nSuppose we want to find a root of the function\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0, 1.5])\nxlabel('x'), ylabel('y')    \nset(gca, 'ygrid', 'on')  \ntitle('Objective function')\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1;\ny1 = f(x1)\nhold on, scatter(x1, y1)\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndfdx = @(x) exp(x) .* (x + 1);\nslope1 = dfdx(x1);\ntangent1 = @(x) y1 + slope1 * (x - x1);\nfplot(tangent1, [0, 1.5],'--')\ntitle('Function and tangent line')\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nscatter(x2, 0)\ntitle('Root of the tangent')\n\ny2 = f(x2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\ncla, fplot(f, [0.8, 0.9])\nscatter(x2, y2)\nslope2 = dfdx(x2);\ntangent2 = @(x) y2 + slope2 * (x - x2);\nfplot(tangent2, [0.8, 0.9], '--')\nx3 = x2 - y2 / slope2;\nscatter(x3, 0)\ntitle('Next iteration')\n\ny3 = f(x3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nGraphical interpretation of Newton’s method\n\nSuppose we want to find a root of this function:\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0, 1.5, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$y$\")\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1\ny1 = f(x1)\nax.plot(x1, y1, \"ko\", label=\"initial point\")\nax.legend()\nfig\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx = lambda x: exp(x) * (x + 1)\nslope1 = df_dx(x1)\ntangent1 = lambda x: y1 + slope1 * (x - x1)\n\nax.plot(xx, tangent1(xx), \"--\", label=\"tangent line\")\nax.set_ylim(-2, 4)\nax.legend()\nfig\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nax.plot(x2, 0, \"ko\", label=\"tangent root\")\nax.legend()\nfig\n\ny2 = f(x2)\nprint(y2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nxx = linspace(0.83, 0.88, 200)\n\nplot(xx, f(xx))\nplot(x2, y2, \"ko\")\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\n\nslope2 = df_dx(x2)\ntangent2 = lambda x: y2 + slope2 * (x - x2)\nplot(xx, tangent2(xx), \"--\")\nx3 = x2 - y2 / slope2\nplot(x3, 0, \"ko\")\ntitle(\"Second iteration\")\n\ny3 = f(x3)\nprint(y3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nUsing general notation, if we have a root approximation x_k, we can construct a linear model of f(x) using the classic formula for the tangent line of a differentiable function,  q(x) = f(x_k) + f'(x_k)(x-x_k).\n\nFinding the root of q(x)=0 is trivial. We define the next approximation by the condition q(x_{k+1})=0, which leads to the following.\n\nNewton’s method\n\nGiven a function f, its derivative, f', and an initial value x_1, iteratively define  x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}, \\qquad k=1,2,\\ldots.","type":"content","url":"/newton","position":1},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Convergence"},"type":"lvl2","url":"/newton#convergence","position":2},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Convergence"},"content":"The graphs of \n\nDemo 4.3.1 suggest why the Newton iteration may converge to a root: any differentiable function looks more and more like its tangent line as we zoom in to the point of tangency. Yet it is far from clear that it must converge, or at what rate it will do so. The matter of the convergence rate is fairly straightforward to resolve. Define the error sequence\\epsilon_k = x_k - r , \\quad k=1,2,\\ldots,\n\nwhere r is the limit of the sequence and f(r)=0. Exchanging x-values for ε-values in \n\n(4.3.2) gives  \\epsilon_{k+1}+r = \\epsilon_k + r - \\frac{f(r+\\epsilon_k)}{f'(r+\\epsilon_k)}.\n\nWe assume that |\\epsilon_k|\\to 0; eventually, the errors remain as small as we please forever. Then a Taylor expansion of f about x=r gives  \\epsilon_{k+1} = \\epsilon_k - \\frac{ f(r) + \\epsilon_kf'(r) + \\frac{1}{2}\\epsilon_k^2f''(r) +\n    O(\\epsilon_k^3)}{ f'(r) + \\epsilon_kf''(r) + O(\\epsilon_k^2)}.\n\nWe use the fact that f(r)=0 and additionally assume now that r is a simple root, i.e., f'(r)\\neq 0. Then\\epsilon_{k+1} = \\epsilon_k - \\epsilon_k \\left[ 1 + \\dfrac{1}{2}\\dfrac{f''(r)}{f'(r)} \\epsilon_k\n+ O(\\epsilon_k^2)\\right] \\, \\left[ 1 + \\dfrac{f''(r)}{f'(r)}\\epsilon_k + O(\\epsilon_k^2)\\right]^{-1}.\n\nThe series in the denominator is of the form 1/(1+z). Provided |z|<1, this is the limit of the geometric series 1-z+z^2-z^3 + \\cdots. Keeping only the lowest-order terms, we derive\\begin{split}\n\\epsilon_{k+1} &= \\epsilon_k - \\epsilon_k \\left[ 1 + \\dfrac{1}{2}\\dfrac{f''(r)}{f'(r)} \\epsilon_k + O(\\epsilon_k^2) \\right] \\, \\left[ 1 - \\dfrac{f''(r)}{f'(r)}\n\\epsilon_k + O(\\epsilon_k^2) \\right]\\\\\n&= \\frac{1}{2}\\, \\frac{f''(r)}{f'(r)} \\epsilon_k^2 + O(\\epsilon_k^3).\n\\end{split}\n\nAsymptotically, each iteration of Newton’s method roughly squares the error.\n\nQuadratic convergence\n\nSuppose a sequence x_k approaches limit x^*. If the error sequence \\epsilon_k=x_k - x^* satisfies  \\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|^2} = L\n\nfor a positive constant L, then the sequence has quadratic convergence to the limit.\n\nRecall that linear convergence is identifiable by trending toward a straight line on a log-linear plot of the error. When the convergence is quadratic, no such straight line exists—the convergence keeps getting steeper. As a numerical test, note that |\\epsilon_{k+1}|\\approx K |\\epsilon_{k}|^2 implies that as k\\to\\infty,  \\log |\\epsilon_{k+1}| & \\approx 2 \\log |\\epsilon_{k}| + L,\\\\\n    \\frac{\\log |\\epsilon_{k+1}|}{\\log |\\epsilon_{k}|} &\\approx 2 + \\frac{L}{\\log |\\epsilon_{k}|} \\to 2.\n\nConvergence of Newton’s method\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf(x) = x * exp(x) - 2;\ndf_dx(x) = exp(x) * (x + 1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nr = nlsolve(x -> f(x[1]), [1.0]).zero\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = [1; zeros(4)]\nfor k = 1:4\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nx\n\nHere is the sequence of errors.\n\nϵ = @. x - r\n\nBecause the error reaches machine epsilon so rapidly, we’re going to use extended precision to allow us to take a few more iterations. We’ll take the last iteration as the most accurate root estimate.\n\nA BigFloat uses 256 bits of precision, rather than 53 in Float64. But arithmetic is done by software emulation and is much slower.\n\nx = [BigFloat(1); zeros(7)]\nfor k = 1:7\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nr = x[end]\n\nϵ = @. Float64(x[1:end-1] - r)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = @. log(abs(ϵ))\n[logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nConvergence of Newton’s method\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = @(x) x.*exp(x) - 2;\ndfdx = @(x) exp(x).*(x+1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nformat long,  r = fzero(f,1)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = 1;\nfor k = 1:6\n    x(k+1) = x(k) - f(x(k)) / dfdx(x(k));\nend\nx\n\nHere is the sequence of errors.\n\nformat short e\nerr = x' - r\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nformat short\nlogerr = log(abs(err))\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nConvergence of Newton’s method\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = lambda x: x * exp(x) - 2\ndf_dx = lambda x: exp(x) * (x + 1)\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nr = root_scalar(f, bracket=[0.8, 1.0]).root\nprint(r)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = ones(5)\nfor k in range(4):\n    x[k + 1] = x[k] - f(x[k]) / df_dx(x[k])\n\nprint(x)\n\nHere is the sequence of errors.\n\nerr = x - r\nprint(err)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nLet’s summarize the assumptions made to derive quadratic convergence as given by \n\n(4.3.7):\n\nThe residual function f has to have enough continuous derivatives to make the Taylor series expansion valid. Often this is stated as f having sufficient smoothness. This is usually not a problem, but see \n\nExercise 6.\n\nWe required f'(r)\\neq 0, meaning that r must be a simple root. See \n\nExercise 7 to investigate what happens at a multiple root.\n\nWe assumed that the sequence converged, which is not easy to guarantee in any particular case. In fact,\nfinding a starting value from which the Newton iteration converges is often the most challenging part of a rootfinding problem. We will try to deal with this issue in \n\nQuasi-Newton methods.","type":"content","url":"/newton#convergence","position":3},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Implementation"},"type":"lvl2","url":"/newton#implementation","position":4},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Implementation"},"content":"Our implementation of Newton’s iteration is given in \n\nFunction 4.3.2. It accepts functions that evaluate f and f' and the starting value x_1 as input arguments. Beginning programmers are tempted to embed f and f' directly into the code, but there are two good reasons not to do so. First, each new rootfinding problem would require its own copy of the code, creating a lot of duplication. Second, you may want to try more than one rootfinding algorithm for a particular problem, and keeping the definition of the problem separate from the algorithm for its solution makes this task much easier.\n\nnewton\n\nNewton’s method\n\n\"\"\"\n    newton(f,dfdx,x₁[;maxiter,ftol,xtol])\n\nUse Newton's method to find a root of `f` starting from `x₁`, where\n`dfdx` is the derivative of `f`. Returns a vector of root estimates.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\"\"\"\nfunction newton(f,dfdx,x₁;maxiter=40,ftol=100*eps(),xtol=100*eps())\n    x = [float(x₁)]\n    y = f(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (abs(Δx) > xtol) && (abs(y) > ftol)\n        dydx = dfdx(x[k])\n        Δx = -y/dydx            # Newton step\n        push!(x,x[k]+Δx)        # append new estimate\n\n        k += 1\n        y = f(x[k])\n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nNewton’s method\n\nfunction x = newton(f,dfdx,x1)\r\n% NEWTON   Newton's method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   dfdx     derivative function\r\n%   x1       initial root approximation\r\n% Output       \r\n%   x        vector of root approximations (last one is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = x1;  \r\ny = f(x1);\r\ndx = Inf;   % for initial pass below\r\nk = 1;\r\n\r\nwhile (abs(dx) > xtol) && (abs(y) > funtol) && (k < maxiter)\r\n    dydx = dfdx(x(k));\r\n    dx = -y/dydx;           % Newton step\r\n    x(k+1) = x(k) + dx;\r\n\r\n    k = k+1;\r\n    y = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n  warning('Maximum number of iterations reached.')\r\nend\n\nNewton’s method\n\ndef newton(f, dfdx, x1):\n    \"\"\"\n    newton(f, dfdx, x1)\n\n    Use Newton's method to find a root of `f` starting from `x1`, where `dfdx` is the\n    derivative of `f`. Returns a vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[0] = x1\n    y = f(x1)\n    dx = np.inf  # for initial pass below\n    k = 0\n\n    while (abs(dx) > xtol) and (abs(y) > funtol) and (k < maxiter):\n        dydx = dfdx(x[k])\n        dx = -y / dydx  # Newton step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y = f(x[k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n\n    return x[: k + 1]\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nFunction 4.3.2 also deals with a thorny practical issue: how to stop the iteration. It adopts a three-part criterion. First, it monitors the difference between successive root estimates, |x_k-x_{k-1}|, which is used as a stand-in for the unknown error |x_k-r|. In addition, it monitors the residual |f(x_k)|, which is equivalent to the backward error and more realistic to control in badly conditioned problems (see \n\nThe rootfinding problem). If either of these quantities is considered to be sufficiently small, the iteration ends. Finally, we need to protect against the possibility of a nonconvergent iteration, so the procedure terminates with a warning if a maximum number of iterations is exceeded.\n\nUsing Newton’s method\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\ng(x) = exp(x) - x\ndg_dx(x) = exp(x) - 1\ny = range(g(0), g(2), 200)\nx = zeros(length(y))\nfor (i, y) in enumerate(y)\n    f(x) = g(x) - y\n    df_dx(x) = dg_dx(x)\n    r = FNC.newton(f, df_dx, y)\n    x[i] = r[end]\nend\n\nplot(g, 0, 2, aspect_ratio=1, label=L\"g(x)\")\nplot!(y, x, label=L\"g^{-1}(y)\", title=\"Function and its inverse\")\nplot!(x -> x, 0, maximum(y), label=\"\", l=(:dash, 1), color=:black)\n\nUsing Newton’s method\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nWhen a function is created, it can refer to any variables in scope at that moment. Those values are locked in to the definition, which is called a closure. If the enclosed variables change values later, the function still uses the values it was created with.\n\nh = @(x) exp(x) - x;\ndh_dx = @(x) exp(x) - 1;\ny_ = linspace(h(0), h(2), 200);\nx_ = zeros(size(y_));\nfor i = 1:length(y_)\n    f = @(x) h(x) - y_(i);\n    df_dx = @(x) dh_dx(x);\n    x = newton(f, df_dx, 1);  x_(i) = x(end);\nend\n\nclf, fplot(h, [0, 2])\nhold on, axis equal\nplot(y_, x_)\nplot([0, max(y_)], [0, max(y_)], 'k--')\nxlabel('x'), ylabel('y')\nlegend('h(x)', 'inverse', 'y=x')\n\nUsing Newton’s method\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=h(x), or h(x)-y=0, for x when y is given. That equation has no solution in terms of elementary functions. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\nh = lambda x: exp(x) - x\ndh_dx = lambda x: exp(x) - 1\ny_ = linspace(h(0), h(2), 200)\nx_ = zeros(y_.shape)\nfor (i, y) in enumerate(y_):\n    f = lambda x: h(x) - y\n    df_dx = lambda x: dh_dx(x)\n    x = FNC.newton(f, df_dx, y)\n    x_[i] = x[-1]\n\nplot(x_, y_, label=\"$y=h(x)$\")\nplot(y_, x_, label=\"$y=h^{-1}(x)$\")\nplot([0, max(y_)], [0, max(y_)], 'k--', label=\"\")\ntitle(\"Function and its inverse\")\nxlabel(\"x\"), ylabel(\"y\"), axis(\"equal\")\nax.grid(), legend()","type":"content","url":"/newton#implementation","position":5},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Exercises"},"type":"lvl2","url":"/newton#exercises","position":6},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Exercises"},"content":"For each of Exercises 1–3, do the following steps.\n\n(a) ✍ Rewrite the equation into the standard form for rootfinding, f(x) = 0, and compute f'(x).\n\n(b) ⌨  Make a plot of f over the given interval and determine how many roots lie in the interval.\n\n(c) ⌨ Use nlsolve with ftol=1e-15 to find a reference value for each root.\n\n(d) ⌨ Use \n\nFunction 4.3.2 to find each root.\n\n(e) ⌨ For one of the roots, use the errors in the Newton sequence to determine numerically whether the convergence is roughly quadratic.\n\nx^2=e^{-x}, over [-2,2]\n\n2x = \\tan x, over [-0.2,1.4]\n\ne^{x+1}=2+x, over [-2,2]\n\n⌨  Plot the function f(x)=x^{-2} - \\sin x on the interval x \\in [0.5,10].  For each initial value x_1=1,\\, x_1=2,\\,\\ldots,\\, x_1=7, apply \n\nFunction 4.3.2 to f, and make a table showing x_1 and the resulting root found by the method. In which case does the iteration converge to a root other than the one closest to it? Use the plot to explain why that happened.\n\n✍ Show that if f(x)=x^{-1}-b for nonzero b, then Newton’s iteration converging to the root r=1/b can be implemented without performing any divisions.\n\n✍ Discuss what happens when Newton’s method is applied to find a root of f(x) = \\operatorname{sign}(x) \\sqrt{|x|}, starting at x_1\\ne 0. (Hint: Write out both f(x) and f'(x) as piecewise functions.)\n\n✍ In the case of a multiple root, where f(r)=f'(r)=0, the derivation of the quadratic error convergence in \n\n(4.3.7) is invalid. Redo the derivation to show that in this circumstance and with f''(r)\\neq 0, the error converges only linearly.\n\n✍ In \n\nFunction 4.3.2 and elsewhere, the actual error is not available, so we use |x_k-x_{k-1}| as an approximate indicator of error to determine when to stop the iteration. Find an example that foils this indicator; that is, a sequence \\{x_k\\} such that\\lim_{k\\rightarrow \\infty} (x_k-x_{k-1}) = 0,\n\nbut \\{x_k\\} diverges. (Hint: You have seen such sequences in calculus.) Hence the need for residual tolerances and safety valves in the code!","type":"content","url":"/newton#exercises","position":7},{"hierarchy":{"lvl1":"Newton for nonlinear systems"},"type":"lvl1","url":"/newtonsys","position":0},{"hierarchy":{"lvl1":"Newton for nonlinear systems"},"content":"The rootfinding problem becomes much more difficult when multiple variables and equations are involved.\n\nMultidimensional rootfinding problem\n\nGiven a continuous vector-valued function \\mathbf{f} mapping from \\mathbb{R}^n into \\mathbb{R}^n, find a vector \\mathbf{r} such that\\begin{split}\n  f_1(r_1,\\dots,r_n) &= 0,\\\\\n  f_2(r_1,\\dots,r_n) &= 0,\\\\\n  &\\vdots\\\\\n  f_n(r_1,\\dots,r_n) &= 0.\n\\end{split}\n\nParticular problems are often posed using scalar variables and equations.\n\nThe steady state of interactions between the population w(t) of a predator species and the population h(t) of a prey species might be modeled asah - b h w &= 0, \\\\ \n-cw + d w h &= 0\n\nfor positive parameters a,b,c,d. To cast this in the form of \n\n(4.5.1), we could define \\mathbf{x}=[h,w], f_1(x_1,x_2) = ax_1 - bx_1x_2, and f_2(x_1,x_2)= -c x_2 + d x_1 x_2.\n\nWhile the equations of \n\nExample 4.5.1 are easy to solve by hand, in practice even establishing the existence and uniqueness of solutions for any particular system is typically quite difficult.","type":"content","url":"/newtonsys","position":1},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Linear model"},"type":"lvl2","url":"/newtonsys#linear-model","position":2},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Linear model"},"content":"To extend rootfinding methods to systems, we will keep to the basic philosophy of constructing easily managed models of the exact function. As usual, the starting point is a linear model. We base it on the multidimensional Taylor series,\\mathbf{f}(\\mathbf{x}+\\mathbf{h}) = \\mathbf{f}(\\mathbf{x}) + \\mathbf{J}(\\mathbf{x})\\mathbf{h} + O(\\| \\mathbf{h} \\|^2),\n\nwhere \\mathbf{J} is called the Jacobian matrix of \\mathbf{f} and is defined by\\mathbf{J}(\\mathbf{x}) =\n  \\begin{bmatrix}\n    \\rule[2mm]{0pt}{1em}\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\cdots & \\frac{\\partial f_1}{\\partial x_n}\\\\[2mm]\n    \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\cdots & \\frac{\\partial f_2}{\\partial x_n}\\\\[1mm]\n    \\vdots & \\vdots & & \\vdots\\\\[1mm]\n    \\rule[-3mm]{0pt}{1em} \\frac{\\partial f_n}{\\partial x_1} & \\frac{\\partial f_n}{\\partial x_2} & \\cdots & \\frac{\\partial f_n}{\\partial x_n}\n  \\end{bmatrix} = \\left[ \\frac{\\partial f_i}{\\partial x_j} \\right]_{\\,i,j=1,\\ldots,n}.\n\nBecause of the Jacobian’s role in \n\n(4.5.3), we may write \\mathbf{J}(\\mathbf{x}) as \\mathbf{f}{\\,}'(\\mathbf{x}). Like any derivative, it is a function of the independent variable \\mathbf{x}.\n\nLet\\begin{split}\n    f_1(x_1,x_2,x_3) &= -x_1\\cos(x_2) - 1\\\\\n    f_2(x_1,x_2,x_3) &= x_1x_2 + x_3\\\\\n    f_3(x_1,x_2,x_3) &= e^{-x_3}\\sin(x_1+x_2) + x_1^2 - x_2^2.\n\\end{split}\n\nThen    \\mathbf{J}(x) =\n    \\begin{bmatrix}\n       -\\cos(x_2) & x_1 \\sin(x_2) & 0\\\\\n      x_2 & x_1 & 1\\\\\n       e^{-x_3}\\cos(x_1+x_2)+2x_1 & e^{-x_3}\\cos(x_1+x_2)-2x_2 &\n       -e^{-x_3}\\sin(x_1+x_2)\n    \\end{bmatrix}.\n\nIf we were to start writing out the terms in \n\n(4.5.3), we would begin with\\begin{split}\n    f_1(x_1+h_1,x_2+h_2,x_3+h_3) &= -x_1\\cos(x_2)-1 -\\cos(x_2)h_1 +\n    x_1\\sin(x_2)h_2 + O\\bigl(\\| \\mathbf{h} \\|^2\\bigr) \\\\\n    f_2(x_1+h_1,x_2+h_2,x_3+h_3) &= x_1x_2 + x_3 + x_2h_1 +x_1h_2 +\n    h_3 + O\\bigl(\\| \\mathbf{h} \\|^2\\bigr),\n  \\end{split}\n\nand so on.\n\nThe terms \\mathbf{f}(\\mathbf{x})+\\mathbf{J}(\\mathbf{x})\\mathbf{h} in \n\n(4.5.3) represent the linear part of \\mathbf{f} near \\mathbf{x}. If \\mathbf{f} is actually linear, i.e., \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x}-\\mathbf{b}, then the Jacobian matrix is the constant matrix \\mathbf{A} and the higher-order terms in \n\n(4.5.3) disappear.","type":"content","url":"/newtonsys#linear-model","position":3},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"The multidimensional Newton iteration"},"type":"lvl2","url":"/newtonsys#the-multidimensional-newton-iteration","position":4},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"The multidimensional Newton iteration"},"content":"With a method in hand for constructing a linear model for the vector system \\mathbf{f}(\\mathbf{x}), we can generalize Newton’s method. Specifically, at a root estimate \\mathbf{x}_k, we set \\mathbf{h} = \\mathbf{x}-\\mathbf{x}_k in \n\n(4.5.3) and get\\mathbf{f}(\\mathbf{x}) \\approx \\mathbf{q}(\\mathbf{x})  = \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{J}(\\mathbf{x}_k)(\\mathbf{x}-\\mathbf{x}_k).\n\nWe define the next iteration value \\mathbf{x}_{k+1} by requiring \\mathbf{q}(\\mathbf{x}_{k+1})=\\boldsymbol{0},\\begin{split}\n  \\boldsymbol{0} &=  \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{J}(\\mathbf{x}_k)(\\mathbf{x}_{k+1}-\\mathbf{x}_k),\\\\\n\\end{split}\n\nwhich can be rearranged into\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\bigl[\\mathbf{J}(\\mathbf{x}_k)\\bigr]^{-1} \\mathbf{f}(\\mathbf{x}_k).\n\nNote that \\mathbf{J}^{-1}\\mathbf{f} now plays the role that f/f' had in the scalar case; in fact, the two are the same in one dimension. In computational practice, however, we don’t compute matrix inverses.\n\nMultidimensional Newton’s method\n\nGiven \\mathbf{f} and a starting value \\mathbf{x}_1, for each k=1,2,3,\\ldots\n\nCompute \\mathbf{y}_k = \\mathbf{f}(\\mathbf{x}_k) and \\mathbf{A}_k=\\mathbf{f\\,}'(\\mathbf{x}_k).\n\nSolve the linear system \\mathbf{A}_k\\mathbf{s}_k = -\\mathbf{y}_k for the Newton step \\mathbf{s}_k.\n\nLet \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\mathbf{s}_k.\n\nAn extension of our series analysis of the scalar Newton’s method shows that the vector version is also quadratically convergent in any vector norm, under suitable circumstances and when the iteration converges at all.","type":"content","url":"/newtonsys#the-multidimensional-newton-iteration","position":5},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Implementation"},"type":"lvl2","url":"/newtonsys#implementation","position":6},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Implementation"},"content":"An implementation of Newton’s method for systems is given in \n\nFunction 4.5.2. Other than computing the Newton step using backslash and taking vector magnitudes with norm, \n\nFunction 4.5.2 is virtually identical to the scalar version \n\nFunction 4.3.2 presented earlier.\n\nnewtonsys\n\nNewton’s method for systems\n\n\"\"\"\n    newtonsys(f,jac,x₁[;maxiter,ftol,xtol])\n\nUse Newton's method to find a root of a system of equations,\nstarting from `x₁`. The functions `f` and `jac` should return the\nresidual vector and the Jacobian matrix, respectively. Returns the\nhistory of root estimates as a vector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction newtonsys(f,jac,x₁;maxiter=40,ftol=1000*eps(),xtol=1000*eps())\n    x = [float(x₁)]\n    y,J = f(x₁),jac(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (norm(Δx) > xtol) && (norm(y) > ftol)\n        Δx = -(J\\y)             # Newton step\n        push!(x,x[k] + Δx)    # append to history\n        k += 1\n        y,J = f(x[k]),jac(x[k])\n\n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n    end\n    return x\nend\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nNewton’s method for systems\n\nfunction x = newtonsys(f,x1)\r\n% NEWTONSYS   Newton's method for a system of equations.\r\n% Input:\r\n%   f        function that computes residual and Jacobian matrix\r\n%   x1       initial root approximation (n-vector)\r\n% Output       \r\n%   x        array of approximations (one per column, last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 1000*eps;  xtol = 1000*eps;  maxiter = 40;\r\n\r\nx = x1(:);  \r\n[y,J] = f(x1);\r\ndx = Inf;\r\nk = 1;\r\n\r\nwhile (norm(dx) > xtol) && (norm(y) > funtol) && (k < maxiter)\r\n    dx = -(J\\y);   % Newton step\r\n    x(:,k+1) = x(:,k) + dx;\r\n\r\n    k = k+1;\r\n    [y,J] = f(x(:,k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nNewton’s method for systems\n\ndef newtonsys(f, jac, x1):\n    \"\"\"\n        newtonsys(f, jac, x1)\n\n    Use Newton's method to find a root of a system of equations, starting from `x1`. The\n    function `f` should return the residual vector, and the function `jac` should return \n    the Jacobian matrix. Returns root estimates as a matrix, one estimate per column.\n    \"\"\"\n    # Operating parameters.\n    funtol = 1000 * np.finfo(float).eps\n    xtol = 1000 * np.finfo(float).eps\n    maxiter = 40\n\n    x = np.zeros((len(x1), maxiter))\n    x[:, 0] = x1\n    y, J = f(x1), jac(x1)\n    dx = 10.0  # for initial pass below\n    k = 0\n\n    while (norm(dx) > xtol) and (norm(y) > funtol) and (k < maxiter):\n        dx = -lstsq(J, y)[0]  # Newton step\n        x[:, k+1] = x[:, k] + dx\n\n        k = k + 1\n        y, J = f(x[:, k]), jac(x[:, k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:, :k+1]\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nConvergence of Newton’s method for systems\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nBe careful when coding a Jacobian all in one statement. Spaces separate columns, so x[3]-1 is not the same as x[3] - 1.\n\nfunction func(x)\n    [exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\nend;\n\nfunction jac(x)\n    [\n        -exp(x[2] - x[1]) exp(x[2] - x[1]) 0\n        x[2] x[1] 1\n        2*x[1] x[3]-1 x[2]\n    ]\nend;\n\nWe will use a BigFloat starting value, and commensurately small stopping tolerances, in order to get a sequence long enough to measure convergence.\n\nx₁ = BigFloat.([0, 0, 0])\nϵ = eps(BigFloat)\nx = FNC.newtonsys(func, jac, x₁, xtol=ϵ, ftol=ϵ);\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x[end]\n@show residual = norm(func(r));\n\nWe take the sequence of norms of errors, applying the log so that we can look at the exponents.\n\nlogerr = [Float64(log(norm(r - x[k]))) for k in 1:length(x)-1]\n[logerr[k+1] / logerr[k] for k in 1:length(logerr)-1]\n\nThe ratio is neatly converging toward 2, which is expected for quadratic convergence.\n\nConvergence of Newton’s method for systems\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nThis function needs to be defined within a script file or in a file of its own with the .m extension.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nSince our system function is defined in an external file here, we need to use @ in order to reference it as a function argument.\n\nnlsystem = @f45_nlsystem;\nx1 = [0; 0; 0];    % column vector!\nx = newtonsys(nlsystem, x1);\nnum_iter = size(x, 2)\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x(:, end)\nback_err = norm(nlsystem(r))\n\nWe take the sequence errors in the first component of the solution, applying the log so that we can look at the exponents.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'\n\nThis sequence looks to be nearly doubling at each iteration, which is a good sign of quadratic convergence.\n\nConvergence of Newton’s method for systems\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\ndef jac(x):\n    return array([\n            [-exp(x[1] - x[0]), exp(x[1] - x[0]), 0],\n            [x[1], x[0], 1],\n            [2 * x[0], x[2] - 1, x[1]],\n    ])\n\nOur initial guess at a root is the origin.\n\nx1 = zeros(3)\nx = FNC.newtonsys(func, jac, x1)\nprint(x)\n\nThe output has one column per iteration, so the last column contains the final Newton estimate. Let’s compute the residual of the last result.\n\nr = x[:, -1]\nf = func(r)\nprint(\"final residual:\", f)\n\nLet’s check the convergence rate:\n\nlogerr = [log(norm(x[:, k] - r)) for k in range(x.shape[1] - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])\n\nThe ratio is apparently converging toward 2, as expected for quadratic convergence.","type":"content","url":"/newtonsys#implementation","position":7},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Exercises"},"type":"lvl2","url":"/newtonsys#exercises","position":8},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Exercises"},"content":"✍ Suppose that\\mathbf{f}(\\mathbf{x}) =\n\\begin{bmatrix}\n  x_1x_2+x_2^2-1 \\\\[1mm] x_1x_2^3 + x_1^2x_2^2 + 1\n\\end{bmatrix}.\n\nLet \\mathbf{x}_1=[-2,1]^T. Use Newton’s method to find \\mathbf{x}_2.\n\n✍ Suppose that \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b} for a constant n\\times n matrix \\mathbf{A} and constant n\\times 1 vector \\mathbf{b}. Show that Newton’s method converges to the exact root in one iteration.\n\nTwo curves in the (u,v) plane are defined implicitly by the equations u\\log u + v \\log v = -0.3 and u^4 + v^2 = 1.\n\n(a) ✍ Write the intersection of these curves in the form \\mathbf{f}(\\mathbf{x}) = \\boldsymbol{0} for two-dimensional \\mathbf{f} and \\mathbf{x}.\n\n(b) ✍ Find the Jacobian matrix of \\mathbf{f}.\n\n(c) ⌨ Use \n\nFunction 4.5.2 to find an intersection point starting from u=1, v=0.1.\n\n(d) ⌨ Use \n\nFunction 4.5.2 to find an intersection point starting from u=0.1, v=1.\n\nTwo elliptical orbits (x_1(t),y_1(t)) and (x_2(t),y_2(t)) are described by the equations\\begin{bmatrix}\n  x_1(t) \\\\ y_1(t)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  -5+10\\cos(t) \\\\ 6\\sin(t)\n\\end{bmatrix}, \\qquad\n\\begin{bmatrix}\n  x_2(t)\\\\y_2(t)\n\\end{bmatrix} =\n\\begin{bmatrix}\n  8\\cos(t) \\\\ 3+12\\sin(t)\n\\end{bmatrix},\n\nwhere t represents time.\n\n(a) ⌨ Make a plot of the two orbits with the following code:x1(t) = -5+10*cos(t);   y1(t) = 6*sin(t);\nplot(x1,y1,0,2pi,aspect_ratio=1,legend=false)\nx2(t) = 8*cos(t);   y2(t) = 3 + 12*sin(t);\nplot!(x2,y2,0,2pi)\n\n(b) ✍ Write out a 2\\times 2 nonlinear system of equations that describes an intersection of these orbits. (Note: An intersection is not the same as a collision—they don’t have to occupy the same point at the same time.)\n\n(c) ✍ Write out the Jacobian matrix of this nonlinear system.\n\n(d) ⌨ Use \n\nFunction 4.5.2 to find all of the unique intersections.\n\n⌨  Suppose one wants to find the points on the ellipsoid x^2/25 + y^2/16 + z^2/9 = 1 that are closest to and farthest from the point (5,4,3). The method of Lagrange multipliers implies that any such point satisfies\\begin{split}\n    x-5 &= \\frac{\\lambda x}{25}, \\\\[1mm]\n    y-4 &= \\frac{\\lambda y}{16}, \\\\[1mm]\n    z-3 &= \\frac{\\lambda z}{9}, \\\\[1mm]\n    1 &=  \\frac{1}{25}x^2 + \\frac{1}{16}y^2 + \\frac{1}{9}z^2\n\\end{split}\n\nfor an unknown value of λ.\n\n(a) Write out this system in the form \\mathbf{f}(\\mathbf{u}) = \\boldsymbol{0}. (Note that the system has four variables to go with the four equations.)\n\n(b) Write out the Jacobian matrix of this system.\n\n(c) Use \n\nFunction 4.5.2 with different initial guesses to find the two roots of this system. Which is the closest point to (5,4,3), and which is the farthest?\n\n⌨  Any three noncollinear points in the plane determine a unique circle. Suppose the points are given as (x_i,y_i) for i=1,2,3. We can define the circle in terms of its center (a,b) and radius r. Thenf_i(a,b,r) = (a-x_i)^2 + (b-y_i)^2 - r^2\n\nshould be made zero for all i=1,2,3. This defines a nonlinear system \\mathbf{f}(\\mathbf{v})=\\boldsymbol{0} for \\mathbf{v}=[a,b,r].\n\nUse \n\nFunction 4.5.2 on this system to find the circle passing through (-5,0), (1,-3), and (4,2). Make a plot that shows you found the correct circle.","type":"content","url":"/newtonsys#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-3","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The fixed point iteration has been used to prove results about convergence; see Quarteroni et al. \n\nQuarteroni et al. (2007) for more details.\n\nSolving nonlinear systems is a complex task.  Some classic texts on the subject include Ortega and Rheinbolt \n\nOrtega & Rheinboldt (2014), Kelley \n\nKelley (1995), and many others.\n\nTurning to nonlinear least squares, the widely used Levenberg–Marquardt algorithm has a connection to the authors’ home institution.  Donald Marquardt completed an MS in mathematics and statistics at the University of Delaware in 1956 entitled “Application of Digital Computers to Statistics.” He developed the method while working at DuPont Corporation’s laboratories; he worked there from 1953 to 1991.  He needed a better fitting method for experimental data generated at DuPont, and did just that.  The method was published in 1963 in the Journal of the Society for Industrial and Applied Mathematics \n\nMarquardt (1963). In a note at the end, he thanks a referee for pointing out that Levenberg had published related ideas elsewhere \n\nLevenberg (1944), and then cites that work.  He also made a FORTRAN program available that contained an implementation of the program.  There’s a lesson there for budding mathematical software designers:  If you want people to use your algorithm or method, give away software to do it!  An interesting discussion of the evolution of computing during his career at DuPont can be found in an interview \n\nHahn (1995).\n\nOptimization is closely linked to solving nonlinear equations as well.  More info can be found, among many other places, in Strang \n\nStrang (2007), Quarteroni et al. \n\nQuarteroni et al. (2007), and Conn et al. \n\nConn et al. (2009).\n\nFinally, we close with a remark about polynomials.  Polynomials are common, and finding their roots is a frequently occurring task. As we saw in \n\nChapter 1, however, the condition number of polynomial rootfinding can be large, and the possibility of complex roots is another challenge. It turns out that while general-purpose rootfinding can work for polynomials, it’s faster and more robust to use something tailored to the task. One of the best known ways is by converting the problem to one of finding the eigenvalues of a related matrix. A recent paper on the subject won an outstanding paper award from the Society for Industrial and Applied Mathematics \n\nAurentz et al. (2015); it used a clever combination of the companion matrix together with a specialized QR factorization to develop a fast and backward stable method. That paper also contains a very good comparison among modern methods for polynomial rootfinding.","type":"content","url":"/next-3","position":1},{"hierarchy":{"lvl1":"Nonlinear least squares"},"type":"lvl1","url":"/nlsq","position":0},{"hierarchy":{"lvl1":"Nonlinear least squares"},"content":"After the solution of square linear systems, we generalized to the case of having more constraints to satisfy than available variables. Our next step is to do the same for nonlinear equations, thus filling out this table:\n\n\n\nlinear\n\nnonlinear\n\nsquare\n\n\\mathbf{A}\\mathbf{x}=\\mathbf{b}\n\n\\mathbf{f}(\\mathbf{x})=\\boldsymbol{0}\n\noverdetermined\n\n\\min\\, \\bigl|\\mathbf{A}\\mathbf{x} - \\mathbf{b}\\bigr|_2\n\n\\min\\, \\bigl|\\mathbf{f}(\\mathbf{x}) \\bigr|_2\n\nNonlinear least-squares problem\n\nGiven a function \\mathbf{f}(\\mathbf{x}) mapping from \\real^n to \\real^m, the nonlinear least-squares problem is to find \\mathbf{x}\\in\\real^n such that \\bigl\\|\\mathbf{f}(\\mathbf{x})\\bigr\\|_2 is minimized.\n\nAs in the linear case, we consider only overdetermined problems, where m>n. Minimizing a positive quantity is equivalent to minimizing its square, so we could also define the result as minimizing \\phi(\\mathbf{x})=\\mathbf{f}(\\mathbf{x})^T\\mathbf{f}(\\mathbf{x}).","type":"content","url":"/nlsq","position":1},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Gauss–Newton method"},"type":"lvl2","url":"/nlsq#gauss-newton-method","position":2},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Gauss–Newton method"},"content":"You should not be surprised to learn that we can formulate an algorithm by substituting a linear model function for \\mathbf{f}. At a current estimate \\mathbf{x}_k we define  \\mathbf{q}(\\mathbf{x})  = \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{A}_k(\\mathbf{x}-\\mathbf{x}_k),\n\nwhere \\mathbf{A}_k is the exact m\\times n Jacobian matrix, \\mathbf{J}(\\mathbf{x}_k), or an approximation of it as described in \n\nQuasi-Newton methods.\n\nIn the square case, we solved \\mathbf{q}=\\boldsymbol{0} to define the new value for \\mathbf{x}, leading to the condition \\mathbf{A}_k\\mathbf{s}_k=-\\mathbf{f}_k, where  \\mathbf{s}_k=\\mathbf{x}_{k+1}-\\mathbf{x}_k. Now, with m>n, we cannot expect to solve \\mathbf{q}=\\boldsymbol{0}, so instead we define \\mathbf{x}_{k+1} as the value that minimizes \\| \\mathbf{q} \\|_2.\n\nGauss–Newton method\n\nGiven \\mathbf{f} and a starting value \\mathbf{x}_1, for each k=1,2,3,\\ldots\n\nCompute \\mathbf{y}_k = \\mathbf{f}(\\mathbf{x}_k) and \\mathbf{A}_k, the exact or approximate Jacobian matrix at \\mathbf{x}_k.\n\nSolve the linear least squares problem \\argmin \\| \\mathbf{A}_k\\mathbf{s}_k  + \\mathbf{y}_k\\|_2 for \\mathbf{s}_k.\n\nLet \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\mathbf{s}_k.\n\nIn brief, Gauss–Newton solves a series of linear least-squares problems in order to solve a nonlinear least-squares problem.\n\nSurprisingly, \n\nFunction 4.5.2 and \n\nFunction 4.6.3, which were introduced for the case of m=n nonlinear equations, work without modification as the Gauss–Newton method for the overdetermined case! The reason is that the backslash operator applies equally well to the linear system and linear least-squares problems, and nothing else in those functions was written with explicit reference to n.","type":"content","url":"/nlsq#gauss-newton-method","position":3},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Convergence"},"type":"lvl2","url":"/nlsq#convergence","position":4},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Convergence"},"content":"In the multidimensional Newton method for a nonlinear system, we expect quadratic convergence to a solution in the typical case. For the Gauss–Newton method, the picture is more complicated.\n\nAs always in least-squares problems, the residual \\mathbf{f}(\\mathbf{x}) will not necessarily be zero when \\|\\mathbf{f}\\| is minimized. Suppose that the minimum value of \\|\\mathbf{f}\\| is R>0. In general, we might observe quadratic-like convergence until the iterate \\|\\mathbf{x}_k\\| is within distance R of a true minimizer, and linear convergence thereafter. When R is not sufficiently small, the convergence can be quite slow.\n\nConvergence of nonlinear least squares\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng(x) = [sin(x[1] + x[2]), cos(x[1] - x[2]), exp(x[1] - x[2])]\np = [1, 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nplt = plot(xlabel=\"iteration\", yaxis=(:log10, \"error\"),\n    title=\"Convergence of Gauss–Newton\")\nfor R in [1e-3, 1e-2, 1e-1]\n    # Define the perturbed function.\n    f(x) = g(x) - g(p) + R * normalize([-1, 1, -1])\n    x = FNC.levenberg(f, [0, 0])\n    r = x[end]\n    err = [norm(x - r) for x in x[1:end-1]]\n    normres = norm(f(r))\n    plot!(err, label=@sprintf(\"R=%.2g\", normres))\nend\nplt\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nConvergence of nonlinear least squares\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = @(x) [sin(x(1) + x(2)); cos(x(1) - x(2)); exp(x(1) - x(2))];\np = [1; 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nclf\nlabels = [];\nfor R = [1e-3, 1e-2, 1e-1]\n    % Define the perturbed function.\n    f = @(x) g(x) - g(p) + R * [-1; 1; -1] / sqrt(3)\n    x = levenberg(f, [0; 0]);\n    r = x(:, end);\n    err = abs(x(1, 1:end-1) - r(1));\n    normres = norm(f(r));\n    semilogy(err), hold on\n    labels = [labels; sprintf(\"R=%.2g\", normres)];\nend\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend(labels)\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nConvergence of nonlinear least squares\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = lambda x: array([sin(x[0] + x[1]), cos(x[0] - x[1]), exp(x[0] - x[1])])\np = array([1, 1])\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nfor R in [1e-3, 1e-2, 1e-1]:\n    # Define the perturbed function.\n    f = lambda x: g(x) - g(p) + R * array([-1, 1, -1]) / sqrt(3)\n    x = FNC.levenberg(f, [0, 0])\n    r = x[:, -1]\n    err = [norm(x[:, j] - r) for j in range(x.shape[1] - 1)]\n    normres = norm(f(r))\n    semilogy(err, label=f\"R={normres:.2g}\")\ntitle(\"Convergence of Gauss–Newton\")\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend();\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.","type":"content","url":"/nlsq#convergence","position":5},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Nonlinear data fitting"},"type":"lvl2","url":"/nlsq#nonlinear-data-fitting","position":6},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Nonlinear data fitting"},"content":"In \n\nFitting functions to data we saw how to fit functions to data values, provided that the set of candidate fitting functions depends linearly on the undetermined coefficients. We now have a tool to generalize that process to fitting functions that depend nonlinearly on unknown parameters.\n\nSuppose that (t_i,y_i) for i=1,\\ldots,m are given points. We wish to model the data by a function g(t,\\mathbf{x}) that depends on unknown parameters x_1,\\ldots,x_n in an arbitrary way. A standard approach is to minimize the discrepancy between the model and the observations, in a least-squares sense. Define\\mathbf{f}(\\mathbf{x}) = \\left[\\, g(t_i,\\mathbf{x})-y_i  \\, \\right]_{\\,i=1,\\ldots,m}.\n\nWe call \\mathbf{f} a misfit function. By minimizing \\bigl\\| \\mathbf{f}(\\mathbf{c}) \\bigr\\|^2, we get the best possible fit to the data. If an explicit Jacobian matrix is desired for the minimization, we can compute\\mathbf{f}{\\,}'(\\mathbf{x}) = \\left[ \\frac{\\partial}{\\partial x_j} g(t_i,\\mathbf{x}) \\right]_{\\,i=1,\\ldots,m;\\,j=1,\\ldots,n.}\n\nThe form of g is up to the modeler. There may be compelling theoretical choices, or you may just be looking for enough algebraic power to express the data well. Naturally, in the special case where the dependence on \\mathbf{c} is linear, i.e.,  g(t,\\mathbf{c}) = c_1 g_1(t) + c_2 g_2(t) + \\cdots + c_m g_m(t),\n\nthen the misfit function is also linear in \\mathbf{c} and the fitting problem reduces to linear least squares.\n\nInhibited enzyme reactions often follow what are known as Michaelis–Menten kinetics, in which a reaction rate w follows a law of the formw(s) = \\frac{V s}{K_m + s},\n\nwhere s is the concentration of a substrate. The real values V and K_m are parameters that are free to fit to data. For this example, we cook up some artificial data with V=2 and K_m=1/2.\n\nNonlinear data fitting\n\nm = 25;\ns = range(0.05, 6, length=m)\nŵ = @. 2 * s / (0.5 + s)                      # exactly on the curve\nw = @. ŵ + 0.15 * cos(2 * exp(s / 16) * s);     # smooth noise added\n\nscatter(s, w, label=\"noisy data\",\n    xlabel=\"s\", ylabel=\"v\", leg=:bottomright)\nplot!(s, ŵ, l=:dash, color=:black, label=\"perfect data\")\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\nfunction misfit(x)\n    V, Km = x   # rename components for clarity\n    return @. V * s / (Km + s) - w\nend\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction misfitjac(x)\n    V, Km = x   # rename components for clarity\n    J = zeros(m, 2)\n    J[:, 1] = @. s / (Km + s)              # dw/dV\n    J[:, 2] = @. -V * s / (Km + s)^2         # dw/d_Km\n    return J\nend\n\nx₁ = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x₁)\n\n@show V, Km = x[end]  # final values\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\nmodel(s) = V * s / (Km + s)\nplot!(model, 0, 6, label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nA = [s .^ (-1) s .^ 0]\nu = 1 ./ w\nα, β = A \\ u\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel(x) = 1 / (β + α / x)\nplot!(linmodel, 0, 6, label=\"linearized fit\")\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.\n\nNonlinear data fitting\n\nm = 25; V = 2; Km = 0.5;\ns = linspace(0.05, 6, m)';\nw = V * s ./ (Km + s);                      % exactly on the curve\nw = w + 0.15 * cos(2 * exp(s / 16) .* s);   % noise added\nclf, fplot(@(s) V * s ./ (Km + s), [0, 6], '--')\nhold on, scatter(s, w)\nxlabel('concentration'), ylabel('reaction rate')    \nlabels = [\"ideal\", \"noisy data\"];    \nlegend(labels, 'location', 'east')\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g. In the Jacobian, the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction [f, J] = misfit(c, s, w)\n    V = c(1);   Km = c(2);\n    f = V * s ./ (Km + s) - w;\n    J(:,1) = s ./ (Km + s);            % d/d(V)\n    J(:,2) = -V * s ./ (Km + s).^2;    % d/d(Km)\nend\n\n\nThe misfit function above has to know the parameters x that are being optimized as well as the data s and w that remain fixed. We use a closure to pass the data values along.\n\nf = @(x) f47_misfit(x, s, w);\n\nNow we have a function that accepts a single 2-vector input and returns a 25-vector output. We can pass this function to levenberg to find the best-fit parameters.\n\nx1 = [1; 0.75];\nx = newtonsys(f, x1);\nV = x(1, end),  Km = x(2, end)     % final values\nmodel = @(s) V * s ./ (Km + s);    % best-fit model\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data:\n\nfinal_misfit_norm = norm(model(s) - w) \nhold on, fplot(model, [0, 6])\ntitle('Michaelis-Menten fitting')    \nlabels = [labels, \"nonlinear fit\"];    \nlegend(labels, 'location', 'east')\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nu = 1 ./ w;\nA = [s.^(-1), s.^0];  \nz = A \\ u;\nalpha = z(1);  beta = z(2);\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel = @(s) 1 ./ (beta + alpha ./ s);\nfinal_misfit_linearized = norm(linmodel(s) - w)\nfplot(linmodel, [0, 6])\nlabels = [labels, \"linearized fit\"];    \nlegend(labels, 'location', 'east')\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.\n\nNonlinear data fitting\n\nm = 25\nV, Km = 2, 0.5\ns = linspace(0.05, 6, m)\nmodel = lambda x: V * x / (Km + x)\nw = model(s) + 0.15 * cos(2 * exp(s / 16) * s)    # noise added\n\nfig, ax = subplots()\nax.scatter(s, w, label=\"data\")\nax.plot(s, model(s), 'k--', label=\"unperturbed model\")\nxlabel(\"s\"), ylabel(\"w\")\nlegend()\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\ndef misfit(c):\n    V, Km = c  # rename components for clarity\n    f = V * s / (Km + s) - w\n    return f\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\ndef misfitjac(x):\n    V, Km = x   # rename components for clarity\n    J = zeros([m, 2])\n    J[:, 0] = s / (Km + s)          # d/d(V)\n    J[:, 1] = -V * s / (Km + s)**2  # d/d(Km)\n    return J\n\nx1 = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x1)\nV, Km = x[:, -1]  # final values\nprint(f\"estimates are V = {V:.3f}, Km = {Km:.3f}\")\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\n# since V and Km have been updated, model() is too\nax.plot(s, model(s), label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nfrom numpy.linalg import lstsq\nA = array( [[1 / s[i], 1.0] for i in range(len(s))] )\nz = lstsq(A, 1 / w, rcond=None)[0]\nalpha, beta = z\nprint(\"alpha:\", alpha, \"beta:\", beta)\n\nThe two fits are different; they do not optimize the same quantities.\n\nlinmodel = lambda x: 1 / (beta + alpha / x)\nax.plot(s, linmodel(s), label=\"linear fit\")\nax.legend()\nfig\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/nlsq#nonlinear-data-fitting","position":7},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Exercises"},"type":"lvl2","url":"/nlsq#exercises","position":8},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Exercises"},"content":"✍ Define \\mathbf{f}(x)=[ x-8, \\; x^2-4 ].\n\n(a) Write out the linear model of \\mathbf{f} at x=2.\n\n(b) Find the estimate produced by one step of the Gauss–Newton method, starting at x=2.\n\n✍ (Continuation of Exercise 1.) The Gauss–Newton method replaces \\mathbf{f}(\\mathbf{x}) by a linear model and minimizes the norm of its residual. An alternative is to replace \\| \\mathbf{f}(\\mathbf{x}) \\|_2^2 by a scalar quadratic model q(\\mathbf{x}) and minimize that.\n\n(a) Using \\mathbf{f}(x) = [ x-8, \\; x^2-4 ], let q(x) be defined by the first three terms in the Taylor series for \\| \\mathbf{f}(x) \\|_2^2 at x=2.\n\n(b) Find the unique x that minimizes q(x). Is the result the same as the estimate produced by Gauss–Newton?\n\n⌨  A famous result by Kermack and McKendrick in 1927 \n\nKermack et al. (1927) suggests that in epidemics that kill only a small fraction of a susceptible population, the death rate as a function of time is well modeled byw'(t) = A \\operatorname{sech}^2[B(t-C)]\n\nfor constant values of the parameters A,B,C. Since the maximum of sech is \\operatorname{sech}(0)=1, A is the maximum death rate and C is the time of peak deaths. You will use this model to fit the deaths per week from plague recorded in Mumbai\nduring 1906:5, 10, 17, 22, 30, 50, 51, 90, 120, 180, 292, 395, 445, 775, 780,\n700, 698, 880, 925, 800, 578, 400, 350, 202, 105, 65, 55, 40, 30, 20\n\n(a) Use \n\nFunction 4.6.3 to find the best least-squares fit to the data using the \\operatorname{sech}^2 model. Make a plot of the model fit superimposed on the data.\n\n(b) Repeat part (a) using only the first 15 data values.\n\n⌨  (Variation on \n\nExercise 4.5.6.) Suppose the points (x_i,y_i) for i=1,\\ldots,m are given, and the goal is to find the circle with center (a,b) and radius r that best fits the points. Definef_i(a,b,r) = (a-x_i)^2 + (b-y_i)^2 - r^2, \\qquad i=1,\\ldots,m.\n\nThen we can define the best circle as the one that minimizes \\|\\mathbf{f}\\|.\n\nDefine data points as follows:m = 30; t = 2π*rand(m);\nx = @. -2 + 5*cos(t); y = @. 1 + 5*sin(t);\nx += 0.2*randn(m); y += 0.2*randn(m);\n\nUse \n\nFunction 4.6.3 to find the best-fit circle, and make a plot of the circle superimposed on the points.\n\n⌨ The position of the upper lid during an eye blink can be measured from high-speed video \n\nWu et al. (2014), and it may be possible to classify blinks based in part on fits to the lid position \n\nBrosch et al. (2017). The lid position functions proposed to fit blinks is a product of a monomial or polynomial multiplying a decaying exponential \n\nBerke & Mueller (1998).  In this problem, you will generate representative data, add a small amount of noise to it, and then perform nonlinear least-squares fits to the data.\n\n(a) Consider the function y(\\mathbf{a}) = a_1 t^2 \\exp \\left( -a_2 t^{a_3} \\right), using the vector of coefficients \\mathbf{a} = [a_1,a_2,a_3], and create synthetic eyelid position data as follows:N = 20;                            # number of time values\nt = (1:N)/N;                       # equally spaced to t=1\na = [10, 10, 2];                   # baseline values\ny = @. a(1)*t^2*exp(-a(2)*t^a(3)); # ideal data\nym = copy(y);                      # vector for data\nir = 1:N-1;                        # range to add noise\nnoise = 0.03;                      # amplitude of noise\nym[ir] += noise*rand(N-1);         # add noise\n\n(b) Using the data (t,ym), find the nonlinear least-squares fit using \n\nFunction 4.6.3.\n\n(c) Plot the fits using np = 100 points over t=(1:np)/np together with symbols for the N measured data points ym.\n\n(d) Increase the noise to 5% and 10%. You may have to increase the number of measured points N and/or the maximum number of iterations.  How close are the coefficients?  Plot the data and the resulting fit for each case.\n\n⌨ Repeat the previous problem using the fitting function y(\\mathbf{a}) = (a_1+a_2 t + a_3 t^2) t^2 \\exp \\left( -a_4 t^{a_5} \\right), using the vector of coefficients \\mathbf{a} = [a_1,\\ldots,a_5]. (This was the choice used in Brosch et al \n\nBrosch et al. (2017).)  Use a = [20, -10, -8, 7, 2] to create the data and as an initial guess for the coefficients for the fit to the noisy data.","type":"content","url":"/nlsq#exercises","position":9},{"hierarchy":{"lvl1":"Roots of nonlinear equations"},"type":"lvl1","url":"/overview-3","position":0},{"hierarchy":{"lvl1":"Roots of nonlinear equations"},"content":"He says “I found her,” and keeps repeating, “She’s here.”\n\nC3PO, Star Wars: A New Hope\n\nIn this chapter we extend from linear algebra to deal with nonlinear algebraic problems. This kind of problem arises when there is a parameter or variable that can be changed in order to satisfy a constraint or achieve some goal. We start with scalar functions of a single variable, then generalize to n variables and n nonlinear equations. Finally, we generalize the problem of linear least squares to situations with more nonlinear constraints to satisfy than there are variables. In every case the strategy used is one of the cornerstones of numerical computing: replace a problem you can’t solve with an approximate one that you can. In the context of nonlinear algebraic problems, the particular tactic is to set up and solve a sequence of linear problems of the types covered in the two previous chapters.","type":"content","url":"/overview-3","position":1},{"hierarchy":{"lvl1":"Quasi-Newton methods"},"type":"lvl1","url":"/quasinewton","position":0},{"hierarchy":{"lvl1":"Quasi-Newton methods"},"content":"Newton’s method is a foundation for algorithms to solve equations and minimize quantities. But it is not ideal in its straightforward or pure form. Specifically, its least appealing features are the programming nuisance and computational expense of evaluating the Jacobian matrix, and the tendency of the iteration to diverge from many starting points. There are different quasi-Newton methods that modify the basic idea in an attempt to overcome these issues.","type":"content","url":"/quasinewton","position":1},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Jacobian by finite differences"},"type":"lvl2","url":"/quasinewton#jacobian-by-finite-differences","position":2},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Jacobian by finite differences"},"content":"In the scalar case, we found an easy alternative to a direct evaluation of the derivative. In retrospect, we may interpret the secant formula \n\n(4.4.2) as the Newton formula \n\n(4.3.2) with f'(x_k) replaced by the difference quotient  \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}.\n\nIf the sequence of x_k values converges to a root r, then this quotient converges to f'(r).\n\nIn the system case, replacing the Jacobian evaluation is more complicated: derivatives are needed with respect to n variables, not just one. From \n\n(4.5.4), we note that the jth column of the Jacobian is  \\mathbf{J}(\\mathbf{x}) \\mathbf{e}_j =\n  \\begin{bmatrix}\n    \\frac{\\partial{f_1}}{\\partial x_j} \\\\[2mm] \\frac{\\partial{f_2}}{\\partial x_j}\n    \\\\ \\vdots \\\\ \\frac{\\partial{f_n}}{\\partial x_j}\n  \\end{bmatrix}.\n\n(As always, \\mathbf{e}_j represents the jth column of the identity matrix, here in n dimensions.) Inspired by \n\n(4.6.1), we can replace the differentiation with a quotient involving a change in only x_j while the other variables remain fixed:  \\mathbf{J}(\\mathbf{x}) \\mathbf{e}_j \\approx\n  \\frac{\\mathbf{f}(\\mathbf{x}+\\delta \\mathbf{e}_j) - \\mathbf{f}(\\mathbf{x})}{\\delta}, \\qquad j=1,\\ldots,n.\n\nFor reasons explained in Chapter 5, δ is usually chosen close to \\sqrt{\\epsilon}, where ε represents the expected noise or uncertainty level in evaluation of \\mathbf{f}. If the only source of noise is floating-point roundoff, then \\delta \\approx \\sqrt{\\epsilon_\\text{mach}}.\n\nThe finite-difference formula \n\n(4.6.3) is implemented by \n\nFunction 4.6.1.\n\nfdjac\n\nFinite differences for Jacobian\n\n\"\"\"\n    fdjac(f,x₀[,y₀])\n\nCompute a finite-difference approximation of the Jacobian matrix for\n`f` at `x₀`, where `y₀`=`f(x₀)` may be given.\n\"\"\"\nfunction fdjac(f,x₀,y₀=f(x₀))\n    δ = sqrt(eps())*max(norm(x₀),1)   # FD step size\n    m,n = length(y₀),length(x₀)\n    if n==1\n        J = (f(x₀+δ) - y₀) / δ\n    else\n        J = zeros(m,n)\n        x = copy(x₀)\n        for j in 1:n\n            x[j] += δ\n            J[:,j] = (f(x) - y₀) / δ\n            x[j] -= δ\n        end\n    end\n    return J\nend\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.\n\nFinite differences for Jacobian\n\nfunction J = fdjac(f,x0,y0)\n% FDJAC   Finite-difference approximation of a Jacobian.\n% Input:\n%   f        function to be differentiated\n%   x0       evaluation point (n-vector)\n%   y0       value of f at x0 (m-vector)\n% Output       \n%   J        approximate Jacobian (m-by-n)\n\ndelta = sqrt(eps);   % FD step size\nm = length(y0);  n = length(x0);\nJ = zeros(m,n);\nI = eye(n);\nfor j = 1:n\n    J(:,j) = ( f(x0+delta*I(:,j)) - y0) / delta;\nend\n\nFinite differences for Jacobian\n\ndef fdjac(f, x0, y0):\n    \"\"\"\n    fdjac(f,x0,y0)\n\n    Compute a finite-difference approximation of the Jacobian matrix for `f` at `x0`,\n    where `y0`=`f(x0)` is given.\n    \"\"\"\n\n    delta = np.sqrt(np.finfo(float).eps)  # FD step size\n    m, n = len(y0), len(x0)\n    J = np.zeros((m, n))\n    I = np.eye(n)\n    for j in range(n):\n        J[:, j] = (f(x0 + delta * I[:, j]) - y0) / delta\n    return J\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.","type":"content","url":"/quasinewton#jacobian-by-finite-differences","position":3},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Broyden’s update"},"type":"lvl2","url":"/quasinewton#broydens-update","position":4},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Broyden’s update"},"content":"The finite-difference Jacobian is easy to conceive and use. But, as you can see from \n\n(4.6.3), it requires n additional evaluations of the system function at each iteration, which can be unacceptably slow in some applications. Conceptually these function evaluations seem especially wasteful given that the root estimates, and thus presumably the Jacobian matrix, are supposed to change little as the iteration converges. This is a good time to step in with the principle of approximate approximation, which suggests looking for a shortcut in the form of a cheap-but-good-enough way to update the Jacobian from one iteration to the next.\n\nRecall that the Newton iteration is derived by solving the linear model implied by \n\n(4.5.3):  \\mathbf{f}(\\mathbf{x}_{k+1}) \\approx \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{J}(\\mathbf{x}_k)\\,(\\mathbf{x}_{k+1}-\\mathbf{x}_k) = \\boldsymbol{0}.\n\nLet \\mathbf{s}_k=\\mathbf{x}_{k+1}-\\mathbf{x}_k  be the Newton step. Let \\mathbf{y}_k=\\mathbf{f}(\\mathbf{x}_k), and now we replace \\mathbf{J}(\\mathbf{x}_k) by a matrix \\mathbf{A}_{k} that is meant to approximate the Jacobian. Hence the Newton step is considered to be defined, as in \n\nAlgorithm 4.5.1, by  \\mathbf{A}_k \\mathbf{s}_k = -\\mathbf{y}_k.\n\nOnce \\mathbf{x}_{k+1} is obtained, we should update the approximate Jacobian to a new \\mathbf{A}_{k+1}. If we think one-dimensionally for a moment, the secant method would assume that A_{k+1}=(f_{k+1}-f_k)/(x_{k+1}-x_k). It’s not easy to generalize a fraction to vectors, but we can do it if we instead write it as  \\mathbf{y}_{k+1}-\\mathbf{y}_k = \\mathbf{A}_{k+1} (\\mathbf{x}_{k+1}-\\mathbf{x}_k) = \\mathbf{A}_{k+1} \\mathbf{s}_k.\n\nThis is used to justify the following requirement:  \\mathbf{A}_{k+1} \\mathbf{s}_k = \\mathbf{y}_{k+1}-\\mathbf{y}_k.\n\nThis isn’t enough to uniquely determine \\mathbf{A}_{k+1}. However, if we also require that \\mathbf{A}_{k+1}-\\mathbf{A}_k is a matrix of rank 1, then one arrives at the following.\n\nBroyden update formula\n\nUsing the definitions above,  \\mathbf{A}_{k+1} = \\mathbf{A}_k + \\frac{1}{\\mathbf{s}_k^T \\mathbf{s}_k}(\\mathbf{y}_{k+1} - \\mathbf{y}_k -\\mathbf{A}_k \\mathbf{s}_k)\\, \\mathbf{s}_k^T.\n\nObserve that \\mathbf{A}_{k+1}-\\mathbf{A}_k is proportional to the outer product of two vectors, and that computing it requires no extra evaluations of \\mathbf{f}. Remarkably, under reasonable assumptions, the sequence of \\mathbf{x}_k resulting when Broyden updates are used converges superlinearly, even though the matrices \\mathbf{A}_k do not necessarily converge to the Jacobian of \\mathbf{f}.\n\nIn practice, one typically uses finite differences to initialize the Jacobian at iteration k=1. If for some k the step computed by the update formula fails to make enough improvement in the residual, then \\mathbf{A}_k is reinitialized by finite differences and the step is recalculated.","type":"content","url":"/quasinewton#broydens-update","position":5},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Levenberg’s method"},"type":"lvl2","url":"/quasinewton#levenbergs-method","position":6},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Levenberg’s method"},"content":"The most difficult part of many rootfinding problems is finding a starting point that will lead to convergence. The linear model implicitly constructed during a Newton iteration—whether we use an exact, finite-difference, or iteratively updated Jacobian matrix—becomes increasingly inaccurate as one ventures farther from the most recent root estimate, eventually failing to resemble the exact function much at all.\n\nAlthough one could imagine trying to do a detailed accuracy analysis of each linear model as we go, in practice simple strategies are valuable here. Suppose, after computing the step suggested by the linear model, we ask a binary question: Would taking that step improve our situation? Since we are trying to find a root of \\mathbf{f}, we have a quantitative way to pose this question: Does the backward error \\|\\mathbf{f}\\| decrease? If not, we should reject the step and find an alternative.\n\nThere are several ways to find alternatives to the standard step, but we will consider just one of them, based on the parameterized equation  (\\mathbf{A}_k^T \\mathbf{A}_k + \\lambda \\mathbf{I})\\,\\mathbf{s}_k = -\\mathbf{A}_k^T \\mathbf{f}_k.\n\nLevenberg’s method\n\nGiven \\mathbf{f}, a starting value \\mathbf{x}_1, and a scalar λ, for each k=1,2,3,\\ldots\n\nCompute \\mathbf{y}_k = \\mathbf{f}(\\mathbf{x}_k), and let \\mathbf{A}_k be an exact or approximate Jacobian matrix.\n\nSolve the linear system \n\n(4.6.9) for \\mathbf{s}_k.\n\nLet \\hat{\\mathbf{x}} = \\mathbf{x}_k + \\mathbf{s}_k.\n\nIf the residual is reduced at \\hat{\\mathbf{x}}, then let \\mathbf{x}_{k+1}=\\hat{\\mathbf{x}}.\n\nUpdate λ and update \\mathbf{A}_k to \\mathbf{A}_{k+1}.\n\nSome justification of \n\n(4.6.9) comes from considering extreme cases for λ. If \\lambda=0, then  \\mathbf{A}_k^T \\mathbf{A}_k \\mathbf{s}_k = -\\mathbf{A}_k^T \\mathbf{f}_k,\n\nwhich is equivalent to the definition of the usual linear model (i.e., Newton or quasi-Newton) step \n\n(4.6.5). On the other hand, as \\lambda\\to\\infty, Equation \n\n(4.6.9) approaches  \\lambda \\mathbf{s}_k = - \\mathbf{A}_k^T \\mathbf{f}_k.\n\nTo interpret this equation, define the scalar residual function\\phi(\\mathbf{x})=\\mathbf{f}(\\mathbf{x})^T\\mathbf{f}(\\mathbf{x}) = \\|\\mathbf{f}(\\mathbf{x})\\|^2.\n\nFinding a root of \\mathbf{f} is equivalent to minimizing ϕ. A calculation shows that the gradient of ϕ is   \\nabla \\phi(\\mathbf{x}) = 2 \\mathbf{J}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{x}).\n\nHence, if \\mathbf{A}_k=\\mathbf{J}(\\mathbf{x}_k), then \\mathbf{s}_k from \n\n(4.6.11) is in the opposite direction from the gradient vector. In vector calculus you learn that this direction is the one of most rapid decrease or steepest descent. A small enough step in this direction is guaranteed in all but pathological cases to decrease ϕ, which is exactly what we want from a backup plan.\n\nIn effect, the λ parameter in \n\n(4.6.9) allows a smooth transition between the pure Newton step, for which convergence is very rapid near a root, and a small step in the gradient descent direction, which guarantees progress for the iteration when we are far from a root.","type":"content","url":"/quasinewton#levenbergs-method","position":7},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Implementation"},"type":"lvl2","url":"/quasinewton#implementation","position":8},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Implementation"},"content":"To a large extent, the incorporation of finite differences, Jacobian updates, and Levenberg step are independent decisions. \n\nFunction 4.6.3 shows how they might be combined. This function is one of the most logically complex we have encountered so far.\n\nEach pass through the loop starts by using \n\n(4.6.9) to propose a step \\mathbf{s}_k. The function then asks whether using this step would decrease the value of \\|\\mathbf{f}\\| from its present value. If so, we accept the new root estimate, we decrease λ in order to get more Newton-like (since things have gone well), and we apply the Broyden formula to get a cheap update of the Jacobian. If the proposed step is not successful, we increase λ to get more gradient-like (since we just failed) and, if the current Jacobian was the result of a cheap update, use finite differences to reevaluate it.\n\nlevenberg\n\nLevenberg’s method\n\n\"\"\"\n    levenberg(f,x₁[;maxiter,ftol,xtol])\n\nUse Levenberg's quasi-Newton iteration to find a root of the system\n`f` starting from `x₁` Returns the history of root estimates as a \nvector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction levenberg(f,x₁;maxiter=40,ftol=1e-12,xtol=1e-12)\n    x = [float(x₁)]\n    yₖ = f(x₁)\n    k = 1;  s = Inf;\n    A = fdjac(f,x[k],yₖ)   # start with FD Jacobian\n    jac_is_new = true\n\n    λ = 10;\n    while (norm(s) > xtol) && (norm(yₖ) > ftol)\n        # Compute the proposed step.\n        B = A'*A + λ*I\n        z = A'*yₖ\n        s = -(B\\z)\n        \n        x̂ = x[k] + s\n        ŷ = f(x̂)\n\n        # Do we accept the result?\n        if norm(ŷ) < norm(yₖ)    # accept\n            λ = λ/10   # get closer to Newton\n            # Broyden update of the Jacobian.\n            A += (ŷ-yₖ-A*s)*(s'/(s'*s))\n            jac_is_new = false\n            \n            push!(x,x̂)\n            yₖ = ŷ\n            k += 1\n        else                       # don't accept\n            # Get closer to gradient descent.\n            λ = 4λ\n            # Re-initialize the Jacobian if it's out of date.\n            if !jac_is_new\n                A = fdjac(f,x[k],yₖ)\n                jac_is_new = true\n            end\n        end\n\n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n        \n    end\n    return x\nend\n\nLevenberg’s method\n\nfunction x = levenberg(f,x1,tol)\r\n% LEVENBERG   Quasi-Newton method for nonlinear systems.\r\n% Input:\r\n%   f         objective function \r\n%   x1        initial root approximation\r\n%   tol       stopping tolerance (default is 1e-12)\r\n% Output       \r\n%   x         array of approximations (one per column)\r\n\r\n% Operating parameters.\r\nif nargin < 3, tol = 1e-12; end\r\nftol = tol;  xtol = tol;  maxiter = 40;\r\n\r\nx = x1(:);     fk = f(x1);\r\nk = 1;  s = Inf;        \r\nAk = fdjac(f,x(:,1),fk);   % start with FD Jacobian\r\njac_is_new = true;\r\nI = eye(length(x));\r\n\r\nlambda = 10; \r\nwhile (norm(s) > xtol) && (norm(fk) > ftol) && (k < maxiter)\r\n    % Compute the proposed step.\r\n    B = Ak'*Ak + lambda*I;\r\n    z = Ak'*fk;\r\n    s = -(B\\z);\r\n\r\n    xnew = x(:,k) + s;   fnew = f(xnew);\r\n    \r\n    % Do we accept the result?\r\n    if norm(fnew) < norm(fk)    % accept\r\n        y = fnew - fk;\r\n        x(:,k+1) = xnew;  fk = fnew;  \r\n        k = k+1;\r\n        \r\n        lambda = lambda/10;  % get closer to Newton\r\n        % Broyden update of the Jacobian.\r\n        Ak = Ak + (y-Ak*s)*(s'/(s'*s));\r\n        jac_is_new = false;\r\n    else                       % don't accept\r\n        % Get closer to steepest descent.\r\n        lambda = lambda*4;\r\n        % Re-initialize the Jacobian if it's out of date.\r\n        if ~jac_is_new\r\n            Ak = fdjac(f,x(:,k),fk);\r\n            jac_is_new = true;\r\n        end\r\n    end\r\nend\r\n\r\nif (norm(fk) > 1e-3)\r\n    warning('Iteration did not find a root.')\r\nend\n\nLevenberg’s method\n\ndef levenberg(f, x1, tol=1e-12):\n    \"\"\"\n    levenberg(f,x1,tol)\n\n    Use Levenberg's quasi-Newton iteration to find a root of the system `f`, starting from\n    `x1`, with `tol` as the stopping tolerance in both step size and residual norm. Returns\n    root estimates as a matrix, one estimate per column.\n    \"\"\"\n\n    # Operating parameters.\n    ftol = tol\n    xtol = tol\n    maxiter = 40\n\n    n = len(x1)\n    x = np.zeros((n, maxiter))\n    x[:, 0] = x1\n    fk = f(x1)\n    k = 0\n    s = 10.0\n    Ak = fdjac(f, x[:, 0], fk)  # start with FD Jacobian\n    jac_is_new = True\n\n    lam = 10\n    while (norm(s) > xtol) and (norm(fk) > ftol) and (k < maxiter):\n        # Compute the proposed step.\n        B = Ak.T @ Ak + lam * np.eye(n)\n        z = Ak.T @ fk\n        s = -lstsq(B, z)[0]\n\n        xnew = x[:, k] + s\n        fnew = f(xnew)\n\n        # Do we accept the result?\n        if norm(fnew) < norm(fk):  # accept\n            y = fnew - fk\n            x[:, k + 1] = xnew\n            fk = fnew\n            k = k + 1\n\n            lam = lam / 10  # get closer to Newton\n            # Broyden update of the Jacobian.\n            Ak = Ak + np.outer(y - Ak @ s, s / np.dot(s, s))\n            jac_is_new = False\n        else:  # don't accept\n            # Get closer to steepest descent.\n            lam = lam * 4\n            # Re-initialize the Jacobian if it's out of date.\n            if not jac_is_new:\n                Ak = fdjac(f, x[:, k], fk)\n                jac_is_new = True\n\n    if norm(fk) > 1e-3:\n        warnings.warn(\"Iteration did not find a root.\")\n    return x[:, :k+1]\n\nIn some cases our simple logic in \n\nFunction 4.6.3 can make λ oscillate between small and large values; several better but more complicated strategies for controlling λ are known. In addition, the linear system \n\n(4.6.9) is usually modified to get the well-known Levenberg–Marquardt algorithm, which does a superior job in some problems as \\lambda\\to \\infty.\n\nUsing Levenberg’s method\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nf(x) = \n    [\n        exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx₁ = [0.0, 0.0, 0.0]\nx = FNC.levenberg(f, x₁)\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[end]\nprintln(\"backward error = $(norm(f(r)))\")\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method.\n\nlogerr = [log(norm(x[k] - r)) for k in 1:length(x)-1]\n[logerr[k+1] / logerr[k] for k in 1:length(logerr)-1]\n\nUsing Levenberg’s method\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nA rule of thumb is that if you use a function as an input argument for another function, there needs to be an @ involved once: either for an anonymous definition or to reference a function defined elsewhere.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nIn all other respects usage is the same as for the newtonsys function.\n\nf = @f46_nlsystem;\nx1 = [0; 0; 0];   \nx = levenberg(f, x1);\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x(:, end)\nbackward_err = norm(f(r))\n\nLooking at the convergence of the first component, we find a rate between linear and quadratic, like with the secant method.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'\n\nUsing Levenberg’s method\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx1 = zeros(3)\nx = FNC.levenberg(func, x1)\nprint(f\"Took {x.shape[1]-1} iterations.\")\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[:, -1]\nprint(\"backward error:\", norm(func(r)))\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method:\n\nlogerr = [log(norm(x[:, k] - r)) for k in range(x.shape[1] - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])","type":"content","url":"/quasinewton#implementation","position":9},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Exercises"},"type":"lvl2","url":"/quasinewton#exercises","position":10},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Exercises"},"content":"⌨ (Variation on \n\nExercise 4.5.2.) Two curves in the (u,v) plane are defined implicitly by the equations u\\log u + v \\log v = -0.3 and u^4 + v^2 = 1.\n\n(a) ✍ Write the intersection of these curves in the form \\mathbf{f}(\\mathbf{x}) = \\boldsymbol{0} for two-dimensional \\mathbf{f} and \\mathbf{x}.\n\n(b) ⌨ Use \n\nFunction 4.6.3 to find an intersection point starting from u=1, v=0.1.\n\n(d) ⌨ Use \n\nFunction 4.6.3 to find an intersection point starting from u=0.1, v=1.\n\n⌨ (Variation on \n\nExercise 4.5.4) Two elliptical orbits (x_1(s),y_1(s)) and (x_2(t),y_2(t)) are described by the equations\\begin{bmatrix}\n  x_1(t) \\\\ y_1(t)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  -5+10\\cos(t) \\\\ 6\\sin(t)\n\\end{bmatrix}, \\qquad\n\\begin{bmatrix}\n  x_2(t)\\\\y_2(t)\n\\end{bmatrix} =\n\\begin{bmatrix}\n  8\\cos(t) \\\\ 1+12\\sin(t)\n\\end{bmatrix},\n\nwhere t represents time.\n\n(a) ✍ Write out a 2\\times 2 nonlinear system of equations that describes an intersection of these orbits. (Note: An intersection is not the same as a collision—they don’t have to occupy the same point at the same time.)\n\n(b) ⌨ Use \n\nFunction 4.6.3 to find all of the unique intersections.\n\n⌨  (Variation on \n\nExercise 4.5.5) Suppose one wants to find the points on the ellipsoid x^2/25 + y^2/16 + z^2/9 = 1 that are closest to and farthest from the point (5,4,3). The method of Lagrange multipliers implies that any such point satisfies\\begin{split}\n    x-5 &= \\frac{\\lambda x}{25}, \\\\[1mm]\n    y-4 &= \\frac{\\lambda y}{16}, \\\\[1mm]\n    z-3 &= \\frac{\\lambda z}{9}, \\\\[1mm]\n    1 &=  \\frac{1}{25}x^2 + \\frac{1}{16}y^2 + \\frac{1}{9}z^2\n\\end{split}\n\nfor an unknown value of λ.\n\n(a) Write out this system in the form \\mathbf{f}(\\mathbf{u}) = \\boldsymbol{0}. (Note that the system has four variables to go with the four equations.)\n\n(b) Use \n\nFunction 4.6.3 with different initial guesses to find the two roots of this system. Which is the closest point to (5,4,3), and which is the farthest?\n\n✍ The Broyden update formula \n\n(4.6.8) is just one instance of so-called rank-1 updating. Verify the  Sherman–Morrison formula,(\\mathbf{A}+\\mathbf{u}\\mathbf{v}^T)^{-1} = \\mathbf{A}^{-1} - \\mathbf{A}^{-1}\\frac{\\mathbf{u}\\mathbf{v}^T}{1+\\mathbf{v}^T\\mathbf{A}^{-1}\\mathbf{u}}\\mathbf{A}^{-1},\n\nwhich is valid whenever \\mathbf{A} is invertible and the denominator above is nonzero. (Hint: Show that \\mathbf{A}+\\mathbf{u}\\mathbf{v}^T times the matrix above simplifies to the identity matrix.)\n\n✍ Derive Equation \n\n(4.6.13).\n\n⌨ (See also \n\nExercise 4.5.11.) Suppose that\\mathbf{f}(\\mathbf{x}) =\n\\begin{bmatrix}\n  x_1x_2+x_2^2-1 \\\\[1mm] x_1x_2^3 + x_1^2x_2^2 + 1\n\\end{bmatrix}.\n\nLet \\mathbf{x}_1=[-2,1]^T and let \\mathbf{A}_1=\\mathbf{J}(\\mathbf{x}_1) be the exact Jacobian.\n\n(a) Solve \n\n(4.6.9) for \\mathbf{s}_1 with \\lambda=0; this is the “pure” Newton step. Show numerically that \\|\\mathbf{f}(\\mathbf{x}_1+\\mathbf{s}_1)\\| > \\|\\mathbf{f}(\\mathbf{x}_1)\\|. (Thus, the Newton step made us go to a point seemingly farther from a root than where we started.)\n\n(b) Now repeat part (a) with \\lambda=0.01j for j=1,2,3,\\ldots. What is the smallest value of j such that \\|\\mathbf{f}(\\mathbf{x}_1+\\mathbf{s}_1)\\| < \\|\\mathbf{f}(\\mathbf{x}_1)\\|?\n\n✍ Show that Equation \n\n(4.6.9) is equivalent to the linear least-squares problem\\min_{\\mathbf{v}} \\Bigl(  \\bigl\\|\\mathbf{A}_k\\mathbf{v} + \\mathbf{f}_k\\bigr\\|_2^2 +\n\\lambda^2 \\bigl\\| \\mathbf{v} \\bigr\\|_2^2 \\Bigr).\n\n(Hint: Express the minimized quantity using block matrix notation, such that \n\n(4.6.9) becomes the normal equations for it.)\n\nThus, another interpretation of Levenberg’s method is that it is the Newton step plus a penalty, weighted by λ, for taking large steps.","type":"content","url":"/quasinewton#exercises","position":11},{"hierarchy":{"lvl1":"The rootfinding problem"},"type":"lvl1","url":"/rootproblem","position":0},{"hierarchy":{"lvl1":"The rootfinding problem"},"content":"For the time being we will focus on the rootfinding problem for single functions of one variable.\n\nRootfinding problem\n\nGiven a continuous scalar function f of a scalar variable, find a real number r, called a root, such that f(r)=0.\n\nThe formulation f(x)=0 is general enough to solve any equation. If we are trying to solve an equation g(x)=h(x), we can define f=g-h and find a root of f.\n\nUnlike the linear problems of the earlier chapters, the usual situation here is that the root cannot be produced in a finite number of operations, even in exact arithmetic. Instead, we seek a sequence of approximations that formally converge to the root, stopping when some member of the sequence seems to be good enough, in a sense we will clarify later. The NLsolve package for Julia has a function nlsolve for general-purpose rootfinding.\n\nIn the theory of vibrations of a circular drum, the displacement of the drumhead can be expressed in terms of pure harmonic modes,J_m(\\omega_{k,m} r) \\cos(m\\theta) \\cos(c \\omega_{k,m} t),\n\nwhere (r,\\theta) are polar coordinates, 0\\le r\\le 1, t is time, m is a positive integer, c is a material parameter, and J_m is a Bessel function of the first kind. The quantity \\omega_{k,m} is a resonant frequency and is a positive root of the equationJ_m(\\omega_{k,m}) = 0,\n\nwhich states that the drumhead is clamped around the rim. Bessel functions often appear in physical problems featuring radial symmetry, and tabulating approximations to the zeros of Bessel functions occupied numerous mathematician-hours before computers were on the scene.\n\nThe rootfinding problem for Bessel functions\n\nJ₃(x) = besselj(3, x)\nplot(J₃, 0, 20, title=\"Bessel function\",\n    xaxis=(L\"x\"), yaxis=(L\"J_3(x)\"), grid=:xy)\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nType \\omega followed by Tab to get the character ω.\n\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nω = []\nfor guess = [6., 10. ,13., 16., 19.]\n    s = nlsolve(x -> J₃(x[1]), [guess], ftol=1e-14)\n    append!(ω, s.zero)\nend\n\npretty_table([ω J₃.(ω)], header=[\"root estimate\",\"function value\"])\n\nscatter!(ω, J₃.(ω), title=\"Bessel function with roots\")\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nr = []\nfor guess = [3., 6., 10., 13.]\n    f(x) = J₃(x[1]) - 0.2\n    s = nlsolve(f, [guess], ftol=1e-14)\n    append!(r, s.zero)\nend\nscatter!(r, J₃.(r), title=\"Roots and other Bessel values\")\n\nThe rootfinding problem for Bessel functions\n\nJ3 = @(x) besselj(3,x);\nfplot(J3, [0, 20])\ngrid on\nxlabel('x'), ylabel('J_3(x)')  \ntitle('Bessel function')\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nType \\omega followed by Tab to get the character ω.\n\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nomega = [];\nfor guess = [6, 10, 13, 16, 19]\n    omega = [omega; fzero(J3, guess)];\nend\nomega\n\ntable(omega, J3(omega), 'VariableNames', {'root estimate', 'function value'})\n\nhold on\nscatter(omega, J3(omega))\ntitle('Bessel roots')\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = [];\nfor guess = [3, 6, 10, 13]\n    f = @(x) J3(x) - 0.2;\n    omega = [omega; fzero(f, guess)];\nend\nscatter(omega, J3(omega), '<')\n\nThe rootfinding problem for Bessel functions\n\nimport scipy.special as special\ndef J3(x):\n    return special.jv(3.0, x)\n\nxx = linspace(0, 20, 500)\nfig, ax = subplots()\nax.plot(xx, J3(xx))\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$J_3(x)$\")\ntitle(\"Bessel function\")\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use root_scalar from the scipy.optimize package to find these roots accurately.\n\nfrom scipy.optimize import root_scalar\n\nomega = []\nfor guess in [6.0, 10.0, 13.0, 16.0, 19.0]:\n    s = root_scalar(J3, bracket=[guess - 0.5, guess + 0.5]).root\n    omega.append(s)\n\nresults = PrettyTable()\nresults.add_column(\"root estimate\", omega)\nresults.add_column(\"function value\", [J3(ω) for ω in omega])\nprint(results)\n\nax.scatter(omega, J3(omega))\nax.set_title(\"Bessel function roots\")\nfig\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = []\nfor guess in [3., 6., 10., 13.]:\n    f = lambda x: J3(x) - 0.2\n    s = root_scalar(f, x0=guess).root\n    omega.append(s)\n\nax.scatter(omega, J3(omega))\nfig","type":"content","url":"/rootproblem","position":1},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Conditioning, error, and residual"},"type":"lvl2","url":"/rootproblem#conditioning-error-and-residual","position":2},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Conditioning, error, and residual"},"content":"In the rootfinding problem, the data is a continuous function f and the result is a root. (This overrides our Chapter 1 notation of f as the map from data to result.) How does the result change in response to perturbations in f? We will compute an absolute condition number rather than a relative one.\n\nYou might wonder about the relevance of perturbing a function as data to a problem. If nothing else, the values of f will be represented in floating point and thus subject to rounding error. Furthermore, in many applications, f might not be a simple formula but the result of a computation that uses an inexact algorithm. While there are infinitely many possible perturbations to a function, a constant perturbation is enough to get the main idea.\n\nWe assume f has at least one continuous derivative near a particular root r. Suppose that f is perturbed to \\tilde{f}(x) = f(x) + \\epsilon. As a result, the root (if it still exists) will be perturbed to \\tilde{r} = r + \\delta such that \\tilde{f}(\\tilde{r})=0. We now compute an absolute condition number \\kappa_r, which is the ratio \\left | \\frac{\\delta}{\\epsilon} \\right| as \\epsilon\\to 0.\n\nUsing Taylor’s theorem,  0 = f(r+\\delta) + \\epsilon \\approx f(r) + f'(r) \\delta + \\epsilon.\n\nSince r is a root, we have f(r)=0. This lets us relate δ to ε, and their ratio is the condition number.\n\nCondition number of rootfinding\n\nIf f is differentiable at a root r, then the absolute condition number of r with respect to constant changes in f is  \\kappa_r = \\bigl| f'(r) \\bigr|^{-1}.\n\nWe say \\kappa_r = \\infty if f'(r)=0.\n\nEquivalently, \n\n(4.1.4) is just the magnitude of the derivative of the inverse function f^{-1} at zero.\n\nCondition number of a rootfinding problem\n\nConsider first the function\n\nf(x) = (x - 1) * (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nThe syntax interval... is called splatting and means to insert all the individual elements of interval as a sequence.\n\ninterval = [0.8, 1.2]\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Well-conditioned root\")\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf(x) = (x - 1) * (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Poorly-conditioned root\")\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!\n\nCondition number of a rootfinding problem\n\nConsider first the function\n\nf  = @(x) (x - 1) .* (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nclf\ninterval = [0.8, 1.2];\nfplot(f, interval)\ngrid on, hold on\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\naxis equal \nxlabel('x'), ylabel('f(x)')\ntitle('Well-conditioned root')\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = @(x) (x - 1) .* (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\naxis(axis), cla\nfplot(f, interval)\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\ntitle('Poorly conditioned root')\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!\n\nCondition number of a rootfinding problem\n\nConsider first the function\n\nf = lambda x: (x - 1) * (x - 2)\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Well-conditioned root\")\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = lambda x: (x - 1) * (x - 1.01)\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Poorly-conditioned root\")\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!\n\nWe must accept that when |f'| is small at the root, it may not be possible to get a small error in a computed root estimate. As always, the error is not a quantity we can compute without knowing the exact answer. There is something else we can measure, though.\n\nRootfinding residual\n\nIf \\tilde{r} approximates a root r of function f, then the residual at \\tilde{r} is f(\\tilde{r}).\n\nIt stands to reason that a small residual might be associated with a small error. To quantify the relationship, let \\tilde{r} approximate root r, and define the new function g(x)=f(x)-f(\\tilde{r}). Trivially, g(\\tilde{r})=0, meaning that \\tilde{r} is a true root of g. Since the difference g(x)-f(x) is the residual value f(\\tilde{r}), the residual is the distance to an exactly solved rootfinding problem.\n\nThe backward error in a root estimate is equal to the residual.\n\nIn general, it is not realistic to expect a small error in a root approximation if the condition number \n\n(4.1.4) is large. However, we can gauge the backward error from the residual.","type":"content","url":"/rootproblem#conditioning-error-and-residual","position":3},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Multiple roots"},"type":"lvl2","url":"/rootproblem#multiple-roots","position":4},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Multiple roots"},"content":"The condition number \n\n(4.1.4) naturally leads to the question of what happens if f'(r)=0 at a root r. The following definition agrees with and extends the notion of algebraic multiplicity in a polynomial to roots of more general differentiable functions.\n\nMultiplicity of a root\n\nIf f(r)=f'(r)=\\cdots=f^{(m-1)}(r)=0, but f^{(m)}(r)\\neq 0, then we say f has a root of multiplicity m at r. In particular, if f(r)=0 and f'(r)\\neq 0, then m=1 and we call r a simple root.\n\nAnother useful characterization of multiplicity m is that f(x)=(x-r)^m q(x) for a differentiable q with q(r)\\neq 0.\n\nWhen r is a nonsimple root, the condition number \n\n(4.1.4) is effectively infinite. However, even if r is simple, we should expect difficulty in rootfinding if the condition number is very large. This occurs when |f'(r)| is very small, which means that the quotient q satisfies q(r)\\approx 0 and another root of f is very close to r. We made the same observation about polynomial roots all the way back in \n\nDemo 1.4.3.","type":"content","url":"/rootproblem#multiple-roots","position":5},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Exercises"},"type":"lvl2","url":"/rootproblem#exercises","position":6},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Exercises"},"content":"⌨  For each equation and given interval, do the following steps.\n\n(a) Rewrite the equation into the standard form for rootfinding, f(x) = 0. Make a plot of f over the given interval and determine how many roots lie in the interval.\n\n(b)  Use nlsolve to find each root, as shown in \n\nDemo 4.1.1.\n\n(c) Compute the condition number of each root found in part (b).\n\nx^2=e^{-x}, over [-2,2]\n\n2x = \\tan x, over [-0.2,1.4]\n\ne^{x+1}=2+x, over [-2,2]\n\n⌨ A basic safe type of investment is an annuity: one makes monthly deposits of size P for n months at a fixed annual interest rate r, and at maturity collects the amount\\frac{12 P}{r} \\left( \\Bigl(1+\\frac{r}{12}\\Bigr)^n - 1\\right).\n\nSay you want to create an annuity for a term of 300 months and final value of $1,000,000. Using nlsolve, make a table of the interest rate you will need to get for each of the different contribution values P=500,550,\\ldots,1000.\n\n⌨ The most easily observed properties of the orbit of a celestial body around the sun are the period τ and the elliptical eccentricity ε. (A circle has \\epsilon=0.) From these, it is possible to find at any time t the angle \\theta(t) made between the body’s position and the major axis of the ellipse. This is done through\\tan \\frac{\\theta}{2} = \\sqrt{\\frac{1+\\epsilon}{1-\\epsilon}}\\,\n\\tan \\frac{\\psi}{2},\n\nwhere the eccentric anomaly \\psi(t) satisfies Kepler’s equation:\\psi - \\epsilon \\sin \\psi - \\frac{2\\pi t}{\\tau} = 0.\n\nEquation \n\n(4.1.7) must be solved numerically to find \\psi(t), and then \n\n(4.1.6) can be solved analytically to find \\theta(t).\n\nThe asteroid Eros has \\tau=1.7610 years and \\epsilon=0.2230. Using nlsolve for \n\n(4.1.7), make a plot of \\theta(t) for 100 values of t between 0 and τ, which is one full orbit. (Note: Use mod(θ,2π) to put the angle between 0 and 2\\pi if you want the result to be a continuous function.)\n\n⌨  Lambert’s W function is defined as the inverse of x e^x. That is, y=W(x) if and only if x=ye^y. Write a function lambertW that computes W using nlsolve. Make a plot of W(x) for 0\\le x \\le 4.\n\n✍ For each function, find the multiplicity of the given root. If it is a simple root, find its absolute condition number.\n\n(a) f(x) = x^3-2x^2+x-2, root r=2\n\n(b) f(x) = (\\cos x  + 1)^2, root r=\\pi\n\n(c) f(x) = \\frac{\\sin^2 x}{x}, root r=0 (define f(0) =0)\n\n(d) f(x) =(x-1)\\log(x), root r=1\n\nBased on our definitions, this means that the relative change to the root when f is changed by a perturbation of size ε is not O(\\epsilon) as \\epsilon\\to 0.","type":"content","url":"/rootproblem#exercises","position":7},{"hierarchy":{"lvl1":"Interpolation-based methods"},"type":"lvl1","url":"/secant","position":0},{"hierarchy":{"lvl1":"Interpolation-based methods"},"content":"From a practical standpoint, one of the biggest drawbacks of Newton’s method is the requirement to supply f' in \n\nFunction 4.3.2. It is both a programming inconvenience and a step that requires computational time. We can avoid using f', however, by making a simple but easily overlooked observation:\n\nWhen a step produces an approximate result, you are free to carry it out approximately.\n\nLet’s call this the principle of approximate approximation.\n\nIn the Newton context, the principle of approximate approximation begins with the observation that the use of f' is linked to the construction of a linear approximation q(x) equivalent to a tangent line. The root of q(x) is used to define the next iterate in the sequence. We can avoid calculating the value of f' by choosing a different linear approximation.\n\nGraphical interpretation of the secant method\n\nWe return to finding a root of the equation x e^x=2.\n\nf(x) = x * exp(x) - 2;\n\nplot(f, 0.25, 1.25, label=\"function\",\n    xlabel=L\"x\", ylabel=L\"y\", legend=:topleft)\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx₁ = 1;\ny₁ = f(x₁);\nx₂ = 0.5;\ny₂ = f(x₂);\nscatter!([x₁, x₂], [y₁, y₂], label=\"initial points\",\n    title=\"Two initial values\")\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nm₂ = (y₂ - y₁) / (x₂ - x₁)\nsecant = x -> y₂ + m₂ * (x - x₂)\nplot!(secant, 0.25, 1.25, label=\"secant line\", l=:dash, color=:black,\n    title=\"Secant line\")\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx₃ = x₂ - y₂ / m₂\n@show y₃ = f(x₃)\nscatter!([x₃], [0], label=\"root of secant\", title=\"First iteration\")\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nm₃ = (y₃ - y₂) / (x₃ - x₂)\nx₄ = x₃ - y₃ / m₃\n\nGraphical interpretation of the secant method\n\nWe return to finding a root of the equation x e^x=2.\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0.25, 1.25])\nset(gca, 'ygrid', 'on')  \nxlabel('x'), ylabel('y')    \ntitle('Objective function')\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1;    y1 = f(x1);\nx2 = 0.5;  y2 = f(x2);\nhold on, scatter([x1, x2], [y1, y2])\ntitle('Two initial values')\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1);\nsecant2 = @(x) y2 + slope2 * (x - x2);\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nfplot(secant2,[0.25, 1.25],'k--')\nx3 = x2 - y2 / slope2;\ny3 = f(x3)\nscatter(x3, 0)\ntitle('Next value')\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope2 = (y3 - y2) / (x3 - x2);\nx4 = x3 - y3 / slope2;\ny4 = f(x4)\n\nGraphical interpretation of the secant method\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0.25, 1.25, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$f(x)$\")\nax.grid()\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1\ny1 = f(x1)\nx2 = 0.5\ny2 = f(x2)\nax.plot([x1, x2], [y1, y2], \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1)\nsecant2 = lambda x: y2 + slope2 * (x - x2)\nax.plot(xx, secant2(xx), \"--\", label=\"secant line\")\nax.legend()\nfig\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx3 = x2 - y2 / slope2\nax.plot(x3, 0, \"o\", label=\"root of secant\")\ny3 = f(x3)\nprint(y3)\nax.legend()\nfig\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope3 = (y3 - y2) / (x3 - x2)\nx4 = x3 - y3 / slope3\nprint(f(x4))\n\nThe example in \n\nDemo 4.4.1 demonstrates the secant method. In the secant method, one finds the root of the linear approximation through the two most recent root estimates. That is, given previous approximations x_1,\\ldots,x_k, define the linear model function as the line through \\bigl(x_{k-1},f(x_{k-1})\\bigr) and \\bigl(x_k,f(x_k)\\bigr):q(x) = f(x_k) + \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}(x-x_k).\n\nSolving q(x_{k+1})=0 for x_{k+1} gives the iteration formula.\n\nSecant iteration\n\nGiven function f and two initial values x_1 and x_2, definex_{k+1} = x_k - \\frac{f(x_k)(x_k-x_{k-1})}{f(x_k)-f(x_{k-1})}, \\quad k=2,3,\\ldots.\n\nOur implementation of the secant method is given in \n\nFunction 4.4.2.\n\nsecant\n\nSecant method\n\n    x = [float(x₁),float(x₂)]\n    y₁ = f(x₁)\n    Δx,y₂ = Inf,Inf   # for initial pass in the loop below\n    k = 2\n\n    while (abs(Δx) > xtol) && (abs(y₂) > ftol) \n        y₂ = f(x[k])\n        Δx = -y₂ * (x[k]-x[k-1]) / (y₂-y₁)   # secant step\n        push!(x,x[k]+Δx)        # append new estimate\n\n        k += 1\n        y₁ = y₂    # current f-value becomes the old one next time\n        \n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.\n\nSecant method\n\nfunction x = secant(f,x1,x2)\r\n% SECANT   Secant method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   x1,x2    initial root approximations\r\n% Output       \r\n%   x        vector of root approximations (last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = [x1 x2];\r\ndx = Inf;  y1 = f(x1);\r\nk = 2;  y2 = f(x2);\r\n\r\nwhile (abs(dx) > xtol) && (abs(y2) > funtol) && (k < maxiter)\r\n    dx = -y2 * (x(k)-x(k-1)) / (y2-y1);   % secant step\r\n    x(k+1) = x(k) + dx;\r\n    \r\n    k = k+1;\r\n    y1 = y2;    % current f-value becomes the old one next time\r\n    y2 = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nSecant method\n\ndef secant(f, x1, x2):\n    \"\"\"\n    secant(f, x1, x2)\n\n    Use the secant method to find a root of `f` starting from `x1` and `x2`. Returns a\n    vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[:2] = [x1, x2]\n    y1 = f(x1)\n    y2 = 100\n    dx = np.inf  # for initial pass below\n    k = 1\n\n    while (abs(dx) > xtol) and (abs(y2) > funtol) and (k < maxiter):\n        y2 = f(x[k])\n        dx = -y2 * (x[k] - x[k - 1]) / (y2 - y1)  # secant step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y1 = y2  # current f-value becomes the old one next time\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:k+1]\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.","type":"content","url":"/secant","position":1},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Convergence"},"type":"lvl2","url":"/secant#convergence","position":2},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Convergence"},"content":"Graphically, a secant line usually looks like a less accurate model of f than the tangent line. How will that affect the convergence?\n\nAs before, let \\epsilon_k = x_k-r be the errors in the successive root approximations, and assume that r is a simple root. If the initial errors are small, then a tedious but straightforward Taylor expansion shows that, to lowest order,\\epsilon_{k+1} \\approx \\frac{1}{2}\\frac{f''(r)}{f'(r)} \\epsilon_k \\epsilon_{k-1}.\n\nIf we make an educated guess that\\epsilon_{k+1} = c (\\epsilon_k)^\\alpha, \\quad \\epsilon_k = c (\\epsilon_{k-1})^\\alpha, \\ldots, \\qquad \\alpha>0,\n\nthen \n\n(4.4.3) becomes\\left[ \\epsilon_{k-1}^{\\alpha} \\right]^{\\,\\alpha} \\approx C \\epsilon_{k-1}^{\\alpha+1}\n\nfor an unknown constant C. Treating the approximation as an equality, this becomes solvable if and only if the exponents match, i.e., \\alpha^2 = \\alpha+1. The only positive root of this equation is the golden ratio,  \\alpha = \\frac{1+\\sqrt{5}}{2} \\approx 1.618.\n\nHence the errors in the secant method converge like \\epsilon_{k+1} = c (\\epsilon_k)^\\alpha  for 1<\\alpha<2.\n\nSuperlinear convergence\n\nSuppose a sequence x_k approaches limit x^*. If the error sequence \\epsilon_k=x_k - x^* satisfies  \\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|^\\alpha} = L\n\nfor constants \\alpha >1 and L>0, then the sequence has superlinear convergence with rate α.\n\nQuadratic convergence is a particular case of superlinear convergence. Roughly speaking, we expect\\log |\\epsilon_{k+1}| & \\approx \\alpha (\\log |\\epsilon_k|) + \\log L, \\\\ \n\\frac{\\log |\\epsilon_{k+1}|}{\\log |\\epsilon_k|} & \\approx \\alpha + \\frac{\\log L}{\\log |\\epsilon_k|} \\to \\alpha,\n\nas k\\to\\infty.\n\nConvergence of the secant method\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1. Again we will use extended precision to get a longer sequence than double precision allows.\n\nf(x) = x * exp(x) - 2\nx = FNC.secant(f, BigFloat(1), BigFloat(0.5), xtol=1e-80, ftol=1e-80);\n\nWe don’t know the exact root, so we use the last value as a proxy.\n\nr = x[end]\n\nHere is the sequence of errors.\n\nϵ = @. Float64(r - x[1:end-1])\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\n[log(abs(ϵ[k+1])) / log(abs(ϵ[k])) for k in 1:length(ϵ)-1]\n\nAs expected, this settles in at around 1.618.\n\nConvergence of the secant method\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = @(x) x .* exp(x) - 2;\nx = secant(f, 1, 0.5);\n\nWe don’t know the exact root, so we use fzero to get a good proxy.\n\nr = fzero(f, 1);\n\nHere is the sequence of errors.\n\nformat short e\nerr = r - x(1:end-1)'\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)\n\nAs expected, this settles in at around 1.618.\n\nConvergence of the secant method\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = lambda x: x * exp(x) - 2\nx = FNC.secant(f, 1, 0.5)\nprint(x)\n\nWe don’t know the exact root, so we use root_scalar to get a substitute.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.5, 1]).root\nprint(r)\n\nHere is the sequence of errors.\n\nerr = r - x\nprint(err)\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 2):\n    print(logerr[i+1] / logerr[i])\n\nAs expected, this settles in at around 1.618.\n\nIn terms of the error as a function of the iteration number k, the secant method converges at a rate strictly between linear and quadratic, which is slower than Newton’s method. But error versus iteration count may not be the best means of comparison.\n\nOften we analyze rootfinding methods by assuming that the bulk of computing time is spent evaluating the user-defined functions f and f'. (Our simple examples and exercises mostly don’t support this assumption, but many practical applications do.) In this light, we see that Newton’s method requires two evaluations, f(x_k) and f'(x_k), for each iteration. The secant method, on the other hand, while it uses the two function values f(x_k) and f(x_{k-1}) at each iteration, only needs to compute a single new one. Note that \n\nFunction 4.4.2 keeps track of one previous function value rather than recomputing it.\n\nNow suppose that |\\epsilon_k|=\\delta. Roughly speaking, two units of work (i.e., function evaluations) in Newton’s method brings us to an error of \\delta^2. If one spreads out the improvement in the error evenly across the two steps, using\\delta^2 = \\bigl( \\delta^{\\sqrt{2}} \\bigr)^{\\!\\sqrt{2}},\n\nit seems reasonable to say that the rate of convergence in Newton per function evaluation is \\sqrt{2}\\approx 1.41. This is actually less than the comparable rate of about 1.62 for the secant method.\n\nIf function evaluations are used to measure computational work, the secant iteration converges more rapidly than Newton’s method.\n\nNot only is the secant method easier to apply than Newton’s method in practice, it’s also more efficient—a rare win-win!","type":"content","url":"/secant#convergence","position":3},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Inverse interpolation"},"type":"lvl2","url":"/secant#inverse-interpolation","position":4},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Inverse interpolation"},"content":"At each iteration, the secant method constructs a linear model function that interpolates the two most recently found points on the graph of f. Two points determine a straight line, so this seems like a sensible choice. But as the iteration progresses, why use only the two most recent points? What would it mean to use more of them?\n\nIf we interpolate through three points by a polynomial, we get a unique quadratic function. Unfortunately, a parabola may have zero, one, or two crossings of the x-axis, potentially leaving some doubt as to how to define the next root estimate. On the other hand, if we turn a parabola on its side, we get a graph that intersects the x-axis exactly once, which is ideal for defining the next root estimate.\n\nThis leads to the idea of defining q(y) as the quadratic interpolant to the points (y_{k-2},x_{k-2}), (y_{k-1},x_{k-1}), and (y_k,x_k), where y_i=f(x_i) for all i, and setting x_{k+1}=q(0). The process defined in this way (given three initial estimates) is called inverse quadratic interpolation. Rather than deriving lengthy formulas for it here, we demonstrate how to perform inverse quadratic interpolation using fit to perform the interpolation step.\n\nInverse quadratic interpolation\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf(x) = x + cos(10 * x)\ninterval = [0.5, 1.5]\n\nplot(f, interval..., label=\"Function\", legend=:bottomright,\n    grid=:y, ylim=[-0.1, 3], xlabel=L\"x\", ylabel=L\"y\")\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]\ny = @. f(x)\nscatter!(x, y, label=\"initial points\")\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nq = Polynomials.fit(x, y, 2)      # interpolating polynomial\nplot!(x -> q(x), interval..., l=:dash, label=\"interpolant\")\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.:::{card}\nBy giving two functions in the plot call, we get the parametric plot $(q(y),y)$ as a function of $y$.\n\nplot(f, interval..., label=\"Function\",\n    legend=:bottomright, grid=:y, xlabel=L\"x\", ylabel=L\"y\")\nscatter!(x, y, label=\"initial points\")\n\nq = Polynomials.fit(y, x, 2)       # interpolating polynomial\nplot!(y -> q(y), y -> y, -0.1, 2.6, l=:dash, label=\"inverse interpolant\")\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nq(0)\n\nLet’s restart the process with BigFloat numbers to get a convergent sequence.\n\nx = BigFloat.([8, 12, 10]) / 10\ny = @. f(x)\n\nfor k = 3:12\n    q = Polynomials.fit(y[k-2:k], x[k-2:k], 2)\n    push!(x, q(0))\n    push!(y, f(x[k+1]))\nend\n\nprintln(\"residual = $(f(x[end]))\")\n\nAs far as our current precision is concerned, we have an exact root.\n\nr = x[end]\nlogerr = @. log(Float64(abs(r - x[1:end-1])))\n[logerr[k+1] / logerr[k] for k in 1:length(logerr)-1]\n\nThe convergence is probably superlinear at a rate of \\alpha=1.8 or greater.\n\nInverse quadratic interpolation\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = @(x) x + cos(10 * x);\ninterval = [0.5, 1.5];\nclf, fplot(f, interval)\nset(gca, 'ygrid', 'on'), axis(axis)   \ntitle('Objective function')    \nxlabel('x'), ylabel('y')    \nr = fzero(f, 1)\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]';\ny = f(x);\nhold on, scatter(x, y)\ntitle('Three initial points')\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nc = polyfit(x, y, 2);    % coefficients of interpolant\nq = @(x) polyval(c, x);\nfplot(q, interval, '--')\ntitle('Parabola model')\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.:::{card}\nBy giving two functions in the `fplot` call, we get the parametric plot $(q(y),y)$ as a function of $y$.\n\ncla, fplot(f, interval)\nscatter(x, y)     \nc = polyfit(y, x, 2);    % coefficients of interpolating polynomial\nq = @(y) polyval(c, y);\nfplot(q, @(y) y, ylim,'--')    % plot x=q(y), y=y\ntitle('Sideways parabola')\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = [x; q(0)];\ny = [y; f(x(end))]\n\nWe repeat the process a few more times.\n\nfor k = 4:8\n    c = polyfit(y(k-2:k), x(k-2:k), 2);\n    x(k+1) = polyval(c, 0);\n    y(k+1) = f(x(k+1));\nend\ndisp('final residual:')\ny(end)\n\nHere is the sequence of errors.\n\nformat short e\nerr = x - r\n\nThe convergence is probably superlinear:\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)\n\nInverse quadratic interpolation\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = lambda x: x + cos(10 * x)\nxx = linspace(0.5, 1.5, 400)\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$y$\")\nfig\n\nWe choose three values to get the iteration started.\n\nx = array([0.8, 1.2, 1])\ny = f(x)\nax.plot(x, y, \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nq = poly1d(polyfit(x, y, 2))  # interpolating polynomial\nax.plot(xx, q(xx), \"--\", label=\"interpolant\")\nax.set_ylim(-0.1, 3), ax.legend()\nfig\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nplot(xx, f(xx), label=\"function\")\nplot(x, y, \"ko\", label=\"initial points\")\n\nq = poly1d(polyfit(y, x, 2))  # inverse interpolating polynomial\nyy = linspace(-0.1, 2.6, 400)\nplot(q(yy), yy, \"--\", label=\"inverse interpolant\")\n\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\nlegend()\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = hstack([x, q(0)])\ny = hstack([y, f(x[-1])])\nprint(\"x:\", x, \"\\ny:\", y)\n\nWe repeat the process a few more times.\n\nfor k in range(6):\n    q = poly1d(polyfit(y[-3:], x[-3:], 2))\n    x = hstack([x, q(0)])\n    y = hstack([y, f(x[-1])])\nprint(f\"final residual is {y[-1]:.2e}\")\n\nHere is the sequence of errors.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.9, 1]).root\nerr = x - r\nprint(err)\n\nThe error seems to be superlinear, but subquadratic:\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])","type":"content","url":"/secant#inverse-interpolation","position":5},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Bracketing"},"type":"lvl2","url":"/secant#bracketing","position":6},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Bracketing"},"content":"Like Newton’s method, the secant and inverse quadratic interpolation methods cannot guarantee convergence. One final new idea is needed to make a (nearly) foolproof algorithm.\n\nIf f is continuous on the interval [a,b] and f(a)f(b)<0—that is, f changes sign on the interval—then f must have at least one root in the interval, due to the Intermediate Value Theorem from calculus. If we come up with a new root estimate c\\in(a,b), then whatever sign f(c) is, it is different from the sign at one of the endpoints. (Of course, if f(c) is zero, we are done!) So either [a,c] or [c,b] is guaranteed to have a root too, and in this way we can maintain not just individual estimates but an interval that always contains a root.\n\nThe best algorithms blend the use of fast-converging methods with the guarantee provided by a bracket. For example, say that an iteration begins with a bracketing interval. Make a list of the inverse quadratic estimate, the secant estimate, and the midpoint of the current interval, and pick the first member of the list that lies within the current interval. Replace the interval with the bracketing subinterval, and start a new iteration. This is the idea behind Brent’s method, which is a very successful rootfinding algorithm.","type":"content","url":"/secant#bracketing","position":7},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Exercises"},"type":"lvl2","url":"/secant#exercises","position":8},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Exercises"},"content":"For each of Exercises 1–3, do the following steps.\n\n(a) ✍ Rewrite the equation into the standard form for rootfinding, f(x) = 0.\n\n(b) ⌨ Make a plot of f over the given interval and determine how many roots lie in the interval.\n\n(c) ⌨ Use nlsolve with ftol=1e-15 to find a reference value for each root.\n\n(d) ⌨ Determine a bracketing interval for each root. Then use \n\nFunction 4.4.2, starting with the endpoints of the bracketing interval, to find each root.\n\n(e) ⌨ For one of the roots, use the errors in the Newton sequence to determine numerically whether the convergence is apparently between linear and quadratic.\n\nx^2=e^{-x}, over [-2,2]\n\n2x = \\tan x, over [-0.2,1.4]\n\ne^{x+1}=2+x, over [-2,2]\n\n⌨ Use a plot to approximately locate all the roots of f(x)=x^{-2}-\\sin(x) in the interval [0.5,10]. Then find a pair of initial points for each root such that \n\nFunction 4.4.2 converges to that root.\n\n✍ Show analytically that the secant method converges in one step for a linear function, regardless of the initialization.\n\n✍ In general, the secant method formula \n\n(4.4.2) cannot be applied if x_{k}=x_{k-1}. However, suppose that f(x)=ax^2+bx+c for constants a, b, and c. Show that in this case the formula can be simplified to one that is well defined when x_{k}=x_{k-1}. Then show that the resulting x_{k+1} is the same as the result of one step of Newton’s method applied to f at x_k.\n\n✍ Let f(x)=x^2. Show that if (1/x_1) and (1/x_2) are positive integers, and the secant iteration is applied, then the sequence 1/x_1,1/x_2,1/x_3,\\ldots is a Fibonacci sequence, i.e., satisfying x_{k+1}=x_k+x_{k-1}.\n\n✍ Provide the details that show how to derive \n\n(4.4.3) from \n\n(4.4.2).\n\n⌨ Write a function iqi(f,x₁,x₂,x₃) that performs inverse quadratic interpolation for finding a root of f, given three initial estimates. To find the quadratic polynomial q(y) passing through the three most recent points, use fit. Test your function on the function in Exercise 1 from this section.","type":"content","url":"/secant#exercises","position":9},{"hierarchy":{"lvl1":"Adaptive integration"},"type":"lvl1","url":"/adaptive","position":0},{"hierarchy":{"lvl1":"Adaptive integration"},"content":"To this point, we have used only equally spaced nodes to compute integrals. Yet there are problems in which non-uniformly distributed nodes would clearly be more appropriate, as demonstrated in \n\nDemo 5.7.1.\n\nMotivation for adaptive integration\n\nThis function gets increasingly oscillatory as x increases.\n\nf = x -> (x + 1)^2 * cos((2 * x + 1) / (x - 4.3))\nplot(f, 0, 4, xlabel=L\"x\", ylabel=L\"f(x)\")\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nleft_val, _ = quadgk(f, 0, 2, atol=1e-14, rtol=1e-14)\nright_val, _ = quadgk(f, 2, 4, atol=1e-14, rtol=1e-14)\n\nn = [50 * 2^k for k in 0:3]\nleft_err, right_err = [], []\nfor n in n\n    T, _ = FNC.trapezoid(f, 0, 2, n)\n    push!(left_err, T - left_val)\n\n    T, _ = FNC.trapezoid(f, 2, 4, n)\n    push!(right_err, T - right_val)\nend\n\npretty_table([n left_err right_err], header=[\"n\", \"left error\", \"right error\"])\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nMotivation for adaptive integration\n\nThis function gets increasingly oscillatory as x increases.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\nclf\nfplot(f, [0, 4], 2000)\nxlabel('x'), ylabel('f(x)')\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nleft_val = integral(f, 0, 2, abstol=1e-14, reltol=1e-14);\nright_val = integral(f, 2, 4, abstol=1e-14, reltol=1e-14);\n\nn = round(50 * 2 .^ (0:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    T = trapezoid(f, 0, 2, n(i));\n    err(i, 1) = T - left_val;\n    T = trapezoid(f, 2, 4, n(i));\n    err(i, 2) = T - right_val;\nend\ndisp(table(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"left error\", \"right error\"]))\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nMotivation for adaptive integration\n\nThis function gets increasingly oscillatory as x increases.\n\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nx = linspace(0, 4, 600)\nplot(x, f(x))\nxlabel(\"$x$\")\nylabel(\"$f(x)$\");\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nn_ = 50 * 2 ** arange(4)\nTleft = zeros(4)\nTright = zeros(4)\nfor i, n in enumerate(n_):\n    Tleft[i] = FNC.trapezoid(f, 0, 2, n)[0]\n    Tright[i] = FNC.trapezoid(f, 2, 4, n)[0]\nprint(\"left half:\", Tleft)\nprint(\"right half:\", Tright)\n\nleft_val, err = quad(f, 0, 2, epsabs=1e-13, epsrel=1e-13)\nright_val, err = quad(f, 2, 4, epsabs=1e-13, epsrel=1e-13)\n\nprint(\"    n     left error   right error\")\nfor k in range(n_.size):\n    print(f\"  {n_[k]:4}    {Tleft[k]-left_val:8.3e}    {Tright[k]-right_val:8.3e}\")\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nWe would like an algorithm that automatically detects and reacts to a situation like that in \n\nDemo 5.7.1, a trait known as adaptivity.","type":"content","url":"/adaptive","position":1},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Error estimation"},"type":"lvl2","url":"/adaptive#error-estimation","position":2},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Error estimation"},"content":"Ideally, we would like to make adaptation decisions based on the error of the integration result. Knowing the error exactly would be equivalent to knowing the exact answer, but we can estimate it using the extrapolation technique of \n\nNumerical integration. Consider the Simpson formula \n\n(5.6.15) resulting from one level of extrapolation from trapezoid estimates:  S_f(2n) = \\frac{1}{3} \\Bigl[ 4 T_f(2n) - T_f(n) \\Bigr].\n\nWe expect this method to be fourth-order accurate, i.e.,  \\int_a^b f(x)\\, dx = S_f(2n) + O(n^{-4}),\n\nWe can further extrapolate to sixth-order accuracy using \n\n(5.6.17):  R_f(4n) = \\frac{1}{15} \\Bigl[ 16 S_f(4n) - S_f(2n) \\Bigr].\n\nBy virtue of higher order of accuracy, R_f(4n) should be more accurate than S_f(4n). Hence, a decent estimate of the error in the better of the two Simpson values is  E = R_f(4n) - S_f(4n) = \\frac{S_f(4n) - S_f(2n)}{15}.","type":"content","url":"/adaptive#error-estimation","position":3},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Divide and conquer"},"type":"lvl2","url":"/adaptive#divide-and-conquer","position":4},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Divide and conquer"},"content":"If |E| is judged to be acceptably small, we are done. This judgment takes some care. For instance, suppose the exact integral is \n\n1020.  Requiring |E| < \\delta\\ll 1 would be fruitless in double precision, since it would require more than 20 accurate digits. Hence checking the absolute size of the error alone is not appropriate. Conversely, consider the integral  \\int_{10^{-6}}^{2\\pi} 2 \\sin x\\, dx \\approx -10^{-12}.\n\nWe are likely to sample values of the integrand that are larger than, say, 1/2 in absolute value, so obtaining this very small result has to rely on subtractive cancellation. We cannot hope for more than 4-5 accurate digits, so a strict test of the relative error is also not recommended. In other words, we can seek an error that is small relative to the data (the integrand), which is O(1), but not relative to the answer itself.\n\nTypically, we use both relative and absolute error, stopping when either one is considered small enough. Algebraically, the test is  |E| < \\delta_a + \\delta_r |S_f(n)|,\n\nwhere \\delta_a and \\delta_r are given absolute and relative error tolerances, respectively.\n\nWhen |E| fails to meet \n\n(5.7.6), we bisect the interval [a,b] to exploit the identity  \\int_a^b f(x)\\, dx = \\int_a^{(a+b)/2} f(x)\\, dx + \\int_{(a+b)/2}^b f(x)\\, dx,\n\nand independently compute estimates to each of the half-length integrals. Each of these half-sized computations recursively applies Simpson’s formula and the error estimation criterion, making further bisections as necessary. Such an approach is called divide and conquer in computer science: recursively split the problem into easier pieces and glue the results together.","type":"content","url":"/adaptive#divide-and-conquer","position":5},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Implementation"},"type":"lvl2","url":"/adaptive#implementation","position":6},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Implementation"},"content":"It is typical to use just the minimal formula S_f(4) and its error estimate E to make decisions about adaptivity. A computation of S_f(4) requires three trapezoid estimates T_f(1), T_f(2), and T_f(4). As observed in \n\n(5.6.18) and \n\nDemo 5.6.3, the five integrand evaluations in T_f(4) are sufficient to compute all of these values.\n\nFunction 5.7.1 shows an implementation. It uses five function values to compute three trapezoid estimates with n=1, n=2, and n=4, applying the updating formula \n\n(5.6.18) twice. It goes on to find the two Simpson approximations and to estimate the error by \n\n(5.7.4).\n\nIf the error estimate passes the test \n\n(5.7.6), the better Simpson value is returned as the integral over the given interval. Otherwise, the interval is bisected, integrals over the two pieces are computed using recursive calls, and those results are added to give the complete integral.\n\nintadapt\n\nAdaptive integration\n\n\"\"\"\n    intadapt(f,a,b,tol)\n\nAdaptively integrate `f` over [`a`,`b`] to within target error \ntolerance `tol`. Returns the estimate and a vector of evaluation \nnodes.\n\"\"\"\nfunction intadapt(f,a,b,tol,fa=f(a),fb=f(b),m=(a+b)/2,fm=f(m))\n    # Use error estimation and recursive bisection.\n    # These are the two new nodes and their f-values.\n    xl = (a+m)/2;  fl = f(xl);\n    xr = (m+b)/2;  fr = f(xr);\n    \n    # Compute the trapezoid values iteratively.\n    h = (b-a)\n    T = [0.,0.,0.]\n    T[1] = h*(fa+fb)/2\n    T[2] = T[1]/2 + (h/2)*fm\n    T[3] = T[2]/2 + (h/4)*(fl+fr)\n    \n    S = (4T[2:3]-T[1:2]) / 3      # Simpson values\n    E = (S[2]-S[1]) / 15           # error estimate\n    \n    if abs(E) < tol*(1+abs(S[2]))  # acceptable error?\n        Q = S[2]                   # yes--done\n        nodes = [a,xl,m,xr,b]      # all nodes at this level\n    else\n        # Error is too large--bisect and recurse.\n        QL,tL = intadapt(f,a,m,tol,fa,fm,xl,fl)\n        QR,tR = intadapt(f,m,b,tol,fm,fb,xr,fr)\n        Q = QL + QR\n        nodes = [tL;tR[2:end]]   # merge the nodes w/o duplicate\n    end\n    return Q,nodes\nend\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.\n\nAdaptive integration\n\nfunction [Q,t] = intadapt(f,a,b,tol)\n%INTADAPT   Adaptive integration with error estimation.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   tol   acceptable error\n% Output:\n%   Q     approximation to integral(f,a,b)\n%   t     vector of nodes used\n\nm = (b+a)/2;\n[Q,t] = do_integral(a,f(a),b,f(b),m,f(m),tol);\n\n    % Use error estimation and recursive bisection. \n    function [Q,t] = do_integral(a,fa,b,fb,m,fm,tol)\n        \n        % These are the two new nodes and their f-values.\n        xl = (a+m)/2;  fl = f(xl);\n        xr = (m+b)/2;  fr = f(xr);\n        t = [a;xl;m;xr;b];              % all 5 nodes at this level\n\n        % Compute the trapezoid values iteratively. \n        h = (b-a);\n        T(1) = h*(fa+fb)/2;\n        T(2) = T(1)/2 + (h/2)*fm;\n        T(3) = T(2)/2 + (h/4)*(fl+fr);\n        \n        S = (4*T(2:3)-T(1:2)) / 3;      % Simpson values\n        E = (S(2)-S(1)) / 15;           % error estimate\n                \n        if abs(E) < tol*(1+abs(S(2)))   % acceptable error?\n            Q = S(2);                   % yes--done\n        else\n            % Error is too large--bisect and recurse. \n            [QL,tL] = do_integral(a,fa,m,fm,xl,fl,tol);\n            [QR,tR] = do_integral(m,fm,b,fb,xr,fr,tol);\n            Q = QL + QR;\n            t = [tL;tR(2:end)];         % merge the nodes w/o duplicate\n        end        \n    end\n\nend  % main function\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.\n\nAdaptive integration\n\ndef intadapt(f, a, b, tol):\n    \"\"\"\n    intadapt(f,a,b,tol)\n\n    Do adaptive integration to estimate the integral of `f` over [`a`,`b`] to desired\n    error tolerance `tol`. Returns estimate and a vector of evaluation nodes used.\n    \"\"\"\n\n    # Use error estimation and recursive bisection.\n    def do_integral(a, fa, b, fb, m, fm, tol):\n        # These are the two new nodes and their f-values.\n        xl = (a + m) / 2\n        fl = f(xl)\n        xr = (m + b) / 2\n        fr = f(xr)\n        t = np.array([a, xl, m, xr, b])  # all 5 nodes at this level\n\n        # Compute the trapezoid values iteratively.\n        h = b - a\n        T = np.zeros(3)\n        T[0] = h * (fa + fb) / 2\n        T[1] = T[0] / 2 + (h / 2) * fm\n        T[2] = T[1] / 2 + (h / 4) * (fl + fr)\n\n        S = (4 * T[1:] - T[:-1]) / 3  # Simpson values\n        E = (S[1] - S[0]) / 15  # error estimate\n\n        if abs(E) < tol * (1 + abs(S[1])):  # acceptable error?\n            Q = S[1]  # yes--done\n        else:\n            # Error is too large--bisect and recurse.\n            QL, tL = do_integral(a, fa, m, fm, xl, fl, tol)\n            QR, tR = do_integral(m, fm, b, fb, xr, fr, tol)\n            Q = QL + QR\n            t = np.hstack([tL, tR[1:]])  # merge the nodes w/o duplicate\n        return Q, t\n\n    m = (b + a) / 2\n    Q, t = do_integral(a, f(a), b, f(b), m, f(m), tol)\n    return Q, t\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.\n\nUsing adaptive integration\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = x -> (x + 1)^2 * cos((2 * x + 1) / (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nA, t = FNC.intadapt(f, 0, 4, 0.001)\n@show num_nodes = length(t);\n\nplot(f, 0, 4, color=:black, legend=:none,\n    xlabel=L\"x\", ylabel=L\"f(x)\", title=\"Adaptive node selection\")\nplot!(t, f.(t), seriestype=:sticks, m=(:o, 2))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nQ, _ = quadgk(f, 0, 4, atol=1e-14, rtol=1e-14);    # 'exact' value\nprintln(\"error: $(Q-A)\");\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = [1 / 10^k for k in 4:14]\nerr, n = [], []\nfor tol in 10.0 .^ (-4:-1:-14)\n    A, t = FNC.intadapt(f, 0, 4, tol)\n    push!(err, Q - A)\n    push!(n, length(t))\nend\n\npretty_table([tol err n], header=[\"tolerance\", \"error\", \"number of nodes\"])\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nplot(n, abs.(err), m=:o, label=\"results\",\n    xaxis=(:log10, \"number of nodes\"), yaxis=(:log10, \"error\"),\n    title=\"Convergence of adaptive integration\")\n\norder4 = @. 0.01 * (n / n[1])^(-4)\nplot!(n, order4, l=:dash, label=L\"O(n^{-4})\")\n\nUsing adaptive integration\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\n[Q, t] = intadapt(f, 0, 4, 0.001);\nclf, fplot(f, [0, 4], 2000)\nhold on\nstem(t, f(t), '.-')\ntitle('Adaptive node selection')    % ignore this line\nxlabel('x'), ylabel('f(x)')    % ignore this line\nfprintf(\"number of nodes = %d\", length(t))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nI = integral(f, 0, 4, abstol=1e-14, reltol=1e-14);    % 'exact' value\nfprintf(\"error = %.2e\", abs(Q - I))\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = 1 ./ 10.^(4:14)';\nerr = zeros(size(tol));\nn = zeros(size(tol));\nfor i = 1:length(tol)\n    [A, t] = intadapt(f, 0, 4, tol(i));\n    err(i) =  I - A;\n    n(i) = length(t);\nend\ndisp(table(tol, err, n, variableNames=[\"tolerance\", \"error\", \"number of nodes\"]))\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"results\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\ntitle(\"Convergence of adaptive integration\")\norder4 = 0.1 * abs(err(end)) * (n / n(end)).^(-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nlegend()\n\nUsing adaptive integration\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nI, errest = quad(f, 0, 4, epsabs=1e-12, epsrel=1e-12)\nprint(\"integral:\", I)    # 'exact' value\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nQ, t = FNC.intadapt(f, 0, 4, 0.001)\nprint(\"number of nodes:\", t.size)\n\nx = linspace(0, 4, 600)\nplot(x, f(x), \"k\")\nstem(t, f(t))\nxlabel(\"$x$\"); ylabel(\"$f(x)$\");\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nprint(\"error:\", I - Q)\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol_ = 10.0 ** arange(-4, -12, -1)\nerr_ = zeros(tol_.size)\nnum_ = zeros(tol_.size, dtype=int)\nprint(\"    tol         error     # f-evals\")\nfor i, tol in enumerate(tol_):\n    Q, t = FNC.intadapt(f, 0, 4, tol)\n    err_[i] = I - Q\n    num_[i] = t.size\n    print(f\"  {tol:6.1e}    {err_[i]:10.3e}    {num_[i]:6d}\")\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nloglog(num_, abs(err_), \"-o\", label=\"results\")\norder4 = 0.01 * (num_ / num_[0]) ** (-4)\nloglog(num_, order4, \"--\", label=\"$O(n^{-4})$\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\nlegend()\ntitle(\"Convergence of adaptive quadrature\");\n\nAlthough adaptivity and the error estimation that goes with it can be very powerful, they come at some cost. The error estimation cannot be universally perfect, so sometimes the answer will not be as accurate as requested, and sometimes the function will be evaluated more times than necessary. Subtle problems may arise when the integral is a step within a larger computation (see \n\nExercise 6).","type":"content","url":"/adaptive#implementation","position":7},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Exercises"},"type":"lvl2","url":"/adaptive#exercises","position":8},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Exercises"},"content":"must be kept as #1\n\n⌨ For each integral below, use \n\nFunction 5.7.1 with error tolerance 10^{-2},10^{-3},\\ldots,10^{-12}. Make a table of errors and the number of integrand evaluation nodes used, and use a convergence plot as in \n\nDemo 5.7.2 to compare to fourth-order accuracy. (These integrals were taken from \n\nBailey et al. (2005).)\n\n(a) \\displaystyle \\int_0^1 x\\log(1+x)\\, dx = \\frac{1}{4}\n\n(b) \\displaystyle \\int_0^1 x^2 \\tan^{-1}x\\, dx = \\frac{\\pi-2+2\\log 2}{12}\n\n(c) \\displaystyle \\int_0^{\\pi/2}e^x \\cos x\\, dx = \\frac{e^{\\pi/2}-1}{2}\n\n(d) \\displaystyle \\int_{0}^1 \\sqrt{x} \\log(x) \\, dx = -\\frac{4}{9} (Note: Although the integrand has the limiting value zero as x\\to 0, you have to implement the function carefully to return zero as the value of f(0), or start the integral at x=\\macheps.)\n\n(e) \\displaystyle \\int_0^1 \\sqrt{1-x^2}\\, dx = \\frac{\\pi}{4}\n\n⌨ For each integral below: (i) use quadgk to find the value to at least 12 digits; (ii) use \n\nFunction 5.7.1 to evaluate the integral to a tolerance of \n\n10-8; (iii) compute the absolute error and the number of nodes used; (iv) use the O(h^2) term in the Euler–Maclaurin formula \n\n(5.6.9) to estimate how many nodes are required by the fixed-stepsize trapezoidal formula to reach an absolute error of \n\n10-8.\n\n(a) \\displaystyle \\int_{0.1}^3 \\operatorname{sech}(\\sin(1/x))\\, d x\n\n(b) \\rule[2em]{0pt}{0pt} \\displaystyle\\int_{-0.9}^9 \\ln((x+1)^3))\\, d x\n\n(c) \\rule[2em]{0pt}{0pt} \\displaystyle\\int_{-\\pi}^\\pi \\cos(x^3)\\, d x\n\n⌨ An integral such as \\displaystyle \\int_0^1 x^{-\\gamma}\\, dx for \\gamma>0, in which the integrand blows up at one or both ends, is known as an improper integral. It has a finite value if \\gamma<1, despite the singularity. One way to deal with the problem of the infinite value for f(t_0) is to replace the lower limit with a small number ε. (A more robust way to handle improper integrals is discussed in Chapter 9.)\n\nUsing \n\nFunction 5.7.1 with a small tolerance, make a log-log plot of the error as a function of ε when \\gamma=2/3, for \\epsilon=10^{-15},10^{-16},\\ldots,10^{-45}.\n\n⌨ A curious consequence of our logic in \n\nFunction 5.7.1 is that the algorithm uses what we believe to be a more accurate, sixth-order answer only for estimating error; the returned value is the supposedly less accurate S_f(2n). The practice of returning the extrapolated R_f(4n) instead is called local extrapolation.\n\nModify \n\nFunction 5.7.1 to use local extrapolation and repeat parts (a) and (e) of Exercise 1 above, comparing the observed convergence to both fourth order and sixth order.\n\n⌨ The sine integral function is defined by\\operatorname{Si}(x) = \\int_0^x \\frac{\\sin z}{z}\\, dz.\n\nUse \n\nFunction 5.7.1 to plot Si over the interval [1,10]. Note: You will need to replace the lower bound of integration by \\macheps.\n\n⌨  Adaptive integration can have subtle drawbacks. This exercise is based on the error function, a smooth function defined as\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-s^2}\\,ds.\n\n(a) Define a function g that approximates erf by applying \n\nFunction 5.6.1 with n=300. Make a plot of the error g(x)-\\operatorname{erf}(x) at 500 points in the interval [0,3].\n\n(b) Define another approximation h that applies \n\nFunction 5.7.1 with error tolerance \n\n10-7. Plot the error in h as in part (a). Why does it look so different from the previous case?\n\n(c) Suppose you wished to find x such that \\operatorname{erf}(x) = .95 by using rootfinding on one of your two approximations. Why is the version from part (a) preferable?","type":"content","url":"/adaptive#exercises","position":9},{"hierarchy":{"lvl1":"Convergence of finite differences"},"type":"lvl1","url":"/fd-converge","position":0},{"hierarchy":{"lvl1":"Convergence of finite differences"},"content":"All of the finite-difference formulas in the previous section based on equally spaced nodes converge as the node spacing h decreases to zero. However, note that to discretize a function over an interval [a,b], we use h=(b-a)/n, which implies n=(b-a)/h=O(h^{-1}). As h\\to 0, the total number of nodes needed grows without bound. So we would like to make h as large as possible while still achieving some acceptable accuracy.\n\nTruncation error of a finite-difference formula\n\nFor the finite-difference method \n\n(5.4.1) with weights a_{-p},\\ldots,a_{q}, the truncation error is\\tau_f(h) = f'(0) - \\frac{1}{h} \\sum_{k=-p}^{q} a_k f(kh).\n\nThe method is said to be convergent if \\tau_f(h)\\to 0 as h\\to 0.\n\nAlthough we are measuring the truncation error only at x=0, it could be defined for other x as well. The definition adjusts naturally to use f''(0) for difference formulas targeting the second derivative.\n\nAll of the finite-difference formulas given in \n\nFinite differences are convergent.\n\nThe forward difference formula \n\n(5.4.2) given by (f(h)-f(0))/h yields\\begin{split}\n  \\tau_f(h) &= f'(0) - \\frac{ f(h)-f(0)}{h} \\\\\n  &=f'(0) - h^{-1} \\left[ \\bigl( f(0) + h f'(0) + \\tfrac{1}{2}h^2f''(0)+ \\cdots \\bigr) - f(0) \\right] \\\\\n  & = -\\frac{1}{2}h f''(0) + O(h^2).\n  \\end{split}\n\nThe primary conclusion is that the truncation error is O(h) as h\\to 0.","type":"content","url":"/fd-converge","position":1},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Order of accuracy"},"type":"lvl2","url":"/fd-converge#order-of-accuracy","position":2},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Order of accuracy"},"content":"Of major interest is the rate at which \\tau_f\\to 0 in a convergent formula.\n\nOrder of accuracy of a finite-difference formula\n\nIf the truncation error of a finite-difference formula satisfies \\tau_f(h)=O(h^m) for a positive integer m, then m is the order of accuracy of the formula.\n\nHence the forward-difference formula in \n\nExample 5.5.1 has order of accuracy equal to 1; i.e., it is first-order accurate. All else being equal, a higher order of accuracy is preferred, since O(h^m) vanishes more quickly for larger values of m. As a rule, including more function values in a finite-difference formula (i.e., increasing the number of weights in \n\n(5.4.1)) increases the order of accuracy, as can be seen in \n\nTable 5.4.1 and \n\nTable 5.4.2.\n\nOrder of accuracy is calculated by expanding \\tau_f in a Taylor series about h=0 and ignoring all but the leading term.\n\nWe compute the truncation error of the centered difference formula \n\n(5.4.8):\\begin{split}\n  \\tau_f(h) &= f'(0) - \\frac{ f(h)-f(-h)}{2h}\\\\\n  &= f'(0) - (2h)^{-1} \\left[ \\bigl( f(0) + h f'(0) + \\tfrac{1}{2}h^2f''(0)+ \\tfrac{1}{6}h^3f'''(0)+ O(h^4) \\bigr) \\right.\\\\\n  &\\qquad - \\left.  \\bigl( f(0) - h f'(0) + \\tfrac{1}{2}h^2f''(0) - \\tfrac{1}{6}h^3f'''(0)+O(h^4) \\bigr) \\right] \\\\\n  &= -(2h)^{-1} \\left[ \\tfrac{1}{3}h^3f'''(0) + O(h^4) \\right] = O(h^2).\n\\end{split}\n\nThus, this method has order of accuracy equal to 2.\n\nConvergence of finite differences\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = x -> sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = [5 / 10^n for n in 1:6]\nFD1 = [];\nFD2 = [];\nfor h in h\n    push!(FD1, (f(h) - f(0)) / h)\n    push!(FD2, (f(h) - f(-h)) / 2h)\nend\n\npretty_table([h FD1 FD2], header=[\"h\", \"FD1\", \"FD2\"])\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerror_FD1 = @. exact_value - FD1\nerror_FD2 = @. exact_value - FD2\ntable = [h error_FD1 error_FD2]\npretty_table(table, header=[\"h\", \"error in FD1\", \"error in FD2\"])\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nplot(h, abs.([error_FD1 error_FD2]), m=:o, label=[\"FD1\" \"FD2\"],\n    xflip=true, xaxis=(:log10, L\"h\"), yaxis=(:log10, \"error\"),\n    title=\"Convergence of finite differences\", leg=:bottomleft)\n\n# Add lines for perfect 1st and 2nd order.\nplot!(h, [h h .^ 2], l=:dash, label=[L\"O(h)\" L\"O(h^2)\"])\n\nConvergence of finite differences\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = @(x) sin(exp(x + 1));\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = 5 ./ 10.^(1:6)';\nFD1 = zeros(size(h));\nFD2 = zeros(size(h));\nfor i = 1:length(h)\n    h_i = h(i);\n    FD1(i) = (f(h_i) - f(0)    ) / h_i;\n    FD2(i) = (f(h_i) - f(-h_i)) / (2*h_i);\nend\ndisp(table(h, FD1, FD2))\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerr1 = abs(exact_value - FD1);\nerr2 = abs(exact_value - FD2);\ndisp(table(h, err1, err2, variableNames=[\"h\", \"error in FD1\", \"error in FD2\"]))\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nclf\nloglog(h, abs([err1 err2]), \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err1(end) * (h / h(end)) .^ 1;\norder2 = 0.1 * err2(end) * (h / h(end)) .^ 2;\nhold on\nloglog(h, order1, \"--\", h, order2, \"--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"Convergence of finite differences\")\nlegend(\"FD1\", \"FD2\", \"O(h)\", \"O(h^2)\")\n\nConvergence of finite differences\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = lambda x: sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh_ = array([5 / 10**(n+1) for n in range(6)])\nFD = zeros((len(h_), 2))\nfor (i, h) in enumerate(h_):\n    FD[i, 0] = (f(h) - f(0)) / h \n    FD[i, 1] = (f(h) - f(-h)) / (2*h)\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nprint(results)\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerrors = FD - exact_value\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"error in FD1\", errors[:, 0])\nresults.add_column(\"error in FD2\", errors[:, 1])\nprint(results)\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nplot(h_, abs(errors), \"o-\", label=[\"FD1\", \"FD2\"])\ngca().invert_xaxis()\n# Add lines for perfect 1st and 2nd order.\nloglog(h_, h_, \"--\", label=\"$O(h)$\")\nloglog(h_, h_**2, \"--\", label=\"$O(h^2)$\")\nxlabel(\"$h$\")\nylabel(\"error\")\nlegend()","type":"content","url":"/fd-converge#order-of-accuracy","position":3},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Stability"},"type":"lvl2","url":"/fd-converge#stability","position":4},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Stability"},"content":"The truncation error \\tau_f(h) of a finite-difference formula is dominated by a leading term O(h^m) for an integer m. This error decreases as h\\to 0. However, we have not yet accounted for the effects of roundoff error. To keep matters as simple as possible, let’s consider the forward difference\\delta(h) = \\frac{f(x+h)-f(x)}{h}.\n\nAs h\\to 0, the numerator approaches zero even though the values f(x+h) and f(x) are not necessarily near zero. This is the recipe for subtractive cancellation error! In fact, finite-difference formulas are inherently ill-conditioned as h\\to 0. To be precise, recall that the condition number for the problem of computing f(x+h)-f(x) is\\kappa(h) = \\frac{ \\max\\{\\,|f(x+h)|,|f(x)|\\,\\} }{ |f(x+h)-f(x) | },\n\nimplying a relative error of size \\kappa(h) \\epsilon_\\text{mach} in its computation. Hence the numerical value we actually compute for δ is\\tilde{\\delta}(h) &= \\frac{f(x+h)-f(x)}{h}\\, (1+\\kappa(h)\\epsilon_\\text{mach}) \\\\\n&= \\delta(h) + \\frac{ \\max\\{\\,|f(x+h)|,|f(x)|\\,\\} }{ |f(x+h)-f(x) | }\\cdot \\frac{f(x+h)-f(x)}{h} \\cdot \\epsilon_\\text{mach}.\\\\\n\nHence as h\\to 0,\\bigl| \\tilde{\\delta}(h) - \\delta(h) \\bigr| = \\frac{ \\max\\{\\,|f(x+h)|,|f(x)|\\,\\} }{ h}\\,\\epsilon_\\text{mach} \\sim  |f(x)|\\, \\epsilon_\\text{mach}\\cdot h^{-1}.\n\nCombining the truncation error and the roundoff error leads to\\bigl|  f'(x) - \\tilde{\\delta}(h) \\bigr| \\le \\bigl| \\tau_f(h) \\bigr| + \\bigl|f(x) \\bigr|\\, \\epsilon_\\text{mach} \\, h^{-1}.\n\nEquation \n\n(5.5.8) indicates that while the truncation error τ vanishes as h decreases, the roundoff error actually increases thanks to the subtractive cancellation. At some value of h the two error contributions will be of roughly equal size. This occurs when\\bigl|f(x)\\bigr|\\, \\epsilon_\\text{mach}\\, h^{-1} \\approx C h, \\quad \\text{or} \\quad h \\approx K \\sqrt{\\rule[0.05em]{0mm}{0.4em}\\epsilon_\\text{mach}},\n\nfor a constant K that depends on x and f, but not h. In summary, for a first-order finite-difference method, the optimum spacing between nodes is proportional to \\epsilon_\\text{mach}^{\\,\\,1/2}. (This observation explains the choice of δ in \n\nFunction 4.6.1.)\n\nFor a method of truncation order m, the details of the subtractive cancellation are a bit different, but the conclusion generalizes.\n\nFor computing with a finite-difference method of order m in the presence of roundoff, the optimal spacing of nodes satisfiesh_\\text{opt} \\approx \\epsilon_\\text{mach}^{\\,\\,1/(m+1)},\n\nand the optimum total error is roughly \\epsilon_\\text{mach}^{\\,\\, m/(m+1)}.\n\nA different statement of the conclusion is that for a first-order formula, at most we can expect accuracy in only about half of the available machine digits. As m increases, we get ever closer to using the full accuracy available. Higher-order finite-difference methods are both more efficient and less vulnerable to roundoff than low-order methods.\n\nRoundoff error in finite differences\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = x -> exp(-1.3 * x);\nexact = -1.3\n\nh = [1 / 10^n for n in 1:12]\nFD1, FD2, FD4 = [], [], []\nfor h in h\n    nodes = h * (-2:2)\n    vals = @. f(nodes)\n    push!(FD1, dot([0 0 -1 1 0] / h, vals))\n    push!(FD2, dot([0 -1 / 2 0 1 / 2 0] / h, vals))\n    push!(FD4, dot([1 / 12 -2 / 3 0 2 / 3 -1 / 12] / h, vals))\nend\n\ntable = [h FD1 FD2 FD4]\npretty_table(table[1:4, :], header=[\"h\", \"FD1\", \"FD2\", \"FD4\"])\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = @. abs([FD1 FD2 FD4] - exact)\n\nplot(h, err, m=:o, label=[\"FD1\" \"FD2\" \"FD4\"],\n    xaxis=(:log10, L\"h\"), xflip=true, yaxis=(:log10, \"error\"),\n    title=\"FD error with roundoff\", legend=:bottomright)\n\n# Add line for perfect 1st order.\nplot!(h, 0.1 * eps() ./ h, l=:dash, color=:black, label=L\"O(h^{-1})\")\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).\n\nRoundoff error in finite differences\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = @(x) exp(-1.3 * x);\nexact = -1.3;\n\nh = 10 .^ (-(1:12))';\nFD = zeros(length(h), 3);\nfor i = 1:length(h)\n    h_i = h(i);\n    nodes = h_i * (-2:2);\n    vals = f(nodes);\n    FD(i, 1) = dot([0      0 -1   1    0] / h_i, vals);\n    FD(i, 2) = dot([0    -1/2 0 1/2    0] / h_i, vals);\n    FD(i, 3) = dot([1/12 -2/3 0 2/3 -1/12] / h_i, vals);\nend\nformat long\ndisp(table(h, FD(:, 1), FD(:, 2), FD(:, 3), variableNames=[\"h\", \"FD1\", \"FD2\", \"FD4\"]))\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = abs(FD - exact);\nclf\nloglog(h, err, \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err(end, 1) * (h / h(end)) .^ (-1);\nhold on\nloglog(h, order1, \"k--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"FD error with roundoff\")\nlegend(\"FD1\", \"FD2\", \"FD4\", \"O(1/h)\", \"location\", \"northeast\")\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).\n\nRoundoff error in finite differences\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = lambda x: exp(-1.3 * x)\nexact = -1.3\n\nh_ = array([1 / 10**(n+1) for n in range(12)])\nFD = zeros((len(h_), 3))\nfor (i, h) in enumerate(h_):\n    nodes = h * linspace(-2, 2, 5)\n    vals = f(nodes)\n    FD[i, 0] = dot(array([0, 0, -1, 1, 0]) / h, vals)\n    FD[i, 1] = dot(array([0, -1/2, 0, 1/2, 0]) / h, vals)\n    FD[i, 2] = dot(array([1/12, -2/3, 0, 2/3, -1/12]) / h, vals)\n\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nresults.add_column(\"FD4\", FD[:, 2])\nprint(results)\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nloglog(h_, abs(FD[:, 0] + 1.3), \"-o\", label=\"FD1\")\nloglog(h_, abs(FD[:, 1] + 1.3), \"-o\", label=\"FD2\")\nloglog(h_, abs(FD[:, 2] + 1.3), \"-o\", label=\"FD4\")\ngca().invert_xaxis()\nplot(h_, 0.1 * 2 ** (-52) / h_, \"--\", color=\"k\", label=\"$O(h^{-1})$\")\nxlabel(\"$h$\")\nylabel(\"total error\")\ntitle(\"FD error with roundoff\")\nlegend()\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/fd-converge#stability","position":5},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Exercises"},"type":"lvl2","url":"/fd-converge#exercises","position":6},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Exercises"},"content":"⌨ Evaluate the centered second-order finite-difference approximation to f'(4\\pi/5) for f(x)=\\cos(x^3) and h=2^{-1},2^{-2},\\ldots,2^{-8}. On a log-log graph, plot the error as a function of h and compare it graphically to second-order convergence.\n\n✍ Derive the first two nonzero terms of the Taylor series at h=0 of the truncation error \\tau_{f}(h) for the formula \n\n(5.4.3).\n\n✍ Calculate the first nonzero term in the Taylor series of the truncation error \\tau_{f}(h) for the finite-difference formula defined by the second row of \n\nTable 5.4.2.\n\n✍ Calculate the first nonzero term in the Taylor series of the truncation error \\tau_{f}(h) for the finite-difference formula defined by the third row of \n\nTable 5.4.2.\n\n✍ Show that the formula \n\n(5.4.12) is second-order accurate.\n\n✍  A different way to derive finite-difference formulas is the method of undetermined coefficients. Starting from \n\n(5.4.1),f'(x) \\approx \\frac{1}{h}\\sum_{k=-p}^q a_k f(x+kh),\n\nlet each f(x+k h) be expanded in a series around h=0. When the coefficients of powers of h are collected, one obtains\\frac{1}{h} \\sum_{k=-p}^q a_k f(x+kh) = \\frac{b_0}{h} + b_1 f'(x) + b_2 f''(x)h + \\cdots,\n\nwhereb_i = \\sum_{k=-p}^q k^i a_k.\n\nIn order to make the result as close as possible to f'(x), we impose the conditionsb_0 = 0,\\, b_1=1,\\, b_2=0,\\, b_3=0,\\,\\ldots,\\,b_{p+q}=0.\n\nThis provides a system of linear equations for the weights.\n\n(a) For p=q=2, write out the system of equations for a_{-2}, a_{-1}, a_0, a_1, a_2.\n\n(b) Verify that the coefficients from the appropriate row of \n\nTable 5.4.1 satisfy the equations you wrote down in part (a).\n\n(c) Derive the finite-difference formula for p=1, q=2 using the method of undetermined coefficients.\n\nThe term truncation error is derived from the idea that the finite-difference formula, being finite, has to truncate the series representation and thus cannot be exactly correct for all functions.","type":"content","url":"/fd-converge#exercises","position":7},{"hierarchy":{"lvl1":"Finite differences"},"type":"lvl1","url":"/finitediffs","position":0},{"hierarchy":{"lvl1":"Finite differences"},"content":"Now we turn to one of the most common and important applications of interpolants: finding derivatives of functions. Because differentiation is a linear operation, we will constrain ourselves to formulas that are linear in the nodal values.\n\nFinite-difference formula\n\nA finite-difference formula is a list of values a_{-p},\\ldots,a_q, called weights, such that for all f in some class of functions,  f'(x) \\approx \\frac{1}{h} \\sum_{k=-p}^{q} a_k f(x + kh).\n\nThe weights are independent of f and h. The formula is said to be convergent if the approximation becomes equality in the limit h\\to 0 for a suitable class of functions.\n\nNote that while \n\n(5.4.1) is about finding the derivative at a single point x, the same formula can be applied for different x. The usual situation is a regularly spaced grid of nodes, a,a+h,a+2h,\\ldots,b, and then the value of f at each node takes part in multiple applications of the formula. This will be demonstrated in \n\nExample 5.4.1 below.","type":"content","url":"/finitediffs","position":1},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Common examples"},"type":"lvl2","url":"/finitediffs#common-examples","position":2},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Common examples"},"content":"There are three appealing special cases of \n\n(5.4.1) that get special attention.\n\nForward, backward, and centered FD formulas\n\nA forward difference formula is characterized by \n\n(5.4.1) with p=0, a backward difference formula has q=0, and a centered difference formula has p=q.\n\nThe simplest example of a forward difference formula is inspired by the familiar limit definition of a derivative:  f'(x) \\approx \\frac{f(x+h)-f(x)}{h},\n\nwhich is \n\n(5.4.1) with p=0, q=1, a_0=-1, and a_1=1. Analogously, we have the backward difference  f'(x) \\approx \\frac{f(x)-f(x-h)}{h},\n\nin which p=1, q=0.\n\nSuppose f(x)=x^2, and we take h=\\frac{1}{4} over the interval [0,1]. This results in the nodes 0,\\frac{1}{4},\\frac{1}{2},\\frac{3}{4},1. We evaluate f at the nodes to getf(0) = 0, \\; f\\left(\\tfrac{1}{4}\\right) = \\frac{1}{16},\\; f\\left(\\tfrac{1}{2}\\right)=\\frac{1}{4},\\; f\\left(\\tfrac{3}{4}\\right)=\\frac{9}{16}, \\; f(1)=1.\n\nThis gives four forward difference estimates,f'(0) & \\approx 4\\left(\\frac{1}{16}-0\\right), &\\quad \nf'\\left(\\tfrac{1}{4}\\right)& \\approx 4\\left(\\frac{1}{4}-\\frac{1}{16}\\right), \\\\\nf'\\left(\\tfrac{1}{2}\\right)& \\approx 4\\left(\\frac{9}{16}-\\frac{1}{4}\\right), &\\quad \nf'\\left(\\tfrac{3}{4}\\right) &\\approx 4\\left(1-\\frac{9}{16}\\right).\n\nWe also get four backward difference estimates,f'\\left(\\tfrac{1}{4}\\right) &\\approx 4\\left(\\frac{1}{16}-0\\right), &\\quad \nf'\\left(\\tfrac{1}{2}\\right) &\\approx 4\\left(\\frac{1}{4}-\\frac{1}{16}\\right), \\\\ \nf'\\left(\\tfrac{3}{4}\\right) &\\approx 4\\left(\\frac{9}{16}-\\frac{1}{4}\\right), &\\quad \nf'\\left(1\\right) &\\approx 4\\left(1-\\frac{9}{16}\\right).\n\nNotice that it’s the same four differences each time, but we’re interpreting them as derivative estimates at different nodes.\n\nAs pointed out in \n\nExample 5.4.1, the only real distinction between \n\n(5.4.2) and \n\n(5.4.3) is whether we think that f' is being evaluated at the left node or the right one. Symmetry would suggest that we should evaluate it halfway between. That is the motivation behind centered difference formulas.\n\nLet’s derive the shortest centered formula using p=q=1. For simplicity, we will set x=0 without affecting the result. This means that f(-h), f(0), and f(h) are all available in \n\n(5.4.1).\n\nNote that \n\n(5.4.2) is simply the slope of the line through the points \\bigl(0,f(0)\\bigr) and \\bigl(h,f(h)\\bigr). One route to using all three function values is to differentiate the quadratic polynomial that interpolates \\bigl(-h,f(-h)\\bigr) as well (see \n\nExercise 1):Q(x) = \\frac{x(x-h)}{2h^2} f(-h) - \\frac{x^2-h^2}{h^2} f(0) + \\frac{x(x+h)}{2h^2} f(h).\n\nThis leads tof'(0) \\approx Q'(0) = \\frac{f(h)-f(-h)}{2h}.\n\nThis result is equivalent to \n\n(5.4.1) with p=q=1 and weights a_{-1}=-\\frac{1}{2}, a_0=0, and a_1=\\frac{1}{2}. Observe that while the value of f(0) was available during the derivation, its weight ends up being zero.\n\nBesides the aesthetic appeal of symmetry, in \n\nConvergence of finite differences we will see another important advantage of \n\n(5.4.8) compared to the one-sided formulas.\n\nWe can in principle derive any finite-difference formula from the same process: Interpolate the given function values, then differentiate the interpolant exactly. Some results of the process are given in \n\nTable 5.4.1 for centered differences, and in \n\nTable 5.4.2 for forward differences. Both show the weights for estimating the derivative at x=0. To get backward differences, you change the signs and reverse the order of the coefficients in any row of \n\nTable 5.4.2; see \n\nExercise 2.\n\nTable 5.4.1:Weights for centered finite-difference formulas.\n\norder\n\n-4h\n\n-3h\n\n-2h\n\n-h\n\n0\n\nh\n\n2h\n\n3h\n\n4h\n\n2\n\n\n\n\n\n\n\n-\\frac{1}{2}\n\n0\n\n\\frac{1}{2}\n\n\n\n\n\n\n\n4\n\n\n\n\n\n\\frac{1}{12}\n\n-\\frac{2}{3}\n\n0\n\n\\frac{2}{3}\n\n-\\frac{1}{12}\n\n\n\n\n\n6\n\n\n\n-\\frac{1}{60}\n\n\\frac{3}{20}\n\n-\\frac{3}{4}\n\n0\n\n\\frac{3}{4}\n\n-\\frac{3}{20}\n\n\\frac{1}{60}\n\n\n\n8\n\n\\frac{1}{280}\n\n-\\frac{4}{105}\n\n\\frac{1}{5}\n\n-\\frac{4}{5}\n\n0\n\n\\frac{4}{5}\n\n-\\frac{1}{5}\n\n\\frac{4}{105}\n\n-\\frac{1}{280}\n\nTable 5.4.2:Weights for forward finite-difference formulas. To get backward differences, change the signs and reverse the order of the coefficients.\n\norder\n\n0\n\nh\n\n2h\n\n3h\n\n4h\n\n1\n\n-1\n\n1\n\n\n\n\n\n\n\n2\n\n-\\frac{3}{2}\n\n2\n\n-\\frac{1}{2}\n\n\n\n\n\n3\n\n-\\frac{11}{6}\n\n3\n\n-\\frac{3}{2}\n\n\\frac{1}{3}\n\n\n\n4\n\n-\\frac{25}{12}\n\n4\n\n-3\n\n\\frac{4}{3}\n\n-\\frac{1}{4}\n\nThe main motivation for using more function values in a formula is to improve the accuracy. This is measured by order of accuracy, which is shown in the tables and explored in \n\nSection 5.5.\n\nAccording to the tables, here are three specific finite-difference formulas:\\begin{split}\nf'(0) &\\approx \\tfrac{1}{h} \\left[ \\tfrac{1}{12} f(-2h)\n- \\tfrac{2}{3} f(-h) + \\tfrac{2}{3} f(h) - \\tfrac{1}{12} f(2h) \\right], \\\\[1mm]\nf'(0) &\\approx \\tfrac{1}{h} \\left[ -\\tfrac{3}{2} f(0) + 2 f(h) -\\tfrac{1}{2} f(2h) \\right], \\\\[1mm]\nf'(0) &\\approx \\tfrac{1}{h} \\left[ \\tfrac{1}{2} f(-2h) - 2 f(-h) + \\tfrac{3}{2} f(0) \\right].\n\\end{split}\n\nFinite differences\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = x -> exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / 2h\nCD4 = (f(-2h) - 8f(-h) + 8f(h) - f(2h)) / 12h\n@show (CD2, CD4);\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3f(0) + 4f(h) - f(2h)) / 2h\n@show (FD1, FD2);\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2h) - 4f(-h) + 3f(0)) / 2h\n@show (BD1, BD2);\n\nFinite differences\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05;\nformat long\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\n\nFinite differences\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\nprint(f\"CD2 is {CD2:.9f} and CD4 is {CD4:.9f}\")\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")","type":"content","url":"/finitediffs#common-examples","position":3},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Higher derivatives"},"type":"lvl2","url":"/finitediffs#higher-derivatives","position":4},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Higher derivatives"},"content":"Many applications require the second derivative of a function. It’s tempting to use the finite difference of a finite difference. For example, applying \n\n(5.4.8) to f' givesf''(0) \\approx  \\frac{ f'(h) - f'(h) }{2h}.\n\nThen applying \n\n(5.4.8) to approximate the appearances of f' leads tof''(0) \\approx  \\frac{ f(-2h) - 2 f(0) + f(2h) }{4h^2}.\n\nThis is a valid formula, but it uses values at \\pm 2h rather than the closer values at \\pm h. A better and more generalizable tactic is to return to the quadratic Q(x) in \n\n(5.4.7) and use Q''(0) to approximate f''(0). Doing so yields  f''(0) \\approx  \\frac{ f(-h) - 2 f(0) + f(h) }{h^2},\n\nwhich is the simplest centered second-difference formula. As with the first derivative, we can choose larger values of p and q in \n\n(5.4.1) to get new formulas, such asf''(0) \\approx \\frac{ f(0) - 2 f(h) + f(2h) }{h^2},\n\nandf''(0) \\approx \\frac{ 2f(0) - 5 f(h) + 4 f(2h) -f(3h) }{h^2}.\n\nFor the second derivative, converting a forward difference to a backward difference requires reversing the order of the weights, while not changing their signs.\n\nFinite differences for f''\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = x -> exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2f(0) + f(h)) / h^2\n@show CD2;\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2f(h) + f(2h)) / h^2\nFD2 = (2f(0) - 5f(h) + 4f(2h) - f(3h)) / h^2\n@show (FD1, FD2);\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2h) - 2f(-h) + f(0)) / h^2\nBD2 = (-f(-3h) + 4f(-2h) - 5f(-h) + 2f(0)) / h^2\n@show (BD1, BD2);\n\nFinite differences for f''\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05;\nformat long\nCD2 = (f(-h) - 2*f(0) + f(h)) / h^2\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h^2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h^2\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h^2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h^2\n\nFinite differences for f''\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2*f(0) + f(h)) / h**2\nprint(f\"CD2 is {CD2:.9f}\")\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h**2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h**2\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h**2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h**2\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")","type":"content","url":"/finitediffs#higher-derivatives","position":5},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Arbitrary nodes"},"type":"lvl2","url":"/finitediffs#arbitrary-nodes","position":6},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Arbitrary nodes"},"content":"Although function values at equally spaced nodes are a common and convenient situation, the node locations may be arbitrary. The general form of a finite-difference formula is  f^{(m)}(0) \\approx \\sum_{k=0}^{r} c_{k,m} \\,f(t_k).\n\nWe no longer assume equally spaced nodes, so there is no “h” to be used in the formula. As before, the weights may be applied after any translation of the independent variable. The weights again follow from the interpolate/differentiate recipe, but the algebra becomes complicated. Fortunately there is an elegant recursion known as Fornberg’s algorithm that can calculate these weights for any desired formula. We present it without derivation as \n\nFunction 5.4.1.\n\nfdweights\n\nFornberg’s algorithm for finite difference weights\n\n\"\"\"\n    fdweights(t,m)\n\nCompute weights for the `m`th derivative of a function at zero using\nvalues at the nodes in vector `t`.\n\"\"\"\nfunction fdweights(t,m)\n# This is a compact implementation, not an efficient one.\n    # Recursion for one weight. \n    function weight(t,m,r,k)\n        # Inputs\n        #   t: vector of nodes \n        #   m: order of derivative sought \n        #   r: number of nodes to use from t \n        #   k: index of node whose weight is found\n\n        if (m<0) || (m>r)        # undefined coeffs must be zero\n            c = 0\n        elseif (m==0) && (r==0)  # base case of one-point interpolation\n            c = 1\n        else                     # generic recursion\n            if k<r\n                c = (t[r+1]*weight(t,m,r-1,k) -\n                    m*weight(t,m-1,r-1,k))/(t[r+1]-t[k+1])\n            else\n                numer = r > 1 ? prod(t[r]-x for x in t[1:r-1]) : 1\n                denom = r > 0 ? prod(t[r+1]-x for x in t[1:r]) : 1\n                β = numer/denom\n                c = β*(m*weight(t,m-1,r-1,r-1) - t[r]*weight(t,m,r-1,r-1))\n            end\n        end\n        return c\n    end\n    r = length(t)-1\n    w = zeros(size(t))\n    return [ weight(t,m,r,k) for k=0:r ]\nend\n\nFornberg’s algorithm for finite difference weights\n\nfunction w = fdweights(t,m)\r\n%FDWEIGHTS   Fornberg's algorithm for finite difference weights.\r\n% Input:\r\n%   t    nodes (vector, length r+1)\r\n%   m    order of derivative sought at x=0 (integer scalar)\r\n% Output:\r\n%   w    weights for the approximation to the jth derivative (vector)\r\n\r\n% This is a compact implementation, not an efficient one. \r\n\r\nr = length(t)-1;\r\nw = zeros(size(t));\r\nfor k = 0:r\r\n  w(k+1) = weight(t,m,r,k);\r\nend\r\n\r\n\r\nfunction c = weight(t,m,r,k)\r\n% Implement a recursion for the weights.\r\n% Input:\r\n%   t   nodes (vector)\r\n%   m   order of derivative sought \r\n%   r   number of nodes to use from t (<= length(t))\r\n%   k   index of node whose weight is found \r\n% Output:\r\n%   c   finite difference weight \r\n\r\nif (m<0) || (m>r)        % undefined coeffs must be zero\r\n  c = 0;    \r\nelseif (m==0) && (r==0)  % base case of one-point interpolation\r\n  c = 1;   \r\nelse                     % generic recursion \r\n  if k<r\r\n    c = (t(r+1)*weight(t,m,r-1,k) - ...\r\n        m*weight(t,m-1,r-1,k))/(t(r+1)-t(k+1));\r\n  else\r\n    beta = prod(t(r)-t(1:r-1)) / prod(t(r+1)-t(1:r));\r\n    c = beta*(m*weight(t,m-1,r-1,r-1) - t(r)*weight(t,m,r-1,r-1));\r\n  end\r\nend\n\nFornberg’s algorithm for finite difference weights\n\ndef fdweights(t, m):\n    \"\"\"\n    fdweights(t,m)\n\n    Return weights for the `m`th derivative of a function at zero using values at the\n    nodes in vector `t`.\n    \"\"\"\n    # This is a compact implementation, not an efficient one.\n\n    def weight(t, m, r, k):\n        # Recursion for one weight.\n        # Input:\n        #   t   nodes (vector)\n        #   m   order of derivative sought\n        #   r   number of nodes to use from t (<= length(t))\n        #   k   index of node whose weight is found\n\n        if (m < 0) or (m > r):  # undefined coeffs must be zero\n            c = 0\n        elif (m == 0) and (r == 0):  # base case of one-point interpolation\n            c = 1\n        else:  # generic recursion\n            if k < r:\n                c = t[r] * weight(t, m, r - 1, k) - m * weight(t, m - 1, r - 1, k)\n                c = c / (t[r] - t[k])\n            else:\n                if r <= 1:\n                    numer = 1.0\n                else:\n                    numer = np.prod(t[r-1] - t[:r-1])\n                if r <= 0:\n                    denom = 1.0\n                else:\n                    denom = np.prod(t[r] - t[:r])\n                beta = numer / denom\n                c = weight(t, m - 1, r - 1, r - 1) - t[r-1] * weight(t, m, r - 1, r - 1)\n                c *= beta\n        return c\n\n    r = len(t) - 1\n    w = np.zeros(t.shape)\n    return [weight(t, m, r, k) for k in range(r + 1)]\n\nFinite differences at arbitrary nodes\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75]   # nodes\nf = x -> cos(x^2)\ndfdx = x -> -2 * x * sin(x^2)\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t .- 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f.(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nFNC.fdweights(0:3, 1)\n\nBy giving nodes of type Rational, we can get exact values instead.\n\nFNC.fdweights(Rational.(0:3), 1)\n\nFinite differences at arbitrary nodes\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75];    % nodes\nf = @(x) cos(x.^2);\ndfdx = @(x) -2 * x * sin(x^2);\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nformat short\nw = fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = w * f(t)'\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nfdweights(0:3, 1)\n\nFinite differences at arbitrary nodes\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = array([0.35, 0.5, 0.57, 0.6, 0.75])   # nodes\nf = lambda x: cos(x**2)\ndfdx = lambda x: -2 * x * sin(x**2)\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nprint(FNC.fdweights(linspace(0, 3, 4), 1))","type":"content","url":"/finitediffs#arbitrary-nodes","position":7},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Exercises"},"type":"lvl2","url":"/finitediffs#exercises","position":8},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Exercises"},"content":"✍ This problem refers to Q(x) defined by \n\n(5.4.7).\n\n(a) Show that Q(x) interpolates the three values of f at x=-h, x=0, and x=h.\n\n(b) Show that Q'(0) gives the finite-difference formula defined by \n\n(5.4.8).\n\n(a) ✍ \n\nTable 5.4.2 lists forward difference formulas in which p=0 in \n\n(5.4.1). Show that the change of variable g(x) = f(-x) transforms these formulas into backward difference formulas with q=0, and write out the table analogous to \n\nTable 5.4.2 for backward differences.\n\n(b) ⌨ Suppose you are given the nodes t_0=0.9, t_1=1, and t_2=1.1, and f(x) = \\sin(2x). Using formulas from \n\nTable 5.4.1 and \n\nTable 5.4.2, compute second-order accurate approximations to f' at each of the three nodes.\n\n⌨ Let f(x)=e^{-x}, x=0.5, and h=0.2. Using \n\nFunction 5.4.1 to get the necessary weights on five nodes centered at x, find finite-difference approximations to the first, second, third, and fourth derivatives of f. Make a table showing the derivative values and the errors in each case.\n\n⌨ In the manner of \n\nDemo 5.4.5, use \n\nFunction 5.4.1 on centered node vectors of length  3, 5, 7, and 9 to produce a table analogous to \n\nTable 5.4.1 for the second derivative f''(0). (You do not need to show the orders of accuracy, just the weights.)\n\n⌨ For this problem, let f(x)=\\tan(2x).\n\n(a) ⌨ Apply \n\nFunction 5.4.1 to find a finite-difference approximation to f''(0.3) using the five nodes t_j=0.3+jh for j=-2,\\ldots,2 and h=0.05. Compare to the exact value of f''(0.3).\n\n(b) ⌨  Repeat part (a) for f''(0.75) on the nodes t_j=0.75+jh. Why is the finite-difference result so inaccurate? (Hint: A plot of f might be informative.)\n\n✍ Find the finite-difference formula for f''(0) that results from applying \n\n(5.4.2) on f' and then \n\n(5.4.3) on f' within that result.\n\n(a) ✍ Show using L’Hôpital’s Rule that the centered formula approximation \n\n(5.4.8) converges to an equality as h\\to 0.\n\n(b) ✍ Derive two conditions on the finite-difference weights in \n\n(5.4.1) that arise from requiring convergence as h\\to 0. (Hint: Consider what is required in order to apply L’Hôpital’s Rule, as well as the result of applying it.)","type":"content","url":"/finitediffs#exercises","position":9},{"hierarchy":{"lvl1":"Numerical integration"},"type":"lvl1","url":"/integration","position":0},{"hierarchy":{"lvl1":"Numerical integration"},"content":"In calculus you learn that the elegant way to evaluate a definite integral is to apply the Fundamental Theorem of Calculus and find an antiderivative. The connection is so profound and pervasive that it’s easy to overlook that a definite integral is a numerical quantity existing independently of antidifferentiation.  However, most conceivable integrands have no antiderivative in terms of familiar functions.\n\nNumerical integration\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe Julia package QuadGK has an all-purpose numerical integrator that estimates the value without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nQ, errest = quadgk(x -> exp(x), 0, 1)\n@show Q;\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quadgk(x -> exp(sin(x)), 0, 1)\n@show Q;\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nplot([exp, x -> exp(sin(x))], 0, 1, fill=0, layout=(2, 1),\n    xlabel=L\"x\", ylabel=[L\"e^x\" L\"e^{\\sin(x)}\"], ylim=[0, 2.7])\n\nNumerical integration\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nformat long\nexact = exp(1) - 1\n\nMATLAB has numerical integrator integral that estimates the value without finding the antiderivative first. As you can see here, it can be as accurate as floating-point precision allows.\n\nintegral(@(x) exp(x), 0, 1)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nintegral(@(x) exp(sin(x)), 0, 1)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 201)';\nsubplot(2,1,1), fill([x; 1; 0], [exp(x); 0;0 ], [1, 0.9, 0.9])\ntitle('exp(x)')  % ignore this line\nylabel('f(x)')    % ignore this line\nsubplot(2, 1, 2), fill([x; 1; 0], [exp(sin(x)); 0; 0], [1, 0.9, 0.9])\ntitle('exp(sin(x))')  % ignore this line\nxlabel('x'), ylabel('f(x)')    % ignore this line\n\nNumerical integration\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe module scipy.integrate has multiple functions that estimate the value of an integral numerically without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nQ, errest = quad(exp, 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quad(lambda x: exp(sin(x)), 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 300)\nsubplot(1, 2, 1)\nplot(x, exp(x))\nylim([0, 2.7]), title(\"exp(x)\")\nsubplot(1, 2, 2)\nplot(x, exp(sin(x)))\nylim([0, 2.7]), title(\"exp(sin(x))\");\n\nNumerical integration, which also goes by the older name quadrature, is performed by combining values of the integrand sampled at nodes. In this section we will assume equally spaced nodes using the definitions  t_i = a +i h, \\quad h=\\frac{b-a}{n}, \\qquad i=0,\\ldots,n.\n\nNumerical integration formula\n\nA numerical integration formula is a list of weights w_0,\\ldots,w_n chosen so that for all f in some class of functions,  \\begin{split}\n    \\int_a^b f(x)\\, dx \\approx h \\sum_{i=0}^n w_if(t_i) =  h \\bigl[ w_0f(t_0)+w_1f(t_1)+\\cdots w_nf(t_n) \\bigr],\n  \\end{split}\n\nwith the t_i defined in \n\n(5.6.1). The weights are independent of f and h.\n\nNumerical integration formulas can be applied to sequences of data values even if no function is explicitly known to generate them. For our presentation and implementations, however, we assume that f is known and can be evaluated anywhere.\n\nA straightforward way to derive integration formulas is to mimic the approach taken for finite differences: find an interpolant and operate exactly on it.","type":"content","url":"/integration","position":1},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Trapezoid formula"},"type":"lvl2","url":"/integration#trapezoid-formula","position":2},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Trapezoid formula"},"content":"One of the most important integration formulas results from integration of the piecewise linear interpolant (see \n\nPiecewise linear interpolation). Using the cardinal basis form of the interpolant in \n\n(5.2.3), we have\\int_a^b f(x) \\, dx \\approx \\int_a^b \\sum_{i=0}^n f(t_i) H_i(x)\\, dx = \\sum_{i=0}^n f(t_i) \\left[ \\int_a^b H_i(x)\\right]\\, dx.\n\nThus we can identify the weights as w_i = h^{-1} \\int_a^b H_i(x)\\, dx. Using areas of triangles, it’s trivial to derive thatw_i = \\begin{cases}\n1, & i=1,\\ldots,n-1,\\\\\n\\frac{1}{2}, & i=0,n.\n\\end{cases}\n\nPutting everything together, the resulting formula is\\begin{split}\n  \\int_a^b f(x)\\, dx \\approx T_f(n) &= h\\left[\n    \\frac{1}{2}f(t_0) + f(t_1) + f(t_2) + \\cdots + f(t_{n-1}) +\n    \\frac{1}{2}f(t_n) \\right].\n\\end{split}\n\nTrapezoid formula\n\nThe trapezoid formula is a numerical integration formula in the form \n\n(5.6.2), withw_i = \\begin{cases}\n  \\frac{1}{2},& i=0 \\text{ or } i=n, \\\\ \n  1, & 0 < i < n.\n  \\end{cases}\n\nGeometrically, as illustrated in \n\nFigure 5.6.1, the trapezoid formula sums of the areas of trapezoids approximating the region under the curve y=f(x).\n\nThe trapezoid formula is the Swiss Army knife of integration formulas. A short implementation is given as \n\nFunction 5.6.1.\n\n\n\nFigure 5.6.1:Trapezoid formula for integration. The piecewise linear interpolant defines trapezoids that approximate the region under the curve.\n\ntrapezoid\n\nTrapezoid formula for numerical integration\n\n\"\"\"\n    trapezoid(f,a,b,n)\n\nApply the trapezoid integration formula for integrand `f` over\ninterval [`a`,`b`], broken up into `n` equal pieces. Returns\nthe estimate, a vector of nodes, and a vector of integrand values at the\nnodes.\n\"\"\"\nfunction trapezoid(f,a,b,n)\n    h = (b-a)/n\n    t = range(a,b,length=n+1)\n    y = f.(t)\n    T = h * ( sum(y[2:n]) + 0.5*(y[1] + y[n+1]) )\n    return T,t,y\nend\n\nTrapezoid formula for numerical integration\n\nfunction [T,t,y] = trapezoid(f,a,b,n)\n%TRAPEZOID   Trapezoid formula for numerical integration.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   n     number of interval divisions\n% Output:\n%   T     approximation to the integral of f over (a,b)\n%   t     vector of nodes used\n%   y     vector of function values at nodes\n\nh = (b-a)/n;\nt = a + h*(0:n)';\ny = f(t);\nT = h * ( sum(y(2:n)) + 0.5*(y(1) + y(n+1)) );\n\nTrapezoid formula for numerical integration\n\ndef trapezoid(f, a, b, n):\n    \"\"\"\n    trapezoid(f,a,b,n)\n\n    Apply the trapezoid integration formula for integrand `f` over interval [`a`,`b`], broken up into `n` equal pieces. Returns estimate, vector of nodes, and vector of integrand values at the nodes.\n    \"\"\"\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n    y = f(t)\n    T = h * (np.sum(y[1:-1]) + 0.5 * (y[0] + y[-1]))\n    return T, t, y\n\nLike finite-difference formulas, numerical integration formulas have a truncation error.\n\nTruncation error of a numerical integration formula\n\nFor the numerical integration formula \n\n(5.6.2), the truncation error is\\tau_f(h) = \\int_a^b f(x) \\, dx - h \\sum_{i=0}^{n} w_i f(t_i).\n\nThe order of accuracy is as defined in \n\nDefinition 5.5.2.\n\nIn \n\nTheorem 5.2.2 we stated that the pointwise error in a piecewise linear interpolant with equal node spacing h is bounded by O(h^2) as h\\rightarrow 0. Using I to stand for the exact integral of f and p to stand for the piecewise linear interpolant, we obtain\\begin{split}\n  I - T_f(n) = I - \\int_a^b p(x)\\, dx &= \\int_a^b \\bigl[f(x)-p(x)\\bigr] \\, dx \\\\\n  &\\le (b-a) \\max_{x\\in[a,b]} |f(x)-p(x)| = O(h^2).\n\\end{split}\n\nA more thorough statement of the truncation error is known as the Euler–Maclaurin formula,\\int_a^b f(x)\\, dx &= T_f(n) - \\frac{h^2}{12} \\left[ f'(b)-f'(a) \\right] + \\frac{h^4}{740} \\left[ f'''(b)-f'''(a) \\right] + O(h^6) \\\\\n    &= T_f(n) - \\sum_{k=1}^\\infty \\frac{B_{2k}h^{2k}}{(2k)!}  \\left[ f^{(2k-1)}(b)-f^{(2k-1)}(a) \\right],\n\nwhere the B_{2k} are constants known as Bernoulli numbers. Unless we happen to be fortunate enough to have a function with f'(b)=f'(a), we should expect truncation error at second order and no better.\n\nThe trapezoid integration formula is second-order accurate.\n\nTrapezoid integration\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = x -> exp(sin(7 * x));\na = 0;\nb = 2;\n\nIn lieu of the exact value, we use the QuadGK package to find an accurate result.:::{card}\nIf a function has multiple return values, you can use an underscore `_` to indicate a  return value you want to ignore.\n\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14);\nprintln(\"Integral = $Q\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\n@show (T, Q - T);\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = [10^n for n in 1:5]\nerr = []\nfor n in n\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    push!(err, Q - T)\nend\n\npretty_table([n err], header=[\"n\", \"error\"])\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nplot(n, abs.(err), m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"error\"),\n    title=\"Convergence of trapezoidal integration\")\n\n# Add line for perfect 2nd order.\nplot!(n, 3e-3 * (n / n[1]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\n\nTrapezoid integration\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = @(x) exp(sin(7 * x));\na = 0;  b = 2;\n\nIn lieu of the exact value, we use the integral function to find an accurate result.\n\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14);\nfprintf(\"Integral = %.15f\", I)\n\nHere is the trapezoid result at n=40, and its error.\n\nT = trapezoid(f, a, b, 40);\nfprintf(\"Trapezoid error = %.2e\", I - T)\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = 10 .^ (1:5)';\nerr = zeros(size(n));\nfor i = 1:length(n)\n    T = trapezoid(f, a, b, n(i));\n    err(i) = I - T;\nend\ndisp(table(n, err, variableNames=[\"n\", \"Trapezoid error\"]))\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"trapezoid\")\nhold on\nloglog(n, 0.1 * abs(err(end)) * (n / n(end)).^(-2), \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"error\")\ntitle(\"Convergence of trapezoidal integration\")\nlegend()\n\nTrapezoid integration\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = lambda x: exp(sin(7 * x))\na, b = 0, 2\n\nIn lieu of the exact value, we will use the quad function to find an accurate result.\n\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\nprint(f\"Trapezoid estimate is {T:.14f} with error {I - T:.2e}\")\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn_ = 40 * 2 ** arange(6)\nerr = zeros(size(n_))\nprint(\"     n     error\")\nfor k, n in enumerate(n_):\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    err[k] = I - T\n    print(f\"{n:6d}   {err[k]:8.3e} \")\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nloglog(n_, abs(err), \"-o\", label=\"results\")\nloglog(n_, 3e-3 * (n_ / n_[0]) ** (-2), \"--\", label=\"2nd order\")\ngca().invert_xaxis()\nxlabel(\"$n$\")\nylabel(\"error\")\nlegend()\ntitle(\"Convergence of trapezoidal integration\");","type":"content","url":"/integration#trapezoid-formula","position":3},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Extrapolation"},"type":"lvl2","url":"/integration#extrapolation","position":4},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Extrapolation"},"content":"If evaluations of f are computationally expensive, we want to get as much accuracy as possible from them by using a higher-order formula. There are many routes for doing so; for example, we could integrate a not-a-knot cubic spline interpolant. However, splines are difficult to compute by hand, and as a result different methods were developed before computers came on the scene.\n\nKnowing the structure of the error allows the use of extrapolation to improve accuracy. Suppose a quantity A_0 is approximated by an algorithm A(h) with an\nerror expansion  A_0 = A(h) + c_1 h + c_2 h^2 + c_3 h^3 + \\cdots.\n\nCrucially, it is not necessary to know the values of the error constants c_k, merely that they exist and are independent of h.\n\nUsing I for the exact integral of f, the trapezoid formula has  I = T_f(n) + c_2 h^2 + c_4 h^{4} + \\cdots,\n\nas proved by the Euler–Maclaurin formula \n\n(5.6.9). The error constants depend on f and can’t be evaluated in general, but we know that this expansion holds. For convenience we recast the error expansion in terms of n=O(h^{-1}):  I = T_f(n) + c_2 n^{-2} + c_4 n^{-4} + \\cdots.\n\nWe now make the simple observation that  I = T_f(2n) + \\tfrac{1}{4} c_2 n^{-2} + \\tfrac{1}{16} c_4 n^{-4} + \\cdots.\n\nIt follows that if we combine \n\n(5.6.12) and \n\n(5.6.13) correctly, we can cancel out the second-order term in the error. Specifically, define  S_f(2n) = \\frac{1}{3} \\Bigl[ 4 T_f(2n) - T_f(n) \\Bigr].\n\n(We associate 2n rather than n with the extrapolated result because of the total number of nodes needed.) Then  I = S_f(2n) + O(n^{-4}) =  b_4 n^{-4} + b_6 n^{-6} + \\cdots.\n\nThe formula \n\n(5.6.14) is called Simpson’s formula, or Simpson’s rule. A different presentation and derivation are considered in \n\nExercise 4.\n\nEquation \n\n(5.6.15) is another particular error expansion in the form \n\n(5.6.10), so we can extrapolate again! The details change only a little. Considering that  I = S_f(4n) = \\tfrac{1}{16} b_4 n^{-4} + \\tfrac{1}{64} b_6 n^{-6} + \\cdots,\n\nthe proper combination this time is  R_f(4n) = \\frac{1}{15} \\Bigl[ 16 S_f(4n) - S_f(2n) \\Bigr],\n\nwhich is sixth-order accurate. Clearly the process can be repeated to get eighth-order accuracy and beyond. Doing so goes by the name of Romberg integration, which we will not present in full generality.","type":"content","url":"/integration#extrapolation","position":5},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Node doubling"},"type":"lvl2","url":"/integration#node-doubling","position":6},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Node doubling"},"content":"Note in \n\n(5.6.17) that R_f(4n) depends on S_f(2n) and S_f(4n), which in turn depend on T_f(n), T_f(2n), and T_f(4n).  There is a useful benefit realized by doubling of the nodes in each application of the trapezoid formula. As shown in \n\nFigure 5.6.2, when doubling n, only about half of the nodes are new ones, and previously computed function values at the other nodes can be reused.\n\n\n\nFigure 5.6.2:Dividing the node spacing by half introduces new nodes only at midpoints, allowing the function values at existing nodes to be reused for extrapolation.\n\nSpecifically, we have\\begin{split}\n  T_f(2m) & = \\frac{1}{2m} \\left[  \\frac{1}{2} f(a) + \\frac{1}{2} f(b) + \\sum_{i=1}^{2m-1}  f\\Bigl( a + \\frac{i}{2m} \\Bigr) \\right]\\\\[1mm]\n  & = \\frac{1}{2m} \\left[  \\frac{1}{2} f(a) + \\frac{1}{2} f(b)\\right] + \\frac{1}{2m} \\sum_{k=1}^{m-1}  f\\Bigl( a+\\frac{2k}{2m} \\Bigr)  + \\frac{1}{2m} \\sum_{k=1}^{m} f\\Bigl( a+\\frac{2k-1}{2m} \\Bigr) \\\\[1mm]\n  &=  \\frac{1}{2m} \\left[  \\frac{1}{2} f(a) + \\frac{1}{2} f(b) + \\sum_{k=1}^{m-1} f\\Bigl( a+\\frac{k}{m} \\Bigr) \\right] + \\frac{1}{2m} \\sum_{k=1}^{m}  f\\Bigl( a+\\frac{2k-1}{2m} \\Bigr)  \\\\[1mm]\n  &= \\frac{1}{2} T_f(m) + \\frac{1}{2m} \\sum_{k=1}^{m-1}  f\\left(t_{2k-1} \\right),\n\\end{split}\n\nwhere the nodes referenced in the last line are relative to n=2m. Hence in passing from n=m to n=2m, new integrand evaluations are needed only at the odd-numbered nodes of the finer grid.\n\nIntegration by extrapolation\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = x -> x^2 * exp(-2 * x);\na = 0;\nb = 2;\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14)\n@show Q;\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       # the coarsest formula\nn = N;\nh = (b - a) / n;\nt = h * (0:n);\ny = f.(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = [h * (sum(y[2:n]) + y[1] / 2 + y[n+1] / 2)]\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nWe can repeat the same code to double n again.\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = [(4T[i+1] - T[i]) / 3 for i in 1:2]\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16S[2] - S[1]) / 15\n\nWe can make a triangular table of the errors:\n\nThe value nothing equals nothing except nothing.\n\nerr = [T .- Q [nothing; S .- Q] [nothing; nothing; R - Q]]\npretty_table(err, header=[\"order 2\", \"order 4\", \"order 6\"])\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.\n\nIntegration by extrapolation\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = @(x) x.^2 .* exp(-2 * x);\na = 0;  b = 2;\nformat long\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14)\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       % the coarsest formula\nn = N;  h = (b - a) / n;\nt = h * (0:n)';\ny = f(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = h * ( sum(y(2:n)) + y(1) / 2 + y(n+1) / 2 )\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(2) = T(1) / 2 + h * sum( f(t(2:2:n)) )\n\nWe can repeat the same code to double n again.\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(3) = T(2) / 2 + h * sum( f(t(2:2:n)) )\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = (4 * T(2:3) - T(1:2)) / 3\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16*S(2) - S(1)) / 15\n\nWe can make a triangular table of the errors:\n\nerr2 = T(:) - I;\nerr4 = [NaN; S(:) - I];\nerr6 = [NaN; NaN; R - I];\nformat short e\ndisp(table(err2, err4, err6, variablenames=[\"order 2\", \"order 4\", \"order 6\"]))\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.\n\nIntegration by extrapolation\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = lambda x: x**2 * exp(-2 * x)\na = 0\nb = 2\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20    # the coarsest formula\nn = N\nh = (b - a) / n\nt = h * arange(n + 1)\ny = f(t)\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = zeros(3)\nT[0] = h * (sum(y[1:-1]) + y[0] / 2 + y[-1] / 2)\nprint(f\"error (2nd order): {I - T[0]:.2e}\")\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[1] = T[0] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:2])\n\nAs expected for a second-order estimate, the error went down by a factor of about 4. We can repeat the same code to double n again.\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[2] = T[1] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:3])\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = array([(4 * T[i + 1] - T[i]) / 3 for i in range(2)])\nprint(\"error (4th order):\", I - S)\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16 * S[1] - S[0]) / 15\nprint(\"error (6th order):\", I - R)\n\nWe can make a triangular table of the errors:\n\nerr = nan * ones((3, 3))\nerr[0, :] = I - T\nerr[1, 1:] = I - S\nerr[2, 2] = I - R\nresults = PrettyTable([\"2nd order\", \"4th order\", \"6th order\"])\nresults.add_rows(err.T)\nprint(results)\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/integration#node-doubling","position":7},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Exercises"},"type":"lvl2","url":"/integration#exercises","position":8},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Exercises"},"content":"must be kept as #1\n\n⌨ For each integral below, use \n\nFunction 5.6.1 to estimate the integral for n=10\\cdot 2^k nodes for k=1,2,\\ldots,10. Make a log-log plot of the errors and confirm or refute second-order accuracy. (These integrals were taken from \n\nBailey et al. (2005).)\n\n(a) \\displaystyle \\int_0^1 x\\log(1+x)\\, dx = \\frac{1}{4}\n\n(b) \\displaystyle \\int_0^1 x^2 \\tan^{-1}x\\, dx = \\frac{\\pi-2+2\\log 2}{12}\n\n(c) \\displaystyle \\int_0^{\\pi/2}e^x \\cos x\\, dx = \\frac{e^{\\pi/2}-1}{2}\n\n(d) \\displaystyle \\int_0^1 \\sqrt{x} \\log(x) \\, dx = -\\frac{4}{9} (Note: Although the integrand has the limiting value zero as x\\to 0, it cannot be evaluated naively at x=0. You can start the integral at x=\\macheps instead.)\n\n(e) \\displaystyle \\int_0^1 \\sqrt{1-x^2}\\,\\, dx = \\frac{\\pi}{4}\n\n✍ The Euler–Maclaurin error expansion \n\n(5.6.9) for the trapezoid formula implies that if we could cancel out the term due to f'(b)-f'(a), we would obtain fourth-order accuracy. We should not assume that f' is available, but approximating it with finite differences can achieve the same goal. Suppose the forward difference formula \n\n(5.4.13) is used for f'(a), and its reflected backward difference is used for f'(b). Show that the resulting modified trapezoid formula is\n\n:label: gregory\nG_f(h) = T_f(h) - \\frac{h}{24} \\left[ 3\\Bigl( f(t_n)+f(t_0) \\Bigr) -4\\Bigr( f(t_{n-1}) + f(t_1) \\Bigr) + \\Bigl( f(t_{n-2})+f(t_2)   \\Bigr) \\right],\n```which is known as a **Gregory integration formula**.\n\n⌨ Repeat each integral in Exercise 1 above using Gregory integration  instead of the trapezoid formula. Compare the observed errors to fourth-order convergence.\n\n✍  Simpson’s formula can be derived without appealing to extrapolation.\n\n(a) Show thatp(x) = \\beta + \\frac{\\gamma-\\alpha}{2h}\\, x + \\frac{\\alpha-2\\beta+\\gamma}{2h^2}\\, x^2\n\ninterpolates the three points (-h,\\alpha), (0,\\beta), and (h,\\gamma).\n\n(b) Find  \\int_{-h}^h p(s)\\, ds,\n\nwhere p is the quadratic polynomial from part (a), in terms of h, α, β, and γ.\n\n(c) Assume equally spaced nodes in the form t_i=a+ih, for h=(b-a)/n and i=0,\\ldots,n. Suppose f is approximated by p(x) over the subinterval [t_{i-1},t_{i+1}]. Apply the result from part (b) to find  \\int_{t_{i-1}}^{t_{i+1}} f(x)\\, dx \\approx \\frac{h}{3} \\bigl[ f(t_{i-1}) + 4f(t_i) + f(t_{i+1}) \\bigr].\n\n(Use the change of variable s=x-t_i.)\n\n(d) Now also assume that n=2m for an integer m. Derive Simpson’s formula,\n\n:label: simpson\n\\begin{split}\n\\int_a^b f(x), dx \\approx  \\frac{h}{3}\\bigl[ &f(t_0) + 4f(t_1) + 2f(t_2) + 4f(t_3) + 2f(t_4) + \\cdots\\\n&+ 2f(t_{n-2}) + 4f(t_{n-1}) + f(t_n) \\bigr].\n\\end{split}\n```\n\n✍ Show that the Simpson formula  is equivalent to S_f(n/2), given the definition of S_f in \n\n(5.6.14).\n\n⌨ For each integral in Exercise 1 above, apply the Simpson formula  and compare the errors to fourth-order convergence.\n\n⌨ For n=10,20,30,\\ldots,200, compute the trapezoidal approximation to\\int_{0}^1 \\frac{1}{2.01+\\sin (6\\pi x)-\\cos(2\\pi x)} \\,d x \\approx 0.9300357672424684.\n\nMake two separate plots of the absolute error as a function of n, one using a log-log scale and the other using log-linear. The graphs suggest that the error asymptotically behaves as C \\alpha^n for some C>0 and some 0<\\alpha<1. How does this result relate to \n\n(5.6.9)?\n\n⌨ For each integral in Exercise 1 above, extrapolate the trapezoidal results two levels to get sixth-order accurate results, and compute the errors for each value.\n\n✍ Find a formula like \n\n(5.6.17) that extrapolates two values of R_f to obtain an eighth-order accurate one.\n\nSome texts distinguish between a formula for a single subinterval [t_{k-1},t_k] and a composite formula that adds them up over the whole interval to get \n\n(5.6.5).","type":"content","url":"/integration#exercises","position":9},{"hierarchy":{"lvl1":"The interpolation problem"},"type":"lvl1","url":"/interpolation","position":0},{"hierarchy":{"lvl1":"The interpolation problem"},"content":"Interpolation problem\n\nGiven n+1 distinct points (t_0,y_0), (t_1,y_1),\\ldots,(t_n,y_n), with t_0<t_1<\\ldots <t_n called nodes, the interpolation problem is to find a function p(x), called the interpolant, such that p(t_k)=y_k for k=0,\\dots,n.\n\nIn this chapter, we use t_k for the nodes and x to denote the continuous independent variable.\n\nAttention\n\nThe interpolation nodes are numbered from 0 to n. This is convenient for our mathematical statements, but less so in a language such as Julia in which vector indices start with 1. Our approach is that indices in a computer code have the same meaning as those identically named in the mathematical formulas, and therefore must be incremented by one whenever used in an indexing context.","type":"content","url":"/interpolation","position":1},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Polynomials"},"type":"lvl2","url":"/interpolation#polynomials","position":2},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Polynomials"},"content":"Polynomials are the obvious first candidate to serve as interpolating functions. They are easy to work with, and in \n\nPolynomial interpolation we saw that a linear system of equations can be used to determine the coefficients of a polynomial that passes through every member of a set of given points in the plane. However, it’s not hard to find examples for which polynomial interpolation leads to unusable results.\n\nTrouble in polynomial interpolation\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5\nt = range(-1, 1, length=n + 1)\ny = @. t^2 + t + 0.05 * sin(20 * t)\n\nscatter(t, y, label=\"data\", leg=:top)\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\np = Polynomials.fit(t, y, n)     # interpolating polynomial\nplot!(p, -1, 1, label=\"interpolant\")\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = range(-1, 1, length=n + 1)\ny = @. t^2 + t + 0.05 * sin(20 * t)\n\nscatter(t, y, label=\"data\", leg=:top)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = Polynomials.fit(t, y, n)\nx = range(-1, 1, length=1000)    # use a lot of points\nplot!(x, p.(x), label=\"interpolant\")\n\nSurely there must be functions that are more intuitively representative of those points!\n\nTrouble in polynomial interpolation\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5;\nt = linspace(-1,1,n+1)';  \ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t,y)\n\nThe polynomial interpolant, as computed using polyfit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on\nfplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north')\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on, fplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north')\n\nSurely there must be functions that are more intuitively representative of those points!\n\nTrouble in polynomial interpolation\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\np = poly1d(polyfit(t, y, n))  # interpolating polynomial\ntt = linspace(-1, 1, 400)\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = poly1d(polyfit(t, y, n))\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nSurely there must be functions that are more intuitively representative of those points!\n\nInterpolation by a polynomial at equally spaced nodes is ill-conditioned as the degree of the polynomial grows.\n\nIn Chapter 9 we explore the large oscillations in the last figure of \n\nDemo 5.1.1; it turns out that one must abandon either equally spaced nodes or n\\to\\infty for polynomials. In the rest of this chapter we will keep n fairly small and let the nodes be unrestricted.","type":"content","url":"/interpolation#polynomials","position":3},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Piecewise polynomials"},"type":"lvl2","url":"/interpolation#piecewise-polynomials","position":4},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Piecewise polynomials"},"content":"In order to keep polynomial degrees small while interpolating large data sets, we will choose interpolants from the piecewise polynomials. Specifically, the interpolant p must be a polynomial on each subinterval [t_{k-1},t_k] for k=1,\\ldots,n.\n\nSome examples of piecewise polynomials for the nodes  t_0=-2, t_1=0, t_2=1, and t_3=4 are p_1(x)=x+1, p_2(x)=\\operatorname{sign}(x), p_3(x)=|x-1|^{3}, and p_4(x)=(\\max\\{0,x\\})^{4}. Note that p_{1}, p_{2}, and p_4 would also be piecewise polynomial on the node set \\{t_0,t_1,t_3\\}, but p_3 would not.\n\nUsually we designate in advance a maximum degree d for each polynomial piece of p(x). An important property of the piecewise polynomials of degree d is that they form a vector space: that is, any linear combination of piecewise polynomials of degree d is another piecewise polynomial of degree d. If p and q share the same node set, then the combination is piecewise polynomial on that node set.\n\nPiecewise polynomial interpolation\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 12\nt = range(-1, 1, length=n + 1)\ny = @. t^2 + t + 0.5 * sin(20 * t)\n\nscatter(t, y, label=\"data\", leg=:top)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\np = FNC.plinterp(t, y)\nplot!(p, -1, 1, label=\"piecewise linear\")\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\np = Spline1D(t, y)\nplot!(x -> p(x), -1, 1, label=\"piecewise cubic\")\n\nPiecewise polynomial interpolation\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using interp1 from MATLAB.\n\nx = linspace(-1, 1, 400)';\nhold on, plot(x, interp1(t, y, x))\ntitle('Piecewise linear interpolant')\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\ncla\nscatter(t, y)\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic interpolant')\n\nPiecewise polynomial interpolation\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nclf\nn = 12\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.5 * sin(20 * t)\nfig, ax = subplots()\nscatter(t, y, label=\"data\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\ntt = linspace(-1, 1, 400)\np = interp1d(t, y, kind=\"linear\")\nax.plot(tt, p(tt), label=\"piecewise linear\")\nax.legend()\nfig\n\nWe may prefer a smoother interpolant that is piecewise cubic:\n\nscatter(t, y, label=\"data\")\np = interp1d(t, y, kind=\"cubic\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cubic spline\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\nlegend()\n\nWe will consider piecewise linear interpolation in more detail in \n\nPiecewise linear interpolation, and we look at piecewise cubic interpolation in \n\nCubic splines.","type":"content","url":"/interpolation#piecewise-polynomials","position":5},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Conditioning of interpolation"},"type":"lvl2","url":"/interpolation#conditioning-of-interpolation","position":6},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Conditioning of interpolation"},"content":"In the interpolation problem we are given the values (t_k,y_k) for k=0,\\ldots,n. Let us consider the nodes t_k of the problem to be fixed, and let a=t_0, b=t_n. Then the data for the interpolation problem consists of a vector \\mathbf{y}, and the result of the problem is a function on [a,b].\n\nLet \\mathcal{I} be a prescription for producing the interpolant from a data vector.  That is, \\mathcal{I}(\\mathbf{y})=p, where p(t_k)=y_k for all k. The interpolation methods we will consider are all linear, in the sense that\\cI(\\alpha\\mathbf{y} + \\beta\\mathbf{z}) = \\alpha \\cI(\\mathbf{y}) + \\beta \\cI(\\mathbf{z})\n\nfor all vectors \\mathbf{y},\\mathbf{z} and scalars \\alpha,\\beta.\n\nLinearity greatly simplifies the analysis of interpolation. To begin with, for any data vector \\mathbf{y} we have the standard expression \\mathbf{y}=\\sum y_k \\mathbf{e}_k, where as always \\mathbf{e}_k is a column of an identity matrix. Hence by linearity,\\cI( \\mathbf{y} ) = \\cI \\left( \\sum_{k=0}^n y_k \\mathbf{e}_k  \\right) = \\sum_{k=0}^n y_k \\cI( \\mathbf{e}_k ).\n\nThe functions appearing within the sum above have particular significance.\n\nCardinal function\n\nA cardinal function \\phi_k for a node set t_0,\\ldots,t_n is the function that interpolates the value (t_k,1) and (t_j,0) for all j\\neq k.\n\nFor any set of n+1 nodes, there are n+1 cardinal functions \\phi_0,\\ldots,\\phi_n, each singling out a different interpolation node in the set. We finish \n\n(5.1.2) by writing\\cI( \\mathbf{y} ) = \\sum_{k=0}^n y_k \\phi_k.\n\nIn the following result we use the function infinity-norm or max-norm defined by\\| f\\|_{\\infty} = \\max_{x \\in [a,b]} |f(x)|.\n\nConditioning of interpolation\n\nSuppose that \\cI is a linear interpolation method on nodes t_0,\\ldots,t_n. Then with respect to the infinity norm, the absolute condition number of \\cI satisfies\\max_{0\\le k \\le n}\\, \\bigl\\| \\phi_k \\bigr\\|_\\infty \\le \\kappa(\\mathbf{y}) \\le  \\sum_{k=0}^n  \\, \\bigl\\| \\phi_k \\bigr\\|_\\infty,\n\nwhere the \\phi_k are cardinal interpolating functions.\n\nSuppose the data vector is perturbed from \\mathbf{y} to \\mathbf{y}+ \\mathbf{d}. Then  \\cI(\\mathbf{y} + \\mathbf{d}) - \\cI(\\mathbf{y}) = \\cI(\\mathbf{d}) = \\sum_{k=0}^n d_k \\phi_k.\n\nHence\\frac{\\bigl\\|\\cI(\\mathbf{y} + \\mathbf{d}) - \\cI(\\mathbf{y}) \\bigr\\|_{\\infty}}{\\| \\mathbf{d} \\|_{\\infty}} =\n\\left\\|\\, \\sum_{k=0}^{n} \\frac{d_k}{\\|\\mathbf{d} \\|_{\\infty}} \\phi_k \\,  \\right\\|_{\\infty}.\n\nThe absolute condition number maximizes this quantity over all \\mathbf{d}. Suppose j is such that \\|\\phi_j\\|_\\infty is maximal. Then let \\mathbf{d}=\\mathbf{e}_j and the first inequality in \n\n(5.1.5) follows. The other inequality follows from the triangle inequality:\\left\\| \\, \\sum_{k=0}^{n} \\frac{d_k}{\\|\\mathbf{d} \\|_{\\infty}} \\phi_k \\,  \\right\\|_{\\infty} \\le \\sum_{k=0}^{n} \\frac{|d_k|}{\\|\\mathbf{d} \\|_{\\infty}} \\| \\phi_k \\|_\\infty.\n\nSince |d_k|\\le \\|\\mathbf{d}\\|_\\infty for all k, this finishes \n\n(5.1.5).\n\nConditioning of interpolation\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18\nt = range(-1, stop=1, length=n + 1)\ny = [zeros(9); 1; zeros(n - 9)];  # data for 10th cardinal function\n\nscatter(t, y, label=\"data\")\n\nϕ = Spline1D(t, y)\nplot!(x -> ϕ(x), -1, 1, label=\"spline\",\n    xlabel=L\"x\", ylabel=L\"\\phi(x)\",\n    title=\"Piecewise cubic cardinal function\")\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nscatter(t, y, label=\"data\")\n\nϕ = Polynomials.fit(t, y, n)\nplot!(x -> ϕ(x), -1, 1, label=\"polynomial\",\n    xlabel=L\"x\", ylabel=L\"\\phi(x)\", legend=:top,\n    title=\"Polynomial cardinal function\")\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.\n\nConditioning of interpolation\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18;\nt = linspace(-1, 1, n+1)';\ny = [zeros(9, 1); 1; zeros(n - 9, 1)];    % 10th cardinal function\nclf, scatter(t, y)\nhold on\nx = linspace(-1, 1, 400)';\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic cardinal function') \nxlabel('x'), ylabel('p(x)')\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nclf, scatter(t, y)\nc = polyfit(t, y, n);\nhold on, plot(x, polyval(c, x))\ntitle('Polynomial cardinal function')\nxlabel('x'), ylabel('p(x)')\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.\n\nConditioning of interpolation\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nclf\nn = 18\nt = linspace(-1, 1, n + 1)\ny = zeros(n + 1)\ny[9] = 1.0\np = interp1d(t, y, kind=\"cubic\")\n\nscatter(t, y, label=\"data\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cardinal function\")\ntitle(\"Cubic spline cardinal function\")\nlegend()\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\np = poly1d(polyfit(t, y, n))\nscatter(t, y, label=\"data\")\nplot(tt, p(tt), label=\"cardinal function\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\ntitle(\"Polynomial cardinal function\")\nlegend()\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/interpolation#conditioning-of-interpolation","position":7},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Exercises"},"type":"lvl2","url":"/interpolation#exercises","position":8},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Exercises"},"content":"⌨ Create data by enteringt = -2:4;  y = tanh.(t);\n\n(a) Use fit to construct and plot the polynomial interpolant of the data, superimposed on a scatter plot of the data.\n\n(b) Use Spline1D to construct and plot a piecewise cubic interpolant of the data, superimposed on a scatter plot of the data.\n\n⌨ The following table gives the life expectancy in the U.S. by year of birth.\n\n1980\n\n1985\n\n1990\n\n1995\n\n2000\n\n2005\n\n2010\n\n73.7\n\n74.7\n\n75.4\n\n75.8\n\n77.0\n\n77.8\n\n78.7\n\n(a) Defining “year since 1980” as the independent variable, use fit to construct and plot the polynomial interpolant of the data.\n\n(b) Use Spline1D to construct and plot a piecewise cubic interpolant of the data.\n\n(c) Use both methods to estimate the life expectancy for a person born in 2007. Which value is more believable?\n\n⌨ The following two vectors define a flying saucer shape.x = [ 0,0.51,0.96,1.06,1.29,1.55,1.73,2.13,2.61,\n      2.19,1.76,1.56,1.25,1.04,0.58,0 ]\ny = [ 0,0.16,0.16,0.43,0.62,0.48,0.19,0.18,0,\n      -0.12,-0.12,-0.29,-0.30,-0.15,-0.16,0 ]\n\nWe can regard both x and y as functions of a parameter s, with the points being values given at s=0,1,\\ldots,15.\n\n(a) Use Spline1D once on each coordinate as functions of s, and make a picture of the flying saucer.\n\n(b) One drawback of the result in part (a) is the noticeable corner at the left side, which corresponds to s=0 from above and s=15 from below. There is a periodic variation on cubic spline interpolation that you can invoke by adding the keyword periodic=true to the Spline1D call. Use this to re-plot the flying saucer.\n\n✍ Defineq(s) = a\\frac{s(s-1)}{2} - b (s-1)(s+1) + c \\frac{s(s+1)}{2}.\n\n(a) Show that q is a polynomial interpolant of the points (-1,a), (0,b), (1,c).\n\n(b) Find a change of variable s=Ax+B so that the values s=-1,0,1 correspond to x=x_0-h,x_0,x_0+h.\n\n(c) Find a quadratic polynomial interpolant \\tilde{q}(x) for the points (x_0-h,a), (x_0,b), (x_0+h,c).\n\n✍ (continuation) Use the result of the previous exercise and \n\nTheorem 5.1.1 to derive bounds on the condition number of quadratic polynomial interpolation at the nodes x_0-h, x_0, x_0+h.\n\nTo be precise, we are using \\mathbf{e}_k to mean column number k+1 from an (n+1)\\times (n+1) identity matrix, since in linear algebra we start indexing at 1.","type":"content","url":"/interpolation#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-4","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The algorithmic possibilities for piecewise linear and cubic spline approximation are explored in a different way in Van Loan \n\nVan Loan (2000).  In that source, a binary search is used to find the interval for evaluating the piecewise polynomial interpolant.\n\nFurther details regarding the derivation of the cubic spline equations, with an emphasis on minimizing memory usage, may be found in a number of sources, e.g., Burden and Faires \n\nBurden & Faires (2001), Cheney and Kincaid \n\nCheney & Kincaid (2012), and Atkinson and Han \n\nAtkinson & Han (2004). Comprehensive theoretical results can be found in de Boor \n\nde Boor (1978).\n\nOn a historical note, Carl de Boor was elected to several National Academies of Science (USA, Poland, and Germany, e.g.) and was awarded the (USA) National Medal of Science in 2003 for his work on splines.  Splines continue to be important for computer-aided design and computer graphics, among other applications.\n\nAn excellent and pragmatic introduction to finite-difference methods is by Fornberg \n\nFornberg (1998). Numerical integration is a large topic unto itself; one longer introduction to it is by Davis and Rabinowitz \n\nDavis & Rabinowitz (2014).","type":"content","url":"/next-4","position":1},{"hierarchy":{"lvl1":"Piecewise interpolation"},"type":"lvl1","url":"/overview-4","position":0},{"hierarchy":{"lvl1":"Piecewise interpolation"},"content":"You must feel the Force around you. Here, between you...me...the tree...the rock...everywhere!\n\nYoda, The Empire Strikes Back\n\nIn many scientific problems the solution is a function. Accordingly, our next task is to represent functions numerically. This task is more difficult and complicated than the one we faced in representing real numbers. With numbers it’s intuitively clear how one real value can stand for a small interval around it. But designating representatives for sets of functions is less straightforward—in fact, it’s one of the core topics in computing. The process of converting functions into numerical representations of finite length is known as discretization.\n\nOnce we have selected a method of discretization, we can define numerical analogs of our two favorite operations on functions, differentiation and integration. These are linear operations, so the most natural numerical analogs are linear operations too. As we will see in many of the chapters following this one, a lot of numerical computing boils down to converting calculus to algebra, with discretization as the link between them.","type":"content","url":"/overview-4","position":1},{"hierarchy":{"lvl1":"Piecewise linear interpolation"},"type":"lvl1","url":"/pwlin","position":0},{"hierarchy":{"lvl1":"Piecewise linear interpolation"},"content":"Piecewise linear interpolation is simply a game of connect-the-dots. That is, the data points are joined pairwise by line segments.\n\nPiecewise linear interpolant\n\nGiven nodes t_0 < t_1 < \\cdots < t_n, the piecewise linear interpolant p(x) is given byp(x) = y_k + \\frac{y_{k+1}-y_k}{t_{k+1}-t_k}(x-t_k) \\quad \\text{ for } x\\in[t_k,t_{k+1}].\n\nIt should be clear from \n\n(5.2.1) that on each interval [t_k,t_{k+1}], p(x) is a linear function passing through both (t_k,y_k) and (t_{k+1},y_{k+1}).","type":"content","url":"/pwlin","position":1},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Hat functions"},"type":"lvl2","url":"/pwlin#hat-functions","position":2},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Hat functions"},"content":"Rather than basing an implementation on \n\n(5.2.1), we return to the idea used in \n\nDemo 2.1.1 of choosing the interpolant from among the linear combinations of a preselected finite set of functions. In the present context we use, for k=0,\\ldots,n,  H_k(x) =\n  \\begin{cases}\n    \\dfrac{x-t_{k-1}}{t_k-t_{k-1}} & \\text{if $x\\in[t_{k-1},t_k]$},\\\\[2.5ex]\n    \\dfrac{t_{k+1}-x}{t_{k+1}-t_{k}} & \\text{if $x\\in[t_{k},t_{k+1}]$},\\\\[2.5ex]\n    0 & \\text{otherwise}.\n  \\end{cases} \\qquad\n\nThe functions H_0,\\ldots,H_n are called hat functions. They depend on the node vector \\mathbf{t}, but this dependence is not usually indicated explicitly.\n\nEach hat function is globally continuous and is linear inside every interval [t_k,t_{k+1}].  Consequently, any linear combination of them will have the same property. Furthermore, any such function is expressible as a unique linear combination of hat functions, i.e.,  \\sum_{k=0}^n c_k H_k(x)\n\nfor some choice of the coefficients c_0,\\ldots,c_n. No smaller set of functions can have the same properties. We summarize these facts by calling the hat functions a basis of the set of functions that are continuous and piecewise linear relative to \\mathbf{t}.  Another point of view, familiar from abstract linear algebra, is that a basis sets up a one-to-one correspondence between the spanned function space and the more familiar space \\mathbb{R}^{n+1}, with each function being represented by its coefficients c_0,\\ldots,c_n.\n\nAn appealing characteristic of the hat function basis is that it depends only on the node locations, while the expansion coefficients in \n\n(5.2.3) depend only on the data values. This clean separation would be useful if we wanted to construct many interpolants on the same node set, and it has deeper theoretical uses as well.\n\nFunction 5.2.1 presents a simple implementation of hat functions. The inputs are a presorted vector of nodes and a value of k between 0 and n, which represent the indices of the endpoints. The return value is a function of x that can be evaluated as needed. Note that we have not formally defined values for a hat function outside of the node interval; our choice in \n\nFunction 5.2.1 is to make it zero there.\n\nhatfun\n\nHat function\n\n\"\"\"\n    hatfun(t,k)\n\nCreate a piecewise linear hat function, where `t` is a\nvector of n+1 interpolation nodes and `k` is an integer in 0:n\ngiving the index of the node where the hat function equals one.\n\"\"\"\n\nfunction hatfun(t,k)\n    n = length(t)-1\n    return function(x)\n        if k > 0 && t[k] ≤ x ≤ t[k+1]\n            return (x-t[k])/(t[k+1]-t[k])\n        elseif k < n && t[k+1] ≤ x ≤ t[k+2]\n            return (t[k+2]-x)/(t[k+2]-t[k+1])\n        else\n            return 0\n        end\n    end\nend\n\nHat function\n\nfunction H = hatfun(x,t,k)\r\n% HATFUN   Hat function/piecewise linear basis function.\r\n% Input: \r\n%   x      evaluation points (vector)\r\n%   t      interpolation nodes (vector, length n+1)\r\n%   k      node index (integer, in 0,...,n)\r\n% Output:\r\n%   H      values of the kth hat function\r\n\r\nn = length(t)-1;\r\nk = k+1;  % adjust for starting with index=1\r\n\r\n% Fictitious nodes to deal with first, last funcs.\r\nt = [ 2*t(1)-t(2); t(:); 2*t(n+1)-t(n) ];\r\nk = k+1;  % adjust index for the fictitious first node\r\n\r\nH1 = (x-t(k-1))/(t(k)-t(k-1));   % upward slope\r\nH2 = (t(k+1)-x)/(t(k+1)-t(k));   % downward slope\r\n\r\nH = min(H1,H2);\r\nH = max(0,H);\n\nHat function\n\ndef hatfun(x, t, k):\n    \"\"\"\n    hatfun(x,t,k)\n\n    Evaluate a piecewise linear \"hat\" function at `x`, where `t` is a vector of\n    n+1 interpolation nodes and `k` is an integer in 0:n giving the index of the node\n    where the hat function equals one.\n    \"\"\"\n    n = len(t) - 1\n\n    # Return correct node given mathematical index k, including fictitious choices.\n    def node(k):\n        if k < 0:\n            return 2 * t[0] - t[1]\n        elif k > n:\n            return 2 * t[n] - t[n - 1]\n        else:\n            return t[k]\n\n    H1 = (x - node(k - 1)) / (node(k) - node(k - 1))  # upward slope\n    H2 = (node(k + 1) - x) / (node(k + 1) - node(k))  # downward slope\n    H = np.minimum(H1, H2)\n    return np.maximum(0, H)\n\nA look at hat functions\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1]\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nUse annotate! to add text to a plot.\n\nplt = plot(layout=(4, 1), legend=:top,\n    xlabel=L\"x\", ylims=[-0.1, 1.1], ytick=[])\nfor k in 0:3\n    Hₖ = FNC.hatfun(t, k)\n    plot!(Hₖ, 0, 1, subplot=k + 1)\n    scatter!(t, Hₖ.(t), m=3, subplot=k + 1)\n    annotate!(t[k+1], 0.25, text(latexstring(\"H_$k\"), 10), subplot=k + 1)\nend\nplt\n\nA look at hat functions\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1];\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nclf\nfor k = 0:3\n    subplot(4, 1, k+1)\n    Hk = @(x) hatfun(x, t, k);\n    fplot(Hk, [0, 1])\n    hold on\n    scatter(t, Hk(t))\n    text(t(k+1), 0.6, sprintf(\"H_%d\", k))\nend\n\nA look at hat functions\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nx = linspace(0, 1, 300)\nfor k in range(6):\n    plot(x, FNC.hatfun(x, t, k))\nxlabel(\"$x$\")\nylabel(\"$H_k(x)$\")\ntitle(\"Hat functions\")","type":"content","url":"/pwlin#hat-functions","position":3},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Cardinality conditions"},"type":"lvl2","url":"/pwlin#cardinality-conditions","position":4},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Cardinality conditions"},"content":"A handy property of the hat functions is that they are cardinal functions for piecewise linear interpolation, since they satisfy the cardinality conditionsH_k(t_i) =\n\\begin{cases}\n  1 &\\text{if $i=k$,}\\\\\n  0 & \\text{otherwise.}\n\\end{cases}\n\nAll candidate piecewise linear (PL) functions can be expressed as a linear combination such as \n\n(5.2.3) for some coefficients c_0,\\ldots,c_n. But because of the cardinality conditions and the necessity for p(x) to interpolate the data values in \\mathbf{y}, expressing the interpolant using the hat functions is trivial:  p(x) = \\sum_{k=0}^n y_k H_k(x).\n\nThe resulting algorithmic simplicity is reflected in \n\nFunction 5.2.2. Take note that the output of \n\nFunction 5.2.2 is itself a function, meant to be called with a single argument representing a value of x. Our mathematical viewpoint is that the result of an interpolation process is a function, and our codes reflect this.\n\nplinterp\n\nPiecewise linear interpolation\n\n\"\"\"\n    plinterp(t,y)\n\nConstruct a piecewise linear interpolating function for data values in\n`y` given at nodes in `t`.\n\"\"\"\nfunction plinterp(t,y)\n    n = length(t)-1\n    H = [ hatfun(t,k) for k in 0:n ]\n    return x -> sum( y[k+1]*H[k+1](x) for k in 0:n )\nend\n\nPiecewise linear interpolation\n\nfunction p = plinterp(t,y)\r\n% PLINTERP   Piecewise linear interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   p     piecewise linear interpolant (function)\r\n\r\nn = length(t)-1;\r\np = @evaluate;\r\n\r\n    % This function evaluates p when called.\r\n    function f = evaluate(x)\r\n        f = 0;\r\n        for k = 0:n\r\n            f = f + y(k+1)*hatfun(x,t,k);\r\n        end\r\n    end\r\n\r\nend\n\nPiecewise linear interpolation\n\ndef plinterp(t, y):\n    \"\"\"\n    plinterp(t,y)\n\n    Create a piecewise linear interpolating function for data values in `y` given at nodes\n    in `t`.\n    \"\"\"\n    n = len(t) - 1\n    return lambda x: np.sum(y[k] * hatfun(x, t, k) for k in range(n + 1))\n\nUsing piecewise linear interpolation\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = x -> exp(sin(7 * x))\n\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]    # nodes\ny = f.(t)                             # function values\n\nscatter!(t, y, label=\"values at nodes\")\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"PL interpolation\")\n\nUsing piecewise linear interpolation\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = @(x) exp(sin(7 * x));\nclf\nfplot(f, [0, 1], displayname=\"function\")\nxlabel(\"x\");  ylabel(\"y\")\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % function values\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = plinterp(t, y);\nhold on\nfplot(p, [0, 1], displayname=\"interpolant\")\nscatter(t, y, displayname=\"values at nodes\")\ntitle(\"PL interpolation\")\nlegend()\n\nUsing piecewise linear interpolation\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 400)\nfig, ax = subplots()\nplot(x, f(x), label=\"function\")\nxlabel(\"$x$\")\nylabel(\"$f(x)$\")\n\nFirst we sample the function to create the data.\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # function values\n\nax.plot(t, y, \"o\", label=\"nodes\")\nax.legend()\nfig\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nax.plot(x, p(x), label=\"interpolant\")\nax.legend()\nfig","type":"content","url":"/pwlin#cardinality-conditions","position":5},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Conditioning and convergence"},"type":"lvl2","url":"/pwlin#conditioning-and-convergence","position":6},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Conditioning and convergence"},"content":"The condition number bounds from \n\nTheorem 5.1.1 are very simple for piecewise linear interpolation because the interpolant of the data \\mathbf{e}_k is just the hat function H_k. Hence 1\\le \\kappa \\le n+1. However, there is an even simpler result.\n\nConditioning of PL interpolation\n\nThe absolute condition number of piecewise linear interpolation in the infinity norm equals 1. More specifically, if \\mathcal{I} is the piecewise linear interpolation operator, then\\| \\mathcal{I}(\\mathbf{y}+\\mathbf{z}) - \\mathcal{I}(\\mathbf{y}) \\|_\\infty = \\|\\mathbf{z}\\|_\\infty.\n\n(The norm on the left side is on functions, while the norm on the right side is on vectors.)\n\nBy linearity,\\mathcal{I}(\\mathbf{y}+\\mathbf{z}) - \\mathcal{I}(\\mathbf{y}) = \\mathcal{I}(\\mathbf{z}) = \\sum_{k=0}^n z_k H_k(x).\n\nCall this piecewise linear function p(x). Consider a maximum element of \\mathbf{z}, i.e., choose i such that |z_i|=\\|\\mathbf{z}\\|_\\infty. Then |p(t_i)|=\\|\\mathbf{z}\\|_\\infty. Hence \\|p\\|_\\infty\\ge \\|\\mathbf{z}\\|_\\infty. Now consider|p(x)| = \\left|\\sum_{k=0}^n z_k H_k(x)\\right| \\le \\sum_{k=0}^n |z_k| H_k(x) \\le \\|\\mathbf{z}\\|_\\infty \\sum_{k=0}^n H_k(x) = \\|\\mathbf{z}\\|_\\infty.\n\nYou are asked to prove the final step above in \n\nExercise 4. We conclude that  \\|p\\|_\\infty\\le \\|\\mathbf{z}\\|_\\infty, so that \\|p\\|_\\infty = \\|\\mathbf{z}\\|_\\infty, which completes the proof.\n\nNow suppose that f is a “nice” function on an interval [a,b] containing all of the nodes. We can sample values of f to get data, i.e., y_k=f(t_k) for all k, then perform piecewise linear interpolation of the data to get a different function, the interpolant p. How close is p to the original f?\n\nTo make a simple statement, we will consider only the case of equally spaced nodes covering the interval. It turns out that piecewise linear interpolation converges at second order in the spacing of the nodes.\n\nConvergence of PL interpolation\n\nSuppose that f(x) has a continuous second derivative in [a,b] (often expressed as f\\in C^2([a,b])). Let p_n(x) be the piecewise linear interpolant of \\bigl(t_i,f(t_i)\\bigr) for i=0,\\ldots,n, where t_i=a+i h and h=(b-a)/n. Then\\bigl\\| f - p_n \\bigr\\|_\\infty = \\max_{x \\in [a,b]}\n|f(x)-p(x)| \\le M h^2,\n\nwhere M = \\bigl\\| f'' \\bigr\\|_\\infty.\n\nFor an outline of a proof, see \n\nExercise 5.\n\nWe normally don’t have access to f'', so the importance of \n\nTheorem 5.2.2 is that the error in the interpolant is O(h^2) as h\\to 0.\n\nAlgebraic convergence\n\nIf an approximation has error that is O(h^m) as h\\to 0 for an integer m and a discretization size parameter h, then we say the approximation has algebraic convergence. If the error is not also O(h^{m+1}), then m is the order of accuracy.\n\nThus, \n\nTheorem 5.2.2 states that piecewise linear interpolation is second-order accurate. For instance, if we increase the number of equally spaced nodes by a factor of 10, the piecewise linear interpolant becomes about 100 times more accurate. Note also that if y \\approx C h^m, then\\log y \\approx m (\\log h) + \\log C.\n\nHence a log-log graph of error versus h should be approximately a straight line of slope m.\n\nConvergence of piecewise linear interpolation\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = x -> exp(sin(7 * x))\nx = range(0, 1, length=10001)  # sample the difference at many points\nn = @. round(Int, 10^(1:0.25:3.5))\nmaxerr = zeros(0)\nfor n in n\n    t = (0:n) / n    # interpolation nodes\n    p = FNC.plinterp(t, f.(t))\n    err = @. f(x) - p(x)\n    push!(maxerr, norm(err, Inf))\nend\n\ndata = (n=n[1:4:end], err=maxerr[1:4:end])\npretty_table(data, header=[\"n\", \"max-norm error\"])\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nh = @. 1 / n\norder2 = @. 10 * (h / h[1])^2\n\nplot(h, maxerr, m=:o, label=\"error\")\nplot!(h, order2, l=:dash, label=L\"O(h^2)\", xflip=true,\n    xaxis=(:log10, L\"h\"), yaxis=(:log10, L\"|| f-p\\, ||_\\infty\"),\n    title=\"Convergence of PL interpolation\")\n\nConvergence of piecewise linear interpolation\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = @(x) exp(sin(7 * x));\nx = linspace(0, 1, 10001)';    % sample the difference at many points\nn = round(10.^(1:0.25:3.5))';\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i)) / n(i);       % interpolation nodes\n    p = plinterp(t, f(t));\n    maxerr(i) = norm(f(x) - p(x), Inf);\nend\ndisp(table(n(1:4:end), maxerr(1:4:end), variableNames=[\"n\", \"inf-norm error\"]))\n\nAs predicted, a factor of 10 in n produces a factor of 100 reduction in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder2 = 0.5 * maxerr(end) * (n / n(end)) .^ (-2);\nhold on\nloglog(n, order2, \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"|| f-p ||_{\\infty}\")\ntitle(\"Convergence of PL interpolation\")\nlegend()\n\nConvergence of piecewise linear interpolation\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 10000)  # sample the difference at many points\nN = 2 ** arange(3, 11)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.plinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\norder2 = 0.1 * (N / N[0]) ** (-2)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order2, \"--\", label=\"2nd order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-p\\|_\\infty$\")\nlegend()","type":"content","url":"/pwlin#conditioning-and-convergence","position":7},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/pwlin#exercises","position":8},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Exercises"},"content":"⌨ For each given function and interval, perform piecewise linear interpolation using \n\nFunction 5.2.2 for n+1 equispaced nodes with n=10,20,40,80,160,320. For each n, estimate the errorE(n) = \\| f-p \\|_\\infty = \\max_x | f(x) - p(x) |\n\nby evaluating the function and interpolant at 1600 points in the interval. Make a log-log plot of E as a function of n and add the line E=Cn^{-2} for a constant C of your choosing.\n\n(a) \\cos(\\pi x^2) on [0,4]\n\n(b) \\log(x) on [1,20]\n\n(c) \\sin\\left(\\frac{1}{x}\\right) on \\left[\\frac{1}{2},7\\right]\n\n✍ For this problem, let H(x) be the hat function that passes through the three points (-1,0), (0,1), and (1,0).\n\n(a) Write out a piecewise definition of H in the style of \n\n(5.2.2).\n\n(b) Define the function Q by Q(x) = \\int_{x-1}^x H(t)\\, dt. Find a piecewise formula for Q(x). (Hint: Perform the integration separately for the cases -1\\le x \\le 0, 0\\le x \\le 1, etc.)\n\n(c) Make a sketch of Q(x) for -2\\le x \\le 2.\n\n(d) Show that Q is continuous. Are Q' and Q''?\n\n✍ Before electronic calculators, the function \\ln(x) was often computed using piecewise linear interpolation with a table of values. If you were using such a table at the nodes 3.1,3.2,\\ldots,3.9,4, what is an upper bound on the error in the result?\n\n✍ Show that for any node distribution and any x\\in[t_0,t_n],\\sum_{k=0}^n H_k(x) = 1.\n\n(Hint: The simplest way is to apply \n\n(5.2.5).) This is called the partition of unity property.\n\n✍ Here we consider a proof of \n\nTheorem 5.2.2 using the mean value theorems from elementary calculus: If f is continuously differentiable in (a,b), then there exist points s and t in (a,b) such that\\int_a^b f(z) \\, dz = (b-a)f(s) \\qquad \\text{and} \\qquad f'(t) = \\frac{f(b)-f(a)}{b-a}.\n\nFor the following, suppose x \\in (t_k,t_{k+1}).\n\n(a) Show that for some s \\in (t_k,t_{k+1}),f(x) = y_k + (x-t_k)f'(s).\n\n(b) Show that for some other values u and v in (t_k,t_{k+1}),f'(s) -  \\frac{y_{k+1}-y_k}{t_{k+1}-t_k} = (s-u) f''(v).\n\n(c) Use \n\n(5.2.1) to finish the proof of the theorem.","type":"content","url":"/pwlin#exercises","position":9},{"hierarchy":{"lvl1":"Cubic splines"},"type":"lvl1","url":"/splines","position":0},{"hierarchy":{"lvl1":"Cubic splines"},"content":"A piecewise linear interpolant is continuous but has discontinuities in its derivative. We often desire a smoother interpolant, i.e., one that has some continuous derivatives. By far the most popular choice is piecewise cubic.\n\nCubic spline\n\nA cubic spline is a piecewise cubic function that has two continuous derivatives everywhere.\n\nWe use S(x) to denote the cubic spline interpolant. As before, suppose that distinct nodes t_0 < t_1 < \\cdots < t_n (not necessarily equally spaced) and data y_0,\\ldots,y_n are given. For any k=1,\\ldots,n, the spline S(x) on the interval [t_{k-1},t_k] is by definition a cubic polynomial S_k(x), which we express as S_k(x) = a_k + b_k(x-t_{k-1}) + c_k(x-t_{k-1})^2 + d_k(x-t_{k-1})^3, \\qquad k=1,\\ldots,n,\n\nwhere a_k,b_k,c_k,d_k are values to be determined. Overall there are 4n such undetermined coefficients.","type":"content","url":"/splines","position":1},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Smoothness conditions"},"type":"lvl2","url":"/splines#smoothness-conditions","position":2},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Smoothness conditions"},"content":"We are able to ensure that S has at least two continuous derivatives everywhere by means of the following constraints.\n\n1. Interpolation by S_k at both of its endpoints.\n\nAlgebraically we require S_k(t_{k-1})=y_{k-1} and S_k(t_k)=y_k for every k=1,\\dots,n. In terms of \n\n(5.3.1), these conditions area_k = y_{k-1},    a_k + b_k  h_k + c_k h_k^2 + d_k h_k^3 = y_{k}, \\qquad k=1,\\ldots,n,\n\nwhere we have used the definitionh_k = t_{k}-t_{k-1}, \\qquad k=1,\\ldots,n.\n\nThe values of h_k are derived from the nodes. Crucially, the unknown coefficients appear only linearly in the constraint equations. So we will express the constraints using linear algebra. The left endpoint interpolation constraints \n\n(5.3.2) are, in matrix form,\\begin{bmatrix}\n  \\mathbf{I} & \\boldsymbol{0} & \\boldsymbol{0} & \\boldsymbol{0}\n\\end{bmatrix}\n\\begin{bmatrix}\n    \\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n\\end{bmatrix}\n=\n  \\begin{bmatrix}\n  y_0 \\\\ \\vdots \\\\ y_{n-1}\n\\end{bmatrix},\n\nwith \\mathbf{I} being an n\\times n identity. The right endpoint interpolation constraints, given by \n\n(5.3.3), become\\begin{bmatrix}\n  \\mathbf{I} & \\mathbf{H} & \\mathbf{H}^2 & \\mathbf{H}^3\n\\end{bmatrix}\n\\begin{bmatrix}\n  \\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n\\end{bmatrix}\n  =\n\\begin{bmatrix}\n  y_1 \\\\ \\vdots \\\\ y_{n}\n\\end{bmatrix},\n\nwhere we have defined the diagonal matrix\\mathbf{H}  =\n\\begin{bmatrix}\n  h_1 & & & \\\\ & h_2 & & \\\\ & & \\ddots & \\\\ & & & h_n\n\\end{bmatrix}.\n\nCollectively, \n\n(5.3.5) and \n\n(5.3.6) express 2n scalar constraints on the unknowns.\n\n2. Continuity of S'(x) at interior nodes.\n\nWe do not know what the slope of the interpolant should be at the nodes, but we do want the same slope whether a node is approached from the left or the right. Thus we obtain constraints at the nodes that sit between two neighboring piecewise definitions, so that S_1'(t_1)=S_2'(t_1), and so on. Altogether these areb_k + 2 c_k h_k + 3 d_k h_k^2 = b_{k+1}, \\qquad k=1,\\dots,n-1.\n\nMoving the unknowns to the left side, as a system these become\\mathbf{E}\n\\begin{bmatrix}\n  \\boldsymbol{0} & \\mathbf{J} & 2\\mathbf{H} & 3\\mathbf{H}^2\n\\end{bmatrix}\n\\begin{bmatrix}\n  \\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n  \\end{bmatrix}\n= \\boldsymbol{0},\n\nwhere now we have defined\\mathbf{J} =\n\\begin{bmatrix}\n  1  & -1 & & & \\\\ & 1 & -1 & & \\\\ & & \\ddots & \\ddots & \\\\ & & &1 & -1 \\\\ & & & & 1\n\\end{bmatrix},\n\nand \\mathbf{E} is the (n-1)\\times n matrix resulting from deleting the last row of the identity:\\mathbf{E} =\n\\begin{bmatrix}\n  1  & 0 & & & \\\\ & 1 & 0 & & \\\\ & & \\ddots & \\ddots & \\\\ & & & 1&  0\n\\end{bmatrix}.\n\nLeft-multiplying by \\mathbf{E} deletes the last row of any matrix or vector. Hence \n\n(5.3.9) represents n-1 constraints on the unknowns. (Remember, there are only n-1 interior nodes.)\n\n3. Continuity of S''(x) at interior nodes.\n\nThese again apply only at the interior nodes t_1,\\dots,t_{n-1}, in the form S_1''(t_1)=S_2''(t_1) and so on. Using \n\n(5.3.1) once more, we obtain  2 c_k + 6 d_k h_k = 2c_{k+1}, \\qquad k=1,\\dots,n-1.\n\nIn system form (after canceling a factor of 2 from each side) we get\\mathbf{E}\n\\begin{bmatrix}\n\\boldsymbol{0} & \\boldsymbol{0} & \\mathbf{J} & 3\\mathbf{H}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n\\end{bmatrix}\n= \\boldsymbol{0}.","type":"content","url":"/splines#smoothness-conditions","position":3},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"End conditions"},"type":"lvl2","url":"/splines#end-conditions","position":4},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"End conditions"},"content":"So far the equations \n\n(5.3.5),  \n\n(5.3.6),  \n\n(5.3.9), and \n\n(5.3.13) form 2n+(n-1)+(n-1)=4n-2 linear conditions on the 4n unknowns in the piecewise definition \n\n(5.3.1). In order to obtain a square system, we must add two more constraints. If the application prescribes values for S' or S'' at the endpoints, those may be applied. Otherwise there are two major alternatives:\n\nNatural spline: \\quad S_1''(t_0)=S_n''(t_n)=0\n\nNot-a-knot spline: \\quad S_1'''(t_1)=S_2'''(t_1), \\;  S_{n-1}'''(t_{n-1})=S_n'''(t_{n-1})\n\nWhile natural splines have important theoretical properties, not-a-knot splines give better pointwise accuracy, and they are the only type we consider further.\n\nIn the not-a-knot spline, the values and first three derivatives of the cubic polynomials S_1 and S_2 agree at the node t_1. Hence they must be the same cubic polynomial! The same is true of S_{n-1} and S_n. We could use these facts to eliminate some of the undetermined coefficients from our linear system of constraints. However, rather than rework the algebra we just append two more rows to the system, expressing the conditionsd_1=d_2, \\quad  d_{n-1}=d_n.\n\nCollectively, \n\n(5.3.5),  \n\n(5.3.6),  \n\n(5.3.9),  \n\n(5.3.13), and \n\n(5.3.14) comprise a square linear system of size 4n which can be solved for the coefficients defining the piecewise cubics in \n\n(5.3.1). This is a major difference from the piecewise linear interpolant, for which there is no linear system to solve. Indeed, while it is possible to find a basis for the cubic spline interpolant analogous to the hat functions, it is not possible in closed form to construct a cardinal basis, so the solution of a linear system cannot be avoided.","type":"content","url":"/splines#end-conditions","position":5},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Implementation"},"type":"lvl2","url":"/splines#implementation","position":6},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Implementation"},"content":"spinterp\n\nCubic spline interpolation\n\n\"\"\"\n    spinterp(t,y)\n\nConstruct a cubic not-a-knot spline interpolating function for data\nvalues in `y` given at nodes in `t`.\n\"\"\"\nfunction spinterp(t,y)\n    n = length(t)-1\n    h = [ t[k+1]-t[k] for k in 1:n ]\n\n    # Preliminary definitions.\n    Z = zeros(n,n);\n    In = I(n);  E = In[1:n-1,:];\n    J = diagm(0=>ones(n),1=>-ones(n-1))\n    H = diagm(0=>h)\n\n    # Left endpoint interpolation:\n    AL = [ In Z Z Z ]\n    vL = y[1:n]\n\n    # Right endpoint interpolation:\n    AR = [ In H H^2 H^3 ];\n    vR = y[2:n+1]\n\n    # Continuity of first derivative:\n    A1 = E*[ Z J 2*H 3*H^2 ]\n    v1 = zeros(n-1)\n\n    # Continuity of second derivative:\n    A2 = E*[ Z Z J 3*H ]\n    v2 = zeros(n-1)\n\n    # Not-a-knot conditions:\n    nakL = [ zeros(1,3*n) [1 -1 zeros(1,n-2)] ]\n    nakR = [ zeros(1,3*n) [zeros(1,n-2) 1 -1] ]\n\n    # Assemble and solve the full system.\n    A = [ AL; AR; A1; A2; nakL; nakR ]\n    v = [ vL; vR; v1; v2; 0; 0 ]\n    z = A\\v\n\n    # Break the coefficients into separate vectors.\n    rows = 1:n\n    a = z[rows]\n    b = z[n.+rows];  c = z[2*n.+rows];  d = z[3*n.+rows]\n    S = [ Polynomial([a[k],b[k],c[k],d[k]]) for k in 1:n ]\n\n    # This function evaluates the spline when called with a value\n    # for x.\n    return function (x)\n        if x < t[1] || x > t[n+1]    # outside the interval\n            return NaN\n        elseif x==t[1]\n            return y[1]\n        else\n            k = findlast(x .> t)    # last node to the left of x\n            return S[k](x-t[k])\n        end\n    end\nend\n\nCubic spline interpolation\n\nfunction S = spinterp(t,y)\r\n% SPINTERP   Cubic not-a-knot spline interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   S     not-a-knot cubic spline (function)\r\n\r\nt = t(:);  y = y(:);  % ensure column vectors\r\nn = length(t)-1;\r\nh = diff(t);          % differences of all adjacent pairs\r\n\r\n% Preliminary definitions.\r\nZ = zeros(n);\r\nI = eye(n);  E = I(1:n-1,:);\r\nJ = I - diag(ones(n-1,1),1);\r\nH = diag(h);\r\n\r\n% Left endpoint interpolation:\r\nAL = [ I, Z, Z, Z ];\r\nvL = y(1:n);\r\n\r\n% Right endpoint interpolation:\r\nAR = [ I, H, H^2, H^3 ];\r\nvR = y(2:n+1);\r\n\r\n% Continuity of first derivative:\r\nA1 = E*[ Z, J, 2*H, 3*H^2 ];\r\nv1 = zeros(n-1,1);\r\n\r\n% Continuity of second derivative:\r\nA2 = E*[ Z, Z, J, 3*H ];\r\nv2 = zeros(n-1,1);\r\n\r\n% Not-a-knot conditions:\r\nnakL = [ zeros(1,3*n), [1,-1, zeros(1,n-2)] ];\r\nnakR = [ zeros(1,3*n), [zeros(1,n-2), 1,-1] ];\r\n\r\n% Assemble and solve the full system.\r\nA = [ AL; AR; A1; A2; nakL; nakR ];\r\nv = [ vL; vR; v1; v2; 0 ;0 ];\r\nz = A\\v;\r\n\r\n% Break the coefficients into separate vectors.\r\nrows = 1:n;\r\na = z(rows);\r\nb = z(n+rows);  c = z(2*n+rows);  d = z(3*n+rows);\r\nS = @evaulate;\r\n\r\n    % This function evaluates the spline when called with a value for x.\r\n    function f = evaulate(x)\r\n        f = zeros(size(x));\r\n        for k = 1:n       % iterate over the pieces\r\n            % Evalaute this piece's cubic at the points inside it.\r\n            index = (x>=t(k)) & (x<=t(k+1));   \r\n            f(index) = polyval( [d(k),c(k),b(k),a(k)], x(index)-t(k) );\r\n        end\r\n    end\r\n\r\nend\n\nCubic spline interpolation\n\ndef spinterp(t, y):\n    \"\"\"\n    spinterp(t,y)\n\n    Create a cubic not-a-knot spline interpolating function for data values in `y` given at nodes in `t`.\n    \"\"\"\n    n = len(t) - 1\n    h = [t[i + 1] - t[i] for i in range(n)]\n\n    # Preliminary definitions.\n    Z = np.zeros([n, n])\n    I = np.eye(n)\n    E = I[: n - 1, :]\n    J = np.eye(n) + np.diag(-np.ones(n - 1), 1)\n    H = np.diag(h)\n\n    # Left endpoint interpolation:\n    AL = np.hstack([I, Z, Z, Z])\n    vL = y[:-1]\n\n    # Right endpoint interpolation:\n    AR = np.hstack([I, H, H**2, H**3])\n    vR = y[1:]\n\n    # Continuity of first derivative:\n    A1 = E @ np.hstack([Z, J, 2 * H, 3 * H**2])\n    v1 = np.zeros(n - 1)\n\n    # Continuity of second derivative:\n    A2 = E @ np.hstack([Z, Z, J, 3 * H])\n    v2 = np.zeros(n - 1)\n\n    # Not-a-knot conditions:\n    nakL = np.hstack([np.zeros(3 * n), np.hstack([1, -1, np.zeros(n - 2)])])\n    nakR = np.hstack([np.zeros(3 * n), np.hstack([np.zeros(n - 2), 1, -1])])\n\n    # Assemble and solve the full system.\n    A = np.vstack([AL, AR, A1, A2, nakL, nakR])\n    v = np.hstack([vL, vR, v1, v2, 0, 0])\n    z = solve(A, v)\n\n    # Break the coefficients into separate vectors.\n    rows = np.arange(n)\n    a = z[rows]\n    b = z[n + rows]\n    c = z[2 * n + rows]\n    d = z[3 * n + rows]\n    S = [np.poly1d([d[k], c[k], b[k], a[k]]) for k in range(n)]\n\n    # This function evaluates the spline when called with a value for x.\n    def evaluate(x):\n        f = np.zeros(x.shape)\n        for k in range(n):\n            # Evaluate this piece's cubic at the points inside it.\n            index = (x >= t[k]) & (x <= t[k + 1])\n            f[index] = S[k](x[index] - t[k])\n        return f\n\n    return evaluate\n\nFunction 5.3.1 gives an implementation of cubic not-a-knot spline interpolation. For clarity it stays very close to the description given above. There are some possible shortcuts—for example, one could avoid using \\mathbf{E} and instead directly delete the last row of any matrix it left-multiplies. Observe that the linear system is assembled and solved just once, and the returned evaluation function simply uses the resulting coefficients. This allows us to make multiple calls to evaluate S without unnecessarily repeating the linear algebra.","type":"content","url":"/splines#implementation","position":7},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Conditioning and convergence"},"type":"lvl2","url":"/splines#conditioning-and-convergence","position":8},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Conditioning and convergence"},"content":"Cubic splines\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nf = x -> exp(sin(7 * x))\n\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]  # nodes\ny = f.(t)                           # values at nodes\n\nscatter!(t, y, label=\"values at nodes\")\n\nS = FNC.spinterp(t, y)\n\nplot!(S, 0, 1, label=\"spline\")\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000) / 1e4              # sample the difference at many points\nn = @. round(Int, 2^(3:0.5:7))  # numbers of nodes\nerr = zeros(0)\nfor n in n\n    t = (0:n) / n\n    S = FNC.spinterp(t, f.(t))\n    dif = @. f(x) - S(x)\n    push!(err, norm(dif, Inf))\nend\n\npretty_table((; n, err), header=[\"n\", \"error\"])\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = @. (n / n[1])^(-4)\n\nplot(n, [err order4], m=[:o :none], l=[:solid :dash],\n    label=[\"error\" \"4th order\"],\n    xaxis=(:log10, \"n\"), yaxis=(:log10, L\"|| f-S\\,||_\\infty\"),\n    title=\"Convergence of spline interpolation\")\n\nCubic splines\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nclf\nf = @(x) exp(sin(7 * x));\nfplot(f, [0, 1], displayname=\"function\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % values at nodes\nhold on, scatter(t, y, displayname=\"values at nodes\")\n\nS = spinterp(t, y);\nfplot(S, [0, 1], displayname=\"spline\")\n\nxlabel(\"x\");  ylabel(\"y\")\nlegend()\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000)' / 1e4;              % sample the difference at many points\nn = round(2 .^ (3:0.5:7))';        % numbers of nodes\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i))' / n(i);\n    S = spinterp(t, f(t));\n    err = f(x) - S(x);\n    maxerr(i) = norm(err, Inf);\nend\ndisp(table(n(1:2:end), maxerr(1:2:end), variableNames=[\"n\", \"inf-norm error\"]))\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder4 = 0.5 * maxerr(end) * (n / n(end)) .^ (-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nxlabel(\"n\");  ylabel(\"|| f-S ||_{\\infty}\")\ntitle(\"Convergence of spline interpolation\")\n\nCubic splines\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nf = lambda x: exp(sin(7 * x))\n\nx = linspace(0, 1, 500)\nfig, ax = subplots()\nax.plot(x, f(x), label=\"function\")\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # values at nodes\n\nxlabel(\"$x$\")\nylabel(\"$y$\")\nax.scatter(t, y, label=\"nodes\")\n\nS = FNC.spinterp(t, y)\nax.plot(x, S(x), label=\"spline\")\nax.legend()\nfig\n\nNow we look at the convergence rate as the number of nodes increases.\n\nN = floor(2 ** linspace(3, 8, 17)).astype(int)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.spinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = (N / N[0]) ** (-4)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order4, \"--\", label=\"4th order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-S\\|_\\infty$\")\nlegend()\n\nBesides having more smoothness than a piecewise linear interpolant, the not-a-knot cubic spline improves the order of accuracy to 4.\n\nSuppose that f(x) has four continuous derivatives in [a,b] (i.e., f\\in C^4[a,b]). Let S_n(x) be the not-a-knot cubic spline interpolant of \\bigl(t_i,f(t_i)\\bigr) for i=0,\\ldots,n, where t_i=a+i h and h=(b-a)/n. Then for all sufficiently small h, there is a constant C>0 such that\\bigl\\| f - S_n \\bigr\\|_\\infty \\le Ch^4.\n\nThe conditioning of spline interpolation is much more complicated than for the piecewise linear case. First, the fact that the coefficients of all the cubics must be solved for simultaneously implies that each data value in \\mathbf{y} has an influence on S over the entire interval. Second, S can take on values larger in magnitude than all of the values in \\mathbf{y} (see \n\nExercise 5). The details may be found in more advanced texts.","type":"content","url":"/splines#conditioning-and-convergence","position":9},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Exercises"},"type":"lvl2","url":"/splines#exercises","position":10},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Exercises"},"content":"✍ In each case, write out the entries of the matrix and right-hand side of the linear system that determines the coefficients for the cubic not-a-knot spline interpolant of the given function and node vector.\n\n(a) \\cos  (\\pi^2 x^2 ), \\: \\mathbf{t} = [-1,1,4]\n\n(b) \\cos (\\pi^2 x^2), \\: \\mathbf{t} = [0,\\tfrac{1}{2},\\tfrac{3}{4},1]\n\n(c) \\ln(x), \\:  \\mathbf{t} = [1,2,3]\n\n(d) \\sin(x^2),\\:  \\mathbf{t} = [-1,0,1]\n\n⌨ (continuation) For each case in the preceding problem, use Julia to solve the linear system you wrote down. Then plot the resulting cubic spline over the interval between the second and third nodes.\n\n⌨ For each given function, interval, and value of n, define n+1 evenly spaced nodes. Then use \n\nFunction 5.3.1 to plot the cubic spline interpolant using those nodes, together with the original function over the given interval.\n\n(a) \\cos(\\pi x^2) on [0,4], n=18\n\n(b) \\ln(x) on [1,20], n=4\n\n(c) \\sin\\left(\\frac{1}{x}\\right) on \\left[\\frac{1}{2},7\\right], n=9\n\n⌨ For each given function and interval, perform piecewise linear interpolation using \n\nFunction 5.3.1 for n+1 equispaced nodes with n=10,20,40,80,160,320. For each n, estimate the errorE(n) = \\| f-p \\|_\\infty = \\max_x | f(x) - p(x) |\n\nby evaluating the function and interpolant at 1600 points in the interval. Make a log-log plot of E as a function of n and add the line E=Cn^{-4} for a constant C of your choosing.\n\n(a) \\cos(\\pi x^2) on [0,4]\n\n(b) \\ln(x) on [1,20]\n\n(c) \\sin\\left(\\frac{1}{x}\\right) on \\left[\\frac{1}{2},7\\right]\n\n⌨  Although the cardinal cubic splines are intractable in closed form, they can be found numerically. Each cardinal spline interpolates the data from one column of an identity matrix. Define the nodes \\mathbf{t} = \\bigl[0,\\, 0.075,\\, 0.25,\\, 0.55,\\, 1]. Plot over [0,1] the five cardinal functions for this node set over the interval [0,1].\n\n✍ Suppose you were to define a piecewise quadratic spline that interpolates n+1 given values and has a continuous first derivative. Follow the derivation of this section to express all of the interpolation and continuity conditions. How many additional conditions are required to make a square system for the coefficients?\n\n(a) ✍ If y_0=y_n, another possibility for cubic spline end conditions is to make S(x) a periodic function. This implies that S' and S'' are also periodic. Write out the two new algebraic equations for these constraints in terms of the piecewise coefficients.\n\n(b) ⌨ Modify \n\nFunction 5.3.1 to compute a periodic spline interpolant. Test by making a plot of the interpolant for f(x) =\\exp(\\sin(3x)) over the interval [0,2\\pi/3] with equally spaced nodes and n=8.\n\nThis explains the name of the not-a-knot spline—for splines, “knots” are the points at which  different piecewise definitions meet.","type":"content","url":"/splines#exercises","position":11},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta"},"type":"lvl1","url":"/adaptive-rk","position":0},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta"},"content":"The derivation and analysis of methods for initial-value problems usually assumes a fixed step size h. While the error behavior O(h^p) is guaranteed by \n\nTheorem 6.2.1 as h\\rightarrow 0, this bound comes with an unknowable constant, and it is not very useful as a guide to the numerical value of the error at any particular value of h. Furthermore, as we saw in \n\nAdaptive integration for numerical integration, in many problems a fixed step size is far from the most efficient strategy.\n\nIn response we will employ the basic strategy of \n\nAdaptive integration: estimate the error and adapt the step size in order to reach an accuracy goal. Unlike the integration problem, though, the “integrand” of an IVP is dependent on the solution itself, so the details differ greatly.","type":"content","url":"/adaptive-rk","position":1},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Step size prediction"},"type":"lvl2","url":"/adaptive-rk#step-size-prediction","position":2},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Step size prediction"},"content":"Suppose that, starting from a given value u_i and using a step size h, we run one step of two different RK methods simultaneously: one method with order p, producing u_{i+1}, and the other method with order p+1, producing \\tilde{u}_{i+1}. In most circumstances, we can expect that \\tilde{\\mathbf{u}}_{i+1} is a much better approximation to the solution than \\mathbf{u}_{i+1} is. So it seems reasonable to useE_i(h)=|\\tilde{\\mathbf{u}}_{i+1} - \\mathbf{u}_{i+1}|\n\nas an estimate of the actual local error made by the pth-order method. For a vector IVP, we would use a norm rather than an absolute value. If the goal is to keep global error less than some predetermined value, we could decide to accept the new solution value if $E_i$ small enough, and otherwise reject it.[^extrap]\n\n[^extrap]: Even though the estimate $E_i$ is meant to go with the *less* accurate proposed value $\\mathbf{u}_{i+1}$, it's hard to resist the temptation to keep the more accurate value instead, and this is common in practice. \n\nNow we ask: looking back, what step size should we have taken to meet an error target of size ε? Let’s speculate, given the behavior of local truncation error as h\\rightarrow 0, that E_i(h)\\approx C h^{p+1} for an unknown constant C. If we had used a step size q h for some q>0, then trivially, we would expectE_i(qh)\\approx C q^{p+1}h^{p+1}.\n\nOur best guess for q would therefore be to set E_i(qh)\\approx \\epsilon, or  q \\approx \\left(\\frac{\\epsilon}{E_i}\\right)^{1/(p+1)}.\n\nPerhaps, though, we should aim to control the contribution to global error, which is closer to E_i(qh)/(q h). Then we end up with  q \\le \\left(\\frac{\\epsilon}{E_i}\\right)^{1/p}.\n\nExperts have different recommendations about whether to use \n\n(6.5.3) or \n\n(6.5.4). Even though \n\n(6.5.4) appears to be more in keeping with our assumptions about global errors, modern practice seems to favor \n\n(6.5.3).\n\nWe now have an outline of an algorithm.\n\nAdaptive step size for an IVP\n\nGiven a solution estimate u_i at t=t_i, and a step size h, do the following:\n\nProduce estimates {u}_{i+1} and \\tilde{u}_{i+1}, and estimate the error.\n\nIf the error is small enough, adopt \\tilde{u}_{i+1} as the solution value at t=t_i+h, then increment i.\n\nReplace h by q h, with q given by \n\n(6.5.3) or \n\n(6.5.4).\n\nRepeat until t=b.\n\nMany details remain unspecified at this point, but we first address step 1.","type":"content","url":"/adaptive-rk#step-size-prediction","position":3},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Embedded formulas"},"type":"lvl2","url":"/adaptive-rk#embedded-formulas","position":4},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Embedded formulas"},"content":"Suppose, for example, we choose to use a  pair of second- and third-order RK methods to get the \\mathbf{u}_{i+1} and \\tilde{\\mathbf{u}}_{i+1} needed in \n\nAlgorithm 6.5.1. Then we seem to need at least 2+3=5 evaluations of f(t,y) for each attempted time step. This is more than double the computational work needed by the second-order method without adaptivity.\n\nFortunately, the marginal cost of adaptivity can be substantially reduced by using embedded Runge–Kutta formulas. Embedded RK formulas are a pair of RK methods whose stages share the same internal f evaluations, combining them differently in order to get estimates of two different orders of accuracy.\n\nA good example of an embedded method is the Bogacki–Shampine (BS23) formula, given by the table\\begin{array}{r|cccc}\n0                  & \\rule{0pt}{2.75ex} &                    &                    &                    \\\\\n\\frac{1}{2}        & \\frac{1}{2}        & \\rule{0pt}{2.75ex} &                    &                    \\\\\n\\frac{3}{4}        & 0                  & \\frac{3}{4}        & \\rule{0pt}{2.75ex} &                    \\\\\n1                 & \\frac{2}{9}        & \\frac{1}{3}        & \\frac{4}{9}        & \\rule{0pt}{2.75ex} \\\\[2pt] \\hline\n\\rule{0pt}{2.75ex} & \\frac{2}{9}        & \\frac{1}{3}        & \\frac{4}{9}        & 0                  \\\\[2pt] \\hline\n\\rule{0pt}{2.75ex} & \\frac{7}{24}       & \\frac{1}{4}        & \\frac{1}{3}        & \\frac{1}{8}\n\\end{array}\n\nThe top part of the table describes four stages in the usual RK fashion. The last two rows describe how to construct a third-order estimate \\tilde{\\mathbf{u}}_{i+1} and a second-order estimate \\mathbf{u}_{i+1} by taking different combinations of those stages.","type":"content","url":"/adaptive-rk#embedded-formulas","position":5},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Implementation"},"type":"lvl2","url":"/adaptive-rk#implementation","position":6},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Implementation"},"content":"Our implementation of an embedded second/third-order (RK23) code is given in \n\nFunction 6.5.2.\n\nrk23\n\nAdaptive IVP solver based on embedded RK formulas\n\n\"\"\"\n    rk23(ivp,tol)\n\nApply an adaptive embedded RK formula pair to solve given IVP with\nestimated error `tol`. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk23(ivp,tol)\n    # Initialize for the first time step.\n    a,b = ivp.tspan\n    t = [a]\n    u = [float(ivp.u0)];   i = 1;\n    h = 0.5*tol^(1/3)\n    s₁ = ivp.f(ivp.u0,ivp.p,a)\n\n    # Time stepping.\n    while t[i] < b\n        # Detect underflow of the step size.\n        if t[i]+h == t[i]\n            @warn \"Stepsize too small near t=$(t[i])\"\n            break  # quit time stepping loop\n        end\n\n        # New RK stages.\n        s₂ = ivp.f( u[i]+(h/2)*s₁,   ivp.p, t[i]+h/2   )\n        s₃ = ivp.f( u[i]+(3h/4)*s₂, ivp.p, t[i]+3h/4 )\n        unew3 = u[i] + h*(2s₁  + 3s₂ + 4s₃)/9   # 3rd order solution\n        s₄ = ivp.f( unew3, ivp.p, t[i]+h )\n        err = h*(-5s₁/72 + s₂/12 + s₃/9 - s₄/8)  # 2nd/3rd difference\n        E = norm(err,Inf)                         # error estimate\n        maxerr = tol*(1 + norm(u[i],Inf))     # relative/absolute blend\n\n        # Accept the proposed step?\n        if E < maxerr     # yes\n            push!(t,t[i]+h)\n            push!(u,unew3)\n            i += 1\n            s₁ = s₄       # use FSAL property\n        end\n\n        # Adjust step size.\n        q = 0.8*(maxerr/E)^(1/3)   # conservative optimal step factor\n        q = min(q,4)               # limit stepsize growth\n        h = min(q*h,b-t[i])        # don't step past the end\n    end\n    return t,u\nend\n\nAbout the code\n\nThe check t[i]+h == t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\nAdaptive IVP solver based on embedded RK formulas\n\nfunction [t, u] = rk23(ivp, a, b, tol)\r\n% RK23   Adaptive IVP solver based on embedded RK formulas.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   tol     global error target (positive scalar)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Initialize for the first time step.\r\nt = a;\r\nu(:, 1) = u0(:);  i = 1;\r\nh = 0.5 * tol^(1/3);\r\ns1 = du_dt(t(1), u(:, 1));\r\n\r\n% Time stepping.\r\nwhile t(i) < b\r\n    % Detect underflow of the step size.\r\n    if t(i) + h == t(i)\r\n        warning('Stepsize too small near t=%.6g.',t(i))\r\n        break  % quit time stepping loop\r\n    end\r\n    \r\n    % New RK stages.\r\n    s2 = du_dt(t(i) + h/2,   u(:, i) + (h/2)   * s1, p);\r\n    s3 = du_dt(t(i) + 3*h/4, u(:, i) + (3*h/4) * s2, p);\r\n    unew2 = u(:, i) + h * (2*s1 + 3*s2 + 4*s3) / 9;    % 2rd order solution\r\n    s4 = du_dt(t(i) + h, unew2, p );\r\n    err = h * (-5*s1/72 + s2/12 + s3/9 - s4/8);        % 2nd/3rd order difference\r\n    E = norm(err, Inf);                                % error estimate\r\n    maxerr = tol * (1 + norm(u(:, i), Inf));           % relative/absolute blend\r\n    \r\n    % Accept the proposed step? \r\n    if E < maxerr     % yes \r\n        t(i+1) = t(i) + h;\r\n        u(:, i+1) = unew2;\r\n        i = i+1;\r\n        s1 = s4;      % use FSAL property\r\n    end\r\n    \r\n    % Adjust step size. \r\n    q = 0.8 * (maxerr/E)^(1/3);       % conservative optimal step factor\r\n    q = min(q, 4);                    % limit stepsize growth\r\n    h = min(q*h, b - t(i));           % don't step past the end\r\nend\n\nAbout the code\n\nThe check t(i) + h == t(i)on line 24 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 36, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 47--49 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 43 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s4 as s1 for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\nAdaptive IVP solver based on embedded RK formulas\n\ndef euler(dudt, tspan, u0, n):\n    \"\"\"\n    euler(dudt,tspan,u0,n)\n\n    Apply Euler's method to solve the IVP u'=`dudt`(u,t) over the interval `tspan` with\n    u(`tspan[1]`)=`u0`, using `n` subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * dudt(t[i], u[i])\n\n    return t, u.T\n\nAbout the code\n\nThe check t[i]+h==t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\nAdaptive step size\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nf(u, p, t) = exp(t - u * sin(u))\nivp = ODEProblem(f, 0, (0.0, 5.0))\nt, u = FNC.rk23(ivp, 1e-5)\n\nplot(t, u, m=2,\n    xlabel=L\"t\", ylabel=L\"u(t)\", title=\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nΔt = diff(t)\nplot(t[1:end-1], Δt, title=\"Adaptive step sizes\",\n    xaxis=(L\"t\", (0, 5)), yaxis=(:log10, \"step size\"))\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprintln(\"minimum step size = $(minimum(Δt))\")\n\nOn the other hand, the average step size that was actually taken was\n\nprintln(\"average step size = $(sum(Δt)/(length(t)-1))\")\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nAdaptive step size\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) exp(t - u * sin(u));\nivp.InitialValue = 0;\na = 0;  b = 5;\n\n[t, u] = rk23(ivp, a, b, 1e-5);\nclf, plot(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle(\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nDelta_t = diff(t);\nsemilogy(t(1:end-1), Delta_t) \nxlabel(\"t\");  ylabel(\"step size\")\ntitle(\"Adaptive step sizes\")\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nfprintf(\"minimum step size = %.2e\", min(Delta_t))\n\nOn the other hand, the average step size that was actually taken was\n\nfprintf(\"average step size = %.2e\", mean(Delta_t))\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nAdaptive step size\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nf = lambda t, u: exp(t - u * sin(u))\nt, u = FNC.rk23(f, [0.0, 5.0], [0.0], 1e-5)\nscatter(t, u[0, :])\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\ndt = [t[i + 1] - t[i] for i in range(t.size - 1)]\nsemilogy(t[:-1], dt)\nxlabel(\"$t$\"), ylabel(\"time step\")\ntitle(\"Adaptive step sizes\")\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprint(f\"min step size was {min(dt):.2e}\")\n\nOn the other hand, the average step size that was actually taken was\n\nprint(f\"mean step size was {mean(dt):.2e}\")\n\nWe took fewer steps by a factor of 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\n\n\n\n\n\n\nOften the adaptively chosen steps clearly correspond to identifiable features of the solution. However, there are so-called stiff problems in which the time steps seem unreasonably small in relation to the observable behavior of the solution. These problems benefit from a particular type of solver that is considered in \n\nImplementation of multistep methods.","type":"content","url":"/adaptive-rk#implementation","position":7},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Exercises"},"type":"lvl2","url":"/adaptive-rk#exercises","position":8},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Exercises"},"content":"⌨ Using \n\nFunction 6.5.2 with an error tolerance of \n\n10-8, solve y'' +(1+y')^3 y = 0 over  0 \\le t \\le 4 \\pi with the indicated initial conditions. Plot y(t) and y'(t) as functions of t and separately plot the time step size as a function of t.\n\n(a) y(0) = 0.1, \\quad y'(0) = 0\n\n(b) y(0) = 0.5, \\quad y'(0) = 0\n\n(c) y(0) = 0.75, \\quad y'(0) = 0\n\n(d) y(0) = 0.95, \\quad y'(0) = 0\n\n⌨ Solve the FitzHugh–Nagumo system from \n\nExercise 4.3.6 for I=0.05740 using \n\nFunction 6.5.2 with error tolerance \n\n10-2, \n\n10-3, and \n\n10-4. (This illustrates that the error tolerance is a target, not a guarantee!)\n\n✍ Derive Equation \n\n(6.5.4) using the stated assumption about controlling global rather than local error.\n\n⌨ Solve the problem u'=100u^2-u^3, u(0)=0.0002, 0\\le t \\le 100, and make plots that show both the solution and the time steps taken. The solution makes a quick transition between two nearly constant states. Does the step size selection behave the same in both states?","type":"content","url":"/adaptive-rk#exercises","position":9},{"hierarchy":{"lvl1":"Basics of IVPs"},"type":"lvl1","url":"/basics","position":0},{"hierarchy":{"lvl1":"Basics of IVPs"},"content":"Initial-value problem (scalar)\n\nA scalar first-order initial-value problem (IVP) is\\begin{split}\n   u'(t) &= f(t,u(t)), \\qquad a \\le t \\le b,  \\\\\n  u(a) &=u_0.\n\\end{split}\n\nWe call t the independent variable and u the dependent variable. If u'=f(t,u)=g(t)+u h(t), the differential equation is linear; otherwise, it is nonlinear.\n\nA solution of an initial-value problem is a function u(t) that makes both u'(t)=f\\bigl(t,u(t)\\bigr) and u(a)=u_0 true equations.\n\nWhen t is meant to be time, sometimes we write \\dot{u} (read “u-dot”) instead of u'.\n\nSuppose u(t) is the size of a population at time t. We idealize by allowing u to take any real (not just integer) value. If we assume a constant per capita birth rate (births per unit population per unit time), then\\frac{d u}{d t} = k u, \\qquad u(0)=u_0\n\nfor some k>0. The solution of this linear equation is u(t)=e^{kt}u_0, which is exponential growth.\n\nA more realistic model would cap the growth due to finite resources. Suppose the death rate is proportional to the size of the population, indicating competition. Then  \\frac{d u}{d t} = ku - ru^2, \\qquad u(0)=u_0.\n\nThis is the logistic equation. Although crude, it is still useful in population models.  The solution relevant for population models has the form  u(t) = \\frac{k/r}{ 1 + \\left( \\frac{k}{r u_0} - 1 \\right) e^{-k t} }.\n\nFor k,r,u_0>0, the solution smoothly varies from the initial population u_0 to a finite population, equal to k/r, that has been limited by competition.\n\nLinear problems can be solved in terms of integrals. Defining the integrating factor \\rho(t) = \\exp\\bigl[\\int -h(t)\\, dt \\bigr], the solution is derived from  \\rho(t) u(t) = u_0 + \\int_a^t \\rho(s) g(s) \\, ds.\n\nIn many cases, however, the necessary integrals cannot be done in closed form. Some nonlinear ODEs, such as separable equations, may also be solvable with a short formula, perhaps with difficult integrations. Most often, though, there is no analytic formula available for the solution.\n\nAn ODE may have higher derivatives of the unknown solution present. For example, a second-order ordinary differential equation is often given in the form u''(t)=f\\bigl(t,u,u'\\bigr). A second-order IVP requires two conditions at the initial time in order to specify a solution completely. As we will see in \n\nIVP systems, we are always able to reformulate higher-order IVPs in a first-order form, so we will deal with first-order problems exclusively.","type":"content","url":"/basics","position":1},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Numerical solutions"},"type":"lvl2","url":"/basics#numerical-solutions","position":2},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Numerical solutions"},"content":"Solving an IVP\n\nThe DifferentialEquations package offers solvers for IVPs. Let’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nBecause many practical problems come with parameters that are fixed within an instance but varied from one instance to another, the syntax for IVPs includes a input argument p that stays fixed throughout the solution. Here we don’t want to use that argument, but it must be in the definition for the solver to work.\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf(u, p, t) = sin((t + u)^2)     # defines du/dt, must include p argument\nu₀ = -1.0                       # initial value\ntspan = (0.0, 4.0)               # t interval\n\nWith the data above we define an IVP problem object and then solve it. Here we tell the solver to use the Tsit5 method, which is a good first choice for most problems.\n\nivp = ODEProblem(f, u₀, tspan)\nsol = solve(ivp, Tsit5());\n\nThe resulting solution object can be shown using plot.\n\nplot(sol, label=\"solution\", legend=:bottom,\n    xlabel=\"t\", ylabel=L\"u(t)\", title=L\"u'=\\sin((t+u)^2)\")\n\nThe solution also acts like any callable function that can be evaluated at different values of t.\n\n@show sol(1.0);\n\nUnder the hood, the solution object holds some information about how the values and plot are produced:\n\n[sol.t sol.u]\n\nThe solver initially finds approximate values of the solution (second column above) at some automatically chosen times (first column above). To compute the solution at other times, the object performs an interpolation on those values. This chapter is about how the discrete t and u values are computed. For now, just note how we can extract them from the solution object.\n\nscatter!(sol.t, sol.u, label=\"discrete values\")\n\nSolving an IVP\n\nLet’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1. To create an initial-value problem for u(t), you must create an ode with a function that computes u' and an initial condition for u. Then you create a solution by calling solve with a time interval.\n\nMost real ODE problems contain parameters that are constant during the solution but that can change from one problem instance to the next. Accordingly, we define the ODE function below to accept a third argument, p, which is a vector of parameters. We always include this argument for consistency, even when there are no parameters.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialTime = 0;\nivp.InitialValue = -1;\nsol = solve(ivp, 0, 4);\n\nThe resulting solution object has fields Time and Solution that contain the approximate values of the solution at automatically chosen times in the interval you provided.\n\nclf\nplot(sol.Time, sol.Solution, '-o')\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle(\"Solution of an IVP\")\n\nYou might want to know the solution at particular times other than the ones selected by the solver. That requires an interpolation, which is done by solutionFcn.\n\nu = solutionFcn(ivp, 0, 10);\nu(0:5)\n\nSolving an IVP\n\nLet’s use solve_ivp from scipy.integrate to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = [-1.0]\n\nNote above that even though this is a problem for a scalar function u(t), we had to set the initial condition as a “one-dimensional vector.”\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, u0)\n\nThe resulting solution object has fields t and y that contain the values of the independent and dependent variables, respectively; those field names are the same regardless of what we use in our own codes.\n\nprint(\"t shape:\", sol.t.shape)\nprint(\"u shape:\", sol.y.shape)\nplot(sol.t, sol.y[0, :], \"-o\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution of $u' = sin((t+u)^2)$\")\n\nYou can see above that the solution was not computed at enough points to make a smooth graph. There is a way to request output at times of your choosing.\n\nsol = solve_ivp(f, tspan, u0, t_eval=linspace(0, 4, 200))\nplot(sol.t, sol.y[0, :], \"-\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution of $u' = sin((t+u)^2)$\")\n\nAnother option is to enable interpolation to evaluate the solution anywhere after the fact:\n\nsol = solve_ivp(f, tspan, u0, dense_output=True)\nfor t in linspace(0, 4, 6):\n    print(f\"u({t:.2f}) = {sol.sol(t)[0]:.4f}\")","type":"content","url":"/basics#numerical-solutions","position":3},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Existence and uniqueness"},"type":"lvl2","url":"/basics#existence-and-uniqueness","position":4},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Existence and uniqueness"},"content":"There are simple IVPs that do not have solutions at all possible times.\n\nFinite-time singularity\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nf(u, p, t) = (t + u)^2\n\nivp = ODEProblem(f, 1.0, (0.0, 1.0))\nsol = solve(ivp, Tsit5());\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nplot(sol, label=\"\",\n    xlabel=L\"t\", yaxis=(:log10, L\"u(t)\"), title=\"Finite-time blowup\")\n\nFinite-time singularity\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialTime = 0;\nivp.InitialValue = 1;\nsol = solve(ivp, 0, 1);\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nclf\nsemilogy(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle(\"Finite-time blowup\")\n\nFinite-time singularity\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nIt’s a good idea to check sol.success after calling solve_ivp. If it’s False, the solution may not be reliable.\n\nf = lambda t, u: (t + u) ** 2\nsol = solve_ivp(f, [0.0, 1.0], [1.0])\nif not sol.success:\n    print(sol.message)\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nsemilogy(sol.t, sol.y[0, :])\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle(\"Blowup in finite time\")\n\nWe can also produce an IVP that has more than one solution.\n\nThe functions u(t)=u^2 and u(t)\\equiv 0 both satisfy the differential equation u'=2\\sqrt{u} and the initial condition u(0)=0. Thus the corresponding IVP has more than one solution.\n\nThe following standard theorem gives us a condition that is easy to check and guarantees that a unique solution exists. But it is not the most general possible such condition, so there are problems with a unique solution that it cannot detect. We state the theorem without proof.\n\nExistence and uniqueness\n\nIf the derivative \\frac{\\partial f}{\\partial u} exists and \\left|\\frac{\\partial f}{\\partial u}\\right| is bounded by a constant L for all a\\le t \\le b and all u, then the initial-value problem \n\n(6.1.1) has a unique solution for t\\in [a,b].","type":"content","url":"/basics#existence-and-uniqueness","position":5},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Conditioning of first-order IVPs"},"type":"lvl2","url":"/basics#conditioning-of-first-order-ivps","position":6},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Conditioning of first-order IVPs"},"content":"In a numerical context we have to be concerned about the conditioning of the IVP. There are two key items in \n\n(6.1.1) that we might consider to be the data of the initial-value ODE problem: the function f(t,u), and the initial value u_0. It’s easier to discuss perturbations to numbers than to functions, so we will focus on the effect of u_0 on the solution, using the following theorem that we give without proof. Happily, its conditions are identical to those in \n\nTheorem 6.1.1.\n\nDependence on initial value\n\nIf the derivative \\frac{\\partial f}{\\partial u} exists and \\left|\\frac{\\partial f}{\\partial u}\\right| is bounded by a constant L for all a\\le t \\le b and all u, then the solution u(t;u_0+\\delta) of u'=f(t,u) with initial condition u(0)=u_0+\\delta satisfies\\left\\|u(t;u_0+\\delta)-u(t;u_0)\\right\\|_\\infty \\le |\\delta| e^{L(b-a)}\n\nfor all sufficiently small |\\delta|.\n\nNumerical solutions of IVPs have errors, and those errors can be seen as perturbations to the solution. \n\nTheorem 6.1.2 gives an upper bound of e^{L(b-a)} on the infinity norm (i.e., pointwise) absolute condition number of the solution with respect to perturbations at an initial time. However, the upper bound may be a terrible overestimate of the actual sensitivity for a particular problem.\n\nConditioning of an IVP\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = range(0, 3, length=800)\nu = @. exp(t) * 1\nlower, upper = @. exp(t) * 0.7, @. exp(t) * 1.3\nplot(t, u, l=:black, ribbon=(lower, upper),\n    leg=:none, xlabel=L\"t\", ylabel=L\"u(t)\",\n    title=\"Exponential divergence of solutions\")\n\nBut with u'=-u, solutions actually get closer together with time.\n\nu = @. exp(-t) * 1\nlower, upper = @. exp(-t) * 0.7, @. exp(-t) * 1.3\nplot(t, u, l=:black, ribbon=(lower, upper),\n    leg=:none, xlabel=L\"t\", ylabel=L\"u(t)\",\n    title=\"Exponential convergence of solutions\")\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.\n\nConditioning of an IVP\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')   % ignore this line\ntitle('Exponential divergence of solutions')   % ignore this line\n\nBut with u'=-u, solutions actually get closer together with time.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(-t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')   % ignore this line\ntitle('Exponential convergence of solutions')   % ignore this line\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.\n\nConditioning of an IVP\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = linspace(0, 3, 200)\nu = array([exp(t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle(\"Exponential divergence of solutions\")\n\nBut with u'=-u, solutions actually get closer together with time.\n\nt = linspace(0, 3, 200)\nu = array([exp(-t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle(\"Exponential convergence of solutions\")\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence, the exponentially growing upper bound e^{b-a} is a gross overestimate.\n\nIn general, solutions can diverge from, converge to, or oscillate around the original trajectory in response to perturbations. We won’t fully consider these behaviors and their implications for numerical methods again until a later chapter.","type":"content","url":"/basics#conditioning-of-first-order-ivps","position":7},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Exercises"},"type":"lvl2","url":"/basics#exercises","position":8},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Exercises"},"content":"✍ For each IVP, determine whether the problem satisfies the conditions of \n\nTheorem 6.1.2). If so, determine the smallest possible value for L.\n\n(a) f(t,u) = 3 u,\\; 0 \\le t \\le 1\n\n(b) f(t,u) = -t \\sin(u),\\; 0 \\le t \\le 5\n\n(c) f(t,u) = -(1+t^2) u^2,\\; 1 \\le t \\le 3\n\n(d) f(t,u) = \\sqrt{u},\\; 0 \\le t \\le 1\n\n⌨ For each ODE in the preceding problem, assume that u is initially equal to 1 on the given interval. Solve the resulting IVP with solve and make a plot of the solution.\n\n✍ Use an integrating factor to find the solution of each problem in analytic form.\n\n(a) u' = -t u,\\ 0 \\le t \\le 5,\\ u(0) = 2\n\n(b) u' - 3 u = e^{-2t},\\ 0 \\le t \\le 1,\\  u(0) = 5\n\n✍ Consider the IVP u'=u^2, u(0)=\\alpha.\n\n(a) Does \n\nTheorem 6.1.1 apply to this problem?\n\n(b) Show that u(t) = \\alpha/(1-\\alpha t) is a solution of the IVP.\n\n(c) Does this solution necessarily exist for all t\\in[0,1]?\n\n⌨ Using solve, compute solutions x(t) to the logistic equation with harvesting,x' = k (S-x)(x-M), \\qquad 0\\le t \\le 10,\n\nwith k=S=1 and M=0.25, for the initial conditions x(0)=0.9M, 1.1M, 1.5M, 0.9S, 1.1S, 3S. Show all the solutions together on one plot with 0\\le x \\le 3. (Note: One of the solutions will throw a warning and fail to reach t=10, but you can plot it anyway.)\n\n⌨ (a) Using solve, solve the IVP u'=u\\cos(u) + \\cos(4t), 0\\le t \\le 10, u(0) = u_0 for u_0 = -2,-1.5,-1,\\ldots,1.5,2. Plot all the solutions on a single graph.\n\n(b) All of the solutions in part (a) eventually settle into one of two periodic oscillations. To two digits of accuracy, find the value of u_0 in (-1,1) at which the selected long-term solution changes. (This will take repeated trials, narrowing down the range for u_0 each time.)\n\n⌨ Experimental evidence (see \n\nNewton et al. (1981)) shows that a 300-mg oral dose of caffeine, such as might be found in a large mug of drip-brewed coffee, creates a concentration of about 8 \\mu{\\rm g}/mL in blood plasma. This boost is followed by first-order kinetics with a half-life of about 6 hours (although this rate can vary a great deal from person to person). We can model the caffeine concentration due to one drink taken over half an hour via  x'(t) = -kx + C(t),\\quad x(0)=0,\n\nwhere k=\\log(2)/6 and  C(t) =\n  \\begin{cases}\n    16, & 0\\le t \\le 0.5, \\\\\n    0, & t > 0.5.\n  \\end{cases}\n\nUse solve to make a plot of the caffeine concentration for 12 hours. Then change k=\\log(2)/8 (half-life of 8 hours) and plot the solution again.\n\n⌨ A reasonable model of the velocity v(t) of a skydiver is\\frac{dv}{dt} = -g + \\frac{k}{m}v^2,  \\qquad v(0)=0,\n\nwhere g=9.8 \\text{ m/sec}^2 is gravitational acceleration, m is the mass of the skydiver with parachute, and k quantifies the effect of air resistance. At the US Air Force Academy, a training jump starts at about 1200 m and has k=0.4875 for t<13 and k=29.16 or t\\ge 13. (This is an oversimplification; see \n\nMeade & Struthers (1999).)\n\n(a) Solve the IVP for v for an 80-kg cadet for t\\in [0,200], and plot the solution.\n\n(b) The total distance fallen up to time t is \\displaystyle\\int_0^t v(s)\\, ds. Use \n\nFunction 5.7.1 to calculate and plot the altitude of the cadet as a function of time.\n\n(c) In part (b), you should have found that the altitude becomes negative. Use \n\nFunction 4.4.2 to determine accurately when the cadet reaches the ground.","type":"content","url":"/basics#exercises","position":9},{"hierarchy":{"lvl1":"Euler’s method"},"type":"lvl1","url":"/euler","position":0},{"hierarchy":{"lvl1":"Euler’s method"},"content":"Let a first-order initial-value problem be given in the form\\begin{split}\n  u'(t) &= f\\bigl(t,u(t)\\bigr), \\qquad a \\le t \\le b,\\\\\n  u(a)& =u_0.\n\\end{split}\n\nWe represent a numerical solution of an IVP by its values at a finite collection of nodes, which for now we require to be equally spaced:t_i = a + ih, \\qquad h=\\frac{b-a}{n}, \\qquad i=0,\\ldots,n.\n\nThe number h is called the step size.\n\nBecause we don’t get exactly correct values of the solution at the nodes, we need to take some care with the notation. From now on we let \\hat{u}(t) denote the exact solution of the IVP. The approximate value at t_i computed at the nodes by our numerical methods will be denoted by u_i\\approx \\hat{u}(t_i). Because we are given the initial value u(a)=u_0 exactly, there is no need to distinguish whether we mean u_0 as the exact or the numerical solution.\n\nConsider a piecewise linear interpolant to the (as yet unknown) values u_0,u_1,\\ldots, u_n. For t_i < t < t_{i+1}, its slope is\\frac{u_{i+1} - u_{i}}{t_{i+1}-t_i} = \\frac{u_{i+1}-u_i}{h}.\n\nWe can connect this derivative to the differential equation by following the model of u'=f(t,u):\\frac{u_{i+1}-u_i}{h} = f(t_i,u_i), \\qquad i=0,\\ldots,n-1.\n\nWe could view the left-hand side as a forward-difference approximation to u'(t) at t=t_i. We can rearrange the equation to get Euler’s method, our first method for IVPs.\n\nEuler’s method for an IVP\n\nGiven the IVP u'=f(t,u), u(a)=u_0, and the nodes \n\n(6.2.2), iteratively compute the sequence  u_{i+1}=u_i + h f(t_i,u_i), \\qquad i=0,\\ldots,n-1.\n\nThen u_i is approximately the value of the solution at t=t_i.\n\nEuler’s method marches ahead in t, obtaining the solution at a new time level explicitly in terms of the latest value.\n\nA basic implementation of Euler’s method is shown in \n\nFunction 6.2.2.\n\neuler\n\nEuler’s method for an initial-value problem\n\n\"\"\"\n    euler(ivp,n)\n\nApply Euler's method to solve the given IVP using `n` time steps.\nReturns a vector of times and a vector of solution values.\n\"\"\"\nfunction euler(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initial condition and output setup.\n    u = fill(float(ivp.u0),n+1)\n\n    # The time stepping iteration.\n    for i in 1:n\n        u[i+1] = u[i] + h*ivp.f(u[i],ivp.p,t[i])\n    end\n    return t,u\nend\n\nAbout the code\n\nThe ivp input argument is an ODEProblem, like in \n\nDemo 6.1.2. It has fields ivp.f, ivp.tspan, ivp.u0, and ivp.p that fully define the problem. The outputs are vectors of the nodes and approximate solution values at those nodes.\n\nEuler’s method for an initial-value problem\n\nfunction [t, u] = eulerivp(ivp, a, b, n)\r\n% EULERIVP   Euler's method for a scalar initial-value problem.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;\r\nt = a + (0:n) * h;\r\n\r\n% Initialize solution array.\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0;\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  u(:, i+1) = u(:, i) + h * du_dt(t(i), u(i), p);\r\nend\n\nAbout the code\n\nThe ivp input argument is the same structure that is used with the built-in solve solvers. The outputs t and u are row vectors of the same length, like the fields in a solution object output by solve. While the entries of u could be simplified to u(1), u(i), etc., we chose a column-access syntax like u(:, i) that will prove useful for what’s coming next in the chapter.\n\nEuler’s method for an initial-value problem\n\ndef euler(dudt, tspan, u0, n):\n    \"\"\"\n    euler(dudt,tspan,u0,n)\n\n    Apply Euler's method to solve the IVP u'=`dudt`(u,t) over the interval `tspan` with\n    u(`tspan[1]`)=`u0`, using `n` subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * dudt(t[i], u[i])\n\n    return t, u.T","type":"content","url":"/euler","position":1},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Local truncation error"},"type":"lvl2","url":"/euler#local-truncation-error","position":2},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Local truncation error"},"content":"Let \\hat{u}(t) be the exact solution of the IVP \n\n(6.2.1), and suppose that somehow we have access to it at t=t_i, so that u_i=\\hat{u}(t_i). How good is u_{i+1} as an approximation to \\hat{u}(t_{i+1})? The answer is revealed through a Taylor series:\\begin{split}\n  \\hat{u}(t_{i+1}) - \\bigl[ u_i + hf(t_i,u_i) \\bigr]\n &=  \\hat{u}(t_{i+1}) - \\bigl[ \\hat{u}(t_i) + hf\\bigl(t_i,\\hat{u}(t_i)\\bigr) \\bigr] \\\\\n &= \\bigl[ \\hat{u}(t_i) + h \\hat{u}'(t_i) + \\tfrac{1}{2}h^2 \\hat{u}''(t_i) + O(h^3) \\bigr] - \\bigl[ \\hat{u}(t_i) + h\\hat{u}'(t_i) \\bigr] \\notag \\\\\n  &= \\tfrac{1}{2}h^2 \\hat{u}''(t_i) + O(h^3),\n\\end{split}\n\nwhere we used the fact that \\hat{u} satisfies the differential equation.\n\nWe now introduce some formalities.\n\nOne-step IVP method\n\nA one-step method for the IVP \n\n(6.2.1) is a formula of the form{u}_{i+1} = u_i + h\\phi(t_i,u_i,h), \\qquad i=0,\\ldots,n-1.\n\nEuler’s method is the particular case of \n\n(6.2.7) with \\phi(t,u,h) = f(t,u), but we will see other one-step methods in later sections.\n\nIn close analogy with \n\nConvergence of finite differences, we define truncation error as the residual of \n\n(6.2.7) when the exact solution is inserted.\n\nTruncation error of a one-step IVP method\n\nThe local truncation error (LTE) of the one-step method \n\n(6.2.7) is  \\tau_{i+1}(h) := \\frac{\\hat{u}(t_{i+1})-\\hat{u}(t_i)}{h} - \\phi\\bigl(t_i,\\hat{u}(t_i),h\\bigr).\n\nThe method is called consistent if \\tau_{i+1}(h)\\to 0 as h\\to 0.\n\nThe following follows immediately from the definitions.\n\nIf \\phi(t,u,0)=f(t,u) for any function u, then the method \n\n(6.2.7) is consistent.","type":"content","url":"/euler#local-truncation-error","position":3},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Convergence"},"type":"lvl2","url":"/euler#convergence","position":4},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Convergence"},"content":"While the local truncation error is straightforward to calculate from its definition, it is not the quantity we want to know about and control.\n\nGlobal error of an IVP solution\n\nGiven an IVP whose exact solution is \\hat{u}(t), the global error of approximate solution values u_0,u_1,\\ldots,u_n at times t_i in \n\n(6.2.2) is the vector [ \\hat{u}(t_i) - u_i ]_{\\,i=0,\\ldots,n}.\n\nAt times the term global error may be interpreted as the max-norm of the global error vector, or as its final value.\n\nBy our definitions, the local error in stepping from t_i to t_{i+1} is h\\tau_{i+1}(h). To reach the time t=b from t=a with step size h, we need to take n=(b-a)/h steps. If we want to reach, say, t=(a+b)/2, then we would have to take n/2 steps, and so on. In fact, to reach any fixed time in the interval, we need to take O(n)=O(h^{-1}) steps. By expressing the local error with a factor of h taken out, the LTE τ itself is accounting for the simple accumulation of error caused by taking O(n) steps.\n\nHowever, global error is not as simple as a sum of local errors. As explained in \n\nTheorem 6.1.2 and illustrated in \n\nDemo 6.1.5, each step causes a perturbation of the solution that can grow as t advances. Thus, we have to account for the flow evolution of individual step truncation errors as well as their mere accumulation. That is the subject of the following theorem.\n\nSuppose that the unit local truncation error of the one-step method \n\n(6.2.7) satisfies  |\\tau_{i+1}(h)| \\le C h^p,\n\nand that\\left| \\frac{\\partial \\phi}{\\partial u} \\right| \\le L\n\nfor all t\\in[a,b], all u, and all h>0. Then the global error satisfies|\\hat{u}(t_i) - u_i| \\le \\frac{Ch^p}{L} \\left[ e^{L(t_i-a)} - 1\n\\right] = O(h^p),\n\nas h\\rightarrow 0.\n\nDefine the global error sequence ϵ_i=\\hat{u}(t_i)-u_i. Using \n\n(6.2.7), we obtain  ϵ_{i+1} - ϵ_i = \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - ( {u}_{i+1} - u_i ) =\n  \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - h\\phi(t_i,u_i,h),\n\nor  ϵ_{i+1} = ϵ_i + [\\hat{u}(t_{i+1}) - \\hat{u}(t_i) - h\\phi(t_i,\\hat{u}(t_i),h)] +\n  h[\\phi(t_i,\\hat{u}(t_i),h)- \\phi(t_i,u_i,h)].\n\nWe apply the triangle inequality,  \n\n(6.2.8), and \n\n(6.2.9) to find  |ϵ_{i+1}| \\le |ϵ_i| + Ch^{p+1} + h \\left| \\phi(t_i,\\hat{u}(t_i),h)- \\phi(t_i,u_i,h)\\right|.\n\nThe Fundamental Theorem of Calculus implies that\\begin{split}\n  \\left| \\phi(t_i,\\hat{u}(t_i),h)- \\phi(t_i,u_i,h)\\right|\n      & = \\left|  \\int_{u_i}^{\\hat{u}(t_i)} \\frac{\\partial \\phi}{\\partial u} \\,du  \\right|\\\\\n    & \\le  \\int_{u_i}^{\\hat{u}(t_i)} \\left|\\frac{\\partial \\phi}{\\partial u}\\right| \\,du \\\\[1mm]\n    & \\le L | \\hat{u}(t_i)-u_i| = L\\, |ϵ_i|.\n\\end{split}\n\nThus\\begin{split}\n  |ϵ_{i+1}| &\\le Ch^{p+1} + (1 + hL) |ϵ_i| \\\\\n  &\\le Ch^{p+1} + (1 + hL) \\bigl[ Ch^{p+1} + (1 + hL) |ϵ_{i-1}|\n  \\bigr]\\\\\n  &\\;\\vdots \\\\\n  &\\le Ch^{p+1} \\left[ 1 + (1+hL) + (1+hL)^2 + \\cdots + (1+hL)^i\n  \\right].\n\\end{split}\n\nTo get the last line we applied the inequality recursively until reaching ϵ_0, which is zero. Replacing i+1 by i and simplifying the geometric sum, we get  |ϵ_i| \\le Ch^{p+1}\\frac{(1+hL)^i - 1}{(1+hL)-1} = \\frac{Ch^p}{L}\n  \\left[ (1+hL)^i - 1 \\right].\n\nWe observe that 1+x \\le e^x for x\\ge 0 (see \n\nExercise 5). Hence (1+hL)^i \\le e^{i h L}, which completes the proof.\n\nThe theorem justifies one more general definition.\n\nOrder of accuracy of a one-step IVP method\n\nIf the local truncation error of the one-step method \n\n(6.2.7) satisfies \\tau_{i+1}(h)=O(h^p) for a positive integer p, then p is the order of accuracy of the formula.\n\nWe could restate \n\nTheorem 6.2.1 as saying that the global error has the same order of accuracy as the LTE. Note, however, that the O(h^p) convergence hides a leading constant that grows exponentially in time. When the time interval is bounded as h\\to 0, this does not interfere with the conclusion, but the behavior as t\\to\\infty contains no such guarantee.\n\nConvergence of Euler’s method\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf(u, p, t) = sin((t + u)^2);\ntspan = (0.0, 4.0);\nu0 = -1.0;\n\nivp = ODEProblem(f, u0, tspan)\n\nHere is the call to \n\nFunction 6.2.2.\n\nt, u = FNC.euler(ivp, 20)\n\nplot(t, u, m=2, label=\"n=20\",\n    xlabel=L\"t\", ylabel=L\"u(t)\", title=\"Solution by Euler's method\")\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(ivp, 50)\nplot!(t, u, m=2, label=\"n=50\")\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a DifferentialEquations solver to construct an accurate reference solution.\n\nu_exact = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14)\n\nplot!(u_exact, l=(2, :black), label=\"reference\")\n\nNow we can perform a convergence study.\n\nn = [round(Int, 5 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.euler(ivp, n)\n    push!(err, norm(u_exact.(t) - u, Inf))\nend\n\npretty_table((n=n, err=err), header=[\"n\", \"Inf-norm error\"])\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nplot(n, err, m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"Inf-norm global error\"),\n    title=\"Convergence of Euler's method\")\n\n# Add line for perfect 1st order.\nplot!(n, 0.05 * (n / n[1]) .^ (-1), l=:dash, label=L\"O(n^{-1})\")\n\nConvergence of Euler’s method\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We need to define the function for the right-hand side of the ODE, the interval for the independent variable, and the initial value.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nHere is the call to \n\nFunction 6.2.2.\n\n[t, u] = eulerivp(ivp, a, b, 20);\nclf, plot(t, u, '.-')\nxlabel('t')\nylabel('u(t)')\ntitle('Solution by Euler''s method')  % ignore this line\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\n[t, u] = eulerivp(ivp, a, b, 50);\nhold on, plot(t, u, '.-')\nlegend('20 steps', '50 steps')\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a built-in solver to construct an accurate reference solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_exact = solutionFcn(ivp, a, b);\n\nNow we can perform a convergence study.\n\nn = round(5 * 10.^(0:0.5:3));\nerr = [];\nfor k = 1:length(n)\n    [t, u] = eulerivp(ivp, a, b, n(k));\n    err(k) = norm(u_exact(t) - u, Inf);\nend\ntable(n', err', VariableNames=[\"n\", \"inf-norm error\"])\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nclf\nloglog(n, err, 'o-')\nhold on, loglog(n, 0.5 * err(end) * (n / n(end)).^(-1), '--')\nxlabel('n')\nylabel('inf-norm error')  % ignore this line\ntitle('Convergence of Euler''s method')  % ignore this line\nlegend('error', 'O(n^{-1})', 'location', 'southwest')  % ignore this line\n\nConvergence of Euler’s method\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = -1.0\nt, u = FNC.euler(f, tspan, u0, 20)\n\nfig, ax = subplots()\nax.plot(t, u[0, :], \"-o\", label=\"$n=20$\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution by Euler's method\")\nlegend()\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(f, tspan, u0, 200)\nax.plot(t, u[0, :], label=\"$n=200$\")\nax.legend()\nfig\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use solve_ivp to construct an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, [u0], dense_output=True, atol=1e-8, rtol=1e-8)\nax.plot(t, sol.sol(t)[0, :], \"--\", label=\"accurate\")\nax.legend()\nfig\n\nNow we can perform a convergence study.\n\nn_ = array([int(5 * 10**k) for k in arange(0, 3, 0.5)])\nerr_ = zeros(6)\nresults = PrettyTable([\"n\", \"error\"])\nfor j, n in enumerate(n_):\n    t, u = FNC.euler(f, tspan, u0, n)\n    err_[j] = norm(sol.sol(t)[0, :] - u[0, :], inf)\n    results.add_row((n, err_[j]))\nprint(results)\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nloglog(n_, err_, \"-o\", label=\"results\")\nplot(n_, 0.5 * (n_ / n_[0])**(-1), \"--\", label=\"1st order\")\nxlabel(\"$n$\"), ylabel(\"inf-norm error\")\ntitle(\"Convergence of Euler's method\")\nlegend()\n\nEuler’s method is the ancestor of the two major families of IVP methods presented in this chapter. Before we describe them, though, we generalize the initial-value problem itself in a crucial way.","type":"content","url":"/euler#convergence","position":5},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Exercises"},"type":"lvl2","url":"/euler#exercises","position":6},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Exercises"},"content":"✍ Do two steps of Euler’s method for the following problems using the given step size h. Then, compute the error using the given exact solution.\n\n(a) u' = -2t u, \\ u(0) = 2;\\ h=0.1;\\ \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ u(0) = 2;\\ h=0.2;\\ \\hat{u}(t) = -1-t+3e^t\n\n(c) t u' + u = 1, \\ u(1) = 6, \\ h = 0.25;\\ \\hat{u}(t) = 1+5/t\n\n(d) u' - 2u(1-u) = 0, \\ u(0) = 1/2, \\ h = 0.25; \\ \\hat{u}(t) = 1/(1 + e^{-2t})\n\n⌨ For each IVP, solve the problem using \n\nFunction 6.2.2. (i) Plot the solution for n=320. (ii) For n=10\\cdot2^k, k=2,3,\\ldots,10, compute the error at the final time and make a log-log convergence plot, including a reference line for first-order convergence.\n\n(a) u' = -2t u, \\ 0 \\le t \\le 2, \\ u(0) = 2;\\  \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ 0 \\le t \\le 1, \\ u(0) = 2;\\  \\hat{u}(t) = -1-t+3e^t\n\n(c) (1+t^3)uu' = t^2,\\ 0 \\le xt \\le 3, \\ u(0) =1;\\ \\hat{u}(t) = [1+(2/3)\\ln (1+xt^3)]^{1/2}\n\n(d) u' - 2u(1-u) = 0, \\ 0 \\le t \\le 2, \\ u(0) = 1/2; \\ \\hat{u}(t) = 1/(1 + e^{-2t})\n\n(e) v' - (1+x^2) v = 0, \\ 1 \\le x \\le 3, \\ v(1) = 1, \\ \\hat{v}(x) = e^{(x^3+3x-4)/3}\n\n(f) v' + (1+x^2) v^2 = 0, \\ 0 \\le x \\le 2, \\ v(0) = 2, \\ \\hat{v}(x) = 6/(2x^3+6x+3)\n\n(g) u' = 2(1+t)(1+u^2), \\ 0 \\le t \\le 0.5, \\ u(0) = 0,  \\ \\hat{u}(t) = \\tan(2t + t^2)\n\n✍ Here is an alternative to Euler’s method:\\begin{split}\n  v_{i+1} &= u_i + h f(t_i,u_i),\\\\\n  u_{i+1} &= u_i + hf(t_{i}+h,v_{i+1}).\n\\end{split}\n\n(a) Write out the method explicitly in the general one-step form \n\n(6.2.7) (i.e., clarify what ϕ is for this method).\n\n(b) Show that the method is consistent.\n\n✍ Consider the problem u'=ku, u(0)=1 for constant k and t>0.\n\n(a) Find an explicit formula in terms of h, k, and i for the Euler solution u_i at t=ih.\n\n(b) Find values of k and h such that |u_i|\\to\\infty as i\\to\\infty while the exact solution \\hat{u}(t) is bounded as t\\to\\infty.\n\n✍ Prove the fact, used in the proof of \n\nTheorem 6.2.1, that 1+x\\le e^x for all x\\ge 0.\n\n✍ Suppose that the error in making a step is also subject to roundoff error \\epsilon_{i+1}, so that the total local error per unit step is Ch^p+\\epsilon_{i+1} h^{-1}; assume that |\\epsilon_{i+1}| \\le \\epsilon for all i and that the initial condition is known exactly. Generalize \n\nTheorem 6.2.1 for this case.\n\nAnother point of view is that we can of course make local errors smaller by chopping h in half, but then we have to take twice as many steps. The important quantity, then, is local error per unit step length, which is how τ is defined.","type":"content","url":"/euler#exercises","position":7},{"hierarchy":{"lvl1":"Implementation of multistep methods"},"type":"lvl1","url":"/implicit","position":0},{"hierarchy":{"lvl1":"Implementation of multistep methods"},"content":"We now consider some of the practical issues that arise when multistep formulas are used to solve IVPs. In this section we emphasize the vector IVP, \\mathbf{u}'=\\mathbf{f}(t,\\mathbf{u}), and use boldface in the difference formula \n\n(6.6.2) as well.","type":"content","url":"/implicit","position":1},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Explicit methods"},"type":"lvl2","url":"/implicit#explicit-methods","position":2},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Explicit methods"},"content":"As a concrete example, the AB4 method is defined by the formula\\mathbf{u}_{i+1} = \\mathbf{u}_i + h\\, ( \\tfrac{55}{24}\\mathbf{f}_i - \\tfrac{59}{24} \\mathbf{f}_{i-1} + \\tfrac{37}{24}\\mathbf{f}_{i-2} - \\tfrac{9}{24}\\mathbf{f}_{i-3}), \\quad i=3,\\ldots,n-1.\n\nFunction 6.7.1 shows a basic implementation of AB4.\n\nObserve that \n\nFunction 6.4.2 is used to find the starting values \\mathbf{u}_1,\\mathbf{u}_2,\\mathbf{u}_3 that are needed before the iteration formula takes over. As far as RK4 is concerned, it needs to solve  (the same step size as in the AB4 iteration). These results are then used to find \\mathbf{f}_0,\\ldots,\\mathbf{f}_3 and get the main iteration started.\n\nab4\n\n4th-order Adams–Bashforth formula for an IVP\n\n\"\"\"\n    ab4(ivp,n)\n\nApply the Adams-Bashforth 4th order method to solve the given IVP\nusing `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction ab4(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Constants in the AB4 method.\n    k = 4;   σ = [55,-59,37,-9]/24;\n\n    # Find starting values by RK4.\n    u = fill(float(ivp.u0),n+1)\n    rkivp = ODEProblem(ivp.f,ivp.u0,(a,a+(k-1)*h),ivp.p)\n    ts,us = rk4(rkivp,k-1)\n    u[1:k] .= us\n\n    # Compute history of u' values, from newest to oldest.\n    f = [ ivp.f(u[k-i],ivp.p,t[k-i]) for i in 1:k-1  ]\n\n    # Time stepping.\n    for i in k:n\n        f = [ ivp.f(u[i],ivp.p,t[i]), f[1:k-1]... ]   # new value of du/dt\n        u[i+1] = u[i] + h*sum(f[j]*σ[j] for j in 1:k)  # advance a step\n    end\n    return t,u\nend\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n4th-order Adams–Bashforth formula for an IVP\n\nfunction [t, u] = ab4(ivp, a, b, n)\r\n%AB4     4th-order Adams-Bashforth formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Constants in the AB4 method.\r\nk = 4;  \r\nsigma = [55; -59; 37; -9] / 24;  \r\n\r\n% Find starting values by RK4.\r\n[ts, us] = rk4(ivp, a, a + (k-1)*h, k-1);\r\nu = zeros(length(u0), n+1);\r\nu(:, 1:k) = us(:, 1:k);\r\n\r\n% Compute history of u' values, from oldest to newest.\r\nf = zeros(length(u0), k);\r\nfor i = 1:k-1\r\n  f(:, k-i) = du_dt(t(i), u(:, i), p);\r\nend\r\n\r\n% Time stepping.\r\nfor i = k:n\r\n  f = [du_dt(t(i), u(:, i), p), f(:, 1:k-1)];   % new value of du/dt\r\n  u(:, i+1) = u(:, i) + h * (f * sigma);        % advance one step\r\nend\n\nAbout the code\n\nLine 21 sets sigma to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 24--26 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then lines 29--32 compute the vector [f_2,f_1,f_0].\n\nLine 36 computes f_i, based on the most recent solution value and time. That goes into the first column of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n4th-order Adams–Bashforth formula for an IVP\n\ndef ab4(dudt, tspan, u0, n):\n    \"\"\"\n    ab4(dudt,tspan,u0,n)\n\n    Apply the Adams-Bashforth 4th order method to solve the vector-valued IVP u'=`dudt`(u,p,t)\n    over the interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Constants in the AB4 method.\n    k = 4\n    sigma = np.array([55, -59, 37, -9]) / 24\n\n    # Find starting values by RK4.\n    ts, us = rk4(dudt, [a, a + (k - 1) * h], u0, k - 1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[:k] = us[:k].T\n\n    # Compute history of u' values, from newest to oldest.\n    f = np.array([dudt(t[k-j-2], u[k-j-2]) for j in range(k)])\n\n    # Time stepping.\n    for i in range(k-1, n):\n        f = np.vstack([dudt(t[i], u[i]), f[:-1]])  # new value of du/dt\n        u[i+1] = u[i] + h * np.dot(sigma, f)  # advance one step\n\n    return t, u.T\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\nConvergence of Adams–Bashforth\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve is called to give an accurate reference solution.\n\nivp = ODEProblem((u, p, t) -> sin((t + u)^2), -1.0, (0.0, 4.0))\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of the AB4 code.\n\nn = @. [round(Int, 4 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.ab4(ivp, n)\n    push!(err, norm(u_ref.(t) - u, Inf))\nend\n\npretty_table([n err], header=[\"n\", \"inf-norm error\"])\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nplot(n, err, m=3, label=\"AB4\",\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of AB4\", leg=:bottomleft)\n\nplot!(n, (n / n[1]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nConvergence of Adams–Bashforth\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, a built-in solver is called to give an accurate reference solution.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of the AB4 code.\n\nn = round(4 * 10.^(0:0.5:3)');\nerr = [];\nfor i = 1:length(n)\n    [t, u] = ab4(ivp, a, b, n(i));\n    err(i) = norm(u_ref(t) - u, Inf);\nend\n\ndisp(table(n, err, variableNames=[\"n\", \"inf-norm error\"]))\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nclf, loglog(n, err, '-o')\nhold on\nloglog(n, 0.5 * err(end) * (n / n(end)) .^ (-4), '--')\nxlabel(\"n\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of AB4\")\nlegend(\"AB4\", \"O(n^{-4})\", \"location\", \"southwest\")\n\nConvergence of Adams–Bashforth\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve_ivp is called to give an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = [-1.0]\nu_ref = solve_ivp(du_dt, tspan, u0, dense_output=True, rtol=1e-13, atol=1e-13).sol\n\nNow we perform a convergence study of the AB4 code.\n\nn = array([int(4 * 10**k) for k in linspace(0, 3, 7)])\nerr = []\nresults = PrettyTable([\"n\", \"AB4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ab4(du_dt, tspan, u0, n[i])\n    err.append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[-1]])\n\nprint(results)\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nloglog(n, err, \"-o\", label=\"AB4\")\nloglog(n, 0.5 * err[-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"$n$\"),  ylabel(\"final error\")\nlegend(), title(\"Convergence of AB4\");","type":"content","url":"/implicit#explicit-methods","position":3},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Implicit methods"},"type":"lvl2","url":"/implicit#implicit-methods","position":4},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Implicit methods"},"content":"The implementation of an implicit multistep method is more difficult. Consider the second-order implicit formula AM2, also known as the trapezoid method. To advance from step i to i+1, we need to solve  \\mathbf{z} - \\tfrac{1}{2} h f(t_{i+1},\\mathbf{z})  = \\mathbf{u}_i + \\tfrac{1}{2} h \\mathbf{f}(t_i,\\mathbf{u}_i)\n\nfor \\mathbf{z}. This equation can be written as \\mathbf{g}(\\mathbf{z})=\\boldsymbol{0}, so the rootfinding methods of Chapter 4 can be used. The new value \\mathbf{u}_{i+1} is equal to the root of this equation.\n\nAn implementation of AM2 using \n\nFunction 4.6.3 from \n\nQuasi-Newton methods is shown in \n\nFunction 6.7.2.\n\nam2\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\n\"\"\"\n    am2(ivp,n)\n\nApply the Adams-Moulton 2nd order method to solve given IVP using\n`n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction am2(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initialize output.\n    u = fill(float(ivp.u0),n+1)\n\n    # Time stepping.\n    for i in 1:n\n        # Data that does not depend on the new value.\n        known = u[i] + h/2*ivp.f(u[i],ivp.p,t[i])\n        # Find a root for the new value.\n        g = z -> z - h/2*ivp.f(z,ivp.p,t[i+1]) - known\n        unew = levenberg(g,known)\n        u[i+1] = unew[end]\n    end\n    return t,u\nend\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\nfunction [t, u] = am2(ivp, a, b, n)\r\n% AM2    2nd-order Adams-Moulton (trapezoid) formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  % Data that does not depend on the new value.\r\n  known = u(:,i) + h/2 * du_dt(t(i), u(:, i), p);\r\n  % Find a root for the new value. \r\n  unew = levenberg(@trapzero, known);\r\n  u(:, i+1) = unew(:, end);\r\nend\r\n\r\n% This function defines the rootfinding problem at each step.\r\nfunction F = trapzero(z)\r\n    F = z - h/2 * du_dt(t(i+1), z, p) - known;\r\nend\r\n\r\nend  % main function\n\nAbout the code\n\nLines 32--34 define the function \\mathbf{g}. This is sent to levenberg in line~27 to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\ndef am2(dudt, tspan, u0, n):\n    \"\"\"\n    am2(dudt,tspan,u0,n)\n\n    Apply the Adams-Moulton 2nd order method to solve the vector-valued IVP u'=`dudt`(u,p,t)\n    over the interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        # Data that does not depend on the new value.\n        known = u[i] + h / 2 * dudt(t[i], u[i])\n        # Find a root for the new value.\n        F = lambda z: z - h / 2 * dudt(t[i+1], z) - known\n        unew = levenberg(F, known)\n        u[i+1] = unew[:, -1]\n\n    return t, u.T\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/implicit#implicit-methods","position":5},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Stiff problems"},"type":"lvl2","url":"/implicit#stiff-problems","position":6},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Stiff problems"},"content":"At each time step in \n\nFunction 6.7.2, or any implicit IVP solver, a rootfinding iteration of uncertain expense is needed, requiring multiple calls to evaluate the function \\mathbf{f}. This fact makes the cost of an implicit method much greater on a per-step basis than for an explicit one. Given this drawback, you are justified to wonder whether implicit methods are ever competitive! The answer is emphatically yes, as \n\nDemo 6.7.2 demonstrates.\n\nStiffness\n\nThe following simple ODE uncovers a surprise.\n\nivp = ODEProblem((u, p, t) -> u^2 - u^3, 0.005, (0, 400.0))\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(ivp, 200)\n\nplot(tI, uI, label=\"AM2\",\n    xlabel=L\"t\", ylabel=L\"u(t)\", leg=:bottomright)\n\nNow we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(ivp, 200)\n\nscatter!(tE, uE, m=3, label=\"AB4\", ylim=[-4, 2])\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[105:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplt = scatter(tI, uI, label=\"AM2, n=200\", m=3,\n    xlabel=L\"t\", ylabel=L\"u(t)\", leg=:bottomright)\n\nfor n in [1000, 1600]\n    tE, uE = FNC.ab4(ivp, n)\n    plot!(tE, uE, label=\"AM4, n=$n\")\nend\nplt\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!\n\nStiffness\n\nThe following simple ODE uncovers a surprise.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) u^2 - u^3;\nivp.InitialValue = 0.005;\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\n[tI, uI] = am2(ivp, 0, 400, 200);\nclf\nplot(tI, uI)\nxlabel(\"t\");  ylabel(\"u(t)\")\n\nNow we repeat the process using the explicit AB4 method.\n\n[tE, uE] = ab4(ivp, 0, 400, 200);\nhold on\nplot(tE, uE, '.', 'markersize', 8)\nylim([-5, 3])\nlegend(\"AM2\", \"AB4\")\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nformat short e\nuE(105:111)\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nclf,  plot(tI, uI, '.', 'markersize', 10)\nhold on\n[tE, uE] = ab4(ivp, 0, 400, 1000);\nplot(tE, uE)\n[tE, uE] = ab4(ivp, 0, 400, 1600);\nplot(tE, uE)\nlegend(\"AM2, n=200\", \"AB4, n=1000\", \"AB4, n=1600\")\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!\n\nStiffness\n\nThe following simple ODE uncovers a surprise.\n\nf = lambda t, u: u**2 - u**3\nu0 = array([0.005])\ntspan = [0, 400]\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(f, [0.0, 400.0], u0, 200)\nfig, ax = subplots()\nax.plot(tI, uI[0], label=\"AM2\")\nxlabel(\"$t$\"), ylabel(\"$y(t)$\");\n\nSo far, so good. Now we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(f, [0.0, 400.0], u0, 200)\nax.scatter(tE, uE[0], label=\"AB4\")\nax.set_ylim([-4, 2]), ax.legend()\nfig\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[0, 104:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplot(tI, uI[0], color=\"k\", label=\"AM2\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1000)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1000\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1600)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1600\")\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\nlegend()\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!\n\nAlthough the result of \n\nDemo 6.7.2 may seem counter-intuitive, there is no contradiction. A fourth-order explicit formula is more accurate than a second-order implicit one, in the limit h\\to 0. But there is another limit to consider, t\\to \\infty with h fixed, and in this one the implicit method wins.\n\nProblems for which implicit methods are much more efficient than explicit counterparts are called stiff. A complete mathematical description will wait for Chapter 11, but a sure sign of stiffness is the presence of phenomena on widely different time scales. In \n\nDemo 6.7.2, for instance, there are two slow periods during which the solution changes very little, interrupted by a very fast transition in the state. An explicit method “thinks” that the step size must always be dictated by the time scale of the fast transition, whereas an implicit method can take large steps during the slow periods.","type":"content","url":"/implicit#stiff-problems","position":7},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Adaptivity"},"type":"lvl2","url":"/implicit#adaptivity","position":8},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Adaptivity"},"content":"As with RK methods, we can run two time stepping methods simultaneously in order to estimate the error and adjust the step size. For example, we could pair AB3 with AB4 as practically no cost because the methods differ only in how they include known information from the recent past. The more accurate AB4 value should allow an accurate estimate of the local error in the AB3 value, and so on.\n\nBecause multistep methods rely on the solution history, though, changing the step size is more algebraically complicated than for RK methods. If h is changed, then the historical values \\mathbf{u}_{i-1},\\mathbf{u}_{i-2}\\ldots and \\mathbf{f}_{i-1},\\mathbf{f}_{i-2}\\ldots are no longer given at the right moments in time to apply the iteration formula. A typical remedy is to use interpolation to re-evaluate the historical values at the appropriate times. The details are important but not especially illuminating, and we do not give them here.","type":"content","url":"/implicit#adaptivity","position":9},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Exercises"},"type":"lvl2","url":"/implicit#exercises","position":10},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Exercises"},"content":"Must stay as #1\n\n⌨ For each IVP, solve the problem using \n\nFunction 6.7.1 with n=100, and plot the solution and the error u-\\hat{u} on separate plots.\n\n(a) u' = -2t u, \\ 0 \\le t \\le 2, \\ u(0) = 2;\\  \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ 0 \\le t \\le 1, \\ u(0) = 2;\\  \\hat{u}(t) = 1-t+e^t\n\n(c) u' = x^2/[u(1+x^3)],\\ 0 \\le x \\le 3, \\ u(0) =1;\\ \\hat{u}(x) =[1+(2/3)\\ln (1+x^3)]^{1/2}\n\n(d) u''+ 9u = 9t, \\: 0< t< 2\\pi, \\: u(0) =1,\\: u'(0) = 1; \\: \\hat{u}(t) = t+\\cos (3t)\n\n(e) u''+ 9u = \\sin(2t), \\: 0< t< 2\\pi, \\: u(0) =2,\\: u'(0) = 1;\n\\quad \\hat{u}(t) = (1/5) \\sin(3t) + 2 \\cos (3t)+ (1/5) \\sin (2t)\n\n(f) u''- 9u = 9t \\: 0< t< 1, \\: u(0) =2,\\: u'(0) = -1; \\: \\hat{u}(t) = e^{3t} + e^{-3t}-t\n\n(g) u''+ 4u'+ 4u = t, \\: 0< t< 4, \\: u(0) =1,\\: u'(0) = 3/4; \\: \\hat{u}(t) = (3t+5/4)e^{-2t} + (t-1)/4\n\n(h) x^2 u'' +5xu' + 4u = 0,\\: 1<x<e^2, \\: u(1) =1, \\: u'(1) = -1; \\: \\hat{u}(x) = x^{-2}( 1 + \\ln x)\n\n(i) 2 x^2 u'' +3xu' - u = 0,\\: 1<x<16, \\: u(1) =4, \\: u'(1) = -1;\n\\quad \\hat{u}(x) = 2(x^{1/2} + x^{-1})\n\n(j) x^2 u'' -xu' + 2u = 0,\\: 1<x<e^{\\pi}, \\: u(1) =3, \\: u'(1) = 4;\n\\quad \\hat{u}(x) = x \\left[ 3 \\cos \\left( \\ln x \\right)+\\sin \\left( \\ln x \\right) \\right]\n\n⌨ For each IVP in Exercise 1, use \n\nFunction 6.7.1 for n=10\\cdot2^d and d=1,\\ldots,10. Make a log-log convergence plot for the final time error |u_n-\\hat{u}(t_n)| versus n, and add a straight line indicating fourth-order convergence.\n\n⌨ Repeat Exercise 1 above  using \n\nFunction 6.7.2.\n\n⌨  Repeat Exercise 2 above using \n\nFunction 6.7.2 and comparing to second-order rather than fourth-order convergence.\n\n⌨ Using \n\nFunction 6.7.2 as a model, write a function bd2 that applies the BD2 method to solve an IVP. Test the convergence of your function on one of the IVPs in \n\nExercise 1 above.\n\n⌨ For double-precision purposes, the exact solution of the IVP in \n\nDemo 6.7.2 satisfies \\hat{u}(400)=1.\n\n(a) Use \n\nFunction 6.7.1 with n=600,800,1000,\\ldots,2000 and make a log-log convergence plot of the error |u_n-1| as a function of n.\n\n(b) Repeat part (a) using \n\nFunction 6.7.2.\n\nConsider the IVP\\mathbf{u}'(t) = \\mathbf{A} \\mathbf{u}(t), \\quad \\mathbf{A}=\n\\begin{bmatrix}\n  0&-4\\\\4&0\n\\end{bmatrix}, \\quad \\mathbf{u}(0) =\n\\begin{bmatrix}\n  1\\\\0\n\\end{bmatrix}.\n\n(a) ✍ Define E(t) = \\bigl\\|\\mathbf{u}(t)\\bigr\\|_2^2. Show that E(t) is constant. (Hint: differentiate \\mathbf{u}^T\\mathbf{u} with respect to time and simplify it.)\n\n(b) ⌨ Use \n\nFunction 6.7.1 to solve the IVP for t\\in[0,20] with n=100 and n=150. Plot |E(t)-E(0)| versus time for both solutions on a single log-linear graph. You should see exponential growth in time. (In this regime, AB4 is acting unstably in a sense discussed in .)\n\n(c) ⌨ Repeat part (b) with n=400 and n=600, but on a linear-linear plot. Now you should see only linear growth of |E(t)-E(0)|. (In this regime, AB4 is fully stable.)\n\n(d) ⌨ Repeat part (b) with AM2 instead of AB4, on a linear-linear plot. You will find that AM2 conserves energy, just like the exact solution.\n\n⌨ (a) Modify \n\nFunction 6.7.1 to implement the AB2 method.\n\n(b) Repeat part (b) of the preceding exercise, using AB2 in place of AB4.\n\n(c) Repeat part (c) of the preceding exercise, using AB2 in place of AB4.\n\n⌨ (a) Modify \n\nFunction 6.7.2 to implement the backward Euler (AM1) method.\n\n(b) Repeat part (d) of Exercise 7 above, using AM1 in place of AM2 and n=400,800. Does the AM1 method conserve energy?","type":"content","url":"/implicit#exercises","position":11},{"hierarchy":{"lvl1":"Multistep methods"},"type":"lvl1","url":"/multistep","position":0},{"hierarchy":{"lvl1":"Multistep methods"},"content":"In Runge–Kutta methods we start at u_i to find {u}_{i+1}, taking multiple f-evaluations (stages) to achieve high accuracy. In contrast, multistep methods boost accuracy by employing more of the history of the solution, taking information from the recent past. For the discussion in this and following sections, we introduce the shorthand notationf_i = f(t_i,u_i).\n\nMultistep method for IVPs\n\nA k-step multistep (or linear multistep) method is given by the difference equationu_{i+1} &= a_{k-1}u_i + \\cdots + a_0 u_{i-k+1} \\qquad \\\\ \n& \\qquad + h ( b_kf_{i+1} + \\cdots + b_0 f_{i-k+1}),\n\nwhere the a_j and the b_j are constants. If b_k=0, the method is explicit; otherwise, it is implicit.\n\nThe quantities u and f in \n\n(6.6.2) are shown as scalars, but in general they can be vectors.\n\nIn order to use \n\n(6.6.2) as a numerical method, we iterate through i=k-1,\\ldots,n-1. The value u_0 is determined by the initial condition, but we also need some way of generating the starting valuesu_1=\\alpha_1, \\quad \\ldots \\quad u_{k-1}=\\alpha_{k-1}.\n\nIn practice the starting values are often found using an RK formula.\n\nThe difference formula \n\n(6.6.2) defines {u}_{i+1} in terms of known values of the solution and its derivative from the past. In the explicit case with b_k=0, Equation \n\n(6.6.2) immediately gives a formula for the unknown quantity {u}_{i+1} in terms of values at time level t_i and earlier. Thus only one new evaluation of f is needed to make a time step, provided that we store the recent history.\n\nFor an implicit method, however, b_k\\neq 0 and \n\n(6.6.2) has the form  {u}_{i+1} - hb_kf(t_{i+1},{u}_{i+1}) = F(u_i,u_{i-1},\\ldots,u_{i-k+1}).\n\nNow the unknown {u}_{i+1} that we seek appears inside the function f. In general this equation is a nonlinear rootfinding problem for {u}_{i+1} and is not solvable in a finite number of steps by a formula. The implementation of both explicit and implicit multistep formulas is discussed in detail in \n\nImplementation of multistep methods.\n\nAs with RK formulas, a multistep method is entirely specified by the values of a few constants. \n\nTable 6.6.1 and \n\nTable 6.6.2 present some of the most well-known and important formulas. The Adams–Bashforth (AB) methods are explicit, while Adams–Moulton (AM) and backward differentiation formulas (BD) are implicit. The tables also list the methods’ order of accuracy, to be defined shortly. We adopt the convention of referring to a multistep method by appending its order of accuracy to a two-letter name abbreviation, e.g., the AB3 method.\n\nTable 6.6.1:Coefficients of Adams multistep formulas. All have a_{k-1}=1 and a_{k-2} = \\cdots = a_0 = 0.\n\nname/order\n\nsteps k\n\nb_k\n\nb_{k-1}\n\nb_{k-2}\n\nb_{k-3}\n\nb_{k-4}\n\nAB1\n\n1\n\n0\n\n1\n\n(Euler)\n\n\n\n\n\nAB2\n\n2\n\n0\n\n\\frac{3}{2}\n\n-\\frac{1}{2}\n\n\n\n\n\nAB3\n\n3\n\n0\n\n\\frac{23}{12}\n\n-\\frac{16}{12}\n\n\\frac{5}{12}\n\n\n\nAB4\n\n4\n\n0\n\n\\frac{55}{24}\n\n-\\frac{59}{24}\n\n\\frac{37}{24}\n\n-\\frac{9}{24}\n\nAM1\n\n1\n\n1\n\n(Backward Euler)\n\n\n\n\n\n\n\nAM2\n\n1\n\n\\frac{1}{2}\n\n\\frac{1}{2}\n\n(Trapezoid)\n\n\n\n\n\nAM3\n\n2\n\n\\frac{5}{12}\n\n\\frac{8}{12}\n\n-\\frac{1}{12}\n\n\n\n\n\nAM4\n\n3\n\n\\frac{9}{24}\n\n\\frac{19}{24}\n\n-\\frac{5}{24}\n\n\\frac{1}{24}\n\n\n\nAM5\n\n4\n\n\\frac{251}{720}\n\n\\frac{646}{720}\n\n-\\frac{264}{720}\n\n\\frac{106}{720}\n\n-\\frac{19}{720}\n\nTable 6.6.2:Coefficients of backward differentiation formulas. All  have b_k\\neq 0 and b_{k-1} = \\cdots = b_0 = 0.\n\nname/order\n\nsteps k\n\na_{k-1}\n\na_{k-2}\n\na_{k-3}\n\na_{k-4}\n\nb_k\n\nBD1\n\n1\n\n1\n\n(Backward Euler)\n\n\n\n\n\n1\n\nBD2\n\n2\n\n\\frac{4}{3}\n\n-\\frac{1}{3}\n\n\n\n\n\n\\frac{2}{3}\n\nBD3\n\n3\n\n\\frac{18}{11}\n\n-\\frac{9}{11}\n\n\\frac{2}{11}\n\n\n\n\\frac{6}{11}\n\nBD4\n\n4\n\n\\frac{48}{25}\n\n-\\frac{36}{25}\n\n\\frac{16}{25}\n\n-\\frac{3}{25}\n\n\\frac{12}{25}","type":"content","url":"/multistep","position":1},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Generating polynomials"},"type":"lvl2","url":"/multistep#generating-polynomials","position":2},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Generating polynomials"},"content":"An alternative description of a multistep method is the generating polynomials  \\rho(z) &= z^k - a_{k-1} z^{k-1} - \\cdots - a_0,\\\\\n  \\sigma(z) &= b_k z^k + b_{k-1}z^{k-1} + \\cdots + b_0.\n\nFor example, the AB3 method is completely specified by  \\rho(z) = z^3-z^2, \\qquad \\sigma(z) = \\tfrac{1}{12}(23z^2-16z+5).\n\nLet ρ and σ be the generating polynomials of a multistep method. Then:\n\nThe polynomial \\rho(z) is monic (i.e., its leading term has a unit coefficient).\n\nThe degree of ρ is the number of steps k.\n\nThe degree of \\sigma(z) is k for an implicit method and less than k for an explicit method.\n\nThe connection between the generating polynomials and the numerical method requires a little abstraction. Let \\mathcal{Z} be a forward-shift operator, so that, for example, \\mathcal{Z} t_i = t_{i+1}, \\mathcal{Z}^3 u_{i-1} = u_{i+2}, and so on. With this, the difference formula \n\n(6.6.2) can be written concisely as  \\rho(\\mathcal{Z}) u_{i-k+1} = h \\sigma(\\mathcal{Z}) f_{i-k+1}.","type":"content","url":"/multistep#generating-polynomials","position":3},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Truncation and global error"},"type":"lvl2","url":"/multistep#truncation-and-global-error","position":4},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Truncation and global error"},"content":"The definition of local truncation error is easily extended to multistep methods.\n\nLTE and order of accuracy for a multistep IVP method\n\nFor the multistep formula defined by \n\n(6.6.2), the local truncation error is  \\tau_{i+1}(h) = \\frac{\\hat{u}(t_{i+1}) - a_{k-1}\\hat{u}(t_i) - \\cdots - a_0\n    \\hat{u}(t_{i-k+1})}{h} - \\bigl[ b_kf(t_{i+1},\\hat{u}(t_{i+1})) + \\cdots +\n  b_0f(t_{i-k+1},\\hat{u}(t_{i-k+1})) \\bigr].\n\nIf the local truncation error satisfies \\tau_{i+1}(h)=O(h^p), then p is the order of accuracy of the formula. If p>0, the method is consistent.\n\nThe first-order Adams–Moulton method is also known as backward Euler, because its difference equation is  {u}_{i+1} = u_i + hf_{i+1},\n\nwhich is equivalent to a backward-difference approximation to u'(t_{i+1}). AM1 is characterized by \\rho(z) = z-1 and \\sigma(z) = z.\n\nTo derive the LTE, we use the definition:\\begin{split}\n    h\\tau_{i+1}(h) &= \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - hf\\bigl(t_{i+1},\\hat{u}(t_{i+1})\\bigr) \\\\\n    &= \\hat{u}(t_i) + h\\hat{u}'(t_i) + \\frac{h^2}{2}\\hat{u}''(t_i) + O(h^3)\n    - \\hat{u}(t_i) -h \\hat{u}'(t_{i+1}) \\\\\n    &= h\\hat{u}'(t_i) + \\frac{h^2}{2}\\hat{u}''(t_i) + O(h^3)\n    - h[\\hat{u}'(t_i) + h\\hat{u}''(t_i) + O(h^2)]\\\\\n    &= - \\frac{h^2}{2}\\hat{u}''(t_i) + O(h^3).\n\\end{split}\n\nThus \\tau_{i+1}(h)=O(h) and AM1 (backward Euler) is a first-order method.\n\nThe AB2 method has the formula  {u}_{i+1} = u_i + h\\left(\\frac{3}{2} f_i - \\frac{1}{2} f_{i-1} \\right).\n\nThe generating polynomials are \\rho(z)=z^2-z and \\sigma(z) = (3z-1)/2. We find that the method is second order from the LTE:\\begin{split}\n  h\\tau_{i+1}(h)\n  & = \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - h\\left[\n    \\frac{3}{2}f(t_i,\\hat{u}(t_i)) - \\frac{1}{2}f(t_{i-1},\\hat{u}(t_{i-1}))\n    \\right]                                                                                   \\\\\n  & = \\hat{u}(t_i) + h\\hat{u}'(t_i) + \\frac{h^2}{2}\\hat{u}''(t_i) + \\frac{h^3}{6}\\hat{u}'''(t_i) + O(h^4) \\\\\n  & \\qquad - \\hat{u}(t_i) - \\frac{3h}{2}\\hat{u}'(t_i)  \\\\\n  &\\qquad  + \\frac{h}{2} \\bigl[\\hat{u}'(t_i) - h\\hat{u}''(t_i) + \\frac{h^2}{2}\\hat{u}'''(t_i) + O(h^3)\\bigr]        \\\\\n  & = \\frac{5h^3}{12}\\hat{u}'''(t_i) + O(h^4),\n\\end{split}\n\nso that \\tau_{i+1}(h)=O(h^2).\n\nAlthough we will not present the analysis, the main conclusion for the multistep methods in this section is the same as for one-step methods.\n\nThe global error of each method in \n\nTable 6.6.1 and \n\nTable 6.6.2 converges at the same order as the local truncation error.","type":"content","url":"/multistep#truncation-and-global-error","position":5},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Derivation of the formulas"},"type":"lvl2","url":"/multistep#derivation-of-the-formulas","position":6},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Derivation of the formulas"},"content":"Where do coefficients like those in \n\nTable 6.6.1 come from? There are different ways to answer that question, but Adams and BD methods have distinctive stories to tell. The derivation of Adams methods begins with the observation that  \\hat{u}(t_{i+1}) = \\hat{u}(t_i) + \\int_{t_i}^{t_{i+1}} \\hat{u}'(t) \\, dt =\n  \\hat{u}(t_i) + \\int_{t_i}^{t_{i+1}} f\\bigl(t,\\hat{u}(t)\\bigr) \\, dt.\n\nAs a result, a k-step Adams method always has \\rho(z)=z^k-z^{k-1}. While the integrand above is unknown over the interval of integration, we can approximate it by a polynomial interpolant of the historical values of f. That polynomial can be integrated analytically, leading to a derivation of the coefficients b_0,\\ldots,b_k.\n\nLet’s derive a one-step AM method using the two values (t_i,f_i) and (t_{i+1},f_{i+1}). The interpolating polynomial is the linear functionp(t) = f_i\\frac{t_{i+1}-t}{t_{i+1}-t_i} + f_{i+1}\\frac{t-t_i}{t_{i+1}-t_i}.\n\nThings become a little easier with the change of variable s=t-t_i and applying h=t_{i+1}-t_i:\\int_{t_i}^{t_{i+1}} p(t)  \\, d t = \\int_0^h p(t_i+s) \\, d s\n= h^{-1} \\int_0^h [ (h-s)f_i + s f_{i+1} ]\\, d s = \\frac{h}{2}(f_i + f_{i+1}).\n\nHence \\sigma(z)=\\tfrac{1}{2}z + \\tfrac{1}{2}. Like the trapezoid formula for a definite integral, AM2 computes the exact integral of a piecewise linear interpolant, and it often goes by the trapezoid name as well.\n\nIn AB methods, the interpolating polynomial has degree k-1, which means that its interpolation error is O(h^k). Upon integrating we get a local error of O(h^{k+1}), which reduces to a global error of O(h^k). The AM interpolating polynomial is one degree larger, so its order of accuracy is one higher for the same number of steps.\n\nThe idea behind backward differentiation formulas is complementary to that for Adams: Interpolate solution values {u}_{i+1},\\ldots,u_{i-k+1} by a polynomial q, and then, motivated by f(t,\\hat{u})=\\hat{u}'(t), set  f_{i+1} =q'(t_{i+1}).\n\nThe quantity q'(t_{i+1}) can be approximated by a finite difference of the past solution values, leading to the coefficients of \\rho(z) and \\sigma(z)=b_k z^k.\n\nConsulting \n\nTable 5.4.2, we find the finite-difference approximationq'(t_{i+1}) \\approx \\frac{1}{h} \\left( \\frac{3}{2} u_{i+1} - 2 u_i + \\frac{1}{2} u_{i-1} \\right),\n\nfrom which we geth f_{i+1} = \\frac{3}{2} u_{i+1} - 2 u_i + \\frac{1}{2} u_{i-1}.\n\nRearranging and Normalizing by the coefficient of u_{i+1} gives \\rho(z)=z^2 + \\tfrac{4}{3}z - \\tfrac{1}{3} and \\sigma(z) = \\tfrac{2}{3}z^2, which is the BD2 method.","type":"content","url":"/multistep#derivation-of-the-formulas","position":7},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Exercises"},"type":"lvl2","url":"/multistep#exercises","position":8},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Exercises"},"content":"✍ For each method, write out the generating polynomials \\rho(z) and \\sigma(z).\n\n(a) AM2,\n(b) AB2,\n(c) BD2,\n(d) AM3,\n(e) AB3.\n\n✍ Write out by hand an equation that defines the first solution value u_1 produced by AM1 (backward Euler) for each IVP. (Reminder: This is an implicit formula.)\n\n(a) u' = -2t u, \\quad 0 \\le t \\le 2, \\quad u_0 = 2, \\quad h = 0.2\n\n(b) u' = u + t, \\quad 0 \\le t \\le 1, \\quad u_0 = 2, \\quad h = 0.1\n\n(c) (1+x^3)uu' = x^2,\\quad 0 \\le x \\le 3, \\quad u_0=1, , \\quad h = 0.5\n\n✍ Do the preceding exercise for AM2 (trapezoid) instead of backward Euler.\n\n✍ For each method, find the leading term in the local truncation error using \n\n(6.6.8).\n\n(a) AM2,\n(b) AB2,\n(c) BD2.\n\n✍/ ⌨ For each method, find the leading term in the local truncation error using \n\n(6.6.8). (Computer algebra is recommended.)\n\n(a) AM3,\n(b) AB3,\n(c) BD4.\n\n✍ A formula for the quadratic polynomial interpolant through the points (s_1,y_1), (s_2,y_2), and (s_3,y_3) isp(x) = \\frac{(x-s_2)(x-s_3)}{(s_1-s_2)(s_1-s_3)}\\,y_1 +\n        \\frac{(x-s_1)(x-s_3)}{(s_2-s_1)(s_2-s_3)}\\,y_2 +\n        \\frac{(x-s_1)(x-s_2)}{(s_3-s_1)(s_3-s_2)}\\,y_3.\n\n(a) Use \n\n(6.6.13) and a polynomial interpolant through three points to derive the coefficients of the AM3 method.\n\n(b) Use \n\n(6.6.16) and a polynomial interpolant through three points to derive the coefficients of the BD2 method.\n\n✍ By doing series expansion about the point z=1, show for BD2 that\\frac{\\rho(z)}{\\sigma(z)} - \\log(z-1) = O\\bigl( (z-1)^3 \\bigr).\n\n✍/ ⌨  By doing series expansion about the point z=1, show for AB3 and AM3 that\\frac{\\rho(z)}{\\sigma(z)} - \\log(z-1) = O\\bigl( (z-1)^4 \\bigr).\n\n(Computer algebra is recommended.)\n\nIf we must use an RK method to start anyway, why bother with multistep formulas at all? The answer is that multistep methods can be more efficient in some problems, even at the same order of accuracy.","type":"content","url":"/multistep#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-5","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"We use Runge-Kutta methods as a class to represent what are also called single-step or one-step methods. A gentle introduction to these and other kinds of IVP methods can be found in Atkinson and Han \n\nAtkinson (1989). More advanced introductions are given in Corless and Fillon \n\nCorless & Fillion (2013) and Iserles \n\nIserles (1996). The most definitive reference is by Hairer et al. \n\nHairer et al. (2008).\n\nA dated but still interesting article about the built-in functions for solving initial value problems in MATLAB is by Shampine \n\nShampine & Reichelt (1997). Methods for a more general type of problem known as differential–algebraic equations are covered in Brenan et al. \n\nBrenan et al. (1996).\n\nInteresting history of IVP methods can be found at\n\n\nthe SIAM website, where C. W. Gear gives both an \n\noral history and an \n\narticle reprinted from \n\nNash (1990).","type":"content","url":"/next-5","position":1},{"hierarchy":{"lvl1":"Initial-value problems for ODEs"},"type":"lvl1","url":"/overview-5","position":0},{"hierarchy":{"lvl1":"Initial-value problems for ODEs"},"content":"Without precise calculations we could fly right through a star or bounce too close to a supernova and that’d end your trip real quick, wouldn’t it?\n\nHan Solo, Star Wars: A New Hope\n\nQuantities that change continuously in time or space are often modeled by differential equations. When everything depends on just one independent variable, we call the model an ordinary differential equation (ODE).  Differential equations need supplemental conditions to define both the modeling situation and the theoretical solutions uniquely. The initial-value problem (IVP), in which all of the conditions are given at a single value of the independent variable, is the simplest situation. Often the independent variable in this case represents time.\n\nMethods for IVPs usually start from the known initial value and iterate or “march” forward from there. There is a large number of them, owing in part to differences in accuracy, stability, and convenience. The most broadly important methods fall into one of two camps: Runge–Kutta and linear multistep formulas. Each type introduces its own complications, and we will consider them separately.","type":"content","url":"/overview-5","position":1},{"hierarchy":{"lvl1":"Runge–Kutta methods"},"type":"lvl1","url":"/rk","position":0},{"hierarchy":{"lvl1":"Runge–Kutta methods"},"content":"We come now to one of the major and most-used types of methods for initial-value problems: Runge–Kutta (RK) methods. They are one-step methods in the sense of \n\n(6.2.7), though they are not often written in that form. RK methods boost the accuracy past first order by evaluating the ODE function f(t,u) more than once per time step.","type":"content","url":"/rk","position":1},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"A second-order method"},"type":"lvl2","url":"/rk#a-second-order-method","position":2},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"A second-order method"},"content":"Consider a series expansion of the exact solution to u'=f(t,u),\\hat{u}(t_{i+1}) = \\hat{u}(t_i) + h \\hat{u}'(t_i) + \\frac{1}{2}h^2 \\hat{u}''(t_i) + O(h^3) .\n\nIf we replace \\hat{u}' by f and keep only the first two terms on the right-hand side, we would obtain the Euler method. To get more accuracy we will need to compute or estimate the third term as well. Note that\\hat{u}'' = f' = \\frac{d f}{d t} = \\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial u} \\frac{d u}{d t} = f_t + f_u f,\n\nwhere we have applied the multidimensional chain rule to the derivative, because both of the arguments of f depend on t. Using this expression in \n\n(6.4.1), we obtain  \\hat{u}(t_{i+1}) = \\hat{u}(t_i) + h\\left[f\\bigl(t_i,\\hat{u}(t_i)\\bigr) +\n    \\frac{h}{2}f_t\\bigl(t_i,\\hat{u}(t_i)\\bigr) +\n    \\frac{h}{2}f\\bigl(t_i,\\hat{u}(t_i)\\bigr)\\,f_u\\bigl(t_i,\\hat{u}(t_i)\\bigr)\\right] \\\\\n  + O(h^3).\n\nWe have no desire to calculate and then code those partial derivatives of f directly; an approximate approximation is called for. Observe that  f\\bigl(t_i+\\alpha,\\hat{u}(t_i)+\\beta\\bigr) = f\\bigl(t_i,\\hat{u}(t_i)\\bigr) +\n  \\alpha f_t\\bigl(t_i,\\hat{u}(t_i)\\bigr) + \\beta f_u\\bigl(t_i,\\hat{u}(t_i)\\bigr) +\n  O\\bigl(\\alpha^2 + |\\alpha\\beta| + \\beta^2\\bigr).\n\nMatching this expression to the term in brackets in \n\n(6.4.3), it seems natural to select \\alpha = h/2 and \\beta = \\frac{1}{2}h f\\bigl(t_i,\\hat{u}(t_i)\\bigr). Doing so, we find  \\hat{u}(t_{i+1}) = \\hat{u}(t_i) + h\\left[f\\bigl(t_i+\\alpha,\\hat{u}(t_i)+\\beta\\bigr)\\right] +\n  O(h\\alpha^2 + h|\\alpha \\beta| + h\\beta^2 + h^3).\n\nTruncation of the series here results in a new one-step method.\n\nImproved Euler method (IE2)\n\nThe improved Euler method is the one-step formula{u}_{i+1} = u_i +  hf\\left(t_i+\\tfrac{1}{2}h,u_i+\\tfrac{1}{2}h f(t_i,u_i)\\right).\n\nThanks to the definitions above of α and β, the omitted terms are of size  O(h\\alpha^2 + h|\\alpha \\beta| + h\\beta^2 + h^3) = O(h^3).\n\nTherefore h\\tau_{i+1}=O(h^3), and the order of accuracy of improved Euler is two.","type":"content","url":"/rk#a-second-order-method","position":3},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Implementation"},"type":"lvl2","url":"/rk#implementation","position":4},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Implementation"},"content":"Runge–Kutta methods are called multistage methods. We can see why if we interpret \n\n(6.4.6) from the inside out. In the first stage, the method takes an Euler half-step to time t_i+\\frac{1}{2}h:\\begin{split}\n  k_1 &= h f(t_i,u_i), \\\\\n  v &= u_i + \\tfrac{1}{2}k_1.\n\\end{split}\n\nThe second stage employs an Euler-style strategy over the whole time step, but using the value from the first stage to get the slope:\\begin{split}\n  k_2 &= h f\\left(t_i+\\tfrac{1}{2}h,v\\right),\\\\\n  {u}_{i+1} &= u_i + k_2.\n\\end{split}\n\nOur implementation of IE2 is shown in \n\nFunction 6.4.1.\n\nie2\n\nImproved Euler method for an IVP\n\n\"\"\"\n    ie2(ivp,n)\n\nApply the Improved Euler method to solve the given IVP using `n`\ntime steps. Returns a vector of times and a vector of solution\nvalues.\n\"\"\"\nfunction ie2(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initialize output.\n    u = fill(float(ivp.u0),n+1)\n\n    # Time stepping.\n    for i in 1:n\n        uhalf = u[i] + h/2*ivp.f(u[i],ivp.p,t[i]);\n        u[i+1] = u[i] + h*ivp.f(uhalf,ivp.p,t[i]+h/2);\n    end\n    return t,u\nend\n\nImproved Euler method for an IVP\n\nfunction [t, u] = ie2(ivp, a, b, n)\r\n% IE2    Improved Euler method for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping. \r\nfor i = 1:n \r\n    uhalf = u(:, i) + h/2 * du_dt(t(i), u(:, i), p);\r\n    u(:, i+1) = u(:, i) + h * du_dt(t(i) + h/2, uhalf, p);\r\nend\n\nImproved Euler method for an IVP\n\ndef ie2(dudt, tspan, u0, n):\n    \"\"\"\n    ie2(dudt,tspan,u0,n)\n\n    Apply the Improved Euler method to solve the vector-valued IVP u'=`dudt`(u,p,t) over the\n    interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps. Returns a vector\n    of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        uhalf = u[i] + h / 2 * dudt(t[i], u[i])\n        u[i+1] = u[i] + h * dudt(t[i] + h / 2, uhalf)\n\n    return t, u.T","type":"content","url":"/rk#implementation","position":5},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"More Runge–Kutta methods"},"type":"lvl2","url":"/rk#more-runge-kutta-methods","position":6},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"More Runge–Kutta methods"},"content":"While it is interesting to interpret IE2 as a pair of Euler-like steps, the Taylor series derivation is the only way to see that it will be more accurate than Euler, and it is also the path to deriving other methods. Moving to higher orders of accuracy requires introducing additional stages, each having free parameters so that more terms in the series may be matched. The amount of algebra grows rapidly in size and complexity, though there is a sophisticated theory for keeping track of it. We do not give the derivation details.\n\nA generic s-stage RK method takes the form  \\begin{split}\n    k_1 &= h f(t_i,u_i),\\\\\n    k_2 &= h f(t_i+c_1h,u_i + a_{11}k_1),\\\\\n    k_3 &= h f(t_i+c_2h, u_i + a_{21}k_1 + a_{22}k_2),\\\\\n    &\\vdots\\\\\n    k_s &= h f(t_i + c_{s-1}h, u_i + a_{s-1,1}k_1 + \\cdots +\n    a_{s-1,s-1}k_{s-1}),\\\\\n    \\mathbf{u}_{i+1} &= u_i + b_1k_1 + \\cdots + b_s k_s.\n  \\end{split}\n\nThis recipe is completely determined by the number of stages s and the constants a_{ij}, b_j, and c_i.  Often an RK method is presented as just a table of these numbers, as in  \\begin{array}{r|ccccc}\n    0 &  &  & & & \\\\\n    c_1 & a_{11} & & &\\\\\n    c_2 & a_{21} & a_{22} & & &\\\\\n    \\vdots & \\vdots & & \\ddots & &\\\\\n    c_{s-1} & a_{s-1,1} & \\cdots & & a_{s-1,s-1}&\\\\[1mm] \\hline\n    \\rule{0pt}{2.25ex}    & b_1 & b_2 & \\cdots & b_{s-1} & b_s\n  \\end{array}\n\nFor example, IE2 is given by  \\begin{array}{r|cc}\n    \\rule{0pt}{2.75ex}0 &  &  \\\\\n    \\rule{0pt}{2.75ex}\\frac{1}{2} & \\frac{1}{2} &\\\\[1mm] \\hline\n    \\rule{0pt}{2.75ex}& 0 & 1\n  \\end{array}\n\nHere are two more two-stage, second-order methods, modified Euler and Heun’s method, respectively:  \\begin{array}{r|cc}\n    \\rule{0pt}{2.75ex}0 &  &  \\\\\n    \\rule{0pt}{2.75ex}1 & 1 &\\\\[1mm] \\hline\n    \\rule{0pt}{2.75ex}& \\frac{1}{2} & \\frac{1}{2}\n  \\end{array}\n  \\qquad \\qquad\n  \\begin{array}{r|cc}\n   \\rule{0pt}{2.75ex} 0 &  &  \\\\\n   \\rule{0pt}{2.75ex} \\frac{2}{3} & \\frac{2}{3} &\\\\[1mm] \\hline\n   \\rule{0pt}{2.75ex} & \\frac{1}{4} & \\frac{3}{4}\n  \\end{array}\n\nAttention\n\nEuler, improved Euler (IE2), and modified Euler (ME2) are all distinct numerical methods.\n\nThe most commonly used RK method, and perhaps the most popular IVP method of all, is the fourth-order one given by  \\begin{array}{r|cccc}\n    \\rule{0pt}{2.75ex}0 &  & & & \\\\\n    \\rule{0pt}{2.75ex}\\frac{1}{2} & \\frac{1}{2} & & &\\\\\n    \\rule{0pt}{2.75ex}\\frac{1}{2} & 0 & \\frac{1}{2} & &\\\\\n    \\rule{0pt}{2.75ex}1 & 0 & 0 & 1\\\\[1mm] \\hline\n    \\rule{0pt}{2.75ex}& \\frac{1}{6} & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{6}\n  \\end{array}\n\nThis formula is often referred to as the fourth-order RK method, even though there are many others, and we refer to it as RK4.  Written out, the recipe is as follows.\n\nFourth-order Runge–Kutta method (RK4)  \\begin{split}\n    k_1 &= hf(t_i,u_i), \\\\\n    k_2 &= hf(t_i+h/2,u_i+k_1/2),\\\\\n    k_3 &= hf(t_i+h/2,u_i+k_2/2),\\\\\n    k_4 &= hf(t_i+h,u_i+k_3),\\\\\n    u_{i+1} &= u_i + \\frac{1}{6} k_1 + \\frac{1}{3} k_2 + \\frac{1}{3} k_3 + \\frac{1}{6} k_4.\n  \\end{split}\n\nOur implementation is given in \n\nFunction 6.4.2.\n\nrk4\n\nFourth-order Runge-Kutta for an IVP\n\n\"\"\"\n    rk4(ivp,n)\n\nApply the common Runge-Kutta 4th order method to solve the given\nIVP using `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk4(ivp,n)\n\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initialize output.\n    u = fill(float(ivp.u0),n+1)\n\n    # Time stepping.\n    for i in 1:n\n        k₁ = h*ivp.f( u[i],      ivp.p, t[i]     )\n        k₂ = h*ivp.f( u[i]+k₁/2, ivp.p, t[i]+h/2 )\n        k₃ = h*ivp.f( u[i]+k₂/2, ivp.p, t[i]+h/2 )\n        k₄ = h*ivp.f( u[i]+k₃,   ivp.p, t[i]+h   )\n        u[i+1] = u[i] + (k₁ + 2(k₂+k₃) + k₄)/6\n    end\n    return t,u\nend\n\nFourth-order Runge-Kutta for an IVP\n\nfunction [t, u] = rk4(ivp, a, b, n)\r\n% RK4    Fourth-order Runge-Kutta for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  k1 = h * du_dt( t(i),       u(:, i)       , p);\r\n  k2 = h * du_dt( t(i) + h/2, u(:, i) + k1/2, p );\r\n  k3 = h * du_dt( t(i) + h/2, u(:, i) + k2/2, p );\r\n  k4 = h * du_dt( t(i) + h,   u(:, i) + k3  , p);\r\n  u(:, i+1) = u(:, i) + (k1 + 2*(k2 + k3) + k4) / 6;\r\nend\n\nFourth-order Runge-Kutta for an IVP\n\ndef rk4(dudt, tspan, u0, n):\n    \"\"\"\n    rk4(dudt,tspan,u0,n)\n\n    Apply \"the\" Runge-Kutta 4th order method to solve the vector-valued IVP u'=`dudt`(u,p,t)\n    over the interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps.\n    Return a vector of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        k1 = h * dudt(t[i], u[i])\n        k2 = h * dudt(t[i] + h / 2, u[i] + k1 / 2)\n        k3 = h * dudt(t[i] + h / 2, u[i] + k2 / 2)\n        k4 = h * dudt(t[i] + h, u[i] + k3)\n        u[i+1] = u[i] + (k1 + 2 * (k2 + k3) + k4) / 6\n\n    return t, u.T\n\nConvergence of Runge–Kutta methods\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf(u, p, t) = sin((t + u)^2)\ntspan = (0.0, 4.0)\nu₀ = -1.0\n\nivp = ODEProblem(f, u₀, tspan)\n\nWe use a DifferentialEquations solver to construct an accurate approximation to the exact solution.\n\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = [round(Int, 2 * 10^k) for k in 0:0.5:3]\nerr_IE2, err_RK4 = [], []\nfor n in n\n    t, u = FNC.ie2(ivp, n)\n    push!(err_IE2, maximum(@.abs(u_ref(t) - u)))\n    t, u = FNC.rk4(ivp, n)\n    push!(err_RK4, maximum(@.abs(u_ref(t) - u)))\nend\n\npretty_table([n err_IE2 err_RK4], header=[\"n\", \"IE2 error\", \"RK4 error\"])\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nplot([2n 4n], [err_IE2 err_RK4], m=3, label=[\"IE2\" \"RK4\"],\n    xaxis=(:log10, \"f-evaluations\"), yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of RK methods\", leg=:bottomleft)\n\nplot!(2n, 1e-5 * (n / n[end]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\nplot!(4n, 1e-10 * (n / n[end]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.\n\nConvergence of Runge–Kutta methods\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nWe use a built-in solver to construct an accurate approximation to the exact solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = round(2 * 10.^(0:0.5:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    [t, u] = ie2(ivp, a, b, n(i));\n    err(i, 1) = norm(u_ref(t) - u, Inf);\n    [t, u] = rk4(ivp, a, b, n(i));\n    err(i, 2) = norm(u_ref(t) - u, Inf);\nend\n\ndisp(table(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"IE2 error\", \"RK4 error\"]))\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nclf, loglog([2*n 4*n], err, '-o')\nhold on\nloglog(2*n, 1e-5 * (n / n(end)) .^ (-2), '--')\nloglog(4*n, 1e-10 * (n / n(end)) .^ (-4), '--')\nxlabel(\"f-evaluations\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of RK methods\")\nlegend(\"IE2\", \"RK4\", \"O(n^{-2})\", \"O(n^{-4})\", \"location\", \"southwest\")\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.\n\nConvergence of Runge–Kutta methods\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We start by getting a reference solution to validate against.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = -1.0\nsol = solve_ivp(du_dt, tspan, [u0], dense_output=True, atol=1e-13, rtol=1e-13)\nu_ref = sol.sol\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = array([int(2 * 10**k) for k in linspace(0, 3, 7)])\nerr = {\"IE2\" : [], \"RK4\" : []}\nresults = PrettyTable([\"n\", \"IE2 error\", \"RK4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ie2(du_dt, tspan, u0, n[i])\n    err[\"IE2\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    t, u = FNC.rk4(du_dt, tspan, u0, n[i])\n    err[\"RK4\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[\"IE2\"][-1], err[\"RK4\"][-1]])\n\nprint(results)\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nloglog(2 * n, err[\"IE2\"], \"-o\", label=\"IE2\")\nloglog(4 * n, err[\"RK4\"], \"-o\", label=\"RK4\")\nplot(2 * n, 0.5 * err[\"IE2\"][-1] * (n / n[-1])**(-2), \"--\", label=\"2nd order\")\nplot(4 * n, 0.5 * err[\"RK4\"][-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"f-evaluations\"),  ylabel(\"inf-norm error\")\nlegend()\ntitle(\"Convergence of RK methods\");\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/rk#more-runge-kutta-methods","position":7},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Efficiency"},"type":"lvl2","url":"/rk#efficiency","position":8},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Efficiency"},"content":"As with rootfinding and integration, the usual point of view is that evaluations of f are the only significant computations and are therefore to be minimized in number. One of the most important characteristics of a multistage method is that each stage requires an evaluation of f; that is, a single time step of an s-stage method requires s evaluations of f.\n\nThe error decreases geometrically as s is incremented, so trading a stage for an increase in order is a good deal. But s=5, 6, or 7 gives a maximal order of accuracy of s-1; this decreases to s-2 for s=8 and s=9, etc. Fourth order is considered adequate and the sweet spot for many applications.","type":"content","url":"/rk#efficiency","position":9},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Exercises"},"type":"lvl2","url":"/rk#exercises","position":10},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Exercises"},"content":"must stay as #1\n\n✍ For each IVP, write out (possibly using a calculator) the first time step of the improved Euler method with h=0.2.\n\n(a) u' = -2t u, \\ 0 \\le t \\le 2, \\ u(0) = 2;\\  \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ 0 \\le t \\le 1, \\ u(0) = 2;\\  \\hat{u}(t) = -1-t+3e^t\n\n(c) (1+x^3)uu' = x^2,\\ 0 \\le x \\le 3, \\ u(0) = 1;\\ \\hat{u}(x) = [1+(2/3)\\ln (1+x^3)]^{1/2}\n\n✍ Use the modified Euler method to solve the problems in the preceding exercise.\n\n⌨ Modify \n\nFunction 6.4.2 to implement the modified Euler method. Test your function on the IVP in part (a) of Exercise 1 by solving with n=30,60,90,\\ldots,300 and plotting the convergence of the error at the final time together with a line showing O(n^{-2}).\n\n✍ Use Heun’s method to solve the problems in \n\nExercise 1 above.\n\n⌨ Modify \n\nFunction 6.4.2 to implement Heun’s method. Test your function on the IVP in part (a) of Exercise 1 by solving with n=30,60,90,\\ldots,300 and plotting the convergence of the error at the final time together with a line showing O(n^{-2}).\n\n✍ Use RK4 to solve the problems in \n\nExercise 1 above.\n\n✍ Using \n\n(6.4.3) and \n\n(6.4.4), show that the modified Euler method has order of accuracy at least 2.\n\n✍ Using \n\n(6.4.3) and \n\n(6.4.4), show that Heun’s method has order of accuracy at least 2.\n\n⌨ For each IVP, compute the solution using \n\nFunction 6.4.2. (i) Plot the solution for n=300. (ii) For n=100,200,300,\\ldots,1000, compute the error at the final time and make a log-log convergence plot, including a reference line for fourth-order convergence.\n\n(a) u''+ 9u = 9t, \\: 0< t< 2\\pi, \\: u(0) = 1,\\: u'(0) = 1; \\: \\hat{u}(t) = t+\\cos (3t)\n\n(b) u''+ 9u = \\sin(2t), \\: 0< t< 2\\pi, \\: u(0) = 2,\\: u'(0) = 1;\n\n\\quad \\hat{u}(t) = (1/5) \\sin(3t) + 2 \\cos (3t)+  (1/5) \\sin (2t)\n\n(c) u''- 9u = 9t, \\: 0< t< 1, \\: u(0) = 2,\\: u'(0) = -1; \\: \\hat{u}(t) = e^{3t} + e^{-3t}-t\n\n(d) u''+ 4u'+ 4u = t, \\: 0< t< 4, \\: u(0) = 1,\\: u'(0) = 3/4; \\: \\hat{u}(t) = (3t+5/4)e^{-2t} + (t-1)/4\n\n(e) x^2 y'' +5xy' + 4y = 0,\\: 1<x<e^2, \\: y(1) = 1, \\: y'(1) = -1, \\: \\hat{y}(x) = x^{-2}( 1 + \\ln x)\n\n(f) 2 x^2 y'' +3xy' - y = 0,\\: 1<x<16, \\: y(1) = 4, \\: y'(1) = -1, \\: \\hat{y}(x) = 2(x^{1/2} + x^{-1})\n\n(g) x^2 y'' -xy' + 2y = 0,\\: 1<x<e^{\\pi}, \\: y(1) = 3, \\: y'(1) = 4;\n\n\\quad \\hat{y}(x) = x \\left[ 3 \\cos \\left( \\ln x \\right)+\\sin \\left( \\ln x \\right) \\right]\n\n(h) x^2 y'' + 3xy' + 4y = 0,\\: e^{\\pi/12} < x < e^{\\pi}, \\: y(e^{\\pi/12}) = 0,  \\: y'(e^{\\pi/12}) = -6;\n\n\\quad \\hat{y}(x) = x^{-1} \\left[ 3 \\cos \\left( 3 \\ln x \\right)+\\sin \\left( 3 \\ln x \\right) \\right]\n\n⌨ Do \n\nExercise 6.3.4, but using \n\nFunction 6.4.2 instead of solve.\n\n✍ Consider the problem u'=c u, u(0) = 1 for constant c and t>0.\n\n(a) Find an explicit formula in terms of h and c for u_{i+1}/u_i in the modified Euler method.\n\n(b) Show that if ch=-3, then |u_i|\\to\\infty as i\\to\\infty while the exact solution \\hat{u}(t) approaches zero as t\\to\\infty.\n\nAmericans tend to pronounce these German names as “run-ghuh kut-tah.”","type":"content","url":"/rk#exercises","position":11},{"hierarchy":{"lvl1":"IVP systems"},"type":"lvl1","url":"/systems","position":0},{"hierarchy":{"lvl1":"IVP systems"},"content":"Few applications involve an initial-value problem with just a single dependent variable. Usually there are multiple unknowns and a system of equations to define them.\n\nVariations of the following model are commonly seen in ecology:  \\begin{split}\n    \\frac{d y}{d t} &= y(1-\\alpha y) - \\frac{yz}{1+\\beta y}, \\\\\n    \\frac{d z}{d t} &= -z + \\frac{yz}{1+\\beta y},\n  \\end{split}\n\nwhere α and β are positive constants. This model is a system of two differential equations for the unknown functions y(t), which could represent a prey species or susceptible host, and z(t), which could represent a predator species or infected population.  We refer to this as a predator–prey model. Both of the equations involve both of the unknowns, with no clear way to separate them.\n\nWe can pack the two dependent variables y and z into a vector-valued function of time, \\mathbf{u}(t), writing\\begin{split}\n  u_1'(t) &= f_1(t,\\mathbf{u}) =  u_1(1-au_1) - \\frac{u_1 u_2}{1+bu_1},\\\\\n  u_2'(t) &= f_2(t,\\mathbf{u}) = -u_2 + \\frac{u_1 u_2}{1+bu_1},\n\\end{split}\n\nand identifying u_1=y, u_2=z.\n\nWe now upgrade our IVP definition, \n\nDefinition 6.1.1.\n\nVector-valued IVP / IVP system\n\nA vector-valued first-order initial-value problem (IVP) is  \\mathbf{u}'(t) = \\mathbf{f}\\bigl(t,\\mathbf{u}(t)\\bigr), \\qquad a \\le t \\le b, \\qquad\n  \\mathbf{u}(a)=\\mathbf{u}_0,\n\nwhere \\mathbf{u}(t) is m-dimensional. If \\mathbf{f}(t,\\mathbf{u})=\\mathbf{A}(t)\\mathbf{u}(t)+ \\mathbf{g}(t), the differential equation is linear; otherwise, it is nonlinear.\n\nWe use the terms IVP system and vector-valued IVP interchangeably; a system of scalar IVPs can be put into the form of \n\n(6.3.3) by appropriate definitions of \\mathbf{u} and \\mathbf{f}, as shown in \n\nExample 6.3.1.","type":"content","url":"/systems","position":1},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Numerical solutions"},"type":"lvl2","url":"/systems#numerical-solutions","position":2},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Numerical solutions"},"content":"The generalization of any scalar IVP solver to handle systems is straightforward. Consider Euler’s method, which in system form becomes  \\begin{split}\n    \\mathbf{u}_{i+1} &= \\mathbf{u}_i + h\\,\\mathbf{f}(t_i,\\mathbf{u}_i), \\qquad i=0,\\ldots,n-1.\n  \\end{split}\n\nThe vector difference equation \n\n(6.3.4) is just Euler’s formula applied simultaneously to each component of the ODE system. Because operations such as addition and multiplication translate easily from scalars to vectors, \n\nFunction 6.2.2 that we wrote for scalar IVPs works for systems as well. Practically speaking, the only changes that must be made are that the initial condition and the ODE function have to be coded to use vectors.\n\nPredator-prey model\n\nWe encode the predator–prey equations via a function.\n\nfunction predprey(u, p, t)\n    α, β = p      # rename parameters for convenience\n    y, z = u      # rename solution components\n    s = (y * z) / (1 + β * y)     # appears in both equations\n    return [y * (1 - α * y) - s, -z + s]\nend;\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable.\n\nu₀ = [1, 0.01]\ntspan = (0.0, 60.0)\nα, β = 0.1, 0.25\n\nivp = ODEProblem(predprey, u₀, tspan, [α, β])\n\nYou can use any DifferentialEquations solver on the IVP system.\n\nsol = solve(ivp, Tsit5());\nplot(sol, label=[\"prey\" \"predator\"], title=\"Predator-prey solution\")\n\nWe can find the discrete values used to compute the interpolated solution. The sol.u value is a vector of vectors.\n\nt, u = sol.t, sol.u    # extract times and solution values\n@show size(u);\n@show t[20];\n@show u[20];\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt, u = FNC.euler(ivp, 1200);\n\nThe solution u is a vector of [prey,predator] 2-vectors for each of the discrete times in t. Manipulating the vector-of-vectors output can be a little tricky. Here, we convert it to an n\\times 2 matrix. Each column is one component, while each row is a single value of t.\n\nu = [u[j] for u in u, j in 1:2]\nplot!(t[1:3:end], u[1:3:end, :], l=(1, :black), m=2,\n    label=[\"Euler prey\" \"Euler predator\"])\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nYou can use idxs in the plot of a solution produced by solve to specify the components of the solution that appear on each axis.\n\nplot(sol, idxs=(1, 2), title=\"Predator-prey in the phase plane\",\n    xlabel=L\"y\", ylabel=L\"z\")\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nPredator-prey model\n\nWe encode the predator–prey equations via a function, defined here externally.\n\nfunction du_dt = predprey(t, u, p)\n    alpha = p(1);  beta = p(2);\n    y = u(1);      z = u(2);\n    s = (y * z) / (1 + beta * y);  % appears in both equations\n    du_dt = [ y * (1 - alpha * y) - s;  -z + s ];\nend\n\n\nThe values of alpha and beta are parameters that influence the solution of the IVP. We use the Parameters field of the IVP object to define them for the solver, which in turn passes them as the third argument into our ODE function.\n\nu0 = [1; 0.01];    % column vector\np = [0.1, 0.25];\nivp = ode;\nivp.ODEFcn = @f63_predprey;\nivp.InitialValue = u0;\nivp.Parameters = p;\nsol = solve(ivp, 0, 60);\nsize(sol.Solution)\n\nEach column of the Solution field is the solution vector \\mathbf{u} at a particular time; each row is a component of \\mathbf{u} over all time.\n\nclf\nplot(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle('Predator-prey solution')  % ignore this line\nlegend('prey', 'predator')  % ignore this line\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\n[t, u] = eulerivp(ivp, 0, 60, 1200);\n\nhold on\nplot(t, u, '.')\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nclf\nplot(u(1, :), u(2, :))\ntitle(\"Predator-prey in the phase plane\")\nxlabel(\"y\")\nylabel(\"z\")\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nPredator-prey model\n\nWe encode the predator–prey equations via a function.\n\ndef predprey(t, u):\n    y, z = u                        # rename for convenience\n    s = (y * z) / (1 + beta * y)    # appears in both equations\n    return array([y * (1 - alpha * y) - s, -z + s])\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable. These are given in the call to solve_ivp.\n\nfrom scipy.integrate import solve_ivp\nu0 = array([1, 0.01])\ntspan = [0.0, 80.0]\nalpha, beta = 0.1, 0.25\nsol = solve_ivp(predprey, tspan, u0, dense_output=True)\nprint(f\"solved with {sol.y.shape[1]} time steps\")\n\nAs in scalar problems, the solution object has fields t and y that contain the values of the independent and dependent variables, respectively. Each row of y represents one component of the solution at every time step, and each column of y is the entire solution vector at one time step. Since we used dense_output=True, there is also a method sol that can be used to evaluate the solution at any time.\n\nt = linspace(0, 80, 1200)\nu = vstack([sol.sol(t[i]) for i in range(t.size)]).T    # same shape as sol.y\nfig, ax = subplots()\nax.plot(t, u[0, :], label=\"prey\")\nax.plot(t, u[1, :], label=\"predator\")\nxlabel(\"$t$\"), ylabel(\"population\")\ntitle(\"Predator-prey solution\")\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt_E, u_E = FNC.euler(predprey, tspan, u0, 800)\nax.scatter(t_E, u_E[0, :], label=\"prey (Euler)\", s=1)\nax.scatter(t_E, u_E[1, :], label=\"predator (Euler)\", s=2)\nax.legend()\nfig\n\nYou can see above that the Euler solution is not very accurate. When the solution has two components, it’s common to plot the it in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nplot(u[0, :], u[1, :])\nxlabel(\"prey\"), ylabel(\"predator\")\ntitle(\"Predator-prey phase plane\")\n\nFrom this plot we can see that the solution approaches a periodic one, which in the phase plane is represented by a closed path.\n\nIn the rest of this chapter we present methods as though they are for scalar equations, but their application to systems is taken for granted. The generalization of error analysis can be more complicated, but our statements about order of accuracy and other properties are true for systems as well as scalars. The codes are all written to accept systems.","type":"content","url":"/systems#numerical-solutions","position":3},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Transformation of high-order systems"},"type":"lvl2","url":"/systems#transformation-of-high-order-systems","position":4},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Transformation of high-order systems"},"content":"Fortunately, the ability to solve first-order ODE systems implies the ability to solve systems of higher differential order, too. The reason is that there is a systematic way to turn a higher-order problem into a first-order one of higher dimension.\n\nConsider the nonlinear initial-value problem  y''+(1+y')^3 y = 0, \\qquad y(0)= y_0, \\quad y'(0) = 0.\n\nIn order to write this problem as a first-order system we define two scalar unknown functions, u_1 = y and u_2 = y'. With these definitions, we have the two differential equations\\begin{split}\n  u_1' &= u_2, \\\\\n  u_2' &= -(1+u_2)^3 u_1,\n\\end{split}\n\nwhich is a first-order system in two dimensions. The initial\ncondition of the system is  u_1(0) = y_0, \\quad u_2(0) = 0.\n\nTwo identical pendulums suspended from the same rod and swinging in parallel planes can be modeled as the second-order system\\begin{split}\n  \\theta_1''(t) +\\gamma \\theta_1' + \\frac{g}{L} \\sin \\theta_1 +\n  k(\\theta_1-\\theta_2) &= 0,\\\\\n  \\theta_2''(t) +\\gamma \\theta_2' + \\frac{g}{L} \\sin \\theta_2 +\n  k(\\theta_2-\\theta_1) &= 0,\n\\end{split}\n\nwhere \\theta_1 and \\theta_2 are angles made by the two pendulums, L is the length of each pendulum, γ is a frictional parameter, and k is a parameter describing a torque produced by the rod when it is twisted. We can convert this problem into a first-order system using the substitutions  u_1 = \\theta_1, \\quad u_2 = \\theta_2, \\quad u_3 = \\theta_1', \\quad\n  u_4 = \\theta_2'.\n\nWith these definitions the system becomes\\begin{split}\n  u_1' &= u_3, \\\\\n  u_2' &= u_4, \\\\\n  u_3' &= -\\gamma u_3 - \\frac{g}{L}\\sin u_1 + k(u_2-u_1), \\\\\n  u_4' &= -\\gamma u_4 - \\frac{g}{L}\\sin u_2 + k(u_1-u_2),\n\\end{split}\n\nwhich is a first-order system in four dimensions. To complete the description of the problem, you need to specify values for \\theta_1(0), \\theta_1'(0), \\theta_2(0), and \\theta_2'(0).\n\nThe trick illustrated in the preceding examples is always available. Suppose y is a scalar dependent variable in the system. You should introduce a component of \\mathbf{u} for y, y', etc., up to but not including the highest derivative appearing anywhere for y. This is done for each scalar variable in the original system. There should be one component of \\mathbf{u} for each scalar initial condition given. Many equations for the first-order system then come from the trivial relationships among all the lower derivatives. The remaining equations for the system come from the original, high-order equations. In the end, there must be as many scalar component equations as unknown first-order variables.\n\nCoupled pendulums\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nThe similar function creates an array of the same size and type as a given value, without initializing the contents.\n\nfunction couple(u, p, t)\n    γ, L, k = p\n    g = 9.8\n    udot = similar(u)\n    udot[1:2] .= u[3:4]\n    udot[3] = -γ * u[3] - (g / L) * sin(u[1]) + k * (u[2] - u[1])\n    udot[4] = -γ * u[4] - (g / L) * sin(u[2]) + k * (u[1] - u[2])\n    return udot\nend\n\nu₀ = [1.25, -0.5, 0, 0]\ntspan = (0.0, 50.0);\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nHere idxs is used to plot two components as functions of time.\n\nγ, L, k = 0, 0.5, 0\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], title=\"Uncoupled pendulums\")\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 1\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], title=\"Coupled pendulums\")\n\nThe coupling makes the pendulums swap energy back and forth.\n\nCoupled pendulums\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nfunction udot = pendulums(t, u, p)\n    gamma = p(1);  L = p(2);  k = p(3);\n    g = 9.8;\n    udot = zeros(4, 1);\n    udot(1:2) = u(3:4);\n    udot(3) = -gamma * u(3) - (g / L) * sin(u(1)) + k * (u(2) - u(1));\n    udot(4) = -gamma * u(4) - (g / L) * sin(u(2)) + k * (u(1) - u(2));\nend\n\n\nu0 = [1.25; -0.5; 0; 0];\na = 0; b = 50;\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nHere OutputVariables is used to restrict output to just u_1 and u_2.\n\nparams =[0.01, 0.5, 0];    % gamma, L, k\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nt = linspace(a, b, 1001);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\")\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nparams(3) = 1;\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Coupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\")\n\nThe coupling makes the pendulums swap energy back and forth.\n\nCoupled pendulums\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\ndef couple(t, u, params):\n    gamma, L, k = params\n    g = 9.8\n    udot = copy(u)\n    udot[:2] = u[2:4]\n    udot[2] = -gamma * u[2] - (g / L) * sin(u[0]) + k * (u[1] - u[0])\n    udot[3] = -gamma * u[3] - (g / L) * sin(u[1]) + k * (u[0] - u[1])\n    return udot\n\nu0 = array([1.25, -0.5, 0, 0])\ntspan = [0.0, 50.0]\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nWe use a closure here to pass the fixed parameter values into couple.\n\ngamma, L, k = 0.01, 0.5, 0.0\ndu_dt = lambda t, u: couple(t, u, (gamma, L, k))\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)    # first two components of solution\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\");\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 0.75    # changes the value in the du_dt closure\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Coupled pendulums\");\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/systems#transformation-of-high-order-systems","position":5},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Exercises"},"type":"lvl2","url":"/systems#exercises","position":6},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Exercises"},"content":"✍ Rewrite the given higher order problems as first-order systems.\n\n(a) y'''-3y''+3 y' -y = t, \\: y(0) = 1, \\: y'(0) = 2, \\: y''(0) = 3\n\n(b) y'' + 4 (x^2-1)y' + y = 0, \\: y(0) = 2, \\: y'(0) = -1\n\n(c) For a given constant a,\\begin{split}\n  x'' + \\frac{a x}{(x^2+y^2)^{3/2}} &= 0,\\\\\n  y'' + \\frac{a y}{(x^2+y^2)^{3/2}} &= 0,\n  \\end{split}\n\nwith initial values x(0) = 1, x'(0)=y(0) = 0, y'(0)=3\n\n(d) y^{(4)} -y = e^{-t}, \\: y(0) = 0, \\: y'(0) = 0, \\: y''(0) = 1,\\: y'''(0) = 0\n\n(e) y'''-y''+y'-y = t, \\: y(0) = 1, \\: y'(0) = 2, \\: y''(0) = 3\n\n✍ Write the given IVP as a system. Then do two steps of Euler’s method by hand (perhaps with a calculator) with the indicated step size h. Using the given exact solution, compute the error after the second step.\n\n(a) y''+ 4y = 4t, \\: y(0) = 1,\\: y'(0) = 1; \\: \\hat{y}(t) = t+\\cos (2t),\\: h=0.1\n\n(b) y''- 4y = 4t, \\: y(0) = 2,\\: y'(0) = -1; \\: \\hat{y}(t) = e^{2t} + e^{-2t}-t,\\: h=0.1\n\n(c) 2 x^2 y'' +3xy' - y = 0, \\: y(2) = 1, \\: y'(2) = -1/2,  \\: \\hat{y}(x) = 2/x, h = 1/8\n\n(d) 2 x^2 y'' +3xy' - y = 0,\\: y(1) = 4, \\: y'(1) = -1, \\: \\hat{y}(x) = 2(x^{1/2} + x^{-1}), h=1/4\n\n⌨ Solve the following IVPs using \n\nFunction 6.2.2 using n=1000 steps. Plot the solution and its first derivative together on one plot, and plot the error in each component as functions of time on another.\n\n(a) y''+ 4y = 4t, \\: 0< t< 2\\pi, \\: y(0) = 1,\\: y'(0) = 1; \\: \\hat{y}(t) = t+\\cos (2t)\n\n(b) y''+ 9y = \\sin(2t), \\: 0< t< 2\\pi, \\: y(0) = 2,\\: y'(0) = 1; \\quad \\hat{y}(t) = (1/5) \\sin(3t) + 2 \\cos (3t)+  (1/5) \\sin (2t)\n\n(c) y''- 4y = 4t \\: 0< t< 1.5, \\: y(0) = 2,\\: y'(0) = -1; \\: \\hat{y}(t) = e^{2t} + e^{-2t}-t\n\n(d) y''+ 4y'+ 4y = t, \\: 0< t< 4, \\: y(0) = 1,\\: y'(0) = 3/4; \\: \\hat{y}(t) = (3t+5/4)e^{-2t} + (t-1)/4\n\n(e) x^2 y'' +5xy' + 4y = 0,\\: 1<x<e^2, \\: y(1) = 0, \\: y'(1) = 2, \\: \\hat{y}(x) = (2/x^2) \\ln x\n\n(f) x^2 y'' +5xy' + 4y = 0,\\: 1<x<e^2, \\: y(1) = 1, \\: y'(1) = -1, \\: \\hat{y}(x) = x^{-2}( 1 + \\ln x)\n\n(g) 2 x^2 y'' +3xy' - y = 0,\\: 2<x<20, \\: y(2) = 1, \\: y'(2) = -1/2, \\: \\hat{y}(x) = 2/x\n\n(h) 2 x^2 y'' +3xy' - y = 0,\\: 1<x<16, \\: y(1) = 4, \\: y'(1) = -1, \\: \\hat{y}(x) = 2(x^{1/2} + x^{-1})\n\n(i) x^2 y'' -xy' + 2y = 0,\\: 1<x<e^{\\pi}, \\: y(1) = 3, \\: y'(1) = 4; \\quad \\hat{y}(x) = x \\left[ 3 \\cos \\left( \\ln x \\right)+\\sin \\left( \\ln x \\right) \\right]\n\n(j) x^2 y'' + 3xy' + 4y = 0,\\: e^{\\pi/12} < x < e^{\\pi}, \\: y(e^{\\pi/12}) = 0,  \\: y'(e^{\\pi/12}) = -6; \\quad \\hat{y}(x) = x^{-1} \\left[ 3 \\cos \\left( 3 \\ln x \\right)+\\sin \\left( 3 \\ln x \\right) \\right]\n\n⌨ A disease that is endemic to a population can be modeled by tracking the fraction of the population that is susceptible to infection, v(t), and the fraction that is infectious, w(t). (The rest of the population is considered to be recovered and immune.) A typical model is the SIR model (see \n\nBritton (2003))\\frac{dv}{dt} = 0.2(1-v) - 3vw, \\qquad \\frac{dw}{dt} = (3v-1)w.\n\nStarting with v(0) = 0.95 and w(0) = 0.05, use solve to find the long-term steady values of v(t) and w(t). Plot both components of the solution as functions of time.\n\n⌨ In each case below, use solve to solve the given ODE for 0\\le t \\le 10 with the given initial conditions. Plot the results together as curves in the phase plane (that is, with x and y as the axes of the plot), using aspect_ratio=1 in the plot command.\n\n(a)\\begin{split}\n  x'(t) & = - 4y + x(1-x^2-y^2),\\\\\n  y'(t) & = 4x + y(1-x^2-y^2),\n\\end{split}\n\nwith [x(0),y(0)]=[0.1,0] and [x(0),y(0)]=[0,1.9].\n\n(b)\\begin{split}\n  x'(t) & = - 4y - \\tfrac{1}{4}x(1-x^2-y^2)(4-x^2-y^2),\\\\\n  y'(t) & = 4x - \\tfrac{1}{4}y(1-x^2-y^2)(4-x^2-y^2),\n\\end{split}\n\nwith [x(0),y(0)]=[0.95,0], [0,1.05], and [-2.5,0].\n\n⌨ The FitzHugh–Nagumo equations are a simple model of the repeated firing of a neuron. They are given by\\begin{split}\n\\frac{d v_1}{dt} &= - v_1(v_1-1)(v_1-a) - v_2 + I, \\\\\n\\frac{d v_2}{dt} &= \\epsilon ( v_1 - \\gamma v_2).\n\\end{split}\n\nAssume v_1(0) = 0.5, v_2(0) = 0.1, a = 0.1, \\epsilon = 0.008, \\gamma = 1. For each value of I below, find and plot the solution using solve for 0\\le t \\le 600. The solutions are highly sensitive to I, and you need to change the requested absolute and relative error tolerances to \n\n10-9. In each case the solution quickly approaches a periodic oscillation.\n\n(a) I = 0.05527,\\quad\n(b) I = 0.05683,\\quad\n(c) I = 0.0568385,\\quad\n(d) I = 0.05740.\n\nThis exploration was carried out by Baer and Erneux \n\nBaer & Erneux (1986).","type":"content","url":"/systems#exercises","position":7},{"hierarchy":{"lvl1":"Zero-stability of multistep methods"},"type":"lvl1","url":"/zerostability","position":0},{"hierarchy":{"lvl1":"Zero-stability of multistep methods"},"content":"For one-step methods such as Runge–Kutta, \n\nTheorem 6.2.1 guarantees that the method converges and that the global error is of the same order as the local truncation error. For multistep methods, however, a new wrinkle is introduced.\n\nIt is straightforward to check that the two-step method LIAF, defined by  \\mathbf{u}_{i+1} = -4u_i + 5u_{i-1} + h(4f_i + 2f_{i-1}),\n\nis third-order accurate. Let’s apply it to the ridiculously simple IVP u'=u, u(0)=1, whose solution is e^t.\n\nInstability\n\nWe’ll measure the error at the time t=1.\n\ndu_dt(u, t) = u\nû = exp\na, b = 0.0, 1.0;\nn = [5, 10, 20, 40, 60]\nerr = []\nt, u = [], []\nfor n in n\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n    u = [1; û(h); zeros(n - 1)]\n    f_val = [du_dt(u[1], t[1]); zeros(n)]\n    for i in 2:n\n        f_val[i] = du_dt(u[i], t[i])\n        u[i+1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f_val[i] + 2 * f_val[i-1])\n    end\n    push!(err, abs(û(b) - u[end]))\nend\n\npretty_table([n (b - a) ./ n err], header=[\"n\", \"h\", \"error\"])\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nplot(t, abs.(u), m=3, label=\"\",\n    xlabel=L\"t\", yaxis=(:log10, L\"|u(t)|\"), title=\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.\n\nInstability\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = @(t, u) u;\nu_exact = @exp;\na = 0;  b = 1;\nn = [5, 10, 20, 40, 60]';\nerr = zeros(size(n));\nfor j = 1:length(n)\n    h = (b - a) / n(j);\n    t = a + h *(0:n(j));\n    u = [1, u_exact(h), zeros(1, n(j) - 1)];\n    f = [du_dt(t(1), u(1)), zeros(1, n(j) - 2)];\n    for i = 2:n(j)\n        f(i) = du_dt(t(i), u(i));\n        u(i+1) = -4*u(i) + 5*u(i-1) + h * (4*f(i) + 2*f(i-1));\n    end\n    err(j) = abs(u_exact(b) - u(end));\nend\n\nh = (b-a) ./ n;\ndisp(table(n, h, err))\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nclf\nsemilogy(t, abs(u))\nxlabel(\"t\");  ylabel(\"|u(t)|\")\ntitle(\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.\n\nInstability\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = lambda t, u: u\nu_exact = exp\na, b = (0.0, 1.0)\n\ndef LIAF(du_dt, tspan, u0, n):\n    a, b = tspan\n    h = (b - a) / n\n    t = linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[1] = u_exact(t[1])    # use an exact starting value\n    f = copy(u)\n    f[0] = du_dt(t[0], u[0])\n    for i in range(n):\n        f[i] = du_dt(t[i], u[i])\n        u[i + 1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f[i] + 2 * f[i-1])\n\n    return t, u.T\n\nn = [5, 10, 20, 40, 60]\nresults = PrettyTable([\"n\", \"error\"])\nfor j in range(5):\n    t, u = LIAF(du_dt, [a, b], [1.0], n[j])\n    err = abs(u_exact(b) - u[0, -1])\n    results.add_row([n[j], err])\nprint(results)\n\nThere is no convergence in sight! A graph of the last numerical attempt yields a clue:\n\nsemilogy(t, abs(u[0]), \"-o\")\nxlabel(\"$t$\"), ylabel(\"$|u|$\")\ntitle(\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.\n\nThe source of the exponential growth in \n\nDemo 6.8.1 is not hard to identify. Recall that we can rewrite \n\n(6.8.1) as \\rho(\\mathcal{Z})u_{i-1}=h \\sigma(\\mathcal{Z})u_{i-1} using the forward shift operator \\mathcal{Z}:  (\\mathcal{Z}^2 + 4\\mathcal{Z} - 5) u_{i-1} = h(4\\mathcal{Z} + 2)f_{i-1}.\n\n(See \n\n(6.6.7), using k=2 here.) Next, suppose that h is negligible in \n\n(6.8.2). Then the numerical solution of LIAF is roughly defined by  (\\mathcal{Z}^2 + 4\\mathcal{Z} - 5) u_{i-1} = 0.\n\nThe graph in \n\nDemo 6.8.1 strongly suggests that for small h, |u_i|\\approx c \\alpha^i for some \\alpha>1 as m gets large. So we are motivated to try definingu_i = c z^i\n\nfor all i and see if we can prove that it is an exact solution. The beauty of this choice is that for all i,\\mathcal{Z} u_i = u_{i+1} = z u_i.\n\nHence \n\n(6.8.3) becomes  z^2 + 4z - 5 = 0.\n\nTherefore, as h\\to 0, the two roots of z^2+4z+5 will each correspond to an approximate solution in the form \n\n(6.8.4) of the LIAF method. These roots are z=1 and z=-5, and the growth curve at the end of \n\nDemo 6.8.1 is approximately |(-5)^i|.","type":"content","url":"/zerostability","position":1},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Zero-stability"},"type":"lvl2","url":"/zerostability#zero-stability","position":2},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Zero-stability"},"content":"Here is the crucial property that LIAF lacks.\n\nZero-stability of a multistep IVP method\n\nA multistep method is zero-stable if, as h\\to 0, every numerical solution produced by the method remains bounded throughout a\\le t_i \\le b.\n\nWithout zero-stability, any truncation or roundoff error will get exponentially amplified and eventually overwhelm convergence to the exact solution.\n\nThe following theorem concisely summarizes when we can expect zero-stability.\n\nRoot condition\n\nA linear multistep method is zero-stable if and only if every root r of the generating polynomial \\rho(z) satisfies |r|\\le 1, and any root r with |r|=1 is simple.\n\n(Partial proof, when all roots of ρ are simple.) As explained above, the values produced by the numerical method approach solutions of the difference equation \\rho(\\mathcal{Z})u_{i-k+1}=0. We consider only the case where the roots r_1,\\ldots,r_k of \\rho(z). Then u_i=(r_j)^i is a solution of \\rho(\\mathcal{Z})u_i=0 for each j=1,\\ldots,k. By linearity,  u_i = c_1 (r_1)^i + c_2 (r_2)^i + \\cdots + c_k (r_k)^i\n\nis a solution for any values of c_1,\\ldots,c_k. These constants are determined uniquely by the starting values u_0,\\ldots,u_{k-1} (we omit the proof). Now, if all the roots satisfy |r_j|\\le 1, then  |u_i| \\le \\sum_{j=1}^k |c_j| |r_j|^i \\le \\sum_{j=1}^k |c_j|,\n\nindependently of h and i. This proves zero-stability. Conversely, if some |r_j|>1, then |u_i| cannot be bounded above by a constant independent of i. Since b=t_i, i\\to\\infty at t=b as h\\to 0, so zero-stability cannot hold.\n\nA nonsimple root of ρ introduces a modification of \n\n(6.8.4) that is considered in \n\nExercise 4.\n\nA k-step Adams method has \\rho(z) = z^k - z^{k-1} = z^{k-1}(z-1). Hence 1 is a simple root and 0 is a root of multiplicity k-1. So the Adams methods are all stable.\n\nThe method u_{i+1} = 2u_i - u_{i-1} + h(f_i-f_{i-1}) is first-order accurate. But \\rho(z)=(z-1)^2, which has a double root at z=1, so it is not zero-stable.","type":"content","url":"/zerostability#zero-stability","position":3},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Dahlquist theorems"},"type":"lvl2","url":"/zerostability#dahlquist-theorems","position":4},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Dahlquist theorems"},"content":"It turns out that lacking zero-stability is the only thing that can go wrong for a consistent multistep method.\n\nDahlquist equivalence\n\nA linear multistep method converges as h\\to 0 if and only if it is consistent and zero-stable.\n\nThe Dahlquist equivalence theorem is one of the most important and celebrated in the history of numerical analysis. It can be proved more precisely that a zero-stable, consistent method is convergent in the same sense as \n\nTheorem 6.2.1, with the error between numerical and exact solutions being of the same order as the local truncation error, for a wide class of problems.\n\nYou may have noticed that the Adams and BD formulas use only about half of the available data from the past k steps, i.e., they have many possible coefficients set to zero. For instance, a k-step AB method uses only the f_j-values and has order k. The order could be made higher by also using u_j-values, like the LIAF method does for k=2. Also like the LIAF method, however, such attempts are doomed by instability.\n\nFirst Dahlquist stability barrier\n\nThe order of accuracy p of a stable k-step linear multistep method satisfiesp \\le\n\\begin{cases}\n  k+2 & \\text{if $k$ is even},\\\\\n  k+1 & \\text{if $k$ is odd},\\\\\n  k & \\text{if the method is explicit.}\n\\end{cases}\n\nThe lesson of \n\nTheorem 6.8.3 is that accuracy is not the only important feature, and trying to optimize for it leads to failure. New lessons on the same theme appear in .","type":"content","url":"/zerostability#dahlquist-theorems","position":5},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Exercises"},"type":"lvl2","url":"/zerostability#exercises","position":6},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Exercises"},"content":"✍ Show that the LIAF method \n\n(6.8.1) has order of accuracy equal to 3.\n\n✍ / ⌨  Verify that the order of accuracy of the given multistep method is at least 1. Then apply \n\nTheorem 6.8.1 to determine whether it is zero-stable.\n\n(a) BD2\n\n(b) BD3\n\n(c) u_{i+1}=u_{i-1}+2hf_i\n\n(d) u_{i+1} = -u_i +u_{i-1} + u_{i-2} + \\frac{2h}{3}(4f_i+f_{i-1}+f_{i-2})\n\n(e) u_{i+1} = u_{i-3} + \\frac{4h}{3} ( 2f_i - f_{i-1} + 2f_{i-2})\n\n(f) u_{i+1} = -2u_i + 3u_{i-1} + h (f_{i+1}+2f_i+f_{i-1})\n\n✍  A Fibonacci sequence is defined by u_{i+1}=u_i+u_{i-1}, where u_0 and u_1 are seed values. Using the proof of \n\nTheorem 6.8.1, find r_1 and r_2 such that u_i=c_1(r_1)^i+c_2(r_2)^i for all i.\n\n✍ (a) Suppose that \\rho(r) = \\rho'(r) = 0. Show that u_i = i r^i is a solution of the difference equation \\rho(\\mathcal{Z})u_i=0.\n\n(b) Explain why the result of part (a) implies that a non-simple root r with |r|=1 makes it impossible for a multistep method to be zero-stable.","type":"content","url":"/zerostability#exercises","position":7},{"hierarchy":{"lvl1":"Dimension reduction"},"type":"lvl1","url":"/dimreduce","position":0},{"hierarchy":{"lvl1":"Dimension reduction"},"content":"The SVD has another important property that proves very useful in a variety of applications. Let \\mathbf{A} be a real m\\times n matrix with SVD \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T and (momentarily) m\\ge n. Another way of writing the thin form of the SVD is\\begin{split}\n  \\mathbf{A} = \\hat{\\mathbf{U}}\\hat{\\mathbf{S}}\\mathbf{V}^T &=\n  \\begin{bmatrix}\n    \\rule[-0.3em]{0pt}{1em} \\mathbf{u}_1 & \\mathbf{u}_2 & \\cdots & \\mathbf{u}_n\n  \\end{bmatrix} \\:\n  \\begin{bmatrix}\n    \\sigma_1 & & \\\\\n    & \\ddots & \\\\\n    & & \\sigma_n\n  \\end{bmatrix} \\: \n        \\begin{bmatrix}\n          \\mathbf{v}_1^T \\\\ \\vdots \\\\ \\mathbf{v}_n^T\n        \\end{bmatrix}\\ \\\\\n  &=\n  \\begin{bmatrix}\n    \\rule[-0.3em]{0pt}{1em} \\sigma_1\\mathbf{u}_1  & \\cdots & \\sigma_n\\mathbf{u}_n\n  \\end{bmatrix}\\:\n  \\begin{bmatrix}\n    \\mathbf{v}_1^T \\\\ \\vdots \\\\ \\mathbf{v}_n^T\n  \\end{bmatrix} \\\\\n  &= \\sigma_1 \\mathbf{u}_{1}\\mathbf{v}_{1}^T + \\cdots + \\sigma_r \\mathbf{u}_{r}\\mathbf{v}_{r}^T = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_{i}\\mathbf{v}_{i}^T,\n\\end{split}\n\nwhere r is the rank of \\mathbf{A}. The final formula also holds for the case m<n.\n\nEach outer product \\mathbf{u}_{i}\\mathbf{v}_{i}^T is a rank-1 matrix of unit 2-norm. Thanks to the ordering of singular values, then, Equation \n\n(7.5.1) expresses \\mathbf{A} as a sum of decreasingly important contributions. This motivates the definition, for 1\\le k \\le r,\\mathbf{A}_k = \\sum_{i=1}^k \\sigma_i \\mathbf{u}_{i}\\mathbf{v}_{i}^T = \\mathbf{U}_k \\mathbf{S}_k \\mathbf{V}_k^T,\n\nwhere \\mathbf{U}_k and \\mathbf{V}_k are the first k columns of \\mathbf{U} and \\mathbf{V}, respectively, and \\mathbf{S}_k is the upper-left k\\times k submatrix of \\mathbf{S}.\n\nThe rank of a sum of matrices is always less than or equal to the sum of the ranks, so \\mathbf{A}_k is a rank-k approximation to \\mathbf{A}. It turns out that \\mathbf{A}_k is the best rank-k approximation of \\mathbf{A}, as measured in the matrix 2-norm.\n\nSuppose \\mathbf{A} has rank r and let \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T be an SVD. Let \\mathbf{A}_k be as in \n\n(7.5.2) for 1\\le k < r. Then\n\n\\| \\mathbf{A} - \\mathbf{A}_k \\|_2 = \\sigma_{k+1}, \\quad k=1,\\ldots,r-1, and\n\nIf the rank of \\mathbf{B} is k or less, then \\| \\mathbf{A}-\\mathbf{B} \\|_2\\ge \\sigma_{k+1}.\n\n(part 1 only) Note that \n\n(7.5.2) is identical to \n\n(7.5.1) with \\sigma_{k+1},\\ldots,\\sigma_r all set to zero. This implies that\\mathbf{A} - \\mathbf{A}_k = \\mathbf{U}(\\mathbf{S}-\\hat{\\mathbf{S}})\\mathbf{V}^T,\n\nwhere \\hat{\\mathbf{S}} has those same values of \\sigma_i replaced by zero. But that makes the above an SVD of \\mathbf{A} - \\mathbf{A}_k, with singular values 0,\\ldots,0,\\sigma_{k+1},\\ldots,\\sigma_r, the largest of which is \\sigma_{k+1}. That proves the first claim.","type":"content","url":"/dimreduce","position":1},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Compression"},"type":"lvl2","url":"/dimreduce#compression","position":2},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Compression"},"content":"If the singular values of \\mathbf{A} decrease sufficiently rapidly, then \\mathbf{A}_{k} may capture the most significant behavior of the matrix for a reasonably small value of k.\n\nImage compression\n\nWe make an image from some text, then reload it as a matrix.\n\nplot(annotations=(0.5, 0.5, text(\"Hello world\", 44, :center, :center)),\n    grid=:none, frame=:none, size=(400, 150))\nsavefig(\"hello.png\")\nimg = load(\"hello.png\")\nA = @. Float64(Gray(img))\nGray.(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=45.\n\nU, σ, V = svd(A)\nscatter(σ, xaxis=(L\"i\"), yaxis=(:log10, L\"\\sigma_i\"),\n    title=\"Singular values\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nplt = plot(layout=(2, 2), frame=:none, aspect_ratio=1, titlefontsize=10)\nfor i in 1:4\n    k = 3i\n    Ak = U[:, 1:k] * diagm(σ[1:k]) * V[:, 1:k]'\n    plot!(Gray.(Ak), subplot=i, title=\"rank = $k\")\nend\nplt\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\nm, n = size(A)\ncompression = m * n / (9 * (m + n + 1))\n\nImage compression\n\nWe make an image from some text, then reload it as a matrix.\n\nclf\ntobj = text(0, 0,'Hello world','fontsize',44);\nex = get(tobj, 'extent');\naxis([ex(1) ex(1) + ex(3) ex(2) ex(2) + ex(4)]), axis off\nexportgraphics(gca, 'hello.png', resolution=300)\nA = imread('hello.png');\nA = double(im2gray(A));\nsize_A = size(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=100.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\nsemilogy(sigma, '.')\ntitle('singular values'), axis tight        % ignore this line \nxlabel('i'), ylabel('\\sigma_i')  % ignore this line \nr = find(sigma / sigma(1) > 10*eps, 1, 'last')\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor i = 1:4\n    subplot(2, 2, i)\n    k = 2*i;\n    Ak = U(:, 1:k) * S(1:k, 1:k) * V(:, 1:k)';\n    imshow(Ak, [0, 255])\n    title(sprintf('rank = %d', k))\nend\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\n[m, n] = size(A);\nfull_size = m * n;\ncompressed_size = 8 * (m + n + 1);\nfprintf(\"compression ratio: %.1f\", full_size / compressed_size)\n\nImage compression\n\nWe make an image from some text, then reload it as a matrix.\n\ntext(\n    0.5,\n    0.5,\n    \"Hello world\",\n    dict(fontsize=44),\n    horizontalalignment=\"center\",\n    verticalalignment=\"center\",\n)\naxis(\"off\")\nsavefig(\"hello.png\")\n\nimg = imread(\"hello.png\")[:, :, :3]\nA = rgb2gray(img)\nprint(f\"image of size {A.shape}\")\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around index 38.\n\nfrom numpy.linalg import svd\nU, sigma, Vt = svd(A)\nsemilogy(sigma, \"o\")\ntitle(\"Singular values\")\nxlabel(\"$i$\"), ylabel(\"$\\\\sigma_i$\");\n\nsignificant = sigma / sigma[0] > 10 * 2**-52\nprint(f\"last significant singular value at index {max(where(significant)[0])}\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor k in range(4):\n    r = 2 + 2 * k\n    Ak = U[:, :r] @ diag(sigma[:r]) @ Vt[:r, :]\n    subplot(2, 2, k + 1)\n    imshow(Ak, cmap=\"gray\", clim=(0.0, 1.0))\n    title(f\"rank = {r}\")\n    xticks([]), yticks([])\n\nConsider how little data is needed to reconstruct these images. For rank-8, for instance, we have 8 left and right singular vectors plus 8 singular values.\n\nm, n = A.shape\nfull_size = m * n\ncompressed_size = 8 * (m + n + 1)\nprint(f\"compression ratio: {full_size / compressed_size:.1f}\")","type":"content","url":"/dimreduce#compression","position":3},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Capturing major trends"},"type":"lvl2","url":"/dimreduce#capturing-major-trends","position":4},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Capturing major trends"},"content":"The use of dimension reduction offered by low-rank SVD approximation goes well beyond simply reducing computation time. By isolating the most important contributions to the matrix, dimension reduction can uncover deep connections and trends that are otherwise obscured by weaker effects and noise.\n\nOne useful way to quantify the decay in the singular values is to computes_k = \\sum_{i=1}^k \\sigma_i^2, \\quad \\tau_k = \\frac{s_k}{s_r}, \\quad k=1,\\ldots,r.\n\nClearly 0\\le \\tau_k \\le 1 and \\tau_k is non-decreasing as a function of k. We can think of \\tau_k as the fraction of energy (or in statistical terms, variance) contained in the singular values up to and including the kth.\n\nDimension reduction in voting records\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\n@load \"voting.jld2\" A;\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nheatmap(A, color=:viridis,\n    title=\"Votes in 111th U.S. Senate\", xlabel=\"bill\", ylabel=\"senator\")\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, σ, V = svd(A)\nτ = cumsum(σ .^ 2) / sum(σ .^ 2)\nscatter(τ[1:16], xaxis=(\"k\"), yaxis=(L\"\\tau_k\"),\n    title=\"Fraction of singular value energy\")\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nscatter(U[:, 1], label=\"\", layout=(1, 2),\n    xlabel=\"senator\", title=\"left singular vector\")\nscatter!(V[:, 1], label=\"\", subplot=2,\n    xlabel=\"bill\", title=\"right singular vector\")\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = A * V[:, 1];\nx2 = A * V[:, 2];\n\n@load \"voting.jld2\" Rep Dem Ind\nRep = vec(Rep);\nDem = vec(Dem);\nInd = vec(Ind);\nscatter(x1[Dem], x2[Dem], color=:blue, label=\"D\",\n    xaxis=(\"partisanship\"), yaxis=(\"bipartisanship\"), title=\"111th US Senate by voting record\")\nscatter!(x1[Rep], x2[Rep], color=:red, label=\"R\")\nscatter!(x1[Ind], x2[Ind], color=:yellow, label=\"I\")\n\nDimension reduction in voting records\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nload voting\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nclf\nimagesc(A)\ncolormap parula\ntitle('Votes in 111th U.S. Senate')   % ignore this line\nylabel('senator'),  xlabel('bill')    % ignore this line\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\ntau = cumsum(sigma.^2) / sum(sigma.^2);\nplot(tau(1:16), 'o')\nxlabel('k'),  ylabel('\\tau_k')  % ignore this line\ntitle('Fraction of singular value energy')     % ignore this line\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(211), plot(U(:, 1), '.')\nxlabel('senator number'), title('left singular vector')  % ignore this line\nsubplot(212), plot(V(:, 1), '.')\nxlabel('bill number'), title('right singular vector')  % ignore this line\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nclf\nx1 = V(:, 1)'*A';   x2 = V(:, 2)'*A'; \nscatter(x1(Dem), x2(Dem), 20, 'b'),  hold on\nscatter(x1(Rep), x2(Rep), 20, 'r')\nscatter(x1(Ind), x2(Ind), 20, 'k')\nxlabel('partisanship'),  ylabel('bipartisanship')  % ignore this line\ntitle('111th US Senate in 2D')\n\nDimension reduction in voting records\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nfrom scipy.io import loadmat\nvars = loadmat(\"voting.mat\")\nA = vars[\"A\"]\nm, n = A.shape\nprint(\"size:\", (m, n))\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nimshow(A, cmap=\"viridis\")\nxlabel(\"bill\")\nylabel(\"senator\")\ntitle(\"Votes in 111th U.S. Senate\");\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, sigma, Vt = svd(A)\ntau = cumsum(sigma**2) / sum(sigma**2)\nplot(range(1, 17), tau[:16], \"o\")\nxlabel(\"$k$\")\nylabel(\"$\\tau_k$\")\ntitle(\"Fraction of singular value energy\");\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(1, 2, 1)\nplot(U[:, 0], \"o\")\nxlabel(\"senator\"),title(\"left singular vector\")\nsubplot(1, 2, 2)\nplot(Vt[0, :], \"o\")\nxlabel(\"bill\"), title(\"right singular vector\");\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = sigma[0] * U[:, 0]\nx2 = sigma[1] * U[:, 1]\n\nRep = vars[\"Rep\"] - 1\nDem = vars[\"Dem\"] - 1\nInd = vars[\"Ind\"] - 1\n\nscatter(x1[Dem], x2[Dem], color=\"blue\", label=\"D\")\nscatter(x1[Rep], x2[Rep], color=\"red\", label=\"R\")\nscatter(x1[Ind], x2[Ind], color=\"darkorange\", label=\"I\")\n\nxlabel(\"partisanship\")\nylabel(\"bipartisanship\")\nlegend()\ntitle(\"111th US Senate in 2D\");\n\nNot all data sets can be reduced effectively to a small number of dimensions, but as \n\nDemo 7.5.2 illustrates, in some cases reduction reveals information that corresponds to real-world understanding.","type":"content","url":"/dimreduce#capturing-major-trends","position":5},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Exercises"},"type":"lvl2","url":"/dimreduce#exercises","position":6},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Exercises"},"content":"✍  Suppose that \\mathbf{A} is an n\\times n matrix. Explain why \\sigma_n is the distance (in 2-norm) from \\mathbf{A} to the set of all singular matrices.\n\n✍ Suppose \\mathbf{A} is a 7\\times 4 matrix and the eigenvalues of \\mathbf{A}^*\\mathbf{A} are 3, 4, 7, and 10. How close is \\mathbf{A} in the 2-norm to (a) a rank-3 matrix? (b) a rank-2 matrix?\n\n(a) ⌨ Find the rank-1 matrix closest to\\mathbf{A}=\\displaystyle \\begin{bmatrix}\n    1 & 5 \\\\ 5 & 1\n    \\end{bmatrix},\n\nas measured in the 2-norm.\n\n(b) ⌨ Repeat part (a) for\\mathbf{A}=\\displaystyle \\begin{bmatrix}\n    1 & 5 \\\\ 0 & 1\n    \\end{bmatrix}.\n\n✍ Find the rank-1 matrix closest to\\mathbf{A}=\\displaystyle \\begin{bmatrix}\n    1 & b \\\\ b & 1\n    \\end{bmatrix},\n\nas measured in the 2-norm, where b>0.\n\n⌨ Following \n\nDemo 7.5.1 as a guide, load the “mandrill” test image and convert it to a matrix of floating-point pixel grayscale intensities. Using the SVD, display as images the best approximations of rank 5, 10, 15, and 20.\n\nIn statistics this quantity may be interpreted as the fraction of explained variance.","type":"content","url":"/dimreduce#exercises","position":7},{"hierarchy":{"lvl1":"Eigenvalue decomposition"},"type":"lvl1","url":"/evd","position":0},{"hierarchy":{"lvl1":"Eigenvalue decomposition"},"content":"To this point we have dealt frequently with the solution of the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Alongside this problem in its importance to linear algebra is the eigenvalue problem.\n\nEigenvalue and eigenvector\n\nGiven a square matrix \\mathbf{A}, if\\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x}\n\nfor a scalar λ and a nonzero vector \\mathbf{x}, then λ is an eigenvalue and \\mathbf{x} is an associated eigenvector.","type":"content","url":"/evd","position":1},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Complex matrices"},"type":"lvl2","url":"/evd#complex-matrices","position":2},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Complex matrices"},"content":"A matrix with real entries can have complex eigenvalues. Therefore we assume all matrices, vectors, and scalars may be complex in what follows. Recall that a complex number can be represented as a+i b for real a and b and where i^2=-1. The complex conjugate of x=a+i b is denoted \\bar{x} and is given by \\bar{x}=a-i b. The magnitude or modulus of a complex number z is|z| = \\sqrt{z\\cdot \\bar{z}}.\n\nTerms for complex matrices\n\nThe adjoint or hermitian of a matrix \\mathbf{A} is denoted \\mathbf{A}^* and is given by \\mathbf{A}^*=(\\overline{\\mathbf{A}})^T=\\overline{\\mathbf{A}^T}. The matrix is self-adjoint or hermitian if \\mathbf{A}^*=\\mathbf{A}.\n\nThe 2-norm of a complex vector \\mathbf{u} is \\sqrt{\\mathbf{u}^*\\mathbf{u}}. Other vector norms, and all matrix norms, are as defined in \n\nVector and matrix norms.\n\nComplex vectors \\mathbf{u} and \\mathbf{v} of the same dimension are orthogonal if \\mathbf{u}^*\\mathbf{v}=0. Orthonormal vectors are mutually orthogonal and have unit 2-norm. A unitary matrix is a square matrix with orthonormal columns, or, equivalently, a matrix satisfying \\mathbf{A}^* = \\mathbf{A}^{-1}.\n\nFor the most part, “adjoint” replaces “transpose,” “hermitian” replaces “symmetric,” and “unitary matrix” replaces “orthogonal matrix” when applying our previous results to complex matrices.","type":"content","url":"/evd#complex-matrices","position":3},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Eigenvalue decomposition"},"type":"lvl2","url":"/evd#eigenvalue-decomposition","position":4},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Eigenvalue decomposition"},"content":"An easy rewrite of the eigenvalue definition \n\n(7.2.1) is that (\\mathbf{A} - \\lambda\\mathbf{I}) \\mathbf{x} = \\boldsymbol{0}. Hence (\\mathbf{A} - \\lambda\\mathbf{I}) is singular, and it therefore must have a zero determinant. This is the property most often used to compute eigenvalues by hand.\n\nGiven\\mathbf{A} = \\begin{bmatrix} 1 & 1 \\\\ 4 & 1 \\end{bmatrix},\n\nwe compute\\begin{vmatrix}\n1-\\lambda & 1\\\\ \n4 & 1-\\lambda\n\\end{vmatrix}\n= (1-\\lambda)^2 - 4 = \\lambda^2-2\\lambda-3.\n\nThe eigenvalues are the roots of this quadratic, \\lambda_1=3 and \\lambda_2=-1.\n\nThe determinant \\det(\\mathbf{A} - \\lambda \\mathbf{I}) is called the characteristic polynomial. Its roots are the eigenvalues, so we know that an n\\times n matrix has n eigenvalues, counting algebraic multiplicity.\n\nSuppose that \\mathbf{A}\\mathbf{v}_k=\\lambda_k\\mathbf{v}_k for k=1,\\ldots,n. We can summarize these as   \\begin{bmatrix}\n    \\mathbf{A}\\mathbf{v}_1 & \\mathbf{A}\\mathbf{v}_2 & \\cdots & \\mathbf{A}\\mathbf{v}_n\n  \\end{bmatrix}\n  &=\n    \\begin{bmatrix}\n      \\lambda_1 \\mathbf{v}_1 & \\lambda_2\\mathbf{v}_2 & \\cdots & \\lambda_n \\mathbf{v}_n\n    \\end{bmatrix}, \\\\[1mm]\n  \\mathbf{A} \\begin{bmatrix}\n    \\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n\n  \\end{bmatrix}\n  &=\n\\begin{bmatrix}\n    \\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\lambda_1 & &  &  \\\\\n    & \\lambda_2 & & \\\\\n    & & \\ddots & \\\\\n    & & & \\lambda_n\n  \\end{bmatrix},\n\nwhich we write as  \\mathbf{A} \\mathbf{V} = \\mathbf{V} \\mathbf{D}.\n\nIf we find that \\mathbf{V} is a nonsingular matrix, then we arrive at a key factorization.\n\nEigenvalue decomposition (EVD)\n\nAn eigenvalue decomposition (EVD) of a square matrix \\mathbf{A} is\\mathbf{A} = \\mathbf{V} \\mathbf{D} \\mathbf{V}^{-1}.\n\nIf \\mathbf{A} has an EVD, we say that \\mathbf{A} is diagonalizable; otherwise \\mathbf{A} is nondiagonalizable (or defective).\n\nObserve that if \\mathbf{A}\\mathbf{v} = \\lambda \\mathbf{v} for nonzero \\mathbf{v}, then the equation remains true for any nonzero multiple of \\mathbf{v}. Therefore, eigenvectors are not unique, and thus neither is an EVD.\n\nWe stress that while \n\n(7.2.6) is possible for all square matrices, \n\n(7.2.7) is not.  One simple example of a nondiagonalizable matrix is  \\mathbf{B} = \\begin{bmatrix}\n    1 & 1\\\\0 & 1\n  \\end{bmatrix}.\n\nThere is a common circumstance in which we can guarantee an EVD exists. The proof of the following theorem can be found in many elementary texts on linear algebra.\n\nIf the n\\times n matrix \\mathbf{A} has n distinct eigenvalues, then \\mathbf{A} is diagonalizable.\n\nEigenvalues and eigenvectors\n\nEigenvalues and eigenvectors\n\nThe eigvals function returns a vector of the eigenvalues of a matrix.\n\nA = π * ones(2, 2)\n\nλ = eigvals(A)\n\nIf you want the eigenvectors as well, use eigen.\n\nλ, V = eigen(A)\n\nnorm(A * V[:, 2] - λ[2] * V[:, 2])\n\nBoth functions allow you to sort the eigenvalues by specified criteria.\n\nA = diagm(-2.3:1.7)\n@show eigvals(A, sortby=real);\n@show eigvals(A, sortby=abs);\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1]\nλ, V = eigen(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nopnorm(A * V - V * diagm(λ))\n\nEigenvalues and eigenvectors\n\nThe eig function with one output argument returns a vector of the eigenvalues of a matrix.\n\nA = pi * ones(2, 2);\nlambda = eig(A)\n\nWith two output arguments given, eig returns a matrix eigenvectors and a diagonal matrix with the eigenvalues.\n\n[V, D] = eig(A)\n\nWe can check the fact that this is an EVD.\n\nnorm( A - V*D/V )   % / V is like * inv(V)\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1];\n[V, D] = eig(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nnorm(A * V - V * D)\n\nEigenvalues and eigenvectors\n\nThe eig function from scipy.linalg will return a vector of eigenvalues and a matrix of associated eigenvectors.\n\nfrom numpy.linalg import eig\nA = pi * ones([2, 2])\nd, V = eig(A)\nprint(\"eigenvalues:\", d)\n\nWe can check the fact that this is an EVD (although in practice we never invert a matrix).\n\nfrom numpy.linalg import inv\nD = diag(d)\nprint(f\"should be near zero: {norm(A - V @ D @ inv(V), 2):.2e}\")\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nfrom numpy.linalg import cond\nA = array([[1, 1], [0, 1]])\nd, V = eig(A)\nprint(f\"cond(V) is {cond(V):.2e}\")\n\nBut even in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds up to roundoff error.\n\nprint(f\"should be near zero: {norm(A @ V - V @ diag(d), 2):.2e}\")","type":"content","url":"/evd#eigenvalue-decomposition","position":5},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Similarity and matrix powers"},"type":"lvl2","url":"/evd#similarity-and-matrix-powers","position":6},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Similarity and matrix powers"},"content":"The particular relationship between matrices \\mathbf{A} and \\mathbf{D} in \n\n(7.2.7) is important.\n\nSimilar matrices\n\nIf \\mathbf{S} is any nonsingular matrix, we say that \\mathbf{B}=\\mathbf{S}\\mathbf{A}\\mathbf{S}^{-1} is a similarity transformation of \\mathbf{A}, and we say that \\mathbf{B} is similar to \\mathbf{A}.\n\nA similarity transformation does not change eigenvalues, a fact that is typically proved in elementary linear algebra texts.\n\nIf \\mathbf{S} is a nonsingular matrix, then \\mathbf{S}\\mathbf{A}\\mathbf{S}^{-1} has the same eigenvalues as \\mathbf{A}. \nSimilarity transformation has an interesting interpretation. First, consider the product of a nonsingular $\\mathbf{X}$ with any vector:\n\n```{math}\n  \\mathbf{y} = \\mathbf{X} \\mathbf{z} = z_1 \\mathbf{x}_1 +  \\dots + z_n \\mathbf{x}_n.\n```\n\nWe call $z_1,\\ldots,z_n$ the *coordinates* of the vector $\\mathbf{y}$ with respect to the columns of $\\mathbf{X}$. That is, $\\mathbf{z}$ is a representation of $\\mathbf{y}$ in the basis implied by the columns of $\\mathbf{X}$. But also $\\mathbf{z} = \\mathbf{X}^{-1} \\mathbf{y}$. Hence left-multiplication by $\\mathbf{X}^{-1}$ converts the vector $\\mathbf{y}$ into those coordinates. \n\n:::{prf:observation} Change of basis\nMultiplication by the inverse of a matrix performs a *change of basis* into the coordinates associated with the columns of that matrix.\n:::\n\nIn the product $\\mathbf{u} = \\mathbf{A} \\mathbf{x}$, think of $\\mathbf{x}$ as the input and $\\mathbf{u}$ as the output of the linear transformation defined by multiplication by $\\mathbf{A}$. Now the EVD {eq}`evdecomp` implies\n\n$$\n(\\mathbf{V}^{-1}\\mathbf{u}) = \\mathbf{D}(\\mathbf{V}^{-1}\\mathbf{x}).\n$$\n\nThis equation says that if you express the input $\\mathbf{x}$ and the output $\\mathbf{u}$ into the coordinates of the $\\mathbf{V}$-basis, then the relationship between them is diagonal. That is, the EVD is about finding a basis for $\\mathbb{C}^n$ in which the map $\\mathbf{x}\\mapsto\\mathbf{A}\\mathbf{x}$ is a diagonal one. Diagonal transformations are those in which the coordinates are independently rescaled. \n\n\nThe EVD is especially useful for matrix powers. To begin,\\mathbf{A}^2=(\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1})(\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1})=\\mathbf{V}\\mathbf{D}(\\mathbf{V}^{-1}\\mathbf{V})\\mathbf{D}\\mathbf{V}^{-1}=\\mathbf{V}\\mathbf{D}^2\\mathbf{V}^{-1}.\n\nMultiplying this result by \\mathbf{A} repeatedly, we find that\\mathbf{A}^k = \\mathbf{V}\\mathbf{D}^k\\mathbf{V}^{-1}.\n\nBecause \\mathbf{D} is diagonal, its power \\mathbf{D}^k is just the diagonal matrix of the kth powers of the eigenvalues.\n\nFurthermore, given a polynomial p(z)=c_0+c_1 z + \\cdots + c_m z^m, we can apply the polynomial to the matrix in a straightforward way,p(\\mathbf{A}) = c_0\\mathbf{I}  +c_1 \\mathbf{A} + \\cdots + c_m \\mathbf{A}^m.\n\nApplying \n\n(7.2.10) leads top(\\mathbf{A}) & = c_0\\mathbf{V}\\mathbf{V}^{-1}  +c_1 \\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1} + \\cdots + c_m \\mathbf{V}\\mathbf{D}^m\\mathbf{V}^{-1} \\\\ \n&= \\mathbf{V} \\cdot [ c_0\\mathbf{I}  +c_1 \\mathbf{D} + \\cdots + c_m \\mathbf{D}^m] \\cdot \\mathbf{V}^{-1} \\\\[1mm] \n&= \\mathbf{V} \\cdot \\begin{bmatrix}\n  p(\\lambda_1) & & & \\\\ & p(\\lambda_2) & &  \\\\ & & \\ddots & \\\\ & & & p(\\lambda_n)  \n\\end{bmatrix} \\cdot \\mathbf{V}^{-1}.\n\nFinally, given the convergence of Taylor polynomials to common functions, we are able to apply a function f to a square matrix by replacing p with f in \n\n(7.2.11).","type":"content","url":"/evd#similarity-and-matrix-powers","position":7},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Conditioning of eigenvalues"},"type":"lvl2","url":"/evd#conditioning-of-eigenvalues","position":8},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Conditioning of eigenvalues"},"content":"Just as linear systems have condition numbers that quantify the effect of finite precision, eigenvalue problems may be poorly conditioned too. While many possible results can be derived, we will use just one, the Bauer–Fike theorem.\n\nBauer–Fike\n\nLet \\mathbf{A}\\in\\mathbb{C}^{n\\times n} be diagonalizable, \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1}, with eigenvalues \\lambda_1,\\ldots,\\lambda_n. If μ is an eigenvalue of \\mathbf{A}+\\mathbf{E} for a complex matrix \\mathbf{E}, then\\min_{j=1,\\ldots,n} |\\mu - \\lambda_j| \\le \\kappa(\\mathbf{V}) \\, \\| \\mathbf{E} \\|\\,,\n\nwhere \\|\\cdot\\| and κ are in the 2-norm.\n\nThe Bauer–Fike theorem tells us that eigenvalues can be perturbed by an amount that is \\kappa(\\mathbf{V}) times larger than perturbations to the matrix. This result is a bit less straightforward than it might seem—eigenvectors are not unique, so there are multiple possible values for \\kappa(\\mathbf{V}). Even so, the theorem indicates caution when a matrix has eigenvectors that form an ill-conditioned matrix. The limiting case of \\kappa(\\mathbf{V})=\\infty might be interpreted as indicating a nondiagonalizable matrix \\mathbf{A}. The other extreme is also of interest: \\kappa(\\mathbf{V})=1, which implies that \\mathbf{V} is unitary.\n\nNormal matrix\n\nIf \\mathbf{A} has an EVD \n\n(7.2.7) with a unitary eigenvector matrix \\mathbf{V}, then \\mathbf{A} is a normal matrix.\n\nAs we will see in \n\nSymmetry and definiteness, hermitian and real symmetric matrices are normal. Since the condition number of a unitary matrix is equal to 1, \n\n(7.2.13) guarantees that a perturbation of a normal matrix changes the eigenvalues by the same amount or less.\n\nEigenvalue conditioning\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7\nA = randn(n, n) + 1im * randn(n, n)\nA = (A + A') / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nλ, V = eigen(A)\n@show cond(V);\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones.\n\nSince the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = 1:n\nA = triu(x * ones(n)')\nA[1:5, 1:5]\n\nThis matrix is not especially close to normal.\n\nλ, V = eigen(A)\n@show cond(V);\n\nAs a result, the eigenvalues can change by a good deal more.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\nBF_bound = cond(V) * norm(ΔA)\n@show maximum(dist), BF_bound;\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nplt = scatter(λ, zeros(n), aspect_ratio=1)\nfor _ in 1:200\n    ΔA = eps(Float32) * normalize(randn(n, n) + 1im * randn(n, n))\n    λ̃ = eigvals(A + ΔA)\n    scatter!(real(λ̃), imag(λ̃), m=1, color=:black)\nend\nplt\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nEigenvalue conditioning\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7;\nA = randn(n, n) + 1i * randn(n, n);\nA = (A + A') / 2;\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones. Note: since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = [];\nfor j = 1:n\n    dist = [dist; min(abs(dd - lambda(j)))];\nend\ndist\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20;\nx = (1:n)';\nA = triu(x * ones(1, n));\nA(1:5, 1:5)\n\nThis matrix is not at all close to normal.\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = -Inf;\nfor j = 1:n\n    dist = max(dist, min(abs(dd - lambda(j))));\nend\nfprintf(\"max change in eigenvalues: %.2e\", dist)\nfprintf(\"Bauer-Fike upper bound: %.2e\", cond(V) * norm(E))\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nplot(lambda, 0*lambda, 'o')\naxis equal; hold on\nfor k = 1:60\n    E = randn(n, n) + 1i * randn(n, n);\n    E = eps(single(1)) * E / norm(E);\n    dd = eig(A + E);\n    plot(real(dd), imag(dd), 'k.', markersize=2)\nend\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nEigenvalue conditioning\n\nWe first define a hermitian matrix. Note that we add the conjugate transpose of a matrix to itself.\n\nn = 7\nA = random.randn(n, n) + 1j * random.randn(n, n)\nA = (A + conj(A.T)) / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nfrom numpy.linalg import eig\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.5f}\")\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. Note that the Bauer–Fike theorem uses absolute differences, not relative ones. Since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(dist)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = arange(n) + 1\nA = triu(outer(x, ones(n)))\nprint(A[:5, :5])\n\nThis matrix is not at all close to normal.\n\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.2e}\")\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(f\"Maximum eigenvalue change is {max(dist):.2e}\")\nprint(f\"The Bauer-Fike upper bound is {cond(V) * norm(E, 2):.2e}\")\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nscatter(d, zeros(n), 18)\naxis(\"equal\") \nfor _ in range(100):\n    E = random.randn(n, n) + 1j * random.randn(n, n)\n    E = finfo(np.float32).eps * E / norm(E, 2)\n    dd, _ = eig(A + E)\n    scatter(real(dd), imag(dd), 2, 'k')\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.","type":"content","url":"/evd#conditioning-of-eigenvalues","position":9},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Computing the EVD"},"type":"lvl2","url":"/evd#computing-the-evd","position":10},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Computing the EVD"},"content":"Roots of the characteristic polynomial are not used in numerical methods for finding eigenvalues. Practical algorithms for computing the EVD go beyond the scope of this book. The essence of the matter is the connection to matrix powers indicated in \n\n(7.2.10). (We will see much more about the importance of matrix powers in Chapter 8.)\n\nIf the eigenvalues have different complex magnitudes, then as k\\to\\infty the entries on the diagonal of \\mathbf{D}^k become increasingly well separated and easy to pick out. It turns out that there is an astonishingly easy and elegant way to accomplish this separation without explicitly computing the matrix powers.\n\nFrancis QR iteration\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diagm([-6, -1, 2, 4, 5])\nV, R = qr(randn(5, 5))    # V is unitary\nA = V * D * V'\n\neigvals(A)\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\neigvals(A)\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in 1:40\n    Q, R = qr(A)\n    A = R * Q\nend\nA\n\nFrancis QR iteration\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diag([-6, -1, 2, 4, 5]);\n[V, R]= qr(randn(5, 5));    % V is unitary\nA = V * D * V';\n\nsort(eig(A))\n\nNow we will take the QR factorization and just reverse the factors.\n\n[Q, R] = qr(A);\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nsort(eig(A))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k = 1:40\n    [Q, R] = qr(A);\n    A = R * Q;\nend\nformat short e\nA\n\nFrancis QR iteration\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nfrom numpy.linalg import qr\nD = diag([-6, -1, 2, 4, 5])\nV, R = qr(random.randn(5, 5))\nA = V @ D @ V.T    # note that V.T = inv(V) here\n\nprint(sort(eig(A)[0]))\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R @ Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nprint(sort(eig(A)[0]))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in range(40):\n    Q, R = qr(A)\n    A = R @ Q\nset_printoptions(precision=4)\nprint(A)\n\nThe process demonstrated in \n\nDemo 7.2.4 is known as the Francis QR iteration, and it can be formulated as an O(n^3) algorithm for finding the EVD. Such an algorithm is the foundation of what the eigen function uses.","type":"content","url":"/evd#computing-the-evd","position":11},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Exercises"},"type":"lvl2","url":"/evd#exercises","position":12},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Exercises"},"content":"(a) ✍ Suppose that matrix \\mathbf{A} has an eigenvalue λ. Show that for any induced matrix norm, \\| \\mathbf{A} \\|\\ge |\\lambda|.\n\n(b) ✍ Find a matrix \\mathbf{A} such that \\| \\mathbf{A} \\|_2 is strictly larger than |\\lambda| for all eigenvalues λ. (Proof-by-computer isn’t allowed here. You don’t need to compute \\| \\mathbf{A} \\|_2 exactly, just a lower bound for it.)\n\n✍ Prove that the matrix \\mathbf{B} in \n\n(7.2.8) does not have two independent eigenvectors.\n\n⌨ Use eigvals to find the eigenvalues of each matrix. Then for each eigenvalue λ, use rank to verify that \\lambda\\mathbf{I} minus the given matrix is singular.\n\n\\mathbf{A} = \\begin{bmatrix}\n 2  & -1 & 0 \\\\\n -1 &  2 & -1 \\\\\n 0  & -1 & 2\n \\end{bmatrix}\\qquad\n\\mathbf{B} = \\begin{bmatrix}\n      2 & -1 & -1 \\\\\n     -2 &  2 & -1 \\\\\n     -1 & -2 & 2\n   \\end{bmatrix} \\qquad\n \\mathbf{C} = \\begin{bmatrix}\n      2 & -1 & -1 \\\\\n     -1 &  2 & -1 \\\\\n     -1 & -1 & 2\n   \\end{bmatrix} \n\n\\mathbf{D} = \\begin{bmatrix}\n   3 & 1 & 0 & 0 \\\\\n   1 & 3 & 1 & 0 \\\\\n   0 & 1 & 3 & 1 \\\\\n   0 & 0 & 1 & 3\n \\end{bmatrix}\\qquad \n\\mathbf{E} = \\begin{bmatrix}\n      4 & -3 & -2 & -1\\\\\n     -2 &  4 & -2 & -1 \\\\\n     -1 & -2 & 4  & -1 \\\\\n     -1 & -2 & -1 & 4 \\\\\n   \\end{bmatrix} \n\n(a) ✍ Show that the eigenvalues of a diagonal n\\times n matrix \\mathbf{D} are the diagonal entries of \\mathbf{D}. (That is, produce the associated eigenvectors.)\n\n(b) ✍ The eigenvalues of a triangular matrix are its diagonal entries. Prove this in the 3\\times 3 case,  \\mathbf{T} =\n  \\begin{bmatrix}\n    t_{11} & t_{12}&  t_{13}\\\\ 0 & t_{22} & t_{23} \\\\ 0 & 0 & t_{33}\n  \\end{bmatrix},\n\nby finding the eigenvectors. (Start by showing that [1,0,0]^T is an eigenvector. Then show how to make [a,1,0]^T an eigenvector, except for one case that does not change the outcome. Continue the same logic for [a,b,1]^T.)\n\n✍ Let \\mathbf{A}=\\displaystyle\\frac{\\pi}{6}\\begin{bmatrix} 4 & 1 \\\\ 4 & 4 \\end{bmatrix}.\n\n(a) Show that\\lambda_1=\\pi,\\, \\mathbf{v}_1=\\begin{bmatrix}1 \\\\ 2 \\end{bmatrix}, \\quad \\lambda_2=\\frac{\\pi}{3},\\, \\mathbf{v}_2=\\begin{bmatrix}1 \\\\ -2 \\end{bmatrix}\n\nyield an EVD of \\mathbf{A}.\n\n(b) Use \n\n(7.2.12) to evaluate p(\\mathbf{A}), where p(x) = (x-\\pi)^4.\n\n(c) Use the function analog of \n\n(7.2.12) to evaluate \\cos(\\mathbf{A}).\n\n⌨ In \n\nExercise 2.3.5, you showed that the\ndisplacements of point masses placed along a string satisfy a linear system \\mathbf{A}\\mathbf{q}=\\mathbf{f} for an (n-1)\\times(n-1) matrix \\mathbf{A}. The eigenvalues and eigenvectors of \\mathbf{A} correspond to resonant frequencies and modes of vibration of the string. For n=40 and the physical parameters given in part (b) of that exercise, find the eigenvalue decomposition of \\mathbf{A}. Report the three eigenvalues with smallest absolute value, and plot all three associated eigenvectors on a single graph (as functions of the vector row index).\n\n⌨ \n\nDemo 7.2.4 suggests that the result of the Francis QR iteration as k\\to\\infty sorts the eigenvalues on the diagonal according to a particular ordering. Following the code there as a model, create a random matrix with eigenvalues equal to -9.6,-8.6,\\ldots,10.4, perform the iteration 200 times, and check whether the sorting criterion holds in your experiment as well.\n\n⌨ Eigenvalues of random matrices and their perturbations can be very interesting.\n\n(a) Let A=randn(60,60). Scatter plot its eigenvalues in the complex plane, using aspect_ratio=1 and red diamonds as markers.\n\n(b) Let \\mathbf{E} be another random 60\\times 60 matrix, and on top of the previous graph, plot the eigenvalues of \\mathbf{A}+0.05\\mathbf{E} as blue dots. Repeat this for 100 different values of \\mathbf{E}.\n\n(c) Let T=triu(A). On a new graph, scatter plot the eigenvalues of \\mathbf{T} in the complex plane. (They all lie on the real axis.)\n\n(d) Repeat part (b) with \\mathbf{T} in place of \\mathbf{A}.\n\n(e) Compute some condition numbers and apply \n\nTheorem 7.2.3 to explain the dramatic difference between your plots with respect to the dot distributions.\n\nThe terms “factorization” and “decomposition” are equivalent; they coexist mainly for historical reasons.\n\nIn fact, the situation is reversed: eigenvalue methods are among the best ways to compute the roots of a given polynomial.","type":"content","url":"/evd#exercises","position":13},{"hierarchy":{"lvl1":"From matrix to insight"},"type":"lvl1","url":"/insight","position":0},{"hierarchy":{"lvl1":"From matrix to insight"},"content":"Any two-dimensional array of numbers may be interpreted as a matrix. Whether or not this is the only point of view that matters to a particular application, it does lead to certain types of analysis. The related mathematical and computational tools are universally applicable and find diverse uses.","type":"content","url":"/insight","position":1},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Tables as matrices"},"type":"lvl2","url":"/insight#tables-as-matrices","position":2},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Tables as matrices"},"content":"Tables are used to represent variation of a quantity with respect to two variables. These variables may be encoded as the rows and columns of a matrix.\n\nA corpus is a collection of text documents. A term-document matrix has one column for each document and one row for each unique term appearing in the corpus. The (i,j) entry of the matrix is the number of times term i appears in document j. That is, column j of the matrix is a term-frequency vector quantifying all occurrences of the indexed terms. A new document could be represented by its term-frequency vector, which is then comparable to the columns of the matrix. Or, a new term could be represented by counting its appearances in all of the documents and be compared to the rows of the matrix.\n\nIt turns out that by finding the \n\nsingular value decomposition of the term-document matrix, the strongest patterns within the corpus can be isolated, frequently corresponding to what we interpret as textual meaning. This is known as latent semantic analysis.\n\nEach vote cast in the U. S. Congress is \n\navailable for download. We can put members of Congress along the columns of a matrix and bills along the rows, recording a number that codes for “yea,”  “nay,” “none,” etc. The \n\nsingular value decomposition can reveal an objective, reproducible analysis of the partisanship and cooperation of individual members.\n\nIn 2006 the online video service Netflix started an open competition for a $1 million prize. They provided a data set of 100,480,507 ratings (one to five stars) made by 480,189 users for 17,770 movies. Each rating is implicitly an entry in a 17,770-by-480,189 matrix. The object of the prize was to predict a user’s ratings for movies they had not rated. This is known as a matrix completion problem. (It took 6 days for a contestant to improve on Netflix’s private algorithm, and in 2009 the million-dollar prize was awarded to a team that had improved the performance by over 10%.)","type":"content","url":"/insight#tables-as-matrices","position":3},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Graphs as matrices"},"type":"lvl2","url":"/insight#graphs-as-matrices","position":4},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Graphs as matrices"},"content":"Graphs and adjacency matrices\n\nA graph or network consists of a set V of nodes and a set E of edges, each of which is an ordered pair of nodes. The graph is undirected if for every edge (v_i,v_j), the pair (v_j,v_i) is also an edge; otherwise the graph is directed.\n\nThe \n\nadjacency matrix of a graph with n nodes V and edge set E is the n\\times n matrix whose elements areA_{ij} =\n\\begin{cases}\n1 & \\text{if $(v_i,v_j)\\in E$ (i.e., there is an edge from node $i$ to node $j$)},\\\\\n0 & \\text{otherwise}.\n\\end{cases}\n\nGraphs are a useful way to represent the link structure of social networks, airline routes, power grids, sports teams, and web pages, to name a few examples. The natural interpretation is that the edge (v_i,v_j) denotes a link from node i to node j, in which case we say that node i is adjacent to node j. One usually visualizes small graphs by drawing points for nodes and arrows or lines for the edges.\n\nHere are some elementary results about adjacency matrices.\n\nFor any graph with \n\nadjacency matrix \\mathbf{A},\n\nThe graph is undirected if and only if \\mathbf{A} is symmetric, and\n\nFor any positive integer k, the (i,j) element of \\mathbf{A}^k is the number of ways to walk from node i to node j by following along exactly k edges.\n\nPart 1 follows immediately from the definitions. Part 2 is clearly true for k=1. Assume inductively that it is true for k-1. Each walk of length k from node i to node j must be a walk of length k-1 from i to node p, then a walk of length 1 from node p to node j. The total number of such walks is therefore\\sum_{p=1}^n [\\mathbf{A}^{k-1}]_{ip} \\cdot A_{pj},\n\nwhich is the (i,j) element of \\mathbf{A}^k.\n\nAdjacency matrix\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nThe graphplot function makes a visual representation of this graph.\n\ngraphplot(A, names=1:4, markersize=0.2, arrow=6)\n\nSince this adjacency matrix is not symmetric, the edges are all directed, as indicated by the arrows. Here are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0]\ngraphplot(A, names=1:4, markersize=0.2)\n\nAdjacency matrix\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nSince this adjacency matrix is not symmetric, the edges are all directed. We use digraph to create a directed graph.\n\nG = digraph(A);\nplot(G)\n\nHere are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0];\nplot(graph(A))\n\nA “buckyball” is an allotrope of carbon atoms with the same connection structure as a soccer ball.\n\nplot(graph(bucky))\n\nAdjacency matrix\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = array([[0, 1, 0, 0], [1, 0, 0, 0], [1, 1, 0, 1], [0, 1, 1, 0]])\nprint(A)\n\nThe networkx package has many functions for working with graphs. Here, we instruct it to create a directed graph from the adjacency matrix, then make a drawing of it.\n\nimport networkx as nx\nG = nx.from_numpy_array(A, create_using=nx.DiGraph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nHere are the counts of all walks of length 3 in the graph:\n\nprint(A**3)\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = array([[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [0, 1, 0, 0]])\nG = nx.from_numpy_array(A, create_using=nx.Graph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nThe representation of a graph by its adjacency matrix opens up the possibility of many kinds of analysis of the graph. One might ask whether the nodes admit a natural partition into clusters, for example. Or one might ask to rank the nodes in order of importance to the network as determined by some objective criteria—an application made famous by Google’s PageRank algorithm, and one which is mathematically stated as an \n\neigenvalue problem.","type":"content","url":"/insight#graphs-as-matrices","position":5},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Images as matrices"},"type":"lvl2","url":"/insight#images-as-matrices","position":6},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Images as matrices"},"content":"Computers typically represent images as rectangular arrays of pixels, each of which is colored according to numerical values for red (R), green (G), and blue (B) components of white light. Most often, these are given as integers in the range from zero (no color) to 255 (full color). Thus, an image that is m-by-n pixels can be stored as an m-by-n-by-3 array of integer values. In Julia, we can work with an m\\times n matrix of 3-vectors representing entire colors.\n\nImages as matrices\n\nThe Images package has many functions for image manipulation, and TestImages has some standard images to play with.\n\nimg = testimage(\"mandrill\")\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nimg[100, 10]\n\nYou can use eltype to find out the type of the elements of any array.\n\neltype(img)\n\nIt’s possible to extract matrices of red, green, and blue intensities, scaled from 0 to 1.\n\nR, G, B = red.(img), green.(img), blue.(img);\n@show minB, maxB = extrema(B);\n\nOr we can convert the pixels to gray, each pixel again scaled from 0 to 1.\n\nGray.(img)\n\nIn order to do our usual operations, we need to tell Julia that we want to interpret the elements of the image matrix as floating-point values.\n\nA = Float64.(Gray.(img))\nA[1:4, 1:5]\n\nWe can use Gray to reinterpret a matrix of floating-point values as grayscale pixels.\n\nGray.(reverse(A, dims=1))\n\nImages as matrices\n\nMATLAB ships with a few test images to play with.\n\nA = imread('peppers.png');\ncolor_size = size(A)\n\nUse imshow to display the image.\n\nimshow(A)\n\nThe image has three layers or channels for red, green, and blue. We can deal with each layer as a matrix, or (as below) convert it to a single matrix indicating shades of gray from black (0) to white (255). Either way, we have to explicitly convert the entries to floating-point values rather than integers.\n\nA = im2gray(A);   % collapse from 3 dimensions to 2\ngray_size = size(A)\nimshow(A)\n\nBefore we can do any numerical computation, we need to convert the image to a matrix of floating-point numbers.\n\nA = double(A);\n\nImages as matrices\n\nWe will use a test image from the well-known scikit-image package.\n\nfrom skimage import data as testimages\nimg = getattr(testimages, \"coffee\")()\nimshow(img)\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nprint(f\"image has shape {img.shape}\")\nprint(f\"first pixel has value {img[0, 0]}\")\n\nThe three values at each pixel are for intensities of red, green, and blue. We can convert each of those layers into an ordinary matrix of values between 0 and 255, which is maximum intensity.\n\nR = img[:, :, 0]\nprint(\"upper left corner of the red plane is:\")\nprint(R[:5, :5])\nprint(f\"red channel values range from {R.min()} to {R.max()}\")\n\nIt may also be convenient to convert the image to grayscale, which has just one layer of values from zero (black) to one (white).\n\nfrom skimage.color import rgb2gray\nA = rgb2gray(img)\nA[:5, :5]\nprint(\"upper left corner of grayscale:\")\nprint(A[:5, :5])\nprint(f\"gray values range from {A.min()} to {A.max()}\")\n\nimshow(A, cmap='gray')\naxis('off');\n\nSome changes we make to the grayscale matrix are easy to interpret visually.\n\nimshow(flipud(A), cmap='gray')\naxis('off');\n\nRepresentation of an image as a matrix allows us to describe some common image operations in terms of linear algebra. For example, in \n\nSingular value decomposition we will use the singular value decomposition to compress the information, and in \n\nMatrix-free iterations we will see how to apply and remove blurring effects.","type":"content","url":"/insight#images-as-matrices","position":7},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Exercises"},"type":"lvl2","url":"/insight#exercises","position":8},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Exercises"},"content":"✍ Consider the terms numerical, analysis, and fun. Write out the term-document matrix for the following statements:\n\n(a) Numerical analysis is the most fun type of analysis.\n\n(b) It’s fun to produce numerical values for the digits of pi.\n\n(c) Complex analysis is a beautiful branch of mathematics.\n\n✍ Write out the adjacency matrix for the following graph on six nodes.\n\n✍ Here is a graph adjacency matrix.\\begin{bmatrix}\n0 & 1 & 0 & 1 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 & 1 \\\\\n1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n1 & 1 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0   \n\\end{bmatrix}\n\n(a) How many vertices are adjacent to vertex 5?\n\n(b) How many edges are in the graph?\n\n(c) Is the graph directed or undirected?\n\n(d) Draw the graph.\n\n⌨ Refer to \n\nDemo 7.1.5 on loading and displaying test images.\n\n(a) Display the “lighthouse” test image upside-down.\n\n(b) Display it mirror-reversed from left to right.\n\n(c) Display the image so that it is cropped to isolate the black beacon section at the top of the lighthouse.\n\n⌨ For this problem you need to download and import data via:datafile = download(\"https://tobydriscoll.net/fnc-julia/_static/resources/actors.jld2\")\n@load datafile A\n\nBased on data provided by the Self-Organized Networks Database at the University of Notre Dame, it contains information about the appearances of 392,400 actors in 127,823 movies, as given by the Internet Movie Database. The matrix \\mathbf{A} has A_{ij}=1 if actor j appeared in movie i and zero elements elsewhere.\n\n(a) What is the maximum number of actors appearing in any one movie?\n\n(b) How many actors appeared in exactly three movies?\n\n(c) Define \\mathbf{C}=\\mathbf{A}^T\\mathbf{A}. How many nonzero entries does \\mathbf{C} have? What is the interpretation of C_{ij}?","type":"content","url":"/insight#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-6","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"Details on the computation of the eigenvalue and singular value decompositions are presented at length in \n\nStewart (2001) and more briefly in Chapters 7 and 8 of \n\nGolub & Van Loan (1996). A classic reference on the particulars of the symmetric case is \n\nParlett (1980), while \n\nTrefethen & Embree (2005) focuses on the non-normal case. Dimension reduction via the SVD often goes by the name principal component analysis, which is the subject of \n\nJolliffe (2002).","type":"content","url":"/next-6","position":1},{"hierarchy":{"lvl1":"Matrix analysis"},"type":"lvl1","url":"/overview-6","position":0},{"hierarchy":{"lvl1":"Matrix analysis"},"content":"Judge me by my size, do you?\n\nYoda, The Empire Strikes Back\n\nIn previous chapters, we have seen how matrices that represent square or overdetermined linear systems of equations can be manipulated into LU and QR factorizations. But matrices have other factorizations that are more intrinsic to their nature as mathematical linear transformations. The most fundamental of these are the eigenvalue and singular value decompositions.\n\nThese decompositions can be used to solve linear and least-squares systems, but they have greater value in how they represent the matrix itself. They lead to critical and quantitative insights about the structure of the underlying transformation and suggest ways to approximate it efficiently. In this chapter, we will look at both of these fundamental decompositions and hint at just a few of their computational applications.","type":"content","url":"/overview-6","position":1},{"hierarchy":{"lvl1":"Singular value decomposition"},"type":"lvl1","url":"/svd","position":0},{"hierarchy":{"lvl1":"Singular value decomposition"},"content":"We now introduce another factorization that is as fundamental as the EVD.\n\nSingular value decomposition (SVD)\n\nThe singular value decomposition of an m\\times n matrix \\mathbf{A} is\\mathbf{A} = \\mathbf{U} \\mathbf{S} \\mathbf{V}^*,\n\nwhere \\mathbf{U}\\in\\mathbb{C}^{m\\times m} and \\mathbf{V}\\in\\mathbb{C}^{n\\times n} are unitary and \\mathbf{S}\\in\\mathbb{R}^{m\\times n} is real and diagonal with nonnegative elements.\n\nThe columns of \\mathbf{U} and \\mathbf{V} are called left and right singular vectors, respectively. The diagonal elements of \\mathbf{S}, written \\sigma_1,\\ldots,\\sigma_r, for r=\\min\\{m,n\\}, are called the singular values of \\mathbf{A} and are ordered so that\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r\\ge 0, \\qquad r=\\min\\{m,n\\}.\n\nWe call \\sigma_1 the principal singular value and \\mathbf{u}_{1} and \\mathbf{v}_{1} the principal singular vectors.\n\nEvery m\\times n matrix has an SVD. The singular values of a matrix are unique, but the singular vectors are not. If the matrix is real, then \\mathbf{U} and \\mathbf{V} in \n\n(7.3.1) can be chosen to be real, orthogonal matrices.\n\nThe nonuniqueness is easy: for instance, we can replace \\mathbf{U} and \\mathbf{V} by their negatives without affecting \n\n(7.3.1). Proof of the other statements usually relies on induction in the size of \\mathbf{A} and can be found in advanced linear algebra texts.\n\nIt is easy to check that\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}\n= \\left(\\frac{1}{5} \\begin{bmatrix}\n  3 & -4 \\\\ 4 & 3\n\\end{bmatrix}\\,\\right) \\cdot \\begin{bmatrix}\n  5 \\\\ 0\n\\end{bmatrix}\\cdot \\begin{bmatrix}\n  1\n\\end{bmatrix}\n\nmeets all the requirements of an SVD. Interpreted as a matrix, the vector [3,4] has the lone singular value 5.\n\nSuppose \\mathbf{A} is a real matrix and that \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T is an SVD. Then \\mathbf{A}^T=\\mathbf{V}\\mathbf{S}^T\\mathbf{U}^T meets all the requirements of an SVD for \\mathbf{A}^T: the first and last matrices are orthogonal, and the middle matrix is diagonal with nonnegative elements. Hence \\mathbf{A} and \\mathbf{A}^T have the same singular values.","type":"content","url":"/svd","position":1},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Connections to the EVD"},"type":"lvl2","url":"/svd#connections-to-the-evd","position":2},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Connections to the EVD"},"content":"The nonzero eigenvalues of \\mathbf{A}^*\\mathbf{A} are the squares of the singular values of \\mathbf{A}.\n\nLet \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* be m\\times n, and compute the square hermitian matrix \\mathbf{B}=\\mathbf{A}^*\\mathbf{A}:\\mathbf{B} = (\\mathbf{V}\\mathbf{S}^*\\mathbf{U}^*) (\\mathbf{U}\\mathbf{S}\\mathbf{V}^*) = \\mathbf{V}\\mathbf{S}^*\\mathbf{S}\\mathbf{V}^* = \\mathbf{V}(\\mathbf{S}^T\\mathbf{S})\\mathbf{V}^{-1}.\n\nNote that \\mathbf{S}^T\\mathbf{S} is a diagonal n \\times n matrix. There are two cases to consider. If m \\ge n, then\\mathbf{S}^T\\mathbf{S} = \n\\begin{bmatrix}\n  \\sigma_1^2 & & \\\\\n  & \\ddots & \\\\\n  & & \\sigma_n^2\n\\end{bmatrix}.\n\nOn the other hand, if m<n, then\\mathbf{S}^T\\mathbf{S} =\n\\begin{bmatrix}\n  \\sigma_1^2 & & & \\\\\n  & \\ddots & & \\\\\n  & & \\sigma_m^2 & \\\\\n  & & & \\boldsymbol{0}\n\\end{bmatrix}.\n\nExcept for some unimportant technicalities, the eigenvectors of \\mathbf{A}^*\\mathbf{A}, when appropriately ordered and normalized, are right singular vectors of \\mathbf{A}. The left singular vectors could then be deduced from the identity \\mathbf{A}\\mathbf{V} = \\mathbf{U}\\mathbf{S}.\n\nAnother close connection between EVD and SVD comes via the (m+n)\\times (m+n) matrix\\mathbf{C} =\n\\begin{bmatrix}\n0 & \\mathbf{A}^* \\\\ \\mathbf{A} & 0\n\\end{bmatrix}.\n\nIf σ is a singular value of \\mathbf{B}, then σ and -\\sigma are eigenvalues of \\mathbf{C}, and the associated eigenvector immediately reveals a left and a right singular vector (see \n\nExercise 11). This connection is implicitly exploited by software to compute the SVD.","type":"content","url":"/svd#connections-to-the-evd","position":3},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Interpreting the SVD"},"type":"lvl2","url":"/svd#interpreting-the-svd","position":4},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Interpreting the SVD"},"content":"Another way to write \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* is\\mathbf{A}\\mathbf{V}=\\mathbf{U}\\mathbf{S}.\n\nTaken columnwise, this equation means\\mathbf{A} \\mathbf{v}_{k} = \\sigma_k \\mathbf{u}_{k}, \\qquad k=1,\\ldots,r=\\min\\{m,n\\}.\n\nIn words, each right singular vector is mapped by \\mathbf{A} to a scaled version of its corresponding left singular vector; the magnitude of scaling is its singular value.\n\nBoth the SVD and the EVD describe a matrix in terms of some special vectors and a small number of scalars. \n\nTable 7.3.1 summarizes the key differences. The SVD sacrifices having the same basis in both source and image spaces—after all, they may not even have the same dimension—but as a result gains orthogonality in both spaces.\n\nTable 7.3.1:Comparison of the EVD and SVD\n\nEVD\n\nSVD\n\nexists for most square matrices\n\nexists for all rectangular and square matrices\n\n\\mathbf{A}\\mathbf{x}_k = \\lambda_k \\mathbf{x}_k\n\n\\mathbf{A} \\mathbf{v}_k = \\sigma_k \\mathbf{u}_k\n\nsame basis for domain and range of \\mathbf{A}\n\ntwo orthonormal bases\n\nmay have poor conditioning\n\nperfectly conditioned","type":"content","url":"/svd#interpreting-the-svd","position":5},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Thin form"},"type":"lvl2","url":"/svd#thin-form","position":6},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Thin form"},"content":"In \n\nThe QR factorization we saw that a matrix has both full and thin forms of the QR factorization. A similar situation holds with the SVD.\n\nSuppose \\mathbf{A} is m\\times n with m > n and let \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* be an SVD. The last m-n rows of \\mathbf{S} are all zero due to the fact that \\mathbf{S} is diagonal. Hence\\begin{align*}\n  \\mathbf{U} \\mathbf{S} & =\n  \\begin{bmatrix}\n    \\mathbf{u}_1 & \\cdots & \\mathbf{u}_n & \\mathbf{u}_{n+1} & \\cdots & \\mathbf{u}_m\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\sigma_1 & &  \\\\\n    & \\ddots &  \\\\\n    & & \\sigma_n \\\\\n    & & \\\\\n    & \\boldsymbol{0} & \\\\\n    & &\n  \\end{bmatrix} \\\\\n  &=\n  \\begin{bmatrix}\n    \\mathbf{u}_1 & \\cdots & \\mathbf{u}_n\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\sigma_1 & &  \\\\\n    & \\ddots &  \\\\\n    & & \\sigma_n\n  \\end{bmatrix} = \\hat{\\mathbf{U}} \\hat{\\mathbf{S}},\n\\end{align*}\n\nin which \\hat{\\mathbf{U}} is m\\times n and \\hat{\\mathbf{S}} is n\\times n. This allows us to define the thin SVD\\mathbf{A}=\\hat{\\mathbf{U}}\\hat{\\mathbf{S}}\\mathbf{V}^*,\n\nin which \\hat{\\mathbf{S}} is square and diagonal and \\hat{\\mathbf{U}} is ONC but not square.\n\nGiven the full SVD of \n\nExample 7.3.1, the corresponding thin SVD is\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}\n= \\left(\\frac{1}{5} \\begin{bmatrix}\n  3 \\\\ 4 \n\\end{bmatrix}\\, \\right) \\cdot \\begin{bmatrix}\n  5 \n\\end{bmatrix}\\cdot \\begin{bmatrix}\n  1\n\\end{bmatrix}.\n\nThe thin form retains all the information about \\mathbf{A} from the SVD; the factorization is still an equality, not an approximation. It is computationally preferable when m \\gg n, since it requires far less storage than a full SVD. For a matrix with more columns than rows, one can derive a thin form by taking the adjoint of the thin SVD of \\mathbf{A}^*.","type":"content","url":"/svd#thin-form","position":7},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"SVD and the 2-norm"},"type":"lvl2","url":"/svd#svd-and-the-2-norm","position":8},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"SVD and the 2-norm"},"content":"The SVD is intimately connected to the 2-norm, as the following theorem describes.\n\nSVD properties\n\nLet \\mathbf{A}\\in\\mathbb{C}^{m\\times n} have an SVD \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* in which \n\n(7.3.2) holds. Then:\n\nThe 2-norm satisfies\n\n:label: svdnorm\n| \\mathbf{A} |_2 = \\sigma_1.\n```\n\nThe rank of \\mathbf{A} is the number of nonzero singular values.\n\nLet r=\\min\\{m,n\\}. Then\n\n:label: svdcond\n\\kappa_2(\\mathbf{A}) = |\\mathbf{A}|_2|\\mathbf{A}^+|_2 = \\frac{\\sigma_1}{\\sigma_r},\n```where a division by zero implies that $\\mathbf{A}$ does not have full rank.\n\nThe conclusion  can be proved by vector calculus. In the square case m=n, \\mathbf{A} having full rank is identical to being invertible. The SVD is the usual means for computing the 2-norm and condition number of a matrix.\n\nSVD properties\n\nWe verify some of the fundamental SVD properties using standard Julia functions from LinearAlgebra.\n\nA = [i^j for i = 1:5, j = 0:3]\n\nTo get only the singular values, use svdvals.\n\nσ = svdvals(A)\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\n@show opnorm(A, 2);\n@show σ[1];\n\n@show cond(A, 2);\n@show σ[1] / σ[end];\n\nTo get singular vectors as well, use svd. The thin form of the factorization is the default.\n\nU, σ, V = svd(A);\n@show size(U);\n@show size(V);\n\nWe verify the orthogonality of the singular vectors as follows:\n\n@show opnorm(U' * U - I);\n@show opnorm(V' * V - I);\n\nSVD properties\n\nWe verify some of the fundamental SVD properties using the built-in svd function.\n\nA = vander(1:5);\nA = A(:, 1:4)\n\n[U, S, V] = svd(A);\ndisp(sprintf(\"U is %d by %d. S is %d by %d. V is %d by %d.\\n\", size(U), size(S), size(V)))\n\nWe verify the orthogonality of the singular vectors as follows:\n\nnorm(U' * U - eye(5))\nnorm(V' * V - eye(4))\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\ns = diag(S);\nnorm_A = norm(A)\nsigma_max = s(1)\n\ncond_A = cond(A)\nsigma_ratio = s(1) / s(end)\n\nSVD properties\n\nWe verify some of the fundamental SVD properties using standard Julia functions from LinearAlgebra.\n\nA = array([[(i + 1.0) ** j for j in range(4)] for i in range(5)])\nset_printoptions(precision=4)\nprint(A)\n\nThe factorization is obtained using svd from numpy.linalg.\n\nfrom numpy.linalg import svd\nU, sigma, Vh = svd(A)\nprint(\"singular values:\")\nprint(sigma)\n\nBy default, the full factorization type is returned. This can be a memory hog if one of the dimensions of \\mathbf{A} is very large.\n\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.T.shape)\n\nBoth \\mathbf{U} and \\mathbf{V} are orthogonal (in the complex case, unitary). Note that it’s \\mathbf{V}^* that is returned, not \\mathbf{V}.\n\nprint(f\"should be near zero: {norm(U.T @ U - eye(5), 2):.2e}\")\nprint(f\"should be near zero: {norm(Vh @ Vh.T - eye(4), 2):.2e}\")\n\nNext we test that we have the factorization promised by the SVD, using diagsvd to construct a rectangular diagonal matrix.\n\nfrom scipy.linalg import diagsvd\nS = diagsvd(sigma, 5, 4)\nprint(f\"should be near zero: {norm(A - U @ S @ Vh, 2):.2e}\")\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\nfrom numpy.linalg import cond\nprint(\"largest singular value:\", sigma[0])\nprint(\"2-norm of the matrix:  \", norm(A, 2))\nprint(\"singular value ratio:\", sigma[0] / sigma[-1])\nprint(\"2-norm condition no.:\", cond(A, 2))\n\nFor matrices that are much taller than they are wide, the thin SVD form is more memory-efficient, because \\mathbf{U} takes the same shape.\n\nA = random.randn(1000, 10)\nU, sigma, Vh = svd(A, full_matrices=False)\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.shape)","type":"content","url":"/svd#svd-and-the-2-norm","position":9},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Exercises"},"type":"lvl2","url":"/svd#exercises","position":10},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Exercises"},"content":"✍ Each factorization below is algebraically correct. The notation \\mathbf{I}_n means an n\\times n identity. In each case, determine whether it is an SVD. If it is, write down \\sigma_1, \\mathbf{u}_1, and \\mathbf{v}_1. If it is not, state all of the ways in which it fails the required properties.\n\n(a) \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix} = \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0 \n \\end{bmatrix} \\begin{bmatrix}\n   1 & 0 \\\\ 0 & 0\n \\end{bmatrix} \\begin{bmatrix}\n   0 & 1 \\\\ -1 & 0 \n \\end{bmatrix}\\qquad \n(b) \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix} =\n \\mathbf{I}_2 \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix}\n \\mathbf{I}_2\n\n\n(c)\n\\begin{bmatrix}\n   1 & 0\\\\ 0 & \\sqrt{2}\\\\ 1 & 0\n \\end{bmatrix} = \\begin{bmatrix}\n   \\alpha & 0 & -\\alpha \\\\ 0 & 1 & 0 \\\\ \\alpha & 0 & -\\alpha \n \\end{bmatrix}  \\begin{bmatrix}\n   \\sqrt{2} & 0 \\\\ 0 & \\sqrt{2} \\\\ 0 & 0 \n \\end{bmatrix}  \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0 \n \\end{bmatrix}, \\quad \\alpha=1/\\sqrt{2}\n\n\n(d)\n\\begin{bmatrix}\n   \\sqrt{2} & \\sqrt{2}\\\\ -1 & 1\\\\ 0 & 0\n \\end{bmatrix} =\n \\mathbf{I}_3  \\begin{bmatrix}\n   2 & 0 \\\\ 0 & \\sqrt{2} \\\\ 0 & 0 \n \\end{bmatrix}  \\begin{bmatrix}\n  \\alpha & \\alpha \\\\ -\\alpha & \\alpha \n \\end{bmatrix}, \\quad \\alpha=1/\\sqrt{2}\n\n✍ Apply \n\nTheorem 7.3.2 to find an SVD of \\mathbf{A}=\\displaystyle \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\\\ -1 & -1 \\end{bmatrix}.\n\n⌨ Let x be a vector of 1000 equally spaced points between 0 and 1. Suppose \\mathbf{A}_n is the 1000\\times n matrix whose (i,j) entry is x_i^{j-1} for j=1,\\ldots,n.\n\n(a) Print out the singular values of \\mathbf{A}_1, \\mathbf{A}_2, and \\mathbf{A}_3.\n\n(b) Make a log-linear plot of the singular values of \\mathbf{A}_{40}.\n\n(c) Repeat part (b) after converting the elements of x to type Float32 (i.e., single precision).\n\n(d) Having seen the plot for part (c), which singular values in part (b) do you suspect may be incorrect?\n\n⌨ See \n\nDemo 7.1.5 for how to get the “mandrill” test image. Make a log-linear scatter plot of the singular values of the matrix of grayscale intensity values. (The shape of this graph is surprisingly similar across a wide range of images.)\n\n✍ Prove that for a square real matrix \\mathbf{A}, \\| \\mathbf{A} \\|_2=\\| \\mathbf{A}^T \\|_2.\n\n✍ Prove  of \n\nTheorem 7.3.3, given that  is true. (Hint: If the SVD of \\mathbf{A} is known, what is the SVD of \\mathbf{A}^{+}?)\n\n✍ Suppose \\mathbf{A}\\in\\mathbb{R}^{m\\times n}, with m>n, has the thin SVD \\mathbf{A}=\\hat{\\mathbf{U}}\\hat{\\mathbf{S}}\\mathbf{V}^T. Show that the matrix \\mathbf{A}\\mathbf{A}^{+} is equal to \\hat{\\mathbf{U}}\\hat{\\mathbf{U}}^T. (You must be careful with matrix sizes in this derivation.)\n\n✍ In  \n\n(3.2.6) we defined the 2-norm condition number of a rectangular matrix as \\kappa(\\mathbf{A})=\\|\\mathbf{A}\\|\\cdot \\|\\mathbf{A}^{+}\\|, and then claimed (in the real case) that \\kappa(\\mathbf{A}^*\\mathbf{A})=\\kappa(\\mathbf{A})^2. Prove this assertion using the SVD.\n\n✍ Show that the square of each singular value of \\mathbf{A} is an eigenvalue of the matrix \\mathbf{A}\\mathbf{A}^* for any m\\times n matrix \\mathbf{A}. (You should consider the cases m>n and m\\le n separately.)\n\n✍ In this problem you will see how  is proved in the real case.\n\n(a) Use the technique of Lagrange multipliers to show that among vectors that satisfy \\|\\mathbf{x}\\|_2^2=1, any vector that maximizes \\|\\mathbf{A}\\mathbf{x}\\|_2^2 must be an eigenvector of \\mathbf{A}^T\\mathbf{A}. It will help to know that if \\mathbf{B} is any symmetric matrix, the gradient of the scalar function \\mathbf{x}^T\\mathbf{B}\\mathbf{x} with respect to \\mathbf{x} is 2\\mathbf{B}\\mathbf{x}.\n\n(b) Use the result of part (a) to prove  for real matrices.\n\n✍ Suppose \\mathbf{A}\\in\\mathbb{R}^{n \\times n}, and define \\mathbf{C} as in \n\n(7.3.7).\n\n(a) Suppose that \\mathbf{v}=\\begin{bmatrix} \\mathbf{x} \\\\ \\mathbf{y} \\end{bmatrix}, and write the block equation \\mathbf{C}\\mathbf{v} = \\lambda \\mathbf{v} as two individual equations involving both \\mathbf{x} and \\mathbf{y}.\n\n(b) By applying some substitutions, rewrite the equations from part (a) as one in which \\mathbf{x} was eliminated, and another in which \\mathbf{y} was eliminated.\n\n(c) Substitute the SVD \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T and explain why \\lambda^2=\\sigma_k^2 for some singular value \\sigma_k.\n\n(d) As a more advanced variation, modify the argument to show that \\lambda=0 is another possibility if \\mathbf{A} is not square.","type":"content","url":"/svd#exercises","position":11},{"hierarchy":{"lvl1":"Symmetry and definiteness"},"type":"lvl1","url":"/symm-eig","position":0},{"hierarchy":{"lvl1":"Symmetry and definiteness"},"content":"As we saw in \n\nExploiting matrix structure, symmetry can simplify the LU factorization into the symmetric form \\mathbf{A}=\\mathbf{L}\\mathbf{D}\\mathbf{L}^T. Important specializations occur as well for the eigenvalue and singular value factorizations. In this section we stay with complex-valued matrices, so we are interested in the case when \\mathbf{A}^*=\\mathbf{A}, i.e., \\mathbf{A} is hermitian. However, we often loosely speak of symmetry to mean this property even in the complex case. All of the statements in this section easily specialize to the real case.","type":"content","url":"/symm-eig","position":1},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Normality"},"type":"lvl2","url":"/symm-eig#normality","position":2},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Normality"},"content":"Suppose now that \\mathbf{A}^*=\\mathbf{A} and that \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* is an SVD. Since \\mathbf{S} is real and square, we have\\mathbf{A}^* = \\mathbf{V} \\mathbf{S}^* \\mathbf{U}^* = \\mathbf{V} \\mathbf{S} \\mathbf{U}^*,\n\nand it’s tempting to conclude that \\mathbf{U}=\\mathbf{V}. Happily, this is nearly true. The following theorem is typically proved in an advanced linear algebra course.\n\nSpectral decomposition\n\nIf \\mathbf{A}=\\mathbf{A}^*, then \\mathbf{A} has a diagonalization \\mathbf{A}=\\mathbf{V} \\mathbf{D} \\mathbf{V}^{-1} in which \\mathbf{V} is unitary and \\mathbf{D} is diagonal and real.\n\nAnother way to state the result of this theorem is that a hermitian matrix has real eigenvalues and a complete set of orthonormal eigenvectors—that is, it is normal. Because hermitian matrices are normal, their eigenvalue condition number is guaranteed to be 1 by \n\nTheorem 7.2.3.\n\nThe converse of \n\nTheorem 7.4.1 is also true: every normal matrix with real eigenvalues is hermitian. This was illustrated in \n\nDemo 7.2.3.\n\nFor a hermitian matrix, the EVD\\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1}=\\mathbf{V} \\mathbf{D} \\mathbf{V}^*\n\nis almost an SVD.\n\nIf \\mathbf{A}^*=\\mathbf{A} and \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1} is a unitary diagonalization, then\\mathbf{A} = (\\mathbf{V}\\mathbf{T})\\cdot |\\mathbf{D}|\\cdot \\mathbf{V}^*\n\nis an SVD, where |\\mathbf{D}| is the elementwise absolute value and \\mathbf{T} is diagonal with |T_{ii}|=1 for all i.\n\nLet T_{ii}=\\operatorname{sign}(D_{ii}) for all i. Then \\mathbf{T}^2=\\mathbf{I}, |\\mathbf{D}|=\\mathbf{T}\\mathbf{D}, and\\mathbf{A}=\\mathbf{V} \\mathbf{D} \\mathbf{V}^*=\\mathbf{V} \\mathbf{T}^2 \\mathbf{D} \\mathbf{V}^*=(\\mathbf{V} \\mathbf{T}) (\\mathbf{T} \\mathbf{D}) \\mathbf{V}^*.","type":"content","url":"/symm-eig#normality","position":3},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Rayleigh quotient"},"type":"lvl2","url":"/symm-eig#rayleigh-quotient","position":4},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Rayleigh quotient"},"content":"Recall that for a matrix \\mathbf{A} and compatible vector \\mathbf{x}, the quadratic form \\mathbf{x}^* \\mathbf{A} \\mathbf{x} is a scalar.\n\nGiven hermitian \\mathbf{A} and nonzero vector \\mathbf{x}, the Rayleigh quotient is the functionR_{\\mathbf{A}}(\\mathbf{x}) = \\frac{ \\mathbf{x}^* \\mathbf{A} \\mathbf{x}}{\\mathbf{x}^* \\mathbf{x}}.\n\nIf \\mathbf{v} is an eigenvector such that \\mathbf{A} \\mathbf{v}=\\lambda \\mathbf{v}, then one easily calculates that R_{\\mathbf{A}}(\\mathbf{v})=\\lambda. That is, the Rayleigh quotient maps an eigenvector into its associated eigenvalue.\n\nIf \\mathbf{A}^*=\\mathbf{A}, then the Rayleigh quotient has another interesting property: \\nabla R_{\\mathbf{A}}(\\mathbf{v})=\\boldsymbol{0} if \\mathbf{v} is an eigenvector. By a multidimensional Taylor series, then,R_{\\mathbf{A}}(\\mathbf{v}+\\epsilon\\mathbf{z}) = R_{\\mathbf{A}}(\\mathbf{v}) + 0 + O( \\epsilon^2) =  \\lambda + O( \\epsilon^2),\n\nas \\epsilon\\to 0. The conclusion is that a good estimate of an eigenvector becomes an even better estimate of an eigenvalue.\n\nRayleigh quotient\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nλ = 1:n\nD = diagm(λ)\nV, _ = qr(randn(n, n))   # get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = x -> (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nR(V[:, 7])\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nδ = @. 1 ./ 10^(1:5)\neval_diff = zeros(size(δ))\nfor (k, delta) in enumerate(δ)\n    e = randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 7] + e\n    eval_diff[k] = R(x) - 7\nend\nlabels = [\"perturbation δ\", \"δ²\", \"R(x) - λ\"]\npretty_table([δ δ .^ 2 eval_diff], header=labels)\n\nRayleigh quotient\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nlambda = 1:n;\nD = diag(lambda);\n[V, ~] = qr(randn(n, n));    % get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = @(x) (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nformat long\nR(V(:, 7))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\ndelta = 1 ./ 10 .^ (1:5)';\ndif = zeros(size(delta));\nfor k = 1:length(delta)\n    e = randn(n, 1);\n    e = delta(k) * e / norm(e);\n    x = V(:, 6) + e;\n    dif(k) = R(x) - lambda(6);\nend\ndisp(table(delta, dif, variablenames=[\"perturbation size\", \"R(x) - lambda\"]))\n\nRayleigh quotient\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nfrom numpy.linalg import qr\nn = 20\nd = arange(n) + 1\nD = diag(d)\nV, _ = qr(random.randn(n, n))    # get a random orthogonal V\nA = V @ D @ V.T\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = lambda x: dot(x, A @ x) / dot(x, x)\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nprint(R(V[:, 6]))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nresults = PrettyTable([\"perturbation size\", \"R.Q. - λ\"])\nfor delta in 1 / 10 ** arange(1, 6):\n    e = random.randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 5] + e\n    quotient = R(x)\n    results.add_row([delta, quotient - d[5]])\n\nprint(results)","type":"content","url":"/symm-eig#rayleigh-quotient","position":5},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Definite, semidefinite, and indefinite matrices"},"type":"lvl2","url":"/symm-eig#definite-semidefinite-and-indefinite-matrices","position":6},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Definite, semidefinite, and indefinite matrices"},"content":"In the real case, we called a symmetric matrix \\mathbf{A} symmetric positive definite (SPD) if \\mathbf{x}^T \\mathbf{A}\\mathbf{x} > 0  for all nonzero vectors \\mathbf{x}. In the complex case the relevant property is  hermitian positive definite (HPD), meaning that \\mathbf{A}^*=\\mathbf{A} and \\mathbf{x}^* \\mathbf{A}\\mathbf{x} > 0 for all complex vectors \\mathbf{x}. Putting this property together with the Rayleigh quotient leads to the following.\n\nIf \\mathbf{A}^*=\\mathbf{A}, then the following statements are equivalent.\n\n\\mathbf{A} is HPD.\n\nThe eigenvalues of \\mathbf{A} are positive numbers.\n\nSuppose item 1 is true. If \\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x} is an eigenpair, then a Rayleigh quotient implies that\\lambda = \\frac{ \\mathbf{x}^*\\mathbf{A}\\mathbf{x} }{\\mathbf{x}^*\\mathbf{x}} > 0.\n\nHence item 2 is true. Conversely, suppose item 2 is known. Then we can write the EVD as \\mathbf{A}=\\mathbf{V}\\mathbf{S}^2\\mathbf{V}^*, where the S_{ii} are positive square roots of the eigenvalues. Hence\\mathbf{x}^*\\mathbf{A}\\mathbf{x} = \\mathbf{x}^*\\mathbf{V}\\mathbf{S}^2\\mathbf{V}^*\\mathbf{x} = \\|\\mathbf{S}\\mathbf{V}^*\\mathbf{x}\\|^2 > 0,\n\nas both \\mathbf{S} and \\mathbf{V} are invertible. Thus, item 1 is true.\n\nAccording to \n\nTheorem 7.4.3, for an HPD matrix, the EVD \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^* meets all the requirements of the SVD, provided the ordering of eigenvalues is chosen appropriately.\n\nA hermitian matrix with all negative eigenvalues is called negative definite, and one with eigenvalues of different signs is indefinite. Finally, if one or more eigenvalues is zero and the rest have one sign, it is positive or negative semidefinite.","type":"content","url":"/symm-eig#definite-semidefinite-and-indefinite-matrices","position":7},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Exercises"},"type":"lvl2","url":"/symm-eig#exercises","position":8},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Exercises"},"content":"✍ Each line below is an EVD for a hermitian matrix. State whether the matrix is definite, indefinite, or semidefinite. Then state whether the given factorization is also an SVD, and if it is not, modify it to find an SVD.\n\n(a) \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix} =   \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0\n \\end{bmatrix}  \\begin{bmatrix}\n   -1 & 0 \\\\ 0 & 0\n \\end{bmatrix}  \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0\n \\end{bmatrix}\n\n\n(b) \\begin{bmatrix}\n   4 & -2 \\\\ -2 & 1\n \\end{bmatrix} = \\begin{bmatrix}\n   1 & -0.5 \\\\ -0.5 & -1\n \\end{bmatrix}  \\begin{bmatrix}\n   5 & 0 \\\\ 0 & 0\n \\end{bmatrix}  \\begin{bmatrix}\n   0.8 & -0.4 \\\\ -0.4 & -0.8\n \\end{bmatrix}\n\n\n(c)\n\\begin{bmatrix}\n   -5 & 3\\\\ 3 & -5\n \\end{bmatrix} =  \\begin{bmatrix}\n   \\alpha & \\alpha \\\\ \\alpha & -\\alpha\n \\end{bmatrix}  \\begin{bmatrix}\n   -2 & 0 \\\\ 0 & -8\n \\end{bmatrix}  \\begin{bmatrix}\n   \\alpha & \\alpha \\\\ \\alpha & -\\alpha\n \\end{bmatrix}, \\quad\\alpha=1/\\sqrt{2}\n\n⌨ Determine whether each matrix is positive definite, negative definite, positive or negative semidefinite, or indefinite.\n\n(a) matrixdepot(\"pei\",5)-6I\n\n(b) matrixdepot(\"hilb\",8)-2I\n\n(c) matrixdepot(\"dingdong\",20)\n\n(d) matrixdepot(\"lehmer\",100)\n\n(e) matrixdepot(\"fiedler\",200)\n\n✍ Prove true, or give a counterexample: If \\mathbf{A} and \\mathbf{B} are hermitian matrices of the same size, thenR_{\\mathbf{A}+\\mathbf{B}}(\\mathbf{x}) = R_{\\mathbf{A}}(\\mathbf{x})+R_{\\mathbf{B}}(\\mathbf{x}).\n\n⌨ The range of the function R_{\\mathbf{A}}(\\mathbf{x}) is a subset of the complex plane known as the field of values of the matrix \\mathbf{A}. Use 500 random vectors to plot points in the field of values of \\mathbf{A} = \\displaystyle  \\begin{bmatrix}\n  1  &   0   & -2\\\\\n  0  &   2  &   0\\\\\n -2   &  0 &    1\n \\end{bmatrix}. Then compute its eigenvalues and guess what the exact field of values is.It's the interval $[-1,3]$ (between the extreme eigenvalues).\n\n✍ Let \\mathbf{A}=\\displaystyle \\begin{bmatrix} 3 & -2 \\\\ -2 & 0 \\end{bmatrix}.\n\n(a) Write out R_{\\mathbf{A}}(\\mathbf{x}) explicitly as a function of x_1 and x_2.\n\n(b) Find R_{\\mathbf{A}}(\\mathbf{x}) for x_1=1, x_2=2.\n\n(c) Find the gradient vector \\nabla R_{\\mathbf{A}}(\\mathbf{x}).\n\n(d) Show that the gradient vector is zero when x_1=1, x_2=2.\n\n✍ A skew-Hermitian matrix is one that satisfies \\mathbf{A}^*=-\\mathbf{A}. Show that if \\mathbf{A} is skew-Hermitian, then R_{\\mathbf{A}} is imaginary-valued.\n\n⌨ Thanks largely to \n\nTheorem 7.4.1, the eigenvalue problem for symmetric/hermitian matrices is easier than for general matrices.\n\n(a) Let \\mathbf{A} be a 1000\\times 1000 random real matrix, and let \\mathbf{S}=\\mathbf{A}+\\mathbf{A}^T. Using @elapsed, time the eigvals function for \\mathbf{A} and then for \\mathbf{S}. You should find that the computation for \\mathbf{S} is around an order of magnitude faster.\n\n(b) Perform the experiment from part (a) on n\\times n matrices for n=200,300,\\ldots,1600. Plot running time as a function of n for both matrices on a single log-log plot. Is the ratio of running times roughly constant, or does it grow with n?","type":"content","url":"/symm-eig#exercises","position":9},{"hierarchy":{"lvl1":"GMRES"},"type":"lvl1","url":"/gmres","position":0},{"hierarchy":{"lvl1":"GMRES"},"content":"The most important use of the Arnoldi iteration is to solve the square linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nIn \n\nDemo 8.4.1, we attempted to replace the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b} by the lower-dimensional approximation\\min_{\\mathbf{x}\\in \\mathcal{K}_m} \\|  \\mathbf{A}\\mathbf{x}-\\mathbf{b}  \\| = \\min_{\\mathbf{z}\\in\\mathbb{C}^m} \\|   \\mathbf{A}\\mathbf{K}_m\\mathbf{z}-\\mathbf{b}  \\|,\n\nwhere \\mathbf{K}_m is the Krylov matrix generated using \\mathbf{A} and the seed vector \\mathbf{b}. This method was unstable due to the poor conditioning of \\mathbf{K}_m, which is a numerically poor basis for \\mathcal{K}_m.\n\nThe Arnoldi algorithm yields an orthonormal basis of the same space and fixes the stability problem. Set \\mathbf{x}=\\mathbf{Q}_m\\mathbf{z} and obtain\\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{A} \\mathbf{Q}_m \\mathbf{z}-\\mathbf{b}  \\bigr\\|.\n\nFrom the fundamental Arnoldi identity \n\n(8.4.8), this is equivalent to\\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{Q}_{m+1} \\mathbf{H}_m\\mathbf{z}-\\mathbf{b} \\bigr\\|.\n\nNote that \\mathbf{q}_1 is a unit multiple of \\mathbf{b}, so \\mathbf{b} = \\|\\mathbf{b}\\| \\mathbf{Q}_{m+1}\\mathbf{e}_1. Thus \n\n(8.5.3) becomes\\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{Q}_{m+1} (\\mathbf{H}_m\\mathbf{z}-\\|\\mathbf{b}\\|\\mathbf{e}_1) \\bigr\\|.\n\nThe least-squares problems \n\n(8.5.2),  \n\n(8.5.3), and \n\n(8.5.4) are all n\\times m. But observe that for any \\mathbf{w}\\in\\mathbb{C}^{m+1},  \\|\\mathbf{Q}_{m+1}\\mathbf{w}\\|^2 = \\mathbf{w}^*\\mathbf{Q}_{m+1}^*\\mathbf{Q}_{m+1}\\mathbf{w} = \\mathbf{w}^*\\mathbf{w} = \\|\\mathbf{w}\\|^2.\n\nThe first norm in that equation is on \\mathbb{C}^n, while the last is on the much smaller space \\mathbb{C}^{m+1}. Hence the least-squares problem \n\n(8.5.4) is equivalent to  \\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{H}_m\\mathbf{z}-\\|\\mathbf{b}\\|\\,\\mathbf{e}_1 \\bigr\\|,\n\nwhich is of size (m+1)\\times m. We call the solution of this minimization \\mathbf{z}_m, and then \\mathbf{x}_m=\\mathbf{Q}_m \\mathbf{z}_m is the mth approximation to the solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nGMRES\n\nGiven n\\times n matrix \\mathbf{A} and n-vector \\mathbf{b}:\n\nFor m=1,2,\\ldots, let \\mathbf{x}_m=\\mathbf{Q}_m \\mathbf{z}_m, where \\mathbf{z}_m solves the linear least-squares problem \n\n(8.5.6), and \\mathbf{Q}_m,\\mathbf{H}_m arise from the Arnoldi iteration.\n\nGMRES uses the Arnoldi iteration to minimize the residual \\mathbf{b} - \\mathbf{A}\\mathbf{x} over successive Krylov subspaces. In exact arithmetic, GMRES should get the exact solution when m=n, but the goal is to reduce the residual enough to stop at some m \\ll n.\n\nGMRES\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = [norm(b); zeros(60)]\nfor m in 1:60\n    s = [norm(b); zeros(m)]\n    z = H[1:m+1, 1:m] \\ s\n    x = Q[:, 1:m] * z\n    resid[m+1] = norm(b - A * x)\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nplot(0:60, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, \"norm of mth residual\"),\n    title=\"Residual for GMRES\", leg=:none)\n\n\n\nGMRES\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = [norm(b); zeros(60)]\nfor m in 1:60\n    s = [norm(b); zeros(m)]\n    z = H[1:m+1, 1:m] \\ s\n    x = Q[:, 1:m] * z\n    resid[m+1] = norm(b - A * x)\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nplot(0:60, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, \"norm of mth residual\"),\n    title=\"Residual for GMRES\", leg=:none)\n\nCompare the graph in \n\nDemo 8.5.1  to the one in \n\nDemo 8.4.1. Both start with the same linear convergence, but only the version using Arnoldi avoids the instability created by the poor Krylov basis.\n\nA basic implementation of GMRES is given in \n\nFunction 8.5.2.\n\ngmres\n\nGMRES\n\n\"\"\"\n    gmres(A,b,m)\n\nDo `m` iterations of GMRES for the linear system `A`*x=`b`. Returns\nthe final solution estimate x and a vector with the history of\nresidual norms. (This function is for demo only, not practical use.)\n\"\"\"\nfunction gmres(A,b,m)\n    n = length(b)\n    Q = zeros(n,m+1)\n    Q[:,1] = b/norm(b)\n    H = zeros(m+1,m)\n\n    # Initial solution is zero.\n    x = 0\n    residual = [norm(b);zeros(m)]\n\n    for j in 1:m\n        # Next step of Arnoldi iteration.\n        v = A*Q[:,j]\n        for i in 1:j\n            H[i,j] = dot(Q[:,i],v)\n            v -= H[i,j]*Q[:,i]\n        end\n        H[j+1,j] = norm(v)\n        Q[:,j+1] = v/H[j+1,j]\n\n        # Solve the minimum residual problem.\n        r = [norm(b); zeros(j)]\n        z = H[1:j+1,1:j] \\ r\n        x = Q[:,1:j]*z\n        residual[j+1] = norm( A*x - b )\n    end\n    return x,residual\nend\n\n\n\nGMRES\n\ndef arngmres(A, b, m):\n    \"\"\"\n    arngmres(A,b,m)\n\n    Do `m` iterations of GMRES for the linear system `A`*x=`b`. Return the final solution\n    estimate x and a vector with the history of residual norms. (This function is for\n    demo only, not practical use.)\n    \"\"\"\n    n = len(b)\n    Q = np.zeros([n, m + 1])\n    Q[:, 0] = b / np.linalg.norm(b)\n    H = np.zeros([m + 1, m])\n\n    # Initial \"solution\" is zero.\n    residual = np.hstack([np.linalg.norm(b), np.zeros(m)])\n\n    for j in range(m):\n        # Next step of Arnoldi iteration.\n        v = A @ Q[:, j]\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n        # Solve the minimum residual problem.\n        r = np.hstack([np.linalg.norm(b), np.zeros(j + 1)])\n        z = np.linalg.lstsq(H[:j + 2, :j + 1], r)[0]\n        x = Q[:, :j + 1] @ z\n        residual[j + 1] = np.linalg.norm(A @ x - b)\n\n    return x, residual","type":"content","url":"/gmres","position":1},{"hierarchy":{"lvl1":"GMRES","lvl2":"Convergence and restarting"},"type":"lvl2","url":"/gmres#convergence-and-restarting","position":2},{"hierarchy":{"lvl1":"GMRES","lvl2":"Convergence and restarting"},"content":"Thanks to \n\nTheorem 8.4.1, minimization of \\|\\mathbf{b}-\\mathbf{A}\\mathbf{x}\\| over \\mathcal{K}_{m+1} includes minimization over \\mathcal{K}_m. Hence the norm of the residual \\mathbf{r}_m = \\mathbf{b} - \\mathbf{A}\\mathbf{x}_m (being the minimized quantity) cannot increase as the iteration unfolds.\n\nUnfortunately, making other conclusive statements about the convergence of GMRES is neither easy nor simple. \n\nDemo 8.5.1 shows the cleanest behavior: essentially linear convergence down to the range of machine epsilon. But it is possible for the convergence to go through phases of sublinear and superlinear convergence as well. There is a strong dependence on the eigenvalues of the matrix, a fact we state with more precision and detail in the next section.\n\nOne of the practical challenges in GMRES is that as the dimension of the Krylov subspace grows, the number of new entries to be found in \\mathbf{H}_m and the total number of columns in \\mathbf{Q} also grow. Thus both the work and the storage requirements are quadratic in m, which can become intolerable in some applications. For this reason, GMRES is often used with restarting.\n\nSuppose \\hat{\\mathbf{x}} is an approximate solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Then if we set \\mathbf{x}=\\mathbf{u}+\\hat{\\mathbf{x}}, we have \\mathbf{A}(\\mathbf{u}+\\hat{\\mathbf{x}}) = \\mathbf{b}, or \\mathbf{A}\\mathbf{u} = \\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}}. The conclusion is that if we get an approximate solution and compute its residual \\mathbf{r}=\\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}}, then we need only to solve \\mathbf{A}\\mathbf{u} = \\mathbf{r} in order to get a correction to \\hat{\\mathbf{x}}.\n\nRestarting guarantees a fixed upper bound on the per-iteration cost of GMRES. However, this benefit comes at a price. Even though restarting preserves progress made in previous iterations, the Krylov space information is discarded and the residual minimization process starts again over low-dimensional spaces. That can significantly retard or even stagnate the convergence.\n\nRestarting GMRES\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nA = FNC.poisson(50)\nn = size(A, 1)\nb = ones(n);\nspy(A, color=:blues)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from the IterativeSolvers package, since our simple implementation does not offer restarting.\n\nThe syntax f(x;foo) is shorthand for f(x,foo=foo).\n\nreltol = 1e-12;\nplt = plot(title=\"Convergence of restarted GMRES\", leg=:bottomleft,\n    xaxis=(L\"m\"), yaxis=(:log10, \"residual norm\", [1e-8, 100]))\n\nfor restart in [n, 20, 40, 60]\n    x, hist = IterativeSolvers.gmres(A, b; restart, reltol,\n        maxiter=100, log=true)\n    plot!(hist[:resnorm], label=\"restart = $restart\")\nend\n\nplt\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.\n\n\n\nRestarting GMRES\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nA = FNC.poisson(50)\nn = size(A, 1)\nb = ones(n);\nspy(A, color=:blues)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from the IterativeSolvers package, since our simple implementation does not offer restarting.\n\nThe syntax f(x;foo) is shorthand for f(x,foo=foo).\n\nreltol = 1e-12;\nplt = plot(title=\"Convergence of restarted GMRES\", leg=:bottomleft,\n    xaxis=(L\"m\"), yaxis=(:log10, \"residual norm\", [1e-8, 100]))\n\nfor restart in [n, 20, 40, 60]\n    x, hist = IterativeSolvers.gmres(A, b; restart, reltol,\n        maxiter=100, log=true)\n    plot!(hist[:resnorm], label=\"restart = $restart\")\nend\n\nplt\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.\n\nRestarting creates a tradeoff between the number of iterations and the speed per iteration. It’s essentially impossible in general to predict the ideal restart location in any given problem, so one goes by experience and hopes for the best.\n\nThere are other ways to avoid the growth in computational effort as the GMRES/Arnoldi iteration proceeds. Three of the more popular variations are abbreviated CGS, BiCGSTAB, and QMR. We do not describe them in this book.","type":"content","url":"/gmres#convergence-and-restarting","position":3},{"hierarchy":{"lvl1":"GMRES","lvl2":"Exercises"},"type":"lvl2","url":"/gmres#exercises","position":4},{"hierarchy":{"lvl1":"GMRES","lvl2":"Exercises"},"content":"✍ (See also \n\nExercise 8.4.1.) Consider the linear system with\\mathbf{A}=\\displaystyle \n    \\begin{bmatrix}\n      0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0\n    \\end{bmatrix}, \\qquad \\mathbf{b}=\\mathbf{e}_1.\n\n(a) Find the exact solution by inspection.\n\n(b) Find the GMRES approximate solutions \\mathbf{x}_m for m=1,2,3,4.\n\n✍ (Continuation of \n\nExercise 8.4.3.) Show that if \\mathbf{x}_m\\in\\mathcal{K}_m, then the residual \\mathbf{b}-\\mathbf{A}\\mathbf{x}_m is equal to q(\\mathbf{A})\\mathbf{b}, where q is a polynomial of degree at most m and q(0)=1. (This fact is a key one for many convergence results.)\n\n✍ Explain why GMRES, in exact arithmetic, converges to the true solution in n iterations for an n\\times n matrix if \\operatorname{rank}(\\mathbf{K}_n)=n. (Hint: Consider how the algorithm is defined from first principles.)\n\n⌨ Let \\mathbf{A} be the n\\times n tridiagonal matrix\\begin{bmatrix}\n      -4 & 1      &        &        &   \\\\\n      1  & -4     & 1      &        &   \\\\\n         & \\ddots & \\ddots & \\ddots &   \\\\\n         &        & 1      & -4     & 1 \\\\\n         &        &        & 1      & -4 \n    \\end{bmatrix}\n\nand let the n-vector \\mathbf{b} have elements b_i=i/n. For n=8,16,32,64, run \n\nFunction 8.5.2 for m=n/2 iterations. On one semi-log graph, plot \\|\\mathbf{r}_k\\|/\\|\\mathbf{b}\\| for all the cases. How does the convergence rate of GMRES seem to depend on n?must stay as #5\n\n⌨  In this exercise you will see the strong effect the eigenvalues of the matrix may have on GMRES convergence. Let\\mathbf{B}=\n    \\begin{bmatrix}\n      1 & & & \\\\\n      & 2 & & \\\\\n      & & \\ddots & \\\\\n      & & & 100\n    \\end{bmatrix},\n\nlet \\mathbf{I} be a 100\\times 100 identity, and let \\mathbf{Z} be a 100\\times 100 matrix of zeros. Also let \\mathbf{b} be a 200\\times 1 vector of ones. You will use IterativeSolvers.gmres with restarts, as in \n\nDemo 8.5.2.\n\n(a) Let \\mathbf{A} = \\begin{bmatrix} \\mathbf{B} & \\mathbf{I} \\\\ \\mathbf{Z} & \\mathbf{B} \\end{bmatrix}. What are its eigenvalues (no computer required here)? Apply gmres with tolerance \n\n10-10 for 100 iterations without restarts, and plot the residual convergence.\n\n(b) Repeat part (a) with restarts every 20 iterations.\n\n(c) Now let \\mathbf{A} = \\begin{bmatrix} \\mathbf{B} & \\mathbf{I} \\\\ \\mathbf{Z} & -\\mathbf{B} \\end{bmatrix}. What are its eigenvalues? Repeat part (a). Which matrix is more difficult for GMRES? (Note: Even though this matrix is triangular, GMRES has no way of exploiting that fact.)\n\n⌨ (Continuation of \n\nExercise 8.3.5.) We again consider the n^2\\times n^2 sparse matrix defined by FNC.poisson(n). The solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b} may be interpreted as the deflection of a lumped membrane in response to a load represented by \\mathbf{b}.\n\n(a) For n=10,15,20,25, let \\mathbf{b} be the vector of n^2 ones and apply \n\nFunction 8.5.2 for 50 iterations. On one semi-log graph, plot the four convergence curves \\|\\mathbf{r}_m\\|/\\|\\mathbf{b}\\|.\n\n(b) For the case n=25 use surface(1:n,1:n,reshape(x,25,25)) to plot the solution, which should look physically plausible (though upside-down for a weighted membrane).\n\nGMRES stands for Generalized Minimum RESidual. We will encounter its precursor MINRES in \n\nMINRES and conjugate gradients.\n\nThis statement is not strictly correct for rare special cases of breakdown where the rank of \\mathcal{K}_n is less than n. In that situation, some additional steps must be taken that we do not discuss here.\n\nThe new problem needs to be solved for accuracy relative to \\|\\mathbf{b}\\|, not relative to \\|\\mathbf{r}\\|.","type":"content","url":"/gmres#exercises","position":5},{"hierarchy":{"lvl1":"Inverse iteration"},"type":"lvl1","url":"/inviter","position":0},{"hierarchy":{"lvl1":"Inverse iteration"},"content":"Power iteration finds only the dominant eigenvalue. We next show that it can be adapted to find any eigenvalue, provided you start with a reasonably good estimate of it. Some simple linear algebra is all that is needed.\n\nLet \\mathbf{A} be an n\\times n matrix with eigenvalues \\lambda_1,\\ldots,\\lambda_n (possibly with repeats), and let s be a complex scalar. Then:\n\nThe eigenvalues of the matrix \\mathbf{A}-s\\mathbf{I} are \\lambda_1-s,\\ldots,\\lambda_n-s.\n\nIf s is not an eigenvalue of \\mathbf{A}, the eigenvalues of the matrix (\\mathbf{A}-s\\mathbf{I})^{-1} are (\\lambda_1-s)^{-1},\\ldots,(\\lambda_n-s)^{-1}.\n\nThe eigenvectors associated with the eigenvalues in the first two parts are the same as those of \\mathbf{A}.\n\nThe equation \\mathbf{A}\\mathbf{v}=\\lambda \\mathbf{v} implies that (\\mathbf{A}-s\\mathbf{I})\\mathbf{v} = \\mathbf{A}\\mathbf{v} - s\\mathbf{I}\\mathbf{v} = \\lambda\\mathbf{v} - s\\mathbf{v} = (\\lambda-s)\\mathbf{v}. That proves the first part of the theorem. For the second part, we note that by assumption, (\\mathbf{A}-s\\mathbf{I}) is nonsingular, so (\\mathbf{A}-s\\mathbf{I})\\mathbf{v} = (\\lambda-s) \\mathbf{v} implies that \\mathbf{v} = (\\lambda-s) (\\mathbf{A}-s\\mathbf{I}) \\mathbf{v}, or  (\\lambda-s)^{-1} \\mathbf{v} =(\\mathbf{A}-s\\mathbf{I})^{-1} \\mathbf{v}. The discussion above also proves the third part of the theorem.\n\nConsider first part 2 of the theorem with s=0, and suppose that \\mathbf{A} has a smallest eigenvalue,|\\lambda_n| \\ge |\\lambda_{n-1}| \\ge \\cdots > |\\lambda_1|.\n\nThen clearly|\\lambda_1^{-1}| > |\\lambda_{2}^{-1}| \\ge \\cdots \\ge |\\lambda_n^{-1}|,\n\nand \\mathbf{A}^{-1} has a dominant eigenvalue. Hence power iteration on \\mathbf{A}^{-1} can be used to find the eigenvalue of \\mathbf{A} closest to zero. For nonzero values of s, then we suppose there is an ordering|\\lambda_n-s| \\ge \\cdots \\ge |\\lambda_2-s|  > |\\lambda_1-s|.\n\nThen it follows that|\\lambda_1-s|^{-1} > |\\lambda_{2}-s|^{-1} \\ge \\cdots \\ge |\\lambda_n-s|^{-1},\n\nand power iteration on the matrix (\\mathbf{A}-s\\mathbf{I})^{-1} converges to (\\lambda_1-s)^{-1}, which is easily solved for \\lambda_1 itself.","type":"content","url":"/inviter","position":1},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Algorithm"},"type":"lvl2","url":"/inviter#algorithm","position":2},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Algorithm"},"content":"A literal application of \n\nAlgorithm 8.2.1 would include the step\\mathbf{y}_k = (\\mathbf{A}-s\\mathbf{I})^{-1} \\mathbf{x}_k.\n\nAs always, we do not want to explicitly find the inverse of a matrix. Instead we should write this step as the solution of a linear system.\n\nInverse iteration\n\nGiven matrix \\mathbf{A} and shift s:\n\nChoose \\mathbf{x}_1.\n\nFor k=1,2,\\ldots,\n\na. Solve for \\mathbf{y}_k in\n\n:label: shiftinvstep\n(\\mathbf{A}-s\\mathbf{I}) \\mathbf{y}_k =\\mathbf{x}_k .\n:::b. Find $m$ such that $|y_{k,m}|=\\|{\\mathbf{y}_k} \\|_\\infty$.\n\nc. Set $\\alpha_k = \\dfrac{1}{y_{k,m}}$ and $\\,\\beta_k = s + \\dfrac{x_{k,m}}{y_{k,m}}$.\n\nd. Set $\\mathbf{x}_{k+1} = \\alpha_k \\mathbf{y}_k$.\n\nNote that in \n\nAlgorithm 8.2.1, we used y_{k,m}/x_{k,m} as an estimate of the dominant eigenvalue of \\mathbf{A}. Here, that ratio is an estimate of (\\lambda_1-s)^{-1}, and solving for \\lambda_1 gives the \\beta_k in \n\nAlgorithm 8.3.1.\n\nEach pass of inverse iteration requires the solution of a linear system of equations with the matrix \\mathbf{B}=\\mathbf{A}-s\\mathbf{I}. This solution might use methods we consider later in this chapter. Here, we use (sparse) PLU factorization and hope for the best. Since the matrix \\mathbf{B} is constant, the factorization needs to be done only once for all iterations. The details are in \n\nFunction 8.3.2.\n\ninviter\n\nInverse iteration\n\n\"\"\"\n    inviter(A,s,numiter)\n\nPerform `numiter` inverse iterations with the matrix `A` and shift\n`s`, starting from a random vector. Returns a vector of\neigenvalue estimates and the final eigenvector approximation.\n\"\"\"\nfunction inviter(A,s,numiter)\n    n = size(A,1)\n    x = normalize(randn(n),Inf)\n    β = zeros(numiter)\n    fact = lu(A - s*I)\n    for k in 1:numiter\n        y = fact\\x\n        normy,m = findmax(abs.(y))\n        β[k] = x[m]/y[m] + s\n        x = y/y[m]\n    end\n    return β,x\nend\n\n\n\nInverse iteration\n\ndef inviter(A, s, numiter):\n    \"\"\"\n    inviter(A,s,numiter)\n\n    Perform `numiter` inverse iterations with the matrix `A` and shift `s`, starting\n    from a random vector, and return a vector of eigenvalue estimates and the final\n    eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    PL, U = lu(A - s * np.eye(n), permute_l=True)\n    for k in range(numiter):\n        y = np.linalg.solve(U, np.linalg.solve(PL, x))\n        m = np.argmax(abs(y))\n        gamma[k] = x[m] / y[m] + s\n        x = y / y[m]\n\n    return gamma, x","type":"content","url":"/inviter#algorithm","position":3},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Convergence"},"type":"lvl2","url":"/inviter#convergence","position":4},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Convergence"},"content":"The convergence is linear, at a rate found by reinterpreting \n\n(8.2.10) with (\\mathbf{A}-s\\mathbf{I})^{-1} in place of \\mathbf{A}:\\frac{\\beta_{k+1} - \\lambda_1}{\\beta_{k} - \\lambda_1} \\rightarrow\n\\frac{  \\lambda_1 - s } {\\lambda_2 - s}\\quad \\text{ as } \\quad k\\rightarrow \\infty,\n\nwith the eigenvalues ordered as in \n\n(8.3.3). Thus, the convergence is best when the shift s is close to the target eigenvalue \\lambda_1, specifically when it is much closer to that eigenvalue than to any other.\n\nConvergence of inverse iteration\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run inverse iteration with the shift s=0.7 and take the final estimate as our “exact” answer to observe the convergence.\n\ns = 0.7\nβ, x = FNC.inviter(A, s, 30)\neigval = β[end]\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nerr = @. abs(eigval - β)\nplot(0:28, err[1:end-1], m=:o,\n    title=\"Convergence of inverse iteration\",\n    xlabel=L\"k\", yaxis=(L\"|\\lambda_3-\\beta_k|\", :log10, [1e-16, 1]))\n\nThe observed linear convergence rate is found from the data.\n\n@show observed_rate = err[22] / err[21];\n\nWe reorder the eigenvalues to enforce \n\n(8.3.3).\n\nThe sortperm function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nλ = λ[sortperm(abs.(λ .- s))]\n\nHence the theoretical convergence rate is\n\n@show theoretical_rate = (λ[1] - s) / (λ[2] - s);\n\n\n\nConvergence of inverse iteration\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run inverse iteration with the shift s=0.7. Convergence should be to the eigenvalue closest to the shift, which we know to be 0.6 here.\n\nbeta, x = FNC.inviter(A, 0.7, 30)\nprint(beta)\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nerr = beta[-1] - beta    # last estimate is our best\nsemilogy(arange(30), abs(err), \"-o\")\nylim(1e-16, 1)\nxlabel(\"$k$\"),  ylabel(\"$|\\\\lambda_3 - \\\\beta_k|$\")\ntitle(\"Convergence of inverse iteration\")\n\nLet’s reorder the eigenvalues to enforce \n\n(8.3.3).\n\nThe argsort function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nev = ev[argsort(abs(ev - 0.7))]\nprint(ev)\n\nNow it is easy to compare the theoretical and observed linear convergence rates.\n\nprint(f\"theory: {(ev[0] - 0.7) / (ev[1] - 0.7):.5f}\")\nprint(f\"observed: {err[21] / err[20]:.5f}\")","type":"content","url":"/inviter#convergence","position":5},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Dynamic shifting"},"type":"lvl2","url":"/inviter#dynamic-shifting","position":6},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Dynamic shifting"},"content":"There is a clear opportunity for positive feedback in \n\nAlgorithm 8.3.1. The convergence rate of inverse iteration improves as the shift gets closer to the true eigenvalue—and the algorithm computes improving eigenvalue estimates! If we update the shift to s=\\beta_k after each iteration, the convergence accelerates. You are asked to implement this algorithm in \n\nExercise 6.\n\nLet’s analyze the resulting convergence. If the eigenvalues are ordered by distance to s, then the convergence is linear with rate |\\lambda_1-s|/|\\lambda_2-s|. As s\\to\\lambda_1, the change in the denominator is negligible. So if the error (\\lambda_1-s) is ε, then the error in the next estimate is reduced by a factor O(\\epsilon). That is, ε becomes O(\\epsilon^2), which is quadratic convergence.\n\nDynamic shift strategy\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\ns = 0.7\nx = ones(5)\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = β\nx = y / y[1]\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in 1:4\n    s = β\n    x = y / y[1]\n    y = (A - s * I) \\ x\n    @show β = x[1] / y[1] + s\nend\n\n\n\nDynamic shift strategy\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\nfrom numpy.linalg import solve\ns = 0.7\nx = ones(5)\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = beta\nx = y / y[0]\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in range(4):\n    s = beta\n    x = y / y[0]\n    y = solve(A - s * eye(5), x)\n    beta = x[0] / y[0] + s\n    print(f\"latest estimate: {beta:.8f}\")\n\nThere is a price to pay for this improvement. The matrix of the linear system to be solved, (\\mathbf{A}-s\\mathbf{I}), now changes with each iteration. That means that we can no longer do just one LU factorization for the entire iteration. The speedup in convergence usually makes this tradeoff worthwhile, however.\n\nIn practice power and inverse iteration are not as effective as the algorithms used by eigs and based on the mathematics described in the rest of this chapter. However, inverse iteration can be useful for turning an eigenvalue estimate into an eigenvector estimate.","type":"content","url":"/inviter#dynamic-shifting","position":7},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Exercises"},"type":"lvl2","url":"/inviter#exercises","position":8},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Exercises"},"content":"⌨  Use \n\nFunction 8.3.2 to perform 10 iterations for the given matrix and shift. Compare the results quantitatively to the convergence given by \n\n(8.3.6).\n\n(a)  \\mathbf{A} = \\begin{bmatrix}\n     1.1 & 1 \\\\\n     0 & 2.1\n   \\end{bmatrix}, \\; s = 1 \\qquad \n(b) \\mathbf{A} = \\begin{bmatrix}\n     1.1 & 1 \\\\\n     0 & 2.1\n   \\end{bmatrix}, \\; s = 2\\qquad \n\n(c) \\mathbf{A} = \\begin{bmatrix}\n     1.1 & 1 \\\\\n     0 & 2.1\n   \\end{bmatrix}, \\; s = 1.6\\qquad \n(d) \\mathbf{A} = \\begin{bmatrix}\n     2 & 1 \\\\\n     1 & 0\n   \\end{bmatrix}, \\; s = -0.33 \\qquad\n\n(e) \\mathbf{A} = \\begin{bmatrix}\n   6 & 5 & 4 \\\\\n   5 & 4 & 3 \\\\\n   4 & 3 & 2\n \\end{bmatrix}, \\;  s = 0.1 \n\n✍ Let \\mathbf{A} = \\displaystyle \\begin{bmatrix} 1.1 & 1 \\\\ 0 & 2.1 \\end{bmatrix}. Given the starting vector \\mathbf{x}_1=[1,1], find the vector \\mathbf{x}_2 for the following shifts.\n\n(a) s=1\\quad (b) s=2\\quad (c) s=1.6\n\n✍ Why is it a bad idea to use unshifted inverse iteration with the matrix \\displaystyle \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}? Does the shift s=-1 improve matters?\n\n✍ When the shift s is very close to an eigenvalue of \\mathbf{A}, the matrix \\mathbf{A}-s\\mathbf{I} is close to a singular matrix. But then  is a linear system with a badly conditioned matrix, which should create a lot of error in the numerical solution for \\mathbf{y}_k. However, it happens that the error is mostly in the direction of the eigenvector we are looking for, as the following toy example illustrates.\n\nProve that \\displaystyle \\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix} has an eigenvalue at zero with associated eigenvector \\mathbf{v}=[-1,1]^T. Suppose this matrix is perturbed slightly to \\displaystyle \\mathbf{A} = \\begin{bmatrix} 1 & 1 \\\\ 0 & \\epsilon \\end{bmatrix}, and that \\mathbf{x}_k=[1,1] in . Show that once \\mathbf{y}_k is normalized by its infinity norm, the result is within ε of a multiple of \\mathbf{v}.must stay as #5\n\n⌨ (Continuation of \n\nExercise 8.2.3.) This exercise concerns the n^2\\times n^2 sparse matrix defined by FNC.poisson(n) for integer n. It represents a lumped model of a vibrating square membrane held fixed around the edges.\n\n(a) The eigenvalues of \\mathbf{A} closest to zero are approximately squares of the frequencies of vibration for the membrane. Using eigs, find the eigenvalue \\lambda_m closest to zero for n=10,15,20,25.\n\n(b) For each n in part (a), apply 50 steps of \n\nFunction 8.3.2 with zero shift. On one graph, plot the four convergence curves |\\beta_k-\\lambda_m| using a semi-log scale.\n\n(c) Let v be the eigenvector (second output) found by \n\nFunction 8.3.2 for n=25. Visualize the vibration mode of the membrane usingsurface(reshape(v,n,n))must remain as number 6\n\n⌨ This problem explores the use of dynamic shifting to accelerate the inverse iteration.\n\n(a) Modify \n\nFunction 8.3.2 to change the value of the shift s to be the most recently computed value in the vector β. Note that the matrix B must also change with each iteration, and the LU factorization cannot be done just once.\n\n(b) Define a matrix with eigenvalues at k^2 for k=1,\\ldots,100 viaA = diagm(0=>(1:100).^2,1=>rand(99))\n\nUsing an initial shift of s=920, apply the dynamic inverse iteration. Determine which eigenvalue was found and make a table of the log10 of the errors in the iteration as a function of iteration number. (These should approximately double, until machine precision is reached, due to quadratic convergence.)\n\n(c) Repeat part (b) using a different initial shift of your choice.","type":"content","url":"/inviter#exercises","position":9},{"hierarchy":{"lvl1":"Matrix-free iterations"},"type":"lvl1","url":"/matrixfree","position":0},{"hierarchy":{"lvl1":"Matrix-free iterations"},"content":"A primary reason for our interest in matrices is their relationship to linear transformations. If we define \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x}, then for all vectors \\mathbf{x}, \\mathbf{y}, and scalars α,\\begin{split}\n\\mathbf{f}(\\mathbf{x} + \\mathbf{y} ) &= \\mathbf{f}(\\mathbf{x}) + \\mathbf{f}(\\mathbf{y} ), \\\\\n\\mathbf{f}(\\alpha \\mathbf{x} ) & = \\alpha\\, \\mathbf{f}(\\mathbf{x}).\n\\end{split}\n\nThese properties define a linear transformation. Moreover, every linear transformation between finite-dimensional vector spaces can be represented as a matrix-vector multiplication.","type":"content","url":"/matrixfree","position":1},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Matrix-free iterations"},"type":"lvl2","url":"/matrixfree#matrix-free-iterations","position":2},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Matrix-free iterations"},"content":"In Chapter 4 we solved the nonlinear rootfinding problem \\mathbf{f}(\\mathbf{x})=\\boldsymbol{0} with methods that needed only the ability to evaluate \\mathbf{f} at any known value of \\mathbf{x}. By repeatedly evaluating \\mathbf{f} at cleverly chosen points, these algorithms were able to return an estimate for \\mathbf{f}^{-1}(\\boldsymbol{0}).\n\nA close examination reveals that the power method and Krylov subspace methods have the same structure because the only appearance of the matrix \\mathbf{A} in them is to multiply a known vector, i.e., to evaluate \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x}. This is used to evaluate the inverse, \\mathbf{A}^{-1}\\mathbf{b}.\n\nBringing these points of view together leads us to a cornerstone of modern scientific computation: matrix-free iterations. Krylov subspace methods can be used to invert a linear transformation if one provides code for the transformation, even if its associated matrix is not known explicitly.","type":"content","url":"/matrixfree#matrix-free-iterations","position":3},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Blurring images"},"type":"lvl2","url":"/matrixfree#blurring-images","position":4},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Blurring images"},"content":"In \n\nFrom matrix to insight we saw that a grayscale image can be represented as an m\\times n matrix \\mathbf{X} of pixel intensity values. Now consider a simple model for blurring the image. Define \\mathbf{B} as the m\\times m tridiagonal matrixB_{ij} =\n\\begin{cases}\n\\tfrac{1}{2} & \\text{if $i=j$},\\\\\n\\tfrac{1}{4} & \\text{if $|i-j|=1$},\\\\\n0 & \\text{otherwise.}\n\\end{cases}\n\nThe product \\mathbf{B}\\mathbf{X} applies \\mathbf{B} to each column of \\mathbf{X}. Within that column it does a weighted average of the values of each pixel and its two neighbors. That has the effect of blurring the image vertically. We can increase the amount of blur by applying \\mathbf{B} repeatedly.\n\nIn order to blur horizontally, we can transpose the image and apply blurring in the same way. We need a blurring matrix defined as in \n\n(8.7.2) but with size n\\times n. We call this matrix \\mathbf{C}. Altogether the horizontal blurring is done by transposing, applying \\mathbf{C}, and transposing back to the original orientation. That is,\\bigl(\\mathbf{C} \\mathbf{X}^T\\bigr)^T = \\mathbf{X}\\mathbf{C}^T = \\mathbf{X}\\mathbf{C},\n\nusing the symmetry of \\mathbf{C}. So we can describe blur in both directions as the function\\operatorname{blur}(\\mathbf{X}) = \\mathbf{B}^k \\mathbf{X} \\mathbf{C}^k\n\nfor a positive integer k.\n\nBlurring an image\n\nWe use a readily available test image.\n\nimg = testimage(\"mandrill\")\nm, n = size(img)\nX = @. Float64(Gray(img))\nplot(Gray.(X), title=\"Original image\", aspect_ratio=1)\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nfunction blurmatrix(d)\n    v1 = fill(0.25, d - 1)\n    return spdiagm(0 => fill(0.5, d), 1 => v1, -1 => v1)\nend\nB, C = blurmatrix(m), blurmatrix(n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nblur = X -> B^12 * X * C^12;\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\n\n\nBlurring an image\n\nWe use a readily available test image.\n\nimg = testimage(\"mandrill\")\nm, n = size(img)\nX = @. Float64(Gray(img))\nplot(Gray.(X), title=\"Original image\", aspect_ratio=1)\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nfunction blurmatrix(d)\n    v1 = fill(0.25, d - 1)\n    return spdiagm(0 => fill(0.5, d), 1 => v1, -1 => v1)\nend\nB, C = blurmatrix(m), blurmatrix(n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nblur = X -> B^12 * X * C^12;\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")","type":"content","url":"/matrixfree#blurring-images","position":5},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Deblurring"},"type":"lvl2","url":"/matrixfree#deblurring","position":6},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Deblurring"},"content":"A more interesting operation is deblurring: given an image blurred by poor focus, can we reconstruct the true image? Conceptually, we want to invert the function \\operatorname{blur}(\\mathbf{X}).\n\nIt’s easy to see from \n\n(8.7.4) that the blur operation is a linear transformation on image matrices. But an m\\times n image matrix is equivalent to a length-mn vector—it’s just a matter of interpreting the shape of the same data. Let \\operatorname{vec}(\\mathbf{X})=\\mathbf{x} and \\operatorname{unvec}(\\mathbf{x})=\\mathbf{X} be the mathematical statements of such reshaping operations. Now say \\mathbf{X} is the original image and \\mathbf{Z}=\\operatorname{blur}(\\mathbf{X}) is the blurred one. Then by linearity there is some matrix \\mathbf{A} such that\\mathbf{A} \\operatorname{vec}(\\mathbf{X}) = \\operatorname{vec}(\\mathbf{Z}),\n\nor \\mathbf{A}\\mathbf{x}=\\mathbf{z}.\n\nThe matrix \\mathbf{A} is mn\\times mn; for a 12-megapixel image, it would have 1.4\\times 10^{14} entries! Admittedly, it is extremely sparse, but the point is that we don’t need it at all.\n\nInstead, given any vector \\mathbf{u} we can compute \\mathbf{v}=\\mathbf{A}\\mathbf{u} through the steps\\begin{align*}\n  \\mathbf{U} &= \\operatorname{unvec}(\\mathbf{u}),\\\\\n  \\mathbf{V} &= \\operatorname{blur}(\\mathbf{U}),\\\\\n  \\mathbf{v} &= \\operatorname{vec}(\\mathbf{V}).\n\\end{align*}\n\nThe following example shows how to put these ideas into practice with MINRES.\n\nDeblurring an image\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = testimage(\"lighthouse\")\nm, n = size(img)\nX = @. Float64(Gray(img))\n\nB = spdiagm(0 => fill(0.5, m),\n    1 => fill(0.25, m - 1), -1 => fill(0.25, m - 1))\nC = spdiagm(0 => fill(0.5, n),\n    1 => fill(0.25, n - 1), -1 => fill(0.25, n - 1))\nblur = X -> B^12 * X * C^12\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\n# vec (built-in) converts matrix to vector\nunvec = z -> reshape(z, m, n);  # convert vector to matrix\n\nNow we declare the three-step blur transformation as a LinearMap, supplying also the size of the vector form of an image.\n\nT = LinearMap(x -> vec(blur(unvec(x))), m * n);\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nThe function clamp01 in Images restricts values to be in the interval [0,1].\n\ny = minres(T, vec(Z), maxiter=50, reltol=1e-5);\nY = unvec(clamp01.(y))\n\nplot(Gray.(X), layout=2, title=\"Original\")\nplot!(Gray.(Y), subplot=2, title=\"Deblurred\")\n\n\n\nDeblurring an image\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = testimage(\"lighthouse\")\nm, n = size(img)\nX = @. Float64(Gray(img))\n\nB = spdiagm(0 => fill(0.5, m),\n    1 => fill(0.25, m - 1), -1 => fill(0.25, m - 1))\nC = spdiagm(0 => fill(0.5, n),\n    1 => fill(0.25, n - 1), -1 => fill(0.25, n - 1))\nblur = X -> B^12 * X * C^12\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\n# vec (built-in) converts matrix to vector\nunvec = z -> reshape(z, m, n);  # convert vector to matrix\n\nNow we declare the three-step blur transformation as a LinearMap, supplying also the size of the vector form of an image.\n\nT = LinearMap(x -> vec(blur(unvec(x))), m * n);\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nThe function clamp01 in Images restricts values to be in the interval [0,1].\n\ny = minres(T, vec(Z), maxiter=50, reltol=1e-5);\nY = unvec(clamp01.(y))\n\nplot(Gray.(X), layout=2, title=\"Original\")\nplot!(Gray.(Y), subplot=2, title=\"Deblurred\")","type":"content","url":"/matrixfree#deblurring","position":7},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Exercises"},"type":"lvl2","url":"/matrixfree#exercises","position":8},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Exercises"},"content":"✍ Show using \n\n(8.7.1) and \n\n(8.7.4) that the blur operation is a linear transformation.\n\n✍ In each case, state with reasons whether the given transformation on n-vectors is linear.\n\n(a) \\,\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_2\\\\x_3 \\\\\\vdots\\\\ x_n \\\\ x_1 \\end{bmatrix}\\qquad\n(b) \\,\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_1\\\\x_1+x_2\\\\x_1+x_2+x_3\\\\\\vdots\\\\x_1+\\cdots+x_n \\end{bmatrix} \\qquad\n(c) \\,\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_1 + 1 \\\\x_2 + 2 \\\\ x_3 + 3 \\\\\\vdots \\\\ x_n+n \\end{bmatrix} \\qquad\n(d) \\,\\mathbf{f}(\\mathbf{x}) = \\|\\mathbf{x}\\|_\\infty\\, \\mathbf{e}_1\n\n✍ Suppose that code for the linear transformation \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x} is given for an unknown matrix \\mathbf{A}. Explain carefully how one could construct \\mathbf{A}.\n\n⌨ The matrix of the blur transformation happens to be symmetric and positive definite. Repeat \n\nDemo 8.7.2 using CG for the deblurring.\n\nThe condition number of the matrix of the blur transformation is related to the condition numbers of the single-dimension matrices \\mathbf{B}^k and \\mathbf{C}^k in \n\n(8.7.4).\n\n(a) ⌨  Let m=50. Show that \\mathbf{B} has a Cholesky factorization and thus is SPD. Find \\kappa(\\mathbf{B}). (Note: cond requires a regular dense matrix, not a sparse matrix.)\n\n(b) ✍ Explain why part (a) implies \\kappa( \\mathbf{B}^k ) = \\kappa(\\mathbf{B})^k.\n\n(c) ✍ Explain two important effects of the limit k\\to \\infty on deblurring by Krylov methods.\n\nThe cumulative summation function cumsum is defined as\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_1 \\\\ x_1+x_2 \\\\ \\vdots \\\\ x_1 + x_2 + \\cdots + x_n \\end{bmatrix}.\n\n(a) ✍ Show that \\mathbf{f} is a linear transformation.\n\n(b) ⌨ Define vector \\mathbf{b} by b_i = (i/100)^2 for i=1,\\ldots,100. Then use gmres to find \\mathbf{x}=\\mathbf{f}^{-1}(\\mathbf{b}).\n\n(c) ⌨ Plot \\mathbf{x}, and explain why the result looks as it does.","type":"content","url":"/matrixfree#exercises","position":9},{"hierarchy":{"lvl1":"MINRES and conjugate gradients"},"type":"lvl1","url":"/minrescg","position":0},{"hierarchy":{"lvl1":"MINRES and conjugate gradients"},"content":"We have seen before that certain matrix properties enhance solutions to linear algebra problems. One of the most important of these is when \\mathbf{A}^*=\\mathbf{A}; i.e., \\mathbf{A} is hermitian. The Arnoldi iteration has a particularly useful specialization to this case. While in this section we describe the resulting algorithms, we do not present them in detail or show implementations.","type":"content","url":"/minrescg","position":1},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Lanczos iteration"},"type":"lvl2","url":"/minrescg#lanczos-iteration","position":2},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Lanczos iteration"},"content":"Starting from \n\n(8.4.8), we left-multiply by \\mathbf{Q}_m^* to get\\mathbf{Q}_m^* \\mathbf{A} \\mathbf{Q}_m = \\mathbf{Q}_m^* \\mathbf{Q}_{m+1} \\mathbf{H}_m = \\tilde{\\mathbf{H}}_m,\n\nwhere \\tilde{\\mathbf{H}}_m is rows 1 through m of \\mathbf{H}_m. If \\mathbf{A} is hermitian, then so is the left side of this equation, hence \\tilde{\\mathbf{H}}_m is hermitian too. But it is also upper Hessenberg, meaning that the (i,j) element is zero if i > j+1. By symmetry, this means that elements are zero when j > i+1 as well.\n\nFor a hermitian (or real symmetric) matrix, the upper Hessenberg matrix \\mathbf{H}_m produced by the Arnoldi iteration is tridiagonal.\n\nEquation \n\n(8.4.6) of the Arnoldi iteration now simplifies to a much shorter expression:\\mathbf{A} \\mathbf{q}_m = H_{m-1,m} \\,\\mathbf{q}_{m-1} + H_{mm} \\,\\mathbf{q}_m + H_{m+1,m}\\,\\mathbf{q}_{m+1}.\n\nAs before in deriving the Arnoldi iteration, when given the first m vectors we can solve for the entries in column m of \\mathbf{H} and then for \\mathbf{q}_{m+1}. The resulting process is known as the Lanczos iteration. Its most important practical advantage is that while Arnoldi needs O(m) steps to get \\mathbf{q}_{m+1} from the previous vectors, Lanczos needs only O(1) steps, so restarting isn’t required for symmetric matrices.","type":"content","url":"/minrescg#lanczos-iteration","position":3},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"MINRES"},"type":"lvl2","url":"/minrescg#minres","position":4},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"MINRES"},"content":"When \\mathbf{A} is hermitian and the Arnoldi iteration is reduced to Lanczos, the analog of GMRES is known as MINRES. Like GMRES, MINRES minimizes the residual \\|\\mathbf{b}-\\mathbf{A}\\mathbf{x}\\| over increasingly larger Krylov spaces.\n\nMINRES is also more theoretically tractable than GMRES. The following result relies on some advanced approximation theory. Recall that the eigenvalues of a hermitian matrix are real.\n\nConvergence of MINRES (indefinite case)\n\nSuppose \\mathbf{A} is hermitian, invertible, and indefinite. Divide its eigenvalues into positive and negative sets \\Lambda_+ and \\Lambda_-, and define\\kappa_+ = \\frac{ \\max_{\\lambda \\in \\Lambda_+}  |\\lambda| }{ \\min_{\\lambda \\in \\Lambda_+}  |\\lambda| }, \\qquad\n\\kappa_- = \\frac{ \\max_{\\lambda \\in \\Lambda_-}  |\\lambda| }{ \\min_{\\lambda \\in \\Lambda_-}  |\\lambda| }.\n\nThen \\mathbf{x}_m, the mth solution estimate of MINRES, satisfies\\frac{\\|\\mathbf{r}_m\\|_2}{\\|\\mathbf{b}\\|_2} \\le  \\left( \\frac{\\sqrt{\\kappa_+\\kappa_-} - 1}{\\sqrt{\\kappa_+\\kappa_-} + 1} \\right)^{\\lfloor m/2\\rfloor},\n\nwhere \\lfloor m/2\\rfloor means to round m/2 down to the nearest integer.\n\nThe bound for a definite matrix is better, as the next theorem shows. The upper bound \n\n(8.6.4) on the residual obeys a linear convergence rate. As the product \\kappa_+\\kappa_- grows, the rate of this convergence approaches 1. Hence the presence of eigenvalues close to the origin (relative to the max eigenvalues) is expected to force a slower convergence.\n\nSuppose \\mathbf{A} has \\kappa_+=60 and \\kappa_-=15. Then to achieve a guaranteed reduction in the relative residual of \n\n10-3, we require\\left( \\frac{\\sqrt{900} - 1}{\\sqrt{900} + 1} \\right)^{\\lfloor m/2\\rfloor} \\le 10^{-3},{\\lfloor m/2\\rfloor} \\log_{10} \\left( \\frac{29}{31} \\right) \\le -3,m  \\ge  2 \\lceil \\frac{3}{\\log_{10}(29/31)} \\rceil = 208.\n\nBecause the theorem gives an upper bound, MINRES may converge faster. All we can say is that 208 is certain to be enough iterations.\n\nMINRES\n\nThe following matrix is indefinite.\n\nA = FNC.poisson(10) - 20I\nλ = eigvals(Matrix(A))\nisneg = @. λ < 0\n@show sum(isneg), sum(.!isneg);\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nmn, mx = extrema(-λ[isneg])\nκ₋ = mx / mn\nmn, mx = extrema(λ[.!isneg])\nκ₊ = mx / mn\nρ = (sqrt(κ₋ * κ₊) - 1) / (sqrt(κ₋ * κ₊) + 1)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nb = rand(100)\nx, hist = minres(A, b, reltol=1e-10, maxiter=51, log=true);\n\nrelres = hist[:resnorm] / norm(b)\nm = 0:length(relres)-1\nplot(m, relres, label=\"observed\", leg=:left,\n    xaxis=L\"m\", yaxis=(:log10, \"relative residual\"),\n    title=(\"Convergence of MINRES\"))\nplot!(m, ρ .^ (m / 2), l=:dash, label=\"upper bound\")\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\n\n\nMINRES\n\nThe following matrix is indefinite.\n\nA = FNC.poisson(10) - 20I\nλ = eigvals(Matrix(A))\nisneg = @. λ < 0\n@show sum(isneg), sum(.!isneg);\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nmn, mx = extrema(-λ[isneg])\nκ₋ = mx / mn\nmn, mx = extrema(λ[.!isneg])\nκ₊ = mx / mn\nρ = (sqrt(κ₋ * κ₊) - 1) / (sqrt(κ₋ * κ₊) + 1)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nb = rand(100)\nx, hist = minres(A, b, reltol=1e-10, maxiter=51, log=true);\n\nrelres = hist[:resnorm] / norm(b)\nm = 0:length(relres)-1\nplot(m, relres, label=\"observed\", leg=:left,\n    xaxis=L\"m\", yaxis=(:log10, \"relative residual\"),\n    title=(\"Convergence of MINRES\"))\nplot!(m, ρ .^ (m / 2), l=:dash, label=\"upper bound\")\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.","type":"content","url":"/minrescg#minres","position":5},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Conjugate gradients"},"type":"lvl2","url":"/minrescg#conjugate-gradients","position":6},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Conjugate gradients"},"content":"Given positive definiteness in addition to symmetry, we arrive at perhaps the most famous Krylov subspace method for \\mathbf{A}\\mathbf{x}=\\mathbf{b}, called conjugate gradients.\n\nSuppose now that \\mathbf{A} is hermitian and positive definite (HPD). Then \\mathbf{A} has a Cholesky factorization, which in the complex case is \\mathbf{A}=\\mathbf{R}^*\\mathbf{R}. Therefore, for any vector \\mathbf{u},\\mathbf{u}^*\\mathbf{A}\\mathbf{u} = (\\mathbf{R}\\mathbf{u})^*(\\mathbf{R}\\mathbf{u})=\\|\\mathbf{R} \\mathbf{u}\\|^2,\n\nwhich is nonnegative and zero only when \\mathbf{u}=\\boldsymbol{0}, provided \\mathbf{A} (and therefore \\mathbf{R}) is nonsingular. Hence we can define a special vector norm relative to \\mathbf{A}:\\| \\mathbf{u} \\|_{\\mathbf{A}} = \\left( \\mathbf{u}^*\\mathbf{A}\\mathbf{u} \\right)^{1/2}.\n\nMethod of conjugate gradients (CG)\n\nFor each m=1,2,3,\\ldots, minimize \\|\\mathbf{x}_m-\\mathbf{x}\\|_{\\mathbf{A}} for \\mathbf{x} in the Krylov subspace \\mathcal{K}_m.","type":"content","url":"/minrescg#conjugate-gradients","position":7},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Convergence"},"type":"lvl2","url":"/minrescg#convergence","position":8},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Convergence"},"content":"The convergence of CG and MINRES is dependent on the eigenvalues of \\mathbf{A}. In the HPD case the eigenvalues are real and positive, and they equal the singular values. Hence the condition number κ is equal to the ratio of the largest eigenvalue to the smallest one. The following theorem suggests that MINRES and CG are not so different in convergence.\n\nMINRES and CG convergence (definite case)\n\nLet \\mathbf{A} be real and SPD with 2-norm condition number κ. For MINRES define R(m)=\\|\\mathbf{r}_m\\|_2/\\|\\mathbf{b}\\|_2, and for CG define R(m)=\\|\\mathbf{x}_m-\\mathbf{x}\\|_{\\mathbf{A}}/\\|\\mathbf{x}\\|_{\\mathbf{A}},\nwhere \\mathbf{r}_m and \\mathbf{x}_m are the residual and solution approximation associated with the space \\mathcal{K}_m. ThenR(m) \\le  2\\, \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^m.\n\nTheorem 8.6.2 characterizes the convergence of MINRES and CG similarly, differing only in whether the measurement is of the residual or the \\mathbf{A}-norm of the error, respectively. While these are different quantities, in practice one may not find a consistent advantage for one method over the other.\n\nAs in the indefinite case with MINRES, a larger condition number is associated with slower convergence in the positive definite case. Specifically, to make the bound in \n\n(8.6.10) less than a number ε requires\\begin{gather*}\n  2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^m \\approx \\epsilon, \\\\\n  m \\log \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)\n  \\approx \\log\\Bigl( \\frac{\\epsilon}{2} \\Bigr).\n\\end{gather*}\n\nWe estimate\\begin{align*}\n   \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\n &=  (1 - \\kappa^{-1/2}\\,) (1 + \\kappa^{-1/2}\\,)^{-1}\\\\\n &= (1 - \\kappa^{-1/2}\\,)  (1 - \\kappa^{-1/2} + \\kappa^{-1} + \\cdots)\\\\\n &= 1 - 2\\kappa^{-1/2} + O(\\kappa^{-1}) \\quad \\text{ as $\\kappa\n   \\rightarrow \\infty$.}\n\\end{align*}\n\nWith the Taylor expansion \\log(1+x) = x - (x^2/2) + \\cdots, we finally conclude\\begin{gather*}\n  2 m \\kappa^{-1/2} \\approx \\log\\Bigl( \\frac{\\epsilon}{2} \\Bigr),\n  \\text{ or }\n  m = O(\\sqrt{\\kappa}),\n\\end{gather*}\n\nas an estimate of the number of iterations needed to achieve a fixed accuracy.\n\nAs a rule of thumb, the number of iterations required for MINRES or CG to converge is O(\\sqrt{\\kappa}), where κ is the condition number.\n\nThis estimate fails for very large κ, however.\n\nConvergence of MINRES and CG\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, 1 / 100)\nx = (1:n) / n\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from IterativeSolvers.\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = FNC.sprandsym(n, density, 1 / 2500)\nb = A * x;\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.\n\n\n\nConvergence of MINRES and CG\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, 1 / 100)\nx = (1:n) / n\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from IterativeSolvers.\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = FNC.sprandsym(n, density, 1 / 2500)\nb = A * x;\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.","type":"content","url":"/minrescg#convergence","position":9},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Exercises"},"type":"lvl2","url":"/minrescg#exercises","position":10},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Exercises"},"content":"✍ For each part, the eigenvalues of \\mathbf{A} are given. Suppose MINRES is applied to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Use \n\n(8.6.4) or \n\n(8.6.10), whichever is most appropriate, to determine a lower bound on m to guarantee reduction of the residual norm by a factor \n\n10-4.\n\n(a) -100,-99,\\ldots,-1,1,2,\\ldots,100\n\n(b) -100,1,2,\\ldots,100\n\n(c) 1,2,\\ldots,100\n\n⌨ Let \\mathbf{b} be a random unit vector of length 200. Define the matrixu = range(-200,-5,length=100); \nv = range(10,100,length=100);\nA = diagm([u;v]);\n\n(a)  Apply 120 iterations of minres to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Compute the relative error of the answer, and plot the norm of the residual as a function of m on a log-linear scale.\n\n(b) Add to your graph the line representing the upper bound \n\n(8.6.4). (Ignore the rounding in the exponent.) This line should stay strictly on or above the convergence curve.\n\n⌨ Let \\mathbf{b} be a random unit vector of length 500. Define the matrixA = spdiagm(range(4,10000,length=500));\n\n(a)  Apply 100 iterations of minres to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Compute the relative norm of the answer. Plot the norm of the residual as a function of m.\n\n(b) Add to your graph the line representing the upper bound \n\n(8.6.10). This line should stay strictly on or above the convergence curve.\n\n(c) Add a convergence curve for 100 iterations of cg.\n\n✍ Suppose a family of SPD matrices \\mathbf{A} is parameterized by t, and that the condition numbers of the matrices scale like O(t^2) as t\\to\\infty. Given that CG takes 60 iterations to reach a certain reduction in the error of a linear system when t=200, estimate the number of iterations CG will need to reach the same accuracy at t=300.\n\n✍ Given real n\\times n symmetric \\mathbf{A} and vector \\mathbf{b}=\\mathbf{A}\\mathbf{x}, we can define the scalar-valued function\\varphi(\\mathbf{u}) = \\mathbf{u}^T \\mathbf{A} \\mathbf{u} - 2 \\mathbf{u}^T \\mathbf{b}, \\qquad \\mathbf{u}\\in\\mathbb{R}^n.\n\n(a) Expand and simplify the expression \\varphi(\\mathbf{x}+\\mathbf{v})-\\varphi(\\mathbf{x}), keeping in mind that \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\n(b) Using the result of part (a), prove that if \\mathbf{A} is an SPD matrix, φ has a global minimum at \\mathbf{x}.\n\n(c) Show that for any vector \\mathbf{u}, \\|\\mathbf{u}-\\mathbf{x}\\|_{\\mathbf{A}}^2-\\varphi(\\mathbf{u}) is constant.\n\n(d) Using the result of part (c), prove that CG minimizes \\varphi(\\mathbf{u}) over Krylov subspaces.\n\n⌨ The following linear system arises from the Helmholtz equation for wave propagation:A = FNC.poisson(n) - k^2*I\nb = -ones(n^2)\n\n(a) Apply both MINRES and CG to the linear system for n=50 and k=1.3, solving to a relative residual tolerance of \n\n10-5. Plotting their convergence curves together.\n\n(b) Repeat part (a) for k=8.\n\n(c) Use eigs on the matrix from part (b) to show that it is indefinite. (Hint: Use which=:SR and which=:LR to get the smallest real and largest real values.) This helps explain why the CG convergence curve for this matrix looks rather strange.\n\nIn principle, the implementation of Lanczos iteration is minor change from Arnoldi, but numerical stability requires some extra analysis and effort. We do not present the details.","type":"content","url":"/minrescg#exercises","position":11},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-7","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The iterative solution of large linear systems is a vast and difficult subject. A broad yet detailed introduction to the subject, including classical topics such as Jacobi and Gauss–Seidel methods not mentioned in this chapter, is \n\nSaad (2003). A more focused introduction to Krylov methods is given in \n\nvan der Vorst (2003).\n\nThe conjugate gradient method was originally intended to be a direct method.  Theoretically, the answer is found in n steps if there are n unknowns if the arithmetic is perfect.  However, for floating-point arithmetic this result no longer holds.  The trouble is that as the method progresses, the succeeding search directions become closer to being dependent, and this causes problems for conditioning and floating-point computation.  The method was not successful until it came to be viewed as an iterative method that could be stopped once a reasonable approximation was reached.  The method was discovered by Hestenes and Stiefel independently, but they joined forces to publish a widely cited paper \n\nHestenes & Stiefel (1952) as part of an early research program in computing run by what was then called the (US) National Bureau of Standards (now called the National Institute of Standards and Technology).  It took until the 1970s for the method to catch on as a computational method \n\nGolub & O'Leary (1989).  The interested reader can visit the SIAM History Project’s articles at \n\nhttp://​history​.siam​.org​/hestenes​.htm to find an article by Hestenes that recounts the discovery (reprinted from Nash \n\nNash (1990)).\n\nFor those not experienced with preconditioning, it can seem like something of an art.  The approach that works best very often depends on the application. Summaries of some approaches can be found in Quarteroni et al. \n\nQuarteroni et al. (2007) and Trefethen and Bau \n\nTrefethen & III (1997).","type":"content","url":"/next-7","position":1},{"hierarchy":{"lvl1":"Krylov methods in linear algebra"},"type":"lvl1","url":"/overview-7","position":0},{"hierarchy":{"lvl1":"Krylov methods in linear algebra"},"content":"I warn you not to underestimate my powers.\n\nLuke Skywalker, Return of the Jedi\n\nWhat are the implications of the O(n^3) work requirements for solving linear systems? Suppose tomorrow your computer became a thousand times faster. (Historically this has taken about 15 years in the real world.) Assuming you are willing to wait just as long today as you were yesterday, the size of the linear system you can solve has gone up only by a factor of 10. Nice, but not nearly the jump that you got in hardware power. In fact, there is an odd paradox: faster computers make faster algorithms more important, not less, because they demand that you work at larger values of n, where asymptotic differences are large.\n\nIn practice the only reasonable way to deal with large matrices (at this writing, n>10^4 or so) is if they are sparse, or can be approximated sparsely. But LU factorization of a sparse matrix does not necessarily lead to sparse factors, particularly when row pivoting is required. The algorithm can be improved to be more sparse-aware, but we will not go into the details.\n\nInstead, we will replace LU factorization with an iterative algorithm. Unlike the LU factorization, iteration gives useful intermediate and continually improving results before the exact solution is found, allowing us to stop well before the nominal exact termination. More importantly, though, these iterations, based on an idea called Krylov subspaces, allow us to fully exploit sparsity.\n\nKrylov subspace methods have two other advantages that are subtle but critically relevant to applications. One is that they allow us to do linear algebra even without having the relevant matrix. This may sound undesirable or even impossible, but it exploits the connection between matrix-vector multiplication and a linear transformation. The other major advantage of Krylov subspace iterations is that they can exploit approximate inverses when they are available. These two features are among the most powerful ideas behind scientific computation today.","type":"content","url":"/overview-7","position":1},{"hierarchy":{"lvl1":"Power iteration"},"type":"lvl1","url":"/power","position":0},{"hierarchy":{"lvl1":"Power iteration"},"content":"Given that matrix-vector multiplication is fast for sparse matrices, let’s see what we might accomplish with only that at our disposal.\n\nPower iteration\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = rand(1.0:9.0, 5, 5)\nA = A ./ sum(A, dims=1)\nx = randn(5)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A * x\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A * y\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nThis phenomenon seems to occur regardless of the starting vector.\n\nx = randn(5)\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\n\n\nPower iteration\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = random.choice(range(10), (5, 5))\nA = A / sum(A, 0)\nx = random.randn(5)\nprint(x)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A @ x\nprint(y)\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A @ y\nprint(z)\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nx = random.randn(5)\nfor j in range(6):\n    x = A @ x\nprint(x)\nprint(A @ x)\n\nThis phenomenon is unlikely to be a coincidence!\n\nThere was a little cheating in \n\nDemo 8.2.1 to make the story come out neatly (specifically, the line A=A./sum(A,dims=1)). But it illustrates an important general fact that we investigate now.","type":"content","url":"/power","position":1},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Dominant eigenvalue"},"type":"lvl2","url":"/power#dominant-eigenvalue","position":2},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Dominant eigenvalue"},"content":"Analysis of matrix powers is most straightforward in the diagonalizable case. Let \\mathbf{A} be any diagonalizable n\\times n matrix having eigenvalues \\lambda_1,\\ldots,\\lambda_n and corresponding linearly independent eigenvectors \\mathbf{v}_1,\\ldots,\\mathbf{v}_n. Furthermore, suppose the eigenvalues are such that|\\lambda_1| > |\\lambda_2| \\ge |\\lambda_3| \\ge \\cdots \\ge |\\lambda_n|.\n\nGiven \n\n(8.2.1) we say that \\lambda_1 is the dominant eigenvalue. This was the case with \\lambda_1=1 for \\mathbf{A} in \n\nDemo 8.2.1.\n\nNow let \\mathbf{x} be an n-vector, let k be a positive integer, and refer to \n\n(7.2.10):\\mathbf{A}^k \\mathbf{x} = \\mathbf{V}\\mathbf{D}^k\\mathbf{V}^{-1}\\mathbf{x}.\n\nLet \\mathbf{z}=\\mathbf{V}^{-1}\\mathbf{x}, and recall that \\mathbf{D} is a diagonal matrix of eigenvalues. Then\\begin{split}\n  \\mathbf{A}^k\\mathbf{x} &= \\mathbf{V}\\mathbf{D}^k \\mathbf{z} = \\mathbf{V}\\begin{bmatrix} \\lambda_1^kz_1 \\\\[0.5ex] \\lambda_2^kz_2 \\\\ \\vdots \\\\ \\lambda_n^kz_n \\end{bmatrix} \\\\\n\t&= \\lambda_1^k \\left[ z_1 \\mathbf{v}_{1} +\n\t\tz_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right) ^k \n\t\t\\mathbf{v}_{2} + \\cdots + z_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^k\n\t\t\\mathbf{v}_{n} \\right].\n\\end{split}\n\nSince \\lambda_1 is dominant, we conclude that if z_1\\neq 0,\\left\\| \\frac{ \\mathbf{A}^k\\mathbf{x}}{\\lambda_1^k}\n- z_1\\mathbf{v}_1\\right\\| \\le |z_2|\\cdot\\left|\\frac{\\lambda_2}{\\lambda_1}\\right| ^k\n\\| \\mathbf{v}_{2} \\| + \\cdots +  |z_n|\\cdot\\left|\\frac{\\lambda_n}{\\lambda_1}\\right|^k\n\\| \\mathbf{v}_{n} \\| \\rightarrow 0 \\text{ as $k\\rightarrow \\infty$}.\n\nThat is, \\mathbf{A}^k\\mathbf{x} eventually is a scalar multiple of the dominant eigenvector.\n\nAttention\n\nFor algorithmic purposes, it is important to interpret \\mathbf{A}^k\\mathbf{x} as \\mathbf{A}\\bigl( \\cdots\\bigl( \\mathbf{A} (\\mathbf{A}\\mathbf{x})\\bigl) \\cdots\\bigl), i.e., as repeated applications of \\mathbf{A} to a vector. Doing so allows us to fully exploit sparsity of \\mathbf{A}, something which is not preserved by taking a matrix power \\mathbf{A}^k explicitly before the multiplication with \\mathbf{x} (see \n\nDemo 8.1.2).","type":"content","url":"/power#dominant-eigenvalue","position":3},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Power iteration"},"type":"lvl2","url":"/power#power-iteration","position":4},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Power iteration"},"content":"An important technicality separates us from an algorithm: unless |\\lambda_1|=1, the factor \\lambda_1^k tends to make \\|\\mathbf{A}^k\\mathbf{x}\\| either very large or very small. Nor can we easily normalize by \\lambda_1^k, as in \n\n(8.2.4), unless we know \\lambda_1 in advance.\n\nTo make a practical algorithm, we alternate matrix-vector multiplication with a renormalization of the vector. In the following, we use x_{k,m} and y_{k,m} to mean the mth component of vectors \\mathbf{x}_k and \\mathbf{y}_k.\n\nPower iteration\n\nGiven matrix \\mathbf{A}:\n\nChoose \\mathbf{x}_1.\n\nFor k=1,2,\\ldots,\n\na. Set \\mathbf{y}_k = \\mathbf{A} \\mathbf{x}_k.\n\nb. Find m such that |y_{k,m}|=\\|{\\mathbf{y}_k} \\|_\\infty.\n\nc. Set \\alpha_k = \\dfrac{1}{y_{k,m}} and \\,\\beta_k = \\dfrac{y_{k,m}}{x_{k,m}}.\n\nd. Set \\mathbf{x}_{k+1} = \\alpha_k \\mathbf{y}_k.\n\nNote that by definition, \\| \\mathbf{x}_{k+1}\\|_\\infty=1. Also, we can write\\mathbf{x}_{k} = (\\alpha_1 \\alpha_2 \\cdots \\alpha_k ) \\mathbf{A}^k \\mathbf{x}_{1}.\n\nThus \n\nAlgorithm 8.2.1 modifies \n\n(8.2.3) and \n\n(8.2.4) only slightly.\n\nFinally, if \\mathbf{x}_k is nearly a dominant eigenvector of \\mathbf{A}, then \\mathbf{A}\\mathbf{x}_k is nearly \\lambda_1\\mathbf{x}_k, and we can take the ratio \\beta_k=y_{k,m}/x_{k,m} as an eigenvalue estimate. In fact, revisiting \n\n(8.2.3), the extra \\alpha_j normalization factors cancel in the ratio, and, after some simplification, we get\\beta_k = \\frac{y_{k,m}}{x_{k,m}} = \\lambda_1\n\\frac{1+r_2^{k+1} b_2 + \\cdots +  r_n^{k+1} b_n}{1+r_2^{k} b_2 +  \\cdots +  r_n^{k} b_n},\n\nwhere r_j=\\lambda_j/\\lambda_1 and the b_j are constants. By assumption \n\n(8.2.1), each r_j satisfies |r_j|<1, so we see that \\beta_k\\rightarrow \\lambda_1 as k\\rightarrow\\infty.\n\nFunction 8.2.2 is our implementation of power iteration.\n\npoweriter\n\nPower iteration\n\n\"\"\"\n    poweriter(A,numiter)\n\nPerform `numiter` power iterations with the matrix `A`, starting\nfrom a random vector. Returns a vector of eigenvalue estimates\nand the final eigenvector approximation.\n\"\"\"\nfunction poweriter(A,numiter)\n    n = size(A,1)\n    x = normalize(randn(n),Inf)\n    β = zeros(numiter)\n    for k in 1:numiter\n        y = A*x\n        m = argmax(abs.(y))\n        β[k] = y[m]/x[m]\n        x = y/y[m]\n    end\n    return β,x\nend\n\n\n\nPower iteration\n\ndef poweriter(A, numiter):\n    \"\"\"\n    poweriter(A,numiter)\n\n    Perform `numiter` power iterations with the matrix `A`, starting from a random vector, \n    and return a vector of eigenvalue estimates and the final eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    for k in range(numiter):\n        y = A @ x\n        m = np.argmax(abs(y))\n        gamma[k] = y[m] / x[m]\n        x = y / y[m]\n\n    return gamma, x\n\nObserve that the only use of \\mathbf{A} is to find the matrix-vector product \\mathbf{A}\\mathbf{x}, which makes exploitation of the sparsity of \\mathbf{A} trivial.","type":"content","url":"/power#power-iteration","position":5},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Convergence"},"type":"lvl2","url":"/power#convergence","position":6},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Convergence"},"content":"Let’s examine the terms in the numerator and denominator of \n\n(8.2.6) more carefully:\\begin{split}\nr_2^{k} b_2 +  \\cdots +  r_n^{k} b_n &= r_2^k \\left[ b_2 + \\left( \\frac{r_3}{r_2} \\right)^kb_3 + \\cdots + \\left( \\frac{r_n}{r_2} \\right)^kb_n \\right] \\\\\n&= r_2^k \\left[ b_2 + \\left( \\frac{\\lambda_3}{\\lambda_2} \\right)^kb_3 + \\cdots + \\left( \\frac{\\lambda_n}{\\lambda_2} \\right)^kb_n \\right].\n\\end{split}\n\nAt this point we’ll introduce an additional assumption,|\\lambda_2| > |\\lambda_3| \\ge \\cdots \\ge |\\lambda_n|.\n\nThis condition isn’t strictly necessary, but it simplifies the following statements considerably because now it’s clear that the quantity in \n\n(8.2.7) approaches b_2 r_2^k as k\\rightarrow \\infty.\n\nNext we estimate \n\n(8.2.6) for large k, using a geometric series expansion for the denominator to get\\begin{split}\n\\beta_k & \\to \\lambda_1 \\left( 1+b_2 r_2^{k+1} \\right) \\left( 1 - b_2 r_2^{k} + O(r_2^{2k}) \\right), \\\\\n\\beta_k - \\lambda_1 &\\to \\lambda_1 b_2 (  r_2 - 1 ) r_2^{k}.\n\\end{split}\n\nThis is linear convergence with factor r_2:\\frac{\\beta_{k+1} - \\lambda_1}{\\beta_{k}-\\lambda_1} \\rightarrow r_2 = \\frac{\\lambda_2}{\\lambda_1} \\quad \\text{as } k\\rightarrow \\infty.\n\nThe error in the power iteration eigenvalue estimates \\beta_k is reduced asymptotically by a constant factor \\lambda_2/\\lambda_1 at each iteration.\n\nConvergence of power iteration\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run the power iteration 60 times. The best estimate of the dominant eigenvalue is the last entry of the first output.\n\nβ, x = FNC.poweriter(A, 60)\neigval = β[end]\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = @. 1 - β\nplot(0:59, abs.(err), m=:o, title=\"Convergence of power iteration\",\n    xlabel=L\"k\", yaxis=(L\"|\\lambda_1-\\beta_k|\", :log10, [1e-10, 1]))\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\n@show theory = λ[2] / λ[1];\n@show observed = err[40] / err[39];\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nβ[26:30]\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = @. β[end] - β[1:end-1]\nplot(0:58, abs.(err), m=:o, title=\"Convergence of power iteration\",\n    xlabel=L\"k\", yaxis=(L\"|\\beta_{60}-\\beta_k|\", :log10, [1e-10, 1]))\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.\n\n\n\nConvergence of power iteration\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nev = [1, -0.75, 0.6, -0.4, 0]\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run the power iteration 60 times. The first output should be a sequence of estimates converging to the dominant eigenvalue—which, in this case, we set up to be 1.\n\nbeta, x = FNC.poweriter(A, 60)\nprint(beta)\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = 1 - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1)\nxlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\nprint(f\"theory: {ev[1] / ev[0]:.5f}\")\nprint(f\"observed: {err[40] / err[39]:.5f}\")\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nprint(beta[26:30])\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = beta[-1] - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1), xlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.\n\nThe practical utility of \n\n(8.2.10) is limited because if we knew \\lambda_1 and \\lambda_2, we wouldn’t be running the power iteration in the first place! Sometimes it’s possible to find estimates of or bounds on the ratio. If nothing else, though, it is useful to know that linear convergence is expected at a rate based solely on the dominant eigenvalues.","type":"content","url":"/power#convergence","position":7},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Exercises"},"type":"lvl2","url":"/power#exercises","position":8},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Exercises"},"content":"⌨ Use \n\nFunction 8.2.2 to perform 20 power iterations for the following matrices. Quantitatively compare the observed convergence to the prediction in \n\n(8.2.10).\n\n(a)\n\\mathbf{A} = \\begin{bmatrix}\n   1.1 & 1 \\\\\n   0.1 & 2.4\n \\end{bmatrix} \\quad\n(b) \\mathbf{A} = \\begin{bmatrix}\n   2 & 1 \\\\\n   1 & 0\n \\end{bmatrix} \\quad\n(c)  \\mathbf{A} = \\begin{bmatrix}\n   6 & 5 & 4 \\\\\n   5 & 4 & 3 \\\\\n   4 & 3 & 2\n \\end{bmatrix}\n\n(d) \\mathbf{A} = \\begin{bmatrix}\n 8 & -14 & 0 & -14 \\\\\n -8 & 1 & 1 & 1 \\\\\n -4 & -2 & 0 & 2 \\\\\n 8 & -7 & -1 & -7 \n \\end{bmatrix}\n\n✍ Describe what happens during power iteration using the matrix \\mathbf{A}= \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} and initial vector \\mathbf{x}=\\begin{bmatrix} 0.4\\\\0.7 \\end{bmatrix}. Does the algorithm converge to an eigenvector? How does this relate to \n\n(8.2.3)?\n\n⌨  In  \n\nExercise 2.3.5 we considered a mass-lumped model of a hanging string that led to a tridiagonal system of linear equations. Then, in \n\nExercise 7.2.6, we found that eigenvectors of the same matrix correspond to vibrational modes of the string. The same setup can be applied to a membrane hanging from a square frame. Lumping the mass onto a Cartesian grid, each interacts with the four neighbors to the north, south, east, and west. If n masses are used in each coordinate direction, we get an n^2\\times n^2 sparse matrix \\mathbf{A} that can be constructed by FNC.poisson(n).\n\n(a) Let n=10 and make a spy plot of \\mathbf{A}. What is the density of \\mathbf{A}? Most rows all have the same number of nonzeros; find this number.\n\n(b) Find the dominant \\lambda_1 using eigs for n=10,15,20,25.\n\n(c) For each n in part (b), apply 100 steps of \n\nFunction 8.2.2. On one graph, plot the four convergence curves |\\beta_k-\\lambda_1| using a semi-log scale. (They will not be smooth curves because this matrix has many repeated eigenvalues that complicate the convergence analysis.)\n\n⌨ Copy the instructions from \n\nExercise 8.1.5 to obtain a large, sparse matrix \\mathbf{A}. Use \n\nFunction 8.2.2 to find the leading eigenvalue of \\mathbf{A}^T\\mathbf{A} to at least six significant digits.\n\n⌨ For symmetric matrices, the Rayleigh quotient \n\n(7.4.5) converts an O(\\epsilon) eigenvector estimate into an O(\\epsilon^2) eigenvalue estimate. Duplicate \n\nFunction 8.2.2 and rename it to powersym. Modify the new function to use the Rayleigh quotient to produce the entries of β. Your function should not introduce any additional matrix-vector multiplications. Apply the original \n\nFunction 8.2.2 and the new powersym on the matrix matrixdepot(\"fiedler\",100), plotting the convergence curves on one graph.\n\nIf \\mathbf{x} is chosen randomly, the probability that z_1=0 is mathematically zero.","type":"content","url":"/power#exercises","position":9},{"hierarchy":{"lvl1":"Preconditioning"},"type":"lvl1","url":"/precond","position":0},{"hierarchy":{"lvl1":"Preconditioning"},"content":"An important aspect of MINRES and CG (and, by extension, GMRES) is that the convergence of a Krylov method can be expected to deteriorate as the condition number of the matrix increases. Even moderately large condition numbers can make the convergence impractically slow. Therefore it’s common for these methods to be used with a technique to reduce the relevant condition number.\n\nPreconditioning\n\nGiven a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, a preconditioner is a matrix \\mathbf{M} or equivalent linear transformation that modifies the system to be(\\mathbf{M}^{-1} \\mathbf{A}) \\mathbf{x} = \\mathbf{M}^{-1}\\mathbf{b}.\n\nMore specifically, \n\n(8.8.1) is known as left preconditioning, but it is the simplest and most common type.\n\nAs usual, we do not want to actually compute \\mathbf{M}^{-1} for a given \\mathbf{M}. Instead, we have a linear system with the matrix \\mathbf{M}^{-1}\\mathbf{A}. In a Krylov method, the operation “let \\mathbf{v}=\\mathbf{A}\\mathbf{u}” becomes a two-step process:\n\nSet \\mathbf{y}=\\mathbf{A}\\mathbf{u}.\n\nSolve \\mathbf{M}\\mathbf{v}=\\mathbf{y} for \\mathbf{v}.\n\nAs an implementation detail, it is common to provide the Krylov solver with code that does step 2; if the matrix \\mathbf{M} is given, the default is to use sparse factorization.\n\nThere are competing objectives in the choice of \\mathbf{M}. On one hand, we want \\mathbf{M}^{-1}\\mathbf{A}\\approx \\mathbf{I} in some sense because that makes \n\n(8.8.1) easy to solve by Krylov iteration. Hence \\mathbf{M}\\approx \\mathbf{A}. On the other hand, we desire that solving the system \\mathbf{M}\\mathbf{v}=\\mathbf{y} be relatively fast.\n\nGood preconditioning is a matter of finding an easily inverted (i.e., quickly solvable) approximation of the original matrix.","type":"content","url":"/precond","position":1},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Diagonal preconditioning"},"type":"lvl2","url":"/precond#diagonal-preconditioning","position":2},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Diagonal preconditioning"},"content":"One of the simplest choices for the preconditioner \\mathbf{M} is a diagonal matrix. This definitely meets the requirement of being fast to invert: the solution of \\mathbf{M}\\mathbf{v}=\\mathbf{y} is just v_i=y_i/M_{ii}. The only question is whether it can be chosen in such a way that \\mathbf{M}^{-1}\\mathbf{A} is much more amenable to Krylov iterations than \\mathbf{A} is. This may be the case when the rows of \\mathbf{A} differ greatly in scale, or when \\mathbf{A} is diagonally dominant (see \n\n(2.9.1)).\n\nDiagonal preconditioning\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nA = matrixdepot(\"wathen\", 60)\nn = size(A, 1)\n@show n, nnz(A);\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nb = ones(n)\nM = DiagonalPreconditioner(diag(A));\n\nWe now compare CG with and without the preconditioner.\n\nplain(b) = cg(A, b, maxiter=200, reltol=1e-4, log=true)\ntime_plain = @elapsed x, hist1 = plain(b)\nprec(b) = cg(A, b, Pl=M, maxiter=200, reltol=1e-4, log=true)\ntime_prec = @elapsed x, hist2 = prec(b)\n@show time_plain, time_prec\n\nrr = hist1[:resnorm]\nplot(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"plain\")\nrr = hist2[:resnorm]\nplot!(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"preconditioned\")\ntitle!(\"Diagonal preconditioning in CG\")\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\n\n\nDiagonal preconditioning\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nA = matrixdepot(\"wathen\", 60)\nn = size(A, 1)\n@show n, nnz(A);\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nb = ones(n)\nM = DiagonalPreconditioner(diag(A));\n\nWe now compare CG with and without the preconditioner.\n\nplain(b) = cg(A, b, maxiter=200, reltol=1e-4, log=true)\ntime_plain = @elapsed x, hist1 = plain(b)\nprec(b) = cg(A, b, Pl=M, maxiter=200, reltol=1e-4, log=true)\ntime_prec = @elapsed x, hist2 = prec(b)\n@show time_plain, time_prec\n\nrr = hist1[:resnorm]\nplot(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"plain\")\nrr = hist2[:resnorm]\nplot!(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"preconditioned\")\ntitle!(\"Diagonal preconditioning in CG\")\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.","type":"content","url":"/precond#diagonal-preconditioning","position":3},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Incomplete factorization"},"type":"lvl2","url":"/precond#incomplete-factorization","position":4},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Incomplete factorization"},"content":"Another general-purpose technique is the incomplete LU factorization. Since true factorization of a sparse matrix usually leads to an undesirable amount of fill-in, incomplete LU sacrifices exact factors by dropping elements smaller than an adjustable threshold.\n\nIncomplete LU preconditioning\n\nHere is a nonsymmetric matrix arising from a probabilistic model in computational chemistry.\n\nA = sparse(matrixdepot(\"Watson/chem_master1\"))\nn = size(A, 1)\n@show n, nnz(A), issymmetric(A)\n\nWithout a preconditioner, GMRES makes essentially no progress after 100 iterations.\n\nb = rand(40000)\nconst GMRES = IterativeSolvers.gmres\nx, history = GMRES(A, b, maxiter=100, reltol=1e-5, log=true)\nresnorm = history[:resnorm]\n@show resnorm[end] / resnorm[1];\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\niLU = ilu(A, τ=0.25)\n@show nnz(iLU) / nnz(A);\n\nThe result is almost 10 times as dense as \\mathbf{A} and yet still not a true factorization of it. However, it’s close enough for an approximate inverse in a preconditioner. The actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}, but we just supply the factorization to gmres.\n\n_, history = GMRES(A, b, Pl=iLU, maxiter=100, reltol=1e-5, log=true)\nhistory\n\nThe τ parameter in ilu balances the accuracy of the iLU factorization with the time needed to compute it and invert it. As \\tau\\to 0, more of the elements are kept, making the preconditioner more effective but slower per iteration.\n\nplt = plot(0:40, resnorm[1:41] / resnorm[1], label=\"no preconditioning\",\n    xaxis=(\"iteration number\"), yaxis=(:log10, \"residual norm\"),\n    leg=:bottomright, title=\"Incomplete LU preconditioning\")\nfor τ in [2, 1, 0.25, 0.1]\n    t = @elapsed iLU = ilu(A; τ)\n    t += @elapsed _, history = GMRES(A, b, Pl=iLU, maxiter=100,\n        reltol=1e-5, log=true)\n    resnorm = history[:resnorm]\n    label = \"τ = $τ, time = $(round(t,digits=3))\"\n    plot!(0:length(resnorm)-1, resnorm / resnorm[1]; label)\nend\nplt\n\nIn any given problem, it’s impossible to know in advance where the right balance lies between fidelity and speed for the preconditioner.\n\n\n\nIncomplete LU preconditioning\n\nHere is a nonsymmetric matrix arising from a probabilistic model in computational chemistry.\n\nA = sparse(matrixdepot(\"Watson/chem_master1\"))\nn = size(A, 1)\n@show n, nnz(A), issymmetric(A)\n\nWithout a preconditioner, GMRES makes essentially no progress after 100 iterations.\n\nb = rand(40000)\nconst GMRES = IterativeSolvers.gmres\nx, history = GMRES(A, b, maxiter=100, reltol=1e-5, log=true)\nresnorm = history[:resnorm]\n@show resnorm[end] / resnorm[1];\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\niLU = ilu(A, τ=0.25)\n@show nnz(iLU) / nnz(A);\n\nThe result is almost 10 times as dense as \\mathbf{A} and yet still not a true factorization of it. However, it’s close enough for an approximate inverse in a preconditioner. The actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}, but we just supply the factorization to gmres.\n\n_, history = GMRES(A, b, Pl=iLU, maxiter=100, reltol=1e-5, log=true)\nhistory\n\nThe τ parameter in ilu balances the accuracy of the iLU factorization with the time needed to compute it and invert it. As \\tau\\to 0, more of the elements are kept, making the preconditioner more effective but slower per iteration.\n\nplt = plot(0:40, resnorm[1:41] / resnorm[1], label=\"no preconditioning\",\n    xaxis=(\"iteration number\"), yaxis=(:log10, \"residual norm\"),\n    leg=:bottomright, title=\"Incomplete LU preconditioning\")\nfor τ in [2, 1, 0.25, 0.1]\n    t = @elapsed iLU = ilu(A; τ)\n    t += @elapsed _, history = GMRES(A, b, Pl=iLU, maxiter=100,\n        reltol=1e-5, log=true)\n    resnorm = history[:resnorm]\n    label = \"τ = $τ, time = $(round(t,digits=3))\"\n    plot!(0:length(resnorm)-1, resnorm / resnorm[1]; label)\nend\nplt\n\nIn any given problem, it’s impossible to know in advance where the right balance lies between fidelity and speed for the preconditioner.\n\nIn practice, good preconditioning is often as important, if not more important, than the specific choice of Krylov method. Effective preconditioning may require deep understanding of the underlying application, however, which limits our ability to go into further details. For instance, the linear system may be some approximation of a continuous mathematical model, and then \\mathbf{M} can be derived by using a cruder form of the approximation. Krylov methods offer a natural way to exploit these and other approximate inverses.","type":"content","url":"/precond#incomplete-factorization","position":5},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Exercises"},"type":"lvl2","url":"/precond#exercises","position":6},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Exercises"},"content":"✍ Suppose \\mathbf{M}=\\mathbf{R}^T\\mathbf{R}. Show that the eigenvalues of \\mathbf{R}^{-T}\\mathbf{A}\\mathbf{R}^{-1} are the same as the eigenvalues of \\mathbf{M}^{-1}\\mathbf{A}. (This observation underlies preconditioning variants for SPD matrices.)\n\n⌨ The object returned by ilu stores the factors in a way that optimizes sparse triangular substitution. You can recover the factors themselves viaiLU = ilu(A,τ=0.1)   # for example\nL, U = I+iLU.L, iLU.U'\n\nIn this problem, use A = 1.5I + sprand(800,800,0.005).\n\n(a) Using \\tau=0.3 for the factorization, plot the eigenvalues of \\mathbf{A} and of \\mathbf{M}^{-1}\\mathbf{A} in the complex plane on side-by-side subplots. Do they support the notion that \\mathbf{M}^{-1}\\mathbf{A} is “more like” an identity matrix than \\mathbf{A} is? (Hint: the matrices are small enough to convert to standard dense form for the use of eigvals.)\n\n(b) Repeat part (a) for \\tau=0.03. Is \\mathbf{M} more accurate than in part (a), or less?\n\n⌨ (Continuation of \n\nExercise 8.5.5.) Let \\mathbf{B} be diagm(1:100),  let \\mathbf{I} be I(100), and let \\mathbf{Z} be a 100\\times 100 matrix of zeros. Define\\mathbf{A} = \\begin{bmatrix}\n      \\mathbf{B} & \\mathbf{I} \\\\ \\mathbf{Z} & -\\mathbf{B}\n    \\end{bmatrix}\n\nand let \\mathbf{b} be a 200-vector of ones. The matrix \\mathbf{A} is difficult for GMRES.\n\n(a) Design a diagonal preconditioner \\mathbf{M}, with all diagonal elements equal to 1 or -1, such that \\mathbf{M}^{-1}\\mathbf{A} has all positive eigenvalues. Apply gmres without restarts using this preconditioner and a tolerance of \n\n10-10 for 100 iterations. Plot the convergence curve.\n\n(b) Now design another diagonal preconditioner such that all the eigenvalues of \\mathbf{M}^{-1}\\mathbf{A} are 1, and apply preconditioned gmres again. How many iterations are apparently needed for convergence?\n\n⌨ Let A = matrixdepot(\"Bai/rdb2048\"), and let b be a vector of 2048 ones. In the steps below, use GMRES for up to 300 iterations without restarts and with a stopping tolerance of \n\n10-4.\n\n(a) Time the GMRES solution without preconditioning. Verify that convergence was achieved.\n\n(b) Show that diagonal preconditioning is not helpful for this problem.\n\n(c) To two digits, find a value of τ in iLU such that the preconditioned method transitions from effective and faster than part (a) to ineffective.","type":"content","url":"/precond#exercises","position":7},{"hierarchy":{"lvl1":"Sparsity and structure"},"type":"lvl1","url":"/structure-1","position":0},{"hierarchy":{"lvl1":"Sparsity and structure"},"content":"Very large matrices cannot be stored all within primary memory of a computer unless they are sparse. A sparse matrix has structural zeros, meaning entries that are known to be exactly zero.} For instance, the adjacency matrix of a graph has zeros where there are no links in the graph. To store and operate with a sparse matrix efficiently, it is not represented as an array of all of its values. There is a variety of sparse formats available; for the most part, you can imagine that the matrix is stored as triples (i,j,A_{ij}) for all the nonzero (i,j) locations.","type":"content","url":"/structure-1","position":1},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Computing with sparse matrices"},"type":"lvl2","url":"/structure-1#computing-with-sparse-matrices","position":2},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Computing with sparse matrices"},"content":"Most graphs with real applications have many fewer edges than the maximum possible n^2 for n nodes. Accordingly, their adjacency matrices have mostly zero elements and should be represented sparsely. Julia functions to deal with sparse matrices are found in the SparseArrays package in the standard library.\n\nSparsity\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\n@load \"roswell.jld2\" A;      # file is on the book's website\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nUse nnz to count the number of nonzeros in a sparse matrix.\n\nm, n = size(A)\n@show density = nnz(A) / (m * n);\n\nThe computer memory consumed by any variable can be discovered using summarysize. We can use it to compare the space needed for the sparse representation to its dense counterpart, that is, the space needed to store all the elements, whether zero or not.\n\nF = Matrix(A)\nBase.summarysize(F) / Base.summarysize(A)\n\nAs you can see, the storage savings are dramatic. Matrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nx = randn(n)\nA * x;   # make sure * is loaded and compiled\n@elapsed for i in 1:300\n    A * x\nend\n\nF * x;\n@elapsed for i in 1:300\n    F * x\nend\n\n\n\nSparsity\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nimport scipy.sparse as sp\nfrom scipy.io import loadmat\n\nvars = loadmat(\"roswelladj.mat\")    # get from the book's website\nA = sp.csr_matrix(vars[\"A\"])\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nm, n = A.shape\nprint(f\"density is {A.nnz / (m * n):.3%}\")\n\nWe can compare the storage space needed for the sparse \\mathbf{A} with the space needed for its dense / full counterpart.\n\nF = A.todense()\nprint(f\"{A.data.nbytes/1e6:.3f} MB for sparse form, {F.nbytes/1e6:.3f} MB for dense form\")\n\nMatrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nfrom timeit import default_timer as timer\nx = random.randn(n)\nstart = timer()\nfor i in range(1000):\n    A @ x\nprint(f\"sparse time: {timer() - start:.4g} sec\")\n\nstart = timer()\nfor i in range(1000):\n    F @ x\nprint(f\"dense time: {timer() - start:.4g} sec\")\n\nArithmetic operations such as +, -, *, and ^ respect and exploit sparsity if the matrix operands are sparse. However, matrix operations may substantially decrease the amount of sparsity, a phenomenon known as fill-in.\n\nFill-in of a sparse matrix\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\n@load \"smallworld.jld2\" A\ngraphplot(A, linealpha=0.5)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nspy(A, title=\"Nonzero locations\", m=2, color=:blues)\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nplt = plot(layout=(1, 3), legend=:none, size=(600, 240))\nfor k in 2:4\n    spy!(A^k, subplot=k - 1, color=:blues,\n        title=latexstring(\"\\\\mathbf{A}^$k\"))\nend\nplt\n\n\n\nFill-in of a sparse matrix\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nimport networkx as nx\nwsg = nx.watts_strogatz_graph(200, 4, 0.02)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nA = nx.adjacency_matrix(wsg)\nspy(A)\ntitle(\"Adjacency matrix $A$\");\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nWhile A**6 is valid syntax here, it means elementwise power, not matrix power.\n\nfrom scipy.sparse.linalg import matrix_power\nspy(matrix_power(A, 6))\ntitle(\"$A^6$\")","type":"content","url":"/structure-1#computing-with-sparse-matrices","position":3},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Banded matrices"},"type":"lvl2","url":"/structure-1#banded-matrices","position":4},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Banded matrices"},"content":"A particularly important type of sparse matrix is a banded matrix. Recall from \n\nExploiting matrix structure that \\mathbf{A} has upper bandwidth p if j-i > p implies A_{ij}=0, and lower bandwidth q if i-j > q implies A_{ij}=0. We say the total bandwidth is p+q+1. Banded matrices appear naturally in many applications where each element interacts directly with only a few neighbors.\n\nWithout pivoting, an LU factorization preserves bandwidth, but pivoting can change or destroy bandedness.\n\nBanded matrices\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nUse fill to create an array of a given size, with each element equal to a provided value.\n\nA = diagm( -1 => [4, 3, 2, 1, 0], \n    0 => [2, 2, 0, 2, 1, 2], \n    1 => fill(-1, 5) )\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\n@show diag_main = diag(A);\n@show diag_minusone = diag(A, -1);\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\nL, U = FNC.lufact(A)\nL\n\nU\n\nBanded matrices\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nA = [ 2 -1  0  0  0  0\n      4  2 -1  0  0  0\n      0  3  0 -1  0  0\n      0  0  2  2 -1  0\n      0  0  0  1  1 -1\n      0  0  0  0  0  2 ];\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\ndiag_main = diag(A, 0)'\ndiag_plusone = diag(A, 1)'\ndiag_minusone = diag(A,-1)'We can also put whatever numbers we like onto any diagonal with `diag`.\n\nA = A + diag([5 8 6 7], 2)\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\n[L, U] = lufact(A)\n\nBanded matrices\n\nHere is a matrix with both lower and upper bandwidth equal to one. Such a matrix is called tridiagonal.\n\nA = array([ \n    [2, -1,  0,  0,  0,  0],\n    [4,  2, -1,  0,  0,  0],\n    [0,  3,  0, -1,  0,  0],\n    [0,  0,  2,  2, -1,  0],\n    [0,  0,  0,  1,  1, -1],\n    [0,  0,  0,  0,  0,  2 ]\n    ])\n\nWe can extract the elements on any diagonal using the diag command. The “main” or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nprint( diag(A) )\n\nprint( diag(A, 1) )\n\nprint( diag(A, -1) )\n\nWe can also construct matrices by specifying a diagonal with the diag function.\n\nA = A + diag([pi, 8, 6, 7], 2)\nprint(A)\n\nL, U = FNC.lufact(A)\nprint(L)\n\nprint(U)\n\nObserve above that the lower and upper bandwidths of \\mathbf{A} are preserved in the factor matrices.","type":"content","url":"/structure-1#banded-matrices","position":5},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Systems and eigenvalues"},"type":"lvl2","url":"/structure-1#systems-and-eigenvalues","position":6},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Systems and eigenvalues"},"content":"If given a sparse matrix, the backslash operator will automatically try a form of sparse-aware Cholesky or pivoted LU factorization. Depending on the sparsity pattern of the matrix, the time taken to solve the linear system may be well below the O(n^3) needed in the general case.\n\nFor very large matrices, it’s unlikely that you will want to find all of its eigenvalues and eigenvectors. In \n\nKrylov subspaces we describe some of the math behind an algorithm that can find a selected number of eigenvalues of largest magnitude, lying to the extreme left or right, or nearest a given complex number.\n\nEigenvalues of sparse matrices\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nλ = @. 1 + 1 / (1:n)   # exact eigenvalues\nA = FNC.sprandsym(n, density, λ);\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=:LM.\n\nλmax, V = eigs(A, nev=5, which=:LM)    # Largest Magnitude\nfmt = ft_printf(\"%20.15f\")\npretty_table([λmax λ[1:5]], header=[\"found\", \"exact\"], formatters=fmt)\n\nNow we find the 5 closest to the value 1 in the complex plane, via sigma=1.\n\nλ1, V = eigs(A, nev=5, sigma=1)    # closest to sigma\ndata = [λ1 λ[end:-1:end-4]]\npretty_table(data, header=[\"found\", \"exact\"], formatters=fmt)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nx = @. 1 / (1:n);\nb = A * x;\n\nnorm(x - A \\ b);  # force compilation\nt = @elapsed sparse_err = norm(x - A \\ b)\nprintln(\"Time for sparse solve: $t\")\n\nD = Matrix(A)  # convert to regular matrix\nnorm(x - D \\ b);\nt = @elapsed dense_err = norm(x - D \\ b)\nprintln(\"Time for dense solve: $t\")\n\n@show sparse_err;\n@show dense_err;\n\n\n\nEigenvalues of sparse matrices\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nev = 1 / arange(1, n + 1)\nA = FNC.sprandsym(n, density, eigvals=ev)\nprint(f\"density is {A.nnz / prod(A.shape):.3%}\")\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=\"LM\".\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=5, which=\"LM\")    # largest magnitude\nprint(1 / ev)\n\nNow we find the 4 closest to the value 1 in the complex plane, via sigma=1.\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=4, sigma=0.03)    # closest to sigma\nprint(ev)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nfrom scipy.sparse.linalg import spsolve\nx = 1 / arange(1, n + 1)\nb = A @ x\nstart = timer()\nxx = spsolve(A, b)\nprint(f\"sparse time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")\n\nfrom numpy.linalg import solve\nF = A.todense()\nstart = timer()\nxx = solve(F, b)\nprint(f\"dense time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")","type":"content","url":"/structure-1#systems-and-eigenvalues","position":7},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Exercises"},"type":"lvl2","url":"/structure-1#exercises","position":8},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Exercises"},"content":"⌨ Use spdiagm to build the 50\\times 50 matrices\\mathbf{A} =\n\\begin{bmatrix}\n-2 & 1 & & &  \\\\\n1 & -2 & 1 & &  \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & 1 & -2 & 1 \\\\\n& & & 1 & -2\n\\end{bmatrix}, \\qquad\n\\mathbf{B} =\n\\begin{bmatrix}\n-2 & 1 & & & 1 \\\\\n1 & -2 & 1 & &  \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & 1 & -2 & 1 \\\\\n1 & & & 1 & -2\n\\end{bmatrix}.\n\nFor each matrix, use spy and an inspection of the 5\\times 5 submatrices in the corners to verify the correctness of your matrices.\n\n⌨ This problem requires the matrix used in \n\nDemo 8.1.2; you can load it viaurl = \"https://tobydriscoll.net/fnc-julia/_static/resources/smallworld.jld2\"\ndatafile = download(url)\n@load datafile A\n\n(a) Find the density of \\mathbf{A} (number of nonzeros divided by total number of elements), \\mathbf{A}^2, \\mathbf{A}^4, and \\mathbf{A}^8. (You should find that it increases with the power of A.)\n\n(b) The LU factors tend to at least partially retain sparsity. Find the density of the \\mathbf{L} and \\mathbf{U} factors of \\mathbf{A} using the built-in lu. (See \n\nDemo 2.9.1 for usage of lu in the sparse case.)\n\n(c) Repeat part (b) for the QR factorization using qr.\n\n⌨ One use of adjacency matrices is to analyze the links between members of a collection. Obtain the adjacency matrix \\mathbf{A} from \n\nDemo 8.1.1 via the following:url = \"https://tobydriscoll.net/fnc-julia/_static/resources/roswell.jld2\"\ndatafile = download(url)\n@load datafile A\n\nThe matrix catalogs the links between web sites related to the town of Roswell, NM, with A_{ij}=1 if and only if site i links to site j.\n\n(a) Verify numerically that the matrix does not include any links from a site to itself.\n\n(b) Verify numerically that \\mathbf{A} is not symmetric. (Thus, its graph is a directed one.)\n\n(c) How many sites in the group are not pointed to by any other sites in the group?\n\n(d) Which site points to the most other sites?\n\n(e) Which site is pointed to the most by the other sites? This is a crude way to establish the most important site.\n\n(f) There are \n\n27902 possible ways to connect ordered pairs of sites. What fraction of these pairs is connected by a walk of links that is no greater than three in length?\n\n⌨ The graph Laplacian matrix is \\mathbf{L}=\\mathbf{D}-\\mathbf{A}, where \\mathbf{A} is the adjacency matrix and \\mathbf{D} is the degree matrix, a diagonal matrix with diagonal entries d_{jj}=\\sum_{i=1}^n a_{ij}.\n\nFollow the directions in Exercise 3 to obtain an adjacency matrix \\mathbf{A}. Then find the five eigenvalues of \\mathbf{L} having largest magnitude.\n\n⌨ See \n\nExercise 7.1.5 for instructions on loading a matrix \\mathbf{A} that contains information about the appearances of 392,400 actors in 127,823 movies, as given by the Internet Movie Database. Specifically, A_{ij}=1 if actor j appeared in movie i, and all other elements are zero.\n\n(a) What is the maximum number of actors appearing in any one movie?\n\n(b) How many actors appeared in exactly three movies?\n\n(c) Define \\mathbf{C}=\\mathbf{A}^T\\mathbf{A}. How many nonzero entries does \\mathbf{C} have? What is the interpretation of C_{ij}?\n\n⌨  A matrix that arises from the Helmholtz equation for wave propagation can be specified usingA = FNC.poisson(n) - k^2*I;\n\nwhere k is a real parameter. Let n=50.\n\n(a) Let k=1. What is the size of \\mathbf{A}? What is its density?\n\n(b) Still with k=1, use eigs to find the four largest and four smallest (in magnitude) eigenvalues of \\mathbf{A}. (See \n\nDemo 8.1.4 for examples.)\n\n(c) The eigenvalues are all real. Find a value of k so that \\mathbf{A} has exactly three negative eigenvalues.","type":"content","url":"/structure-1#exercises","position":9},{"hierarchy":{"lvl1":"Krylov subspaces"},"type":"lvl1","url":"/subspace","position":0},{"hierarchy":{"lvl1":"Krylov subspaces"},"content":"The power and inverse iterations have a flaw that seems obvious once it is pointed out. Given a seed vector \\mathbf{u}, they produce a sequence of vectors \\mathbf{u}_1,\\mathbf{u}_2,\\ldots that are scalar multiples of \\mathbf{u},\\mathbf{A}\\mathbf{u},\\mathbf{A}^{2}\\mathbf{u},\\ldots, but only the most recent vector is used to produce an eigenvector estimate.\n\nIt stands to reason that we could do no worse, and perhaps much better, if we searched among all linear combinations of the vectors seen in the past. In other words, we seek a solution in the range (column space) of the matrix\\mathbf{K}_m =\n\\begin{bmatrix}\n  \\mathbf{u} & \\mathbf{A}\\mathbf{u} & \\mathbf{A}^{2} \\mathbf{u} & \\cdots & \\mathbf{A}^{m-1} \\mathbf{u}\n\\end{bmatrix}.\n\nKrylov matrix and subspace\n\nGiven n\\times n matrix \\mathbf{A} and n-vector \\mathbf{u}, the mth Krylov matrix is the n\\times m matrix \n\n(8.4.1). The range (i.e., column space) of this matrix is the mth Krylov subspace \\mathcal{K}_m.\n\nIn general, we expect that the dimension of the Krylov subspace \\mathcal{K}_m, which is the rank of \\mathbf{K}_m, equals m, though it may be smaller.","type":"content","url":"/subspace","position":1},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Properties"},"type":"lvl2","url":"/subspace#properties","position":2},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Properties"},"content":"As we have seen with the power iteration, part of the appeal of the Krylov matrix is that it can be generated in a way that fully exploits the sparsity of \\mathbf{A}, simply through repeated matrix-vector multiplication. Furthermore, we have some important mathematical properties.\n\nSuppose \\mathbf{A} is n\\times n, 0<m<n, and a vector \\mathbf{u} is used to generate Krylov subspaces. If \\mathbf{x}\\in\\mathcal{K}_m, then the following hold:\n\n\\mathbf{x} = \\mathbf{K}_m \\mathbf{z} for some \\mathbf{z}\\in\\mathbb{C}^m.\n\n\\mathbf{x} \\in \\mathcal{K}_{m+1}.\n\n\\mathbf{A}\\mathbf{x} \\in \\mathcal{K}_{m+1}.\n\nIf \\mathbf{x}\\in\\mathcal{K}_m, then for some coefficients c_1,\\ldots,c_m,\\mathbf{x} = c_1 \\mathbf{u} + c_2 \\mathbf{A} \\mathbf{u} + \\cdots + c_m \\mathbf{A}^{m-1} \\mathbf{u}.\n\nThus let \\mathbf{z}= \\begin{bmatrix} c_1 & \\cdots & c_m \\end{bmatrix}^T. Also \\mathbf{x}\\in\\mathcal{K}_{m+1}, as we can add zero times \\mathbf{A}^{m}\\mathbf{u} to the sum. Finally,\\mathbf{A}\\mathbf{x} = c_1 \\mathbf{A} \\mathbf{u} + c_2 \\mathbf{A}^{2} \\mathbf{u} + \\cdots + c_m \\mathbf{A}^{m} \\mathbf{u} \\in \\mathcal{K}_{m+1}.","type":"content","url":"/subspace#properties","position":3},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Dimension reduction"},"type":"lvl2","url":"/subspace#dimension-reduction","position":4},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Dimension reduction"},"content":"The problems \\mathbf{A}\\mathbf{x}=\\mathbf{b} and \\mathbf{A}\\mathbf{x}=\\lambda\\mathbf{x} are statements about a very high-dimensional space \\mathbb{C}^n. One way to approximate them is to replace the full n-dimensional space with a much lower-dimensional \\mathcal{K}_m for m\\ll n. This is the essence of the Krylov subspace approach.\n\nFor instance, we can interpret \\mathbf{A}\\mathbf{x}_m\\approx \\mathbf{b} in the sense of linear least-squares—that is, using \n\nTheorem 8.4.1 to let \\mathbf{x}=\\mathbf{K}_m\\mathbf{z},\\min_{\\mathbf{x}\\in\\mathcal{K}_m} \\|  \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|\n= \\min_{\\mathbf{z}\\in\\mathbb{C}^m} \\| \\mathbf{A}(\\mathbf{K}_m\\mathbf{z})-\\mathbf{b} \\|\n= \\min_{\\mathbf{z}\\in\\mathbb{C}^m} \\| (\\mathbf{A}\\mathbf{K}_m)\\mathbf{z}-\\mathbf{b} \\|.\n\nThe natural seed vector for \\mathcal{K}_m in this case is the vector \\mathbf{b}. In the next example we try to implement \n\n(8.4.4). We do take one precaution: because the vectors \\mathbf{A}^{k}\\mathbf{b} may become very large or small in norm, we normalize after each multiplication by \\mathbf{A}, just as we did in the power iteration.\n\nConditioning of the Krylov matrix\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = [b zeros(100, 29)]\nfor m in 1:29\n    v = A * Km[:, m]\n    Km[:, m+1] = v / norm(v)\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nresid = zeros(30)\nfor m in 1:30\n    z = (A * Km[:, 1:m]) \\ b\n    x = Km[:, 1:m] * z\n    resid[m] = norm(b - A * x)\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nplot(0:29, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, L\"\\| b-Ax_m \\|\"),\n    title=\"Residual for linear systems\", leg=:none)\n\n\n\nConditioning of the Krylov matrix\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = [b zeros(100, 29)]\nfor m in 1:29\n    v = A * Km[:, m]\n    Km[:, m+1] = v / norm(v)\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nresid = zeros(30)\nfor m in 1:30\n    z = (A * Km[:, 1:m]) \\ b\n    x = Km[:, 1:m] * z\n    resid[m] = norm(b - A * x)\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nplot(0:29, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, L\"\\| b-Ax_m \\|\"),\n    title=\"Residual for linear systems\", leg=:none)","type":"content","url":"/subspace#dimension-reduction","position":5},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"The Arnoldi iteration"},"type":"lvl2","url":"/subspace#the-arnoldi-iteration","position":6},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"The Arnoldi iteration"},"content":"The breakdown of convergence in \n\nDemo 8.4.1 is due to a critical numerical defect in our approach: the columns of the Krylov matrix \n\n(8.4.1) increasingly become parallel to the dominant eigenvector, as \n\n(8.2.4) predicts, and therefore to one another. As we saw in \n\nThe QR factorization, near-parallel vectors create the potential for numerical cancellation. This manifests as a large condition number for \\mathbf{K}_m as m grows, eventually creating excessive error when solving the least-squares system.\n\nThe polar opposite of an ill-conditioned basis for \\mathcal{K}_m is an orthonormal one. Suppose we had a thin QR factorization of \\mathbf{K}_m:\\begin{align*}\n  \\mathbf{K}_m  = \\mathbf{Q}_m \\mathbf{R}_m\n  & =\n  \\begin{bmatrix}\n    \\mathbf{q}_1& \\mathbf{q}_2 & \\cdots & \\mathbf{q}_m\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    R_{11} & R_{12} & \\cdots & R_{1m} \\\\\n    0 & R_{22} & \\cdots & R_{2m} \\\\\n    \\vdots & & \\ddots & \\\\\n    0 & 0 & \\cdots & R_{mm}\n  \\end{bmatrix}.\n\\end{align*}\n\nThen the vectors \\mathbf{q}_1,\\ldots,\\mathbf{q}_m are the orthonormal basis we seek for \\mathcal{K}_m. By \n\nTheorem 8.4.1, we know that \\mathbf{A}\\mathbf{q}_m \\in \\mathcal{K}_{m+1}, and therefore\\mathbf{A} \\mathbf{q}_m = H_{1m} \\, \\mathbf{q}_1 + H_{2m} \\, \\mathbf{q}_2 + \\cdots + H_{m+1,m}\\,\\mathbf{q}_{m+1}\n\nfor some choice of the H_{ij}. Note that by using orthonormality, we have\\mathbf{q}_i^* (\\mathbf{A}\\mathbf{q}_m) = H_{im},\\qquad i=1,\\ldots,m.\n\nSince we started by assuming that we know \\mathbf{q}_1,\\ldots,\\mathbf{q}_m, the only unknowns in \n\n(8.4.6) are H_{m+1,m} and \\mathbf{q}_{m+1}. But they appear only as a product, and we know that \\mathbf{q}_{m+1} is a unit vector, so they are uniquely defined (up to sign) by the other terms in the equation.\n\nWe can now proceed iteratively.\n\nArnoldi iteration\n\nGiven matrix \\mathbf{A} and vector \\mathbf{u}:\n\nLet \\mathbf{q}_1= \\mathbf{u} \\,/\\, \\| \\mathbf{u}\\|.\n\nFor m=1,2,\\ldots\n\na. Use \n\n(8.4.7) to find H_{im} for i=1,\\ldots,m.\n\nb. Let\n\n:label: arnoldigs\n\\mathbf{v} = (\\mathbf{A} \\mathbf{q}m) - H{1m} ,\\mathbf{q}1 - H{2m}, \\mathbf{q}2 - \\cdots - H{mm}, \\mathbf{q}_m.\n:::c. Let $H_{m+1,m}=\\|\\mathbf{v}\\|$.\n\nd. Let $\\mathbf{q}_{m+1}=\\mathbf{v}\\,/\\,H_{m+1,m}$.\n\nThe Arnoldi iteration finds nested orthonormal bases for a family of nested Krylov subspaces.\n\nArnoldi iteration\n\nWe illustrate a few steps of the Arnoldi iteration for a small matrix.\n\nA = rand(1.0:9.0, 6, 6)\n\nThe seed vector we choose here determines the first member of the orthonormal basis.\n\nu = randn(6)\nQ = u / norm(u);\n\nMultiplication by \\mathbf{A} gives us a new vector in \\mathcal{K}_2.\n\nAq = A * Q[:, 1];\n\nWe subtract off its projection in the previous direction. The remainder is rescaled to give us the next orthonormal column.\n\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1]\nQ = [Q v / norm(v)];\n\nOn the next pass, we have to subtract off the projections in two previous directions.\n\nAq = A * Q[:, 2]\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1] - dot(Q[:, 2], Aq) * Q[:, 2]\nQ = [Q v / norm(v)];\n\nAt every step, \\mathbf{Q}_m is an ONC matrix.\n\n@show opnorm(Q' * Q - I);\n\nAnd \\mathbf{Q}_m spans the same space as the three-dimensional Krylov matrix.\n\nK = [u A * u A * A * u];\n@show rank([Q K]);\n\n\n\nArnoldi iteration\n\nWe illustrate a few steps of the Arnoldi iteration for a small matrix.\n\nA = rand(1.0:9.0, 6, 6)\n\nThe seed vector we choose here determines the first member of the orthonormal basis.\n\nu = randn(6)\nQ = u / norm(u);\n\nMultiplication by \\mathbf{A} gives us a new vector in \\mathcal{K}_2.\n\nAq = A * Q[:, 1];\n\nWe subtract off its projection in the previous direction. The remainder is rescaled to give us the next orthonormal column.\n\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1]\nQ = [Q v / norm(v)];\n\nOn the next pass, we have to subtract off the projections in two previous directions.\n\nAq = A * Q[:, 2]\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1] - dot(Q[:, 2], Aq) * Q[:, 2]\nQ = [Q v / norm(v)];\n\nAt every step, \\mathbf{Q}_m is an ONC matrix.\n\n@show opnorm(Q' * Q - I);\n\nAnd \\mathbf{Q}_m spans the same space as the three-dimensional Krylov matrix.\n\nK = [u A * u A * A * u];\n@show rank([Q K]);","type":"content","url":"/subspace#the-arnoldi-iteration","position":7},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Key identity"},"type":"lvl2","url":"/subspace#key-identity","position":8},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Key identity"},"content":"Up to now we have focused only on finding the orthonormal basis that lies in the columns of \\mathbf{Q}_m. But the H_{ij} values found during the iteration are also important. Taking j=1,2,\\ldots,m in \n\n(8.4.6) leads to\\begin{split}\n  \\mathbf{A}\\mathbf{Q}_m &= \\begin{bmatrix}\n    \\mathbf{A}\\mathbf{q}_1 & \\cdots \\mathbf{A}\\mathbf{q}_m\n  \\end{bmatrix}\\\\\n  & = \\begin{bmatrix}\n    \\mathbf{q}_1 & \\mathbf{q}_2 & \\cdots & \\mathbf{q}_{m+1}\n  \\end{bmatrix}\\:  \\begin{bmatrix}\n    H_{11} & H_{12} & \\cdots & H_{1m} \\\\\n    H_{21} & H_{22} & \\cdots & H_{2m} \\\\\n    & H_{32} & \\ddots & \\vdots \\\\\n    & & \\ddots & H_{mm} \\\\\n    & & & H_{m+1,m}\n\\end{bmatrix} = \\mathbf{Q}_{m+1} \\mathbf{H}_m,\n\\end{split}\n\nwhere the matrix \\mathbf{H}_m has a particular “triangular plus one” structure.\n\nUpper Hessenberg matrix\n\nA matrix \\mathbf{H} is upper Hessenberg if H_{ij}=0 whenever i>j+1.\n\nEquation \n\n(8.4.8) is a fundamental identity of Krylov subspace methods.","type":"content","url":"/subspace#key-identity","position":9},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Implementation"},"type":"lvl2","url":"/subspace#implementation","position":10},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Implementation"},"content":"arnoldi\n\nArnoldi iteration\n\n\"\"\"\n    poweriter(A,numiter)\n\nPerform `numiter` power iterations with the matrix `A`, starting\nfrom a random vector. Returns a vector of eigenvalue estimates\nand the final eigenvector approximation.\n\"\"\"\nfunction poweriter(A,numiter)\n    n = size(A,1)\n    x = normalize(randn(n),Inf)\n    β = zeros(numiter)\n    for k in 1:numiter\n        y = A*x\n        m = argmax(abs.(y))\n        β[k] = y[m]/x[m]\n        x = y/y[m]\n    end\n    return β,x\nend\n\nAbout the code\n\nThe loop starting at line 17 does not exactly implement \n\n(8.4.7) and . The reason is numerical stability. Though the described and implemented versions are mathematically equivalent in exact arithmetic (see \n\nExercise 6), the approach in \n\nFunction 8.4.2 is more stable.\n\n\n\nArnoldi iteration\n\ndef arnoldi(A, u, m):\n    \"\"\"\n    arnoldi(A,u,m)\n\n    Perform the Arnoldi iteration for `A` starting with vector `u`, out to the Krylov\n    subspace of degree `m`. Return the orthonormal basis (`m`+1 columns) and the upper\n    Hessenberg `H` of size `m`+1 by `m`.\n    \"\"\"\n    n = u.size\n    Q = np.zeros([n, m + 1])\n    H = np.zeros([m + 1, m])\n    Q[:, 0] = u / np.linalg.norm(u)\n    for j in range(m):\n        # Find the new direction that extends the Krylov subspace.\n        v = A @ Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        # Normalize and store the new basis vector.\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n    return Q, H\n\nAbout the code\n\nThe loop starting at line 17 does not exactly implement \n\n(8.4.7) and . The reason is numerical stability. Though the described and implemented versions are mathematically equivalent in exact arithmetic (see \n\nExercise 6), the approach in \n\nFunction 8.4.2 is more stable.\n\nAn implementation of the Arnoldi iteration is given in \n\nFunction 8.4.2. A careful inspection shows that the loop starting at line 17 does not exactly implement \n\n(8.4.7) and . The reason is numerical stability. Though the described and implemented versions are mathematically equivalent in exact arithmetic (see \n\nExercise 6), the approach in \n\nFunction 8.4.2 is more stable.\n\nIn the next section we revisit the idea of approximately solving \\mathbf{A}\\mathbf{x}=\\mathbf{b} over a Krylov subspace \\mathcal{K}_m, using the ONC matrix \\mathbf{Q}_m in place of \\mathbf{K}_m. A related idea explored in \n\nExercise 7 is used to approximate the eigenvalue problem for \\mathbf{A}, which is the approach that underlies eigs for sparse matrices.","type":"content","url":"/subspace#implementation","position":11},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Exercises"},"type":"lvl2","url":"/subspace#exercises","position":12},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Exercises"},"content":"✍ Let \\mathbf{A}=\\displaystyle \\begin{bmatrix}\n 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0\n \\end{bmatrix}.\n\n(a) Find the Krylov matrix \\mathbf{K}_3 for the seed vector \\mathbf{u}=\\mathbf{e}_1.\n\n(b) Find \\mathbf{K}_3 for the seed vector \\mathbf{u}=\\begin{bmatrix}1; \\: 1;\\: 1; \\: 1\\end{bmatrix}.\n\n⌨ For each matrix, make a table of the 2-norm condition numbers \\kappa(\\mathbf{K}_m) for m=1,\\ldots,10. Use a vector of all ones as the Krylov seed.\n\n(a) Matrix from \n\nDemo 8.4.1\n\n(b) \\begin{bmatrix}\n   -2 & 1 & & &  \\\\\n   1 & -2 & 1 & &  \\\\\n   & \\ddots & \\ddots & \\ddots & \\\\\n   & & 1 & -2 & 1 \\\\\n    & & & 1 & -2\n  \\end{bmatrix} \\: (100\\times 100)\n\n(c) \\begin{bmatrix}\n   -2 & 1 & & & 1 \\\\\n   1 & -2 & 1 & &  \\\\\n   & \\ddots & \\ddots & \\ddots & \\\\\n   & & 1 & -2 & 1 \\\\\n   1 & & & 1 & -2\n \\end{bmatrix} \\:(200\\times 200) must stay as #3\n\n✍ Show that if \\mathbf{x}\\in\\mathcal{K}_m, then \\mathbf{x}=p(\\mathbf{A})\\mathbf{u} for a polynomial p of degree at most m-1. (See \n\n(7.2.11) for applying a polynomial to a matrix.)\n\n✍ Compute the asymptotic flop requirements for \n\nFunction 8.4.2. Assume that due to sparsity, a matrix-vector multiplication \\mathbf{A}\\mathbf{u} requires only c n flops for a constant c, rather than the usual O(n^2).\n\n⌨ When Arnoldi iteration is performed on the Krylov subspace generated using the matrix \\mathbf{A}=\\displaystyle \\begin{bmatrix}  2& 1& 1& 0\\\\ 1 &3 &1& 0\\\\ 0& 1& 3& 1\\\\ 0& 1& 1& 2 \\end{bmatrix}, the results can depend strongly on the initial vector \\mathbf{u}.\n\n(a) Apply \n\nFunction 8.4.2 and output Q and H when using the following seed vectors.\n\n(i) u=[1,0,0,0] \\qquad (ii) u=[1,1,1,1] \\qquad (iii) u=rand(4)\n\n(b) Can you explain why case (ii) in part (a) cannot finish successfully? (Hint: What line(s) of the function can possibly return NaN when applied to finite values?)must stay as #6\n\n✍ As mentioned in the text, \n\nFunction 8.4.2 does not compute H_{ij} as defined by \n\n(8.4.7), but ratherS_{ij} = \\mathbf{q}_i^* ( \\mathbf{A}\\mathbf{q}_j - S_{1j}\\,\\mathbf{q}_1 - \\cdots -\n    S_{i-1,j}\\,\\mathbf{q}_{i-1} )\n\nfor i=1,\\ldots,j. Show that S_{ij}=H_{ij}. (Hence the function is mathematically equivalent to our Arnoldi formulas.)must stay as #7\n\nOne way to approximate the eigenvalue problem \\mathbf{A}\\mathbf{x}=\\lambda\\mathbf{x} over \\mathcal{K}_m is to restrict \\mathbf{x} to the low-dimensional spaces \\mathcal{K}_m.\n\n(a) ✍ Show starting from \n\n(8.4.8) that\\mathbf{Q}_m^* \\mathbf{A} \\mathbf{Q}_m =  \\tilde{\\mathbf{H}}_m,\n\nwhere \\tilde{\\mathbf{H}}_m is the upper Hessenberg matrix resulting from deleting the last row of \\mathbf{H}_m. What is the size of this matrix?\n\n(b) ✍ Show the reasoning above leads to the approximate eigenvalue problem \\tilde{\\mathbf{H}}_m\\mathbf{z} \\approx \\lambda\\mathbf{z}. (Hint: Start with \\mathbf{A}\\mathbf{x} \\approx \\lambda\\mathbf{x}, and let \\mathbf{x}=\\mathbf{Q}_m\\mathbf{z} before applying part (a).)\n\n(c) ⌨ Apply \n\nFunction 8.4.2 to the matrix of \n\nDemo 8.4.1 using a random seed vector. Compute eigenvalues of \\tilde{\\mathbf{H}}_m for m=1,\\ldots,40, keeping track in each case of the error between the largest of those values (in magnitude) and the largest eigenvalue of \\mathbf{A}. Make a log-linear graph of the error as a function of m.\n\nThe proper pronunciation of “Krylov” is something like “kree-luv,” but American English speakers often say “kreye-lahv.”","type":"content","url":"/subspace#exercises","position":13},{"hierarchy":{"lvl1":"Index"},"type":"lvl1","url":"/genindex","position":0},{"hierarchy":{"lvl1":"Index"},"content":"A\n\nAdams--Bashforth formula: Paragraph\n\nAdams--Moulton formula: Paragraph\n\nArnoldi iteration: Algorithm 8.4.1, \n\nParagraph, \n\nArnoldi iteration\n\naccuracy (relative vs. absolute): Paragraph\n\nadaptivity:\n\nin IVP solver:  \n\nParagraph, \n\nSection 6.7.4\n\nin integration:  \n\nSection 5.7.2adjacency matrix: Definition 7.1.1, \n\nParagraph, \n\nadjacency matrix\n\nadjoint: \n\nadjoint\n\nadjoint of a matrix: Paragraph, \n\nParagraph\n\nadvection equation: \n\nadvection equation\n\nalgorithm: Paragraph, \n\nalgorithm\n\nargmin: Definition 3.1.1\n\nasymptotic: \n\nasymptotic\n\nasymptotic notation: Section 2.5.1\n\n\n\nB\n\nBauer–Fike theorem: Paragraph\n\nBroyden update: Paragraph\n\nbackward difference: Paragraph\n\nbackward differentiation formula for IVPs: Paragraph\n\nbackward error: Definition 1.4.1, \n\nObservation 4.1.1, \n\nParagraph, \n\nbackward error\n\nin a linear system:  \n\nParagraphbackward substitution: \n\nParagraph, \n\nbackward substitution\n\nbanded matrix: \n\nParagraph\n\nbandwidth: \n\nbandwidth\n\nbandwidth of a matrix: Definition 2.9.1\n\nbarycentric formula: \n\nbarycentric formula\n\nbig-O: \n\nbig-O\n\nboundary-value problem: \n\nboundary-value problem\n\n\n\nC\n\nCholesky factorization: \n\nCholesky factorization\n\ncardinal function: Definition 5.1.2, \n\nParagraph, \n\ncardinal function\n\ncentered difference: Paragraph\n\ncharacteristic polynomial: Paragraph\n\ncollocation: \n\ncollocation\n\ncondition number: \n\ncondition number\n\nof a matrix:  \n\nParagraph, \n\nDefinition 3.2.3, \n\nParagraph, \n\nNotebook-code, \n\nNotebook-code, \n\nNotebook-code\n\nof a scalar function:  Definition 1.2.1\n\nof eigenvalues:  \n\nParagraph\n\nof elementary functions:  \n\nParagraph\n\nof initial-value problems:  \n\nParagraph\n\nof interpolation:  \n\nTheorem 5.1.1, \n\nTheorem 5.2.1\n\nof linear least squares:  \n\nDefinition 3.2.3\n\nof linear system:  \n\nParagraph\n\nof normal equations:  \n\nParagraph\n\nof rootfinding:  \n\nTheorem 4.1.1conjugate gradients: Definition 8.6.1\n\ncontraction mapping: Paragraph\n\nconvergence rate:\n\nalgebraic:  Definition 5.2.2\n\nlinear:  Definition 4.2.2, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nquadratic:  Definition 4.3.1, \n\nParagraph\n\nsuperlinear:  Paragraphcubic spline: Definition 5.3.1, \n\ncubic spline\n\n\n\nD\n\nDahlquist theorems: \n\nSection 6.8.2\n\nDirichlet condition: \n\nDirichlet condition\n\ndata fitting: \n\nParagraph\n\nby straight line:  \n\nParagraph\n\nnonlinear:  \n\nParagraph\n\npower law:  \n\nParagraphdiagonal matrix: Paragraph, \n\nDefinition 7.2.3, \n\nDefinition 7.3.1\n\ndiagonalizable: \n\ndiagonalizable\n\ndiagonalizable matrix: Definition 7.2.3\n\ndifferentiation matrix: \n\ndifferentiation matrix\n\ndimension reduction: \n\nParagraph, \n\nParagraph\n\ndivide and conquer: \n\nSection 5.7.2\n\ndominant eigenvalue: \n\ndominant eigenvalue\n\ndouble precision: \n\ndouble precision\n\n\n\nE\n\nEuler's method: Paragraph, \n\nParagraph\n\nEuler–Maclaurin formula: Paragraph\n\nEuler’s method: \n\nEuler’s method\n\neigenvalue: Definition 7.2.1, \n\nComment, \n\neigenvalue\n\nconditioning of:  Paragraph\n\ndominant:  Paragraph, \n\nParagrapheigenvalue decomposition: Definition 7.2.3, \n\nParagraph\n\neigenvalue decomposition (EVD): \n\neigenvalue decomposition (EVD)\n\neigenvector: Definition 7.2.1, \n\neigenvector\n\nevolutionary PDE: \n\nevolutionary PDE\n\nextrapolation: Paragraph, \n\nextrapolation\n\n\n\nF\n\nFrancis QR iteration: Paragraph\n\nFrobenius norm: \n\nFrobenius norm\n\nfill-in of sparse matrices: \n\nParagraph\n\nfinite difference: \n\nfinite difference\n\nfinite differences: Definition 5.4.1, \n\nParagraph, \n\nParagraph\n\nfinite element method (FEM): \n\nfinite element method (FEM)\n\nfixed point iteration: \n\nfixed point iteration\n\nfixed point problem: \n\nfixed point problem\n\nfixed-point iteration: Algorithm 4.2.1\n\nfixed-point problem: Definition 4.2.1\n\nfloating-point numbers: Definition 1.1.1, \n\nParagraph, \n\nfloating-point numbers\n\nflops: \n\nParagraph, \n\nflops\n\nforward difference: Paragraph\n\nforward substitution: \n\nParagraph, \n\nforward substitution\n\n\n\nG\n\nGMRES: Algorithm 8.5.1, \n\nGMRES\n\npreconditioning in:  \n\nDefinition 8.8.1\n\nrelationship to MINRES:  \n\nParagraph\n\nrestarting:  ParagraphGaussian elimination: \n\nParagraph, \n\nGaussian elimination\n\nGauss–Newton method: Algorithm 4.7.1, \n\nGauss–Newton method\n\nGregory integration formula: MystDirectiveError\n\ngenerating polynomials: Paragraph, \n\ngenerating polynomials\n\nglobal error: Definition 6.2.3, \n\nglobal error\n\ngraph: Definition 7.1.1, \n\ngraph\n\n\n\nH\n\nHan Solo: \n\nHan Solo, The Empire Strikes Back\n\nHorner's algorithm: Example 1.3.1\n\nHouseholder reflector: Paragraph\n\nhat functions: \n\nParagraph, \n\nhat functions\n\nheat equation: \n\nheat equation\n\nhermitian: \n\nhermitian\n\nhermitian matrix: Paragraph, \n\nParagraph, \n\nTheorem 7.3.2\n\nhermitian positive definite (HPD): \n\nhermitian positive definite (HPD)\n\nhermitian positive definite matrix: See \n\nsymmetric positive definite matrix\n\n\n\nI\n\nIEEE 754: \n\nParagraph\n\nidentity matrix: Paragraph, \n\nParagraph, \n\nidentity matrix\n\nill-conditioned: \n\nill-conditioned\n\nimage (as a matrix): \n\nParagraph, \n\nExample 7.5.1, \n\nParagraph\n\nimplicit: \n\nimplicit\n\nimplicit IVP solver: Definition 6.6.1, \n\nParagraph\n\ninduced matrix norm: \n\ninduced matrix norm\n\ninitial-value problem: Definition 6.1.1\n\none-step method for:  Definition 6.2.1initial-value problem (IVP): \n\ninitial-value problem (IVP)\n\ninner product: \n\nParagraph, \n\ninner product\n\nof vectors:  Paragraphinterpolation: Definition 5.1.1, \n\nParagraph, \n\ninterpolation\n\nby piecewise polynomials:  \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nby polynomials:  \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraphinverse iteration: Algorithm 8.3.1, \n\ninverse iteration\n\ninvertible matrix: Paragraph\n\n\n\nJ\n\nJacobian matrix: Paragraph, \n\nParagraph, \n\nJacobian matrix\n\nJulia:\n\n+=:  Paragraph\n\n.+:  Grid\n\n.-:  Grid\n\n::  Paragraph, \n\nParagraph\n\n@.:  Grid\n\n@sprintf:  Grid, Grid\n\nBoolean indexing:  \n\nGrid\n\nDiagonalPreconditioner:  Paragraph, Paragraph\n\nFNC:  Grid\n\nI:  Grid\n\nImages:  Paragraph, Paragraph, Paragraph\n\nLinearMap:  Paragraph, Paragraph\n\nNaN:  \n\nParagraph\n\nODEProblem:  Notebook-code, Notebook-code\n\nPair:  Grid\n\nRational:  Paragraph\n\nSpline1D:  Paragraph, Paragraph\n\n\\!:  Grid\n\n\\':  Paragraph, \n\nParagraph\n\n\\\\:  Grid, \n\nTabSet, \n\nParagraph, \n\nGrid, \n\nParagraph\n\nadjoint:  Paragraph, \n\nParagraph\n\nannotate!:  Notebook-code, Notebook-code, Notebook-code\n\nanonymous functions:  Paragraph\n\nbreak:  Algorithm 4.3.2\n\nbroadcasting:  Grid, \n\nGrid, \n\nGrid, \n\nParagraph\n\ncg:  Paragraph, Paragraph\n\ncholesky:  Grid\n\ncomprehension:  Grid\n\ncond:  Grid, \n\nParagraph\n\ndestructuring:  Grid\n\ndiag:  Grid, Grid\n\ndiagm:  Grid, \n\nGrid, \n\nGrid\n\neigen:  Paragraph\n\neigs:  Paragraph\n\neigvals:  Paragraph\n\neltype:  Paragraph\n\nend:  Grid\n\nenumerate:  Grid, Grid\n\nfill:  Grid\n\nfit:  Paragraph, Paragraph, Paragraph\n\nfor:  Grid\n\nfunctions:  Paragraph\n\ngmres:  Grid, Grid\n\ngraphplot:  Paragraph\n\nilu:  Paragraph, Paragraph\n\nindexing arrays:  Grid, \n\nAttention\n\nkeyword function arguments:  Algorithm 4.3.2, \n\nAlgorithm 5.7.1, \n\nNotebook-code, \n\nNotebook-code\n\nlength:  Grid\n\nmaximum:  Grid\n\nminimum:  Grid\n\nminres:  Notebook-code, Notebook-code\n\nnamespace:  Grid\n\nnlsolve:  Paragraph\n\nnnz:  Grid\n\nnorm:  Paragraph\n\nnormalize:  Paragraph, \n\nGrid\n\nopnorm:  Paragraph\n\nplotting functions:  \n\nGrid\n\npush!:  \n\nNotebook-code, \n\nNotebook-code\n\npush\\!:  Grid\n\nquadgk:  Paragraph, Paragraph\n\nrange:  Paragraph, \n\nGrid\n\nreturn:  Paragraph\n\nscatter:  Grid\n\nscientific notation:  Grid\n\nsize:  Grid\n\nsolve:  Notebook-code, Notebook-code\n\nsortby:  Paragraph\n\nsortperm:  Grid\n\nsparse:  Grid\n\nspdiagm:  Paragraph, Paragraph\n\nsplatting:  Grid\n\nstring interpolation:  Grid\n\nsubplots:  Paragraph\n\nsum:  Grid, \n\nAbout the code\n\nsummarysize:  Paragraph\n\nsvd:  Paragraph\n\nsvdvals:  Paragraph\n\ntranspose:  Paragraph\n\ntril:  Grid, \n\nParagraph\n\ntriu:  Grid, \n\nParagraph\n\nusing:  Grid\n\nK\n\nKronecker product: \n\nKronecker product\n\nKrylov matrix: Definition 8.4.1\n\nKrylov subspace: Definition 8.4.1, \n\nKrylov subspace\n\n\n\nL\n\nLU factorization: Definition 2.4.1, \n\nParagraph, \n\nParagraph, \n\nLU factorization\n\nincomplete:  ParagraphLagrange formula: \n\nLagrange formula\n\nLanczos iteration: Paragraph, \n\nLanczos iteration\n\nLaplace equation: \n\nLaplace equation\n\nLevenberg's method: Algorithm 4.6.2\n\nLipschitz condition: Definition 4.2.3\n\nLuke Skywalker: \n\nLuke Skywalker, Return of the Jedi\n\nlinear combination: Paragraph\n\nlinear convergence: Definition 4.2.2, \n\nlinear convergence\n\nlinear least-squares problem: \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nlinear least-squares problem\n\nlocal truncation error: \n\nlocal truncation error\n\nlogistic equation: Paragraph\n\n\n\nM\n\nMATLAB:\n\n::  Paragraph, \n\nParagraph\n\nBoolean indexing:  \n\nGrid\n\nNaN:  \n\nParagraph\n\n\\':  Paragraph, \n\nParagraph\n\n\\\\:  Grid, Grid\n\n\\~:  Grid\n\nadjoint:  Paragraph, \n\nParagraph\n\nanonymous functions:  Paragraph\n\nbroadcasting:  \n\nParagraph\n\nchol:  Grid\n\ncond:  Paragraph\n\ndiag:  Grid, Grid, Paragraph, Grid\n\ndiagm:  \n\nParagraph\n\neig:  Paragraph\n\nend:  Grid\n\neye:  Grid, Paragraph\n\nfill:  Paragraph\n\nfplot:  Notebook-code\n\nfunctions:  Paragraph\n\ngraph (network):  Paragraph\n\nhold on:  Grid\n\nindexing arrays:  Grid\n\nintegral:  Paragraph\n\nlength:  Grid\n\nlinspace:  Grid, Paragraph\n\nmax:  Grid, Grid\n\nnorm:  Notebook-code, Paragraph\n\node:  Notebook-code\n\nones:  Paragraph\n\nplot:  Grid\n\npolyval:  \n\nNotebook-code\n\nscatter:  Grid\n\nscientific notation:  Grid\n\nsize:  Grid\n\nsolve:  Notebook-code\n\nsubplot:  Notebook-code\n\nsum:  Grid\n\nsvd:  Notebook-code\n\ntic and toc:  Paragraph\n\ntranspose:  Paragraph\n\ntril:  Grid, \n\nParagraph\n\ntriu:  Grid, \n\nParagraph\n\nvander:  Paragraph\n\nzeros:  ParagraphMINRES: Paragraph\n\nmachine epsilon: Definition 1.1.2, \n\nParagraph, \n\nParagraph, \n\nmachine epsilon\n\nin double precision:  \n\nParagraphmantissa: See \n\nsignificand\n\nmatrix condition number: \n\nmatrix condition number\n\nmatrix factorization: \n\nTheorem 7.3.2\n\nCholesky:  Theorem 2.9.2\n\nEVD:  Definition 7.2.3\n\nLU:  Definition 2.4.1, \n\nParagraph\n\nQR:  Paragraph, \n\nParagraph\n\nSVD:  Definition 7.3.1\n\npivoted LU:  Definition 2.6.1matrix inverse: Paragraph, \n\nParagraph\n\nmatrix multiplication: Paragraph\n\nmethod of lines: \n\nmethod of lines\n\nmultistep: \n\nmultistep\n\nmultistep method: Definition 6.6.1, \n\nParagraph\n\nimplementation of:  \n\nParagraph\n\nN\n\nNaN: \n\nParagraph\n\nNeumann condition: \n\nNeumann condition\n\nNewton's method: Algorithm 4.3.1, \n\nParagraph\n\nmultidimensional:  Algorithm 4.5.1Newton’s method: \n\nNewton’s method\n\nnodes: \n\nnodes\n\nnonlinear least squares: Definition 4.7.1\n\nnonlinear least-squares problem: \n\nnonlinear least-squares problem\n\nnorm: \n\nnorm\n\nFrobenius:  Paragraph\n\nmatrix:  Definition 2.7.2, \n\nTheorem 7.3.3\n\nvector:  Paragraph, \n\nParagraphnormal: \n\nnormal\n\nnormal equations: Theorem 3.2.1, \n\nTheorem 3.2.2, \n\nParagraph, \n\nnormal equations\n\nnormal matrix: Definition 7.2.5\n\nnumerical integration: Paragraph, \n\nParagraph, \n\nnumerical integration\n\n\n\nO\n\nONC matrix: Paragraph, \n\nParagraph, \n\nONC matrix\n\none-step IVP method: \n\none-step IVP method\n\norder of accuracy: \n\norder of accuracy\n\nof a finite-difference formula:  Definition 5.5.2\n\nof a one-step IVP method:  Paragraph\n\nof an approximation:  Definition 5.2.2\n\nof numerical integration:  Definition 5.6.3orthogonal matrix: Paragraph, \n\nParagraph, \n\nParagraph, \n\nDefinition 7.2.2, \n\northogonal matrix\n\northogonal polynomials: \n\northogonal polynomials\n\northogonal vectors: Paragraph, \n\northogonal vectors\n\northonormal vectors: Paragraph, \n\northonormal vectors\n\nouter product: Paragraph, \n\nParagraph, \n\nParagraph, \n\nouter product\n\noverdetermined: \n\noverdetermined\n\n\n\nP\n\nPLU factorization: Definition 2.6.1, \n\nPLU factorization\n\nPython:\n\n::  Paragraph\n\nNaN:  \n\nParagraph\n\nadjoint:  Paragraph\n\narange:  Paragraph\n\nargsort:  Grid\n\nbroadcast:  Paragraph\n\nbroadcasting:  \n\nParagraph, \n\nParagraph\n\ncholesky:  Notebook-code\n\ncond:  Paragraph, \n\nNotebook-code, \n\nParagraph\n\ndestructuring:  Grid\n\ndiag:  Paragraph, Paragraph\n\ndiags:  Notebook-code\n\neig:  Paragraph\n\neigs:  Paragraph\n\nelementwise multiplication:  Paragraph\n\nenumerate:  Notebook-code\n\nhstack:  Paragraph\n\nindexing arrays:  Paragraph\n\nlength:  \n\nExample 1.3.2\n\nlinspace:  Paragraph\n\nlstsq:  Notebook-code\n\nmatrix_power:  Notebook-code\n\nmax:  Paragraph\n\nnetworkx:  Notebook-code\n\nnnz:  Notebook-code\n\nnorm:  Paragraph, Paragraph\n\nplotting functions:  \n\nParagraph\n\nreturn:  Paragraph\n\nscientific notation:  Grid\n\nslice:  Paragraph\n\nsplu:  Notebook-code\n\nsum:  \n\nParagraph\n\nsvd:  Paragraph\n\ntranspose:  Paragraph\n\ntril:  Paragraph, \n\nParagraph\n\ntriu:  Paragraph, \n\nParagraph, \n\nNotebook-code\n\nvstack:  Paragraphpiecewise linear: \n\npiecewise linear\n\npiecewise linear interpolant: Paragraph\n\npivoting: Paragraph, \n\nParagraph, \n\nTheorem 2.9.2\n\npower iteration: Algorithm 8.2.1, \n\npower iteration\n\npreconditioning: Definition 8.8.1, \n\npreconditioning\n\npredator–prey model: \n\nParagraph\n\npseudoinverse: Paragraph, \n\npseudoinverse\n\n\n\nQ\n\nQR factorization: \n\nQR factorization\n\nquadratic convergence: Definition 4.3.1, \n\nquadratic convergence\n\nquadrature: See \n\nnumerical integration\n\nquasi-Newton methods: \n\nquasi-Newton methods\n\nquasimatrix: \n\nquasimatrix\n\n\n\nR\n\nRayleigh quotient: Paragraph, \n\nRayleigh quotient\n\nReturn of the Jedi: \n\nLuke Skywalker, Return of the Jedi\n\nRunge phenomenon: \n\nRunge phenomenon\n\nRunge--Kutta: \n\nRunge--Kutta\n\nRunge–Kutta method: Paragraph, \n\nParagraph, \n\nParagraph\n\nreduced QR factorization: \n\nreduced QR factorization\n\nreduced SVD: \n\nreduced SVD\n\nresidual: \n\nParagraph, \n\nresidual, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nof a linear system:  Definition 2.8.2\n\nof rootfinding:  Paragraphrestarting: \n\nrestarting\n\nrootfinding problem: Definition 4.1.1, \n\nParagraph, \n\nrootfinding problem\n\nmultidimensional:  Definition 4.5.1roots:\n\nmultiplicity of:  Paragraph, \n\nParagraphrow pivoting: \n\nrow pivoting\n\n\n\nS\n\nSPD matrix: See \n\nsymmetric positive definite matrix\n\nSVD: See \n\nsingular value decomposition\n\nSimpson's formula: Paragraph, \n\nParagraph\n\nsecant method: Algorithm 4.4.1, \n\nsecant method\n\nshifted inverse iteration: See \n\ninverse iteration\n\nshooting: \n\nshooting\n\nsignificand: Paragraph\n\nsignificant digits: \n\nParagraph\n\nsimilarity transformation: Paragraph\n\nsimple root: \n\nsimple root\n\nsingular matrix: Paragraph\n\nsingular value decomposition: Definition 7.3.1, \n\nParagraph\n\nthin form:  Paragraphsingular value decomposition (SVD): \n\nsingular value decomposition (SVD)\n\nsparse: \n\nsparse\n\nsparse matrix: Paragraph, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nspectral convergence: \n\nspectral convergence\n\nspline (cubic spline): Definition 5.3.1\n\nstability: Paragraph, \n\nParagraph\n\nof multistep methods:  \n\nDefinition 6.8.1stability region: \n\nstability region\n\nsteepest descent: \n\nParagraph\n\nstep size: \n\nstep size\n\nstiff: \n\nstiff\n\nstiff differential equation: \n\nParagraph, \n\nExample 6.7.2\n\nsubtractive cancellation: Paragraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nsubtractive cancellation\n\nsuperlinear convergence: Paragraph, \n\nsuperlinear convergence\n\nsymmetric matrix: Paragraph, \n\nDefinition 2.9.2, \n\nParagraph, \n\nParagraph, \n\nsymmetric matrix\n\nsymmetric positive definite (SPD) matrix: \n\nsymmetric positive definite (SPD) matrix\n\nsymmetric positive definite matrix: Definition 2.9.3, \n\nParagraph, \n\nDefinition 8.6.1\n\n\n\nT\n\nThe Empire Strikes Back: \n\nYoda, The Empire Strikes Back, \n\nHan Solo, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back\n\ntensor-product domain: \n\ntensor-product domain\n\nthin QR factorization: \n\nthin QR factorization\n\nthin SVD: \n\nthin SVD\n\ntranspose: Paragraph, \n\nParagraph\n\ntrapezoid formula: \n\ntrapezoid formula\n\nfor an IVP:  Table 6.6.1, \n\nParagraph\n\nfor integration:  Definition 5.6.2triangular matrix: Paragraph, \n\nParagraph, \n\ntriangular matrix\n\ntridiagonal matrix: Definition 2.9.1, \n\ntridiagonal matrix\n\ntrigonometric interpolation: \n\ntrigonometric interpolation\n\ntruncation error: \n\ntruncation error\n\nof a finite-difference formula:  Definition 5.5.1\n\nof a multistep IVP formula:  Paragraph\n\nof a numerical integration formula:  Definition 5.6.3\n\nof a one-step IVP solver:  Paragraph\n\nU\n\nunit lower triangular matrix: Paragraph\n\nunit roundoff: \n\nDefinition 1.1.2\n\nunit triangular matrix: \n\nunit triangular matrix\n\nunit vector: Paragraph, \n\nunit vector\n\nunitary: \n\nunitary\n\nunitary matrix: Definition 7.2.2, \n\nDefinition 7.2.5, \n\nDefinition 7.3.1, \n\nTheorem 7.4.2\n\nunstable: \n\nunstable\n\nupper Hessenberg: \n\nupper Hessenberg\n\nupper Hessenberg matrix: Definition 8.4.2\n\n\n\nV\n\nVandermonde matrix: Paragraph, \n\nParagraph, \n\nVandermonde matrix\n\n\n\nW\n\nweights: \n\nweights\n\n\n\nY\n\nYoda: \n\nYoda, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back\n\n\n\nZ\n\nzero-stability: Definition 6.8.1\n\nzero-stable: \n\nzero-stable\n\n","type":"content","url":"/genindex","position":1},{"hierarchy":{"lvl1":"Home"},"type":"lvl1","url":"/home","position":0},{"hierarchy":{"lvl1":"Home"},"content":"\n\nThis is a new edition of the textbook \n\nFundamentals of Numerical Computation by Tobin A. Driscoll and Richard J. Braun. A hardcopy is \n\navailable for purchase at the SIAM Bookstore. This material is copyright © Society of Applied and Industrial Mathematics, 2022.\n\nThe book was originally written for MATLAB. That version is still \n\navailable for purchase at the SIAM Bookstore. This new edition is largely the same, but you should not expect exercise numbers to align perfectly in both editions.","type":"content","url":"/home","position":1},{"hierarchy":{"lvl1":"Home","lvl2":"Usage tips"},"type":"lvl2","url":"/home#usage-tips","position":2},{"hierarchy":{"lvl1":"Home","lvl2":"Usage tips"},"content":"\n\nUsing this book. needed to make Mathjax work for some reason \\relax","type":"content","url":"/home#usage-tips","position":3},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1","position":0},{"hierarchy":{"lvl1":"Chapter 1"},"content":"import Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter1","position":1},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1#chapter-1","position":2},{"hierarchy":{"lvl1":"Chapter 1"},"content":"","type":"content","url":"/chapter1#chapter-1","position":3},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"type":"lvl2","url":"/chapter1#functions","position":4},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"content":"Horner’s algorithm for evaluating a polynomial\"\"\"\n    horner(c,x)\n\nEvaluate a polynomial whose coefficients are given in ascending\norder in `c`, at the point `x`, using Horner's rule.\n\"\"\"\nfunction horner(c,x)\n    n = length(c)\n    y = c[n]\n    for k in n-1:-1:1\n        y = x*y + c[k]\n    end\n    return y\nend","type":"content","url":"/chapter1#functions","position":5},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"type":"lvl2","url":"/chapter1#examples","position":6},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"content":"","type":"content","url":"/chapter1#examples","position":7},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#section-1-1","position":8},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.1","lvl2":"Examples"},"content":"Absolute and relative accuracy\n\nRecall the grade-school approximation to the number π.\n\n@show p = 22/7;\n\nNot all the digits displayed for p are the same as those of π.\n\nThe value of pi is predefined and equivalent to π, which is entered by typing \\pi followed immediately by the Tab key.\n\n@show float(π);\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nA dollar sign $ in a string substitutes (or interpolates) the named variable or expression into the string.\n\nacc = abs(p-π)\nprintln(\"absolute accuracy = $acc\")\nprintln(\"relative accuracy = $(acc/π)\")\n\nHere we calculate the number of accurate digits in p.\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprintln(\"Number of accurate digits = $(-log10(acc/π))\")\n\nThis last value could be rounded down by using floor.\n\nFloating-point representation\n\nIn Julia, 1 and 1.0 are different values, because they have different types:\n\n@show typeof(1);\n@show typeof(1.0);\n\nThe standard choice for floating-point values is Float64, which is double precision using 64 binary bits. We can see all the bits by using bitstring.\n\nbitstring(1.0)\n\nThe first bit determines the sign of the number::::{card}\n\nSquare brackets concatenate the contained values into vectors.\n\n\n[bitstring(1.0), bitstring(-1.0)]\n\nThe next 11 bits determine the exponent (scaling) of the number, and so on.\n\n[bitstring(1.0), bitstring(2.0)]\n\nThe sign bit, exponent, and significand in \n\n(1.1.1) are all directly accessible.\n\nx = 3.14\n@show sign(x), exponent(x), significand(x);\n\nx = x / 8\n@show sign(x), exponent(x), significand(x);\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. You can get its value from the eps function in Julia. By default, it returns the value for double precision.\n\nTo call a function, including eps, you must use parentheses notation, even when there are no input arguments.\n\neps()\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps())\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nnextfloat(161.8)\n\nans - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\n@show floatmin(),floatmax();\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2^(-4)\n\nThere are some exceptions. A floating-point value can’t be used as an index into an array, for example, even if it is numerically equal to an integer. In such cases you use Int to convert it.\n\n@show 5.0, Int(5.0);\n\nIf you try to convert a noninteger floating-point value into an integer you get an InexactValue error. This occurs whenever you try to force a type conversion that doesn’t make clear sense.\n\nFloating-point arithmetic oddity\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\ne = eps()/2\n(1.0 + e) - 1.0\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1.0 + (e - 1.0)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!","type":"content","url":"/chapter1#section-1-1","position":9},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#section-1-2","position":10},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.2","lvl2":"Examples"},"content":"Conditioning of polynomial roots\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nThe statement x,y = 10,20 makes individual assignments to both x and y.\n\nϵ = 1e-6   # type \\epsilon and then press Tab\na,b,c = 1/3,(-2-ϵ)/3,(1+ϵ)/3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4a*c)\nr₁ = (-b - d) / (2a)   # type r\\_1 and then press Tab\nr₂ = (-b + d) / (2a)\n(r₁, r₂)\n\nThe relative errors in these values are\n\n@show abs(r₁ - 1) / abs(1);\n@show abs(r₂ - (1+ϵ)) / abs(1+ϵ);\n\nThe condition number of each root is\n\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}. \n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps() / ϵ\n\nThis matches the observation pretty well.","type":"content","url":"/chapter1#section-1-2","position":11},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#section-1-3","position":12},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.3","lvl2":"Examples"},"content":"Using a function\n\nHere we show how to use \n\nFunction 1.3.1 to evaluate a polynomial. It’s not a part of core Julia, so you need to download and install this text’s package once, and load it for each new Julia session. The download is done by the following lines.\n\nimport Pkg\nPkg.add(\"FundamentalsNumericalComputation\");\n\nOnce installed, any package can be loaded with the using command, as follows.\n\nMany Julia functions, including the ones in this text, are in packages that must be loaded via using or import in each session. Sometimes a using statement can take a few seconds or even minutes to execute, if packages have been installed or updated.\n\nusing FundamentalsNumericalComputation\n\nFor convenience, this package also imports many other packages used throughout the book and makes them available as though you had run a using command for each of them.:::{card}\n\nIf you are not sure where a particular function is defined, you can run `methods` on the function name to find all its definitions.\n\n\nReturning to horner, let us define a vector of the coefficients of p(x)=(x-1)^3=x^3-3x^2+3x-1, in ascending degree order.\n\nc = [-1, 3, -3, 1]\n\nIn order to avoid clashes between similarly named functions, Julia has boxed all the book functions into a namespace called FNC. We use this namespace whenever we invoke one of the functions.:::{card}\n\nYou must use the module name when a package is loaded by `import`, but when loaded via `using`, some functions may be available with no prefix.\n\n\nFNC.horner(c, 1.6)\n\nThe above is the value of p(1.6).\n\nWhile the namespace does lead to a little extra typing, a nice side effect of using this paradigm is that if you type FNC. (including the period) and hit the Tab key, you will see a list of all the functions known in that namespace.\n\nThe multi-line string at the start of \n\nFunction 1.3.1 is documentation, which we can access using ?FNC.horner.","type":"content","url":"/chapter1#section-1-3","position":13},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#section-1-4","position":14},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.4","lvl2":"Examples"},"content":"Instability of the quadratic formula\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6+1e-6);  c = 1;\n@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n@show x₂ = (-b - sqrt(b^2 - 4a*c)) / 2a;\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6-x₂)/1e-6 \n@show accurate_digits = -log10(error);\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nStable alternative to the quadratic formula\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6+1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\n@show x₁ = (-b + sqrt(b^2-4a*c)) / 2a;\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\n@show x₂ = c / (a*x₁);\n\nAs you see in this output, Julia often suppresses trailing zeros in a decimal expansion. To be sure we have an accurate result, we compute its relative error.\n\nabs(x₂-1e-6) / 1e-6\n\nBackward error\n\nFor this example we will use the Polynomials package, which is installed by the FNC package.\n\nIn the rest of the book, we do not show the using statement needed to load the book’s package, but you will need to enter it if you want to run the codes yourself.\n\nusing FundamentalsNumericalComputation\n\nOur first step is to construct a polynomial with six known roots.\n\nr = [-2.0,-1,1,1,3,6]\np = fromroots(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr̃ = sort(roots(p))   # type r\\tilde and then press Tab\n\nHere are the relative errors in each of the computed roots.\n\nThe @. notation at the start means to do the given operations on each element of the given vectors.\n\nprintln(\"Root errors:\") \n@. abs(r-r̃) / r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply fromroots to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np̃ = fromroots(r̃)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nc,c̃ = coeffs(p),coeffs(p̃)\nprintln(\"Coefficient errors:\") \n@. abs(c-c̃) / c\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.","type":"content","url":"/chapter1#section-1-4","position":15},{"hierarchy":{"lvl1":"Chapter 2"},"type":"lvl1","url":"/chapter2","position":0},{"hierarchy":{"lvl1":"Chapter 2"},"content":"import Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\nJulia implementations","type":"content","url":"/chapter2","position":1},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"type":"lvl2","url":"/chapter2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"content":"Forward substitution\n\n\"\"\"\n    forwardsub(L,b)\n\nSolve the lower-triangular linear system with matrix `L` and\nright-hand side vector `b`.\n\"\"\"\nfunction forwardsub(L,b)\n    n = size(L,1)\n    x = zeros(n)\n    x[1] = b[1]/L[1,1]\n    for i in 2:n\n        s = sum( L[i,j]*x[j] for j in 1:i-1 )\n        x[i] = ( b[i] - s ) / L[i,i]\n    end\n    return x\nend\n\nAbout the code\n\nThe sum in line 12 gives an error if i equals 1, so that case is taken care of before the loop starts.\n\nBackward substitution\n\n\"\"\"\n    backsub(U,b)\n\nSolve the upper-triangular linear system with matrix `U` and\nright-hand side vector `b`.\n\"\"\"\nfunction backsub(U,b)\n    n = size(U,1)\n    x = zeros(n)\n    x[n] = b[n]/U[n,n]\n    for i in n-1:-1:1\n        s = sum( U[i,j]*x[j] for j in i+1:n )\n        x[i] = ( b[i] - s ) / U[i,i]\n    end\n    return x\nend\n\nLU factorization (not stable)\n\n\"\"\"\n    lufact(A)\n\nCompute the LU factorization of square matrix `A`, returning the\nfactors.\n\"\"\"\nfunction lufact(A)\n    n = size(A,1)        # detect the dimensions from the input\n    L = diagm(ones(n))   # ones on main diagonal, zeros elsewhere\n    U = zeros(n,n)\n    Aₖ = float(copy(A))  # make a working copy \n\n    # Reduction by outer products\n    for k in 1:n-1\n        U[k,:] = Aₖ[k,:]\n        L[:,k] = Aₖ[:,k]/U[k,k]\n        Aₖ -= L[:,k]*U[k,:]'\n    end\n    U[n,n] = Aₖ[n,n]\n    return LowerTriangular(L),UpperTriangular(U)\nend\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out two subtle Julia issues. First, vectors and matrix variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement Aₖ=A just clones the array reference of A into the variable Aₖ. Any changes made to entries of Aₖ would then also be made to entries of A because they refer to the same location in memory. In this context we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nThe second issue is that even when A has all integer entries, its LU factors may not. So we convert Aₖ to floating point so that line 17 will not fail due to the creation of floating-point values in an integer matrix. An alternative would be to require the caller to provide a floating-point array in the first place.\n\nLU factorization with partial pivoting\n\n\"\"\"\n    plufact(A)\n\nCompute the PLU factorization of square matrix `A`, returning the\ntriangular factors and a row permutation vector.\n\"\"\"\nfunction plufact(A)\n    n = size(A,1)\n    L = zeros(n,n)\n    U = zeros(n,n)\n    p = fill(0,n)\n    Aₖ = float(copy(A))\n\n    # Reduction by outer products\n    for k in 1:n-1\n        p[k] = argmax(abs.(Aₖ[:,k]))\n        U[k,:] = Aₖ[p[k],:]\n        L[:,k] = Aₖ[:,k]/U[k,k]\n        Aₖ -= L[:,k]*U[k,:]'\n    end\n    p[n] = argmax(abs.(Aₖ[:,n]))\n    U[n,n] = Aₖ[p[n],n]\n    L[:,n] = Aₖ[:,n]/U[n,n]\n    return LowerTriangular(L[p,:]),U,p\nend","type":"content","url":"/chapter2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"type":"lvl2","url":"/chapter2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"content":"","type":"content","url":"/chapter2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-1","position":6},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.1","lvl2":"Examples"},"content":"Linear system for polynomial interpolation\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982, 2000, 2010, 2015]; \npop = [1008.18, 1262.64, 1337.82, 1374.62];\n\nIt’s convenient to measure time in years since 1980. We use .- to subtract a scalar from every element of a vector. We will also use a floating-point value in the subtraction, so the result is also in double precision.\n\nA dotted operator such as .- or .* acts elementwise, broadcasting scalar values to match up with elements of an array.\n\nt = year .- 1980.0\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nAn expression inside square brackets and ending with a for statement is called a comprehension. It’s often an easy and readable way to construct vectors and matrices.\n\nV = [ t[i]^j for i=1:4, j=0:3 ]\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V*c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in ascending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\nThe Polynomials package has functions to make working with polynomials easy and efficient.\n\np = Polynomial(c)    # construct a polynomial\np(2005-1980)         # include the 1980 time shift\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nscatter(t,y, label=\"actual\", legend=:topleft,\n    xlabel=\"years since 1980\", ylabel=\"population (millions)\", \n    title=\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval. The dot after the name of the polynomial is a universal way to apply a function to every element of an array, a technique known as broadcasting.\n\nThe range function constructs evenly spaced values given the endpoints and either the number of values, or the step size between them.\n\nAdding a dot to the end of a function name causes it to be broadcast, i.e., applied to every element of a vector or matrix.\n\n# Choose 500 times in the interval [0,35].\ntt = range(0,35,length=500)   \n# Evaluate the polynomial at all the vector components.\nyy = p.(tt)\nforeach(println,yy[1:4])\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\n\nBy convention, functions whose names end with the bang ! change the value or state of something, in addition to possibly returning output.\n\nplot!(tt,yy,label=\"interpolant\")","type":"content","url":"/chapter2#section-2-1","position":7},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-2","position":8},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.2","lvl2":"Examples"},"content":"Matrix operations\n\nIn Julia, vectors and matrices are one-dimensional and two-dimensional arrays, respectively. Square brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ 1 2 3 4 5; 50 40 30 20 10\n    π sqrt(2) exp(1) (1+sqrt(5))/2 log(3) ]\n\nm, n = size(A)\n\nA vector is not quite the same thing as a matrix: it has only one dimension, not two. Separate its elements by commas or semicolons:\n\nx = [ 3, 3, 0, 1, 0 ]\nsize(x)\n\nFor some purposes, however, an n-vector in Julia is treated like having a column shape. Note the difference if we use spaces instead of commas inside the brackets:\n\ny = [ 3 3 0 1 0 ]\nsize(y)\n\nThis 1\\times 5 matrix is not equivalent to a vector.\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nIf x is simply a vector, then its transpose has a row shape.\n\nx'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              # start:stop\n\nz = 0:3:12           # start:step:stop\n\n(Ranges are not strictly considered vectors, but they behave identically in most circumstances.) Instead of specifying the step size, you can give the number of points in the range if you use range.\n\ns = range(-1, 1, 5)\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within square brackets.\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A[2, end-1]\n\nx[2]\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA[1:2, end-2:end]    # first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA[:, 1:2:end]        # all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nUse diagm to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diagm( [-1, 0, -5] )   # create a diagonal matrix\n\n@show size(A), size(B);\nBA = B * A     # matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nErrors are formally called exceptions in Julia.\n\nA * B    # throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    # same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x.^2\n\ntwo_to_x = 2 .^ x\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, expect scalars as operands. However, you can broadcast any function, including ones that you have defined, across a vector or array by using a special dot syntax.\n\nA dot added to the end of a function name means to apply the function elementwise to an array.\n\nshow(cos.(π*x))    # broadcast to a function\n\nRather than dotting multiple individual functions, you can use @. before an expression to broadcast everything within it.\n\nshow(@. cos(π*(x+1)^3))    # broadcast an entire expression","type":"content","url":"/chapter2#section-2-2","position":9},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-3","position":10},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.3","lvl2":"Examples"},"content":"Solving linear systems\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1, 2, 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A*x\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = [0 1; 0 0]\nb = [1, -1]\nx = A \\ b\n\nIn this case we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nTriangular systems of equations\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = rand(1.:9., 5, 5)\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L,b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext we’ll engineer a problem to which we know the exact answer. Use \\alpha Tab and \\beta Tab to get the Greek letters.\n\nThe notation 0=>ones(5) creates a Pair. In diagm, pairs indicate the position of a diagonal and the elements that are to be placed on it.\n\nα = 0.3;\nβ = 2.2;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nU\n\nx_exact = ones(5)\nb = [α, 0, 0, 0, 1]\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nα = 0.3;\nβ = 1e12;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nb = [α, 0, 0, 0, 1]\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with 16! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.","type":"content","url":"/chapter2#section-2-3","position":11},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-4","position":12},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.4","lvl2":"Examples"},"content":"Triangular outer products\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( rand(1:9, 3, 3) )\n\nU = triu( rand(1:9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nAlthough U[1,:] is a row of U, it is a vector, and as such it has a default column interpretation.\n\nL[:, 1] * U[1, :]'\n\nL[:, 2] * U[2, :]'\n\nL[:, 3] * U[3, :]'\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nLU factorization\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA₁ = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = diagm(ones(4))\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[1, :] = A₁[1, :]\nU\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 1] = A₁[:, 1] / U[1, 1]\nL\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[2, :] = A₂[2, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nL\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[3, :] = A₃[3, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\nFinally, we pick up the last unknown in the factors.\n\nU[4, 4] = A₄[4, 4];\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA₁ - L * U\n\nIIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nSolving a linear system by LU factors\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4,9,9,4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A*x","type":"content","url":"/chapter2#section-2-4","position":13},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-5","position":14},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.5","lvl2":"Examples"},"content":"Floating-point operations in matrix-vector multiplication\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = randn(n, n)\nx = rand(n)\ny = zeros(n)\nfor i in 1:n\n    for j in 1:n\n        y[i] += A[i, j] * x[j]    # 1 multiply, 1 add\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. Note that Julia is unusual in that loops have a variable scope separate from its enclosing code. Thus, for n in n below means that inside the loop, the name n will take on each one of the values that were previously assigned to the vector n.\n\nThe push! function attaches a new value to the end of a vector.\n\nn = 1000:1000:5000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:80; A * x; end\n    push!(t, time)\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\npretty_table([n t], header=([\"size\", \"time\"], [\"\", \"(sec)\"]))\n\nLooking at the timings just for n=2000 and n=4000, they have ratio\n\nThe expression n.==4000 here produces a vector of Boolean (true/false) values the same size as n. This result is used to index within t, accessing only the value for which the comparison is true.\n\n@show t[n.==4000] ./ t[n.==2000];\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nAsymptotics in log-log plots\n\nLet’s repeat the experiment of the previous figure for more, and larger, values of n.\n\nrandn(5,5)*randn(5);  # throwaway to force compilation\n\nn = 400:200:6000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:50; A * x; end\n    push!(t, time)\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nscatter(n, t, label=\"data\", legend=false,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time (sec)\"),\n    title=\"Timing of matrix-vector multiplications\")\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nplot!(n, t[end] * (n/n[end]).^2, l=:dash,\n    label=L\"O(n^2)\", legend=:topleft)\n\nFloating-point operations in LU factorization\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nlu(randn(3, 3));   # throwaway to force compilation\n\nn = 400:400:4000\nt = []\nfor n in n\n    A = randn(n, n)  \n    time = @elapsed for j in 1:12; lu(A); end\n    push!(t, time)\nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nscatter(n, t, label=\"data\", legend=:topleft,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time\"))\nplot!(n, t[end ]* (n/n[end]).^3, l=:dash, label=L\"O(n^3)\")","type":"content","url":"/chapter2#section-2-5","position":15},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-6","position":16},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.6","lvl2":"Examples"},"content":"Failure of naive LU factorization\n\nHere is a previously encountered matrix that factors well.\n\nA = [2 0 4 3 ; -4 5 -7 -10 ; 1 15 2 -4.5 ; -2 0 2 -13];\nL, U = FNC.lufact(A)\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[2, 4], :] = A[[4, 2], :]  \nL, U = FNC.lufact(A)\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[1, :] = A[1, :]\nL[:, 1] = A[:, 1] / U[1, 1]\nA -= L[:, 1] * U[1, :]'\n\nThe next step is U[2, :] = A[2, :], which is also OK. But then we are supposed to divide by U[2, 2], which is zero. The algorithm cannot continue.\n\nRow pivoting in LU factorization\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA₁ = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs.(A₁[:, 1]) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = zeros(4,4),zeros(4,4)\nU[1, :] = A₁[i, :]\nL[:, 1] = A₁[:, 1] / U[1, 1]\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n@show i = argmax( abs.(A₂[:, 2]) ) \nU[2, :] = A₂[i, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n@show i = argmax( abs.(A₃[:, 3]) ) \nU[3, :] = A₃[i, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\n@show i = argmax( abs.(A₄[:, 4]) ) \nU[4, :] = A₄[i, :]\nL[:, 4] = A₄[:, 4] / U[4, 4];\n\nWe do have a factorization of the original matrix:\n\nA₁ - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nRow permutation in LU factorization\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1. If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A[[4, 3, 2, 1], :]\nL, U = FNC.lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nU\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nL\n\nPLU factorization for solving linear systems\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = rand(1:20, 4, 4)\nL, U, p = FNC.plufact(A)\nA[p,:] - L * U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4)\nz = FNC.forwardsub(L,b[p])\nx = FNC.backsub(U,z)\n\nA residual check is successful:\n\nb - A*x\n\nBuilt-in PLU factorization\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500)   # 500x500 with normal random entries\nA \\ rand(500)          # force compilation\n@elapsed for k=1:50; A \\ rand(500); end\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\nfactored = lu(A)     # store factorization result\nfactored \\ rand(500)   # force compilation\n@elapsed for k=1:50; factored \\ rand(500); end\n\nStability of PLU factorization\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nϵ = 1e-12\nA = [-ϵ 1; 1 -1]\nb = A * [1, 1]\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nϵ = 1e-20; A = [-ϵ 1; 1 -1]\nb = A * [1, 1]\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b","type":"content","url":"/chapter2#section-2-6","position":17},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-7","position":18},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.7","lvl2":"Examples"},"content":"Vector norms\n\nIn Julia the LinearAlgebra package has a norm function for vector norms.\n\nx = [2, -3, 1, -1]\ntwonorm = norm(x)         # or norm(x,2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nThere is also a normalize function that divides a vector by its norm, making it a unit vector.\n\nnormalize(x, Inf)\n\nMatrix norms\n\nA = [ 2 0; 1 -1 ]\n\nIn Julia, one uses norm for vector norms and for the Frobenius norm of a matrix, which is like stacking the matrix into a single vector before taking the 2-norm.\n\nFronorm = norm(A)\n\nMost of the time we want to use opnorm, which is an induced matrix norm. The default is the 2-norm.\n\ntwonorm = opnorm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = opnorm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nUse sum to sum along a dimension of a matrix. You can also sum over the entire matrix by omitting the dims argument.\n\nThe maximum and minimum functions also work along one dimension or over an entire matrix. To get both values at once, use extrema.\n\n# Sum down the rows (1st matrix dimension):\nmaximum( sum(abs.(A), dims=1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = opnorm(A, Inf)\n\n # Sum across columns (2nd matrix dimension):\nmaximum( sum(abs.(A), dims=2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nYou can use functions as values, e.g., as elements of a vector.\n\n# Construct 601 unit column vectors.\nθ = 2π * (0:1/600:1)   # type \\theta then Tab\nx = [ fun(t) for fun in [cos, sin], t in θ ];\n\nTo create an array of plots, start with a plot that has a layout argument, then do subsequent plot! calls with a subplot argument.\n\nplot(aspect_ratio=1, layout=(1, 2),\n    xlabel=L\"x_1\",  ylabel=L\"x_2\")\nplot!(x[1, :], x[2, :], subplot=1, title=\"Unit circle\")\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse.\n\nplot!(Ax[1, :], Ax[2, :], \n    subplot=2, title=\"Image under x → Ax\")\n\nThat ellipse just touches the circle of radius \\|\\mathbf{A}\\|_2.\n\nplot!(twonorm*x[1, :], twonorm*x[2, :], subplot=2, l=:dash)","type":"content","url":"/chapter2#section-2-7","position":19},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.8","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-8","position":20},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.8","lvl2":"Examples"},"content":"Matrix condition number\n\nJulia has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nType \\kappa followed by Tab to get the Greek letter κ.\n\nA = [ 1 / (i + j) for i in 1:6, j in 1:6 ]\nκ = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = 1:6\nb = A * x\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\n# type \\Delta then Tab to get Δ\nΔA = randn(size(A));  ΔA = 1e-10 * (ΔA / opnorm(ΔA));\nΔb = randn(size(b));  Δb = 1e-10 * normalize(Δb);\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + ΔA) \\ (b + Δb))\nΔx = new_x - x\n\nHere is the relative error in the solution.\n\n@show relative_error = norm(Δx) / norm(x);\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprintln(\"Upper bound due to b: $(κ * norm(Δb) / norm(b))\")\nprintln(\"Upper bound due to A: $(κ * opnorm(ΔA) / opnorm(A))\")\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n@show rounding_bound = κ * eps();\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = [ 1 / (i + j) for i=1:14, j=1:14 ];\nκ = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = κ*eps()\n\nLet’s put that prediction to the test.\n\nx = 1:14\nb = A * x  \nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.","type":"content","url":"/chapter2#section-2-8","position":21},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.9","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#section-2-9","position":22},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.9","lvl2":"Examples"},"content":"Banded matrices\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nUse fill to create an array of a given size, with each element equal to a provided value.\n\nA = diagm( -1 => [4, 3, 2, 1, 0], \n    0 => [2, 2, 0, 2, 1, 2], \n    1 => fill(-1, 5) )\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\n@show diag_main = diag(A);\n@show diag_minusone = diag(A, -1);\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\nL, U = FNC.lufact(A)\nL\n\nU\n\nTiming banded LU\n\nIf we use an ordinary or dense matrix, then there’s no way to exploit a banded structure such as tridiagonality.\n\nn = 10000\nA = diagm(0=>1:n, 1=>n-1:-1:1, -1=>ones(n-1))\nlu(rand(3, 3))  # force compilation\n@time lu(A);\n\nIf instead we construct a proper sparse matrix, though, the speedup can be dramatic.\n\nA = spdiagm(0=>1:n, 1=>n-1:-1:1, -1=>ones(n-1))\nlu(A);    # compile for sparse case\n@time lu(A);\n\nYou can also see above that far less memory was used in the sparse case.\n\nSymmetric LDLT factorization\n\nWe begin with a symmetric \\mathbf{A}.\n\nA₁ = [  2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = diagm(ones(4))\nd = zeros(4)\nd[1] = A₁[1, 1]\nL[:, 1] = A₁[:, 1] / d[1]\nA₂ = A₁ - d[1] * L[:, 1] * L[:, 1]'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[2] = A₂[2, 2]\nL[:, 2] = A₂[:, 2] / d[2]\nA₃ = A₂ - d[2] * L[:, 2] * L[:, 2]'\n\nWe continue working our way down the diagonal.\n\nd[3] = A₃[3, 3]\nL[:, 3] = A₃[:, 3] / d[3]\nA₄ = A₃ - d[3] * L[:, 3] * L[:, 3]'\nd[4] = A₄[4, 4]\n@show d;\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nopnorm(A₁ - (L * diagm(d) * L'))\n\nCholesky factorization\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = rand(1.0:9.0, 4, 4)\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nThe cholesky function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix. However, it does not check for symmetry.\n\ncholesky(B)    # throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A\ncf = cholesky(B)\n\nWhat’s returned is a factorization object. Another step is required to extract the factor as a matrix:\n\nR = cf.U\n\nHere we validate the factorization:\n\nopnorm(R' * R - B) / opnorm(B)","type":"content","url":"/chapter2#section-2-9","position":23},{"hierarchy":{"lvl1":"Chapter 3"},"type":"lvl1","url":"/chapter3","position":0},{"hierarchy":{"lvl1":"Chapter 3"},"content":"Julia implementations","type":"content","url":"/chapter3","position":1},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"type":"lvl2","url":"/chapter3#functions","position":2},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"content":"Solution of least squares by the normal equations\n\n\"\"\"\n    lsnormal(A,b)\n\nSolve a linear least-squares problem by the normal equations.\nReturns the minimizer of ||b-Ax||.\n\"\"\"\nfunction lsnormal(A,b)\n    N = A'*A;  z = A'*b;\n    R = cholesky(N).U\n    w = forwardsub(R',z)                   # solve R'z=c\n    x = backsub(R,w)                       # solve Rx=z\n    return x\nend\n\nAbout the code\n\nThe syntax on line 9 is a field reference to extract the matrix we want from the structure returned by cholesky.\n\nSolution of least squares by QR factorization\n\n\"\"\"\n    lsqrfact(A,b)\n\nSolve a linear least-squares problem by QR factorization. Returns\nthe minimizer of ||b-Ax||.\n\"\"\"\nfunction lsqrfact(A,b)\n    Q,R = qr(A)\n    c = Q'*b\n    x = backsub(R,c)\n    return x\nend\n\nQR factorization by Householder reflections\n\n\"\"\"\n    qrfact(A)\n\nQR factorization by Householder reflections. Returns Q and R.\n\"\"\"\nfunction qrfact(A)\n    m,n = size(A)\n    Qt = diagm(ones(m))\n    R = float(copy(A))\n    for k in 1:n\n        z = R[k:m,k]\n        w = [ -sign(z[1])*norm(z) - z[1]; -z[2:end] ]\n        nrmw = norm(w)\n        if nrmw < eps() continue; end    # skip this iteration\n        v = w / nrmw;\n        # Apply the reflection to each relevant column of R and Q\n        for j in k:n\n            R[k:m,j] -= v*( 2*(v'*R[k:m,j]) )\n        end\n        for j in 1:m\n            Qt[k:m,j] -= v*( 2*(v'*Qt[k:m,j]) )\n        end\n    end\n    return Qt',triu(R)\nend","type":"content","url":"/chapter3#functions","position":3},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"type":"lvl2","url":"/chapter3#examples","position":4},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"content":"\n\nimport Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter3#examples","position":5},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#section-3-1","position":6},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.1","lvl2":"Examples"},"content":"Interpolating temperature data\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = 1955:5:2000\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n       0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n    \nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", leg=:bottomright)\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = @. (year - 1950) / 10\nn = length(t)\nV = [ t[i]^j for i in 1:n, j in 0:n-1 ]\nc = V \\ temp\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\nIf you plot a function, then the points are chosen automatically to make a smooth curve.\n\np = Polynomial(c)\nf = yr -> p((yr - 1950) / 10)\nplot!(f, 1955, 2000, label=\"interpolant\")\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nFitting temperature data\n\nHere are the 5-year temperature averages again.\n\nyear = 1955:5:2000\nt = @. (year-1950)/10\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n          0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = [ t.^0 t ]    # Vandermonde-ish matrix\n@show size(V)\nc = V \\ temp\np = Polynomial(c)\n\nf = yr -> p((yr - 1955) / 10)\nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", leg=:bottomright)\nplot!(f, 1955, 2000, label=\"linear fit\")\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [ t[i]^j for i in 1:length(t), j in 0:3 ]   \n@show size(V);\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nThe definition of f above is in terms of p. When p is changed, then f calls the new version.\n\np = Polynomial( V \\ temp )\nplot!(f, 1955, 2000, label=\"cubic fit\")\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nFitting a power law\n\na = [1/k^2 for k=1:100] \ns = cumsum(a)        # cumulative summation\np = @. sqrt(6*s)\n\nscatter(1:100, p, title=\"Sequence convergence\",\n    xlabel=L\"k\", ylabel=L\"p_k\")\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nϵ = @. abs(π - p)    # error sequence\nscatter(1:100, ϵ, title=\"Convergence of errors\",\n    xaxis=(:log10,L\"k\"), yaxis=(:log10,\"error\"))\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nk = 1:100\nV = [ k.^0 log.(k) ]     # fitting matrix\nc = V \\ log.(ϵ)          # coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[1]), c[2];\n@show b;\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nplot!(k, a * k.^b, l=:dash, label=\"power-law fit\")","type":"content","url":"/chapter3#section-3-1","position":7},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#section-3-2","position":8},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.2","lvl2":"Examples"},"content":"Instability in the normal equations\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = range(0, 3, 400)\nf = [ x->sin(x)^2, x->cos((1+1e-7)*x)^2, x->1. ]\nA = [ f(t) for t in t, f in f ]\n@show κ = cond(A);\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1., 2, 1]\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b\n@show observed_error = norm(x_BS - x) / norm(x);\n@show error_bound = κ * eps();\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A' * A\nx_NE = N \\ (A'*b)\n@show observed_err = norm(x_NE - x) / norm(x);\n@show digits = -log10(observed_err);","type":"content","url":"/chapter3#section-3-2","position":9},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#section-3-3","position":10},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.3","lvl2":"Examples"},"content":"QR factorization\n\nJulia provides access to both the thin and full forms of the QR factorization.\n\nA = rand(1.:9., 6, 4)\n@show m,n = size(A);\n\nHere is a standard call:\n\nQ,R = qr(A);\nQ\n\nR\n\nIf you look carefully, you see that we seemingly got a full \\mathbf{Q} but a thin \\mathbf{R}. However, the \\mathbf{Q} above is not a standard matrix type. If you convert it to a true matrix, then it reverts to the thin form.\n\nTo enter the accented character Q̂, type Q\\hat followed by Tab.\n\nQ̂ = Matrix(Q)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nopnorm(Q' * Q - I)\n\nThe thin \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC:\n\nQ̂' * Q̂ - I\n\nStability of least-squares via QR\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = range(0, 3, 400)\nf = [ x->sin(x)^2, x->cos((1+1e-7)*x)^2, x->1. ]\nA = [ f(t) for t in t, f in f ]\nx = [1., 2, 1]\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(FNC.lsqrfact(A,b) - x) / norm(x);\n@show observed_error;\n@show error_bound = cond(A) * eps();","type":"content","url":"/chapter3#section-3-3","position":11},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#section-3-4","position":12},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.4","lvl2":"Examples"},"content":"Householder QR factorization\n\nWe will use Householder reflections to produce a QR factorization of a random matrix.\n\nThe rand function can select randomly from within the interval [0,1], or from a vector or range that you specify.\n\nA = rand(float(1:9),6,4)\nm,n = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).:::{card}\n`I` can stand for an identity matrix of any size, inferred from the context when needed.\n\nz = A[:, 1];\nv = normalize(z - norm(z) * [1; zeros(m-1)])\nP₁ = I - 2v * v'   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nP₁ * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}\\mathbf{A}.\n\nA = P₁ * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[2:m, 2]\nv = normalize(z - norm(z) * [1; zeros(m-2)])\nP₂ = I - 2v * v'\n\nWe now apply this reflector to rows 2 and below only.\n\nA[2:m, :] = P₂ * A[2:m, :]\nA\n\nWe need to iterate the process for the last two columns.\n\nfor j in 3:n\n    z = A[j:m, j]\n    v = normalize(z - norm(z) * [1; zeros(m-j)])\n    P = I - 2v * v'\n    A[j:m, :] = P * A[j:m, :]\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)","type":"content","url":"/chapter3#section-3-4","position":13},{"hierarchy":{"lvl1":"Chapter 4"},"type":"lvl1","url":"/chapter4","position":0},{"hierarchy":{"lvl1":"Chapter 4"},"content":"","type":"content","url":"/chapter4","position":1},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"type":"lvl2","url":"/chapter4#functions","position":2},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"content":"Newton’s method\n\n\"\"\"\n    newton(f,dfdx,x₁[;maxiter,ftol,xtol])\n\nUse Newton's method to find a root of `f` starting from `x₁`, where\n`dfdx` is the derivative of `f`. Returns a vector of root estimates.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\"\"\"\nfunction newton(f,dfdx,x₁;maxiter=40,ftol=100*eps(),xtol=100*eps())\n    x = [float(x₁)]\n    y = f(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (abs(Δx) > xtol) && (abs(y) > ftol)\n        dydx = dfdx(x[k])\n        Δx = -y/dydx            # Newton step\n        push!(x,x[k]+Δx)        # append new estimate\n\n        k += 1\n        y = f(x[k])\n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nSecant method\n\n    x = [float(x₁),float(x₂)]\n    y₁ = f(x₁)\n    Δx,y₂ = Inf,Inf   # for initial pass in the loop below\n    k = 2\n\n    while (abs(Δx) > xtol) && (abs(y₂) > ftol) \n        y₂ = f(x[k])\n        Δx = -y₂ * (x[k]-x[k-1]) / (y₂-y₁)   # secant step\n        push!(x,x[k]+Δx)        # append new estimate\n\n        k += 1\n        y₁ = y₂    # current f-value becomes the old one next time\n        \n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.\n\nNewton’s method for systems\n\n\"\"\"\n    newtonsys(f,jac,x₁[;maxiter,ftol,xtol])\n\nUse Newton's method to find a root of a system of equations,\nstarting from `x₁`. The functions `f` and `jac` should return the\nresidual vector and the Jacobian matrix, respectively. Returns the\nhistory of root estimates as a vector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction newtonsys(f,jac,x₁;maxiter=40,ftol=1000*eps(),xtol=1000*eps())\n    x = [float(x₁)]\n    y,J = f(x₁),jac(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (norm(Δx) > xtol) && (norm(y) > ftol)\n        Δx = -(J\\y)             # Newton step\n        push!(x,x[k] + Δx)    # append to history\n        k += 1\n        y,J = f(x[k]),jac(x[k])\n\n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n    end\n    return x\nend\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nFinite differences for Jacobian\n\n\"\"\"\n    fdjac(f,x₀[,y₀])\n\nCompute a finite-difference approximation of the Jacobian matrix for\n`f` at `x₀`, where `y₀`=`f(x₀)` may be given.\n\"\"\"\nfunction fdjac(f,x₀,y₀=f(x₀))\n    δ = sqrt(eps())*max(norm(x₀),1)   # FD step size\n    m,n = length(y₀),length(x₀)\n    if n==1\n        J = (f(x₀+δ) - y₀) / δ\n    else\n        J = zeros(m,n)\n        x = copy(x₀)\n        for j in 1:n\n            x[j] += δ\n            J[:,j] = (f(x) - y₀) / δ\n            x[j] -= δ\n        end\n    end\n    return J\nend\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.\n\nLevenberg’s method\n\n\"\"\"\n    levenberg(f,x₁[;maxiter,ftol,xtol])\n\nUse Levenberg's quasi-Newton iteration to find a root of the system\n`f` starting from `x₁` Returns the history of root estimates as a \nvector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction levenberg(f,x₁;maxiter=40,ftol=1e-12,xtol=1e-12)\n    x = [float(x₁)]\n    yₖ = f(x₁)\n    k = 1;  s = Inf;\n    A = fdjac(f,x[k],yₖ)   # start with FD Jacobian\n    jac_is_new = true\n\n    λ = 10;\n    while (norm(s) > xtol) && (norm(yₖ) > ftol)\n        # Compute the proposed step.\n        B = A'*A + λ*I\n        z = A'*yₖ\n        s = -(B\\z)\n        \n        x̂ = x[k] + s\n        ŷ = f(x̂)\n\n        # Do we accept the result?\n        if norm(ŷ) < norm(yₖ)    # accept\n            λ = λ/10   # get closer to Newton\n            # Broyden update of the Jacobian.\n            A += (ŷ-yₖ-A*s)*(s'/(s'*s))\n            jac_is_new = false\n            \n            push!(x,x̂)\n            yₖ = ŷ\n            k += 1\n        else                       # don't accept\n            # Get closer to gradient descent.\n            λ = 4λ\n            # Re-initialize the Jacobian if it's out of date.\n            if !jac_is_new\n                A = fdjac(f,x[k],yₖ)\n                jac_is_new = true\n            end\n        end\n\n        if k==maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n        \n    end\n    return x\nend","type":"content","url":"/chapter4#functions","position":3},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"type":"lvl2","url":"/chapter4#examples","position":4},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"content":"\n\nimport Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter4#examples","position":5},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-1","position":6},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.1","lvl2":"Examples"},"content":"The rootfinding problem for Bessel functions\n\nJ₃(x) = besselj(3, x)\nplot(J₃, 0, 20, title=\"Bessel function\",\n    xaxis=(L\"x\"), yaxis=(L\"J_3(x)\"), grid=:xy)\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nType \\omega followed by Tab to get the character ω.\n\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nω = []\nfor guess = [6., 10. ,13., 16., 19.]\n    s = nlsolve(x -> J₃(x[1]), [guess], ftol=1e-14)\n    append!(ω, s.zero)\nend\n\npretty_table([ω J₃.(ω)], header=[\"root estimate\",\"function value\"])\n\nscatter!(ω, J₃.(ω), title=\"Bessel function with roots\")\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nr = []\nfor guess = [3., 6., 10., 13.]\n    f(x) = J₃(x[1]) - 0.2\n    s = nlsolve(f, [guess], ftol=1e-14)\n    append!(r, s.zero)\nend\nscatter!(r, J₃.(r), title=\"Roots and other Bessel values\")\n\nCondition number of a rootfinding problem\n\nConsider first the function\n\nf(x) = (x - 1) * (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nThe syntax interval... is called splatting and means to insert all the individual elements of interval as a sequence.\n\ninterval = [0.8, 1.2]\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Well-conditioned root\")\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf(x) = (x - 1) * (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Poorly-conditioned root\")\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!","type":"content","url":"/chapter4#section-4-1","position":7},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-2","position":8},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.2","lvl2":"Examples"},"content":"Fixed-point iteration\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\np = Polynomial([3.5, -4,1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nWe define g(x)=x-p(x).\n\ng(x) = x - p(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nplt = plot([g x->x], 2, 3, l=2, label=[L\"y=g(x)\" L\"y=x\"],\n    xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=1,\n    title=\"Finding a fixed point\", legend=:bottomright)\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot!([x, y], [y, y], arrow=true, color=3)\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y;  y = g(x)\nplot!([x, x], [x, y], arrow=true, color=4)\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot!([x, y], [y, y], color=3);  \n    x = y       # y becomes the new x\n    y = g(x)    # g(x) becomes the new y\n    plot!([x, x], [x, y], color=4)  \nend\nplt\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - rmax) / rmax\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nplt = plot([g x->x], 1, 2, l=2, label=[\"y=g(x)\" \"y=x\"], aspect_ratio=1, \n    xlabel=L\"x\", ylabel=L\"y\", title=\"Divergence\", legend=:bottomright)\n\nx = 1.3; y = g(x);\narrow = false\nfor k = 1:5\n    plot!([x, y], [y, y], arrow=arrow, color=3)  \n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    plot!([x, x], [x, y], arrow=arrow, color=4)\n    if k > 2; arrow = true; end\nend\nplt\n\nThis time, the iteration is pushing us away from the correct answer.\n\nConvergence of fixed-point iteration\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\np = Polynomial([3.5, -4, 1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nHere is the fixed point iteration. This time we keep track of the whole sequence of approximations.\n\ng(x) = x - p(x)\nx = [2.1]\nfor k = 1:12\n    push!(x, g(x[k]))\nend\nx\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = @. abs(x - rmax)\nplot(0:12, err, m=:o,\n    xaxis=(\"iteration number\"), yaxis=(\"error\", :log10),\n    title=\"Convergence of fixed point iteration\")\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log.(err[5:12])\np = Polynomials.fit(5:12, y, 1)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nσ = exp(p.coeffs[2])\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\n[err[i+1] / err[i] for i in 8:11]\n\nThe methods for finding σ agree well.","type":"content","url":"/chapter4#section-4-2","position":9},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-3","position":10},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.3","lvl2":"Examples"},"content":"Graphical interpretation of Newton’s method\n\nSuppose we want to find a root of the function\n\nf(x) = x * exp(x) - 2\n\nplot(f, 0, 1.5, label=\"function\",\n    grid=:y, ylim=[-2, 4], xlabel=L\"x\", ylabel=L\"y\", legend=:topleft)\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx₁ = 1\ny₁ = f(x₁)\nscatter!([x₁], [y₁], label=\"initial point\")\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx(x) = exp(x) * (x + 1)\nm₁ = df_dx(x₁)\ntangent = x -> y₁ + m₁ * (x - x₁)\n\nplot!(tangent, 0, 1.5, l=:dash, label=\"tangent line\",\n    title=\"Tangent line approximation\")\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\n@show x₂ = x₁ - y₁ / m₁\nscatter!([x₂], [0], label=\"tangent root\", title=\"First iteration\")\n\ny₂ = f(x₂)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nplot(f, 0.82, 0.87, label=\"function\", legend=:topleft,\n    xlabel=L\"x\", ylabel=L\"y\", title=\"Second iteration\")\n\nscatter!([x₂], [y₂], label=\"starting point\")\n\nm₂ = df_dx(x₂)\ntangent = x -> y₂ + m₂ * (x - x₂)\nplot!(tangent, 0.82, 0.87, l=:dash, label=\"tangent line\")\n\n@show x₃ = x₂ - y₂ / m₂\nscatter!([x₃], [0], label=\"tangent root\")\n\ny₃ = f(x₃)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nConvergence of Newton’s method\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf(x) = x * exp(x) - 2;\ndf_dx(x) = exp(x) * (x + 1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nr = nlsolve(x -> f(x[1]), [1.0]).zero\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = [1; zeros(4)]\nfor k = 1:4\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nx\n\nHere is the sequence of errors.\n\nϵ = @. x - r\n\nBecause the error reaches machine epsilon so rapidly, we’re going to use extended precision to allow us to take a few more iterations. We’ll take the last iteration as the most accurate root estimate.\n\nA BigFloat uses 256 bits of precision, rather than 53 in Float64. But arithmetic is done by software emulation and is much slower.\n\nx = [BigFloat(1); zeros(7)]\nfor k = 1:7\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nr = x[end]\n\nϵ = @. Float64(x[1:end-1] - r)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = @. log(abs(ϵ))\n[logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nUsing Newton’s method\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\ng(x) = exp(x) - x\ndg_dx(x) = exp(x) - 1\ny = range(g(0), g(2), 200)\nx = zeros(length(y))\nfor (i, y) in enumerate(y)\n    f(x) = g(x) - y\n    df_dx(x) = dg_dx(x)\n    r = FNC.newton(f, df_dx, y)\n    x[i] = r[end]\nend\n\nplot(g, 0, 2, aspect_ratio=1, label=L\"g(x)\")\nplot!(y, x, label=L\"g^{-1}(y)\", title=\"Function and its inverse\")\nplot!(x -> x, 0, maximum(y), label=\"\", l=(:dash, 1), color=:black)","type":"content","url":"/chapter4#section-4-3","position":11},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-4","position":12},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.4","lvl2":"Examples"},"content":"Graphical interpretation of the secant method\n\nWe return to finding a root of the equation x e^x=2.\n\nf(x) = x * exp(x) - 2;\n\nplot(f, 0.25, 1.25, label=\"function\",\n    xlabel=L\"x\", ylabel=L\"y\", legend=:topleft)\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx₁ = 1;\ny₁ = f(x₁);\nx₂ = 0.5;\ny₂ = f(x₂);\nscatter!([x₁, x₂], [y₁, y₂], label=\"initial points\",\n    title=\"Two initial values\")\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nm₂ = (y₂ - y₁) / (x₂ - x₁)\nsecant = x -> y₂ + m₂ * (x - x₂)\nplot!(secant, 0.25, 1.25, label=\"secant line\", l=:dash, color=:black,\n    title=\"Secant line\")\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx₃ = x₂ - y₂ / m₂\n@show y₃ = f(x₃)\nscatter!([x₃], [0], label=\"root of secant\", title=\"First iteration\")\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nm₃ = (y₃ - y₂) / (x₃ - x₂)\nx₄ = x₃ - y₃ / m₃\n\nConvergence of the secant method\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1. Again we will use extended precision to get a longer sequence than double precision allows.\n\nf(x) = x * exp(x) - 2\nx = FNC.secant(f, BigFloat(1), BigFloat(0.5), xtol=1e-80, ftol=1e-80);\n\nWe don’t know the exact root, so we use the last value as a proxy.\n\nr = x[end]\n\nHere is the sequence of errors.\n\nϵ = @. Float64(r - x[1:end-1])\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\n[log(abs(ϵ[k+1])) / log(abs(ϵ[k])) for k in 1:length(ϵ)-1]\n\nAs expected, this settles in at around 1.618.\n\nInverse quadratic interpolation\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf(x) = x + cos(10 * x)\ninterval = [0.5, 1.5]\n\nplot(f, interval..., label=\"Function\", legend=:bottomright,\n    grid=:y, ylim=[-0.1, 3], xlabel=L\"x\", ylabel=L\"y\")\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]\ny = @. f(x)\nscatter!(x, y, label=\"initial points\")\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nq = Polynomials.fit(x, y, 2)      # interpolating polynomial\nplot!(x -> q(x), interval..., l=:dash, label=\"interpolant\")\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.:::{card}\nBy giving two functions in the plot call, we get the parametric plot $(q(y),y)$ as a function of $y$.\n\nplot(f, interval..., label=\"Function\",\n    legend=:bottomright, grid=:y, xlabel=L\"x\", ylabel=L\"y\")\nscatter!(x, y, label=\"initial points\")\n\nq = Polynomials.fit(y, x, 2)       # interpolating polynomial\nplot!(y -> q(y), y -> y, -0.1, 2.6, l=:dash, label=\"inverse interpolant\")\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nq(0)\n\nLet’s restart the process with BigFloat numbers to get a convergent sequence.\n\nx = BigFloat.([8, 12, 10]) / 10\ny = @. f(x)\n\nfor k = 3:12\n    q = Polynomials.fit(y[k-2:k], x[k-2:k], 2)\n    push!(x, q(0))\n    push!(y, f(x[k+1]))\nend\n\nprintln(\"residual = $(f(x[end]))\")\n\nAs far as our current precision is concerned, we have an exact root.\n\nr = x[end]\nlogerr = @. log(Float64(abs(r - x[1:end-1])))\n[logerr[k+1] / logerr[k] for k in 1:length(logerr)-1]\n\nThe convergence is probably superlinear at a rate of \\alpha=1.8 or greater.","type":"content","url":"/chapter4#section-4-4","position":13},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-5","position":14},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.5","lvl2":"Examples"},"content":"Convergence of Newton’s method for systems\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nBe careful when coding a Jacobian all in one statement. Spaces separate columns, so x[3]-1 is not the same as x[3] - 1.\n\nfunction func(x)\n    [exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\nend;\n\nfunction jac(x)\n    [\n        -exp(x[2] - x[1]) exp(x[2] - x[1]) 0\n        x[2] x[1] 1\n        2*x[1] x[3]-1 x[2]\n    ]\nend;\n\nWe will use a BigFloat starting value, and commensurately small stopping tolerances, in order to get a sequence long enough to measure convergence.\n\nx₁ = BigFloat.([0, 0, 0])\nϵ = eps(BigFloat)\nx = FNC.newtonsys(func, jac, x₁, xtol=ϵ, ftol=ϵ);\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x[end]\n@show residual = norm(func(r));\n\nWe take the sequence of norms of errors, applying the log so that we can look at the exponents.\n\nlogerr = [Float64(log(norm(r - x[k]))) for k in 1:length(x)-1]\n[logerr[k+1] / logerr[k] for k in 1:length(logerr)-1]\n\nThe ratio is neatly converging toward 2, which is expected for quadratic convergence.","type":"content","url":"/chapter4#section-4-5","position":15},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-6","position":16},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.6","lvl2":"Examples"},"content":"Using Levenberg’s method\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nf(x) = \n    [\n        exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx₁ = [0.0, 0.0, 0.0]\nx = FNC.levenberg(f, x₁)\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[end]\nprintln(\"backward error = $(norm(f(r)))\")\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method.\n\nlogerr = [log(norm(x[k] - r)) for k in 1:length(x)-1]\n[logerr[k+1] / logerr[k] for k in 1:length(logerr)-1]","type":"content","url":"/chapter4#section-4-6","position":17},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#section-4-7","position":18},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.7","lvl2":"Examples"},"content":"Convergence of nonlinear least squares\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng(x) = [sin(x[1] + x[2]), cos(x[1] - x[2]), exp(x[1] - x[2])]\np = [1, 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nplt = plot(xlabel=\"iteration\", yaxis=(:log10, \"error\"),\n    title=\"Convergence of Gauss–Newton\")\nfor R in [1e-3, 1e-2, 1e-1]\n    # Define the perturbed function.\n    f(x) = g(x) - g(p) + R * normalize([-1, 1, -1])\n    x = FNC.levenberg(f, [0, 0])\n    r = x[end]\n    err = [norm(x - r) for x in x[1:end-1]]\n    normres = norm(f(r))\n    plot!(err, label=@sprintf(\"R=%.2g\", normres))\nend\nplt\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nNonlinear data fitting\n\nm = 25;\ns = range(0.05, 6, length=m)\nŵ = @. 2 * s / (0.5 + s)                      # exactly on the curve\nw = @. ŵ + 0.15 * cos(2 * exp(s / 16) * s);     # smooth noise added\n\nscatter(s, w, label=\"noisy data\",\n    xlabel=\"s\", ylabel=\"v\", leg=:bottomright)\nplot!(s, ŵ, l=:dash, color=:black, label=\"perfect data\")\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\nfunction misfit(x)\n    V, Km = x   # rename components for clarity\n    return @. V * s / (Km + s) - w\nend\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction misfitjac(x)\n    V, Km = x   # rename components for clarity\n    J = zeros(m, 2)\n    J[:, 1] = @. s / (Km + s)              # dw/dV\n    J[:, 2] = @. -V * s / (Km + s)^2         # dw/d_Km\n    return J\nend\n\nx₁ = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x₁)\n\n@show V, Km = x[end]  # final values\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\nmodel(s) = V * s / (Km + s)\nplot!(model, 0, 6, label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nA = [s .^ (-1) s .^ 0]\nu = 1 ./ w\nα, β = A \\ u\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel(x) = 1 / (β + α / x)\nplot!(linmodel, 0, 6, label=\"linearized fit\")\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/chapter4#section-4-7","position":19},{"hierarchy":{"lvl1":"Chapter 5"},"type":"lvl1","url":"/chapter5","position":0},{"hierarchy":{"lvl1":"Chapter 5"},"content":"","type":"content","url":"/chapter5","position":1},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"type":"lvl2","url":"/chapter5#functions","position":2},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"content":"Hat function\n\n\"\"\"\n    hatfun(t,k)\n\nCreate a piecewise linear hat function, where `t` is a\nvector of n+1 interpolation nodes and `k` is an integer in 0:n\ngiving the index of the node where the hat function equals one.\n\"\"\"\n\nfunction hatfun(t,k)\n    n = length(t)-1\n    return function(x)\n        if k > 0 && t[k] ≤ x ≤ t[k+1]\n            return (x-t[k])/(t[k+1]-t[k])\n        elseif k < n && t[k+1] ≤ x ≤ t[k+2]\n            return (t[k+2]-x)/(t[k+2]-t[k+1])\n        else\n            return 0\n        end\n    end\nend\n\nPiecewise linear interpolation\n\n\"\"\"\n    plinterp(t,y)\n\nConstruct a piecewise linear interpolating function for data values in\n`y` given at nodes in `t`.\n\"\"\"\nfunction plinterp(t,y)\n    n = length(t)-1\n    H = [ hatfun(t,k) for k in 0:n ]\n    return x -> sum( y[k+1]*H[k+1](x) for k in 0:n )\nend\n\nCubic spline interpolation\n\n\"\"\"\n    spinterp(t,y)\n\nConstruct a cubic not-a-knot spline interpolating function for data\nvalues in `y` given at nodes in `t`.\n\"\"\"\nfunction spinterp(t,y)\n    n = length(t)-1\n    h = [ t[k+1]-t[k] for k in 1:n ]\n\n    # Preliminary definitions.\n    Z = zeros(n,n);\n    In = I(n);  E = In[1:n-1,:];\n    J = diagm(0=>ones(n),1=>-ones(n-1))\n    H = diagm(0=>h)\n\n    # Left endpoint interpolation:\n    AL = [ In Z Z Z ]\n    vL = y[1:n]\n\n    # Right endpoint interpolation:\n    AR = [ In H H^2 H^3 ];\n    vR = y[2:n+1]\n\n    # Continuity of first derivative:\n    A1 = E*[ Z J 2*H 3*H^2 ]\n    v1 = zeros(n-1)\n\n    # Continuity of second derivative:\n    A2 = E*[ Z Z J 3*H ]\n    v2 = zeros(n-1)\n\n    # Not-a-knot conditions:\n    nakL = [ zeros(1,3*n) [1 -1 zeros(1,n-2)] ]\n    nakR = [ zeros(1,3*n) [zeros(1,n-2) 1 -1] ]\n\n    # Assemble and solve the full system.\n    A = [ AL; AR; A1; A2; nakL; nakR ]\n    v = [ vL; vR; v1; v2; 0; 0 ]\n    z = A\\v\n\n    # Break the coefficients into separate vectors.\n    rows = 1:n\n    a = z[rows]\n    b = z[n.+rows];  c = z[2*n.+rows];  d = z[3*n.+rows]\n    S = [ Polynomial([a[k],b[k],c[k],d[k]]) for k in 1:n ]\n\n    # This function evaluates the spline when called with a value\n    # for x.\n    return function (x)\n        if x < t[1] || x > t[n+1]    # outside the interval\n            return NaN\n        elseif x==t[1]\n            return y[1]\n        else\n            k = findlast(x .> t)    # last node to the left of x\n            return S[k](x-t[k])\n        end\n    end\nend\n\nFornberg’s algorithm for finite difference weights\n\n\"\"\"\n    fdweights(t,m)\n\nCompute weights for the `m`th derivative of a function at zero using\nvalues at the nodes in vector `t`.\n\"\"\"\nfunction fdweights(t,m)\n# This is a compact implementation, not an efficient one.\n    # Recursion for one weight. \n    function weight(t,m,r,k)\n        # Inputs\n        #   t: vector of nodes \n        #   m: order of derivative sought \n        #   r: number of nodes to use from t \n        #   k: index of node whose weight is found\n\n        if (m<0) || (m>r)        # undefined coeffs must be zero\n            c = 0\n        elseif (m==0) && (r==0)  # base case of one-point interpolation\n            c = 1\n        else                     # generic recursion\n            if k<r\n                c = (t[r+1]*weight(t,m,r-1,k) -\n                    m*weight(t,m-1,r-1,k))/(t[r+1]-t[k+1])\n            else\n                numer = r > 1 ? prod(t[r]-x for x in t[1:r-1]) : 1\n                denom = r > 0 ? prod(t[r+1]-x for x in t[1:r]) : 1\n                β = numer/denom\n                c = β*(m*weight(t,m-1,r-1,r-1) - t[r]*weight(t,m,r-1,r-1))\n            end\n        end\n        return c\n    end\n    r = length(t)-1\n    w = zeros(size(t))\n    return [ weight(t,m,r,k) for k=0:r ]\nend\n\nTrapezoid formula for numerical integration\n\n\"\"\"\n    trapezoid(f,a,b,n)\n\nApply the trapezoid integration formula for integrand `f` over\ninterval [`a`,`b`], broken up into `n` equal pieces. Returns\nthe estimate, a vector of nodes, and a vector of integrand values at the\nnodes.\n\"\"\"\nfunction trapezoid(f,a,b,n)\n    h = (b-a)/n\n    t = range(a,b,length=n+1)\n    y = f.(t)\n    T = h * ( sum(y[2:n]) + 0.5*(y[1] + y[n+1]) )\n    return T,t,y\nend\n\nAdaptive integration\n\n\"\"\"\n    intadapt(f,a,b,tol)\n\nAdaptively integrate `f` over [`a`,`b`] to within target error \ntolerance `tol`. Returns the estimate and a vector of evaluation \nnodes.\n\"\"\"\nfunction intadapt(f,a,b,tol,fa=f(a),fb=f(b),m=(a+b)/2,fm=f(m))\n    # Use error estimation and recursive bisection.\n    # These are the two new nodes and their f-values.\n    xl = (a+m)/2;  fl = f(xl);\n    xr = (m+b)/2;  fr = f(xr);\n    \n    # Compute the trapezoid values iteratively.\n    h = (b-a)\n    T = [0.,0.,0.]\n    T[1] = h*(fa+fb)/2\n    T[2] = T[1]/2 + (h/2)*fm\n    T[3] = T[2]/2 + (h/4)*(fl+fr)\n    \n    S = (4T[2:3]-T[1:2]) / 3      # Simpson values\n    E = (S[2]-S[1]) / 15           # error estimate\n    \n    if abs(E) < tol*(1+abs(S[2]))  # acceptable error?\n        Q = S[2]                   # yes--done\n        nodes = [a,xl,m,xr,b]      # all nodes at this level\n    else\n        # Error is too large--bisect and recurse.\n        QL,tL = intadapt(f,a,m,tol,fa,fm,xl,fl)\n        QR,tR = intadapt(f,m,b,tol,fm,fb,xr,fr)\n        Q = QL + QR\n        nodes = [tL;tR[2:end]]   # merge the nodes w/o duplicate\n    end\n    return Q,nodes\nend\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.","type":"content","url":"/chapter5#functions","position":3},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"type":"lvl2","url":"/chapter5#examples","position":4},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"content":"\n\nimport Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter5#examples","position":5},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-1","position":6},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.1","lvl2":"Examples"},"content":"Trouble in polynomial interpolation\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5\nt = range(-1, 1, length=n + 1)\ny = @. t^2 + t + 0.05 * sin(20 * t)\n\nscatter(t, y, label=\"data\", leg=:top)\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\np = Polynomials.fit(t, y, n)     # interpolating polynomial\nplot!(p, -1, 1, label=\"interpolant\")\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = range(-1, 1, length=n + 1)\ny = @. t^2 + t + 0.05 * sin(20 * t)\n\nscatter(t, y, label=\"data\", leg=:top)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = Polynomials.fit(t, y, n)\nx = range(-1, 1, length=1000)    # use a lot of points\nplot!(x, p.(x), label=\"interpolant\")\n\nSurely there must be functions that are more intuitively representative of those points!\n\nPiecewise polynomial interpolation\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 12\nt = range(-1, 1, length=n + 1)\ny = @. t^2 + t + 0.5 * sin(20 * t)\n\nscatter(t, y, label=\"data\", leg=:top)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\np = FNC.plinterp(t, y)\nplot!(p, -1, 1, label=\"piecewise linear\")\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\np = Spline1D(t, y)\nplot!(x -> p(x), -1, 1, label=\"piecewise cubic\")\n\nConditioning of interpolation\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18\nt = range(-1, stop=1, length=n + 1)\ny = [zeros(9); 1; zeros(n - 9)];  # data for 10th cardinal function\n\nscatter(t, y, label=\"data\")\n\nϕ = Spline1D(t, y)\nplot!(x -> ϕ(x), -1, 1, label=\"spline\",\n    xlabel=L\"x\", ylabel=L\"\\phi(x)\",\n    title=\"Piecewise cubic cardinal function\")\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nscatter(t, y, label=\"data\")\n\nϕ = Polynomials.fit(t, y, n)\nplot!(x -> ϕ(x), -1, 1, label=\"polynomial\",\n    xlabel=L\"x\", ylabel=L\"\\phi(x)\", legend=:top,\n    title=\"Polynomial cardinal function\")\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/chapter5#section-5-1","position":7},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-2","position":8},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.2","lvl2":"Examples"},"content":"A look at hat functions\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1]\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nUse annotate! to add text to a plot.\n\nplt = plot(layout=(4, 1), legend=:top,\n    xlabel=L\"x\", ylims=[-0.1, 1.1], ytick=[])\nfor k in 0:3\n    Hₖ = FNC.hatfun(t, k)\n    plot!(Hₖ, 0, 1, subplot=k + 1)\n    scatter!(t, Hₖ.(t), m=3, subplot=k + 1)\n    annotate!(t[k+1], 0.25, text(latexstring(\"H_$k\"), 10), subplot=k + 1)\nend\nplt\n\nUsing piecewise linear interpolation\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = x -> exp(sin(7 * x))\n\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]    # nodes\ny = f.(t)                             # function values\n\nscatter!(t, y, label=\"values at nodes\")\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"PL interpolation\")\n\nConvergence of piecewise linear interpolation\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = x -> exp(sin(7 * x))\nx = range(0, 1, length=10001)  # sample the difference at many points\nn = @. round(Int, 10^(1:0.25:3.5))\nmaxerr = zeros(0)\nfor n in n\n    t = (0:n) / n    # interpolation nodes\n    p = FNC.plinterp(t, f.(t))\n    err = @. f(x) - p(x)\n    push!(maxerr, norm(err, Inf))\nend\n\ndata = (n=n[1:4:end], err=maxerr[1:4:end])\npretty_table(data, header=[\"n\", \"max-norm error\"])\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nh = @. 1 / n\norder2 = @. 10 * (h / h[1])^2\n\nplot(h, maxerr, m=:o, label=\"error\")\nplot!(h, order2, l=:dash, label=L\"O(h^2)\", xflip=true,\n    xaxis=(:log10, L\"h\"), yaxis=(:log10, L\"|| f-p\\, ||_\\infty\"),\n    title=\"Convergence of PL interpolation\")","type":"content","url":"/chapter5#section-5-2","position":9},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-3","position":10},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.3","lvl2":"Examples"},"content":"Cubic splines\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nf = x -> exp(sin(7 * x))\n\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]  # nodes\ny = f.(t)                           # values at nodes\n\nscatter!(t, y, label=\"values at nodes\")\n\nS = FNC.spinterp(t, y)\n\nplot!(S, 0, 1, label=\"spline\")\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000) / 1e4              # sample the difference at many points\nn = @. round(Int, 2^(3:0.5:7))  # numbers of nodes\nerr = zeros(0)\nfor n in n\n    t = (0:n) / n\n    S = FNC.spinterp(t, f.(t))\n    dif = @. f(x) - S(x)\n    push!(err, norm(dif, Inf))\nend\n\npretty_table((; n, err), header=[\"n\", \"error\"])\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = @. (n / n[1])^(-4)\n\nplot(n, [err order4], m=[:o :none], l=[:solid :dash],\n    label=[\"error\" \"4th order\"],\n    xaxis=(:log10, \"n\"), yaxis=(:log10, L\"|| f-S\\,||_\\infty\"),\n    title=\"Convergence of spline interpolation\")","type":"content","url":"/chapter5#section-5-3","position":11},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-4","position":12},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.4","lvl2":"Examples"},"content":"Finite differences\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = x -> exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / 2h\nCD4 = (f(-2h) - 8f(-h) + 8f(h) - f(2h)) / 12h\n@show (CD2, CD4);\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3f(0) + 4f(h) - f(2h)) / 2h\n@show (FD1, FD2);\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2h) - 4f(-h) + 3f(0)) / 2h\n@show (BD1, BD2);\n\nFinite differences for f''\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = x -> exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2f(0) + f(h)) / h^2\n@show CD2;\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2f(h) + f(2h)) / h^2\nFD2 = (2f(0) - 5f(h) + 4f(2h) - f(3h)) / h^2\n@show (FD1, FD2);\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2h) - 2f(-h) + f(0)) / h^2\nBD2 = (-f(-3h) + 4f(-2h) - 5f(-h) + 2f(0)) / h^2\n@show (BD1, BD2);\n\nFinite differences at arbitrary nodes\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75]   # nodes\nf = x -> cos(x^2)\ndfdx = x -> -2 * x * sin(x^2)\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t .- 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f.(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nFNC.fdweights(0:3, 1)\n\nBy giving nodes of type Rational, we can get exact values instead.\n\nFNC.fdweights(Rational.(0:3), 1)","type":"content","url":"/chapter5#section-5-4","position":13},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-5","position":14},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.5","lvl2":"Examples"},"content":"Convergence of finite differences\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = x -> sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = [5 / 10^n for n in 1:6]\nFD1 = [];\nFD2 = [];\nfor h in h\n    push!(FD1, (f(h) - f(0)) / h)\n    push!(FD2, (f(h) - f(-h)) / 2h)\nend\n\npretty_table([h FD1 FD2], header=[\"h\", \"FD1\", \"FD2\"])\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerror_FD1 = @. exact_value - FD1\nerror_FD2 = @. exact_value - FD2\ntable = [h error_FD1 error_FD2]\npretty_table(table, header=[\"h\", \"error in FD1\", \"error in FD2\"])\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nplot(h, abs.([error_FD1 error_FD2]), m=:o, label=[\"FD1\" \"FD2\"],\n    xflip=true, xaxis=(:log10, L\"h\"), yaxis=(:log10, \"error\"),\n    title=\"Convergence of finite differences\", leg=:bottomleft)\n\n# Add lines for perfect 1st and 2nd order.\nplot!(h, [h h .^ 2], l=:dash, label=[L\"O(h)\" L\"O(h^2)\"])\n\nRoundoff error in finite differences\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = x -> exp(-1.3 * x);\nexact = -1.3\n\nh = [1 / 10^n for n in 1:12]\nFD1, FD2, FD4 = [], [], []\nfor h in h\n    nodes = h * (-2:2)\n    vals = @. f(nodes)\n    push!(FD1, dot([0 0 -1 1 0] / h, vals))\n    push!(FD2, dot([0 -1 / 2 0 1 / 2 0] / h, vals))\n    push!(FD4, dot([1 / 12 -2 / 3 0 2 / 3 -1 / 12] / h, vals))\nend\n\ntable = [h FD1 FD2 FD4]\npretty_table(table[1:4, :], header=[\"h\", \"FD1\", \"FD2\", \"FD4\"])\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = @. abs([FD1 FD2 FD4] - exact)\n\nplot(h, err, m=:o, label=[\"FD1\" \"FD2\" \"FD4\"],\n    xaxis=(:log10, L\"h\"), xflip=true, yaxis=(:log10, \"error\"),\n    title=\"FD error with roundoff\", legend=:bottomright)\n\n# Add line for perfect 1st order.\nplot!(h, 0.1 * eps() ./ h, l=:dash, color=:black, label=L\"O(h^{-1})\")\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/chapter5#section-5-5","position":15},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-6","position":16},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.6","lvl2":"Examples"},"content":"Numerical integration\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe Julia package QuadGK has an all-purpose numerical integrator that estimates the value without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nQ, errest = quadgk(x -> exp(x), 0, 1)\n@show Q;\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quadgk(x -> exp(sin(x)), 0, 1)\n@show Q;\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nplot([exp, x -> exp(sin(x))], 0, 1, fill=0, layout=(2, 1),\n    xlabel=L\"x\", ylabel=[L\"e^x\" L\"e^{\\sin(x)}\"], ylim=[0, 2.7])\n\nTrapezoid integration\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = x -> exp(sin(7 * x));\na = 0;\nb = 2;\n\nIn lieu of the exact value, we use the QuadGK package to find an accurate result.:::{card}\nIf a function has multiple return values, you can use an underscore `_` to indicate a  return value you want to ignore.\n\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14);\nprintln(\"Integral = $Q\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\n@show (T, Q - T);\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = [10^n for n in 1:5]\nerr = []\nfor n in n\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    push!(err, Q - T)\nend\n\npretty_table([n err], header=[\"n\", \"error\"])\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nplot(n, abs.(err), m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"error\"),\n    title=\"Convergence of trapezoidal integration\")\n\n# Add line for perfect 2nd order.\nplot!(n, 3e-3 * (n / n[1]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\n\nIntegration by extrapolation\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = x -> x^2 * exp(-2 * x);\na = 0;\nb = 2;\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14)\n@show Q;\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       # the coarsest formula\nn = N;\nh = (b - a) / n;\nt = h * (0:n);\ny = f.(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = [h * (sum(y[2:n]) + y[1] / 2 + y[n+1] / 2)]\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nWe can repeat the same code to double n again.\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = [(4T[i+1] - T[i]) / 3 for i in 1:2]\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16S[2] - S[1]) / 15\n\nWe can make a triangular table of the errors:\n\nThe value nothing equals nothing except nothing.\n\nerr = [T .- Q [nothing; S .- Q] [nothing; nothing; R - Q]]\npretty_table(err, header=[\"order 2\", \"order 4\", \"order 6\"])\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/chapter5#section-5-6","position":17},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#section-5-7","position":18},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.7","lvl2":"Examples"},"content":"Motivation for adaptive integration\n\nThis function gets increasingly oscillatory as x increases.\n\nf = x -> (x + 1)^2 * cos((2 * x + 1) / (x - 4.3))\nplot(f, 0, 4, xlabel=L\"x\", ylabel=L\"f(x)\")\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nleft_val, _ = quadgk(f, 0, 2, atol=1e-14, rtol=1e-14)\nright_val, _ = quadgk(f, 2, 4, atol=1e-14, rtol=1e-14)\n\nn = [50 * 2^k for k in 0:3]\nleft_err, right_err = [], []\nfor n in n\n    T, _ = FNC.trapezoid(f, 0, 2, n)\n    push!(left_err, T - left_val)\n\n    T, _ = FNC.trapezoid(f, 2, 4, n)\n    push!(right_err, T - right_val)\nend\n\npretty_table([n left_err right_err], header=[\"n\", \"left error\", \"right error\"])\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nUsing adaptive integration\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = x -> (x + 1)^2 * cos((2 * x + 1) / (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nA, t = FNC.intadapt(f, 0, 4, 0.001)\n@show num_nodes = length(t);\n\nplot(f, 0, 4, color=:black, legend=:none,\n    xlabel=L\"x\", ylabel=L\"f(x)\", title=\"Adaptive node selection\")\nplot!(t, f.(t), seriestype=:sticks, m=(:o, 2))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nQ, _ = quadgk(f, 0, 4, atol=1e-14, rtol=1e-14);    # 'exact' value\nprintln(\"error: $(Q-A)\");\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = [1 / 10^k for k in 4:14]\nerr, n = [], []\nfor tol in 10.0 .^ (-4:-1:-14)\n    A, t = FNC.intadapt(f, 0, 4, tol)\n    push!(err, Q - A)\n    push!(n, length(t))\nend\n\npretty_table([tol err n], header=[\"tolerance\", \"error\", \"number of nodes\"])\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nplot(n, abs.(err), m=:o, label=\"results\",\n    xaxis=(:log10, \"number of nodes\"), yaxis=(:log10, \"error\"),\n    title=\"Convergence of adaptive integration\")\n\norder4 = @. 0.01 * (n / n[1])^(-4)\nplot!(n, order4, l=:dash, label=L\"O(n^{-4})\")","type":"content","url":"/chapter5#section-5-7","position":19},{"hierarchy":{"lvl1":"Chapter 6"},"type":"lvl1","url":"/chapter6","position":0},{"hierarchy":{"lvl1":"Chapter 6"},"content":"","type":"content","url":"/chapter6","position":1},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"type":"lvl2","url":"/chapter6#functions","position":2},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"content":"Euler’s method for an initial-value problem\n\n\"\"\"\n    euler(ivp,n)\n\nApply Euler's method to solve the given IVP using `n` time steps.\nReturns a vector of times and a vector of solution values.\n\"\"\"\nfunction euler(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initial condition and output setup.\n    u = fill(float(ivp.u0),n+1)\n\n    # The time stepping iteration.\n    for i in 1:n\n        u[i+1] = u[i] + h*ivp.f(u[i],ivp.p,t[i])\n    end\n    return t,u\nend\n\nAbout the code\n\nThe ivp input argument is an ODEProblem, like in \n\nDemo 6.1.2. It has fields ivp.f, ivp.tspan, ivp.u0, and ivp.p that fully define the problem. The outputs are vectors of the nodes and approximate solution values at those nodes.\n\nImproved Euler method for an IVP\n\n\"\"\"\n    ie2(ivp,n)\n\nApply the Improved Euler method to solve the given IVP using `n`\ntime steps. Returns a vector of times and a vector of solution\nvalues.\n\"\"\"\nfunction ie2(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initialize output.\n    u = fill(float(ivp.u0),n+1)\n\n    # Time stepping.\n    for i in 1:n\n        uhalf = u[i] + h/2*ivp.f(u[i],ivp.p,t[i]);\n        u[i+1] = u[i] + h*ivp.f(uhalf,ivp.p,t[i]+h/2);\n    end\n    return t,u\nend\n\nFourth-order Runge-Kutta for an IVP\n\n\"\"\"\n    rk4(ivp,n)\n\nApply the common Runge-Kutta 4th order method to solve the given\nIVP using `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk4(ivp,n)\n\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initialize output.\n    u = fill(float(ivp.u0),n+1)\n\n    # Time stepping.\n    for i in 1:n\n        k₁ = h*ivp.f( u[i],      ivp.p, t[i]     )\n        k₂ = h*ivp.f( u[i]+k₁/2, ivp.p, t[i]+h/2 )\n        k₃ = h*ivp.f( u[i]+k₂/2, ivp.p, t[i]+h/2 )\n        k₄ = h*ivp.f( u[i]+k₃,   ivp.p, t[i]+h   )\n        u[i+1] = u[i] + (k₁ + 2(k₂+k₃) + k₄)/6\n    end\n    return t,u\nend\n\nAdaptive IVP solver based on embedded RK formulas\n\n\"\"\"\n    rk23(ivp,tol)\n\nApply an adaptive embedded RK formula pair to solve given IVP with\nestimated error `tol`. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk23(ivp,tol)\n    # Initialize for the first time step.\n    a,b = ivp.tspan\n    t = [a]\n    u = [float(ivp.u0)];   i = 1;\n    h = 0.5*tol^(1/3)\n    s₁ = ivp.f(ivp.u0,ivp.p,a)\n\n    # Time stepping.\n    while t[i] < b\n        # Detect underflow of the step size.\n        if t[i]+h == t[i]\n            @warn \"Stepsize too small near t=$(t[i])\"\n            break  # quit time stepping loop\n        end\n\n        # New RK stages.\n        s₂ = ivp.f( u[i]+(h/2)*s₁,   ivp.p, t[i]+h/2   )\n        s₃ = ivp.f( u[i]+(3h/4)*s₂, ivp.p, t[i]+3h/4 )\n        unew3 = u[i] + h*(2s₁  + 3s₂ + 4s₃)/9   # 3rd order solution\n        s₄ = ivp.f( unew3, ivp.p, t[i]+h )\n        err = h*(-5s₁/72 + s₂/12 + s₃/9 - s₄/8)  # 2nd/3rd difference\n        E = norm(err,Inf)                         # error estimate\n        maxerr = tol*(1 + norm(u[i],Inf))     # relative/absolute blend\n\n        # Accept the proposed step?\n        if E < maxerr     # yes\n            push!(t,t[i]+h)\n            push!(u,unew3)\n            i += 1\n            s₁ = s₄       # use FSAL property\n        end\n\n        # Adjust step size.\n        q = 0.8*(maxerr/E)^(1/3)   # conservative optimal step factor\n        q = min(q,4)               # limit stepsize growth\n        h = min(q*h,b-t[i])        # don't step past the end\n    end\n    return t,u\nend\n\nAbout the code\n\nThe check t[i]+h == t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\n4th-order Adams–Bashforth formula for an IVP\n\n\"\"\"\n    ab4(ivp,n)\n\nApply the Adams-Bashforth 4th order method to solve the given IVP\nusing `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction ab4(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Constants in the AB4 method.\n    k = 4;   σ = [55,-59,37,-9]/24;\n\n    # Find starting values by RK4.\n    u = fill(float(ivp.u0),n+1)\n    rkivp = ODEProblem(ivp.f,ivp.u0,(a,a+(k-1)*h),ivp.p)\n    ts,us = rk4(rkivp,k-1)\n    u[1:k] .= us\n\n    # Compute history of u' values, from newest to oldest.\n    f = [ ivp.f(u[k-i],ivp.p,t[k-i]) for i in 1:k-1  ]\n\n    # Time stepping.\n    for i in k:n\n        f = [ ivp.f(u[i],ivp.p,t[i]), f[1:k-1]... ]   # new value of du/dt\n        u[i+1] = u[i] + h*sum(f[j]*σ[j] for j in 1:k)  # advance a step\n    end\n    return t,u\nend\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\n\"\"\"\n    am2(ivp,n)\n\nApply the Adams-Moulton 2nd order method to solve given IVP using\n`n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction am2(ivp,n)\n    # Time discretization.\n    a,b = ivp.tspan\n    h = (b-a)/n\n    t = [ a + i*h for i in 0:n ]\n\n    # Initialize output.\n    u = fill(float(ivp.u0),n+1)\n\n    # Time stepping.\n    for i in 1:n\n        # Data that does not depend on the new value.\n        known = u[i] + h/2*ivp.f(u[i],ivp.p,t[i])\n        # Find a root for the new value.\n        g = z -> z - h/2*ivp.f(z,ivp.p,t[i+1]) - known\n        unew = levenberg(g,known)\n        u[i+1] = unew[end]\n    end\n    return t,u\nend\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/chapter6#functions","position":3},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"type":"lvl2","url":"/chapter6#examples","position":4},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"content":"\n\nimport Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter6#examples","position":5},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-1","position":6},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.1","lvl2":"Examples"},"content":"Solving an IVP\n\nThe DifferentialEquations package offers solvers for IVPs. Let’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nBecause many practical problems come with parameters that are fixed within an instance but varied from one instance to another, the syntax for IVPs includes a input argument p that stays fixed throughout the solution. Here we don’t want to use that argument, but it must be in the definition for the solver to work.\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf(u, p, t) = sin((t + u)^2)     # defines du/dt, must include p argument\nu₀ = -1.0                       # initial value\ntspan = (0.0, 4.0)               # t interval\n\nWith the data above we define an IVP problem object and then solve it. Here we tell the solver to use the Tsit5 method, which is a good first choice for most problems.\n\nivp = ODEProblem(f, u₀, tspan)\nsol = solve(ivp, Tsit5());\n\nThe resulting solution object can be shown using plot.\n\nplot(sol, label=\"solution\", legend=:bottom,\n    xlabel=\"t\", ylabel=L\"u(t)\", title=L\"u'=\\sin((t+u)^2)\")\n\nThe solution also acts like any callable function that can be evaluated at different values of t.\n\n@show sol(1.0);\n\nUnder the hood, the solution object holds some information about how the values and plot are produced:\n\n[sol.t sol.u]\n\nThe solver initially finds approximate values of the solution (second column above) at some automatically chosen times (first column above). To compute the solution at other times, the object performs an interpolation on those values. This chapter is about how the discrete t and u values are computed. For now, just note how we can extract them from the solution object.\n\nscatter!(sol.t, sol.u, label=\"discrete values\")\n\nFinite-time singularity\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nf(u, p, t) = (t + u)^2\n\nivp = ODEProblem(f, 1.0, (0.0, 1.0))\nsol = solve(ivp, Tsit5());\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nplot(sol, label=\"\",\n    xlabel=L\"t\", yaxis=(:log10, L\"u(t)\"), title=\"Finite-time blowup\")\n\nConditioning of an IVP\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = range(0, 3, length=800)\nu = @. exp(t) * 1\nlower, upper = @. exp(t) * 0.7, @. exp(t) * 1.3\nplot(t, u, l=:black, ribbon=(lower, upper),\n    leg=:none, xlabel=L\"t\", ylabel=L\"u(t)\",\n    title=\"Exponential divergence of solutions\")\n\nBut with u'=-u, solutions actually get closer together with time.\n\nu = @. exp(-t) * 1\nlower, upper = @. exp(-t) * 0.7, @. exp(-t) * 1.3\nplot(t, u, l=:black, ribbon=(lower, upper),\n    leg=:none, xlabel=L\"t\", ylabel=L\"u(t)\",\n    title=\"Exponential convergence of solutions\")\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.","type":"content","url":"/chapter6#section-6-1","position":7},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-2","position":8},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.2","lvl2":"Examples"},"content":"Convergence of Euler’s method\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf(u, p, t) = sin((t + u)^2);\ntspan = (0.0, 4.0);\nu0 = -1.0;\n\nivp = ODEProblem(f, u0, tspan)\n\nHere is the call to \n\nFunction 6.2.2.\n\nt, u = FNC.euler(ivp, 20)\n\nplot(t, u, m=2, label=\"n=20\",\n    xlabel=L\"t\", ylabel=L\"u(t)\", title=\"Solution by Euler's method\")\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(ivp, 50)\nplot!(t, u, m=2, label=\"n=50\")\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a DifferentialEquations solver to construct an accurate reference solution.\n\nu_exact = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14)\n\nplot!(u_exact, l=(2, :black), label=\"reference\")\n\nNow we can perform a convergence study.\n\nn = [round(Int, 5 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.euler(ivp, n)\n    push!(err, norm(u_exact.(t) - u, Inf))\nend\n\npretty_table((n=n, err=err), header=[\"n\", \"Inf-norm error\"])\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nplot(n, err, m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"Inf-norm global error\"),\n    title=\"Convergence of Euler's method\")\n\n# Add line for perfect 1st order.\nplot!(n, 0.05 * (n / n[1]) .^ (-1), l=:dash, label=L\"O(n^{-1})\")","type":"content","url":"/chapter6#section-6-2","position":9},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-3","position":10},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.3","lvl2":"Examples"},"content":"Predator-prey model\n\nWe encode the predator–prey equations via a function.\n\nfunction predprey(u, p, t)\n    α, β = p      # rename parameters for convenience\n    y, z = u      # rename solution components\n    s = (y * z) / (1 + β * y)     # appears in both equations\n    return [y * (1 - α * y) - s, -z + s]\nend;\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable.\n\nu₀ = [1, 0.01]\ntspan = (0.0, 60.0)\nα, β = 0.1, 0.25\n\nivp = ODEProblem(predprey, u₀, tspan, [α, β])\n\nYou can use any DifferentialEquations solver on the IVP system.\n\nsol = solve(ivp, Tsit5());\nplot(sol, label=[\"prey\" \"predator\"], title=\"Predator-prey solution\")\n\nWe can find the discrete values used to compute the interpolated solution. The sol.u value is a vector of vectors.\n\nt, u = sol.t, sol.u    # extract times and solution values\n@show size(u);\n@show t[20];\n@show u[20];\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt, u = FNC.euler(ivp, 1200);\n\nThe solution u is a vector of [prey,predator] 2-vectors for each of the discrete times in t. Manipulating the vector-of-vectors output can be a little tricky. Here, we convert it to an n\\times 2 matrix. Each column is one component, while each row is a single value of t.\n\nu = [u[j] for u in u, j in 1:2]\nplot!(t[1:3:end], u[1:3:end, :], l=(1, :black), m=2,\n    label=[\"Euler prey\" \"Euler predator\"])\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nYou can use idxs in the plot of a solution produced by solve to specify the components of the solution that appear on each axis.\n\nplot(sol, idxs=(1, 2), title=\"Predator-prey in the phase plane\",\n    xlabel=L\"y\", ylabel=L\"z\")\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nCoupled pendulums\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nThe similar function creates an array of the same size and type as a given value, without initializing the contents.\n\nfunction couple(u, p, t)\n    γ, L, k = p\n    g = 9.8\n    udot = similar(u)\n    udot[1:2] .= u[3:4]\n    udot[3] = -γ * u[3] - (g / L) * sin(u[1]) + k * (u[2] - u[1])\n    udot[4] = -γ * u[4] - (g / L) * sin(u[2]) + k * (u[1] - u[2])\n    return udot\nend\n\nu₀ = [1.25, -0.5, 0, 0]\ntspan = (0.0, 50.0);\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nHere idxs is used to plot two components as functions of time.\n\nγ, L, k = 0, 0.5, 0\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], title=\"Uncoupled pendulums\")\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 1\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], title=\"Coupled pendulums\")\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/chapter6#section-6-3","position":11},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-4","position":12},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.4","lvl2":"Examples"},"content":"Convergence of Runge–Kutta methods\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf(u, p, t) = sin((t + u)^2)\ntspan = (0.0, 4.0)\nu₀ = -1.0\n\nivp = ODEProblem(f, u₀, tspan)\n\nWe use a DifferentialEquations solver to construct an accurate approximation to the exact solution.\n\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = [round(Int, 2 * 10^k) for k in 0:0.5:3]\nerr_IE2, err_RK4 = [], []\nfor n in n\n    t, u = FNC.ie2(ivp, n)\n    push!(err_IE2, maximum(@.abs(u_ref(t) - u)))\n    t, u = FNC.rk4(ivp, n)\n    push!(err_RK4, maximum(@.abs(u_ref(t) - u)))\nend\n\npretty_table([n err_IE2 err_RK4], header=[\"n\", \"IE2 error\", \"RK4 error\"])\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nplot([2n 4n], [err_IE2 err_RK4], m=3, label=[\"IE2\" \"RK4\"],\n    xaxis=(:log10, \"f-evaluations\"), yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of RK methods\", leg=:bottomleft)\n\nplot!(2n, 1e-5 * (n / n[end]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\nplot!(4n, 1e-10 * (n / n[end]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/chapter6#section-6-4","position":13},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-5","position":14},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.5","lvl2":"Examples"},"content":"Adaptive step size\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nf(u, p, t) = exp(t - u * sin(u))\nivp = ODEProblem(f, 0, (0.0, 5.0))\nt, u = FNC.rk23(ivp, 1e-5)\n\nplot(t, u, m=2,\n    xlabel=L\"t\", ylabel=L\"u(t)\", title=\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nΔt = diff(t)\nplot(t[1:end-1], Δt, title=\"Adaptive step sizes\",\n    xaxis=(L\"t\", (0, 5)), yaxis=(:log10, \"step size\"))\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprintln(\"minimum step size = $(minimum(Δt))\")\n\nOn the other hand, the average step size that was actually taken was\n\nprintln(\"average step size = $(sum(Δt)/(length(t)-1))\")\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nAdaptive step size near a singularity\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\nf(u, p, t) = (t + u)^2\nivp = ODEProblem(f, 1, (0.0, 1.0))\nt, u = FNC.rk23(ivp, 1e-5);\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nplot(t, u, legend=:none,\n    xlabel=L\"t\", yaxis=(:log10, L\"u(t)\"), title=\"Finite-time blowup\")\n\ntf = t[end]\nvline!([tf], l=:dash)\nannotate!(tf, 1e5, latexstring(@sprintf(\"t = %.6f \", tf)), :right)","type":"content","url":"/chapter6#section-6-5","position":15},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-6","position":16},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.6","lvl2":"Examples"},"content":"Convergence of Adams–Bashforth\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve is called to give an accurate reference solution.\n\nivp = ODEProblem((u, p, t) -> sin((t + u)^2), -1.0, (0.0, 4.0))\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of the AB4 code.\n\nn = @. [round(Int, 4 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.ab4(ivp, n)\n    push!(err, norm(u_ref.(t) - u, Inf))\nend\n\npretty_table([n err], header=[\"n\", \"inf-norm error\"])\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nplot(n, err, m=3, label=\"AB4\",\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of AB4\", leg=:bottomleft)\n\nplot!(n, (n / n[1]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nStiffness\n\nThe following simple ODE uncovers a surprise.\n\nivp = ODEProblem((u, p, t) -> u^2 - u^3, 0.005, (0, 400.0))\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(ivp, 200)\n\nplot(tI, uI, label=\"AM2\",\n    xlabel=L\"t\", ylabel=L\"u(t)\", leg=:bottomright)\n\nNow we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(ivp, 200)\n\nscatter!(tE, uE, m=3, label=\"AB4\", ylim=[-4, 2])\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[105:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplt = scatter(tI, uI, label=\"AM2, n=200\", m=3,\n    xlabel=L\"t\", ylabel=L\"u(t)\", leg=:bottomright)\n\nfor n in [1000, 1600]\n    tE, uE = FNC.ab4(ivp, n)\n    plot!(tE, uE, label=\"AM4, n=$n\")\nend\nplt\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!","type":"content","url":"/chapter6#section-6-6","position":17},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#section-6-7","position":18},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.7","lvl2":"Examples"},"content":"Instability\n\nWe’ll measure the error at the time t=1.\n\ndu_dt(u, t) = u\nû = exp\na, b = 0.0, 1.0;\nn = [5, 10, 20, 40, 60]\nerr = []\nt, u = [], []\nfor n in n\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n    u = [1; û(h); zeros(n - 1)]\n    f_val = [du_dt(u[1], t[1]); zeros(n)]\n    for i in 2:n\n        f_val[i] = du_dt(u[i], t[i])\n        u[i+1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f_val[i] + 2 * f_val[i-1])\n    end\n    push!(err, abs(û(b) - u[end]))\nend\n\npretty_table([n (b - a) ./ n err], header=[\"n\", \"h\", \"error\"])\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nplot(t, abs.(u), m=3, label=\"\",\n    xlabel=L\"t\", yaxis=(:log10, L\"|u(t)|\"), title=\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.","type":"content","url":"/chapter6#section-6-7","position":19},{"hierarchy":{"lvl1":"Chapter 7"},"type":"lvl1","url":"/chapter7","position":0},{"hierarchy":{"lvl1":"Chapter 7"},"content":"","type":"content","url":"/chapter7","position":1},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"type":"lvl2","url":"/chapter7#examples","position":2},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"content":"\n\nimport Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter7#examples","position":3},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#section-7-1","position":4},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.1","lvl2":"Examples"},"content":"Adjacency matrix\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nThe graphplot function makes a visual representation of this graph.\n\ngraphplot(A, names=1:4, markersize=0.2, arrow=6)\n\nSince this adjacency matrix is not symmetric, the edges are all directed, as indicated by the arrows. Here are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0]\ngraphplot(A, names=1:4, markersize=0.2)\n\nImages as matrices\n\nThe Images package has many functions for image manipulation, and TestImages has some standard images to play with.\n\nimg = testimage(\"mandrill\")\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nimg[100, 10]\n\nYou can use eltype to find out the type of the elements of any array.\n\neltype(img)\n\nIt’s possible to extract matrices of red, green, and blue intensities, scaled from 0 to 1.\n\nR, G, B = red.(img), green.(img), blue.(img);\n@show minB, maxB = extrema(B);\n\nOr we can convert the pixels to gray, each pixel again scaled from 0 to 1.\n\nGray.(img)\n\nIn order to do our usual operations, we need to tell Julia that we want to interpret the elements of the image matrix as floating-point values.\n\nA = Float64.(Gray.(img))\nA[1:4, 1:5]\n\nWe can use Gray to reinterpret a matrix of floating-point values as grayscale pixels.\n\nGray.(reverse(A, dims=1))","type":"content","url":"/chapter7#section-7-1","position":5},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#section-7-2","position":6},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.2","lvl2":"Examples"},"content":"Eigenvalues and eigenvectors\n\nThe eigvals function returns a vector of the eigenvalues of a matrix.\n\nA = π * ones(2, 2)\n\nλ = eigvals(A)\n\nIf you want the eigenvectors as well, use eigen.\n\nλ, V = eigen(A)\n\nnorm(A * V[:, 2] - λ[2] * V[:, 2])\n\nBoth functions allow you to sort the eigenvalues by specified criteria.\n\nA = diagm(-2.3:1.7)\n@show eigvals(A, sortby=real);\n@show eigvals(A, sortby=abs);\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1]\nλ, V = eigen(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nopnorm(A * V - V * diagm(λ))\n\nEigenvalue conditioning\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7\nA = randn(n, n) + 1im * randn(n, n)\nA = (A + A') / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nλ, V = eigen(A)\n@show cond(V);\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones.\n\nSince the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = 1:n\nA = triu(x * ones(n)')\nA[1:5, 1:5]\n\nThis matrix is not especially close to normal.\n\nλ, V = eigen(A)\n@show cond(V);\n\nAs a result, the eigenvalues can change by a good deal more.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\nBF_bound = cond(V) * norm(ΔA)\n@show maximum(dist), BF_bound;\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nplt = scatter(λ, zeros(n), aspect_ratio=1)\nfor _ in 1:200\n    ΔA = eps(Float32) * normalize(randn(n, n) + 1im * randn(n, n))\n    λ̃ = eigvals(A + ΔA)\n    scatter!(real(λ̃), imag(λ̃), m=1, color=:black)\nend\nplt\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nFrancis QR iteration\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diagm([-6, -1, 2, 4, 5])\nV, R = qr(randn(5, 5))    # V is unitary\nA = V * D * V'\n\neigvals(A)\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\neigvals(A)\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in 1:40\n    Q, R = qr(A)\n    A = R * Q\nend\nA","type":"content","url":"/chapter7#section-7-2","position":7},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#section-7-3","position":8},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.3","lvl2":"Examples"},"content":"SVD properties\n\nWe verify some of the fundamental SVD properties using standard Julia functions from LinearAlgebra.\n\nA = [i^j for i = 1:5, j = 0:3]\n\nTo get only the singular values, use svdvals.\n\nσ = svdvals(A)\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\n@show opnorm(A, 2);\n@show σ[1];\n\n@show cond(A, 2);\n@show σ[1] / σ[end];\n\nTo get singular vectors as well, use svd. The thin form of the factorization is the default.\n\nU, σ, V = svd(A);\n@show size(U);\n@show size(V);\n\nWe verify the orthogonality of the singular vectors as follows:\n\n@show opnorm(U' * U - I);\n@show opnorm(V' * V - I);","type":"content","url":"/chapter7#section-7-3","position":9},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#section-7-4","position":10},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.4","lvl2":"Examples"},"content":"Rayleigh quotient\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nλ = 1:n\nD = diagm(λ)\nV, _ = qr(randn(n, n))   # get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = x -> (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nR(V[:, 7])\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nδ = @. 1 ./ 10^(1:5)\neval_diff = zeros(size(δ))\nfor (k, delta) in enumerate(δ)\n    e = randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 7] + e\n    eval_diff[k] = R(x) - 7\nend\nlabels = [\"perturbation δ\", \"δ²\", \"R(x) - λ\"]\npretty_table([δ δ .^ 2 eval_diff], header=labels)","type":"content","url":"/chapter7#section-7-4","position":11},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#section-7-5","position":12},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.5","lvl2":"Examples"},"content":"Image compression\n\nWe make an image from some text, then reload it as a matrix.\n\nplot(annotations=(0.5, 0.5, text(\"Hello world\", 44, :center, :center)),\n    grid=:none, frame=:none, size=(400, 150))\nsavefig(\"hello.png\")\nimg = load(\"hello.png\")\nA = @. Float64(Gray(img))\nGray.(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=45.\n\nU, σ, V = svd(A)\nscatter(σ, xaxis=(L\"i\"), yaxis=(:log10, L\"\\sigma_i\"),\n    title=\"Singular values\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nplt = plot(layout=(2, 2), frame=:none, aspect_ratio=1, titlefontsize=10)\nfor i in 1:4\n    k = 3i\n    Ak = U[:, 1:k] * diagm(σ[1:k]) * V[:, 1:k]'\n    plot!(Gray.(Ak), subplot=i, title=\"rank = $k\")\nend\nplt\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\nm, n = size(A)\ncompression = m * n / (9 * (m + n + 1))\n\nDimension reduction in voting records\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\n@load \"voting.jld2\" A;\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nheatmap(A, color=:viridis,\n    title=\"Votes in 111th U.S. Senate\", xlabel=\"bill\", ylabel=\"senator\")\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, σ, V = svd(A)\nτ = cumsum(σ .^ 2) / sum(σ .^ 2)\nscatter(τ[1:16], xaxis=(\"k\"), yaxis=(L\"\\tau_k\"),\n    title=\"Fraction of singular value energy\")\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nscatter(U[:, 1], label=\"\", layout=(1, 2),\n    xlabel=\"senator\", title=\"left singular vector\")\nscatter!(V[:, 1], label=\"\", subplot=2,\n    xlabel=\"bill\", title=\"right singular vector\")\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = A * V[:, 1];\nx2 = A * V[:, 2];\n\n@load \"voting.jld2\" Rep Dem Ind\nRep = vec(Rep);\nDem = vec(Dem);\nInd = vec(Ind);\nscatter(x1[Dem], x2[Dem], color=:blue, label=\"D\",\n    xaxis=(\"partisanship\"), yaxis=(\"bipartisanship\"), title=\"111th US Senate by voting record\")\nscatter!(x1[Rep], x2[Rep], color=:red, label=\"R\")\nscatter!(x1[Ind], x2[Ind], color=:yellow, label=\"I\")","type":"content","url":"/chapter7#section-7-5","position":13},{"hierarchy":{"lvl1":"Chapter 8"},"type":"lvl1","url":"/chapter8","position":0},{"hierarchy":{"lvl1":"Chapter 8"},"content":"","type":"content","url":"/chapter8","position":1},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"type":"lvl2","url":"/chapter8#functions","position":2},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"content":"Power iteration\n\n\"\"\"\n    poweriter(A,numiter)\n\nPerform `numiter` power iterations with the matrix `A`, starting\nfrom a random vector. Returns a vector of eigenvalue estimates\nand the final eigenvector approximation.\n\"\"\"\nfunction poweriter(A,numiter)\n    n = size(A,1)\n    x = normalize(randn(n),Inf)\n    β = zeros(numiter)\n    for k in 1:numiter\n        y = A*x\n        m = argmax(abs.(y))\n        β[k] = y[m]/x[m]\n        x = y/y[m]\n    end\n    return β,x\nend\n\nInverse iteration\n\n\"\"\"\n    inviter(A,s,numiter)\n\nPerform `numiter` inverse iterations with the matrix `A` and shift\n`s`, starting from a random vector. Returns a vector of\neigenvalue estimates and the final eigenvector approximation.\n\"\"\"\nfunction inviter(A,s,numiter)\n    n = size(A,1)\n    x = normalize(randn(n),Inf)\n    β = zeros(numiter)\n    fact = lu(A - s*I)\n    for k in 1:numiter\n        y = fact\\x\n        normy,m = findmax(abs.(y))\n        β[k] = x[m]/y[m] + s\n        x = y/y[m]\n    end\n    return β,x\nend\n\nArnoldi iteration\n\n\"\"\"\n    poweriter(A,numiter)\n\nPerform `numiter` power iterations with the matrix `A`, starting\nfrom a random vector. Returns a vector of eigenvalue estimates\nand the final eigenvector approximation.\n\"\"\"\nfunction poweriter(A,numiter)\n    n = size(A,1)\n    x = normalize(randn(n),Inf)\n    β = zeros(numiter)\n    for k in 1:numiter\n        y = A*x\n        m = argmax(abs.(y))\n        β[k] = y[m]/x[m]\n        x = y/y[m]\n    end\n    return β,x\nend\n\nAbout the code\n\nThe loop starting at line 17 does not exactly implement \n\n(8.4.7) and . The reason is numerical stability. Though the described and implemented versions are mathematically equivalent in exact arithmetic (see \n\nExercise 6), the approach in \n\nFunction 8.4.2 is more stable.\n\nGMRES\n\n\"\"\"\n    gmres(A,b,m)\n\nDo `m` iterations of GMRES for the linear system `A`*x=`b`. Returns\nthe final solution estimate x and a vector with the history of\nresidual norms. (This function is for demo only, not practical use.)\n\"\"\"\nfunction gmres(A,b,m)\n    n = length(b)\n    Q = zeros(n,m+1)\n    Q[:,1] = b/norm(b)\n    H = zeros(m+1,m)\n\n    # Initial solution is zero.\n    x = 0\n    residual = [norm(b);zeros(m)]\n\n    for j in 1:m\n        # Next step of Arnoldi iteration.\n        v = A*Q[:,j]\n        for i in 1:j\n            H[i,j] = dot(Q[:,i],v)\n            v -= H[i,j]*Q[:,i]\n        end\n        H[j+1,j] = norm(v)\n        Q[:,j+1] = v/H[j+1,j]\n\n        # Solve the minimum residual problem.\n        r = [norm(b); zeros(j)]\n        z = H[1:j+1,1:j] \\ r\n        x = Q[:,1:j]*z\n        residual[j+1] = norm( A*x - b )\n    end\n    return x,residual\nend","type":"content","url":"/chapter8#functions","position":3},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"type":"lvl2","url":"/chapter8#examples","position":4},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"content":"\n\nimport Pkg; Pkg.activate(\"/Users/driscoll/Documents/GitHub/fnc\")\nusing FundamentalsNumericalComputation\nFNC.init_format()\n\n","type":"content","url":"/chapter8#examples","position":5},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-1","position":6},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"content":"Sparsity\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\n@load \"roswell.jld2\" A;      # file is on the book's website\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nUse nnz to count the number of nonzeros in a sparse matrix.\n\nm, n = size(A)\n@show density = nnz(A) / (m * n);\n\nThe computer memory consumed by any variable can be discovered using summarysize. We can use it to compare the space needed for the sparse representation to its dense counterpart, that is, the space needed to store all the elements, whether zero or not.\n\nF = Matrix(A)\nBase.summarysize(F) / Base.summarysize(A)\n\nAs you can see, the storage savings are dramatic. Matrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nx = randn(n)\nA * x;   # make sure * is loaded and compiled\n@elapsed for i in 1:300\n    A * x\nend\n\nF * x;\n@elapsed for i in 1:300\n    F * x\nend\n\nFill-in of a sparse matrix\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\n@load \"smallworld.jld2\" A\ngraphplot(A, linealpha=0.5)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nspy(A, title=\"Nonzero locations\", m=2, color=:blues)\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nplt = plot(layout=(1, 3), legend=:none, size=(600, 240))\nfor k in 2:4\n    spy!(A^k, subplot=k - 1, color=:blues,\n        title=latexstring(\"\\\\mathbf{A}^$k\"))\nend\nplt\n\nBanded matrices\n\nThe spdiagm function creates a sparse matrix given its diagonal elements. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50;\nA = spdiagm(-3 => fill(n, n - 3),\n    0 => ones(n),\n    1 => -(1:n-1),\n    5 => fill(0.1, n - 5))\nMatrix(A[1:7, 1:7])\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nThe sparse function converts any matrix to sparse form. But it’s usually better to construct a sparse matrix directly, as the standard form might not fit in memory.\n\nL, U = FNC.lufact(A)\nplot(layout=2)\nspy!(sparse(L), m=2, subplot=1, title=L\"\\mathbf{L}\", color=:blues)\nspy!(sparse(U), m=2, subplot=2, title=L\"\\mathbf{U}\", color=:blues)\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\nfact = lu(A)\nplot(layout=2)\nspy!(sparse(fact.L), m=2, subplot=1, title=L\"\\mathbf{L}\", color=:blues)\nspy!(sparse(fact.U), m=2, subplot=2, title=L\"\\mathbf{U}\", color=:blues)\n\nEigenvalues of sparse matrices\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nλ = @. 1 + 1 / (1:n)   # exact eigenvalues\nA = FNC.sprandsym(n, density, λ);\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=:LM.\n\nλmax, V = eigs(A, nev=5, which=:LM)    # Largest Magnitude\nfmt = ft_printf(\"%20.15f\")\npretty_table([λmax λ[1:5]], header=[\"found\", \"exact\"], formatters=fmt)\n\nNow we find the 5 closest to the value 1 in the complex plane, via sigma=1.\n\nλ1, V = eigs(A, nev=5, sigma=1)    # closest to sigma\ndata = [λ1 λ[end:-1:end-4]]\npretty_table(data, header=[\"found\", \"exact\"], formatters=fmt)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nx = @. 1 / (1:n);\nb = A * x;\n\nnorm(x - A \\ b);  # force compilation\nt = @elapsed sparse_err = norm(x - A \\ b)\nprintln(\"Time for sparse solve: $t\")\n\nD = Matrix(A)  # convert to regular matrix\nnorm(x - D \\ b);\nt = @elapsed dense_err = norm(x - D \\ b)\nprintln(\"Time for dense solve: $t\")\n\n@show sparse_err;\n@show dense_err;","type":"content","url":"/chapter8#id-8-1","position":7},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-2","position":8},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"content":"Power iteration\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = rand(1.0:9.0, 5, 5)\nA = A ./ sum(A, dims=1)\nx = randn(5)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A * x\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A * y\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nThis phenomenon seems to occur regardless of the starting vector.\n\nx = randn(5)\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nConvergence of power iteration\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run the power iteration 60 times. The best estimate of the dominant eigenvalue is the last entry of the first output.\n\nβ, x = FNC.poweriter(A, 60)\neigval = β[end]\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = @. 1 - β\nplot(0:59, abs.(err), m=:o, title=\"Convergence of power iteration\",\n    xlabel=L\"k\", yaxis=(L\"|\\lambda_1-\\beta_k|\", :log10, [1e-10, 1]))\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\n@show theory = λ[2] / λ[1];\n@show observed = err[40] / err[39];\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nβ[26:30]\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = @. β[end] - β[1:end-1]\nplot(0:58, abs.(err), m=:o, title=\"Convergence of power iteration\",\n    xlabel=L\"k\", yaxis=(L\"|\\beta_{60}-\\beta_k|\", :log10, [1e-10, 1]))\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.","type":"content","url":"/chapter8#id-8-2","position":9},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-3","position":10},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"content":"Convergence of inverse iteration\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run inverse iteration with the shift s=0.7 and take the final estimate as our “exact” answer to observe the convergence.\n\ns = 0.7\nβ, x = FNC.inviter(A, s, 30)\neigval = β[end]\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nerr = @. abs(eigval - β)\nplot(0:28, err[1:end-1], m=:o,\n    title=\"Convergence of inverse iteration\",\n    xlabel=L\"k\", yaxis=(L\"|\\lambda_3-\\beta_k|\", :log10, [1e-16, 1]))\n\nThe observed linear convergence rate is found from the data.\n\n@show observed_rate = err[22] / err[21];\n\nWe reorder the eigenvalues to enforce \n\n(8.3.3).\n\nThe sortperm function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nλ = λ[sortperm(abs.(λ .- s))]\n\nHence the theoretical convergence rate is\n\n@show theoretical_rate = (λ[1] - s) / (λ[2] - s);\n\nDynamic shift strategy\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\ns = 0.7\nx = ones(5)\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = β\nx = y / y[1]\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in 1:4\n    s = β\n    x = y / y[1]\n    y = (A - s * I) \\ x\n    @show β = x[1] / y[1] + s\nend","type":"content","url":"/chapter8#id-8-3","position":11},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-4","position":12},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"content":"Conditioning of the Krylov matrix\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = [b zeros(100, 29)]\nfor m in 1:29\n    v = A * Km[:, m]\n    Km[:, m+1] = v / norm(v)\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nresid = zeros(30)\nfor m in 1:30\n    z = (A * Km[:, 1:m]) \\ b\n    x = Km[:, 1:m] * z\n    resid[m] = norm(b - A * x)\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nplot(0:29, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, L\"\\| b-Ax_m \\|\"),\n    title=\"Residual for linear systems\", leg=:none)\n\nArnoldi iteration\n\nWe illustrate a few steps of the Arnoldi iteration for a small matrix.\n\nA = rand(1.0:9.0, 6, 6)\n\nThe seed vector we choose here determines the first member of the orthonormal basis.\n\nu = randn(6)\nQ = u / norm(u);\n\nMultiplication by \\mathbf{A} gives us a new vector in \\mathcal{K}_2.\n\nAq = A * Q[:, 1];\n\nWe subtract off its projection in the previous direction. The remainder is rescaled to give us the next orthonormal column.\n\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1]\nQ = [Q v / norm(v)];\n\nOn the next pass, we have to subtract off the projections in two previous directions.\n\nAq = A * Q[:, 2]\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1] - dot(Q[:, 2], Aq) * Q[:, 2]\nQ = [Q v / norm(v)];\n\nAt every step, \\mathbf{Q}_m is an ONC matrix.\n\n@show opnorm(Q' * Q - I);\n\nAnd \\mathbf{Q}_m spans the same space as the three-dimensional Krylov matrix.\n\nK = [u A * u A * A * u];\n@show rank([Q K]);","type":"content","url":"/chapter8#id-8-4","position":13},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-5","position":14},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"content":"GMRES\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = [norm(b); zeros(60)]\nfor m in 1:60\n    s = [norm(b); zeros(m)]\n    z = H[1:m+1, 1:m] \\ s\n    x = Q[:, 1:m] * z\n    resid[m+1] = norm(b - A * x)\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nplot(0:60, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, \"norm of mth residual\"),\n    title=\"Residual for GMRES\", leg=:none)\n\nRestarting GMRES\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nA = FNC.poisson(50)\nn = size(A, 1)\nb = ones(n);\nspy(A, color=:blues)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from the IterativeSolvers package, since our simple implementation does not offer restarting.\n\nThe syntax f(x;foo) is shorthand for f(x,foo=foo).\n\nreltol = 1e-12;\nplt = plot(title=\"Convergence of restarted GMRES\", leg=:bottomleft,\n    xaxis=(L\"m\"), yaxis=(:log10, \"residual norm\", [1e-8, 100]))\n\nfor restart in [n, 20, 40, 60]\n    x, hist = IterativeSolvers.gmres(A, b; restart, reltol,\n        maxiter=100, log=true)\n    plot!(hist[:resnorm], label=\"restart = $restart\")\nend\n\nplt\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.","type":"content","url":"/chapter8#id-8-5","position":15},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-6","position":16},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"content":"MINRES\n\nThe following matrix is indefinite.\n\nA = FNC.poisson(10) - 20I\nλ = eigvals(Matrix(A))\nisneg = @. λ < 0\n@show sum(isneg), sum(.!isneg);\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nmn, mx = extrema(-λ[isneg])\nκ₋ = mx / mn\nmn, mx = extrema(λ[.!isneg])\nκ₊ = mx / mn\nρ = (sqrt(κ₋ * κ₊) - 1) / (sqrt(κ₋ * κ₊) + 1)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nb = rand(100)\nx, hist = minres(A, b, reltol=1e-10, maxiter=51, log=true);\n\nrelres = hist[:resnorm] / norm(b)\nm = 0:length(relres)-1\nplot(m, relres, label=\"observed\", leg=:left,\n    xaxis=L\"m\", yaxis=(:log10, \"relative residual\"),\n    title=(\"Convergence of MINRES\"))\nplot!(m, ρ .^ (m / 2), l=:dash, label=\"upper bound\")\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nConvergence of MINRES and CG\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, 1 / 100)\nx = (1:n) / n\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from IterativeSolvers.\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = FNC.sprandsym(n, density, 1 / 2500)\nb = A * x;\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.","type":"content","url":"/chapter8#id-8-6","position":17},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-7","position":18},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"content":"Blurring an image\n\nWe use a readily available test image.\n\nimg = testimage(\"mandrill\")\nm, n = size(img)\nX = @. Float64(Gray(img))\nplot(Gray.(X), title=\"Original image\", aspect_ratio=1)\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nfunction blurmatrix(d)\n    v1 = fill(0.25, d - 1)\n    return spdiagm(0 => fill(0.5, d), 1 => v1, -1 => v1)\nend\nB, C = blurmatrix(m), blurmatrix(n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nblur = X -> B^12 * X * C^12;\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nDeblurring an image\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = testimage(\"lighthouse\")\nm, n = size(img)\nX = @. Float64(Gray(img))\n\nB = spdiagm(0 => fill(0.5, m),\n    1 => fill(0.25, m - 1), -1 => fill(0.25, m - 1))\nC = spdiagm(0 => fill(0.5, n),\n    1 => fill(0.25, n - 1), -1 => fill(0.25, n - 1))\nblur = X -> B^12 * X * C^12\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\n# vec (built-in) converts matrix to vector\nunvec = z -> reshape(z, m, n);  # convert vector to matrix\n\nNow we declare the three-step blur transformation as a LinearMap, supplying also the size of the vector form of an image.\n\nT = LinearMap(x -> vec(blur(unvec(x))), m * n);\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nThe function clamp01 in Images restricts values to be in the interval [0,1].\n\ny = minres(T, vec(Z), maxiter=50, reltol=1e-5);\nY = unvec(clamp01.(y))\n\nplot(Gray.(X), layout=2, title=\"Original\")\nplot!(Gray.(Y), subplot=2, title=\"Deblurred\")","type":"content","url":"/chapter8#id-8-7","position":19},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-8","position":20},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"content":"Diagonal preconditioning\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nA = matrixdepot(\"wathen\", 60)\nn = size(A, 1)\n@show n, nnz(A);\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nb = ones(n)\nM = DiagonalPreconditioner(diag(A));\n\nWe now compare CG with and without the preconditioner.\n\nplain(b) = cg(A, b, maxiter=200, reltol=1e-4, log=true)\ntime_plain = @elapsed x, hist1 = plain(b)\nprec(b) = cg(A, b, Pl=M, maxiter=200, reltol=1e-4, log=true)\ntime_prec = @elapsed x, hist2 = prec(b)\n@show time_plain, time_prec\n\nrr = hist1[:resnorm]\nplot(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"plain\")\nrr = hist2[:resnorm]\nplot!(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"preconditioned\")\ntitle!(\"Diagonal preconditioning in CG\")\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\nIncomplete LU preconditioning\n\nHere is a nonsymmetric matrix arising from a probabilistic model in computational chemistry.\n\nA = sparse(matrixdepot(\"Watson/chem_master1\"))\nn = size(A, 1)\n@show n, nnz(A), issymmetric(A)\n\nWithout a preconditioner, GMRES makes essentially no progress after 100 iterations.\n\nb = rand(40000)\nconst GMRES = IterativeSolvers.gmres\nx, history = GMRES(A, b, maxiter=100, reltol=1e-5, log=true)\nresnorm = history[:resnorm]\n@show resnorm[end] / resnorm[1];\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\niLU = ilu(A, τ=0.25)\n@show nnz(iLU) / nnz(A);\n\nThe result is almost 10 times as dense as \\mathbf{A} and yet still not a true factorization of it. However, it’s close enough for an approximate inverse in a preconditioner. The actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}, but we just supply the factorization to gmres.\n\n_, history = GMRES(A, b, Pl=iLU, maxiter=100, reltol=1e-5, log=true)\nhistory\n\nThe τ parameter in ilu balances the accuracy of the iLU factorization with the time needed to compute it and invert it. As \\tau\\to 0, more of the elements are kept, making the preconditioner more effective but slower per iteration.\n\nplt = plot(0:40, resnorm[1:41] / resnorm[1], label=\"no preconditioning\",\n    xaxis=(\"iteration number\"), yaxis=(:log10, \"residual norm\"),\n    leg=:bottomright, title=\"Incomplete LU preconditioning\")\nfor τ in [2, 1, 0.25, 0.1]\n    t = @elapsed iLU = ilu(A; τ)\n    t += @elapsed _, history = GMRES(A, b, Pl=iLU, maxiter=100,\n        reltol=1e-5, log=true)\n    resnorm = history[:resnorm]\n    label = \"τ = $τ, time = $(round(t,digits=3))\"\n    plot!(0:length(resnorm)-1, resnorm / resnorm[1]; label)\nend\nplt\n\nIn any given problem, it’s impossible to know in advance where the right balance lies between fidelity and speed for the preconditioner.","type":"content","url":"/chapter8#id-8-8","position":21},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1-1","position":0},{"hierarchy":{"lvl1":"Chapter 1"},"content":"MATLAB implementations","type":"content","url":"/chapter1-1","position":1},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"type":"lvl2","url":"/chapter1-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"content":"Horner’s algorithm for evaluating a polynomial\n\nfunction y = horner(c,x)\r\n% HORNER   Evaluate a polynomial using Horner's rule. \r\n% Input:\r\n%   c     Coefficients of polynomial, in descending order (vector)\r\n%   x     Evaluation point (scalar)\r\n% Output:\r\n%   y     Value of the polynomial at x (scalar)\r\n\r\nn = length(c);\r\ny = c(1);\r\nfor k = 2:n\r\n  y = x*y + c(k);\r\nend","type":"content","url":"/chapter1-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"type":"lvl2","url":"/chapter1-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter1-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Section 1.1"},"type":"lvl2","url":"/chapter1-1#section-1-1","position":6},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Section 1.1"},"content":"Absolute and relative accuracy\n\nRecall the grade-school approximation to the number π.\n\n```{index} MATLAB; format\n```{card}\nThe number of digits displayed is controlled by `format`, but the underlying values are not affected by it.\n\nformat long\np = 22/7\n\nNot all the digits displayed for p are the same as those of π.\n\nThe value of pi is predefined.\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nabs_accuracy = abs(p - pi)\nrel_accuracy = abs(p - pi) / pi\n\nHere we calculate the number of accurate digits in p.\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nformat short\naccurate_digits = -log10(rel_accuracy)\n\nFloating-point representation\n\nIn MATLAB, values are double-precision floats unless declared otherwise.\n\nfprintf('1 has type: %s', class(1))\nfprintf('1.0 has type: %s', class(1.0))\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. Its value is predefined as eps.\n\nWhile you can assign a different value to eps, doing so does not change any arithmetic. It’s generally a bad idea.\n\neps\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps)\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nx = 161.8 + 0.1*eps(161.8);\nx - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\nformat short e\n[realmin, realmax]\n\nFloating-point arithmetic oddity\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\n( 1 + eps / 2 ) - 1\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1 - (1 - eps / 2)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!","type":"content","url":"/chapter1-1#section-1-1","position":7},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.2","lvl2":"Section 1.1"},"type":"lvl3","url":"/chapter1-1#section-1-2","position":8},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.2","lvl2":"Section 1.1"},"content":"Conditioning of polynomial roots\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nep = 1e-6;\na = 1/3;             % coefficients of p...\nb = (-2 - ep) / 3;   % ...\nc = (1 + ep) / 3;    % ...in ascending order\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4*a*c);\nformat long   % show all digits\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative errors are\n\nPutting values inside square brackets creates a vector.\n\nformat short e\nerr = abs(r1 - 1) ./ abs(1)\nerr = abs(r2 - (1 + ep)) ./ abs(1 + ep)\n\nThe condition number of each root is\n\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}. \n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps / ep\n\nThis matches the observation pretty well.","type":"content","url":"/chapter1-1#section-1-2","position":9},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.3","lvl2":"Section 1.1"},"type":"lvl3","url":"/chapter1-1#section-1-3","position":10},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.3","lvl2":"Section 1.1"},"content":"Using a function\n\nHere we show how to use \n\nFunction 1.3.1 to evaluate a polynomial. Let us define a vector of the coefficients of p(x)=(x-1)^3=x^3-3x^2+3x-1, in ascending degree order.\n\nc = [1, -3, 3, 1]\n\nNow we evaluate p(1.6) using the function horner.\n\nhorner(c, 1.6)\n\nThe result above is the value of p(1.6).\n\nTip\n\nThe comments at the start of \n\nFunction 1.3.1 are documentation, which we can access using help horner.","type":"content","url":"/chapter1-1#section-1-3","position":11},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.4","lvl2":"Section 1.1"},"type":"lvl3","url":"/chapter1-1#section-1-4","position":12},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.4","lvl2":"Section 1.1"},"content":"Instability of the quadratic formula\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23 * 10^4.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a)\nx2 = (-b - sqrt(b^2 - 4*a*c)) / (2*a)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(x2 - 1e-6) / 1e-6 \naccurate_digits = -log10(error)\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nStable alternative to the quadratic formula\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a);\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a*x1)\n\nThis matches the exact root to the displayed digits; to be sure we have an accurate result, we compute its relative error.\n\nabs(x2 - 1e-6) / 1e-6\n\nBackward error\n\nOur first step is to construct a polynomial with six known roots.\n\nThe ' operator is used for transposition. Here, we want to make r a column vector.\n\nr = [-2 ,-1, 1, 1, 3, 6]';\np = poly(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nrr = sort(roots(p))\n\nHere are the relative errors in each of the computed roots.\n\nThe ./ operator is used for element-wise division.\n\ndisp(\"Root errors:\") \nabs(r - rr) ./ r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\npp = poly(rr)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\ndisp(\"Coefficient errors:\") \nabs(p - pp) ./ abs(p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.","type":"content","url":"/chapter1-1#section-1-4","position":13},{"hierarchy":{"lvl1":"Chapter 2"},"type":"lvl1","url":"/chapter2-1","position":0},{"hierarchy":{"lvl1":"Chapter 2"},"content":"MATLAB implementations","type":"content","url":"/chapter2-1","position":1},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"type":"lvl2","url":"/chapter2-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"content":"Forward substitution\n\nfunction x = forwardsub(L,b)\r\n% FORWARDSUB   Solve a lower triangular linear system.\r\n% Input:\r\n%   L    lower triangular square matrix (n by n)\r\n%   b    right-hand side vector (n by 1)   \r\n% Output:\r\n%   x    solution of Lx=b (n by 1 vector)\r\n\r\nn = length(L);\r\nx = zeros(n,1);\r\nfor i = 1:n\r\n  x(i) = ( b(i) - L(i,1:i-1) * x(1:i-1) ) / L(i,i);\r\nend\n\nAbout the code\n\nLine 12 implements \n\n(2.3.7). It contains an inner product between row i of \\mathbf{L} and the solution vector \\mathbf{x}, using only the entries of \\mathbf{x} that have already been computed.\n\nBackward substitution\n\nfunction x = backsub(U,b)\r\n% BACKSUB   Solve an upper triangular linear system.\r\n% Input:\r\n%   U    upper triangular square matrix (n by n)\r\n%   b    right-hand side vector (n by 1)   \r\n% Output:\r\n%   x    solution of Ux=b (n by 1 vector)\r\n\r\nn = length(U);\r\nx = zeros(n,1);\r\nfor i = n:-1:1\r\n  x(i) = ( b(i) - U(i,i+1:n)*x(i+1:n) ) / U(i,i);\r\nend\n\nLU factorization (not stable)\n\nfunction [L, U] = lufact(A)\r\n% LUFACT   LU factorization (demo only--not stable!).\r\n% Input:\r\n%   A    square matrix\r\n% Output:\r\n%   L,U  unit lower triangular and upper triangular such that LU=A\r\n\r\nn = size(A, 1);     % detect the dimensions from the input\r\nL = eye(n);         % ones on main diagonal, zeros elsewhere\r\nU = zeros(n, n);\r\nA_k = A;            % make a working copy \r\n\r\n% Reduction by outer products\r\nfor k = 1:n-1\r\n    U(k, :) = A_k(k, :);\r\n    L(:, k) = A_k(:,k) / U(k, k);\r\n    A_k = A_k -  L(:, k) * U(k, :);\r\nend\r\nU(n, n) = A_k(n, n);\r\nL = tril(L); U = triu(U);    % force exact triangularity\n\nLU factorization with partial pivoting\n\nfunction [L, U, p] = plufact(A)\n% PLUFACT   Pivoted LU factorization \n% Input:\n%   A    square matrix\n% Output:\n%   L    unit lower triangular \n%   U    upper triangular\n%   p    row permutation vector such that A(p,:) = L*U\nn = size(A, 1);\nL = zeros(n, n);\nU = zeros(n, n);\np = zeros(1, n);\nA_k = A;\n\n% Reduction by outer products\nfor k = 1:n\n    [~, p(k)] = max(abs(A_k(:, k)));\n    U(k, :) = A_k(p(k), :);\n    L(:, k) = A_k(:, k) / U(k, k);\n    if k < n\n        A_k = A_k - L(:, k) * U(k, :);\n    end\nend\nL = tril(L(p, :));\nU = triu(U);","type":"content","url":"/chapter2-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"type":"lvl2","url":"/chapter2-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter2-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-1","position":6},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.1","lvl2":"Examples"},"content":"Linear system for polynomial interpolation\n\nWe create two column vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982; 2000; 2010; 2015]; \npop = [1008.18; 1262.64; 1337.82; 1374.62];\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980;\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V * c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in descending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\np = @(t) polyval(c, t - 1980);  % include the 1980 time shift\np(2005)\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nscatter(year, y)\nxlabel(\"years since 1980\")\nylabel(\"population (millions)\")\ntitle(\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval.\n\nThe linspace function constructs evenly spaced values given the endpoints and the number of values.\n\ntt = linspace(1980, 2015, 500);    % 500 times in the interval [1980, 2015]\nyy = p(tt);                        % evaluate p at all the vector elements\nyy(1:4)\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nUse hold on to add to an existing plot rather than replacing it.\n\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\n\nhold on \nplot(tt, yy)\nlegend(\"data\", \"interpolant\", \"location\", \"northwest\")","type":"content","url":"/chapter2-1#section-2-1","position":7},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-2","position":8},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.2","lvl2":"Examples"},"content":"Matrix operations\n\nIn MATLAB, every numerical value is treated like a matrix. A matrix with one row or one column is interpreted as a vector, and a 1\\times 1 matrix is interpreted as a scalar.\n\nSquare brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ \n    1       2      3             4      5; \n    50     40     30            20     10\n    pi sqrt(2) exp(1) (1+sqrt(5))/2 log(3) \n    ]\n\nm, n = size(A)\n\nx = [ 3, 3, 0, 1, 0 ];   % row vector\nsize(x)\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              % start:stop\n\nz = 0:3:12           % start:step:stop\n\nInstead of specifying the step size, you can give the number of points in the range if you use linspace.\n\ns = linspace(-1, 1, 5)    % row result\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within parentheses.\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A(2, end-1)\n\nx(2)\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA(1:2, end-2:end)    % first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA(:, 1:2:end)        % all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nUse diag to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diag([-1, 0, -5])   % create a diagonal matrix\n\nsize(A)\nsize(B)\n\nBA = B * A     % matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nErrors are formally called exceptions in Julia.\n\nA * B    % throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    % same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x .^ 2\n\ntwo_to_x = 2 .^ x\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, can operate elementwise on vectors and matrices.\n\ncos(pi * x)","type":"content","url":"/chapter2-1#section-2-2","position":9},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-3","position":10},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.3","lvl2":"Examples"},"content":"Solving linear systems\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1; 2; 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A*x\n\nIf the matrix \\mathbf{A} is singular, you may get a warning and nonsense result.\n\nA = [0 1; 0 0]\nb = [1; -1]\nx = A \\ b\n\nIn this case, we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nTriangular systems of equations\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = randi(9, 5, 5);\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5);\nx = forwardsub(L, b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext, we’ll engineer a problem to which we know the exact answer.\n\nThe eye function creates an identity matrix. The diag function uses 0 as the main diagonal, positive integers as superdiagonals, and negative integers as subdiagonals.\n\nalpha = 0.3;\nbeta = 2.2;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta]\n\nx_exact = ones(5);\nb = [alpha; 0; 0; 0; 1];\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = backsub(U, b);\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta];\nb = [alpha; 0; 0; 0; 1];\n\nx = backsub(U, b);\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.","type":"content","url":"/chapter2-1#section-2-3","position":11},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-4","position":12},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.4","lvl2":"Examples"},"content":"Triangular outer products\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( randi(9, 3, 3) )\n\nU = triu( randi(9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nL(:, 1) * U(1, :)\n\nL(:, 2) * U(2, :)\n\nL(:, 3) * U(3, :)\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nLU factorization\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = eye(4);\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU(1, :) = A_1(1, :)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL(:, 1) = A_1(:, 1) / U(1, 1)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU(2, :) = A_2(2, :)\nL(:, 2) = A_2(:, 2) / U(2, 2)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU(3, :) = A_3(3, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\nFinally, we pick up the last unknown in the factors.\n\nU(4, 4) = A_4(4, 4);\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L * U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nSolving a linear system by LU factors\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4; 9; 9; 4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\n[L, U] = lufact(A)\nz = forwardsub(L, b);\nx = backsub(U, z);\n\nA check on the residual assures us that we found the solution.\n\nb - A * x","type":"content","url":"/chapter2-1#section-2-4","position":13},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-5","position":14},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.5","lvl2":"Examples"},"content":"Floating-point operations in matrix-vector multiplication\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6;\nA = magic(n);\nx = ones(n,1);\ny = zeros(n,1);\nfor i = 1:n\n    for j = 1:n\n        y(i) = y(i) + A(i,j)*x(j);   % 2 flops\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication, using tic and toc to time the operation.\n\nn_ = (400:400:4000)';\nt_ = zeros(size(n_));\nfor i = 1:length(n_)\n    n = n_(i);\n    A = randn(n, n);  x = randn(n, 1);\n    tic    % start a timer\n    for j = 1:100      % repeat 100 times\n        A*x;\n    end\n    t = toc;           % read the timer\n    t_(i) = t / 100;   % seconds per instance\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\ntable(n_, t_, 'variablenames', {'size', 'time'})\n\nLooking at the timings just for n=2000 and n=4000, they have ratio\n\nThe expression n_==4000 here produces a vector of Boolean (true/false) values the same size as n_. This result is used to index within t_, accessing only the value for which the comparison is true.\n\nt_(n_==4000) / t_(n_==2000)\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nAsymptotics in log-log plots\n\nLet’s repeat the previous experiment for more, and larger, values of n.\n\nn_ = (400:400:6000)';\nt_ = zeros(size(n_));\nfor i = 1:length(n_)\n    n = n_(i);\n    A = randn(n, n);  x = randn(n, 1);\n    tic    % start a timer\n    for j = 1:100      % repeat ten times\n        A*x;\n    end\n    t = toc;          % read the timer\n    t_(i) = t / 100;   % seconds per instance\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nclf    % clear any existing figure\nloglog(n_, t_, '.-')\nxlabel('size of matrix')\nylabel('time (sec)')\ntitle('Timing of matrix-vector multiplications')\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nhold on\nloglog(n_, t_(1) * (n_ / n_(1)).^2, '--')\naxis tight\nlegend('data', 'O(n^2)', 'location', 'southeast')\n\nFloating-point operations in LU factorization\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nn_ = (200:100:2400)';\nt_ = zeros(size(n_));\nfor i = 1:length(n_)\n    n = n_(i);\n    A = randn(n, n);  \n    tic    % start a timer\n    for j = 1:6,  [L, U] = lu(A);  end\n    t = toc;\n    t_(i) = t / 6;  \nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nclf\nloglog(n_,t_,'.-')\nhold on, loglog(n_,t_(end)*(n_/n_(end)).^3,'--')\naxis tight\nxlabel('size of matrix'), ylabel('time (sec)')\ntitle('Timing of LU factorization')\nlegend('lu','O(n^3)','location','southeast')","type":"content","url":"/chapter2-1#section-2-5","position":15},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-6","position":16},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.6","lvl2":"Examples"},"content":"Failure of naive LU factorization\n\nHere is a previously encountered matrix that factors well.\n\nA = [\n    2 0 4 3\n    -4 5 -7 -10\n    1 15 2 -4.5\n    -2 0 2 -13\n    ];\n[L, U] = lufact(A);\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA([2, 4], :) = A([4, 2], :);    % swap rows 2 and 4\n[L, U] = lufact(A);\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU(1, :) = A(1, :);\nL(:, 1) = A(:, 1) / U(1, 1)\nA = A - L(:, 1) * U(1, :)\n\nThe next step is U(2, :) = A(2, :), which is also OK. But then we are supposed to divide by U(2, 2), which is zero. The algorithm cannot continue.\n\nRow pivoting in LU factorization\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nThe second output of max returns the location of the largest element of a vector. The ~ symbol is used to ignore the value of the first output.\n\n[~, i] = max( abs(A_1(:, 1)) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL = zeros(4, 4);\nU = zeros(4, 4);\nU(1, :) = A_1(i, :);\nL(:, 1) = A_1(:, 1) / U(1, 1);\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n[~, i] = max( abs(A_2(:, 2)) )\nU(2, :) = A_2(i, :);\nL(:, 2) = A_2(:, 2) / U(2, 2);\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n[~, i] = max( abs(A_3(:, 3)) ) \nU(3, :) = A_3(i, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\n[~, i] = max( abs(A_4(:, 4)) ) \nU(4, :) = A_4(i, :);\nL(:, 4) = A_4(:, 4) / U(4, 4);\n\nWe do have a factorization of the original matrix:\n\nA_1 - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nRow permutation in LU factorization\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1. If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A([4, 3, 2, 1], :);\n[L, U] = lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nU\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nL\n\nPLU factorization for solving linear systems\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = randi(20, 4, 4);\n[L, U, p] = plufact(A);\nA(p, :) - L * U    % should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4, 1);\nz = forwardsub(L, b(p));\nx = backsub(U, z)\n\nA residual check is successful:\n\nb - A*x\n\nBuilt-in PLU factorization\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500);    % 500x500 with normal random entries\ntic; for k=1:50; A \\ rand(500, 1); end; toc\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\n[L, U, p] = lu(A, 'vector');    % keep factorization result\ntic\nfor k=1:50\n    b = rand(500, 1);\n    U \\ (L \\ b(p));\nend\ntoc\n\nStability of PLU factorization\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1, 1]:\n\nep = 1e-12\nA = [-ep 1; 1 -1];\nb = A * [1; 1];\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20; A = [-ep 1; 1 -1];\nb = A * [1; 1];\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b","type":"content","url":"/chapter2-1#section-2-6","position":17},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-7","position":18},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.7","lvl2":"Examples"},"content":"Vector norms\n\nx = [2; -3; 1; -1];\ntwonorm = norm(x)    % or norm(x, 2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nMatrix norms\n\nA = [ 2 0; 1 -1 ]\n\nThe default matrix norm is the 2-norm.\n\ntwonorm = norm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = norm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nUse sum to sum along a dimension of a matrix. The max and min functions also work along one dimension.\n\n% Sum down the rows (1st matrix dimension):\nmax( sum(abs(A), 1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = norm(A, Inf)\n\n% Sum across columns (2nd matrix dimension):\nmax( sum(abs(A), 2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nYou can use functions as values, e.g., as elements of a vector.\n\ntheta = linspace(0, 2*pi, 601);\nx = [ cos(theta); sin(theta) ];    % 601 unit column vectors\nclf\nsubplot(1, 2, 1)\nplot(x(1, :), x(2, :)), axis equal\ntitle('Unit circle in 2-norm')\nxlabel('x_1')\nylabel('x_2')\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2:\n\nsubplot(1,2,2), plot(Ax(1,:), Ax(2,:)), axis equal\nhold on, plot(twonorm * x(1,:), twonorm * x(2,:), '--')\ntitle('Image of Ax, with ||A||')\nxlabel('x_1')\nylabel('x_2')","type":"content","url":"/chapter2-1#section-2-7","position":19},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.8","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-8","position":20},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.8","lvl2":"Examples"},"content":"Matrix condition number\n\nMATLAB has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6 case.\n\nA = hilb(6)\nkappa = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = (1:6)';\nb = A * x;\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\ndA = randn(size(A));  dA = 1e-10 * (dA / norm(dA));\ndb = randn(size(b));  db = 1e-10 * (db / norm(db));\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + dA) \\ (b + db));\ndx = new_x - x;\n\nHere is the relative error in the solution.\n\nrelative_error = norm(dx) / norm(x)\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nupper_bound_b = (kappa * norm(db) / norm(b))\nupper_bound_A = (kappa * norm(dA) / norm(A))\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\nrounding_bound = kappa * eps\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = hilb(14);\nkappa = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = kappa * eps\n\nLet’s put that prediction to the test.\n\nx = (1:14)';  b = A * x;\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.","type":"content","url":"/chapter2-1#section-2-8","position":21},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.9","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#section-2-9","position":22},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.9","lvl2":"Examples"},"content":"Banded matrices\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nA = [ 2 -1  0  0  0  0\n      4  2 -1  0  0  0\n      0  3  0 -1  0  0\n      0  0  2  2 -1  0\n      0  0  0  1  1 -1\n      0  0  0  0  0  2 ];\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\ndiag_main = diag(A, 0)'\ndiag_plusone = diag(A, 1)'\ndiag_minusone = diag(A,-1)'We can also put whatever numbers we like onto any diagonal with `diag`.\n\nA = A + diag([5 8 6 7], 2)\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\n[L, U] = lufact(A)\n\nTiming banded LU\n\nIf we use an ordinary or dense matrix, then there’s no way to exploit a banded structure such as tridiagonality.\n\nn = 10000;\nA = diag(1:n) + diag(n-1:-1:1, 1) + diag(ones(n-1, 1), -1);\ntic, [L,U] = lu(A); toc\n\nIf instead we convert the matrix to sparse form, though, the speedup can be dramatic.\n\ntic, [L,U] = lu(sparse(A)); toc\n\nSymmetric LDLT factorization\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = [ 2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4);\nd = zeros(4, 1);\nd(1) = A_1(1, 1);\nL(:, 1) = A_1(:, 1) / d(1);\nA_2 = A_1 - d(1) * L(:, 1) * L(:, 1)'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd(2) = A_2(2, 2);\nL(:, 2) = A_2(:, 2) / d(2);\nA_3 = A_2 - d(2) * L(:, 2) * L(:, 2)'\n\nWe continue working our way down the diagonal.\n\nd(3) = A_3(3, 3);\nL(:, 3) = A_3(:, 3) / d(3);\nA_4 = A_3 - d(3) * L(:, 3) * L(:, 3)'\nd(4) = A_4(4, 4);\nd\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nnorm(A_1 - (L * diag(d) * L'))\n\nCholesky factorization\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = magic(4) + eye(4);\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nThe chol function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix.\n\nWarning\n\nThe chol function does not check for symmetry. It may give a nonsensical result if the input is not symmetric.\n\nchol(B)    % throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A;\nR = chol(B)\n\nHere we validate the factorization:\n\nnorm(R' * R - B) / norm(B)","type":"content","url":"/chapter2-1#section-2-9","position":23},{"hierarchy":{"lvl1":"Chapter 3"},"type":"lvl1","url":"/chapter3-1","position":0},{"hierarchy":{"lvl1":"Chapter 3"},"content":"MATLAB implementations","type":"content","url":"/chapter3-1","position":1},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"type":"lvl2","url":"/chapter3-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"content":"Solution of least squares by the normal equations\n\nfunction x = lsnormal(A,b)\r\n% LSNORMAL   Solve linear least squares by normal equations.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\nN = A'*A;  z = A'*b;\r\nR = chol(N);\r\nw = forwardsub(R',z);                   % solve R'z=c\r\nx = backsub(R,w);                       % solve Rx=z\n\nSolution of least squares by QR factorization\n\nfunction x = lsqrfact(A,b)\r\n% LSQRFACT   Solve linear least squares by QR factorization.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\n[Q,R] = qr(A,0);                        % compressed factorization\r\nc = Q'*b;\r\nx = backsub(R,c);                       \n\nQR factorization by Householder reflections\n\nfunction [Q,R] = qrfact(A)\r\n% QRFACT   QR factorization by Householder reflections.\r\n% (demo only--not efficient)\r\n% Input:\r\n%   A      m-by-n matrix\r\n% Output:\r\n%   Q,R    A=QR, Q m-by-m orthogonal, R m-by-n upper triangular\r\n\r\n[m,n] = size(A);\r\nQ = eye(m);\r\nfor k = 1:n\r\n  z = A(k:m,k);\r\n  v = [ -sign(z(1))*norm(z) - z(1); -z(2:end) ];\r\n  nrmv = norm(v);\r\n  if nrmv < eps, continue, end       % nothing is done in this iteration\r\n  v = v / nrmv;                      % removes v'*v in other formulas\r\n  % Apply the reflection to each relevant column of A and Q\r\n  for j = 1:n\r\n    A(k:m,j) = A(k:m,j) - v*( 2*(v'*A(k:m,j)) );\r\n  end\r\n  for j = 1:m\r\n    Q(k:m,j) = Q(k:m,j) - v*( 2*(v'*Q(k:m,j)) );\r\n  end\r\nend\r\n\r\nQ = Q';\r\nR = triu(A);                         % enforce exact triangularity","type":"content","url":"/chapter3-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"type":"lvl2","url":"/chapter3-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter3-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#section-3-1","position":6},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.1","lvl2":"Examples"},"content":"Interpolating temperature data\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nt = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\nscatter(t, y), axis tight\nxlabel('year')\nylabel('anomaly ({\\circ}C)')\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (t - 1950) / 10;  \nn = length(t);\nV = ones(n, 1);    % t^0\nfor j = 1:n-1\n    V(:, j+1) = t .* V(:,j);\nend\nc = V \\ y;    % solve for coefficients\n\nWe created the Vandermonde matrix columns in increasing-degree order. Thus, the coefficients in c also follow that ordering, which is the opposite of what MATLAB uses. We need to flip the coefficients before using them in polyval.\n\np = @(year) polyval(c(end:-1:1), (year - 1950) / 10);\nhold on\nfplot(p, [1955, 2000])    % plot the interpolating function\n\nFitting temperature data\n\nHere are the 5-year temperature averages again.\n\nyear = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nt = (year - 1955) / 10;    % better matrix conditioning later\nV = [ t.^0 t ];            % Vandermonde-ish matrix\nsize(V)\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\n\nclf\nscatter(year, y), axis tight\nxlabel('year'), ylabel('anomaly ({\\circ}C)')\nhold on\nfplot(f, [1955, 2000])\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [t.^0, t.^1, t.^2, t.^3];    % Vandermonde-ish matrix  \nsize(V)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nThe definition of f above is in terms of c. When c is changed, then f has to be redefined.\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\nfplot(f, [1955, 2000]) \nlegend('data', 'linear', 'cubic', 'Location', 'northwest')\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nFitting a power law\n\nk = (1:100)';\na = 1./k.^2;      % sequence\ns = cumsum(a);    % cumulative summation\np = sqrt(6*s);\nclf\nplot(k, p, 'o-')\nxlabel('k'), ylabel('p_k')\ntitle('Sequence converging to \\pi')\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p);    % error sequence\nloglog(k, ep, 'o')\ntitle('Convergence')\nxlabel('k'), ylabel('|p_k - \\pi|'), axis tight\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = [ k.^0, log(k) ];    % fitting matrix\nc = V \\ log(ep)          % coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na = exp(c(1)),  b = c(2)\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nhold on\nloglog(k, a * k.^b)\nlegend('sequence', 'power-law fit')","type":"content","url":"/chapter3-1#section-3-1","position":7},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#section-3-2","position":8},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.2","lvl2":"Examples"},"content":"Instability in the normal equations\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nkappa = cond(A)\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1; 2; 1];\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b;\nobserved_err = norm(x_BS - x) / norm(x)\nmax_err = kappa * eps\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A'*A;\nx_NE = N\\(A'*b);\nobserved_err = norm(x_NE - x) / norm(x)\ndigits = -log10(observed_err)","type":"content","url":"/chapter3-1#section-3-2","position":9},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#section-3-3","position":10},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.3","lvl2":"Examples"},"content":"QR factorization\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = magic(5);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nHere is the full form:\n\n[Q, R] = qr(A);\nszQ = size(Q), szR = size(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nQTQ = Q' * Q\nnorm(QTQ - eye(m))\n\nWith a second input argument given to qr, the thin form is returned. (This is usually the one we want in practice.)\n\n[Q_hat, R_hat] = qr(A, 0);\nszQ_hat = size(Q_hat), szR_hat = size(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nQ_hat' * Q_hat - eye(n)\n\nStability of least-squares via QR\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nx = [1; 2; 1];\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(lsqrfact(A, b) - x) / norm(x)\nerror_bound = cond(A) * eps","type":"content","url":"/chapter3-1#section-3-3","position":11},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#section-3-4","position":12},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.4","lvl2":"Examples"},"content":"Householder QR factorization\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = magic(6);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A(:, 1);\nv = z - norm(z) * eye(m,1);\nP_1 = eye(m) - 2 / (v' * v) * (v * v');\n\nWe check that this reflector introduces zeros as it should:\n\nP_1 * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A(2:m, 2);\nv = z - norm(z) * eye(m-1, 1);\nP_2 = eye(m-1) - 2 / (v' * v) * (v * v');\n\nWe now apply this reflector to rows 2 and below only.\n\nA(2:m, 2:n) = P_2 * A(2:m, 2:n)\n\nWe need to iterate the process for the last two columns.\n\nfor j = 3:n\n    z = A(j:m,j);\n    k = m-j+1;\n    v = z - norm(z) * eye(k, 1);\n    P = eye(k) - 2 / (v' * v) * (v * v');\n    A(j:m, j:n) = P * A(j:m, j:n);\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = A","type":"content","url":"/chapter3-1#section-3-4","position":13},{"hierarchy":{"lvl1":"Chapter 4"},"type":"lvl1","url":"/chapter4-1","position":0},{"hierarchy":{"lvl1":"Chapter 4"},"content":"","type":"content","url":"/chapter4-1","position":1},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"type":"lvl2","url":"/chapter4-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"content":"Newton’s method\n\nfunction x = newton(f,dfdx,x1)\r\n% NEWTON   Newton's method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   dfdx     derivative function\r\n%   x1       initial root approximation\r\n% Output       \r\n%   x        vector of root approximations (last one is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = x1;  \r\ny = f(x1);\r\ndx = Inf;   % for initial pass below\r\nk = 1;\r\n\r\nwhile (abs(dx) > xtol) && (abs(y) > funtol) && (k < maxiter)\r\n    dydx = dfdx(x(k));\r\n    dx = -y/dydx;           % Newton step\r\n    x(k+1) = x(k) + dx;\r\n\r\n    k = k+1;\r\n    y = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n  warning('Maximum number of iterations reached.')\r\nend\n\nSecant method\n\nfunction x = secant(f,x1,x2)\r\n% SECANT   Secant method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   x1,x2    initial root approximations\r\n% Output       \r\n%   x        vector of root approximations (last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = [x1 x2];\r\ndx = Inf;  y1 = f(x1);\r\nk = 2;  y2 = f(x2);\r\n\r\nwhile (abs(dx) > xtol) && (abs(y2) > funtol) && (k < maxiter)\r\n    dx = -y2 * (x(k)-x(k-1)) / (y2-y1);   % secant step\r\n    x(k+1) = x(k) + dx;\r\n    \r\n    k = k+1;\r\n    y1 = y2;    % current f-value becomes the old one next time\r\n    y2 = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nNewton’s method for systems\n\nfunction x = newtonsys(f,x1)\r\n% NEWTONSYS   Newton's method for a system of equations.\r\n% Input:\r\n%   f        function that computes residual and Jacobian matrix\r\n%   x1       initial root approximation (n-vector)\r\n% Output       \r\n%   x        array of approximations (one per column, last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 1000*eps;  xtol = 1000*eps;  maxiter = 40;\r\n\r\nx = x1(:);  \r\n[y,J] = f(x1);\r\ndx = Inf;\r\nk = 1;\r\n\r\nwhile (norm(dx) > xtol) && (norm(y) > funtol) && (k < maxiter)\r\n    dx = -(J\\y);   % Newton step\r\n    x(:,k+1) = x(:,k) + dx;\r\n\r\n    k = k+1;\r\n    [y,J] = f(x(:,k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nFinite differences for Jacobian\n\nfunction J = fdjac(f,x0,y0)\n% FDJAC   Finite-difference approximation of a Jacobian.\n% Input:\n%   f        function to be differentiated\n%   x0       evaluation point (n-vector)\n%   y0       value of f at x0 (m-vector)\n% Output       \n%   J        approximate Jacobian (m-by-n)\n\ndelta = sqrt(eps);   % FD step size\nm = length(y0);  n = length(x0);\nJ = zeros(m,n);\nI = eye(n);\nfor j = 1:n\n    J(:,j) = ( f(x0+delta*I(:,j)) - y0) / delta;\nend\n\nLevenberg’s method\n\nfunction x = levenberg(f,x1,tol)\r\n% LEVENBERG   Quasi-Newton method for nonlinear systems.\r\n% Input:\r\n%   f         objective function \r\n%   x1        initial root approximation\r\n%   tol       stopping tolerance (default is 1e-12)\r\n% Output       \r\n%   x         array of approximations (one per column)\r\n\r\n% Operating parameters.\r\nif nargin < 3, tol = 1e-12; end\r\nftol = tol;  xtol = tol;  maxiter = 40;\r\n\r\nx = x1(:);     fk = f(x1);\r\nk = 1;  s = Inf;        \r\nAk = fdjac(f,x(:,1),fk);   % start with FD Jacobian\r\njac_is_new = true;\r\nI = eye(length(x));\r\n\r\nlambda = 10; \r\nwhile (norm(s) > xtol) && (norm(fk) > ftol) && (k < maxiter)\r\n    % Compute the proposed step.\r\n    B = Ak'*Ak + lambda*I;\r\n    z = Ak'*fk;\r\n    s = -(B\\z);\r\n\r\n    xnew = x(:,k) + s;   fnew = f(xnew);\r\n    \r\n    % Do we accept the result?\r\n    if norm(fnew) < norm(fk)    % accept\r\n        y = fnew - fk;\r\n        x(:,k+1) = xnew;  fk = fnew;  \r\n        k = k+1;\r\n        \r\n        lambda = lambda/10;  % get closer to Newton\r\n        % Broyden update of the Jacobian.\r\n        Ak = Ak + (y-Ak*s)*(s'/(s'*s));\r\n        jac_is_new = false;\r\n    else                       % don't accept\r\n        % Get closer to steepest descent.\r\n        lambda = lambda*4;\r\n        % Re-initialize the Jacobian if it's out of date.\r\n        if ~jac_is_new\r\n            Ak = fdjac(f,x(:,k),fk);\r\n            jac_is_new = true;\r\n        end\r\n    end\r\nend\r\n\r\nif (norm(fk) > 1e-3)\r\n    warning('Iteration did not find a root.')\r\nend","type":"content","url":"/chapter4-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"type":"lvl2","url":"/chapter4-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter4-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-1","position":6},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.1","lvl2":"Examples"},"content":"The rootfinding problem for Bessel functions\n\nJ3 = @(x) besselj(3,x);\nfplot(J3, [0, 20])\ngrid on\nxlabel('x'), ylabel('J_3(x)')  \ntitle('Bessel function')\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nType \\omega followed by Tab to get the character ω.\n\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nomega = [];\nfor guess = [6, 10, 13, 16, 19]\n    omega = [omega; fzero(J3, guess)];\nend\nomega\n\ntable(omega, J3(omega), 'VariableNames', {'root estimate', 'function value'})\n\nhold on\nscatter(omega, J3(omega))\ntitle('Bessel roots')\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = [];\nfor guess = [3, 6, 10, 13]\n    f = @(x) J3(x) - 0.2;\n    omega = [omega; fzero(f, guess)];\nend\nscatter(omega, J3(omega), '<')\n\nCondition number of a rootfinding problem\n\nConsider first the function\n\nf  = @(x) (x - 1) .* (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nclf\ninterval = [0.8, 1.2];\nfplot(f, interval)\ngrid on, hold on\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\naxis equal \nxlabel('x'), ylabel('f(x)')\ntitle('Well-conditioned root')\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = @(x) (x - 1) .* (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\naxis(axis), cla\nfplot(f, interval)\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\ntitle('Poorly conditioned root')\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!","type":"content","url":"/chapter4-1#section-4-1","position":7},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-2","position":8},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.2","lvl2":"Examples"},"content":"Fixed-point iteration\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5])\n\nWe define g(x)=x-p(x).\n\ng = @(x) x - f(x);\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nclf\nfplot(g, [2, 3])\nhold on,  plot([2, 3], [2, 3], 'k')\ntitle('Finding a fixed point'),  axis equal  \nxlabel('x'),  ylabel('y')\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot([x, y], [y, y], '-')\nx = y;\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\ny = g(x)\nplot([x, x],[x, y], '-')\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot([x, y], [y, y], '-')\n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-')  \nend\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - r(1)) / r(1)\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\ncla\nfplot(g, [1, 2])\nhold on, plot([1, 2], [1, 2], 'k')\nylim([1, 2])\nx = 1.3;  y = g(x);\nfor k = 1:5\n    plot([x, y], [y, y], '-'),  \n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-') \nend\ntitle('No convergence')\n\nThis time, the iteration is pushing us away from the correct answer.\n\nConvergence of fixed-point iteration\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5]);\n\nHere is the fixed point iteration. This time we keep track of the whole sequence of approximations.\n\ng = @(x) x - f(x);\nx = 2.1; \nfor k = 1:12\n    x(k+1) = g(x(k));\nend\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - r(1));\nclf\nsemilogy(err, 'o-'), axis tight\nxlabel('iteration'),  ylabel('error')\ntitle('Convergence of fixed point iteration')\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log(err(5:12));\np = polyfit(5:12, y, 1);\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nsigma = exp(p(1))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr(9:12) ./ err(8:11)\n\nThe methods for finding σ agree well.","type":"content","url":"/chapter4-1#section-4-2","position":9},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-3","position":10},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.3","lvl2":"Examples"},"content":"Graphical interpretation of Newton’s method\n\nSuppose we want to find a root of the function\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0, 1.5])\nxlabel('x'), ylabel('y')    \nset(gca, 'ygrid', 'on')  \ntitle('Objective function')\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1;\ny1 = f(x1)\nhold on, scatter(x1, y1)\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndfdx = @(x) exp(x) .* (x + 1);\nslope1 = dfdx(x1);\ntangent1 = @(x) y1 + slope1 * (x - x1);\nfplot(tangent1, [0, 1.5],'--')\ntitle('Function and tangent line')\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nscatter(x2, 0)\ntitle('Root of the tangent')\n\ny2 = f(x2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\ncla, fplot(f, [0.8, 0.9])\nscatter(x2, y2)\nslope2 = dfdx(x2);\ntangent2 = @(x) y2 + slope2 * (x - x2);\nfplot(tangent2, [0.8, 0.9], '--')\nx3 = x2 - y2 / slope2;\nscatter(x3, 0)\ntitle('Next iteration')\n\ny3 = f(x3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nConvergence of Newton’s method\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = @(x) x.*exp(x) - 2;\ndfdx = @(x) exp(x).*(x+1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nformat long,  r = fzero(f,1)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = 1;\nfor k = 1:6\n    x(k+1) = x(k) - f(x(k)) / dfdx(x(k));\nend\nx\n\nHere is the sequence of errors.\n\nformat short e\nerr = x' - r\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nformat short\nlogerr = log(abs(err))\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nUsing Newton’s method\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nWhen a function is created, it can refer to any variables in scope at that moment. Those values are locked in to the definition, which is called a closure. If the enclosed variables change values later, the function still uses the values it was created with.\n\nh = @(x) exp(x) - x;\ndh_dx = @(x) exp(x) - 1;\ny_ = linspace(h(0), h(2), 200);\nx_ = zeros(size(y_));\nfor i = 1:length(y_)\n    f = @(x) h(x) - y_(i);\n    df_dx = @(x) dh_dx(x);\n    x = newton(f, df_dx, 1);  x_(i) = x(end);\nend\n\nclf, fplot(h, [0, 2])\nhold on, axis equal\nplot(y_, x_)\nplot([0, max(y_)], [0, max(y_)], 'k--')\nxlabel('x'), ylabel('y')\nlegend('h(x)', 'inverse', 'y=x')","type":"content","url":"/chapter4-1#section-4-3","position":11},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-4","position":12},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.4","lvl2":"Examples"},"content":"Graphical interpretation of the secant method\n\nWe return to finding a root of the equation x e^x=2.\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0.25, 1.25])\nset(gca, 'ygrid', 'on')  \nxlabel('x'), ylabel('y')    \ntitle('Objective function')\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1;    y1 = f(x1);\nx2 = 0.5;  y2 = f(x2);\nhold on, scatter([x1, x2], [y1, y2])\ntitle('Two initial values')\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1);\nsecant2 = @(x) y2 + slope2 * (x - x2);\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nfplot(secant2,[0.25, 1.25],'k--')\nx3 = x2 - y2 / slope2;\ny3 = f(x3)\nscatter(x3, 0)\ntitle('Next value')\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope2 = (y3 - y2) / (x3 - x2);\nx4 = x3 - y3 / slope2;\ny4 = f(x4)\n\nConvergence of the secant method\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = @(x) x .* exp(x) - 2;\nx = secant(f, 1, 0.5);\n\nWe don’t know the exact root, so we use fzero to get a good proxy.\n\nr = fzero(f, 1);\n\nHere is the sequence of errors.\n\nformat short e\nerr = r - x(1:end-1)'\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)\n\nAs expected, this settles in at around 1.618.\n\nInverse quadratic interpolation\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = @(x) x + cos(10 * x);\ninterval = [0.5, 1.5];\nclf, fplot(f, interval)\nset(gca, 'ygrid', 'on'), axis(axis)   \ntitle('Objective function')    \nxlabel('x'), ylabel('y')    \nr = fzero(f, 1)\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]';\ny = f(x);\nhold on, scatter(x, y)\ntitle('Three initial points')\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nc = polyfit(x, y, 2);    % coefficients of interpolant\nq = @(x) polyval(c, x);\nfplot(q, interval, '--')\ntitle('Parabola model')\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.:::{card}\nBy giving two functions in the `fplot` call, we get the parametric plot $(q(y),y)$ as a function of $y$.\n\ncla, fplot(f, interval)\nscatter(x, y)     \nc = polyfit(y, x, 2);    % coefficients of interpolating polynomial\nq = @(y) polyval(c, y);\nfplot(q, @(y) y, ylim,'--')    % plot x=q(y), y=y\ntitle('Sideways parabola')\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = [x; q(0)];\ny = [y; f(x(end))]\n\nWe repeat the process a few more times.\n\nfor k = 4:8\n    c = polyfit(y(k-2:k), x(k-2:k), 2);\n    x(k+1) = polyval(c, 0);\n    y(k+1) = f(x(k+1));\nend\ndisp('final residual:')\ny(end)\n\nHere is the sequence of errors.\n\nformat short e\nerr = x - r\n\nThe convergence is probably superlinear:\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)","type":"content","url":"/chapter4-1#section-4-4","position":13},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-5","position":14},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.5","lvl2":"Examples"},"content":"Convergence of Newton’s method for systems\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nThis function needs to be defined within a script file or in a file of its own with the .m extension.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nSince our system function is defined in an external file here, we need to use @ in order to reference it as a function argument.\n\nnlsystem = @f45_nlsystem;\nx1 = [0; 0; 0];    % column vector!\nx = newtonsys(nlsystem, x1);\nnum_iter = size(x, 2)\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x(:, end)\nback_err = norm(nlsystem(r))\n\nWe take the sequence errors in the first component of the solution, applying the log so that we can look at the exponents.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'\n\nThis sequence looks to be nearly doubling at each iteration, which is a good sign of quadratic convergence.","type":"content","url":"/chapter4-1#section-4-5","position":15},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-6","position":16},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.6","lvl2":"Examples"},"content":"Using Levenberg’s method\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nA rule of thumb is that if you use a function as an input argument for another function, there needs to be an @ involved once: either for an anonymous definition or to reference a function defined elsewhere.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nIn all other respects usage is the same as for the newtonsys function.\n\nf = @f46_nlsystem;\nx1 = [0; 0; 0];   \nx = levenberg(f, x1);\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x(:, end)\nbackward_err = norm(f(r))\n\nLooking at the convergence of the first component, we find a rate between linear and quadratic, like with the secant method.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'","type":"content","url":"/chapter4-1#section-4-6","position":17},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#section-4-7","position":18},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.7","lvl2":"Examples"},"content":"Convergence of nonlinear least squares\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = @(x) [sin(x(1) + x(2)); cos(x(1) - x(2)); exp(x(1) - x(2))];\np = [1; 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nclf\nlabels = [];\nfor R = [1e-3, 1e-2, 1e-1]\n    % Define the perturbed function.\n    f = @(x) g(x) - g(p) + R * [-1; 1; -1] / sqrt(3)\n    x = levenberg(f, [0; 0]);\n    r = x(:, end);\n    err = abs(x(1, 1:end-1) - r(1));\n    normres = norm(f(r));\n    semilogy(err), hold on\n    labels = [labels; sprintf(\"R=%.2g\", normres)];\nend\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend(labels)\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nNonlinear data fitting\n\nm = 25; V = 2; Km = 0.5;\ns = linspace(0.05, 6, m)';\nw = V * s ./ (Km + s);                      % exactly on the curve\nw = w + 0.15 * cos(2 * exp(s / 16) .* s);   % noise added\nclf, fplot(@(s) V * s ./ (Km + s), [0, 6], '--')\nhold on, scatter(s, w)\nxlabel('concentration'), ylabel('reaction rate')    \nlabels = [\"ideal\", \"noisy data\"];    \nlegend(labels, 'location', 'east')\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g. In the Jacobian, the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction [f, J] = misfit(c, s, w)\n    V = c(1);   Km = c(2);\n    f = V * s ./ (Km + s) - w;\n    J(:,1) = s ./ (Km + s);            % d/d(V)\n    J(:,2) = -V * s ./ (Km + s).^2;    % d/d(Km)\nend\n\n\nThe misfit function above has to know the parameters x that are being optimized as well as the data s and w that remain fixed. We use a closure to pass the data values along.\n\nf = @(x) f47_misfit(x, s, w);\n\nNow we have a function that accepts a single 2-vector input and returns a 25-vector output. We can pass this function to levenberg to find the best-fit parameters.\n\nx1 = [1; 0.75];\nx = newtonsys(f, x1);\nV = x(1, end),  Km = x(2, end)     % final values\nmodel = @(s) V * s ./ (Km + s);    % best-fit model\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data:\n\nfinal_misfit_norm = norm(model(s) - w) \nhold on, fplot(model, [0, 6])\ntitle('Michaelis-Menten fitting')    \nlabels = [labels, \"nonlinear fit\"];    \nlegend(labels, 'location', 'east')\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nu = 1 ./ w;\nA = [s.^(-1), s.^0];  \nz = A \\ u;\nalpha = z(1);  beta = z(2);\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel = @(s) 1 ./ (beta + alpha ./ s);\nfinal_misfit_linearized = norm(linmodel(s) - w)\nfplot(linmodel, [0, 6])\nlabels = [labels, \"linearized fit\"];    \nlegend(labels, 'location', 'east')\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/chapter4-1#section-4-7","position":19},{"hierarchy":{"lvl1":"Chapter 5"},"type":"lvl1","url":"/chapter5-1","position":0},{"hierarchy":{"lvl1":"Chapter 5"},"content":"MATLAB implementations","type":"content","url":"/chapter5-1","position":1},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"type":"lvl2","url":"/chapter5-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"content":"Hat function\n\nfunction H = hatfun(x,t,k)\r\n% HATFUN   Hat function/piecewise linear basis function.\r\n% Input: \r\n%   x      evaluation points (vector)\r\n%   t      interpolation nodes (vector, length n+1)\r\n%   k      node index (integer, in 0,...,n)\r\n% Output:\r\n%   H      values of the kth hat function\r\n\r\nn = length(t)-1;\r\nk = k+1;  % adjust for starting with index=1\r\n\r\n% Fictitious nodes to deal with first, last funcs.\r\nt = [ 2*t(1)-t(2); t(:); 2*t(n+1)-t(n) ];\r\nk = k+1;  % adjust index for the fictitious first node\r\n\r\nH1 = (x-t(k-1))/(t(k)-t(k-1));   % upward slope\r\nH2 = (t(k+1)-x)/(t(k+1)-t(k));   % downward slope\r\n\r\nH = min(H1,H2);\r\nH = max(0,H);\n\nPiecewise linear interpolation\n\nfunction p = plinterp(t,y)\r\n% PLINTERP   Piecewise linear interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   p     piecewise linear interpolant (function)\r\n\r\nn = length(t)-1;\r\np = @evaluate;\r\n\r\n    % This function evaluates p when called.\r\n    function f = evaluate(x)\r\n        f = 0;\r\n        for k = 0:n\r\n            f = f + y(k+1)*hatfun(x,t,k);\r\n        end\r\n    end\r\n\r\nend\n\nCubic spline interpolation\n\nfunction S = spinterp(t,y)\r\n% SPINTERP   Cubic not-a-knot spline interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   S     not-a-knot cubic spline (function)\r\n\r\nt = t(:);  y = y(:);  % ensure column vectors\r\nn = length(t)-1;\r\nh = diff(t);          % differences of all adjacent pairs\r\n\r\n% Preliminary definitions.\r\nZ = zeros(n);\r\nI = eye(n);  E = I(1:n-1,:);\r\nJ = I - diag(ones(n-1,1),1);\r\nH = diag(h);\r\n\r\n% Left endpoint interpolation:\r\nAL = [ I, Z, Z, Z ];\r\nvL = y(1:n);\r\n\r\n% Right endpoint interpolation:\r\nAR = [ I, H, H^2, H^3 ];\r\nvR = y(2:n+1);\r\n\r\n% Continuity of first derivative:\r\nA1 = E*[ Z, J, 2*H, 3*H^2 ];\r\nv1 = zeros(n-1,1);\r\n\r\n% Continuity of second derivative:\r\nA2 = E*[ Z, Z, J, 3*H ];\r\nv2 = zeros(n-1,1);\r\n\r\n% Not-a-knot conditions:\r\nnakL = [ zeros(1,3*n), [1,-1, zeros(1,n-2)] ];\r\nnakR = [ zeros(1,3*n), [zeros(1,n-2), 1,-1] ];\r\n\r\n% Assemble and solve the full system.\r\nA = [ AL; AR; A1; A2; nakL; nakR ];\r\nv = [ vL; vR; v1; v2; 0 ;0 ];\r\nz = A\\v;\r\n\r\n% Break the coefficients into separate vectors.\r\nrows = 1:n;\r\na = z(rows);\r\nb = z(n+rows);  c = z(2*n+rows);  d = z(3*n+rows);\r\nS = @evaulate;\r\n\r\n    % This function evaluates the spline when called with a value for x.\r\n    function f = evaulate(x)\r\n        f = zeros(size(x));\r\n        for k = 1:n       % iterate over the pieces\r\n            % Evalaute this piece's cubic at the points inside it.\r\n            index = (x>=t(k)) & (x<=t(k+1));   \r\n            f(index) = polyval( [d(k),c(k),b(k),a(k)], x(index)-t(k) );\r\n        end\r\n    end\r\n\r\nend\n\nFornberg’s algorithm for finite difference weights\n\nfunction w = fdweights(t,m)\r\n%FDWEIGHTS   Fornberg's algorithm for finite difference weights.\r\n% Input:\r\n%   t    nodes (vector, length r+1)\r\n%   m    order of derivative sought at x=0 (integer scalar)\r\n% Output:\r\n%   w    weights for the approximation to the jth derivative (vector)\r\n\r\n% This is a compact implementation, not an efficient one. \r\n\r\nr = length(t)-1;\r\nw = zeros(size(t));\r\nfor k = 0:r\r\n  w(k+1) = weight(t,m,r,k);\r\nend\r\n\r\n\r\nfunction c = weight(t,m,r,k)\r\n% Implement a recursion for the weights.\r\n% Input:\r\n%   t   nodes (vector)\r\n%   m   order of derivative sought \r\n%   r   number of nodes to use from t (<= length(t))\r\n%   k   index of node whose weight is found \r\n% Output:\r\n%   c   finite difference weight \r\n\r\nif (m<0) || (m>r)        % undefined coeffs must be zero\r\n  c = 0;    \r\nelseif (m==0) && (r==0)  % base case of one-point interpolation\r\n  c = 1;   \r\nelse                     % generic recursion \r\n  if k<r\r\n    c = (t(r+1)*weight(t,m,r-1,k) - ...\r\n        m*weight(t,m-1,r-1,k))/(t(r+1)-t(k+1));\r\n  else\r\n    beta = prod(t(r)-t(1:r-1)) / prod(t(r+1)-t(1:r));\r\n    c = beta*(m*weight(t,m-1,r-1,r-1) - t(r)*weight(t,m,r-1,r-1));\r\n  end\r\nend\n\nTrapezoid formula for numerical integration\n\nfunction [T,t,y] = trapezoid(f,a,b,n)\n%TRAPEZOID   Trapezoid formula for numerical integration.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   n     number of interval divisions\n% Output:\n%   T     approximation to the integral of f over (a,b)\n%   t     vector of nodes used\n%   y     vector of function values at nodes\n\nh = (b-a)/n;\nt = a + h*(0:n)';\ny = f(t);\nT = h * ( sum(y(2:n)) + 0.5*(y(1) + y(n+1)) );\n\nAdaptive integration\n\nfunction [Q,t] = intadapt(f,a,b,tol)\n%INTADAPT   Adaptive integration with error estimation.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   tol   acceptable error\n% Output:\n%   Q     approximation to integral(f,a,b)\n%   t     vector of nodes used\n\nm = (b+a)/2;\n[Q,t] = do_integral(a,f(a),b,f(b),m,f(m),tol);\n\n    % Use error estimation and recursive bisection. \n    function [Q,t] = do_integral(a,fa,b,fb,m,fm,tol)\n        \n        % These are the two new nodes and their f-values.\n        xl = (a+m)/2;  fl = f(xl);\n        xr = (m+b)/2;  fr = f(xr);\n        t = [a;xl;m;xr;b];              % all 5 nodes at this level\n\n        % Compute the trapezoid values iteratively. \n        h = (b-a);\n        T(1) = h*(fa+fb)/2;\n        T(2) = T(1)/2 + (h/2)*fm;\n        T(3) = T(2)/2 + (h/4)*(fl+fr);\n        \n        S = (4*T(2:3)-T(1:2)) / 3;      % Simpson values\n        E = (S(2)-S(1)) / 15;           % error estimate\n                \n        if abs(E) < tol*(1+abs(S(2)))   % acceptable error?\n            Q = S(2);                   % yes--done\n        else\n            % Error is too large--bisect and recurse. \n            [QL,tL] = do_integral(a,fa,m,fm,xl,fl,tol);\n            [QR,tR] = do_integral(m,fm,b,fb,xr,fr,tol);\n            Q = QL + QR;\n            t = [tL;tR(2:end)];         % merge the nodes w/o duplicate\n        end        \n    end\n\nend  % main function\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.","type":"content","url":"/chapter5-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"type":"lvl2","url":"/chapter5-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter5-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-1","position":6},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.1","lvl2":"Examples"},"content":"Trouble in polynomial interpolation\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5;\nt = linspace(-1,1,n+1)';  \ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t,y)\n\nThe polynomial interpolant, as computed using polyfit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on\nfplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north')\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on, fplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north')\n\nSurely there must be functions that are more intuitively representative of those points!\n\nPiecewise polynomial interpolation\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using interp1 from MATLAB.\n\nx = linspace(-1, 1, 400)';\nhold on, plot(x, interp1(t, y, x))\ntitle('Piecewise linear interpolant')\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\ncla\nscatter(t, y)\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic interpolant')\n\nConditioning of interpolation\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18;\nt = linspace(-1, 1, n+1)';\ny = [zeros(9, 1); 1; zeros(n - 9, 1)];    % 10th cardinal function\nclf, scatter(t, y)\nhold on\nx = linspace(-1, 1, 400)';\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic cardinal function') \nxlabel('x'), ylabel('p(x)')\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nclf, scatter(t, y)\nc = polyfit(t, y, n);\nhold on, plot(x, polyval(c, x))\ntitle('Polynomial cardinal function')\nxlabel('x'), ylabel('p(x)')\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/chapter5-1#section-5-1","position":7},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-2","position":8},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.2","lvl2":"Examples"},"content":"A look at hat functions\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1];\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nclf\nfor k = 0:3\n    subplot(4, 1, k+1)\n    Hk = @(x) hatfun(x, t, k);\n    fplot(Hk, [0, 1])\n    hold on\n    scatter(t, Hk(t))\n    text(t(k+1), 0.6, sprintf(\"H_%d\", k))\nend\n\nUsing piecewise linear interpolation\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = @(x) exp(sin(7 * x));\nclf\nfplot(f, [0, 1], displayname=\"function\")\nxlabel(\"x\");  ylabel(\"y\")\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % function values\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = plinterp(t, y);\nhold on\nfplot(p, [0, 1], displayname=\"interpolant\")\nscatter(t, y, displayname=\"values at nodes\")\ntitle(\"PL interpolation\")\nlegend()\n\nConvergence of piecewise linear interpolation\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = @(x) exp(sin(7 * x));\nx = linspace(0, 1, 10001)';    % sample the difference at many points\nn = round(10.^(1:0.25:3.5))';\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i)) / n(i);       % interpolation nodes\n    p = plinterp(t, f(t));\n    maxerr(i) = norm(f(x) - p(x), Inf);\nend\ndisp(table(n(1:4:end), maxerr(1:4:end), variableNames=[\"n\", \"inf-norm error\"]))\n\nAs predicted, a factor of 10 in n produces a factor of 100 reduction in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder2 = 0.5 * maxerr(end) * (n / n(end)) .^ (-2);\nhold on\nloglog(n, order2, \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"|| f-p ||_{\\infty}\")\ntitle(\"Convergence of PL interpolation\")\nlegend()","type":"content","url":"/chapter5-1#section-5-2","position":9},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-3","position":10},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.3","lvl2":"Examples"},"content":"Cubic splines\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nclf\nf = @(x) exp(sin(7 * x));\nfplot(f, [0, 1], displayname=\"function\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % values at nodes\nhold on, scatter(t, y, displayname=\"values at nodes\")\n\nS = spinterp(t, y);\nfplot(S, [0, 1], displayname=\"spline\")\n\nxlabel(\"x\");  ylabel(\"y\")\nlegend()\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000)' / 1e4;              % sample the difference at many points\nn = round(2 .^ (3:0.5:7))';        % numbers of nodes\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i))' / n(i);\n    S = spinterp(t, f(t));\n    err = f(x) - S(x);\n    maxerr(i) = norm(err, Inf);\nend\ndisp(table(n(1:2:end), maxerr(1:2:end), variableNames=[\"n\", \"inf-norm error\"]))\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder4 = 0.5 * maxerr(end) * (n / n(end)) .^ (-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nxlabel(\"n\");  ylabel(\"|| f-S ||_{\\infty}\")\ntitle(\"Convergence of spline interpolation\")","type":"content","url":"/chapter5-1#section-5-3","position":11},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-4","position":12},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.4","lvl2":"Examples"},"content":"Finite differences\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05;\nformat long\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\n\nFinite differences for f''\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05;\nformat long\nCD2 = (f(-h) - 2*f(0) + f(h)) / h^2\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h^2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h^2\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h^2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h^2\n\nFinite differences at arbitrary nodes\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75];    % nodes\nf = @(x) cos(x.^2);\ndfdx = @(x) -2 * x * sin(x^2);\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nformat short\nw = fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = w * f(t)'\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nfdweights(0:3, 1)","type":"content","url":"/chapter5-1#section-5-4","position":13},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-5","position":14},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.5","lvl2":"Examples"},"content":"Convergence of finite differences\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = @(x) sin(exp(x + 1));\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = 5 ./ 10.^(1:6)';\nFD1 = zeros(size(h));\nFD2 = zeros(size(h));\nfor i = 1:length(h)\n    h_i = h(i);\n    FD1(i) = (f(h_i) - f(0)    ) / h_i;\n    FD2(i) = (f(h_i) - f(-h_i)) / (2*h_i);\nend\ndisp(table(h, FD1, FD2))\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerr1 = abs(exact_value - FD1);\nerr2 = abs(exact_value - FD2);\ndisp(table(h, err1, err2, variableNames=[\"h\", \"error in FD1\", \"error in FD2\"]))\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nclf\nloglog(h, abs([err1 err2]), \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err1(end) * (h / h(end)) .^ 1;\norder2 = 0.1 * err2(end) * (h / h(end)) .^ 2;\nhold on\nloglog(h, order1, \"--\", h, order2, \"--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"Convergence of finite differences\")\nlegend(\"FD1\", \"FD2\", \"O(h)\", \"O(h^2)\")\n\nRoundoff error in finite differences\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = @(x) exp(-1.3 * x);\nexact = -1.3;\n\nh = 10 .^ (-(1:12))';\nFD = zeros(length(h), 3);\nfor i = 1:length(h)\n    h_i = h(i);\n    nodes = h_i * (-2:2);\n    vals = f(nodes);\n    FD(i, 1) = dot([0      0 -1   1    0] / h_i, vals);\n    FD(i, 2) = dot([0    -1/2 0 1/2    0] / h_i, vals);\n    FD(i, 3) = dot([1/12 -2/3 0 2/3 -1/12] / h_i, vals);\nend\nformat long\ndisp(table(h, FD(:, 1), FD(:, 2), FD(:, 3), variableNames=[\"h\", \"FD1\", \"FD2\", \"FD4\"]))\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = abs(FD - exact);\nclf\nloglog(h, err, \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err(end, 1) * (h / h(end)) .^ (-1);\nhold on\nloglog(h, order1, \"k--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"FD error with roundoff\")\nlegend(\"FD1\", \"FD2\", \"FD4\", \"O(1/h)\", \"location\", \"northeast\")\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/chapter5-1#section-5-5","position":15},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-6","position":16},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.6","lvl2":"Examples"},"content":"Numerical integration\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nformat long\nexact = exp(1) - 1\n\nMATLAB has numerical integrator integral that estimates the value without finding the antiderivative first. As you can see here, it can be as accurate as floating-point precision allows.\n\nintegral(@(x) exp(x), 0, 1)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nintegral(@(x) exp(sin(x)), 0, 1)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 201)';\nsubplot(2,1,1), fill([x; 1; 0], [exp(x); 0;0 ], [1, 0.9, 0.9])\ntitle('exp(x)')  % ignore this line\nylabel('f(x)')    % ignore this line\nsubplot(2, 1, 2), fill([x; 1; 0], [exp(sin(x)); 0; 0], [1, 0.9, 0.9])\ntitle('exp(sin(x))')  % ignore this line\nxlabel('x'), ylabel('f(x)')    % ignore this line\n\nTrapezoid integration\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = @(x) exp(sin(7 * x));\na = 0;  b = 2;\n\nIn lieu of the exact value, we use the integral function to find an accurate result.\n\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14);\nfprintf(\"Integral = %.15f\", I)\n\nHere is the trapezoid result at n=40, and its error.\n\nT = trapezoid(f, a, b, 40);\nfprintf(\"Trapezoid error = %.2e\", I - T)\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = 10 .^ (1:5)';\nerr = zeros(size(n));\nfor i = 1:length(n)\n    T = trapezoid(f, a, b, n(i));\n    err(i) = I - T;\nend\ndisp(table(n, err, variableNames=[\"n\", \"Trapezoid error\"]))\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"trapezoid\")\nhold on\nloglog(n, 0.1 * abs(err(end)) * (n / n(end)).^(-2), \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"error\")\ntitle(\"Convergence of trapezoidal integration\")\nlegend()\n\nIntegration by extrapolation\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = @(x) x.^2 .* exp(-2 * x);\na = 0;  b = 2;\nformat long\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14)\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       % the coarsest formula\nn = N;  h = (b - a) / n;\nt = h * (0:n)';\ny = f(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = h * ( sum(y(2:n)) + y(1) / 2 + y(n+1) / 2 )\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(2) = T(1) / 2 + h * sum( f(t(2:2:n)) )\n\nWe can repeat the same code to double n again.\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(3) = T(2) / 2 + h * sum( f(t(2:2:n)) )\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = (4 * T(2:3) - T(1:2)) / 3\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16*S(2) - S(1)) / 15\n\nWe can make a triangular table of the errors:\n\nerr2 = T(:) - I;\nerr4 = [NaN; S(:) - I];\nerr6 = [NaN; NaN; R - I];\nformat short e\ndisp(table(err2, err4, err6, variablenames=[\"order 2\", \"order 4\", \"order 6\"]))\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/chapter5-1#section-5-6","position":17},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#section-5-7","position":18},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.7","lvl2":"Examples"},"content":"Motivation for adaptive integration\n\nThis function gets increasingly oscillatory as x increases.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\nclf\nfplot(f, [0, 4], 2000)\nxlabel('x'), ylabel('f(x)')\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nleft_val = integral(f, 0, 2, abstol=1e-14, reltol=1e-14);\nright_val = integral(f, 2, 4, abstol=1e-14, reltol=1e-14);\n\nn = round(50 * 2 .^ (0:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    T = trapezoid(f, 0, 2, n(i));\n    err(i, 1) = T - left_val;\n    T = trapezoid(f, 2, 4, n(i));\n    err(i, 2) = T - right_val;\nend\ndisp(table(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"left error\", \"right error\"]))\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nUsing adaptive integration\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\n[Q, t] = intadapt(f, 0, 4, 0.001);\nclf, fplot(f, [0, 4], 2000)\nhold on\nstem(t, f(t), '.-')\ntitle('Adaptive node selection')    % ignore this line\nxlabel('x'), ylabel('f(x)')    % ignore this line\nfprintf(\"number of nodes = %d\", length(t))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nI = integral(f, 0, 4, abstol=1e-14, reltol=1e-14);    % 'exact' value\nfprintf(\"error = %.2e\", abs(Q - I))\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = 1 ./ 10.^(4:14)';\nerr = zeros(size(tol));\nn = zeros(size(tol));\nfor i = 1:length(tol)\n    [A, t] = intadapt(f, 0, 4, tol(i));\n    err(i) =  I - A;\n    n(i) = length(t);\nend\ndisp(table(tol, err, n, variableNames=[\"tolerance\", \"error\", \"number of nodes\"]))\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"results\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\ntitle(\"Convergence of adaptive integration\")\norder4 = 0.1 * abs(err(end)) * (n / n(end)).^(-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nlegend()","type":"content","url":"/chapter5-1#section-5-7","position":19},{"hierarchy":{"lvl1":"Chapter 6"},"type":"lvl1","url":"/chapter6-1","position":0},{"hierarchy":{"lvl1":"Chapter 6"},"content":"","type":"content","url":"/chapter6-1","position":1},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"type":"lvl2","url":"/chapter6-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"content":"Euler’s method for an initial-value problem\n\nfunction [t, u] = eulerivp(ivp, a, b, n)\r\n% EULERIVP   Euler's method for a scalar initial-value problem.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;\r\nt = a + (0:n) * h;\r\n\r\n% Initialize solution array.\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0;\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  u(:, i+1) = u(:, i) + h * du_dt(t(i), u(i), p);\r\nend\n\nAbout the code\n\nThe ivp input argument is the same structure that is used with the built-in solve solvers. The outputs t and u are row vectors of the same length, like the fields in a solution object output by solve. While the entries of u could be simplified to u(1), u(i), etc., we chose a column-access syntax like u(:, i) that will prove useful for what’s coming next in the chapter.\n\nImproved Euler method for an IVP\n\nfunction [t, u] = ie2(ivp, a, b, n)\r\n% IE2    Improved Euler method for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping. \r\nfor i = 1:n \r\n    uhalf = u(:, i) + h/2 * du_dt(t(i), u(:, i), p);\r\n    u(:, i+1) = u(:, i) + h * du_dt(t(i) + h/2, uhalf, p);\r\nend\n\nFourth-order Runge-Kutta for an IVP\n\nfunction [t, u] = rk4(ivp, a, b, n)\r\n% RK4    Fourth-order Runge-Kutta for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  k1 = h * du_dt( t(i),       u(:, i)       , p);\r\n  k2 = h * du_dt( t(i) + h/2, u(:, i) + k1/2, p );\r\n  k3 = h * du_dt( t(i) + h/2, u(:, i) + k2/2, p );\r\n  k4 = h * du_dt( t(i) + h,   u(:, i) + k3  , p);\r\n  u(:, i+1) = u(:, i) + (k1 + 2*(k2 + k3) + k4) / 6;\r\nend\n\nAdaptive IVP solver based on embedded RK formulas\n\nfunction [t, u] = rk23(ivp, a, b, tol)\r\n% RK23   Adaptive IVP solver based on embedded RK formulas.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   tol     global error target (positive scalar)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Initialize for the first time step.\r\nt = a;\r\nu(:, 1) = u0(:);  i = 1;\r\nh = 0.5 * tol^(1/3);\r\ns1 = du_dt(t(1), u(:, 1));\r\n\r\n% Time stepping.\r\nwhile t(i) < b\r\n    % Detect underflow of the step size.\r\n    if t(i) + h == t(i)\r\n        warning('Stepsize too small near t=%.6g.',t(i))\r\n        break  % quit time stepping loop\r\n    end\r\n    \r\n    % New RK stages.\r\n    s2 = du_dt(t(i) + h/2,   u(:, i) + (h/2)   * s1, p);\r\n    s3 = du_dt(t(i) + 3*h/4, u(:, i) + (3*h/4) * s2, p);\r\n    unew2 = u(:, i) + h * (2*s1 + 3*s2 + 4*s3) / 9;    % 2rd order solution\r\n    s4 = du_dt(t(i) + h, unew2, p );\r\n    err = h * (-5*s1/72 + s2/12 + s3/9 - s4/8);        % 2nd/3rd order difference\r\n    E = norm(err, Inf);                                % error estimate\r\n    maxerr = tol * (1 + norm(u(:, i), Inf));           % relative/absolute blend\r\n    \r\n    % Accept the proposed step? \r\n    if E < maxerr     % yes \r\n        t(i+1) = t(i) + h;\r\n        u(:, i+1) = unew2;\r\n        i = i+1;\r\n        s1 = s4;      % use FSAL property\r\n    end\r\n    \r\n    % Adjust step size. \r\n    q = 0.8 * (maxerr/E)^(1/3);       % conservative optimal step factor\r\n    q = min(q, 4);                    % limit stepsize growth\r\n    h = min(q*h, b - t(i));           % don't step past the end\r\nend\n\nAbout the code\n\nThe check t(i) + h == t(i)on line 24 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 36, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 47--49 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 43 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s4 as s1 for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\n4th-order Adams–Bashforth formula for an IVP\n\nfunction [t, u] = ab4(ivp, a, b, n)\r\n%AB4     4th-order Adams-Bashforth formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Constants in the AB4 method.\r\nk = 4;  \r\nsigma = [55; -59; 37; -9] / 24;  \r\n\r\n% Find starting values by RK4.\r\n[ts, us] = rk4(ivp, a, a + (k-1)*h, k-1);\r\nu = zeros(length(u0), n+1);\r\nu(:, 1:k) = us(:, 1:k);\r\n\r\n% Compute history of u' values, from oldest to newest.\r\nf = zeros(length(u0), k);\r\nfor i = 1:k-1\r\n  f(:, k-i) = du_dt(t(i), u(:, i), p);\r\nend\r\n\r\n% Time stepping.\r\nfor i = k:n\r\n  f = [du_dt(t(i), u(:, i), p), f(:, 1:k-1)];   % new value of du/dt\r\n  u(:, i+1) = u(:, i) + h * (f * sigma);        % advance one step\r\nend\n\nAbout the code\n\nLine 21 sets sigma to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 24--26 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then lines 29--32 compute the vector [f_2,f_1,f_0].\n\nLine 36 computes f_i, based on the most recent solution value and time. That goes into the first column of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\nfunction [t, u] = am2(ivp, a, b, n)\r\n% AM2    2nd-order Adams-Moulton (trapezoid) formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  % Data that does not depend on the new value.\r\n  known = u(:,i) + h/2 * du_dt(t(i), u(:, i), p);\r\n  % Find a root for the new value. \r\n  unew = levenberg(@trapzero, known);\r\n  u(:, i+1) = unew(:, end);\r\nend\r\n\r\n% This function defines the rootfinding problem at each step.\r\nfunction F = trapzero(z)\r\n    F = z - h/2 * du_dt(t(i+1), z, p) - known;\r\nend\r\n\r\nend  % main function\n\nAbout the code\n\nLines 32--34 define the function \\mathbf{g}. This is sent to levenberg in line~27 to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/chapter6-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"type":"lvl2","url":"/chapter6-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter6-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-1","position":6},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.1","lvl2":"Examples"},"content":"Solving an IVP\n\nLet’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1. To create an initial-value problem for u(t), you must create an ode with a function that computes u' and an initial condition for u. Then you create a solution by calling solve with a time interval.\n\nMost real ODE problems contain parameters that are constant during the solution but that can change from one problem instance to the next. Accordingly, we define the ODE function below to accept a third argument, p, which is a vector of parameters. We always include this argument for consistency, even when there are no parameters.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialTime = 0;\nivp.InitialValue = -1;\nsol = solve(ivp, 0, 4);\n\nThe resulting solution object has fields Time and Solution that contain the approximate values of the solution at automatically chosen times in the interval you provided.\n\nclf\nplot(sol.Time, sol.Solution, '-o')\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle(\"Solution of an IVP\")\n\nYou might want to know the solution at particular times other than the ones selected by the solver. That requires an interpolation, which is done by solutionFcn.\n\nu = solutionFcn(ivp, 0, 10);\nu(0:5)\n\nFinite-time singularity\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialTime = 0;\nivp.InitialValue = 1;\nsol = solve(ivp, 0, 1);\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nclf\nsemilogy(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle(\"Finite-time blowup\")\n\nConditioning of an IVP\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')   % ignore this line\ntitle('Exponential divergence of solutions')   % ignore this line\n\nBut with u'=-u, solutions actually get closer together with time.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(-t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')   % ignore this line\ntitle('Exponential convergence of solutions')   % ignore this line\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.","type":"content","url":"/chapter6-1#section-6-1","position":7},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-2","position":8},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.2","lvl2":"Examples"},"content":"Convergence of Euler’s method\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We need to define the function for the right-hand side of the ODE, the interval for the independent variable, and the initial value.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nHere is the call to \n\nFunction 6.2.2.\n\n[t, u] = eulerivp(ivp, a, b, 20);\nclf, plot(t, u, '.-')\nxlabel('t')\nylabel('u(t)')\ntitle('Solution by Euler''s method')  % ignore this line\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\n[t, u] = eulerivp(ivp, a, b, 50);\nhold on, plot(t, u, '.-')\nlegend('20 steps', '50 steps')\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a built-in solver to construct an accurate reference solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_exact = solutionFcn(ivp, a, b);\n\nNow we can perform a convergence study.\n\nn = round(5 * 10.^(0:0.5:3));\nerr = [];\nfor k = 1:length(n)\n    [t, u] = eulerivp(ivp, a, b, n(k));\n    err(k) = norm(u_exact(t) - u, Inf);\nend\ntable(n', err', VariableNames=[\"n\", \"inf-norm error\"])\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nclf\nloglog(n, err, 'o-')\nhold on, loglog(n, 0.5 * err(end) * (n / n(end)).^(-1), '--')\nxlabel('n')\nylabel('inf-norm error')  % ignore this line\ntitle('Convergence of Euler''s method')  % ignore this line\nlegend('error', 'O(n^{-1})', 'location', 'southwest')  % ignore this line","type":"content","url":"/chapter6-1#section-6-2","position":9},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-3","position":10},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.3","lvl2":"Examples"},"content":"Predator-prey model\n\nWe encode the predator–prey equations via a function, defined here externally.\n\nfunction du_dt = predprey(t, u, p)\n    alpha = p(1);  beta = p(2);\n    y = u(1);      z = u(2);\n    s = (y * z) / (1 + beta * y);  % appears in both equations\n    du_dt = [ y * (1 - alpha * y) - s;  -z + s ];\nend\n\n\nThe values of alpha and beta are parameters that influence the solution of the IVP. We use the Parameters field of the IVP object to define them for the solver, which in turn passes them as the third argument into our ODE function.\n\nu0 = [1; 0.01];    % column vector\np = [0.1, 0.25];\nivp = ode;\nivp.ODEFcn = @f63_predprey;\nivp.InitialValue = u0;\nivp.Parameters = p;\nsol = solve(ivp, 0, 60);\nsize(sol.Solution)\n\nEach column of the Solution field is the solution vector \\mathbf{u} at a particular time; each row is a component of \\mathbf{u} over all time.\n\nclf\nplot(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle('Predator-prey solution')  % ignore this line\nlegend('prey', 'predator')  % ignore this line\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\n[t, u] = eulerivp(ivp, 0, 60, 1200);\n\nhold on\nplot(t, u, '.')\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nclf\nplot(u(1, :), u(2, :))\ntitle(\"Predator-prey in the phase plane\")\nxlabel(\"y\")\nylabel(\"z\")\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nCoupled pendulums\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nfunction udot = pendulums(t, u, p)\n    gamma = p(1);  L = p(2);  k = p(3);\n    g = 9.8;\n    udot = zeros(4, 1);\n    udot(1:2) = u(3:4);\n    udot(3) = -gamma * u(3) - (g / L) * sin(u(1)) + k * (u(2) - u(1));\n    udot(4) = -gamma * u(4) - (g / L) * sin(u(2)) + k * (u(1) - u(2));\nend\n\n\nu0 = [1.25; -0.5; 0; 0];\na = 0; b = 50;\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nHere OutputVariables is used to restrict output to just u_1 and u_2.\n\nparams =[0.01, 0.5, 0];    % gamma, L, k\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nt = linspace(a, b, 1001);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\")\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nparams(3) = 1;\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Coupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\")\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/chapter6-1#section-6-3","position":11},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-4","position":12},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.4","lvl2":"Examples"},"content":"Convergence of Runge–Kutta methods\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nWe use a built-in solver to construct an accurate approximation to the exact solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = round(2 * 10.^(0:0.5:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    [t, u] = ie2(ivp, a, b, n(i));\n    err(i, 1) = norm(u_ref(t) - u, Inf);\n    [t, u] = rk4(ivp, a, b, n(i));\n    err(i, 2) = norm(u_ref(t) - u, Inf);\nend\n\ndisp(table(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"IE2 error\", \"RK4 error\"]))\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nclf, loglog([2*n 4*n], err, '-o')\nhold on\nloglog(2*n, 1e-5 * (n / n(end)) .^ (-2), '--')\nloglog(4*n, 1e-10 * (n / n(end)) .^ (-4), '--')\nxlabel(\"f-evaluations\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of RK methods\")\nlegend(\"IE2\", \"RK4\", \"O(n^{-2})\", \"O(n^{-4})\", \"location\", \"southwest\")\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/chapter6-1#section-6-4","position":13},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-5","position":14},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.5","lvl2":"Examples"},"content":"Adaptive step size\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) exp(t - u * sin(u));\nivp.InitialValue = 0;\na = 0;  b = 5;\n\n[t, u] = rk23(ivp, a, b, 1e-5);\nclf, plot(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle(\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nDelta_t = diff(t);\nsemilogy(t(1:end-1), Delta_t) \nxlabel(\"t\");  ylabel(\"step size\")\ntitle(\"Adaptive step sizes\")\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nfprintf(\"minimum step size = %.2e\", min(Delta_t))\n\nOn the other hand, the average step size that was actually taken was\n\nfprintf(\"average step size = %.2e\", mean(Delta_t))\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nAdaptive step size near a singularity\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialValue = 1;\n[t, u] = rk23(ivp, 0, 1, 1e-5);\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nclf, semilogy(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle(\"Adaptive solution near a singularity\")\n\ntf = t(end);\nxline(tf, \"linestyle\", \"--\")\ntext(tf, 1e5, sprintf(\" t = %.6f \", tf))","type":"content","url":"/chapter6-1#section-6-5","position":15},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-6","position":16},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.6","lvl2":"Examples"},"content":"Convergence of Adams–Bashforth\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, a built-in solver is called to give an accurate reference solution.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of the AB4 code.\n\nn = round(4 * 10.^(0:0.5:3)');\nerr = [];\nfor i = 1:length(n)\n    [t, u] = ab4(ivp, a, b, n(i));\n    err(i) = norm(u_ref(t) - u, Inf);\nend\n\ndisp(table(n, err, variableNames=[\"n\", \"inf-norm error\"]))\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nclf, loglog(n, err, '-o')\nhold on\nloglog(n, 0.5 * err(end) * (n / n(end)) .^ (-4), '--')\nxlabel(\"n\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of AB4\")\nlegend(\"AB4\", \"O(n^{-4})\", \"location\", \"southwest\")\n\nStiffness\n\nThe following simple ODE uncovers a surprise.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) u^2 - u^3;\nivp.InitialValue = 0.005;\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\n[tI, uI] = am2(ivp, 0, 400, 200);\nclf\nplot(tI, uI)\nxlabel(\"t\");  ylabel(\"u(t)\")\n\nNow we repeat the process using the explicit AB4 method.\n\n[tE, uE] = ab4(ivp, 0, 400, 200);\nhold on\nplot(tE, uE, '.', 'markersize', 8)\nylim([-5, 3])\nlegend(\"AM2\", \"AB4\")\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nformat short e\nuE(105:111)\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nclf,  plot(tI, uI, '.', 'markersize', 10)\nhold on\n[tE, uE] = ab4(ivp, 0, 400, 1000);\nplot(tE, uE)\n[tE, uE] = ab4(ivp, 0, 400, 1600);\nplot(tE, uE)\nlegend(\"AM2, n=200\", \"AB4, n=1000\", \"AB4, n=1600\")\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!","type":"content","url":"/chapter6-1#section-6-6","position":17},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#section-6-7","position":18},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.7","lvl2":"Examples"},"content":"Instability\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = @(t, u) u;\nu_exact = @exp;\na = 0;  b = 1;\nn = [5, 10, 20, 40, 60]';\nerr = zeros(size(n));\nfor j = 1:length(n)\n    h = (b - a) / n(j);\n    t = a + h *(0:n(j));\n    u = [1, u_exact(h), zeros(1, n(j) - 1)];\n    f = [du_dt(t(1), u(1)), zeros(1, n(j) - 2)];\n    for i = 2:n(j)\n        f(i) = du_dt(t(i), u(i));\n        u(i+1) = -4*u(i) + 5*u(i-1) + h * (4*f(i) + 2*f(i-1));\n    end\n    err(j) = abs(u_exact(b) - u(end));\nend\n\nh = (b-a) ./ n;\ndisp(table(n, h, err))\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nclf\nsemilogy(t, abs(u))\nxlabel(\"t\");  ylabel(\"|u(t)|\")\ntitle(\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.","type":"content","url":"/chapter6-1#section-6-7","position":19},{"hierarchy":{"lvl1":"Chapter 7"},"type":"lvl1","url":"/chapter7-1","position":0},{"hierarchy":{"lvl1":"Chapter 7"},"content":"","type":"content","url":"/chapter7-1","position":1},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"type":"lvl2","url":"/chapter7-1#examples","position":2},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"content":"\n\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab/fnc\naddpath /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter7-1#examples","position":3},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.1) From matrix to insight","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-1","position":4},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.1) From matrix to insight","lvl2":"Examples"},"content":"Adjacency matrix\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nSince this adjacency matrix is not symmetric, the edges are all directed. We use digraph to create a directed graph.\n\nG = digraph(A);\nplot(G)\n\nHere are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0];\nplot(graph(A))\n\nA “buckyball” is an allotrope of carbon atoms with the same connection structure as a soccer ball.\n\nplot(graph(bucky))\n\nImages as matrices\n\nMATLAB ships with a few test images to play with.\n\nA = imread('peppers.png');\ncolor_size = size(A)\n\nUse imshow to display the image.\n\nimshow(A)\n\nThe image has three layers or channels for red, green, and blue. We can deal with each layer as a matrix, or (as below) convert it to a single matrix indicating shades of gray from black (0) to white (255). Either way, we have to explicitly convert the entries to floating-point values rather than integers.\n\nA = im2gray(A);   % collapse from 3 dimensions to 2\ngray_size = size(A)\nimshow(A)\n\nBefore we can do any numerical computation, we need to convert the image to a matrix of floating-point numbers.\n\nA = double(A);","type":"content","url":"/chapter7-1#id-7-1","position":5},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.2) Eigenvalue decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-2","position":6},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.2) Eigenvalue decomposition","lvl2":"Examples"},"content":"Eigenvalues and eigenvectors\n\nThe eig function with one output argument returns a vector of the eigenvalues of a matrix.\n\nA = pi * ones(2, 2);\nlambda = eig(A)\n\nWith two output arguments given, eig returns a matrix eigenvectors and a diagonal matrix with the eigenvalues.\n\n[V, D] = eig(A)\n\nWe can check the fact that this is an EVD.\n\nnorm( A - V*D/V )   % / V is like * inv(V)\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1];\n[V, D] = eig(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nnorm(A * V - V * D)\n\nEigenvalue conditioning\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7;\nA = randn(n, n) + 1i * randn(n, n);\nA = (A + A') / 2;\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones. Note: since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = [];\nfor j = 1:n\n    dist = [dist; min(abs(dd - lambda(j)))];\nend\ndist\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20;\nx = (1:n)';\nA = triu(x * ones(1, n));\nA(1:5, 1:5)\n\nThis matrix is not at all close to normal.\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = -Inf;\nfor j = 1:n\n    dist = max(dist, min(abs(dd - lambda(j))));\nend\nfprintf(\"max change in eigenvalues: %.2e\", dist)\nfprintf(\"Bauer-Fike upper bound: %.2e\", cond(V) * norm(E))\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nplot(lambda, 0*lambda, 'o')\naxis equal; hold on\nfor k = 1:60\n    E = randn(n, n) + 1i * randn(n, n);\n    E = eps(single(1)) * E / norm(E);\n    dd = eig(A + E);\n    plot(real(dd), imag(dd), 'k.', markersize=2)\nend\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nFrancis QR iteration\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diag([-6, -1, 2, 4, 5]);\n[V, R]= qr(randn(5, 5));    % V is unitary\nA = V * D * V';\n\nsort(eig(A))\n\nNow we will take the QR factorization and just reverse the factors.\n\n[Q, R] = qr(A);\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nsort(eig(A))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k = 1:40\n    [Q, R] = qr(A);\n    A = R * Q;\nend\nformat short e\nA","type":"content","url":"/chapter7-1#id-7-2","position":7},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.3) Singular value decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-3","position":8},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.3) Singular value decomposition","lvl2":"Examples"},"content":"SVD properties\n\nWe verify some of the fundamental SVD properties using the built-in svd function.\n\nA = vander(1:5);\nA = A(:, 1:4)\n\n[U, S, V] = svd(A);\ndisp(sprintf(\"U is %d by %d. S is %d by %d. V is %d by %d.\\n\", size(U), size(S), size(V)))\n\nWe verify the orthogonality of the singular vectors as follows:\n\nnorm(U' * U - eye(5))\nnorm(V' * V - eye(4))\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\ns = diag(S);\nnorm_A = norm(A)\nsigma_max = s(1)\n\ncond_A = cond(A)\nsigma_ratio = s(1) / s(end)","type":"content","url":"/chapter7-1#id-7-3","position":9},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.4) Symmetry and definiteness","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-4","position":10},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.4) Symmetry and definiteness","lvl2":"Examples"},"content":"Rayleigh quotient\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nlambda = 1:n;\nD = diag(lambda);\n[V, ~] = qr(randn(n, n));    % get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = @(x) (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nformat long\nR(V(:, 7))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\ndelta = 1 ./ 10 .^ (1:5)';\ndif = zeros(size(delta));\nfor k = 1:length(delta)\n    e = randn(n, 1);\n    e = delta(k) * e / norm(e);\n    x = V(:, 6) + e;\n    dif(k) = R(x) - lambda(6);\nend\ndisp(table(delta, dif, variablenames=[\"perturbation size\", \"R(x) - lambda\"]))","type":"content","url":"/chapter7-1#id-7-4","position":11},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.5) Dimension reduction","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-5","position":12},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"(7.5) Dimension reduction","lvl2":"Examples"},"content":"Image compression\n\nWe make an image from some text, then reload it as a matrix.\n\nclf\ntobj = text(0, 0,'Hello world','fontsize',44);\nex = get(tobj, 'extent');\naxis([ex(1) ex(1) + ex(3) ex(2) ex(2) + ex(4)]), axis off\nexportgraphics(gca, 'hello.png', resolution=300)\nA = imread('hello.png');\nA = double(im2gray(A));\nsize_A = size(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=100.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\nsemilogy(sigma, '.')\ntitle('singular values'), axis tight        % ignore this line \nxlabel('i'), ylabel('\\sigma_i')  % ignore this line \nr = find(sigma / sigma(1) > 10*eps, 1, 'last')\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor i = 1:4\n    subplot(2, 2, i)\n    k = 2*i;\n    Ak = U(:, 1:k) * S(1:k, 1:k) * V(:, 1:k)';\n    imshow(Ak, [0, 255])\n    title(sprintf('rank = %d', k))\nend\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\n[m, n] = size(A);\nfull_size = m * n;\ncompressed_size = 8 * (m + n + 1);\nfprintf(\"compression ratio: %.1f\", full_size / compressed_size)\n\nDimension reduction in voting records\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nload voting\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nclf\nimagesc(A)\ncolormap parula\ntitle('Votes in 111th U.S. Senate')   % ignore this line\nylabel('senator'),  xlabel('bill')    % ignore this line\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\ntau = cumsum(sigma.^2) / sum(sigma.^2);\nplot(tau(1:16), 'o')\nxlabel('k'),  ylabel('\\tau_k')  % ignore this line\ntitle('Fraction of singular value energy')     % ignore this line\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(211), plot(U(:, 1), '.')\nxlabel('senator number'), title('left singular vector')  % ignore this line\nsubplot(212), plot(V(:, 1), '.')\nxlabel('bill number'), title('right singular vector')  % ignore this line\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nclf\nx1 = V(:, 1)'*A';   x2 = V(:, 2)'*A'; \nscatter(x1(Dem), x2(Dem), 20, 'b'),  hold on\nscatter(x1(Rep), x2(Rep), 20, 'r')\nscatter(x1(Ind), x2(Ind), 20, 'k')\nxlabel('partisanship'),  ylabel('bipartisanship')  % ignore this line\ntitle('111th US Senate in 2D')","type":"content","url":"/chapter7-1#id-7-5","position":13},{"hierarchy":{"lvl1":"Preface to the original edition"},"type":"lvl1","url":"/preface-original","position":0},{"hierarchy":{"lvl1":"Preface to the original edition"},"content":"I’ve developed an obscene interest in computation, and I’ll be returning to the United States a better and impurer man.\n\nJohn von Neumann\n\nIt might seem that computing should simply be a matter of translating formulas from the page to the machine. But even when such formulas are known, applying them in a numerical fashion requires care. For instance, rounding off numbers at the sixteenth significant digit can lay low such stalwarts as the quadratic formula! Fortunately, the consequences of applying a numerical method to a mathematical problem are quite understandable from the right perspective. In fact, it is our mastery of what can go wrong in some approaches that gives us confidence in the rest of them.\n\nIf mathematical modeling is the process of turning real phenomena into mathematical abstractions, then numerical computation is largely about the transformation from abstract mathematics to concrete reality.  Many science and engineering disciplines have long benefited from the tremendous value of the correspondence between quantitative information and mathematical manipulation. Other fields, from biology to history to political science, are rapidly catching up. In our opinion, a young mathematician who is ignorant of numerical computation in the 21st century has much in common with one who was ignorant of calculus in the 18th century.","type":"content","url":"/preface-original","position":1},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the student"},"type":"lvl2","url":"/preface-original#to-the-student","position":2},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the student"},"content":"Welcome! We expect that you have had lessons in manipulating power series, solving linear systems of equations, calculating eigenvalues of matrices, and obtaining solutions of differential equations. We also expect that you have written computer programs that take a nontrivial number of steps to perform a well-defined task, such as sorting a list. Even if you have rarely seen how these isolated mathematical and computational tasks interact with one another, or what they have to do with practical realities, you are in the audience for this book.\n\nBased on our experiences teaching this subject, our guess is that some rough seas may lie ahead of you. Probably you do not remember learning all parts of calculus, linear algebra, differential equations, and computer science with equal skill and fondness. This book draws from all of these areas at times, so your weaknesses are going to surface once in a while. Furthermore, this may be the first course you have taken that does not fit neatly within a major discipline. Von Neumann’s use of “impurer” in the quote above is a telling one: numerical computation is about solving problems, and the search for solution methods that work well can take us across intellectual disciplinary boundaries. This mindset may be unfamiliar and disorienting at times.\n\nDon’t panic! There is a great deal to be gained by working your way through this book. It goes almost without saying that you can acquire computing skills that are in much demand for present and future use in science, engineering, and mathematics—and increasingly, in business, social science, and humanities, too. There are less tangible benefits as well. Having a new context to wrestle with concepts like Taylor series and matrices may shed new light on why they are important enough to learn. It can be exhilarating to apply skills to solve relatable problems. Finally, the computational way of thought is one that complements other methods of analysis and can serve you well.","type":"content","url":"/preface-original#to-the-student","position":3},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the instructor"},"type":"lvl2","url":"/preface-original#to-the-instructor","position":4},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the instructor"},"content":"The plausibly important introductory material on numerical computation for the majority of undergraduate students easily exceeds the capacity of two semesters—and of one textbook. As instructors and as authors, we face difficult choices as a result. We set aside the goal of creating an agreeable canon. Instead we hope for students to experience an echo of that “obscene interest” that von Neumann so gleefully described and pursued. For while there are excellent practical reasons to learn about numerical computing, it also stands as a subject of intellectual and even emotional relevance. We have seen students excited and motivated by applications of their newly found abilities to problems in mechanics, biology, networks, finance, and more—problems that are of unmistakable importance in the jungle beyond university textbooks, yet largely impenetrable using only the techniques learned within our well-tended gardens.\n\nIn writing this book, we have not attempted to be encyclopedic. We’re sorry if some of your favorite topics don’t appear or are minimized in the book. (It happened to us too; many painful cuts were made from prior drafts.) But in an information-saturated world, the usefulness of a textbook lies with teaching process, not content. We have aimed not for a cookbook but for an introduction to the principles of cooking.\n\nStill, there are lots of recipes in the book—it’s hard to imagine how one could become a great chef without spending time in the kitchen! Our language for these recipes is MATLAB for a number of reasons: it is precise, it is executable, it is as readable as could be hoped for our purposes, it rewards thinking at the vector and matrix level, and (at this writing) it is widespread and worth knowing.\nThere are 46 standalone functions and over 150 example scripts, all of them downloadable exactly as seen in the text. Some of our codes are quite close to production quality, some are serviceable but lacking, and others still are meant for demonstration only. Ultimately our codes are mainly meant to be clear, not ideal. We try to at least be explicit about the shortcomings of our implementations.\n\nJust as good coding and performance optimization are secondary objectives of the book, we cut some corners in the mathematics as well. We state and in some cases prove the most essential and accessible theorems, but this is not a theorem-oriented book, and in some cases we are content with less precise arguments. We have tried to make clear where solid proof ends and where approximation, estimation, heuristics, and other indispensable tools of numerical analysis begin.\n\nThe examples and exercises are meant to show and encourage a numerical mode of thought. As such they often focus on issues of convergence, experimentation leading to abstraction, and attempts to build on or refine presented ideas. Some exercises follow the premise that an algorithm’s most interesting mode of operation is failure. We expect that any learning resulting from the book is likely to take place mostly from careful study of the examples and working through the problems.","type":"content","url":"/preface-original#to-the-instructor","position":5},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"Acknowledgments"},"type":"lvl2","url":"/preface-original#acknowledgments","position":6},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"Acknowledgments"},"content":"We are, of course, deeply indebted to all who taught us and inspired us about numerical computation over the years. We are thankful to Rodrigo Platte, who used the book before it was fully baked and offered numerous suggestions. We thank an enthusiastic group of grad students for proofreading help: Samuel Cogar, Shukai Du, Kristopher Hollingsworth, Rayanne Luke, Navid Mirzaei, Nicholas Russell, and Osman Usta.  We are also grateful to Paula Callaghan and the publishing team at SIAM, whose dedication to affordable, high-quality books makes a real difference in the field.\n\nWe thank our families for their support and endurance. Last but not least, we are grateful to the many students at the University of Delaware who have taken courses based on iterations of this book. Their experiences are what convinced us that the project was worth finishing.","type":"content","url":"/preface-original#acknowledgments","position":7},{"hierarchy":{"lvl1":"Preface to the original edition","lvl3":"Contents","lvl2":"Acknowledgments"},"type":"lvl3","url":"/preface-original#contents","position":8},{"hierarchy":{"lvl1":"Preface to the original edition","lvl3":"Contents","lvl2":"Acknowledgments"},"content":"Chapter 1 explains how computers represent numbers and arithmetic, and what doing so means for mathematical expressions. Chapter 2 discusses the solution of square systems of linear equations and, more broadly, basic numerical linear algebra. Chapter 3 extends the linear algebra to linear least squares. These topics are the bedrock of scientific computing, because “everything” has multiple dimensions, and while “everything” is also nonlinear, our preferred starting point is to linearize.\n\nChapters 4 through 6 introduce what we take to be the rest of the most common problem types in scientific computing: roots and minimization of algebraic functions, piecewise approximation of functions, numerical analogs of differentiation and integration, and initial-value problems for ordinary differential equations. We also explain some of the most familiar and reliable ways to solve these problems, effective up to a certain point of size and/or difficulty. Chapters 1 through 6 can serve for a single-semester survey course. If desired, Chapter 6 could be left out in favor of one of Chapters 7, 8, or 9.\n\nThe remaining chapters are intended for a second course in the material. They go into more sophisticated types of problems (eigenvalues and singular values, boundary value problems, and partial differential equations), as well as more advanced techniques for problems from the first half (Krylov subspace methods, spectral approximation, stiff problems, boundary conditions, and tensor-product discretizations).","type":"content","url":"/preface-original#contents","position":9},{"hierarchy":{"lvl1":"Preface to the Julia edition"},"type":"lvl1","url":"/preface","position":0},{"hierarchy":{"lvl1":"Preface to the Julia edition"},"content":"The invention of MATLAB introduced a new paradigm within research of numerical computation. Those concerned primarily with prototyping and perfecting algorithms, particularly those involving lots of linear algebra, optimization, and differential equations, were happy to adopt MATLAB as a primary computing environment. It offered concise syntax for such problems, freedom from variable types and declarations, compiling, and linking programs, convenient tools for analyzing results, and cross-platform uniformity. There were drawbacks, however, when it came to performance, scalability, and language features beyond the manipulation of vectors and matrices. While MATLAB has steadily made serious progress on closing the performance gap and introducing new language features, there remain computing tasks for which it is not ideally suited.\n\nThe landscape changed when the SciPy, NumPy, and Matplotlib packages for scientific computing in Python became stable and polished. These enabled Python to offer a fully featured MATLAB alternative that is free, open, and tightly integrated with a much larger world of computing. Among these valuable advances, though, a serious compromise lurked: performance got worse, often by orders of magnitude. While there are notable efforts to overcome the bottlenecks for many use cases, Python continues to face deep and steep performance challenges as a general-purpose scientific computing ecosystem.\n\nJulia was designed from its inception to prioritize numerical scientific computing. It has reaped the benefits of learning from decisions and adaptations made in MATLAB and Python, borrowing the best parts from them and tackling their deficiencies. Julia’s older cousins enjoy a big head start, so it’s impossible to know what the size of Julia’s niche will ultimately be, but interest has continued to build.\n\nWhy teach using Julia? The immediate benefits of Julia over MATLAB for the material in this text include:\n\nJulia allows Unicode characters, such as Greek letters, subscripts, and symbols, as variable names and operators, which makes code look more like mathematics.\n\nJulia makes it effortless to define functions inside of scripts as well as other functions.\n\nJulia’s broadcasting syntax clarifies how to apply functions elementwise to arrays.\n\nComprehensions are convenient and concise ways to construct vectors and matrices.\n\nJulia makes it easier to define keyword and optional function arguments.\n\nThere are also differences that cut both ways; for instance, Julia is often stricter about data types and sizes, which makes it more verbose and more prone to error, but arguably less likely to finish with unexpected results.\n\nMoreover, there are some tradeoffs. MATLAB ships with and installs everything needed for this text, while Julia requires a small installation effort to get started. MATLAB’s documentation is superior, and it’s easier to get accurate help on the Internet. MATLAB’s integrated desktop, particularly the debugger, are not yet fully matched in Julia.\n        \nThere is also a wider context to consider. Julia skills are more likely to be directly applicable in, or more easily transferrable to, high-performance applications. Julia interoperates easily with Python, R, C, and even MATLAB. Julia is native to the widely used Jupyter notebook system that currently dominates data science. Not least, as a free and open-source environment, Julia enables fully reproducible computing, which is increasingly appreciated as essential to long-term progress in research.","type":"content","url":"/preface","position":1},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from Julia"},"type":"lvl2","url":"/preface#what-to-expect-from-julia","position":2},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from Julia"},"content":"Unlike MATLAB and Python, Julia is just-in-time (JIT) compiled, not interpreted. As a result, large packages, including several supporting the code in this book, can take a few seconds to load. Furthermore, if you make a change to one of your own functions, or apply it to new types of function arguments, Julia may hesitate a moment while it compiles the necessary code. On slower hardware, or with frequent revision, the lag can become irritating.","type":"content","url":"/preface#what-to-expect-from-julia","position":3},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from this book"},"type":"lvl2","url":"/preface#what-to-expect-from-this-book","position":4},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from this book"},"content":"*Supplemental material, including animations, downloadable code and examples, suggested projects, and more, can be found at \n\nhttps://​bookstore​.siam​.org​/ot177​/bonus.\n\nWe do not attempt to teach how to become a great Julia programmer. That goal is too ambitious when stacked alongside the mathematical ones. Instead we hope to exhibit decent style and avoid promoting bad habits. But when there is a conflict, clarity and simplicity usually override performance concerns.  A virtue of Julia is that one can start with a working straightforward code that can be adapted and improved to meet performance demands; we are introducing just the first stage of this process.\n\nOne choice advanced users might question is that we address vectors and matrices as starting from index 1, rather than using more general constructs such as eachindex, begin, and first. Our mathematics makes those specific references too, and in most languages, one must learn to deal directly with the difference between, say, 1-indexing and 0-indexing.\n\nAnother notable choice we have made is the use of the popular Plots package for graphics. There are many other fine choices, including and not limited to PyPlot, Makie, and PlotlyJS, but we needed to be concrete.\n\nBeyond that, we touch briefly on available packages that offer advanced functionality for the problem types we study. Our hope is that the student will not only learn fundamentals by working with simple codes in the book, but also learn about the existence and syntax of some power tools for serious applications.\n\nFinally, we have made no mention of one of Julia’s defining features, multiple dispatch. Using its power wisely edges into advanced software design and usually requires a bird’s-eye view of problems that beginners lack. We want to let students expend as much of their cognitive budget as possible on the mathematical principles that have universal application.","type":"content","url":"/preface#what-to-expect-from-this-book","position":5},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"Acknowledgments"},"type":"lvl2","url":"/preface#acknowledgments","position":6},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"Acknowledgments"},"content":"Finally, we have made no mention of one of Julia’s defining features, multiple dispatch. Using its power wisely edges into advanced software design and usually requires a bird’s-eye view of problems that beginners lack. We want to let students expend as much of their cognitive budget as possible on the mathematical principles that have universal application.","type":"content","url":"/preface#acknowledgments","position":7},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"Acknowledgments"},"type":"lvl2","url":"/preface#acknowledgments-1","position":8},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"Acknowledgments"},"content":"We are indebted to Qinying Chen, Hugo Diaz, Mary Gockenbach, Aidan Hamilton, Pascal Kingsley Kataboh, Lindsey Jacobs, Ross Russell, and Jerome Troy, who made this text more accurate and more readable with their sharp eyes and great suggestions. And we are deeply grateful to Paula Callaghan at SIAM, whose patience, dedication, and wisdom were crucial to seeing this through to the end.\n\nIt is strongly recommended that you use at least version 1.6 of Julia. In earlier versions, the wait to compile and load packages can become long.\n\nIn a fast-changing language like Julia, yesterday’s performance roadblocks can disappear anyway.","type":"content","url":"/preface#acknowledgments-1","position":9},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1-2","position":0},{"hierarchy":{"lvl1":"Chapter 1"},"content":"Python implementations","type":"content","url":"/chapter1-2","position":1},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"type":"lvl2","url":"/chapter1-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"content":"Horner’s algorithm for evaluating a polynomial\n\ndef horner(c,x):\n    \"\"\"\n    horner(c,x)\n\n    Evaluate a polynomial whose coefficients are given in descending order \n    in `c`, at the point `x`, using Horner's rule.\n    \"\"\"\n    n = len(c)\n    y = c[0]\n    for k in range(1, n):\n        y = x * y + c[k]   \n    return y","type":"content","url":"/chapter1-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"type":"lvl2","url":"/chapter1-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"content":"\n\nfrom numpy import *\nimport FNC\n\n","type":"content","url":"/chapter1-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Section 1.1"},"type":"lvl2","url":"/chapter1-2#section-1-1","position":6},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Section 1.1"},"content":"Absolute and relative accuracy\n\nRecall the grade-school approximation to the number π.\n\np = 22/7\nprint(p)\n\nNot all the digits displayed for p are the same as those of π.\n\nThe value of pi is predefined in the numpy package.\n\nprint(pi)\n\nThe absolute and relative accuracies of the approximation are as follows:\n\nWe often use \n\nPython f-strings to format numerical output.\n\nprint(f\"absolute accuracy: {abs(p - pi)}\")\n\nrel_acc = abs(p - pi) / pi\nprint(\"relative accuracy: {rel_acc:.4e}\")\n\nHere we calculate the number of accurate digits in p:\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprint(f\"accurate digits: {-log10(rel_acc):.1f}\")\n\nFloating-point representation\n\nPython has native int and float types.\n\nprint(f\"The type of {1} is {type(1)}\")\nprint(f\"The type of {float(1)} is {type(1.0)}\")\n\nThe numpy package has its own float types:\n\none = float64(1)\nprint(f\"The type of {one} is {type(one)}\")\n\nBoth float and float64 are double precision, using 64 binary bits per value. Although it is not normally necessary to do so, we can deconstruct a float into its significand and exponent:\n\nx = 3.14\nmantissa, exponent = frexp(x)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nmantissa, exponent = frexp(x / 8)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon, given here for double precision:\n\nmach_eps = finfo(float).eps\nprint(f\"machine epsilon is {mach_eps:.4e}\")\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nprint(f\"machine epsilon is 2 to the power {log2(mach_eps)}\")\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the significand. The actual range of positive values in double precision is\n\nfinf = finfo(float)\nprint(f\"range of positive values: [{finf.tiny}, {finf.max}]\")\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2**(-4)\n\nYou can convert a floating value to an integer by wrapping it in int.\n\nint(3.14)\n\nFloating-point arithmetic oddity\n\nThere is no double precision number between 1 and 1+\\varepsilon_\\text{mach}. Thus, the following difference is zero despite its appearance.\n\neps = finfo(float).eps\ne = eps/2\nprint((1.0 + e) - 1.0)\n\nHowever, 1-\\varepsilon_\\text{mach}/2 is a double precision number, so it and its negative are represented exactly:\n\nprint(1.0 + (e - 1.0))\n\nThis is now the “correct” result. But we have found a rather shocking breakdown of the associative law of addition!","type":"content","url":"/chapter1-2#section-1-1","position":7},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.2","lvl2":"Section 1.1"},"type":"lvl3","url":"/chapter1-2#section-1-2","position":8},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.2","lvl2":"Section 1.1"},"content":"Conditioning of polynomial roots\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nThe statement x, y = 10, 20 makes individual assignments to both x and y.\n\nep = 1e-6   \na, b, c = 1/3, (-2 - ep) / 3, (1 + ep) / 3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b**2 - 4*a*c)\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\nprint(r1, r2)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative error in the value is\n\nprint(abs(r1 - 1) / abs(1))\nprint(abs(r2 - (1 + ep)) / abs(1 + ep))\n\nThe condition number of each root is\n\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}. \n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\nprint(finfo(float).eps / ep)\n\nThis matches the observation pretty well.","type":"content","url":"/chapter1-2#section-1-2","position":9},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.3","lvl2":"Section 1.1"},"type":"lvl3","url":"/chapter1-2#section-1-3","position":10},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.3","lvl2":"Section 1.1"},"content":"Using a function\n\nHere we show how to use horner to evaluate a polynomial. First, we have to ensure that the FNC package is imported.\n\nimport FNC\n\nHere is the help string for the function:\n\nhelp(FNC.horner)\n\nWe now define a vector of the coefficients of p(x)=(x−1)^3=x^3−3x^2+3x−1, in descending degree order. Note that the textbook’s functions are all in a namespace called FNC, to help distinguish them from other Python commands and modules.\n\nc = array([1, -3, 3, -1])\nprint(FNC.horner(c, 1.6))\n\nThe above is the value of p(1.6), up to a rounding error.","type":"content","url":"/chapter1-2#section-1-3","position":11},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.4","lvl2":"Section 1.1"},"type":"lvl3","url":"/chapter1-2#section-1-4","position":12},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"Section 1.4","lvl2":"Section 1.1"},"content":"Instability of the quadratic formula\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\nx2 = (-b - sqrt(b**2 - 4*a*c)) / 2*a\nprint(x1, x2)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6 - x2) / 1e-6 \nprint(f\"There are {-log10(error):.2f} accurate digits.\")\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nStable alternative to the quadratic formula\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a * x1)\nprint(x1, x2)\n\nTo be sure we have an accurate result, we compute its relative error.\n\nprint(abs(x2 - 1e-6) / 1e-6)\n\nBackward error\n\nOur first step is to construct a polynomial with six known roots.\n\nr = [-2, -1, 1, 1, 3, 6]\np = poly(r)\nprint(p)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr_computed = sort(roots(p))\nprint(r_computed)\n\nHere are the relative errors in each of the computed roots.\n\nprint(abs(r - r_computed) / r)\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np_computed = poly(r_computed)\nprint(p_computed)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nprint(abs(p - p_computed) / p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.","type":"content","url":"/chapter1-2#section-1-4","position":13},{"hierarchy":{"lvl1":"Chapter 2"},"type":"lvl1","url":"/chapter2-2","position":0},{"hierarchy":{"lvl1":"Chapter 2"},"content":"","type":"content","url":"/chapter2-2","position":1},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"type":"lvl2","url":"/chapter2-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"content":"Forward substitution\n\ndef forwardsub(L,b):\n    \"\"\"\n     forwardsub(L,b)\n\n    Solve the lower-triangular linear system with matrix L and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n):\n        s = L[i,:i] @ x[:i]\n        x[i] = ( b[i] - s ) / L[i, i]\n    return x\n\nBackward substitution\n\ndef backsub(U,b):\n    \"\"\"\n    backsub(U,b)\n\n    Solve the upper-triangular linear system with matrix U and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n-1, -1, -1):\n        s = U[i, i+1:] @ x[i+1:]\n        x[i] = ( b[i] - s ) / U[i, i]\n    return x\n\nLU factorization (not stable)\n\ndef lufact(A):\n    \"\"\"\n    lufact(A)\n\n    Compute the LU factorization of square matrix `A`, returning the\n    factors.\n    \"\"\"\n    n = A.shape[0]     # detect the dimensions from the input\n    L = np.eye(n)      # ones on main diagonal, np.zeros elsewhere\n    U = np.zeros((n, n))\n    A_k = np.copy(A)   # make a working np.copy \n\n    # Reduction by np.outer products\n    for k in range(n-1):\n        U[k, :] = A_k[k, :]\n        L[:, k] = A_k[:, k] / U[k,k]\n        A_k -= np.outer(L[:,k], U[k,:])\n    U[n-1, n-1] = A_k[n-1, n-1]\n    return L, U\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out a subtle issue. Array variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement A_k = A would just clone the array reference of A into the new variable. Any changes made to entries of A_k would then also be made to entries of A, because they refer to the same location in memory. In this context, we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nLU factorization with partial pivoting\n\ndef plufact(A):\n    \"\"\"\n        plufact(A)\n\n    Compute the PLU factorization of square matrix `A`, returning the\n    triangular factors and a row permutation vector.\n    \"\"\"\n    n = A.shape[0]\n    L = np.zeros((n, n))\n    U = np.zeros((n, n))\n    p = np.zeros(n, dtype=int)\n    A_k = np.copy(A)\n\n    # Reduction by np.outer products\n    for k in range(n):\n        p[k] = np.argmax(abs(A_k[:, k]))\n        U[k, :] = A_k[p[k], :]\n        L[:, k] = A_k[:, k] / U[k, k]\n        if k < n-1:\n            A_k -= np.outer(L[:, k], U[k, :])\n    return L[p, :], U, p","type":"content","url":"/chapter2-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"type":"lvl2","url":"/chapter2-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"content":"\n\n# from scipy import *\nfrom numpy import *\nfrom matplotlib.pyplot import *\nfrom numpy.linalg import solve\nimport scipy.sparse as sparse\nfrom timeit import default_timer as timer\nimport FNC\n\n# This (optional) block is for improving the display of plots.\n# from IPython.display import set_matplotlib_formats\n# set_matplotlib_formats(\"svg\",\"pdf\")\n# %config InlineBackend.figure_format = 'svg'\nrcParams[\"figure.figsize\"] = [7, 4]\nrcParams[\"lines.linewidth\"] = 2\nrcParams[\"lines.markersize\"] = 4\nrcParams['animation.html'] = \"jshtml\"  # or try \"html5\"\n\n","type":"content","url":"/chapter2-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-1","position":6},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.1","lvl2":"Examples"},"content":"Linear system for polynomial interpolation\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = arange(1980, 2020, 10)   # from 1980 to 2020 by 10\npop = array([984.736, 1148.364, 1263.638, 1330.141])\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980\ny = pop\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\nprint(V)\n\nTo solve a linear system \\mathbf{V} \\mathbf{c} = \\mathbf{y} for the vector of polynomial coefficients, we use solve (imported from numpy.linalg):\n\nc = solve(V, y)\nprint(c)\n\nThe algorithms used by solve are the main topic of this chapter. As a check on the solution, we can compute the residual \\mathbf{y} - \\mathbf{V} \\mathbf{c}, which should be small (near machine precision).\n\nMatrix multiplication in NumPy is done with @ or matmul.\n\nprint(y - V @ c)\n\nBy our definitions, the coefficients in c are given in descending order of power in t. We can use the resulting polynomial to estimate the population of China in 2005:\n\np = poly1d(c)          # construct a polynomial\nprint(p(2005 - 1980))     # apply the 1980 time shift\n\nThe official figure was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points. Then we add a plot of the interpolant, taking care to shift the t variable back to actual years.\n\nscatter(year, y, color=\"k\", label=\"data\");\ntt = linspace(0, 30, 300)   # 300 times from 1980 to 2010\nplot(1980 + tt, p(tt), label=\"interpolant\");\nxlabel(\"year\");\nylabel(\"population (millions)\");\ntitle(\"Population of China\");\nlegend();","type":"content","url":"/chapter2-2#section-2-1","position":7},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-2","position":8},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.2","lvl2":"Examples"},"content":"Matrix operations\n\nNote\n\nWhile NumPy does have distinct representations for matrices and 2D arrays, use of the explicit matrix class is officially discouraged. We follow this advice here and use arrays to represent both matrices and vectors. :::{index}\nsee: Python; size, Python; shape\n::: \n\nA vector is created using square brackets and commas to enclose and separate its entries.\n\nx = array([3, 3, 0, 1, 0 ])\nprint(x.shape)\n\nTo construct a matrix, you nest the brackets to create a “vector of vectors”. The inner vectors are the rows.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    [pi, sqrt(2), exp(1), (1+sqrt(5))/2, log(3)] \n    ])\n\nprint(A)\nprint(A.shape)\n\nIn this text, we treat all vectors as equivalent to matrices with a single column. That isn’t true in NumPy, because even an n \\times 1 array has two dimensions, unlike a vector.\n\narray([[3], [1], [2]]).shape\n\nYou can concatenate arrays with compatible dimensions using hstack and vstack.\n\nprint( hstack([A, A]) )\n\nprint( vstack([A, A]) )\n\nTransposing a matrix is done by appending .T to it.\n\nprint(A.T)\n\nFor matrices with complex values, we usually want instead the adjoint or hermitian, which is .conj().T.\n\nprint((x + 1j).conj().T)\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a vector with evenly spaced entries between two endpoints, you have two options.\n\nprint(arange(1, 7, 2))   # from 1 to 7 (not inclusive), step by 2\n\nprint(linspace(-1, 1, 5))   # from -1 to 1 (inclusive), with 5 total values\n\nThe practical difference between these is whether you want to specify the step size in arange or the number of points in linspace.\n\nAccessing an element is done by giving one (for a vector) or two index values in square brackets. In Python, indexing always starts with zero, not 1.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    linspace(-5, 5, 5) \n    ])\nx = array([3, 2, 0, 1, -1 ])\n\nprint(\"row 2, col 3 of A:\", A[1, 2])\nprint(\"first element of x:\", x[0])\n\nThe indices can be ranges, in which case a slice or block of the matrix is accessed. You build these using a colon in the form start:stop. However, the last value of this range is stop-1, not stop.\n\nprint(A[1:3, 0:2])    # rows 2 and 3, cols 1 and 2\n\nIf start or stop is omitted, the range extends to the first or last index.\n\nprint(x[1:])  # elements 2 through the end\n\nprint(A[:2, 0])  # first two rows in column 1\n\nNotice in the last case above that even when the slice is in the shape of a column vector, the result is just a vector with one dimension and neither row nor column shape.\n\nThere are more variations on the colon ranges. A negative value means to count from the end rather than the beginning. And a colon by itself means to include everything from the relevant dimension.\n\nprint(A[:-1, :])    # all rows up to the last, all columns\n\nFinally, start:stop:step means to step size or stride other than one. You can mix this with the other variations.\n\nprint(x[::2])  # all the odd indexes\n\nprint(A[:, ::-1])  # reverse the columns\n\nThe matrix and vector senses of addition, subtraction, and scalar multiplication and division are all handled by the usual symbols. Two matrices of the same size (what NumPy calls shape) are operated on elementwise.\n\nprint(A - 2 * ones([3, 5]))  # subtract two from each element\n\nIf one operand has a smaller number of dimensions than the other, Python tries to broadcast it in the “missing” dimension(s), and the operation proceeds if the resulting shapes are identical.\n\nprint(A - 2)    # subtract two from each element\n\nu = array([1, 2, 3, 4, 5])\nprint(A - u)    # repeat this row for every row of A\n\nv = array([1, 2, 3])\nprint(A - v)  # broadcasting this would be 3x3, so it's an error\n\nprint(A - v.reshape([3, 1]))    # broadcasts to each column of A ```{index} \nsee: Python; matrix multiplication, Python; \\@\n``` \n\nMatrix–matrix and matrix–vector products are computed using @ or matmul.\n\nB = diag([-1, 0, -5])    # create a diagonal 3x3\nprint(B @ A)    # matrix product\n\nAB is undefined for these matrix sizes.\n\nprint(A @ B)    # incompatible sizes\n\nThe multiplication operator * is reserved for elementwise multiplication. Both operands have to be the same size, after any potential broadcasts.\n\nprint(B * A)    # not the same size, so it's an error\n\nprint((A / 2) * A)    # elementwise\n\nTo raise to a power elementwise, use a double star. This will broadcast as well.\n\nprint(B)\nprint(B**3)\n\nprint(x)\nprint(2.0**x)\n\nDanger\n\nIf A is a matrix, A**2 is not the same as mathematically raising it to the power 2.\n\nMost of the mathematical functions, such as cos, sin, log, exp and sqrt, expecting scalars as operands will be broadcast to arrays.\n\nprint(cos(pi * x))","type":"content","url":"/chapter2-2#section-2-2","position":9},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-3","position":10},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.3","lvl2":"Examples"},"content":"Solving linear systems\n\nFor a square matrix A, the command solve(A, B) is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = array([[1, 0, -1], [2, 2, 1], [-1, -3, 0]])\nb = array([1, 2, 3])\n\nx = solve(A, b)\nprint(x)\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision(relative to the elements in the data).\n\nresidual = b - A @ x\nprint(residual)\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = array([[0, 1], [0, 0]])\nb = array([1, -1])\nsolve(A, b)    # error, singular matrix\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, a numerical solution becomes trickier. Detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. We’re headed toward a more robust way to fully describe this situation.\n\nTriangular systems of equations\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nA = 1 + floor(9 * random.rand(5, 5))\nL = tril(A)\nprint(L)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L, b)\nprint(x)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L @ x\n\nNext we’ll engineer a problem to which we know the exact answer.\n\nalpha = 0.3;\nbeta = 2.2;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nprint(U)\n\nx_exact = ones(5)\nb = array([alpha, 0, 0, 0, 1])\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nb = array([alpha, 0, 0, 0, 1])\n\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! But the source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.","type":"content","url":"/chapter2-2#section-2-3","position":11},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-4","position":12},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.4","lvl2":"Examples"},"content":"Triangular outer products\n\nWe explore the outer product formula for two random triangular matrices.\n\nfrom numpy.random import randint\nL = tril(randint(1, 10, size=(3, 3)))\nprint(L)\n\nU = triu(randint(1, 10, size=(3, 3)))\nprint(U)\n\nHere are the three outer products appearing in the sum in \n\n(2.4.4):\n\nprint(outer(L[:, 0], U[0, :]))\n\nprint(outer(L[:, 1], U[1, :]))\n\nprint(outer(L[:, 2], U[2, :]))\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nLU factorization\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = array([\n     [2,    0,    4,    3], \n     [-4,    5,   -7,  -10], \n     [1,   15,    2,   -4.5],\n     [-2,    0,    2,  -13]\n        ])\nL = eye(4)\nU = zeros((4, 4));\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[0, :] = A_1[0, :]\nprint(U)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 0] = A_1[:, 0] / U[0, 0]\nprint(L)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - outer(L[:, 0],  U[0, :])\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[1, :] = A_2[1, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nprint(L)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - outer(L[:, 1], U[1, :])\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[2, :] = A_3[2, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\n\nFinally, we pick up the last unknown in the factors.\n\nU[3, 3] = A_4[3, 3]\n\nWe now have all of \\mathbf{L},\n\nprint(L)\n\nand all of \\mathbf{U},\n\nprint(U)\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L @ U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nSolving a linear system by LU factors\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = array([\n    [2, 0, 4, 3], \n    [-4, 5, -7, -10], \n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nb = array([4, 9, 9, 4])\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A @ x","type":"content","url":"/chapter2-2#section-2-4","position":13},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-5","position":14},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.5","lvl2":"Examples"},"content":"Floating-point operations in matrix-vector multiplication\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = random.rand(n, n)\nx = ones(n)\ny = zeros(n)\nfor i in range(n):\n    for j in range(n):\n        y[i] += A[i, j] * x[j]   # 2 flops\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. We assume that flops dominate the computation time and thus measure elapsed time.\n\nN = 400 * arange(1, 11)\nt = []\nprint(\"  n           t\")\nfor i, n in enumerate(N):\n    A = random.randn(n, n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(50): A @ x\n    t.append(timer() - start)\n    print(f\"{n:5}   {t[-1]:10.3e}\")\n\nThe reason for doing multiple repetitions at each value of n above is to avoid having times so short that the resolution of the timer is a factor.\n\nLooking at the timings just for n=2000 and n=4000, they have ratio:\n\nprint(t[9] / t[4])\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nAsymptotics in log-log plots\n\nLet’s repeat the experiment of the previous example for more, and larger, values of n.\n\nN = arange(400, 6200, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(20): A@x\n    t[i] = timer() - start\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables, but is formatted more neatly.\n\nfig, ax = subplots()\nax.loglog(N, t, \"-o\", label=\"observed\")\nylabel(\"elapsed time (sec)\");\nxlabel(\"$n$\");\ntitle(\"Timing of matrix-vector multiplications\");\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nax.loglog(N, t[-1] * (N/N[-1])**2, \"--\", label=\"$O(n^2)$\")\nax.legend();  fig\n\nFloating-point operations in LU factorization\n\nWe’ll test the conclusion of O(n^3) flops experimentally using the lu function imported from scipi.linalg.\n\nfrom scipy.linalg import lu\nN = arange(200, 2600, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    start = timer()\n    for j in range(5): lu(A)\n    t[i] = timer() - start\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nloglog(N, t, \"-o\", label=\"obseved\")\nloglog(N, t[-1] * (N / N[-1])**3, \"--\", label=\"$O(n^3)$\")\nlegend();\nxlabel(\"$n$\");\nylabel(\"elapsed time (sec)\");\ntitle(\"Timing of LU factorizations\");","type":"content","url":"/chapter2-2#section-2-5","position":15},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-6","position":16},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.6","lvl2":"Examples"},"content":"Failure of naive LU factorization\n\nHere is a previously encountered matrix that factors well.\n\nA = array([\n    [2, 0, 4, 3],\n    [-4, 5, -7, -10],\n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nL, U = FNC.lufact(A)\nprint(L)\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[1, 3], :] = A[[3, 1], :]  \nL, U = FNC.lufact(A)\nprint(L)\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[0, :] = A[0, :]\nL[:, 0] = A[:, 0] / U[0, 0]\nA -= outer(L[:, 0],  U[0, :])\nprint(A)\n\nThe next step is U[1, :] = A[1, :], which is also OK. But then we are supposed to divide by U[1, 1], which is zero. The algorithm cannot continue.\n\nRow pivoting in LU factorization\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs(A_1[:, 0]) )\nprint(i)\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = eye(4), zeros((4, 4))\nU[0, :] = A_1[i, :]\nL[:, 0] = A_1[:, 0] / U[0, 0]\nA_2 = A_1 - outer(L[:, 0], U[0, :])\nprint(A_2)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\ni = argmax( abs(A_2[:, 1]) ) \nprint(f\"new pivot row is {i}\")\nU[1, :] = A_2[i, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nA_3 = A_2 - outer(L[:, 1], U[1, :])\nprint(A_3)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\ni = argmax( abs(A_3[:, 2]) ) \nprint(f\"new pivot row is {i}\")\nU[2, :] = A_3[i, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\nprint(A_4)\n\ni = argmax( abs(A_4[:, 3]) ) \nprint(f\"new pivot row is {i}\")\nU[3, :] = A_4[i, :]\nL[:, 3] = A_4[:, 3] / U[3, 3];\n\nWe do have a factorization of the original matrix:\n\nA_1 - L @ U\n\nAnd \\mathbf{U} has the required structure:\n\nprint(U)\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nprint(L)\n\nRow permutation in LU factorization\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1 (with NumPy indices being one less). If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A[[3, 2, 1, 0], :]\nL, U = FNC.lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nprint(U)\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nprint(L)\n\nPLU factorization for solving linear systems\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = random.randn(4, 4)\nL, U, p = FNC.plufact(A)\nA[p, :] - L @ U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = random.randn(4)\nz = FNC.forwardsub(L, b[p])\nx = FNC.backsub(U, z)\n\nA residual check is successful:\n\nb - A @ x\n\nBuilt-in PLU factorization\n\nIn linalg.solve, the matrix A is PLU-factored, followed by two triangular solves. If we want to do those steps seamlessly, we can use the lu_factor and lu_solve from scipy.linalg.\n\nfrom scipy.linalg import lu_factor, lu_solve\nA = random.randn(500, 500) \nb = ones(500)  \nLU, perm = lu_factor(A)\nx = lu_solve((LU, perm), b)\n\nWhy would we ever bother with this? In \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per matrix, but solve with multiple right-hand sides.\n\nstart = timer()\nfor k in range(50): linalg.solve(A, random.rand(500))\nprint(f\"elapsed time for 50 full solves: {timer() - start}\")\n\nstart = timer()\nLU, perm = lu_factor(A)\nfor k in range(50): lu_solve((LU, perm), random.rand(500))\nprint(f\"elapsed time for 50 shortcut solves: {timer() - start}\")\n\nStability of PLU factorization\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nep = 1e-12\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20;\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nprint(solve(A, b))","type":"content","url":"/chapter2-2#section-2-6","position":17},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-7","position":18},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.7","lvl2":"Examples"},"content":"Vector norms\n\nThe norm function from numpy.linalg computes vector norms.\n\nfrom numpy.linalg import norm\nx = array([2, -3, 1, -1])\nprint(norm(x))       # 2-norm by default\n\nprint(norm(x, inf))\n\nprint(norm(x, 1))\n\nMatrix norms\n\nfrom numpy.linalg import norm\nA = array([ [2, 0], [1, -1] ])\n\nThe default matrix norm is not the 2-norm. Instead, you must provide the 2 explicitly.\n\nprint(norm(A, 2))\n\nYou can get the 1-norm as well.\n\nprint(norm(A, 1))\n\nThe 1-norm is equivalent to\n\nprint(max( sum(abs(A), axis=0)) )  # sum down the rows\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\nprint(norm(A, inf))\n\nprint(max( sum(abs(A), axis=1)) )  # sum across columns\n\nHere we illustrate the geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\ntheta = linspace(0, 2*pi, 601)\nx = vstack([cos(theta), sin(theta)])  # 601 unit columns\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x simply by using a matrix multiplication.\n\ny = A @ x\n\nWe plot the unit circle on the left and the image of all mapped vectors on the right:\n\nsubplot(1,2,1)\nplot(x[0, :], x[1, :])\naxis(\"equal\")\ntitle(\"Unit circle\")\nxlabel(\"$x_1$\")\nylabel(\"$x_2$\")\n\nsubplot(1,2,2)\nplot(y[0, :], y[1, :])\nplot(norm(A, 2) * x[0, :], norm(A,2) * x[1, :],\"--\")\naxis(\"equal\")\ntitle(\"Image under map\")\nxlabel(\"$y_1$\")\nylabel(\"$y_2$\");\n\nAs seen on the right-side plot, the image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2.","type":"content","url":"/chapter2-2#section-2-7","position":19},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.8","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-8","position":20},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.8","lvl2":"Examples"},"content":"Matrix condition number\n\nThe function cond from numpy.linalg is used to computes matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nA = array([ \n    [1/(i + j + 2) for j in range(6)] \n    for i in range(6) \n    ])\nprint(A)\n\nfrom numpy.linalg import cond\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nNext we engineer a linear system problem to which we know the exact answer.\n\nx_exact = 1.0 + arange(6)\nb = A @ x_exact\n\nNow we perturb the data randomly with a vector of norm \n\n10-12.\n\ndA = random.randn(6, 6)\ndA = 1e-12 * (dA / norm(dA, 2))\ndb = random.randn(6)\ndb = 1e-12 * (db / norm(db, 2))\n\nWe solve the perturbed problem using built-in pivoted LU and see how the solution was changed.\n\nx = solve(A + dA, b + db) \ndx = x - x_exact\n\nHere is the relative error in the solution.\n\nprint(f\"relative error is {norm(dx) / norm(x_exact):.2e}\")\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprint(f\"b_bound: {kappa * 1e-12 / norm(b):.2e}\")\nprint(f\"A_bound: {kappa * 1e-12 / norm(A, 2):.2e}\")\n\nEven if we don’t make any manual perturbations to the data, machine epsilon does when we solve the linear system numerically.\n\nx = solve(A, b)\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nBecause \\kappa\\approx 10^8, it’s possible to lose 8 digits of accuracy in the process of passing from A and b to x. That’s independent of the algorithm; it’s inevitable once the data are expressed in double precision.\n\nLarger Hilbert matrices are even more poorly conditioned.\n\nA = array([ [1/(i+j+2) for j in range(14)] for i in range(14) ])\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nBefore we compute the solution, note that κ exceeds 1/eps. In principle we therefore might end up with an answer that is completely wrong (i.e., a relative error greater than 100%).\n\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nx_exact = 1.0 + arange(14)\nb = A @ x_exact  \nx = solve(A, b)\n\nWe got an answer. But in fact, the error does exceed 100%:\n\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")","type":"content","url":"/chapter2-2#section-2-8","position":21},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.9","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#section-2-9","position":22},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"Section 2.9","lvl2":"Examples"},"content":"Banded matrices\n\nHere is a matrix with both lower and upper bandwidth equal to one. Such a matrix is called tridiagonal.\n\nA = array([ \n    [2, -1,  0,  0,  0,  0],\n    [4,  2, -1,  0,  0,  0],\n    [0,  3,  0, -1,  0,  0],\n    [0,  0,  2,  2, -1,  0],\n    [0,  0,  0,  1,  1, -1],\n    [0,  0,  0,  0,  0,  2 ]\n    ])\n\nWe can extract the elements on any diagonal using the diag command. The “main” or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nprint( diag(A) )\n\nprint( diag(A, 1) )\n\nprint( diag(A, -1) )\n\nWe can also construct matrices by specifying a diagonal with the diag function.\n\nA = A + diag([pi, 8, 6, 7], 2)\nprint(A)\n\nL, U = FNC.lufact(A)\nprint(L)\n\nprint(U)\n\nObserve above that the lower and upper bandwidths of \\mathbf{A} are preserved in the factor matrices.\n\nTiming banded LU\n\nWe’ll use a large banded matrix to observe the speedup possible in LU factorization. If we use an ordinary dense matrix, then there’s no way to exploit a banded structure:\n\nn = 8000\nmain = 1 + arange(n)\nplusone = linspace(n-1, 1, n-1)\nminusone = ones(n-1)\nA = diag(main) + diag(plusone,1) + diag(minusone,1)\n\nfrom scipy.linalg import lu\nstart = timer()\nlu(A)\nprint(f\"time for dense banded: {timer() - start:.5f}\")\n\nIf instead we construct a proper sparse matrix, the speedup can be dramatic.\n\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import splu\nA = diags([main, plusone, minusone], [0, 1, -1], format=\"csc\")\nstart = timer()\nsplu(A)\nprint(f\"time for sparse banded: {timer() - start:.5f}\")\n\nSymmetric LDLT factorization\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = array([\n    [2,     4,     4,     2],\n    [4,     5,     8,    -5],\n    [4,     8,     6,     2],\n    [2,    -5,     2,   -26]\n    ])\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4)\nd = zeros(4)\nd[0] = A_1[0, 0]\nL[:, 0] = A_1[:, 0] / d[0]\nA_2 = A_1 - d[0] * outer(L[:, 0], L[:, 0])\nprint(A_2)\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[1] = A_2[1, 1]\nL[:, 1] = A_2[:, 1] / d[1]\nA_3 = A_2 - d[1] * outer(L[:, 1], L[:, 1])\nprint(A_3)\n\nWe continue working our way down the diagonal.\n\nd[2] = A_3[2, 2]\nL[:, 2] = A_3[:, 2] / d[2]\nA_4 = A_3 - d[2] * outer(L[:, 2], L[:, 2])\nprint(A_4)\n\nWe have arrived at the desired factorization.\n\nd[3] = A_4[3, 3]\nprint(\"diagonal of D:\")\nprint(d)\nprint(\"L:\")\nprint(L)\n\nThis should be comparable to machine roundoff:\n\nprint(norm(A_1 - (L @ diag(d) @ L.T), 2) / norm(A_1))\n\nCholesky factorization\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = 1.0 + floor(9 * random.rand(4, 4))\nB = A + A.T\nprint(B)\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nfrom numpy.linalg import cholesky\ncholesky(B)\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization:\n\nB = A.T @ A\nR = cholesky(B)\nprint(R)\n\nprint(norm(R @ R.T - B) / norm(B))","type":"content","url":"/chapter2-2#section-2-9","position":23},{"hierarchy":{"lvl1":"Chapter 3"},"type":"lvl1","url":"/chapter3-2","position":0},{"hierarchy":{"lvl1":"Chapter 3"},"content":"Python implementations","type":"content","url":"/chapter3-2","position":1},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"type":"lvl2","url":"/chapter3-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"content":"Solution of least squares by the normal equations\n\n    lsnormal(A,b)\n    \n    Solve a linear least squares problem by the normal equations. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    N = A.T @ A\n    z = A.T @ b\n    R = scipy.linalg.cholesky(N)\n    w = forwardsub(R.T, z)                   # solve R'z=c\n    x = backsub(R, w)                        # solve Rx=z\n    return x\n\ndef lsqrfact(A,b):\n\nAbout the code\n\ncholesky is imported from scipy.linalg.\n\nSolution of least squares by QR factorization\n\n    lsqrfact(A,b)\n    \n    Solve a linear least squares problem by QR factorization. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    Q, R = np.linalg.qr(A)\n    c = Q.T @ b\n    x = backsub(R, c)\n    return x\n\ndef qrfact(A):\n\nQR factorization by Householder reflections\n\n        qrfact(A)\n\n    QR factorization by Householder reflections. Returns Q and R.\n    \"\"\"\n    m, n = A.shape\n    Qt = np.eye(m)\n    R = np.copy(A)\n    for k in range(n):\n        z = R[k:, k]\n        w = np.stack((-np.sign(z[0]) * np.linalg.norm(z) - z[0], -z[1:]))\n        nrmw = np.linalg.norm(w)\n        if nrmw < np.finfo(float).eps: continue    # skip this iteration\n        v = w / nrmw\n        # Apply the reflection to each relevant column of R and Q\n        for j in range(k, n):\n            R[k:, j] -= 2 * np.dot(v, R[k:, j]) * v\n        for j in range(m):\n            Qt[k:, j] -= 2 * np.dot(v, Qt[k:, j]) * v \n    return Qt.T, np.triu(R)\n","type":"content","url":"/chapter3-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"type":"lvl2","url":"/chapter3-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"content":"\n\nfrom numpy import *\nfrom matplotlib.pyplot import *\nfrom numpy.linalg import solve, norm\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import splu\nfrom timeit import default_timer as timer\nimport FNC\n\n# This (optional) block is for improving the display of plots.\nrcParams[\"figure.figsize\"] = [7, 4]\nrcParams[\"lines.linewidth\"] = 2\nrcParams[\"lines.markersize\"] = 4\nrcParams['animation.html'] = \"jshtml\"  # or try \"html5\"\n\n","type":"content","url":"/chapter3-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#section-3-1","position":6},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.1","lvl2":"Examples"},"content":"Interpolating temperature data\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = arange(1955,2005,5)\ny = array([ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ])\n\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (year - 1950) / 10\nV = vander(t)\nc = solve(V, y)\nprint(c)\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\np = poly1d(c)    # convert to a polynomial\ntt = linspace(1955, 2000, 500)\nax.plot(tt, p((tt - 1950) / 10), label=\"interpolant\")\nax.legend();\nfig\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nFitting temperature data\n\nHere are the 5-year temperature averages again.\n\nyear = arange(1955, 2005, 5)\ny = array([-0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560])\nt = (year - 1950) / 10\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = array([ [t[i], 1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nfrom numpy.linalg import lstsq\nc, res, rank, sv = lstsq(V, y)\np = poly1d(c)\nf = lambda year: p((year - 1950) / 10)\n```{code-cell}\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"linear fit\")\n\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\nax.legend();\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = array([ [t[i]**3,t[i]**2,t[i],1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nThe definition of f above is in terms of c. When c is changed, f is updated with it.\n\nc, res, rank, sv = lstsq(V, y, rcond=None)\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"cubic fit\")\nfig\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nFitting a power law\n\na = array([1 / (k+1)**2 for k in range(100)])\ns = cumsum(a)        # cumulative summation\np = sqrt(6*s)\n\nplot(range(100), p, \"o\")\nxlabel(\"$k$\") \nylabel(\"$p_k$\") \ntitle(\"Sequence convergence\");\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p)    # error sequence\nloglog(range(100), ep, \"o\")\nxlabel(\"$k$\") \nylabel(\"error\") \ntitle(\"Sequence convergence\");\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = array([ [1, log(k+1)] for k in range(100) ])     # fitting matrix\nc = lstsq(V, log(ep), rcond=None)[0]           # coefficients of linear fit\nprint(c)\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[0]), c[1]\nprint(f\"b: {b:.3f}\")\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nloglog(range(100), ep, \"o\", label=\"sequence\")\nk = arange(1,100)\nplot(k, a*k**b, \"--\", label=\"power fit\")\nxlabel(\"$k$\");  ylabel(\"error\"); \nlegend(); title(\"Sequence convergence\");","type":"content","url":"/chapter3-2#section-3-1","position":7},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#section-3-2","position":8},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.2","lvl2":"Examples"},"content":"Instability in the normal equations\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nfrom numpy.linalg import cond\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nkappa = cond(A)\nprint(f\"cond(A) is {kappa:.3e}\")\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = array([1, 2, 1])\nb = A @ x\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nfrom numpy.linalg import lstsq\nx_BS = lstsq(A, b, rcond=None)[0]\nprint(f\"observed error: {norm(x_BS - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {kappa * finfo(float).eps:.3e}\")\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A.T @ A\nx_NE = solve(N, A.T @ b)\nrelative_err = norm(x_NE - x) / norm(x)\nprint(f\"observed error: {relative_err:.3e}\")\nprint(f\"accurate digits: {-log10(relative_err):.2f}\")","type":"content","url":"/chapter3-2#section-3-2","position":9},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#section-3-3","position":10},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.3","lvl2":"Examples"},"content":"QR factorization\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nA.shape\n\nHere is the full form:\n\nfrom numpy.linalg import qr\nQ, R = qr(A, \"complete\")\nprint(f\"size of Q is {Q.shape}\")\nprint(\"R:\")\nprint(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nprint(f\"norm of (Q^T Q - I) is {norm(Q.T @ Q - eye(6)):.3e}\")\n\nThe default for qr, and the one you usually want, is the thin form.\n\nQ_hat, R_hat = qr(A)\nprint(f\"size of Q_hat is {Q_hat.shape}\")\nprint(\"R_hat:\")\nprint(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nprint(f\"norm of (Q_hat^T Q_hat - I) is {norm(Q_hat.T @ Q_hat - eye(4)):.3e}\")\n\nStability of least-squares via QR\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nx = array([1, 2, 1])\nb = A @ x\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nprint(f\"observed error: {norm(FNC.lsqrfact(A, b) - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {cond(A) * finfo(float).eps:.3e}\")","type":"content","url":"/chapter3-2#section-3-3","position":11},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#section-3-4","position":12},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"Section 3.4","lvl2":"Examples"},"content":"Householder QR factorization\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nm, n = A.shape\nprint(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A[:, 0]\nv = z - norm(z) * hstack([1, zeros(m-1)])\nP_1 = eye(m) - (2 / dot(v, v)) * outer(v, v)   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nprint(P_1 @ z)\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 @ A\nprint(A)\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[1:, 1]\nv = z - norm(z) * hstack([1, zeros(m-2)])\nP_2 = eye(m-1) - (2 / dot(v, v)) * outer(v, v)\n\nWe now apply this reflector to rows 2 and below only.\n\nA[1:, 1:] = P_2 @ A[1:, 1:]\nprint(A)\n\nWe need to iterate the process for the last two columns.\n\nfor j in [2, 3]:\n    z = A[j:, j]\n    v = z - norm(z) * hstack([1, zeros(m-j-1)])\n    P = eye(m-j) - (2 / dot(v, v)) * outer(v, v)\n    A[j:, j:] = P @ A[j:, j:]\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)\nprint(R)","type":"content","url":"/chapter3-2#section-3-4","position":13},{"hierarchy":{"lvl1":"Chapter 4"},"type":"lvl1","url":"/chapter4-2","position":0},{"hierarchy":{"lvl1":"Chapter 4"},"content":"Python implementations","type":"content","url":"/chapter4-2","position":1},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"type":"lvl2","url":"/chapter4-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"content":"Newton’s method\n\ndef newton(f, dfdx, x1):\n    \"\"\"\n    newton(f, dfdx, x1)\n\n    Use Newton's method to find a root of `f` starting from `x1`, where `dfdx` is the\n    derivative of `f`. Returns a vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[0] = x1\n    y = f(x1)\n    dx = np.inf  # for initial pass below\n    k = 0\n\n    while (abs(dx) > xtol) and (abs(y) > funtol) and (k < maxiter):\n        dydx = dfdx(x[k])\n        dx = -y / dydx  # Newton step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y = f(x[k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n\n    return x[: k + 1]\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nSecant method\n\ndef secant(f, x1, x2):\n    \"\"\"\n    secant(f, x1, x2)\n\n    Use the secant method to find a root of `f` starting from `x1` and `x2`. Returns a\n    vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[:2] = [x1, x2]\n    y1 = f(x1)\n    y2 = 100\n    dx = np.inf  # for initial pass below\n    k = 1\n\n    while (abs(dx) > xtol) and (abs(y2) > funtol) and (k < maxiter):\n        y2 = f(x[k])\n        dx = -y2 * (x[k] - x[k - 1]) / (y2 - y1)  # secant step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y1 = y2  # current f-value becomes the old one next time\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:k+1]\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.\n\nNewton’s method for systems\n\ndef newtonsys(f, jac, x1):\n    \"\"\"\n        newtonsys(f, jac, x1)\n\n    Use Newton's method to find a root of a system of equations, starting from `x1`. The\n    function `f` should return the residual vector, and the function `jac` should return \n    the Jacobian matrix. Returns root estimates as a matrix, one estimate per column.\n    \"\"\"\n    # Operating parameters.\n    funtol = 1000 * np.finfo(float).eps\n    xtol = 1000 * np.finfo(float).eps\n    maxiter = 40\n\n    x = np.zeros((len(x1), maxiter))\n    x[:, 0] = x1\n    y, J = f(x1), jac(x1)\n    dx = 10.0  # for initial pass below\n    k = 0\n\n    while (norm(dx) > xtol) and (norm(y) > funtol) and (k < maxiter):\n        dx = -lstsq(J, y)[0]  # Newton step\n        x[:, k+1] = x[:, k] + dx\n\n        k = k + 1\n        y, J = f(x[:, k]), jac(x[:, k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:, :k+1]\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nFinite differences for Jacobian\n\ndef fdjac(f, x0, y0):\n    \"\"\"\n    fdjac(f,x0,y0)\n\n    Compute a finite-difference approximation of the Jacobian matrix for `f` at `x0`,\n    where `y0`=`f(x0)` is given.\n    \"\"\"\n\n    delta = np.sqrt(np.finfo(float).eps)  # FD step size\n    m, n = len(y0), len(x0)\n    J = np.zeros((m, n))\n    I = np.eye(n)\n    for j in range(n):\n        J[:, j] = (f(x0 + delta * I[:, j]) - y0) / delta\n    return J\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.\n\nLevenberg’s method\n\ndef levenberg(f, x1, tol=1e-12):\n    \"\"\"\n    levenberg(f,x1,tol)\n\n    Use Levenberg's quasi-Newton iteration to find a root of the system `f`, starting from\n    `x1`, with `tol` as the stopping tolerance in both step size and residual norm. Returns\n    root estimates as a matrix, one estimate per column.\n    \"\"\"\n\n    # Operating parameters.\n    ftol = tol\n    xtol = tol\n    maxiter = 40\n\n    n = len(x1)\n    x = np.zeros((n, maxiter))\n    x[:, 0] = x1\n    fk = f(x1)\n    k = 0\n    s = 10.0\n    Ak = fdjac(f, x[:, 0], fk)  # start with FD Jacobian\n    jac_is_new = True\n\n    lam = 10\n    while (norm(s) > xtol) and (norm(fk) > ftol) and (k < maxiter):\n        # Compute the proposed step.\n        B = Ak.T @ Ak + lam * np.eye(n)\n        z = Ak.T @ fk\n        s = -lstsq(B, z)[0]\n\n        xnew = x[:, k] + s\n        fnew = f(xnew)\n\n        # Do we accept the result?\n        if norm(fnew) < norm(fk):  # accept\n            y = fnew - fk\n            x[:, k + 1] = xnew\n            fk = fnew\n            k = k + 1\n\n            lam = lam / 10  # get closer to Newton\n            # Broyden update of the Jacobian.\n            Ak = Ak + np.outer(y - Ak @ s, s / np.dot(s, s))\n            jac_is_new = False\n        else:  # don't accept\n            # Get closer to steepest descent.\n            lam = lam * 4\n            # Re-initialize the Jacobian if it's out of date.\n            if not jac_is_new:\n                Ak = fdjac(f, x[:, k], fk)\n                jac_is_new = True\n\n    if norm(fk) > 1e-3:\n        warnings.warn(\"Iteration did not find a root.\")\n    return x[:, :k+1]","type":"content","url":"/chapter4-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"type":"lvl2","url":"/chapter4-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"content":"\n\nfrom numpy import *\nfrom matplotlib.pyplot import *\nfrom numpy.linalg import solve, norm\nimport scipy.sparse as sparse\nfrom scipy.sparse.linalg import splu\nfrom timeit import default_timer as timer\nfrom prettytable import PrettyTable\nimport FNC\n\n","type":"content","url":"/chapter4-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-1","position":6},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.1","lvl2":"Examples"},"content":"The rootfinding problem for Bessel functions\n\nimport scipy.special as special\ndef J3(x):\n    return special.jv(3.0, x)\n\nxx = linspace(0, 20, 500)\nfig, ax = subplots()\nax.plot(xx, J3(xx))\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$J_3(x)$\")\ntitle(\"Bessel function\")\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use root_scalar from the scipy.optimize package to find these roots accurately.\n\nfrom scipy.optimize import root_scalar\n\nomega = []\nfor guess in [6.0, 10.0, 13.0, 16.0, 19.0]:\n    s = root_scalar(J3, bracket=[guess - 0.5, guess + 0.5]).root\n    omega.append(s)\n\nresults = PrettyTable()\nresults.add_column(\"root estimate\", omega)\nresults.add_column(\"function value\", [J3(ω) for ω in omega])\nprint(results)\n\nax.scatter(omega, J3(omega))\nax.set_title(\"Bessel function roots\")\nfig\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = []\nfor guess in [3., 6., 10., 13.]:\n    f = lambda x: J3(x) - 0.2\n    s = root_scalar(f, x0=guess).root\n    omega.append(s)\n\nax.scatter(omega, J3(omega))\nfig\n\nCondition number of a rootfinding problem\n\nConsider first the function\n\nf = lambda x: (x - 1) * (x - 2)\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Well-conditioned root\")\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = lambda x: (x - 1) * (x - 1.01)\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Poorly-conditioned root\")\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!","type":"content","url":"/chapter4-2#section-4-1","position":7},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-2","position":8},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.2","lvl2":"Examples"},"content":"Fixed-point iteration\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nWe define g(x)=x - f(x).\n\ng = lambda x: x - f(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nfig, ax = subplots()\ng = lambda x: x - f(x)\nxx = linspace(2, 3, 400)\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\naxis(\"equal\"), legend()\ntitle(\"Finding a fixed point\")\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1\ny = g(x)\nprint(y)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nax.plot([x, y], [y, y], \"r:\", label=\"\")\nfig\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y\ny = g(x)\nprint(\"y:\", y)\nax.plot([x, x], [x, y], \"k:\")\nfig\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    ax.plot([x, x], [x, y], \"k:\")  \nfig\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nprint(abs(y - max(r)) / max(r))\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nxx = linspace(1, 2, 400)\nfig, ax = subplots()\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\nax.set_aspect(1.0)\nax.legend()\n\nx = 1.3\ny = g(x)\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y\n    y = g(x)\n    ax.plot([x, x], [x, y], \"k:\")\nylim(1, 2.5)\ntitle(\"No convergence\")\n\nThis time, the iteration is pushing us away from the correct answer.\n\nConvergence of fixed-point iteration\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nHere is the fixed point iteration. This time we keep track of the whole sequence of approximations.\n\ng = lambda x: x - f(x)\nx = zeros(12)\nx[0] = 2.1\nfor k in range(11):\n    x[k + 1] = g(x[k])\n\nprint(x)\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - max(r))\nsemilogy(err, \"-o\")\nxlabel(\"iteration number\"), ylabel(\"error\")\ntitle(\"Convergence of fixed point iteration\")\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\np = polyfit(arange(5, 13), log(err[4:]), 1)\nprint(p)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nprint(\"sigma:\", exp(p[0]))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr[8:] / err[7:-1]\n\nThe methods for finding σ agree well.","type":"content","url":"/chapter4-2#section-4-2","position":9},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-3","position":10},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.3","lvl2":"Examples"},"content":"Graphical interpretation of Newton’s method\n\nSuppose we want to find a root of this function:\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0, 1.5, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$y$\")\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1\ny1 = f(x1)\nax.plot(x1, y1, \"ko\", label=\"initial point\")\nax.legend()\nfig\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx = lambda x: exp(x) * (x + 1)\nslope1 = df_dx(x1)\ntangent1 = lambda x: y1 + slope1 * (x - x1)\n\nax.plot(xx, tangent1(xx), \"--\", label=\"tangent line\")\nax.set_ylim(-2, 4)\nax.legend()\nfig\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nax.plot(x2, 0, \"ko\", label=\"tangent root\")\nax.legend()\nfig\n\ny2 = f(x2)\nprint(y2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nxx = linspace(0.83, 0.88, 200)\n\nplot(xx, f(xx))\nplot(x2, y2, \"ko\")\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\n\nslope2 = df_dx(x2)\ntangent2 = lambda x: y2 + slope2 * (x - x2)\nplot(xx, tangent2(xx), \"--\")\nx3 = x2 - y2 / slope2\nplot(x3, 0, \"ko\")\ntitle(\"Second iteration\")\n\ny3 = f(x3)\nprint(y3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nConvergence of Newton’s method\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = lambda x: x * exp(x) - 2\ndf_dx = lambda x: exp(x) * (x + 1)\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nr = root_scalar(f, bracket=[0.8, 1.0]).root\nprint(r)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = ones(5)\nfor k in range(4):\n    x[k + 1] = x[k] - f(x[k]) / df_dx(x[k])\n\nprint(x)\n\nHere is the sequence of errors.\n\nerr = x - r\nprint(err)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nUsing Newton’s method\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=h(x), or h(x)-y=0, for x when y is given. That equation has no solution in terms of elementary functions. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\nh = lambda x: exp(x) - x\ndh_dx = lambda x: exp(x) - 1\ny_ = linspace(h(0), h(2), 200)\nx_ = zeros(y_.shape)\nfor (i, y) in enumerate(y_):\n    f = lambda x: h(x) - y\n    df_dx = lambda x: dh_dx(x)\n    x = FNC.newton(f, df_dx, y)\n    x_[i] = x[-1]\n\nplot(x_, y_, label=\"$y=h(x)$\")\nplot(y_, x_, label=\"$y=h^{-1}(x)$\")\nplot([0, max(y_)], [0, max(y_)], 'k--', label=\"\")\ntitle(\"Function and its inverse\")\nxlabel(\"x\"), ylabel(\"y\"), axis(\"equal\")\nax.grid(), legend()","type":"content","url":"/chapter4-2#section-4-3","position":11},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-4","position":12},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.4","lvl2":"Examples"},"content":"Graphical interpretation of the secant method\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0.25, 1.25, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$f(x)$\")\nax.grid()\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1\ny1 = f(x1)\nx2 = 0.5\ny2 = f(x2)\nax.plot([x1, x2], [y1, y2], \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1)\nsecant2 = lambda x: y2 + slope2 * (x - x2)\nax.plot(xx, secant2(xx), \"--\", label=\"secant line\")\nax.legend()\nfig\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx3 = x2 - y2 / slope2\nax.plot(x3, 0, \"o\", label=\"root of secant\")\ny3 = f(x3)\nprint(y3)\nax.legend()\nfig\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope3 = (y3 - y2) / (x3 - x2)\nx4 = x3 - y3 / slope3\nprint(f(x4))\n\nConvergence of the secant method\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = lambda x: x * exp(x) - 2\nx = FNC.secant(f, 1, 0.5)\nprint(x)\n\nWe don’t know the exact root, so we use root_scalar to get a substitute.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.5, 1]).root\nprint(r)\n\nHere is the sequence of errors.\n\nerr = r - x\nprint(err)\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 2):\n    print(logerr[i+1] / logerr[i])\n\nAs expected, this settles in at around 1.618.\n\nInverse quadratic interpolation\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = lambda x: x + cos(10 * x)\nxx = linspace(0.5, 1.5, 400)\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$y$\")\nfig\n\nWe choose three values to get the iteration started.\n\nx = array([0.8, 1.2, 1])\ny = f(x)\nax.plot(x, y, \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nq = poly1d(polyfit(x, y, 2))  # interpolating polynomial\nax.plot(xx, q(xx), \"--\", label=\"interpolant\")\nax.set_ylim(-0.1, 3), ax.legend()\nfig\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nplot(xx, f(xx), label=\"function\")\nplot(x, y, \"ko\", label=\"initial points\")\n\nq = poly1d(polyfit(y, x, 2))  # inverse interpolating polynomial\nyy = linspace(-0.1, 2.6, 400)\nplot(q(yy), yy, \"--\", label=\"inverse interpolant\")\n\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\nlegend()\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = hstack([x, q(0)])\ny = hstack([y, f(x[-1])])\nprint(\"x:\", x, \"\\ny:\", y)\n\nWe repeat the process a few more times.\n\nfor k in range(6):\n    q = poly1d(polyfit(y[-3:], x[-3:], 2))\n    x = hstack([x, q(0)])\n    y = hstack([y, f(x[-1])])\nprint(f\"final residual is {y[-1]:.2e}\")\n\nHere is the sequence of errors.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.9, 1]).root\nerr = x - r\nprint(err)\n\nThe error seems to be superlinear, but subquadratic:\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])","type":"content","url":"/chapter4-2#section-4-4","position":13},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-5","position":14},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.5","lvl2":"Examples"},"content":"Convergence of Newton’s method for systems\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\ndef jac(x):\n    return array([\n            [-exp(x[1] - x[0]), exp(x[1] - x[0]), 0],\n            [x[1], x[0], 1],\n            [2 * x[0], x[2] - 1, x[1]],\n    ])\n\nOur initial guess at a root is the origin.\n\nx1 = zeros(3)\nx = FNC.newtonsys(func, jac, x1)\nprint(x)\n\nThe output has one column per iteration, so the last column contains the final Newton estimate. Let’s compute the residual of the last result.\n\nr = x[:, -1]\nf = func(r)\nprint(\"final residual:\", f)\n\nLet’s check the convergence rate:\n\nlogerr = [log(norm(x[:, k] - r)) for k in range(x.shape[1] - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])\n\nThe ratio is apparently converging toward 2, as expected for quadratic convergence.","type":"content","url":"/chapter4-2#section-4-5","position":15},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-6","position":16},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.6","lvl2":"Examples"},"content":"Using Levenberg’s method\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx1 = zeros(3)\nx = FNC.levenberg(func, x1)\nprint(f\"Took {x.shape[1]-1} iterations.\")\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[:, -1]\nprint(\"backward error:\", norm(func(r)))\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method:\n\nlogerr = [log(norm(x[:, k] - r)) for k in range(x.shape[1] - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])","type":"content","url":"/chapter4-2#section-4-6","position":17},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#section-4-7","position":18},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"Section 4.7","lvl2":"Examples"},"content":"Convergence of nonlinear least squares\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = lambda x: array([sin(x[0] + x[1]), cos(x[0] - x[1]), exp(x[0] - x[1])])\np = array([1, 1])\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nfor R in [1e-3, 1e-2, 1e-1]:\n    # Define the perturbed function.\n    f = lambda x: g(x) - g(p) + R * array([-1, 1, -1]) / sqrt(3)\n    x = FNC.levenberg(f, [0, 0])\n    r = x[:, -1]\n    err = [norm(x[:, j] - r) for j in range(x.shape[1] - 1)]\n    normres = norm(f(r))\n    semilogy(err, label=f\"R={normres:.2g}\")\ntitle(\"Convergence of Gauss–Newton\")\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend();\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nNonlinear data fitting\n\nm = 25\nV, Km = 2, 0.5\ns = linspace(0.05, 6, m)\nmodel = lambda x: V * x / (Km + x)\nw = model(s) + 0.15 * cos(2 * exp(s / 16) * s)    # noise added\n\nfig, ax = subplots()\nax.scatter(s, w, label=\"data\")\nax.plot(s, model(s), 'k--', label=\"unperturbed model\")\nxlabel(\"s\"), ylabel(\"w\")\nlegend()\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\ndef misfit(c):\n    V, Km = c  # rename components for clarity\n    f = V * s / (Km + s) - w\n    return f\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\ndef misfitjac(x):\n    V, Km = x   # rename components for clarity\n    J = zeros([m, 2])\n    J[:, 0] = s / (Km + s)          # d/d(V)\n    J[:, 1] = -V * s / (Km + s)**2  # d/d(Km)\n    return J\n\nx1 = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x1)\nV, Km = x[:, -1]  # final values\nprint(f\"estimates are V = {V:.3f}, Km = {Km:.3f}\")\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\n# since V and Km have been updated, model() is too\nax.plot(s, model(s), label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nfrom numpy.linalg import lstsq\nA = array( [[1 / s[i], 1.0] for i in range(len(s))] )\nz = lstsq(A, 1 / w, rcond=None)[0]\nalpha, beta = z\nprint(\"alpha:\", alpha, \"beta:\", beta)\n\nThe two fits are different; they do not optimize the same quantities.\n\nlinmodel = lambda x: 1 / (beta + alpha / x)\nax.plot(s, linmodel(s), label=\"linear fit\")\nax.legend()\nfig\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/chapter4-2#section-4-7","position":19},{"hierarchy":{"lvl1":"Chapter 5"},"type":"lvl1","url":"/chapter5-2","position":0},{"hierarchy":{"lvl1":"Chapter 5"},"content":"Python implementations","type":"content","url":"/chapter5-2","position":1},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"type":"lvl2","url":"/chapter5-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"content":"Hat function\n\ndef hatfun(x, t, k):\n    \"\"\"\n    hatfun(x,t,k)\n\n    Evaluate a piecewise linear \"hat\" function at `x`, where `t` is a vector of\n    n+1 interpolation nodes and `k` is an integer in 0:n giving the index of the node\n    where the hat function equals one.\n    \"\"\"\n    n = len(t) - 1\n\n    # Return correct node given mathematical index k, including fictitious choices.\n    def node(k):\n        if k < 0:\n            return 2 * t[0] - t[1]\n        elif k > n:\n            return 2 * t[n] - t[n - 1]\n        else:\n            return t[k]\n\n    H1 = (x - node(k - 1)) / (node(k) - node(k - 1))  # upward slope\n    H2 = (node(k + 1) - x) / (node(k + 1) - node(k))  # downward slope\n    H = np.minimum(H1, H2)\n    return np.maximum(0, H)\n\nPiecewise linear interpolation\n\ndef plinterp(t, y):\n    \"\"\"\n    plinterp(t,y)\n\n    Create a piecewise linear interpolating function for data values in `y` given at nodes\n    in `t`.\n    \"\"\"\n    n = len(t) - 1\n    return lambda x: np.sum(y[k] * hatfun(x, t, k) for k in range(n + 1))\n\nCubic spline interpolation\n\ndef spinterp(t, y):\n    \"\"\"\n    spinterp(t,y)\n\n    Create a cubic not-a-knot spline interpolating function for data values in `y` given at nodes in `t`.\n    \"\"\"\n    n = len(t) - 1\n    h = [t[i + 1] - t[i] for i in range(n)]\n\n    # Preliminary definitions.\n    Z = np.zeros([n, n])\n    I = np.eye(n)\n    E = I[: n - 1, :]\n    J = np.eye(n) + np.diag(-np.ones(n - 1), 1)\n    H = np.diag(h)\n\n    # Left endpoint interpolation:\n    AL = np.hstack([I, Z, Z, Z])\n    vL = y[:-1]\n\n    # Right endpoint interpolation:\n    AR = np.hstack([I, H, H**2, H**3])\n    vR = y[1:]\n\n    # Continuity of first derivative:\n    A1 = E @ np.hstack([Z, J, 2 * H, 3 * H**2])\n    v1 = np.zeros(n - 1)\n\n    # Continuity of second derivative:\n    A2 = E @ np.hstack([Z, Z, J, 3 * H])\n    v2 = np.zeros(n - 1)\n\n    # Not-a-knot conditions:\n    nakL = np.hstack([np.zeros(3 * n), np.hstack([1, -1, np.zeros(n - 2)])])\n    nakR = np.hstack([np.zeros(3 * n), np.hstack([np.zeros(n - 2), 1, -1])])\n\n    # Assemble and solve the full system.\n    A = np.vstack([AL, AR, A1, A2, nakL, nakR])\n    v = np.hstack([vL, vR, v1, v2, 0, 0])\n    z = solve(A, v)\n\n    # Break the coefficients into separate vectors.\n    rows = np.arange(n)\n    a = z[rows]\n    b = z[n + rows]\n    c = z[2 * n + rows]\n    d = z[3 * n + rows]\n    S = [np.poly1d([d[k], c[k], b[k], a[k]]) for k in range(n)]\n\n    # This function evaluates the spline when called with a value for x.\n    def evaluate(x):\n        f = np.zeros(x.shape)\n        for k in range(n):\n            # Evaluate this piece's cubic at the points inside it.\n            index = (x >= t[k]) & (x <= t[k + 1])\n            f[index] = S[k](x[index] - t[k])\n        return f\n\n    return evaluate\n\nFornberg’s algorithm for finite difference weights\n\ndef fdweights(t, m):\n    \"\"\"\n    fdweights(t,m)\n\n    Return weights for the `m`th derivative of a function at zero using values at the\n    nodes in vector `t`.\n    \"\"\"\n    # This is a compact implementation, not an efficient one.\n\n    def weight(t, m, r, k):\n        # Recursion for one weight.\n        # Input:\n        #   t   nodes (vector)\n        #   m   order of derivative sought\n        #   r   number of nodes to use from t (<= length(t))\n        #   k   index of node whose weight is found\n\n        if (m < 0) or (m > r):  # undefined coeffs must be zero\n            c = 0\n        elif (m == 0) and (r == 0):  # base case of one-point interpolation\n            c = 1\n        else:  # generic recursion\n            if k < r:\n                c = t[r] * weight(t, m, r - 1, k) - m * weight(t, m - 1, r - 1, k)\n                c = c / (t[r] - t[k])\n            else:\n                if r <= 1:\n                    numer = 1.0\n                else:\n                    numer = np.prod(t[r-1] - t[:r-1])\n                if r <= 0:\n                    denom = 1.0\n                else:\n                    denom = np.prod(t[r] - t[:r])\n                beta = numer / denom\n                c = weight(t, m - 1, r - 1, r - 1) - t[r-1] * weight(t, m, r - 1, r - 1)\n                c *= beta\n        return c\n\n    r = len(t) - 1\n    w = np.zeros(t.shape)\n    return [weight(t, m, r, k) for k in range(r + 1)]\n\nTrapezoid formula for numerical integration\n\ndef trapezoid(f, a, b, n):\n    \"\"\"\n    trapezoid(f,a,b,n)\n\n    Apply the trapezoid integration formula for integrand `f` over interval [`a`,`b`], broken up into `n` equal pieces. Returns estimate, vector of nodes, and vector of integrand values at the nodes.\n    \"\"\"\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n    y = f(t)\n    T = h * (np.sum(y[1:-1]) + 0.5 * (y[0] + y[-1]))\n    return T, t, y\n\nAdaptive integration\n\ndef intadapt(f, a, b, tol):\n    \"\"\"\n    intadapt(f,a,b,tol)\n\n    Do adaptive integration to estimate the integral of `f` over [`a`,`b`] to desired\n    error tolerance `tol`. Returns estimate and a vector of evaluation nodes used.\n    \"\"\"\n\n    # Use error estimation and recursive bisection.\n    def do_integral(a, fa, b, fb, m, fm, tol):\n        # These are the two new nodes and their f-values.\n        xl = (a + m) / 2\n        fl = f(xl)\n        xr = (m + b) / 2\n        fr = f(xr)\n        t = np.array([a, xl, m, xr, b])  # all 5 nodes at this level\n\n        # Compute the trapezoid values iteratively.\n        h = b - a\n        T = np.zeros(3)\n        T[0] = h * (fa + fb) / 2\n        T[1] = T[0] / 2 + (h / 2) * fm\n        T[2] = T[1] / 2 + (h / 4) * (fl + fr)\n\n        S = (4 * T[1:] - T[:-1]) / 3  # Simpson values\n        E = (S[1] - S[0]) / 15  # error estimate\n\n        if abs(E) < tol * (1 + abs(S[1])):  # acceptable error?\n            Q = S[1]  # yes--done\n        else:\n            # Error is too large--bisect and recurse.\n            QL, tL = do_integral(a, fa, m, fm, xl, fl, tol)\n            QR, tR = do_integral(m, fm, b, fb, xr, fr, tol)\n            Q = QL + QR\n            t = np.hstack([tL, tR[1:]])  # merge the nodes w/o duplicate\n        return Q, t\n\n    m = (b + a) / 2\n    Q, t = do_integral(a, f(a), b, f(b), m, f(m), tol)\n    return Q, t\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.","type":"content","url":"/chapter5-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"type":"lvl2","url":"/chapter5-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"content":"\n\nimport FNC\nfrom numpy import *\nfrom matplotlib.pyplot import *\nfrom numpy.linalg import solve, norm\nfrom scipy.interpolate import interp1d\nfrom scipy.integrate import quad\nfrom prettytable import PrettyTable\n\n# This (optional) block is for improving the display of plots.\nrcParams[\"figure.figsize\"] = [7, 4]\nrcParams[\"lines.linewidth\"] = 2\nrcParams[\"lines.markersize\"] = 4\nrcParams['animation.html'] = \"jshtml\"  # or try \"html5\"\n\n","type":"content","url":"/chapter5-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-1","position":6},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.1","lvl2":"Examples"},"content":"Trouble in polynomial interpolation\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\np = poly1d(polyfit(t, y, n))  # interpolating polynomial\ntt = linspace(-1, 1, 400)\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = poly1d(polyfit(t, y, n))\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nSurely there must be functions that are more intuitively representative of those points!\n\nPiecewise polynomial interpolation\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nclf\nn = 12\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.5 * sin(20 * t)\nfig, ax = subplots()\nscatter(t, y, label=\"data\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\ntt = linspace(-1, 1, 400)\np = interp1d(t, y, kind=\"linear\")\nax.plot(tt, p(tt), label=\"piecewise linear\")\nax.legend()\nfig\n\nWe may prefer a smoother interpolant that is piecewise cubic:\n\nscatter(t, y, label=\"data\")\np = interp1d(t, y, kind=\"cubic\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cubic spline\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\nlegend()\n\nConditioning of interpolation\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nclf\nn = 18\nt = linspace(-1, 1, n + 1)\ny = zeros(n + 1)\ny[9] = 1.0\np = interp1d(t, y, kind=\"cubic\")\n\nscatter(t, y, label=\"data\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cardinal function\")\ntitle(\"Cubic spline cardinal function\")\nlegend()\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\np = poly1d(polyfit(t, y, n))\nscatter(t, y, label=\"data\")\nplot(tt, p(tt), label=\"cardinal function\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\ntitle(\"Polynomial cardinal function\")\nlegend()\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/chapter5-2#section-5-1","position":7},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-2","position":8},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.2","lvl2":"Examples"},"content":"A look at hat functions\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nx = linspace(0, 1, 300)\nfor k in range(6):\n    plot(x, FNC.hatfun(x, t, k))\nxlabel(\"$x$\")\nylabel(\"$H_k(x)$\")\ntitle(\"Hat functions\")\n\nUsing piecewise linear interpolation\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 400)\nfig, ax = subplots()\nplot(x, f(x), label=\"function\")\nxlabel(\"$x$\")\nylabel(\"$f(x)$\")\n\nFirst we sample the function to create the data.\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # function values\n\nax.plot(t, y, \"o\", label=\"nodes\")\nax.legend()\nfig\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nax.plot(x, p(x), label=\"interpolant\")\nax.legend()\nfig\n\nConvergence of piecewise linear interpolation\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 10000)  # sample the difference at many points\nN = 2 ** arange(3, 11)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.plinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\norder2 = 0.1 * (N / N[0]) ** (-2)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order2, \"--\", label=\"2nd order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-p\\|_\\infty$\")\nlegend()","type":"content","url":"/chapter5-2#section-5-2","position":9},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-3","position":10},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.3","lvl2":"Examples"},"content":"Cubic splines\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nf = lambda x: exp(sin(7 * x))\n\nx = linspace(0, 1, 500)\nfig, ax = subplots()\nax.plot(x, f(x), label=\"function\")\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # values at nodes\n\nxlabel(\"$x$\")\nylabel(\"$y$\")\nax.scatter(t, y, label=\"nodes\")\n\nS = FNC.spinterp(t, y)\nax.plot(x, S(x), label=\"spline\")\nax.legend()\nfig\n\nNow we look at the convergence rate as the number of nodes increases.\n\nN = floor(2 ** linspace(3, 8, 17)).astype(int)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.spinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = (N / N[0]) ** (-4)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order4, \"--\", label=\"4th order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-S\\|_\\infty$\")\nlegend()","type":"content","url":"/chapter5-2#section-5-3","position":11},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-4","position":12},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.4","lvl2":"Examples"},"content":"Finite differences\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\nprint(f\"CD2 is {CD2:.9f} and CD4 is {CD4:.9f}\")\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")\n\nFinite differences for f''\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2*f(0) + f(h)) / h**2\nprint(f\"CD2 is {CD2:.9f}\")\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h**2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h**2\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h**2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h**2\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")\n\nFinite differences at arbitrary nodes\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = array([0.35, 0.5, 0.57, 0.6, 0.75])   # nodes\nf = lambda x: cos(x**2)\ndfdx = lambda x: -2 * x * sin(x**2)\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nprint(FNC.fdweights(linspace(0, 3, 4), 1))","type":"content","url":"/chapter5-2#section-5-4","position":13},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-5","position":14},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.5","lvl2":"Examples"},"content":"Convergence of finite differences\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = lambda x: sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh_ = array([5 / 10**(n+1) for n in range(6)])\nFD = zeros((len(h_), 2))\nfor (i, h) in enumerate(h_):\n    FD[i, 0] = (f(h) - f(0)) / h \n    FD[i, 1] = (f(h) - f(-h)) / (2*h)\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nprint(results)\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerrors = FD - exact_value\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"error in FD1\", errors[:, 0])\nresults.add_column(\"error in FD2\", errors[:, 1])\nprint(results)\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nplot(h_, abs(errors), \"o-\", label=[\"FD1\", \"FD2\"])\ngca().invert_xaxis()\n# Add lines for perfect 1st and 2nd order.\nloglog(h_, h_, \"--\", label=\"$O(h)$\")\nloglog(h_, h_**2, \"--\", label=\"$O(h^2)$\")\nxlabel(\"$h$\")\nylabel(\"error\")\nlegend()\n\nRoundoff error in finite differences\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = lambda x: exp(-1.3 * x)\nexact = -1.3\n\nh_ = array([1 / 10**(n+1) for n in range(12)])\nFD = zeros((len(h_), 3))\nfor (i, h) in enumerate(h_):\n    nodes = h * linspace(-2, 2, 5)\n    vals = f(nodes)\n    FD[i, 0] = dot(array([0, 0, -1, 1, 0]) / h, vals)\n    FD[i, 1] = dot(array([0, -1/2, 0, 1/2, 0]) / h, vals)\n    FD[i, 2] = dot(array([1/12, -2/3, 0, 2/3, -1/12]) / h, vals)\n\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nresults.add_column(\"FD4\", FD[:, 2])\nprint(results)\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nloglog(h_, abs(FD[:, 0] + 1.3), \"-o\", label=\"FD1\")\nloglog(h_, abs(FD[:, 1] + 1.3), \"-o\", label=\"FD2\")\nloglog(h_, abs(FD[:, 2] + 1.3), \"-o\", label=\"FD4\")\ngca().invert_xaxis()\nplot(h_, 0.1 * 2 ** (-52) / h_, \"--\", color=\"k\", label=\"$O(h^{-1})$\")\nxlabel(\"$h$\")\nylabel(\"total error\")\ntitle(\"FD error with roundoff\")\nlegend()\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/chapter5-2#section-5-5","position":15},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-6","position":16},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.6","lvl2":"Examples"},"content":"Numerical integration\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe module scipy.integrate has multiple functions that estimate the value of an integral numerically without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nQ, errest = quad(exp, 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quad(lambda x: exp(sin(x)), 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 300)\nsubplot(1, 2, 1)\nplot(x, exp(x))\nylim([0, 2.7]), title(\"exp(x)\")\nsubplot(1, 2, 2)\nplot(x, exp(sin(x)))\nylim([0, 2.7]), title(\"exp(sin(x))\");\n\nTrapezoid integration\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = lambda x: exp(sin(7 * x))\na, b = 0, 2\n\nIn lieu of the exact value, we will use the quad function to find an accurate result.\n\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\nprint(f\"Trapezoid estimate is {T:.14f} with error {I - T:.2e}\")\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn_ = 40 * 2 ** arange(6)\nerr = zeros(size(n_))\nprint(\"     n     error\")\nfor k, n in enumerate(n_):\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    err[k] = I - T\n    print(f\"{n:6d}   {err[k]:8.3e} \")\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nloglog(n_, abs(err), \"-o\", label=\"results\")\nloglog(n_, 3e-3 * (n_ / n_[0]) ** (-2), \"--\", label=\"2nd order\")\ngca().invert_xaxis()\nxlabel(\"$n$\")\nylabel(\"error\")\nlegend()\ntitle(\"Convergence of trapezoidal integration\");\n\nIntegration by extrapolation\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = lambda x: x**2 * exp(-2 * x)\na = 0\nb = 2\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20    # the coarsest formula\nn = N\nh = (b - a) / n\nt = h * arange(n + 1)\ny = f(t)\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = zeros(3)\nT[0] = h * (sum(y[1:-1]) + y[0] / 2 + y[-1] / 2)\nprint(f\"error (2nd order): {I - T[0]:.2e}\")\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[1] = T[0] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:2])\n\nAs expected for a second-order estimate, the error went down by a factor of about 4. We can repeat the same code to double n again.\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[2] = T[1] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:3])\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = array([(4 * T[i + 1] - T[i]) / 3 for i in range(2)])\nprint(\"error (4th order):\", I - S)\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16 * S[1] - S[0]) / 15\nprint(\"error (6th order):\", I - R)\n\nWe can make a triangular table of the errors:\n\nerr = nan * ones((3, 3))\nerr[0, :] = I - T\nerr[1, 1:] = I - S\nerr[2, 2] = I - R\nresults = PrettyTable([\"2nd order\", \"4th order\", \"6th order\"])\nresults.add_rows(err.T)\nprint(results)\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/chapter5-2#section-5-6","position":17},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#section-5-7","position":18},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"Section 5.7","lvl2":"Examples"},"content":"Motivation for adaptive integration\n\nThis function gets increasingly oscillatory as x increases.\n\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nx = linspace(0, 4, 600)\nplot(x, f(x))\nxlabel(\"$x$\")\nylabel(\"$f(x)$\");\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nn_ = 50 * 2 ** arange(4)\nTleft = zeros(4)\nTright = zeros(4)\nfor i, n in enumerate(n_):\n    Tleft[i] = FNC.trapezoid(f, 0, 2, n)[0]\n    Tright[i] = FNC.trapezoid(f, 2, 4, n)[0]\nprint(\"left half:\", Tleft)\nprint(\"right half:\", Tright)\n\nleft_val, err = quad(f, 0, 2, epsabs=1e-13, epsrel=1e-13)\nright_val, err = quad(f, 2, 4, epsabs=1e-13, epsrel=1e-13)\n\nprint(\"    n     left error   right error\")\nfor k in range(n_.size):\n    print(f\"  {n_[k]:4}    {Tleft[k]-left_val:8.3e}    {Tright[k]-right_val:8.3e}\")\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nUsing adaptive integration\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nI, errest = quad(f, 0, 4, epsabs=1e-12, epsrel=1e-12)\nprint(\"integral:\", I)    # 'exact' value\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nQ, t = FNC.intadapt(f, 0, 4, 0.001)\nprint(\"number of nodes:\", t.size)\n\nx = linspace(0, 4, 600)\nplot(x, f(x), \"k\")\nstem(t, f(t))\nxlabel(\"$x$\"); ylabel(\"$f(x)$\");\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nprint(\"error:\", I - Q)\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol_ = 10.0 ** arange(-4, -12, -1)\nerr_ = zeros(tol_.size)\nnum_ = zeros(tol_.size, dtype=int)\nprint(\"    tol         error     # f-evals\")\nfor i, tol in enumerate(tol_):\n    Q, t = FNC.intadapt(f, 0, 4, tol)\n    err_[i] = I - Q\n    num_[i] = t.size\n    print(f\"  {tol:6.1e}    {err_[i]:10.3e}    {num_[i]:6d}\")\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nloglog(num_, abs(err_), \"-o\", label=\"results\")\norder4 = 0.01 * (num_ / num_[0]) ** (-4)\nloglog(num_, order4, \"--\", label=\"$O(n^{-4})$\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\nlegend()\ntitle(\"Convergence of adaptive quadrature\");","type":"content","url":"/chapter5-2#section-5-7","position":19},{"hierarchy":{"lvl1":"Chapter 6"},"type":"lvl1","url":"/chapter6-2","position":0},{"hierarchy":{"lvl1":"Chapter 6"},"content":"","type":"content","url":"/chapter6-2","position":1},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"type":"lvl2","url":"/chapter6-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"content":"Euler’s method for an initial-value problem\n\ndef euler(dudt, tspan, u0, n):\n    \"\"\"\n    euler(dudt,tspan,u0,n)\n\n    Apply Euler's method to solve the IVP u'=`dudt`(u,t) over the interval `tspan` with\n    u(`tspan[1]`)=`u0`, using `n` subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * dudt(t[i], u[i])\n\n    return t, u.T\n\nImproved Euler method for an IVP\n\ndef ie2(dudt, tspan, u0, n):\n    \"\"\"\n    ie2(dudt,tspan,u0,n)\n\n    Apply the Improved Euler method to solve the vector-valued IVP u'=`dudt`(u,p,t) over the\n    interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps. Returns a vector\n    of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        uhalf = u[i] + h / 2 * dudt(t[i], u[i])\n        u[i+1] = u[i] + h * dudt(t[i] + h / 2, uhalf)\n\n    return t, u.T\n\nFourth-order Runge-Kutta for an IVP\n\ndef rk4(dudt, tspan, u0, n):\n    \"\"\"\n    rk4(dudt,tspan,u0,n)\n\n    Apply \"the\" Runge-Kutta 4th order method to solve the vector-valued IVP u'=`dudt`(u,p,t)\n    over the interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps.\n    Return a vector of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        k1 = h * dudt(t[i], u[i])\n        k2 = h * dudt(t[i] + h / 2, u[i] + k1 / 2)\n        k3 = h * dudt(t[i] + h / 2, u[i] + k2 / 2)\n        k4 = h * dudt(t[i] + h, u[i] + k3)\n        u[i+1] = u[i] + (k1 + 2 * (k2 + k3) + k4) / 6\n\n    return t, u.T\n\nAdaptive IVP solver based on embedded RK formulas\n\ndef euler(dudt, tspan, u0, n):\n    \"\"\"\n    euler(dudt,tspan,u0,n)\n\n    Apply Euler's method to solve the IVP u'=`dudt`(u,t) over the interval `tspan` with\n    u(`tspan[1]`)=`u0`, using `n` subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * dudt(t[i], u[i])\n\n    return t, u.T\n\nAbout the code\n\nThe check t[i]+h==t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\n4th-order Adams–Bashforth formula for an IVP\n\ndef ab4(dudt, tspan, u0, n):\n    \"\"\"\n    ab4(dudt,tspan,u0,n)\n\n    Apply the Adams-Bashforth 4th order method to solve the vector-valued IVP u'=`dudt`(u,p,t)\n    over the interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Constants in the AB4 method.\n    k = 4\n    sigma = np.array([55, -59, 37, -9]) / 24\n\n    # Find starting values by RK4.\n    ts, us = rk4(dudt, [a, a + (k - 1) * h], u0, k - 1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[:k] = us[:k].T\n\n    # Compute history of u' values, from newest to oldest.\n    f = np.array([dudt(t[k-j-2], u[k-j-2]) for j in range(k)])\n\n    # Time stepping.\n    for i in range(k-1, n):\n        f = np.vstack([dudt(t[i], u[i]), f[:-1]])  # new value of du/dt\n        u[i+1] = u[i] + h * np.dot(sigma, f)  # advance one step\n\n    return t, u.T\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\ndef am2(dudt, tspan, u0, n):\n    \"\"\"\n    am2(dudt,tspan,u0,n)\n\n    Apply the Adams-Moulton 2nd order method to solve the vector-valued IVP u'=`dudt`(u,p,t)\n    over the interval `tspan` with u(`tspan[1]`)=`u0`, using `n` subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        # Data that does not depend on the new value.\n        known = u[i] + h / 2 * dudt(t[i], u[i])\n        # Find a root for the new value.\n        F = lambda z: z - h / 2 * dudt(t[i+1], z) - known\n        unew = levenberg(F, known)\n        u[i+1] = unew[:, -1]\n\n    return t, u.T\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/chapter6-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"type":"lvl2","url":"/chapter6-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"content":"\n\nfrom numpy import *\nfrom numpy.linalg import norm\nfrom matplotlib.pyplot import *\nfrom prettytable import PrettyTable\nimport sys\nsys.path.append('pkg/')\nimport FNC\nimport importlib\nimportlib.reload(FNC)\n\n# This (optional) block is for improving the display of plots.\nrcParams[\"figure.figsize\"] = [7, 4]\nrcParams[\"lines.linewidth\"] = 2\nrcParams[\"lines.markersize\"] = 4\nrcParams['animation.html'] = \"jshtml\"  # or try \"html5\"\n\n","type":"content","url":"/chapter6-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-1","position":6},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.1","lvl2":"Examples"},"content":"Solving an IVP\n\nLet’s use solve_ivp from scipy.integrate to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = [-1.0]\n\nNote above that even though this is a problem for a scalar function u(t), we had to set the initial condition as a “one-dimensional vector.”\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, u0)\n\nThe resulting solution object has fields t and y that contain the values of the independent and dependent variables, respectively; those field names are the same regardless of what we use in our own codes.\n\nprint(\"t shape:\", sol.t.shape)\nprint(\"u shape:\", sol.y.shape)\nplot(sol.t, sol.y[0, :], \"-o\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution of $u' = sin((t+u)^2)$\")\n\nYou can see above that the solution was not computed at enough points to make a smooth graph. There is a way to request output at times of your choosing.\n\nsol = solve_ivp(f, tspan, u0, t_eval=linspace(0, 4, 200))\nplot(sol.t, sol.y[0, :], \"-\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution of $u' = sin((t+u)^2)$\")\n\nAnother option is to enable interpolation to evaluate the solution anywhere after the fact:\n\nsol = solve_ivp(f, tspan, u0, dense_output=True)\nfor t in linspace(0, 4, 6):\n    print(f\"u({t:.2f}) = {sol.sol(t)[0]:.4f}\")\n\nFinite-time singularity\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nIt’s a good idea to check sol.success after calling solve_ivp. If it’s False, the solution may not be reliable.\n\nf = lambda t, u: (t + u) ** 2\nsol = solve_ivp(f, [0.0, 1.0], [1.0])\nif not sol.success:\n    print(sol.message)\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nsemilogy(sol.t, sol.y[0, :])\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle(\"Blowup in finite time\")\n\nConditioning of an IVP\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = linspace(0, 3, 200)\nu = array([exp(t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle(\"Exponential divergence of solutions\")\n\nBut with u'=-u, solutions actually get closer together with time.\n\nt = linspace(0, 3, 200)\nu = array([exp(-t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle(\"Exponential convergence of solutions\")\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence, the exponentially growing upper bound e^{b-a} is a gross overestimate.","type":"content","url":"/chapter6-2#section-6-1","position":7},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-2","position":8},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.2","lvl2":"Examples"},"content":"Convergence of Euler’s method\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = -1.0\nt, u = FNC.euler(f, tspan, u0, 20)\n\nfig, ax = subplots()\nax.plot(t, u[0, :], \"-o\", label=\"$n=20$\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution by Euler's method\")\nlegend()\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(f, tspan, u0, 200)\nax.plot(t, u[0, :], label=\"$n=200$\")\nax.legend()\nfig\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use solve_ivp to construct an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, [u0], dense_output=True, atol=1e-8, rtol=1e-8)\nax.plot(t, sol.sol(t)[0, :], \"--\", label=\"accurate\")\nax.legend()\nfig\n\nNow we can perform a convergence study.\n\nn_ = array([int(5 * 10**k) for k in arange(0, 3, 0.5)])\nerr_ = zeros(6)\nresults = PrettyTable([\"n\", \"error\"])\nfor j, n in enumerate(n_):\n    t, u = FNC.euler(f, tspan, u0, n)\n    err_[j] = norm(sol.sol(t)[0, :] - u[0, :], inf)\n    results.add_row((n, err_[j]))\nprint(results)\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nloglog(n_, err_, \"-o\", label=\"results\")\nplot(n_, 0.5 * (n_ / n_[0])**(-1), \"--\", label=\"1st order\")\nxlabel(\"$n$\"), ylabel(\"inf-norm error\")\ntitle(\"Convergence of Euler's method\")\nlegend()","type":"content","url":"/chapter6-2#section-6-2","position":9},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-3","position":10},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.3","lvl2":"Examples"},"content":"Predator-prey model\n\nWe encode the predator–prey equations via a function.\n\ndef predprey(t, u):\n    y, z = u                        # rename for convenience\n    s = (y * z) / (1 + beta * y)    # appears in both equations\n    return array([y * (1 - alpha * y) - s, -z + s])\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable. These are given in the call to solve_ivp.\n\nfrom scipy.integrate import solve_ivp\nu0 = array([1, 0.01])\ntspan = [0.0, 80.0]\nalpha, beta = 0.1, 0.25\nsol = solve_ivp(predprey, tspan, u0, dense_output=True)\nprint(f\"solved with {sol.y.shape[1]} time steps\")\n\nAs in scalar problems, the solution object has fields t and y that contain the values of the independent and dependent variables, respectively. Each row of y represents one component of the solution at every time step, and each column of y is the entire solution vector at one time step. Since we used dense_output=True, there is also a method sol that can be used to evaluate the solution at any time.\n\nt = linspace(0, 80, 1200)\nu = vstack([sol.sol(t[i]) for i in range(t.size)]).T    # same shape as sol.y\nfig, ax = subplots()\nax.plot(t, u[0, :], label=\"prey\")\nax.plot(t, u[1, :], label=\"predator\")\nxlabel(\"$t$\"), ylabel(\"population\")\ntitle(\"Predator-prey solution\")\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt_E, u_E = FNC.euler(predprey, tspan, u0, 800)\nax.scatter(t_E, u_E[0, :], label=\"prey (Euler)\", s=1)\nax.scatter(t_E, u_E[1, :], label=\"predator (Euler)\", s=2)\nax.legend()\nfig\n\nYou can see above that the Euler solution is not very accurate. When the solution has two components, it’s common to plot the it in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nplot(u[0, :], u[1, :])\nxlabel(\"prey\"), ylabel(\"predator\")\ntitle(\"Predator-prey phase plane\")\n\nFrom this plot we can see that the solution approaches a periodic one, which in the phase plane is represented by a closed path.\n\nCoupled pendulums\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\ndef couple(t, u, params):\n    gamma, L, k = params\n    g = 9.8\n    udot = copy(u)\n    udot[:2] = u[2:4]\n    udot[2] = -gamma * u[2] - (g / L) * sin(u[0]) + k * (u[1] - u[0])\n    udot[3] = -gamma * u[3] - (g / L) * sin(u[1]) + k * (u[0] - u[1])\n    return udot\n\nu0 = array([1.25, -0.5, 0, 0])\ntspan = [0.0, 50.0]\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nWe use a closure here to pass the fixed parameter values into couple.\n\ngamma, L, k = 0.01, 0.5, 0.0\ndu_dt = lambda t, u: couple(t, u, (gamma, L, k))\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)    # first two components of solution\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\");\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 0.75    # changes the value in the du_dt closure\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Coupled pendulums\");\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/chapter6-2#section-6-3","position":11},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-4","position":12},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.4","lvl2":"Examples"},"content":"Convergence of Runge–Kutta methods\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We start by getting a reference solution to validate against.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = -1.0\nsol = solve_ivp(du_dt, tspan, [u0], dense_output=True, atol=1e-13, rtol=1e-13)\nu_ref = sol.sol\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = array([int(2 * 10**k) for k in linspace(0, 3, 7)])\nerr = {\"IE2\" : [], \"RK4\" : []}\nresults = PrettyTable([\"n\", \"IE2 error\", \"RK4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ie2(du_dt, tspan, u0, n[i])\n    err[\"IE2\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    t, u = FNC.rk4(du_dt, tspan, u0, n[i])\n    err[\"RK4\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[\"IE2\"][-1], err[\"RK4\"][-1]])\n\nprint(results)\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nloglog(2 * n, err[\"IE2\"], \"-o\", label=\"IE2\")\nloglog(4 * n, err[\"RK4\"], \"-o\", label=\"RK4\")\nplot(2 * n, 0.5 * err[\"IE2\"][-1] * (n / n[-1])**(-2), \"--\", label=\"2nd order\")\nplot(4 * n, 0.5 * err[\"RK4\"][-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"f-evaluations\"),  ylabel(\"inf-norm error\")\nlegend()\ntitle(\"Convergence of RK methods\");\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/chapter6-2#section-6-4","position":13},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-5","position":14},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.5","lvl2":"Examples"},"content":"Adaptive step size\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nf = lambda t, u: exp(t - u * sin(u))\nt, u = FNC.rk23(f, [0.0, 5.0], [0.0], 1e-5)\nscatter(t, u[0, :])\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\ndt = [t[i + 1] - t[i] for i in range(t.size - 1)]\nsemilogy(t[:-1], dt)\nxlabel(\"$t$\"), ylabel(\"time step\")\ntitle(\"Adaptive step sizes\")\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprint(f\"min step size was {min(dt):.2e}\")\n\nOn the other hand, the average step size that was actually taken was\n\nprint(f\"mean step size was {mean(dt):.2e}\")\n\nWe took fewer steps by a factor of 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nAdaptive step size near a singularity\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\ndu_dt = lambda t, u: (t + u)**2\ntspan = (0.0, 2.0)\nu0 = [1.0]\nt, u = FNC.rk23(du_dt, tspan, u0, 1e-5)\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nsemilogy(t, u[0, :])\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\ntitle(\"Finite-time blowup\")\n\ntf = t[-1]\naxvline(x=tf, color='k', linestyle='--', label=f\"t = {tf:.6f}\")\nlegend();","type":"content","url":"/chapter6-2#section-6-5","position":15},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.6","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-6","position":16},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.6","lvl2":"Examples"},"content":"Convergence of Adams–Bashforth\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve_ivp is called to give an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = [-1.0]\nu_ref = solve_ivp(du_dt, tspan, u0, dense_output=True, rtol=1e-13, atol=1e-13).sol\n\nNow we perform a convergence study of the AB4 code.\n\nn = array([int(4 * 10**k) for k in linspace(0, 3, 7)])\nerr = []\nresults = PrettyTable([\"n\", \"AB4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ab4(du_dt, tspan, u0, n[i])\n    err.append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[-1]])\n\nprint(results)\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nloglog(n, err, \"-o\", label=\"AB4\")\nloglog(n, 0.5 * err[-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"$n$\"),  ylabel(\"final error\")\nlegend(), title(\"Convergence of AB4\");\n\nStiffness\n\nThe following simple ODE uncovers a surprise.\n\nf = lambda t, u: u**2 - u**3\nu0 = array([0.005])\ntspan = [0, 400]\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(f, [0.0, 400.0], u0, 200)\nfig, ax = subplots()\nax.plot(tI, uI[0], label=\"AM2\")\nxlabel(\"$t$\"), ylabel(\"$y(t)$\");\n\nSo far, so good. Now we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(f, [0.0, 400.0], u0, 200)\nax.scatter(tE, uE[0], label=\"AB4\")\nax.set_ylim([-4, 2]), ax.legend()\nfig\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[0, 104:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplot(tI, uI[0], color=\"k\", label=\"AM2\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1000)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1000\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1600)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1600\")\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\nlegend()\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!","type":"content","url":"/chapter6-2#section-6-6","position":17},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.7","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#section-6-7","position":18},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"Section 6.7","lvl2":"Examples"},"content":"Instability\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = lambda t, u: u\nu_exact = exp\na, b = (0.0, 1.0)\n\ndef LIAF(du_dt, tspan, u0, n):\n    a, b = tspan\n    h = (b - a) / n\n    t = linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[1] = u_exact(t[1])    # use an exact starting value\n    f = copy(u)\n    f[0] = du_dt(t[0], u[0])\n    for i in range(n):\n        f[i] = du_dt(t[i], u[i])\n        u[i + 1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f[i] + 2 * f[i-1])\n\n    return t, u.T\n\nn = [5, 10, 20, 40, 60]\nresults = PrettyTable([\"n\", \"error\"])\nfor j in range(5):\n    t, u = LIAF(du_dt, [a, b], [1.0], n[j])\n    err = abs(u_exact(b) - u[0, -1])\n    results.add_row([n[j], err])\nprint(results)\n\nThere is no convergence in sight! A graph of the last numerical attempt yields a clue:\n\nsemilogy(t, abs(u[0]), \"-o\")\nxlabel(\"$t$\"), ylabel(\"$|u|$\")\ntitle(\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.","type":"content","url":"/chapter6-2#section-6-7","position":19},{"hierarchy":{"lvl1":"Chapter 7"},"type":"lvl1","url":"/chapter7-2","position":0},{"hierarchy":{"lvl1":"Chapter 7"},"content":"","type":"content","url":"/chapter7-2","position":1},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"type":"lvl2","url":"/chapter7-2#examples","position":2},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"content":"\n\nfrom numpy import *\nfrom numpy.linalg import norm\nfrom matplotlib.pyplot import *\nfrom prettytable import PrettyTable\nimport sys\nsys.path.append('pkg/')\nimport FNC\nimport importlib\nimportlib.reload(FNC)\n\n# This (optional) block is for improving the display of plots.\nrcParams[\"figure.figsize\"] = [7, 4]\nrcParams[\"lines.linewidth\"] = 2\nrcParams[\"lines.markersize\"] = 4\nrcParams['animation.html'] = \"jshtml\"  # or try \"html5\"\n\n","type":"content","url":"/chapter7-2#examples","position":3},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.1","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#section-7-1","position":4},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.1","lvl2":"Examples"},"content":"Adjacency matrix\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = array([[0, 1, 0, 0], [1, 0, 0, 0], [1, 1, 0, 1], [0, 1, 1, 0]])\nprint(A)\n\nThe networkx package has many functions for working with graphs. Here, we instruct it to create a directed graph from the adjacency matrix, then make a drawing of it.\n\nimport networkx as nx\nG = nx.from_numpy_array(A, create_using=nx.DiGraph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nHere are the counts of all walks of length 3 in the graph:\n\nprint(A**3)\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = array([[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [0, 1, 0, 0]])\nG = nx.from_numpy_array(A, create_using=nx.Graph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nImages as matrices\n\nWe will use a test image from the well-known scikit-image package.\n\nfrom skimage import data as testimages\nimg = getattr(testimages, \"coffee\")()\nimshow(img)\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nprint(f\"image has shape {img.shape}\")\nprint(f\"first pixel has value {img[0, 0]}\")\n\nThe three values at each pixel are for intensities of red, green, and blue. We can convert each of those layers into an ordinary matrix of values between 0 and 255, which is maximum intensity.\n\nR = img[:, :, 0]\nprint(\"upper left corner of the red plane is:\")\nprint(R[:5, :5])\nprint(f\"red channel values range from {R.min()} to {R.max()}\")\n\nIt may also be convenient to convert the image to grayscale, which has just one layer of values from zero (black) to one (white).\n\nfrom skimage.color import rgb2gray\nA = rgb2gray(img)\nA[:5, :5]\nprint(\"upper left corner of grayscale:\")\nprint(A[:5, :5])\nprint(f\"gray values range from {A.min()} to {A.max()}\")\n\nimshow(A, cmap='gray')\naxis('off');\n\nSome changes we make to the grayscale matrix are easy to interpret visually.\n\nimshow(flipud(A), cmap='gray')\naxis('off');","type":"content","url":"/chapter7-2#section-7-1","position":5},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.2","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#section-7-2","position":6},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.2","lvl2":"Examples"},"content":"Eigenvalues and eigenvectors\n\nThe eig function from scipy.linalg will return a vector of eigenvalues and a matrix of associated eigenvectors.\n\nfrom numpy.linalg import eig\nA = pi * ones([2, 2])\nd, V = eig(A)\nprint(\"eigenvalues:\", d)\n\nWe can check the fact that this is an EVD (although in practice we never invert a matrix).\n\nfrom numpy.linalg import inv\nD = diag(d)\nprint(f\"should be near zero: {norm(A - V @ D @ inv(V), 2):.2e}\")\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nfrom numpy.linalg import cond\nA = array([[1, 1], [0, 1]])\nd, V = eig(A)\nprint(f\"cond(V) is {cond(V):.2e}\")\n\nBut even in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds up to roundoff error.\n\nprint(f\"should be near zero: {norm(A @ V - V @ diag(d), 2):.2e}\")\n\nEigenvalue conditioning\n\nWe first define a hermitian matrix. Note that we add the conjugate transpose of a matrix to itself.\n\nn = 7\nA = random.randn(n, n) + 1j * random.randn(n, n)\nA = (A + conj(A.T)) / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nfrom numpy.linalg import eig\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.5f}\")\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. Note that the Bauer–Fike theorem uses absolute differences, not relative ones. Since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(dist)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = arange(n) + 1\nA = triu(outer(x, ones(n)))\nprint(A[:5, :5])\n\nThis matrix is not at all close to normal.\n\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.2e}\")\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(f\"Maximum eigenvalue change is {max(dist):.2e}\")\nprint(f\"The Bauer-Fike upper bound is {cond(V) * norm(E, 2):.2e}\")\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nscatter(d, zeros(n), 18)\naxis(\"equal\") \nfor _ in range(100):\n    E = random.randn(n, n) + 1j * random.randn(n, n)\n    E = finfo(np.float32).eps * E / norm(E, 2)\n    dd, _ = eig(A + E)\n    scatter(real(dd), imag(dd), 2, 'k')\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nFrancis QR iteration\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nfrom numpy.linalg import qr\nD = diag([-6, -1, 2, 4, 5])\nV, R = qr(random.randn(5, 5))\nA = V @ D @ V.T    # note that V.T = inv(V) here\n\nprint(sort(eig(A)[0]))\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R @ Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nprint(sort(eig(A)[0]))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in range(40):\n    Q, R = qr(A)\n    A = R @ Q\nset_printoptions(precision=4)\nprint(A)","type":"content","url":"/chapter7-2#section-7-2","position":7},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.3","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#section-7-3","position":8},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.3","lvl2":"Examples"},"content":"SVD properties\n\nWe verify some of the fundamental SVD properties using standard Julia functions from LinearAlgebra.\n\nA = array([[(i + 1.0) ** j for j in range(4)] for i in range(5)])\nset_printoptions(precision=4)\nprint(A)\n\nThe factorization is obtained using svd from numpy.linalg.\n\nfrom numpy.linalg import svd\nU, sigma, Vh = svd(A)\nprint(\"singular values:\")\nprint(sigma)\n\nBy default, the full factorization type is returned. This can be a memory hog if one of the dimensions of \\mathbf{A} is very large.\n\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.T.shape)\n\nBoth \\mathbf{U} and \\mathbf{V} are orthogonal (in the complex case, unitary). Note that it’s \\mathbf{V}^* that is returned, not \\mathbf{V}.\n\nprint(f\"should be near zero: {norm(U.T @ U - eye(5), 2):.2e}\")\nprint(f\"should be near zero: {norm(Vh @ Vh.T - eye(4), 2):.2e}\")\n\nNext we test that we have the factorization promised by the SVD, using diagsvd to construct a rectangular diagonal matrix.\n\nfrom scipy.linalg import diagsvd\nS = diagsvd(sigma, 5, 4)\nprint(f\"should be near zero: {norm(A - U @ S @ Vh, 2):.2e}\")\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\nfrom numpy.linalg import cond\nprint(\"largest singular value:\", sigma[0])\nprint(\"2-norm of the matrix:  \", norm(A, 2))\nprint(\"singular value ratio:\", sigma[0] / sigma[-1])\nprint(\"2-norm condition no.:\", cond(A, 2))\n\nFor matrices that are much taller than they are wide, the thin SVD form is more memory-efficient, because \\mathbf{U} takes the same shape.\n\nA = random.randn(1000, 10)\nU, sigma, Vh = svd(A, full_matrices=False)\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.shape)","type":"content","url":"/chapter7-2#section-7-3","position":9},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.4","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#section-7-4","position":10},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.4","lvl2":"Examples"},"content":"Rayleigh quotient\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nfrom numpy.linalg import qr\nn = 20\nd = arange(n) + 1\nD = diag(d)\nV, _ = qr(random.randn(n, n))    # get a random orthogonal V\nA = V @ D @ V.T\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = lambda x: dot(x, A @ x) / dot(x, x)\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nprint(R(V[:, 6]))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nresults = PrettyTable([\"perturbation size\", \"R.Q. - λ\"])\nfor delta in 1 / 10 ** arange(1, 6):\n    e = random.randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 5] + e\n    quotient = R(x)\n    results.add_row([delta, quotient - d[5]])\n\nprint(results)","type":"content","url":"/chapter7-2#section-7-4","position":11},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.5","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#section-7-5","position":12},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"Section 7.5","lvl2":"Examples"},"content":"Image compression\n\nWe make an image from some text, then reload it as a matrix.\n\ntext(\n    0.5,\n    0.5,\n    \"Hello world\",\n    dict(fontsize=44),\n    horizontalalignment=\"center\",\n    verticalalignment=\"center\",\n)\naxis(\"off\")\nsavefig(\"hello.png\")\n\nimg = imread(\"hello.png\")[:, :, :3]\nA = rgb2gray(img)\nprint(f\"image of size {A.shape}\")\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around index 38.\n\nfrom numpy.linalg import svd\nU, sigma, Vt = svd(A)\nsemilogy(sigma, \"o\")\ntitle(\"Singular values\")\nxlabel(\"$i$\"), ylabel(\"$\\\\sigma_i$\");\n\nsignificant = sigma / sigma[0] > 10 * 2**-52\nprint(f\"last significant singular value at index {max(where(significant)[0])}\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor k in range(4):\n    r = 2 + 2 * k\n    Ak = U[:, :r] @ diag(sigma[:r]) @ Vt[:r, :]\n    subplot(2, 2, k + 1)\n    imshow(Ak, cmap=\"gray\", clim=(0.0, 1.0))\n    title(f\"rank = {r}\")\n    xticks([]), yticks([])\n\nConsider how little data is needed to reconstruct these images. For rank-8, for instance, we have 8 left and right singular vectors plus 8 singular values.\n\nm, n = A.shape\nfull_size = m * n\ncompressed_size = 8 * (m + n + 1)\nprint(f\"compression ratio: {full_size / compressed_size:.1f}\")\n\nDimension reduction in voting records\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nfrom scipy.io import loadmat\nvars = loadmat(\"voting.mat\")\nA = vars[\"A\"]\nm, n = A.shape\nprint(\"size:\", (m, n))\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nimshow(A, cmap=\"viridis\")\nxlabel(\"bill\")\nylabel(\"senator\")\ntitle(\"Votes in 111th U.S. Senate\");\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, sigma, Vt = svd(A)\ntau = cumsum(sigma**2) / sum(sigma**2)\nplot(range(1, 17), tau[:16], \"o\")\nxlabel(\"$k$\")\nylabel(\"$\\tau_k$\")\ntitle(\"Fraction of singular value energy\");\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(1, 2, 1)\nplot(U[:, 0], \"o\")\nxlabel(\"senator\"),title(\"left singular vector\")\nsubplot(1, 2, 2)\nplot(Vt[0, :], \"o\")\nxlabel(\"bill\"), title(\"right singular vector\");\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = sigma[0] * U[:, 0]\nx2 = sigma[1] * U[:, 1]\n\nRep = vars[\"Rep\"] - 1\nDem = vars[\"Dem\"] - 1\nInd = vars[\"Ind\"] - 1\n\nscatter(x1[Dem], x2[Dem], color=\"blue\", label=\"D\")\nscatter(x1[Rep], x2[Rep], color=\"red\", label=\"R\")\nscatter(x1[Ind], x2[Ind], color=\"darkorange\", label=\"I\")\n\nxlabel(\"partisanship\")\nylabel(\"bipartisanship\")\nlegend()\ntitle(\"111th US Senate in 2D\");","type":"content","url":"/chapter7-2#section-7-5","position":13},{"hierarchy":{"lvl1":"Chapter 8"},"type":"lvl1","url":"/chapter8-1","position":0},{"hierarchy":{"lvl1":"Chapter 8"},"content":"","type":"content","url":"/chapter8-1","position":1},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"type":"lvl2","url":"/chapter8-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"content":"Power iteration\n\ndef poweriter(A, numiter):\n    \"\"\"\n    poweriter(A,numiter)\n\n    Perform `numiter` power iterations with the matrix `A`, starting from a random vector, \n    and return a vector of eigenvalue estimates and the final eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    for k in range(numiter):\n        y = A @ x\n        m = np.argmax(abs(y))\n        gamma[k] = y[m] / x[m]\n        x = y / y[m]\n\n    return gamma, x\n\nInverse iteration\n\ndef inviter(A, s, numiter):\n    \"\"\"\n    inviter(A,s,numiter)\n\n    Perform `numiter` inverse iterations with the matrix `A` and shift `s`, starting\n    from a random vector, and return a vector of eigenvalue estimates and the final\n    eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    PL, U = lu(A - s * np.eye(n), permute_l=True)\n    for k in range(numiter):\n        y = np.linalg.solve(U, np.linalg.solve(PL, x))\n        m = np.argmax(abs(y))\n        gamma[k] = x[m] / y[m] + s\n        x = y / y[m]\n\n    return gamma, x\n\nArnoldi iteration\n\ndef arnoldi(A, u, m):\n    \"\"\"\n    arnoldi(A,u,m)\n\n    Perform the Arnoldi iteration for `A` starting with vector `u`, out to the Krylov\n    subspace of degree `m`. Return the orthonormal basis (`m`+1 columns) and the upper\n    Hessenberg `H` of size `m`+1 by `m`.\n    \"\"\"\n    n = u.size\n    Q = np.zeros([n, m + 1])\n    H = np.zeros([m + 1, m])\n    Q[:, 0] = u / np.linalg.norm(u)\n    for j in range(m):\n        # Find the new direction that extends the Krylov subspace.\n        v = A @ Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        # Normalize and store the new basis vector.\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n    return Q, H\n\nAbout the code\n\nThe loop starting at line 17 does not exactly implement \n\n(8.4.7) and . The reason is numerical stability. Though the described and implemented versions are mathematically equivalent in exact arithmetic (see \n\nExercise 6), the approach in \n\nFunction 8.4.2 is more stable.\n\nGMRES\n\ndef arngmres(A, b, m):\n    \"\"\"\n    arngmres(A,b,m)\n\n    Do `m` iterations of GMRES for the linear system `A`*x=`b`. Return the final solution\n    estimate x and a vector with the history of residual norms. (This function is for\n    demo only, not practical use.)\n    \"\"\"\n    n = len(b)\n    Q = np.zeros([n, m + 1])\n    Q[:, 0] = b / np.linalg.norm(b)\n    H = np.zeros([m + 1, m])\n\n    # Initial \"solution\" is zero.\n    residual = np.hstack([np.linalg.norm(b), np.zeros(m)])\n\n    for j in range(m):\n        # Next step of Arnoldi iteration.\n        v = A @ Q[:, j]\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n        # Solve the minimum residual problem.\n        r = np.hstack([np.linalg.norm(b), np.zeros(j + 1)])\n        z = np.linalg.lstsq(H[:j + 2, :j + 1], r)[0]\n        x = Q[:, :j + 1] @ z\n        residual[j + 1] = np.linalg.norm(A @ x - b)\n\n    return x, residual","type":"content","url":"/chapter8-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"type":"lvl2","url":"/chapter8-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"content":"\n\nfrom numpy import *\nfrom numpy.linalg import norm\nfrom matplotlib.pyplot import *\nfrom prettytable import PrettyTable\nimport sys\nsys.path.append('pkg/')\nimport FNC\nimport importlib\nimportlib.reload(FNC)\n\n# This (optional) block is for improving the display of plots.\nrcParams[\"figure.figsize\"] = [7, 4]\nrcParams[\"lines.linewidth\"] = 2\nrcParams[\"lines.markersize\"] = 4\nrcParams['animation.html'] = \"jshtml\"  # or try \"html5\"\n\n","type":"content","url":"/chapter8-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-1","position":6},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"content":"Sparsity\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nimport scipy.sparse as sp\nfrom scipy.io import loadmat\n\nvars = loadmat(\"roswelladj.mat\")    # get from the book's website\nA = sp.csr_matrix(vars[\"A\"])\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nm, n = A.shape\nprint(f\"density is {A.nnz / (m * n):.3%}\")\n\nWe can compare the storage space needed for the sparse \\mathbf{A} with the space needed for its dense / full counterpart.\n\nF = A.todense()\nprint(f\"{A.data.nbytes/1e6:.3f} MB for sparse form, {F.nbytes/1e6:.3f} MB for dense form\")\n\nMatrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nfrom timeit import default_timer as timer\nx = random.randn(n)\nstart = timer()\nfor i in range(1000):\n    A @ x\nprint(f\"sparse time: {timer() - start:.4g} sec\")\n\nstart = timer()\nfor i in range(1000):\n    F @ x\nprint(f\"dense time: {timer() - start:.4g} sec\")\n\nFill-in of a sparse matrix\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nimport networkx as nx\nwsg = nx.watts_strogatz_graph(200, 4, 0.02)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nA = nx.adjacency_matrix(wsg)\nspy(A)\ntitle(\"Adjacency matrix $A$\");\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nWhile A**6 is valid syntax here, it means elementwise power, not matrix power.\n\nfrom scipy.sparse.linalg import matrix_power\nspy(matrix_power(A, 6))\ntitle(\"$A^6$\")\n\nBanded matrices\n\nThe scipi.sparse.diags function creates a sparse matrix given its diagonal elements and the diagonal indexes to put them on. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50\ndata = [n * ones(n-3), ones(n), linspace(-1, 1-n, n-1)]\noffsets = [-3, 0, 1]    # 3rd below, main, 1st above\nA = sp.diags(data, offsets, format=\"lil\")\nprint(A[:7, :7].todense())\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nL, U = FNC.lufact(A.todense())\nsubplot(1, 2, 1), spy(L)\nsubplot(1, 2, 2), spy(U);\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\nL, U, p = FNC.plufact(A.todense())\nsubplot(1, 2, 1), spy(L[p, :])\nsubplot(1, 2, 2), spy(U)\n\nEigenvalues of sparse matrices\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nev = 1 / arange(1, n + 1)\nA = FNC.sprandsym(n, density, eigvals=ev)\nprint(f\"density is {A.nnz / prod(A.shape):.3%}\")\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=\"LM\".\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=5, which=\"LM\")    # largest magnitude\nprint(1 / ev)\n\nNow we find the 4 closest to the value 1 in the complex plane, via sigma=1.\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=4, sigma=0.03)    # closest to sigma\nprint(ev)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nfrom scipy.sparse.linalg import spsolve\nx = 1 / arange(1, n + 1)\nb = A @ x\nstart = timer()\nxx = spsolve(A, b)\nprint(f\"sparse time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")\n\nfrom numpy.linalg import solve\nF = A.todense()\nstart = timer()\nxx = solve(F, b)\nprint(f\"dense time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")","type":"content","url":"/chapter8-1#id-8-1","position":7},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-2","position":8},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"content":"Power iteration\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = random.choice(range(10), (5, 5))\nA = A / sum(A, 0)\nx = random.randn(5)\nprint(x)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A @ x\nprint(y)\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A @ y\nprint(z)\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nx = random.randn(5)\nfor j in range(6):\n    x = A @ x\nprint(x)\nprint(A @ x)\n\nThis phenomenon is unlikely to be a coincidence!\n\nConvergence of power iteration\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nev = [1, -0.75, 0.6, -0.4, 0]\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run the power iteration 60 times. The first output should be a sequence of estimates converging to the dominant eigenvalue—which, in this case, we set up to be 1.\n\nbeta, x = FNC.poweriter(A, 60)\nprint(beta)\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = 1 - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1)\nxlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\nprint(f\"theory: {ev[1] / ev[0]:.5f}\")\nprint(f\"observed: {err[40] / err[39]:.5f}\")\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nprint(beta[26:30])\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = beta[-1] - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1), xlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.","type":"content","url":"/chapter8-1#id-8-2","position":9},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-3","position":10},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"content":"Convergence of inverse iteration\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run inverse iteration with the shift s=0.7. Convergence should be to the eigenvalue closest to the shift, which we know to be 0.6 here.\n\nbeta, x = FNC.inviter(A, 0.7, 30)\nprint(beta)\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nerr = beta[-1] - beta    # last estimate is our best\nsemilogy(arange(30), abs(err), \"-o\")\nylim(1e-16, 1)\nxlabel(\"$k$\"),  ylabel(\"$|\\\\lambda_3 - \\\\beta_k|$\")\ntitle(\"Convergence of inverse iteration\")\n\nLet’s reorder the eigenvalues to enforce \n\n(8.3.3).\n\nThe argsort function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nev = ev[argsort(abs(ev - 0.7))]\nprint(ev)\n\nNow it is easy to compare the theoretical and observed linear convergence rates.\n\nprint(f\"theory: {(ev[0] - 0.7) / (ev[1] - 0.7):.5f}\")\nprint(f\"observed: {err[21] / err[20]:.5f}\")\n\nDynamic shift strategy\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\nfrom numpy.linalg import solve\ns = 0.7\nx = ones(5)\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = beta\nx = y / y[0]\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in range(4):\n    s = beta\n    x = y / y[0]\n    y = solve(A - s * eye(5), x)\n    beta = x[0] / y[0] + s\n    print(f\"latest estimate: {beta:.8f}\")","type":"content","url":"/chapter8-1#id-8-3","position":11},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-4","position":12},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"content":"Conditioning of the Krylov matrix\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = [b zeros(100, 29)]\nfor m in 1:29\n    v = A * Km[:, m]\n    Km[:, m+1] = v / norm(v)\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nresid = zeros(30)\nfor m in 1:30\n    z = (A * Km[:, 1:m]) \\ b\n    x = Km[:, 1:m] * z\n    resid[m] = norm(b - A * x)\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nplot(0:29, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, L\"\\| b-Ax_m \\|\"),\n    title=\"Residual for linear systems\", leg=:none)\n\nArnoldi iteration\n\nWe illustrate a few steps of the Arnoldi iteration for a small matrix.\n\nA = rand(1.0:9.0, 6, 6)\n\nThe seed vector we choose here determines the first member of the orthonormal basis.\n\nu = randn(6)\nQ = u / norm(u);\n\nMultiplication by \\mathbf{A} gives us a new vector in \\mathcal{K}_2.\n\nAq = A * Q[:, 1];\n\nWe subtract off its projection in the previous direction. The remainder is rescaled to give us the next orthonormal column.\n\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1]\nQ = [Q v / norm(v)];\n\nOn the next pass, we have to subtract off the projections in two previous directions.\n\nAq = A * Q[:, 2]\nv = Aq - dot(Q[:, 1], Aq) * Q[:, 1] - dot(Q[:, 2], Aq) * Q[:, 2]\nQ = [Q v / norm(v)];\n\nAt every step, \\mathbf{Q}_m is an ONC matrix.\n\n@show opnorm(Q' * Q - I);\n\nAnd \\mathbf{Q}_m spans the same space as the three-dimensional Krylov matrix.\n\nK = [u A * u A * A * u];\n@show rank([Q K]);","type":"content","url":"/chapter8-1#id-8-4","position":13},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-5","position":14},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"content":"GMRES\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = [norm(b); zeros(60)]\nfor m in 1:60\n    s = [norm(b); zeros(m)]\n    z = H[1:m+1, 1:m] \\ s\n    x = Q[:, 1:m] * z\n    resid[m+1] = norm(b - A * x)\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nplot(0:60, resid, m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, \"norm of mth residual\"),\n    title=\"Residual for GMRES\", leg=:none)\n\nRestarting GMRES\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nA = FNC.poisson(50)\nn = size(A, 1)\nb = ones(n);\nspy(A, color=:blues)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from the IterativeSolvers package, since our simple implementation does not offer restarting.\n\nThe syntax f(x;foo) is shorthand for f(x,foo=foo).\n\nreltol = 1e-12;\nplt = plot(title=\"Convergence of restarted GMRES\", leg=:bottomleft,\n    xaxis=(L\"m\"), yaxis=(:log10, \"residual norm\", [1e-8, 100]))\n\nfor restart in [n, 20, 40, 60]\n    x, hist = IterativeSolvers.gmres(A, b; restart, reltol,\n        maxiter=100, log=true)\n    plot!(hist[:resnorm], label=\"restart = $restart\")\nend\n\nplt\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.","type":"content","url":"/chapter8-1#id-8-5","position":15},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-6","position":16},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"content":"MINRES\n\nThe following matrix is indefinite.\n\nA = FNC.poisson(10) - 20I\nλ = eigvals(Matrix(A))\nisneg = @. λ < 0\n@show sum(isneg), sum(.!isneg);\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nmn, mx = extrema(-λ[isneg])\nκ₋ = mx / mn\nmn, mx = extrema(λ[.!isneg])\nκ₊ = mx / mn\nρ = (sqrt(κ₋ * κ₊) - 1) / (sqrt(κ₋ * κ₊) + 1)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nb = rand(100)\nx, hist = minres(A, b, reltol=1e-10, maxiter=51, log=true);\n\nrelres = hist[:resnorm] / norm(b)\nm = 0:length(relres)-1\nplot(m, relres, label=\"observed\", leg=:left,\n    xaxis=L\"m\", yaxis=(:log10, \"relative residual\"),\n    title=(\"Convergence of MINRES\"))\nplot!(m, ρ .^ (m / 2), l=:dash, label=\"upper bound\")\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nConvergence of MINRES and CG\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, 1 / 100)\nx = (1:n) / n\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from IterativeSolvers.\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = FNC.sprandsym(n, density, 1 / 2500)\nb = A * x;\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.","type":"content","url":"/chapter8-1#id-8-6","position":17},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-7","position":18},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"content":"Blurring an image\n\nWe use a readily available test image.\n\nimg = testimage(\"mandrill\")\nm, n = size(img)\nX = @. Float64(Gray(img))\nplot(Gray.(X), title=\"Original image\", aspect_ratio=1)\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nfunction blurmatrix(d)\n    v1 = fill(0.25, d - 1)\n    return spdiagm(0 => fill(0.5, d), 1 => v1, -1 => v1)\nend\nB, C = blurmatrix(m), blurmatrix(n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nblur = X -> B^12 * X * C^12;\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nDeblurring an image\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = testimage(\"lighthouse\")\nm, n = size(img)\nX = @. Float64(Gray(img))\n\nB = spdiagm(0 => fill(0.5, m),\n    1 => fill(0.25, m - 1), -1 => fill(0.25, m - 1))\nC = spdiagm(0 => fill(0.5, n),\n    1 => fill(0.25, n - 1), -1 => fill(0.25, n - 1))\nblur = X -> B^12 * X * C^12\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\n# vec (built-in) converts matrix to vector\nunvec = z -> reshape(z, m, n);  # convert vector to matrix\n\nNow we declare the three-step blur transformation as a LinearMap, supplying also the size of the vector form of an image.\n\nT = LinearMap(x -> vec(blur(unvec(x))), m * n);\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nThe function clamp01 in Images restricts values to be in the interval [0,1].\n\ny = minres(T, vec(Z), maxiter=50, reltol=1e-5);\nY = unvec(clamp01.(y))\n\nplot(Gray.(X), layout=2, title=\"Original\")\nplot!(Gray.(Y), subplot=2, title=\"Deblurred\")","type":"content","url":"/chapter8-1#id-8-7","position":19},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-8","position":20},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"content":"Diagonal preconditioning\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nA = matrixdepot(\"wathen\", 60)\nn = size(A, 1)\n@show n, nnz(A);\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nb = ones(n)\nM = DiagonalPreconditioner(diag(A));\n\nWe now compare CG with and without the preconditioner.\n\nplain(b) = cg(A, b, maxiter=200, reltol=1e-4, log=true)\ntime_plain = @elapsed x, hist1 = plain(b)\nprec(b) = cg(A, b, Pl=M, maxiter=200, reltol=1e-4, log=true)\ntime_prec = @elapsed x, hist2 = prec(b)\n@show time_plain, time_prec\n\nrr = hist1[:resnorm]\nplot(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"plain\")\nrr = hist2[:resnorm]\nplot!(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"preconditioned\")\ntitle!(\"Diagonal preconditioning in CG\")\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\nIncomplete LU preconditioning\n\nHere is a nonsymmetric matrix arising from a probabilistic model in computational chemistry.\n\nA = sparse(matrixdepot(\"Watson/chem_master1\"))\nn = size(A, 1)\n@show n, nnz(A), issymmetric(A)\n\nWithout a preconditioner, GMRES makes essentially no progress after 100 iterations.\n\nb = rand(40000)\nconst GMRES = IterativeSolvers.gmres\nx, history = GMRES(A, b, maxiter=100, reltol=1e-5, log=true)\nresnorm = history[:resnorm]\n@show resnorm[end] / resnorm[1];\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\niLU = ilu(A, τ=0.25)\n@show nnz(iLU) / nnz(A);\n\nThe result is almost 10 times as dense as \\mathbf{A} and yet still not a true factorization of it. However, it’s close enough for an approximate inverse in a preconditioner. The actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}, but we just supply the factorization to gmres.\n\n_, history = GMRES(A, b, Pl=iLU, maxiter=100, reltol=1e-5, log=true)\nhistory\n\nThe τ parameter in ilu balances the accuracy of the iLU factorization with the time needed to compute it and invert it. As \\tau\\to 0, more of the elements are kept, making the preconditioner more effective but slower per iteration.\n\nplt = plot(0:40, resnorm[1:41] / resnorm[1], label=\"no preconditioning\",\n    xaxis=(\"iteration number\"), yaxis=(:log10, \"residual norm\"),\n    leg=:bottomright, title=\"Incomplete LU preconditioning\")\nfor τ in [2, 1, 0.25, 0.1]\n    t = @elapsed iLU = ilu(A; τ)\n    t += @elapsed _, history = GMRES(A, b, Pl=iLU, maxiter=100,\n        reltol=1e-5, log=true)\n    resnorm = history[:resnorm]\n    label = \"τ = $τ, time = $(round(t,digits=3))\"\n    plot!(0:length(resnorm)-1, resnorm / resnorm[1]; label)\nend\nplt\n\nIn any given problem, it’s impossible to know in advance where the right balance lies between fidelity and speed for the preconditioner.","type":"content","url":"/chapter8-1#id-8-8","position":21}]}