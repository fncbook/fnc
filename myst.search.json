{"version":"1","records":[{"hierarchy":{"lvl1":"Glossary"},"type":"lvl1","url":"/glossary","position":0},{"hierarchy":{"lvl1":"Glossary"},"content":"adjacency matrix\n\nMatrix whose nonzero entries show the links between nodes in a graph. (\n\nFrom matrix to insight)\n\nadjoint\n\nConjugate transpose of a complex matrix. (\n\nComputing with matrices)\n\nadvection equation\n\nArchetypical PDE of hyperbolic type, representing transport phenomena. (\n\nTraffic flow)\n\nalgorithm\n\nList of instructions for transforming data into a result. (\n\nAlgorithms)\n\nArnoldi iteration\n\nStable algorithm for finding orthonormal bases of nested Krylov subspaces. (\n\nKrylov subspaces)\n\nasymptotic\n\nRelationship indicating that two functions have the same leading behavior in some limit. (\n\nEfficiency of matrix computations)\n\nbackward error\n\nChange to the input of a problem required to produce the result found by an inexact algorithm. (\n\nStability)\n\nbackward substitution\n\nSystematic method for solving a linear system with an upper triangular matrix. (\n\nLinear systems)\n\nbandwidth\n\nThe number of diagonals around the main diagonal that have nonzero elements. (\n\nExploiting matrix structure)\n\nbarycentric interpolation formula\n\nComputationally useful expression for the interpolating polynomial as a ratio of rational terms. (\n\nThe barycentric formula)\n\nbig-O\n\nRelationship indicating that one function is bounded above by a multiple of another in some limit. (\n\nEfficiency of matrix computations)\n\nboundary-value problem\n\nA differential equation with which partial information about the solution is given at multiple points on the boundary of the domain. (\n\nTwo-point BVP)\n\ncardinal function\n\nInterpolating function that is 1 at one node and 0 at all the others. (\n\nThe interpolation problem)\n\nCholesky factorization\n\nSymmetrized version of LU factorization for SPD matrices. (\n\nExploiting matrix structure)\n\ncollocation\n\nSolution of a differential equation by imposing it approximately at a set of nodes. (\n\nCollocation for linear problems)\n\ncondition number\n\nRatio of the size of change in the output of a function to the size of change in the input that produced it. (\n\nProblems and conditioning)\n\ncubic spline\n\nPiecewise cubic function with two globally continuous derivatives, most often used for interpolation or approximation. (\n\nCubic splines)\n\ndiagonalizable matrix\n\nMatrix that admits an eigenvalue decomposition. Also known as nondefective. (\n\nEigenvalue decomposition)\n\ndifferentiation matrix\n\nMatrix mapping a vector of function values to a vector of approximate derivative values. (\n\nDifferentiation matrices)\n\nDirichlet condition\n\nBoundary condition specifying the value of the solution. (\n\nTwo-point BVP)\n\ndominant eigenvalue\n\nEigenvalue with the largest magnitude (absolute value, in the real case). (\n\nPower iteration)\n\ndouble precision\n\nTypical standard in floating-point representation, using 64 bits to achieve about 16 decimal significant digits of precision. (\n\nFloating-point numbers)\n\neigenvalue\n\nScalar λ such that \\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x} for a square matrix \\mathbf{A} and nonzero vector \\mathbf{x}. (\n\nEigenvalue decomposition)\n\neigenvalue decomposition\n\nExpression of a square matrix as the product of eigenvector and diagonal eigenvalue matrices. (Abbreviated EVD.)(\n\nEigenvalue decomposition)\n\neigenvector\n\nVector for which the action of a matrix is effectively one-dimensional.  (\n\nEigenvalue decomposition)\n\nEuler’s method\n\nPrototype of all IVP solution methods, obtained by assuming constant derivatives for the solution over short time intervals. (\n\nEuler’s method)\n\nevolutionary PDE\n\nA partial differential equation in which one of the independent variables is time or a close analog. (\n\nBlack–Scholes equation)\n\nextrapolation\n\nUse of multiple discretization values to cancel out leading terms in an error expansion. (\n\nNumerical integration)\n\nfinite differences\n\nLinear combination of function values that approximates the value of a derivative of the function at a point. (\n\nFinite differences)\n\nfinite element method (FEM)\n\nUse of piecewise integration to pose a linear system of equations for the approximate solution of a boundary-value problem. (\n\nThe Galerkin method)\n\nfixed-point iteration\n\nRepeated application of a function in hopes of converging to a fixed point. (\n\nFixed-point iteration)\n\nfixed point problem\n\nFinding a value of a given function where the input and output values are the same; equivalent to rootfinding. (\n\nFixed-point iteration)\n\nfloating-point numbers\n\nA finite set that substitutes for the real numbers in machine calculations. Denoted by \\mathbb{F}. (\n\nFloating-point numbers)\n\nflops\n\nArithmetic operations on floating-point numbers, often counted as a proxy for computer runtime. (\n\nEfficiency of matrix computations)\n\nforward substitution\n\nSystematic method for solving a linear system with a lower triangular matrix. (\n\nLinear systems)\n\nFrobenius norm\n\nMatrix norm computed by applying the vector 2-norm to a vector interpretation of the matrix. (\n\nVector and matrix norms)\n\nGauss–Newton method\n\nGeneralization of Newton’s method for nonlinear least squares. (\n\nNonlinear least squares)\n\nGaussian elimination\n\nUse of row operations to transform a linear system to an equivalent one in triangular form. (\n\nLU factorization)\n\ngenerating polynomials\n\nA pair of polynomials whose coefficients match those of a multistep method for IVPs. (\n\nMultistep methods)\n\nglobal error\n\nError made by an IVP method over the entire time interval of the solution. (\n\nEuler’s method)\n\nGMRES\n\nIterative solution of a linear system through stable least-squares solutions on nested Krylov subspaces. (\n\nGMRES)\n\ngraph\n\nRepresentation of a network as a set of nodes and edges. (\n\nFrom matrix to insight)\n\nhat functions\n\nCardinal functions for piecewise linear interpolation. (\n\nPiecewise linear interpolation)\n\nheat equation\n\nArchetypical parabolic PDE that describes diffusion. (\n\nBlack–Scholes equation)\n\nhermitian\n\nCombination of transpose and elementwise complex conjugation. Also describes a matrix that equals its own hermitian. (\n\nSymmetry and definiteness)\n\nhermitian positive definite matrix\n\nMatrix that is hermitian with strictly positive eigenvalues; complex variant of symmetric positive definite. (Abbreviated HPD matrix.)(\n\nSymmetry and definiteness)\n\nhomogeneous boundary condition\n\nHaving a zero value. (\n\nTwo-point BVP, \n\nBlack–Scholes equation)\n\nidentity matrix\n\nMatrix with ones on the diagonal and zeros elsewhere, acting as the multiplicative identity. (\n\nComputing with matrices)\n\nill-conditioned\n\nExhibiting a large condition number, indicating high sensitivity of a result to changes in the data. (\n\nProblems and conditioning)\n\nimplicit\n\nFormula that defines a quantity only indirectly, e.g., as the solution of a nonlinear equation. (\n\nMultistep methods)\n\ninduced matrix norm\n\nNorm computed using the interpretation of a matrix as a linear operator. (\n\nVector and matrix norms)\n\ninitial-value problem\n\nAn ordinary differential equation (possibly vector-valued) together with an initial condition. (\n\nBasics of IVPs, \n\nIVP systems)\n\ninner product\n\nScalar or dot product of a pair of vectors, or its extension to a pair of functions. (\n\nOrthogonal polynomials)\n\ninterpolation\n\nConstruction of a function that passes through a given set of data points. (\n\nPolynomial interpolation, \n\nThe interpolation problem)\n\ninverse iteration\n\nSubtraction of a shift followed by matrix inversion, used in power iteration to transform the eigenvalue closest to a target value into a dominant one.  (\n\nInverse iteration)\n\nJacobian matrix\n\nMatrix of first partial derivatives that defines the linearization of a vector-valued function. (\n\nNewton for nonlinear systems)\n\nKronecker product\n\nAlternative type of matrix multiplication useful for problems on a tensor-product domain. (\n\nLaplace and Poisson equations)\n\nKrylov subspace\n\nVector space generated by powers of a square matrix that is often useful for reducing the dimension of large problems. (\n\nKrylov subspaces)\n\nLagrange formula\n\nTheoretically useful expression for an interpolating polynomial. (\n\nPolynomial interpolation)\n\nLanczos iteration\n\nSpecialization of the Arnoldi iteration to the case of a hermitian (or real symmetric) matrix. (\n\nMINRES and conjugate gradients)\n\nLaplace equation\n\nArchetypical elliptic PDE describing a steady state. (\n\nLaplace and Poisson equations)\n\nlinear convergence\n\nSequence in which the difference between sequence value and limit asymptotically decreases by a constant factor at each term, making a straight line on a log-linear graph.\\\n(\n\nFixed-point iteration)\n\nlinear least-squares problem\n\nMinimization of the 2-norm of the residual for an overdetermined linear system. (\n\nFitting functions to data)\n\nlocal truncation error\n\nDiscretization error made in one time step of an IVP solution method. (\n\nEuler’s method, \n\nMultistep methods)\n\nLU factorization\n\nFactorization of a square matrix into the product of a unit lower triangular matrix and an upper triangular matrix. (\n\nLU factorization)\n\nmachine epsilon\n\nDistance from 1 to the next-largest floating-point number. Also called unit roundoff or machine precision, though the usages are not consistent across different references.\\\n(\n\nFloating-point numbers)\n\nmatrix condition number\n\nNorm of the matrix times the norm of its inverse, equivalent to the condition number for solving a linear system. (\n\nConditioning of linear systems)\n\nmethod of lines\n\nSolution technique for partial differential equations in which each independent variable is discretized separately. (\n\nThe method of lines)\n\nmultistep\n\nFormula using information over more than a single time step to advance the solution. (\n\nMultistep methods)\n\nNeumann condition\n\nBoundary condition specifying the derivative of the solution. (\n\nTwo-point BVP)\n\nNewton’s method\n\nRootfinding iteration that uses the linearization of the given function in order to define the next root approximation. (\n\nNewton’s method)\n\nnodes\n\nValues of the independent variable where an interpolant’s values are prescribed. (\n\nThe interpolation problem)\n\nnonlinear least-squares problem\n\nMinimization of the 2-norm of the residual of a function that depends nonlinearly on a vector. (\n\nNonlinear least squares)\n\nnorm\n\nMeans of defining the magnitude of a vector or matrix. (\n\nVector and matrix norms)\n\nnormal matrix\n\nMatrix that has a \n\nunitary matrix of eigenvectors in an \n\neigenvalue decomposition. (\n\nEigenvalue decomposition)\n\nnormal equations\n\nSquare linear system equivalent to the linear least-squares problem. (\n\nThe normal equations)\n\nnumerical integration\n\nEstimation of a definite integral by combining values of the integrand, rather than by finding an antiderivative. (\n\nNumerical integration)\n\none-step IVP method\n\nIVP solver that uses information from just one time level to advance to the next. (\n\nEuler’s method)\n\nONC matrix\n\nMatrix whose columns are orthonormal vectors. (\n\nThe QR factorization)\n\norder of accuracy\n\nLeading power of the truncation error as a function of a discretization size parameter. (\n\nConvergence of finite differences, \n\nNumerical integration, \n\nEuler’s method, \n\nMultistep methods)\n\northogonal vectors\n\nNonzero vectors that have an inner product of zero. (\n\nThe QR factorization)\n\northogonal matrix\n\nSquare ONC matrix, i.e., matrix whose transpose is its inverse. (\n\nThe QR factorization)\n\northogonal polynomials\n\nFamily of polynomials whose distinct members have an integral inner product equal to zero, as with Legendre and Chebyshev polynomials. (\n\nOrthogonal polynomials)\n\northonormal vectors\n\nVectors that are both mutually orthogonal and all of unit 2-norm. (\n\nThe QR factorization)\n\nouter product\n\nMultiplication of two vectors resulting in a rank-1 matrix. (\n\nLU factorization)\n\noverdetermined\n\nCharacterized by having more constraints than available degrees of freedom. (\n\nFitting functions to data)\n\npiecewise linear\n\nFunction that is linear between each consecutive pair of nodes, but whose slope may jump at the nodes. (\n\nPiecewise linear interpolation)\n\nPLU factorization\n\nLU factorization with row pivoting. (\n\nRow pivoting)\n\npower iteration\n\nRepeated application of a matrix to a vector, followed by normalization, resulting in convergence to an eigenvector for the dominant eigenvalue. (\n\nPower iteration)\n\npreconditioning\n\nUse of an approximate inverse to improve the convergence rate of Krylov iterations for a linear system. (\n\nPreconditioning)\n\npseudoinverse\n\nRectangular matrix that maps data to solution in the linear least-squares problem, generalizing the matrix inverse. (\n\nThe normal equations)\n\nQR factorization\n\nRepresentation of a matrix as the product of an orthogonal and an upper triangular matrix. (\n\nThe QR factorization)\n\nquadratic convergence\n\nSequence in which the difference between sequence value and limit asymptotically decreases by a constant times the square of the preceding difference. (\n\nNewton’s method)\n\nquasi-Newton methods\n\nRootfinding methods that overcome the issues of Jacobian computation and lack of global convergence in Newton’s method. (\n\nQuasi-Newton methods)\n\nquasimatrix\n\nCollection of functions (such as orthogonal polynomials) that have algebraic parallels to columns of a matrix. (\n\nOrthogonal polynomials)\n\nRayleigh quotient\n\nFunction of vectors that equals an eigenvalue when given its eigenvector as input. (\n\nSymmetry and definiteness)\n\nreduced QR factorization\n\nSee thin QR.\n\nreduced SVD\n\nSee thin SVD.\n\nresidual\n\nFor a linear system, the difference between \\mathbf{b} and \\mathbf{A}\\tilde{\\mathbf{x}} for a computed solution approximation \\tilde{\\mathbf{x}}. More generally, the actual value of a quantity that is made zero by an exact solution. (\n\nConditioning of linear systems, \n\nThe rootfinding problem)\n\nrestarting\n\nTechnique used in GMRES to prevent the work per iteration and overall storage from growing uncontrollably. (\n\nGMRES)\n\nrootfinding problem\n\nFinding the input value for a given function which makes that function zero. (\n\nThe rootfinding problem)\n\nrow pivoting\n\nReordering rows during LU factorization to ensure that the factorization exists and can be computed stably. (\n\nRow pivoting)\n\nRunge phenomenon\n\nManifestation of the instability of polynomial interpolation at equally spaced nodes as degree increases. (\n\nStability of polynomial interpolation)\n\nRunge–Kutta\n\nOne-step method for IVPs that evaluates the derivative of the solution more than once to advance a single step. (\n\nRunge–Kutta methods)\n\nsecant method\n\nScalar quasi-Newton method that uses a secant line rather than a tangent line to define a root estimate. (\n\nInterpolation-based methods)\n\nshooting\n\nUnstable technique for solving a boundary-value problem in which an initial value is sought for by a rootfinding algorithm. (\n\nShooting)\n\nsimilar matrices\n\nMatrices that are linked by a \n\nsimilarity transformation, thus sharing the same set of eigenvalues. (\n\nEigenvalue decomposition)\n\nsimilarity transformation\n\nMapping \\mathbf{A} \\mapsto \\mathbf{S}\\mathbf{A}\\mathbf{S}^{-1} for an invertible \\mathbf{S}. The transformation leaves eigenvalues, but not eigenvectors, unchanged. (\n\nEigenvalue decomposition)\n\nsimple root\n\nRoot of a function at which the derivative of the function is nonzero. (\n\nThe rootfinding problem)\n\nsingular value decomposition\n\nExpression of a matrix as a product of two orthogonal/unitary matrices and a nonnegative diagonal matrix. (Abbreviated SVD.) (\n\nSingular value decomposition)\n\nsparse matrix\n\nDescribing a matrix that has mostly zero elements for structural reasons. (\n\nExploiting matrix structure, \n\nSparsity and structure)\n\nspectral convergence\n\nExponentially rapid decrease in error as the number of interpolation nodes increases, e.g., as observed in Chebyshev polynomial and trigonometric interpolation. (\n\nStability of polynomial interpolation)\n\nstability region\n\nRegion of the complex plane describing when numerical solution of a linear IVP is bounded as t\\to\\infty. (\n\nAbsolute stability)\n\nstep size\n\nIncrement in time between successive solution values in a numerical IVP solver. (\n\nEuler’s method)\n\nstiff differential equation\n\nDescribes an IVP in which stability is a greater restriction than accuracy for many solution methods, usually favoring the use of an implicit time stepping method. (\n\nImplementation of multistep methods, \n\nStiffness)\n\nsubtractive cancellation\n\nGrowth in relative error that occurs when two numbers are added/subtracted to get a result that is much smaller in magnitude than the operands; also called loss of significance or cancellation error. (\n\nProblems and conditioning)\n\nsuperlinear convergence\n\nSequence for which the convergence is asymptotically faster than any linear rate. (\n\nInterpolation-based methods)\n\nsymmetric matrix\n\nSquare matrix that is equal to its transpose. (\n\nComputing with matrices)\n\nsymmetric positive definite matrix\n\nMatrix that is symmetric and positive definite, thereby permitting a Cholesky factorization. Correspondingly called hermitian positive definite in the complex case. (\n\nExploiting matrix structure)\n\ntensor-product domain\n\nA domain that can be parameterized using variables that lay in a logical rectangle or cuboid; i.e., each variable independently varies in an interval. (\n\nTensor-product discretizations)\n\nthin QR factorization\n\nVariant of the QR factorization that discards information not needed to fully represent the original matrix. (\n\nThe QR factorization)\n\nthin SVD\n\nVariant of the singular value decomposition that discards information not needed to fully represent the original matrix. (\n\nSingular value decomposition)\n\ntrapezoid formula\n\nNumerical integration method resulting from integration of a piecewise linear interpolant. (\n\nNumerical integration, \n\nMultistep methods)\n\ntriangular matrix\n\nMatrix that is all zero either above (for lower triangular) or below (for upper triangular) the main diagonal. (\n\nLinear systems)\n\ntridiagonal matrix\n\nMatrix with nonzeros only on the main diagonal and the adjacent two diagonals. (\n\nExploiting matrix structure)\n\ntrigonometric interpolation\n\nInterpolation of a periodic function by a linear combination of real or complex trigonometric functions. (\n\nTrigonometric interpolation)\n\ntruncation error\n\nDifference between an exact value and an approximation, such as one that truncates an infinite series. (\n\nConvergence of finite differences, \n\nNumerical integration)\n\nunit triangular matrix\n\nTriangular matrix that has a 1 in every position on the main diagonal. (\n\nLU factorization)\n\nunit vector\n\nA vector whose norm equals 1. (\n\nVector and matrix norms)\n\nunitary matrix\n\nSquare matrix with complex-valued entries whose columns are orthonormal. (\n\nEigenvalue decomposition)\n\nunstable\n\nAllowing perturbations of the data to have much larger effects on the results than can be explained by the problem’s condition number. (\n\nStability)\n\nupper Hessenberg matrix\n\nMatrix that has nonzeros only in the upper triangle and first subdiagonal. (\n\nKrylov subspaces)\n\nVandermonde matrix\n\nMatrix whose columns are formed from elementwise powers of a given vector, important for polynomial interpolation and approximation of data. (\n\nPolynomial interpolation)\n\nweights\n\nCoefficients in a linear combination of function values in a finite-difference or integration method. (\n\nFinite differences, \n\nNumerical integration, \n\nSpectrally accurate integration)\n\nzero-stability\n\nBoundedness property of multistep methods that is required for convergence. (\n\nZero-stability of multistep methods)","type":"content","url":"/glossary","position":1},{"hierarchy":{"lvl1":"Review of linear algebra"},"type":"lvl1","url":"/linear-algebra","position":0},{"hierarchy":{"lvl1":"Review of linear algebra"},"content":"","type":"content","url":"/linear-algebra","position":1},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Terminology"},"type":"lvl2","url":"/linear-algebra#terminology","position":2},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Terminology"},"content":"An ordinary number in \\mathbb{R} or \\mathbb{C} may be called a scalar. An m\\times n matrix \\mathbf{A} is a rectangular m-by-n array of numbers called elements or entries.  The numbers m and n are called the row dimension and the column dimension, respectively; collectively they describe the size or shape of \\mathbf{A}. We say \\mathbf{A} belongs to the set \\mathbb{R}^{m\\times n} if its entries are real, or \\mathbb{C}^{m\\times n} if they are complex-valued.  A square matrix has equal row and column dimensions. A row vector has dimension 1\\times n, while a column vector has dimension m \\times 1.\n\nIn this text, all vectors are column vectors, and we use \\mathbb{R}^n or \\mathbb{C}^n to denote spaces of these vectors. When a row vector is needed, it is given an explicit transpose symbol (see below).\n\nWe use capital letters in bold to refer to matrices, and lowercase bold letters for vectors. The bold symbol \\boldsymbol{0} may refer to a vector of all zeros or to a zero matrix, depending on context; we use 0 as the scalar zero only.\n\nTo refer to a specific element of a matrix, we use the uppercase name of the matrix without boldface. For instance, A_{24} refers to the (2,4) element of \\mathbf{A}. To refer to an element of a vector, we use just one subscript, as in x_3. A boldface character with one or more subscripts, on the other hand, is a matrix (uppercase) or vector (lowercase) that belongs to a numbered collection.\n\nWe will have frequent need to refer to the individual columns of a matrix as vectors. We use a lowercase bold version of the matrix name with a subscript to represent the column number. For example, \\mathbf{a}_1,\\mathbf{a}_2,\\ldots,\\mathbf{a}_n are the columns of the m\\times n matrix \\mathbf{A}. Conversely, whenever we define a sequence of vectors \\mathbf{v}_1,\\ldots,\\mathbf{v}_p, we can implicitly consider them to be columns of a matrix \\mathbf{V}. Sometimes we might write\\mathbf{V}=\\bigl[ \\mathbf{v}_j \\bigr]\n\nto emphasize the connection between a matrix and its columns.\n\nThe diagonal (more specifically, main diagonal) of an n\\times n matrix \\mathbf{A} refers to the entries A_{ii}, i=1,\\ldots,n. The entries A_{ij} where j-i=k are on a superdiagonal if k>0 and a subdiagonal if k<0. The diagonals are numbered as indicated here:  \\begin{bmatrix}\n    0 & 1 & 2 & \\cdots & n-1 \\\\\n    -1 & 0 & 1 & \\cdots & n-2 \\\\\n    \\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n    -n+2 & \\cdots & -1 & 0 & 1\\\\\n    -n+1 & \\cdots & -2 & -1 & 0\n  \\end{bmatrix}.\n\nA diagonal matrix is one whose entries are all zero off the main diagonal.  An upper triangular matrix \\mathbf{U} has entries U_{ij} with U_{ij}=0 if i>j, and a lower triangular matrix \\mathbf{L} has L_{ij}=0 if i<j.\n\nThe transpose of \\mathbf{A}\\in\\mathbb{C}^{m\\times n} is the matrix \\mathbf{A}^T\\in\\mathbb{C}^{n\\times m} given by  \\mathbf{A}^T =\n  \\begin{bmatrix}\n    A_{11} & A_{21} & \\cdots & A_{m1}\\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    A_{1n} & A_{2n} & \\cdots & A_{mn}\n  \\end{bmatrix}.\n\nThe adjoint or hermitian of a matrix \\mathbf{A} is given by \\mathbf{A}^*=\\overline{\\mathbf{A}^T}, where the bar denotes taking a complex conjugate elementwise. If \\mathbf{A} is real, then \\mathbf{A}^*=\\mathbf{A}^T. A square matrix is symmetric if \\mathbf{A}^T=\\mathbf{A} and hermitian if \\mathbf{A}^*=\\mathbf{A}.","type":"content","url":"/linear-algebra#terminology","position":3},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Algebra"},"type":"lvl2","url":"/linear-algebra#algebra","position":4},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Algebra"},"content":"Matrices and vectors of the same size may be added elementwise.  Multiplication by a scalar is also defined elementwise. These operations obey the familiar laws of commutativity, associativity, and distributivity. The multiplication of two matrices, on the other hand, is less straightforward.\n\nThere are two ways for vectors to be multiplied together. If \\mathbf{v} and \\mathbf{w} are in \\mathbb{C}^n, their inner product is  \\mathbf{v}^* \\mathbf{w} = \\sum_{k=1}^n \\overline{v_k}\\, w_k.\n\nTrivially, one finds that \\mathbf{w}^* \\mathbf{v} = \\overline{(\\mathbf{v}^*\\mathbf{w})}.\n\nAdditionally, any two vectors \\mathbf{v}\\in\\mathbb{C}^m and \\mathbf{w}\\in\\mathbb{C}^n (with m\\neq n allowed) have an outer product, which is an m\\times n matrix:  \\mathbf{v} \\mathbf{w}^*\n  = \\bigl[ v_i \\overline{w_j} \\bigr]_{\\,i=1,\\ldots,m,\\, j=1,\\ldots,n }\n  = \\begin{bmatrix}\n    v_1\\,\\overline{w_1} & v_1\\,\\overline{w_2} & \\cdots & v_1\\,\\overline{w_n}\\\\\n    v_2\\,\\overline{w_1} & v_2\\,\\overline{w_2} & \\cdots & v_2\\,\\overline{w_n}\\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    v_m\\,\\overline{w_1} & v_m\\,\\overline{w_2} & \\cdots & v_m\\,\\overline{w_n}\n  \\end{bmatrix}.\n\nFor real vectors, the complex conjugates above have no effect and {}^* becomes {}^T.\n\nIn order for matrices \\mathbf{A} and \\mathbf{B} to be multiplied, it is necessary that their inner dimensions match. Thus, if \\mathbf{A} is m\\times p, then \\mathbf{B} must be p \\times n. In terms of scalar components, the (i,j) entry of \\mathbf{C}=\\mathbf{A}\\mathbf{B} is given by  C_{ij} = \\sum_{k=1}^p A_{ik} B_{kj}.\n\nNote that even if \\mathbf{A}\\mathbf{B} is defined, \\mathbf{B}\\mathbf{A} may not be. Moreover, even when both products are defined, they may not equal each other.\n\nMatrix multiplication is not commutative, i.e., the order of terms in a product matters to the result.\n\nMatrix multiplication is associative, however:\\mathbf{A}\\mathbf{B}\\mathbf{C}=(\\mathbf{A}\\mathbf{B})\\mathbf{C}=\\mathbf{A}(\\mathbf{B}\\mathbf{C}).\n\nHence while we cannot change the ordering of the terms, we can change the order of the operations. This is a property that we will use repeatedly. We also note here the important identity  (\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T.\n\nSpecifically, if either product is defined, then they both are defined and equal each other.","type":"content","url":"/linear-algebra#algebra","position":5},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear combinations"},"type":"lvl2","url":"/linear-algebra#linear-combinations","position":6},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear combinations"},"content":"It is worth reinterpreting \n\n(A.6) at a vector level. If \\mathbf{A} has dimensions m\\times n, it can be multiplied on the right by an n \\times 1 column vector \\mathbf{v} to produce an m \\times 1 column vector \\mathbf{A}\\mathbf{v}, which satisfies  \\mathbf{A}\\mathbf{v} =\n  \\begin{bmatrix}\n    \\displaystyle \\sum_k A_{1k}v_k \\\\[2mm]\n    \\displaystyle \\sum_k A_{2k}v_k \\\\\n    \\vdots\\\\\n    \\displaystyle \\sum_k A_{mk}v_k\n  \\end{bmatrix}\n  = v_1\n  \\begin{bmatrix}\n    A_{11}\\\\A_{21}\\\\\\vdots\\\\A_{m1}\n  \\end{bmatrix} +\n  v_2\n  \\begin{bmatrix}\n    A_{12}\\\\A_{22}\\\\\\vdots\\\\A_{m2}\n  \\end{bmatrix} +\n  \\cdots + v_n\n  \\begin{bmatrix}\n    A_{1n}\\\\A_{2n}\\\\\\vdots\\\\A_{mn}\n  \\end{bmatrix} = v_1 \\mathbf{a}_1 + \\cdots + v_n \\mathbf{a}_n.\n\nWe say that \\mathbf{A}\\mathbf{v} is a linear combination of the columns of \\mathbf{A}.\n\nMultiplying a matrix on the right by a column vector produces a linear combination of the columns of the matrix.\n\nThere is a similar interpretation of multiplying \\mathbf{A} on the left by a row vector. Keeping to our convention that boldface letters represent column vectors, we write, for \\mathbf{v}\\in\\mathbb{R}^m,  \\begin{split}\n  \\mathbf{v}^T \\mathbf{A} &=\n  \\begin{bmatrix}\n    \\displaystyle \\sum_k v_k A_{k1} & \\displaystyle \\sum_k v_k A_{k2} & \\cdots & \\displaystyle \\sum_k v_k A_{kn}\n  \\end{bmatrix} \\\\\n   & = v_1\n  \\begin{bmatrix}\n    A_{11} &  \\cdots & A_{1n}\n  \\end{bmatrix} +\n  v_2\n  \\begin{bmatrix}\n    A_{21} & \\cdots & A_{2n}\n  \\end{bmatrix} +\n  \\cdots + v_m\n  \\begin{bmatrix}\n    A_{m1} & \\cdots & A_{mn}\n  \\end{bmatrix}.\n  \\end{split}\n\nMultiplying a matrix on the left by a row vector produces a linear combination of the rows of the matrix.\n\nThese two observations extend to more general matrix-matrix multiplications. One can show that (assuming that \\mathbf{A} is m\\times p and \\mathbf{B} is p\\times n)  \\mathbf{A}\\mathbf{B} =\n  \\mathbf{A} \\begin{bmatrix}\n    \\mathbf{b}_1 & \\mathbf{b}_2 & \\cdots & \\mathbf{b}_n\n  \\end{bmatrix}\n  = \\begin{bmatrix}\n    \\mathbf{A}\\mathbf{b}_1 & \\mathbf{A}\\mathbf{b}_2 & \\cdots & A\\mathbf{b}_n\n  \\end{bmatrix}.\n\nEquivalently, if we write \\mathbf{A} in terms of rows, then  \\mathbf{A} =\n  \\begin{bmatrix}\n    \\mathbf{w}_1^T \\\\[2mm] \\mathbf{w}_2^T \\\\ \\vdots \\\\ \\mathbf{w}_m^T\n  \\end{bmatrix}\n  \\qquad \\Longrightarrow \\qquad\n    \\mathbf{A}\\mathbf{B} =\n  \\begin{bmatrix}\n    \\mathbf{w}_1^T \\mathbf{B} \\\\[2mm] \\mathbf{w}_2^T \\mathbf{B} \\\\ \\vdots \\\\ \\mathbf{w}_m^T \\mathbf{B}\n  \\end{bmatrix}.\n\nA matrix-matrix product is a horizontal concatenation of matrix-vector products involving the columns of the right-hand matrix. Equivalently, a matrix-matrix product is also a vertical concatenation of vector-matrix products involving the rows of the left-hand matrix.\n\nThe representations of matrix multiplication are interchangeable; whichever one is most convenient at any moment can be used.\n\nLet\\mathbf{A} = \\begin{bmatrix}\n      1 & -1 \\\\ 0 & 2 \\\\ -3 & 1\n    \\end{bmatrix}, \\qquad\n\\mathbf{B} = \\begin{bmatrix}\n      2 & -1 & 0 & 4 \\\\ 1 & 1 & 3 & 2\n    \\end{bmatrix}.\n\nThen, going by \n\n(A.6), we get\\begin{split}\n  \\mathbf{A}\\mathbf{B} &= \\begin{bmatrix}\n          (1)(2) + (-1)(1) & (1)(-1) + (-1)(1) & (1)(0) + (-1)(3) & (1)(4) + (-1)(2) \\\\\n          (0)(2) + (2)(1) & (0)(-1) + (2)(1) & (0)(0) + (2)(3) & (0)(4) + (2)(2) \\\\\n          (-3)(2) + (1)(1) & (-3)(-1) + (1)(1) & (-3)(0) + (1)(3) & (-3)(4) + (1)(2)\n        \\end{bmatrix} \\\\\n  &= \\begin{bmatrix}\n      1 & -2 & -3 & 2 \\\\ 2 & 2 & 6 & 4 \\\\ -5 & 4 & 3 & -10\n    \\end{bmatrix}.\n\\end{split}\n\nBut note also, for instance, that  \\mathbf{A} \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix} = 2 \\begin{bmatrix} 1 \\\\ 0 \\\\ -3\n    \\end{bmatrix} + 1 \\begin{bmatrix} -1 \\\\ 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 2 \\\\ -5 \\end{bmatrix},\n\nand so on, as according to \n\n(A.11).\n\nThere is also an interpretation, presented in \n\nLU factorization, of matrix products in terms of vector outer products.","type":"content","url":"/linear-algebra#linear-combinations","position":7},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Identity and inverse"},"type":"lvl2","url":"/linear-algebra#identity-and-inverse","position":8},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Identity and inverse"},"content":"The identity matrix of size n, called \\mathbf{I} (or sometimes \\mathbf{I}_n), is a diagonal n\\times n matrix with every diagonal entry equal to one. As can be seen from \n\n(A.11) and \n\n(A.12), it satisfies \\mathbf{A}\\mathbf{I}=\\mathbf{A} for \\mathbf{A}\\in\\mathbb{C}^{m\\times n} and \\mathbf{I}\\mathbf{B}=\\mathbf{B} for \\mathbf{B}\\in\\mathbb{C}^{n\\times p}. It is therefore the matrix analog of the number 1, the multiplicative identity.\n\nLet  \\mathbf{B} =\n  \\begin{bmatrix}\n    2 & 1 & 7 & 4\\\\\n    6 & 0 & -1 & 0\\\\\n    -4 & -4 & 0 & 1\n  \\end{bmatrix}.\n\nSuppose we want to create a zero in the (2,1) entry by adding -3 times the first row to the second row, leaving the other rows unchanged.\n\nWe can express this operation as a product \\mathbf{A}\\mathbf{B} as follows. From dimensional considerations alone, \\mathbf{A} will need to be 3\\times 3. According to \n\n(A.10), we get “-3 times row 1 plus row 2” from left-multiplying \\mathbf{B} by the column vector \\bigl[ -3,\\: 1,\\: 0 \\bigr]. Equation \n\n(A.12) tells us that this must be the second row of \\mathbf{A}.\n\nSince the first and third rows of \\mathbf{A}\\mathbf{B} are the same as those of \\mathbf{B}, similar logic tells us that the first and third rows of \\mathbf{A} are the same as the identity matrix:  \\begin{bmatrix}\n    1 & 0 & 0\\\\\n    -3 & 1 & 0\\\\\n    0 & 0 & 1\n  \\end{bmatrix} \\mathbf{B}  =\n  \\begin{bmatrix}\n    2 & 1 & 7 & 4\\\\\n    0 & -3 & -22 & -12\\\\\n    -4 & -4 & 0 & 1\n  \\end{bmatrix}.\n\nThis can be verified using \n\n(A.6).\n\nNote that a square matrix \\mathbf{A} can always be multiplied by itself to get a matrix of the same size. Hence we can define the integer powers \\mathbf{A}^2=(\\mathbf{A})(\\mathbf{A}), \\mathbf{A}^3=(\\mathbf{A}^2) \\mathbf{A} = (\\mathbf{A}) \\mathbf{A}^2 (by associativity), and so on. By definition, \\mathbf{A}^0=\\mathbf{I}.\n\nIf \\mathbf{A} is an n\\times n matrix, then there may be at most one matrix \\mathbf{Z} of the same size such that\\mathbf{Z}\\mathbf{A} = \\mathbf{A}\\mathbf{Z} = \\mathbf{I}.\n\nIf \\mathbf{Z} exists, it is called the inverse of \\mathbf{A} and is written as \\mathbf{A}^{-1}. In this situation we say that \\mathbf{A} is invertible.\n\nThe zero matrix has no inverse. For n>1 there are also nonzero matrices that have no inverse. Such matrices are called singular. The properties “invertible” and “singular” are exclusive opposites; thus, nonsingular means invertible and noninvertible means singular.","type":"content","url":"/linear-algebra#identity-and-inverse","position":9},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear systems"},"type":"lvl2","url":"/linear-algebra#linear-systems","position":10},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Linear systems"},"content":"Given a square, n\\times n matrix \\mathbf{A} and  n-vectors \\mathbf{x} and \\mathbf{b}, the equation \\mathbf{A}\\mathbf{x}=\\mathbf{b} is equivalent to\\begin{split}\n  a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n &= b_1 \\\\\n  a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n &= b_2 \\\\\n  \\vdots  \\\\\n  a_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nn}x_n &= b_n.\n\\end{split}\n\nThe following facts are usually proved in any elementary text on linear algebra.\n\nLinear algebra equivalence\n\nThe following statements are equivalent:\n\n\\mathbf{A} is nonsingular.\n\n(\\mathbf{A}^{-1})^{-1} = \\mathbf{A}.\n\n\\mathbf{A}\\mathbf{x}=\\boldsymbol{0} implies that \\mathbf{x}=\\boldsymbol{0}.\n\n\\mathbf{A}\\mathbf{x}=\\mathbf{b} has a unique solution, \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}, for any n-vector \\mathbf{b}.","type":"content","url":"/linear-algebra#linear-systems","position":11},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Change of basis"},"type":"lvl2","url":"/linear-algebra#change-of-basis","position":12},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Change of basis"},"content":"When we write an n-vector in terms of its components, such as\\mathbf{v} = \\begin{bmatrix}\n1 \\\\ -2 \\\\ 3\n\\end{bmatrix},\n\nwe are implicitly expressing it relative to the standard basis of n-dimensional space, i.e.,\\mathbf{v} = (1) \\begin{bmatrix}\n1 \\\\ 0 \\\\ 0\n\\end{bmatrix} + (-2) \\begin{bmatrix} \n0 \\\\ 1 \\\\ 0\n\\end{bmatrix} + (3) \\begin{bmatrix}\n0 \\\\ 0 \\\\ 1\n\\end{bmatrix}.\n\nIf we want to express it instead as a linear combination of some other basis vectors \\mathbf{u}_1,\\ldots,\\mathbf{u}_n, we can write, to continue the example,\\begin{bmatrix}\n1 \\\\ -2 \\\\ 3\n\\end{bmatrix} \n= x_1 \\mathbf{u}_1 + x_2 \\mathbf{u}_2 + x_3 \\mathbf{u}_3\n= \\underbrace{\\begin{bmatrix}\n\\mathbf{u}_1 & \\mathbf{u}_2 & \\mathbf{u}_3\n\\end{bmatrix}}_{\\mathbf{U}}\n\\begin{bmatrix}\nx_1 \\\\ x_2 \\\\ x_3\n\\end{bmatrix},\n\nwhere the x_i are the components of \\mathbf{v} in the new basis. This is just a linear system to be solved for \\mathbf{x}. Hence:\n\nMultiplication of vector \\mathbf{v} on the left by \\mathbf{U}^{-1} changes the representation of \\mathbf{v} from the standard basis to the basis defined by the columns of \\mathbf{U}.\n\nConversely, multiplication on the left by \\mathbf{U} changes a representation from the U-basis to the standard basis.","type":"content","url":"/linear-algebra#change-of-basis","position":13},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Exercises"},"type":"lvl2","url":"/linear-algebra#exercises","position":14},{"hierarchy":{"lvl1":"Review of linear algebra","lvl2":"Exercises"},"content":"✍ In racquetball, the winner of a rally serves the next rally. Generally, the server has an advantage. Suppose that when Ashley and Barbara are playing racquetball, Ashley wins 60% of the rallies she   serves and Barbara wins 70% of the rallies she serves. If \\mathbf{x}\\in\\mathbb{R}^2 is such that x_1 is the probability that Ashley serves first and x_2=1-x_1 is the probability that Barbara serves first, define a matrix \\mathbf{A} such that \\mathbf{A}\\mathbf{x} is a vector of the probabilities that Ashley and Barbara each serve the second rally. What is the meaning of \\mathbf{A}^{10}\\mathbf{x}?\n\n✍ Suppose we have lists of n terms and m documents. We can   define an m\\times n matrix \\mathbf{A} such that A_{ij}=1 if term j   appears in document i, and A_{ij}=0 otherwise. Now suppose that the term list is\"numerical\", \"analysis\", \"more\", \"cool\", \"accounting\"\n\nand that \\mathbf{x} = \\begin{bmatrix} 1 & 1 & 0 & 1 & 0  \\end{bmatrix}^T. Give an interpretation of the product \\mathbf{A}\\mathbf{x}.\n\n✍ Let\\mathbf{A} =\n\\begin{bmatrix}\n  0 & 1 & 0 & 0 \\\\\n  0 & 0 & 0 & 1 \\\\\n  0 & 0 & 0 & 0 \\\\\n  0 & 0 & 1 & 0\n\\end{bmatrix}.\n\nShow that \\mathbf{A}^n=0 when n\\ge 4.\n\n✍  Find two matrices \\mathbf{A} and \\mathbf{B}, neither of which is the zero matrix, such that \\mathbf{A}\\mathbf{B}=\\boldsymbol{0}.\n\n✍ Prove that when \\mathbf{A} \\mathbf{B} is   defined, \\mathbf{B}^T\\mathbf{A}^T is defined too, and use Equation \n\n(A.6) to show that   (\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T.\n\n✍ Show that if \\mathbf{A} is invertible, then  (\\mathbf{A}^T)^{-1}=(\\mathbf{A}^{-1})^T. (This matrix is often just written as \\mathbf{A}^{-T}.)\n\n✍ Prove true, or give a counterexample: The product of upper triangular square matrices is upper triangular.\n\nThe conjugate of a complex number is found by  replacing all references to the imaginary unit i by -i. We do not use complex numbers until the second half of the book.","type":"content","url":"/linear-algebra#exercises","position":15},{"hierarchy":{"lvl1":"Algorithms"},"type":"lvl1","url":"/algorithms","position":0},{"hierarchy":{"lvl1":"Algorithms"},"content":"An idealized mathematical problem f(x) can usually only be approximated using a finite number of steps in finite precision. A complete set of instructions for transforming data into a result is called an algorithm. In most cases it is reasonable to represent an algorithm by another mathematical function, denoted here by \\tilde{f}(x).\n\nEven simple problems can be associated with multiple algorithms.\n\nSuppose we want to find an algorithm that maps a given x to the value of the polynomial f(x)= 5x^3 + 4x^2 + 3x + 2. Representing x^2 as (x)(x), we can find it with one multiplication. We can then find x^3=(x)(x^2) with one more multiplication. We can then apply all the coefficients (three more multiplications) and add all the terms (three additions), for a total of 8 arithmetic operations.\n\nThere is a more efficient algorithm, however: organize the polynomial according to Horner’s algorithm,f(x) = 2 + x \\bigl( 3 + x( 4 + 5x) \\bigr).\n\nIn this form you can see that evaluation takes only 3 additions and 3 multiplications. The savings represent 25% of the original computational effort, which could be significant if repeated billions of times.","type":"content","url":"/algorithms","position":1},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Algorithms as code"},"type":"lvl2","url":"/algorithms#algorithms-as-code","position":2},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Algorithms as code"},"content":"Descriptions of algorithms may be presented as a mixture of mathematics, words, and computer-style instructions called pseudocode, which varies in syntax and level of formality. In this book we use pseudocode to explain the outline of an algorithm, but the specifics are usually presented as working code.\n\nOf all the desirable traits of code, we emphasize clarity the most after correctness. We do not represent our programs as always being the shortest, fastest, or most elegant. Our primary goal is to illustrate and complement the mathematical underpinnings, while occasionally pointing out key implementation details.\n\nAs our first example, \n\nFunction 1.3.1 implements an algorithm that applies Horner’s algorithm to a general polynomial, using the identity\\begin{split}\np(x) &= c_1 + c_2 x + \\cdots + c_n x^{n-1} \\\\\n&= \\Bigl( \\bigl( (c_n x  + c_{n-1}) x + c_{n-2} \\bigr) x + \\cdots +c_{2} \\Bigr)x + c_{1}.\n\\end{split}\n\nhorner\n\nHorner’s algorithm for evaluating a polynomial\n\n\"\"\"\n    horner(c, x)\n\nEvaluate a polynomial whose coefficients are given in ascending\norder in `c`, at the point `x`, using Horner's rule.\n\"\"\"\nfunction horner(c, x)\n    n = length(c)\n    y = c[n]\n    for k in n-1:-1:1\n        y = x * y + c[k]\n    end\n    return y\nend\n\nAbout the code\n\nThe quoted lines at the beginning are a documentation string. The function itself starts off with the keyword function, followed by a list of its input arguments. The first of these is presumed to be a vector, whose length can be obtained and whose individual components are accessed through square bracket notation. After the computation is finished, the return keyword indicates which value or values are to be returned to the caller.\n\nThe length function in line 8 returns the number of elements in vector c. Here, that value is one greater than the degree of the polynomial. The syntax c[i] accesses element i of a vector c. In Julia, the first index of a vector is 1 by default, so in line 9, the last element of c is accessed.\n\nThe for / end construct in lines 10–12 is a loop. The local variable k is assigned the value n-1, then the loop body is executed, then k is assigned n-2, the body is executed again, and so on until finally k is set to 1 and the body is executed for the last time.\n\nThe return statement in line 13 terminates the function and specifies one or more values to be returned to the caller.\n\nImportant\n\nThe Polynomials package for Julia provides its own fast methods for polynomial evaluation that supersede our simple horner. This will be the case for all the codes in this book because the problems we study are well-known and important. In a more practical setting, you would take implementations of basic methods for granted and build on top of them.\n\nHorner’s algorithm for evaluating a polynomial\n\nfunction y = horner(c,x)\r\n% HORNER   Evaluate a polynomial using Horner's rule. \r\n% Input:\r\n%   c     Coefficients of polynomial, in descending order (vector)\r\n%   x     Evaluation point (scalar)\r\n% Output:\r\n%   y     Value of the polynomial at x (scalar)\r\n\r\nn = length(c);\r\ny = c(1);\r\nfor k = 2:n\r\n  y = x*y + c(k);\r\nend\n\nHorner’s algorithm for evaluating a polynomial\n\ndef horner(c,x):\n    \"\"\"\n    horner(c,x)\n\n    Evaluate a polynomial whose coefficients are given in descending order \n    in c, at the point x, using Horner's rule.\n    \"\"\"\n    n = len(c)\n    y = c[0]\n    for k in range(1, n):\n        y = x * y + c[k]   \n    return y\n\nUsing a function\n\nExample 1.3.2\n\nHere we show how to use \n\nFunction 1.3.1 to evaluate a polynomial. It’s not a part of core Julia, so you need to download and install this text’s package once, and load it for each new Julia session. The download is done by the following lines.\n\n#import Pkg\n#Pkg.add(\"FNCBook\");\n\nOnce installed, any package can be loaded with the using command, as follows.\n\nTip\n\nMany Julia functions, including the ones in this text, are in packages that must be loaded via using or import in each session. Sometimes a using statement can take a few seconds or even minutes to execute, if packages have been installed or updated.\n\n#using FundamentalsNumericalComputation\nusing FNCFunctions\nFNC = FNCFunctions\n\nFor convenience, this package also imports many other packages used throughout the book and makes them available as though you had run a using command for each of them.\n\nTip\n\nIf you are not sure where a particular function is defined, you can run methods on the function name to find all its definitions.\n\nReturning to horner, let us define a vector of the coefficients of p(x)=(x-1)^3=x^3-3x^2+3x-1, in ascending degree order.\n\nc = [-1, 3, -3, 1]\n\nIn order to avoid clashes between similarly named functions, Julia has boxed all the book functions into a namespace called FNC. We use this namespace whenever we invoke one of the functions.\n\nTip\n\nYou must use the module name when a package is loaded by import, but when loaded via using, some functions may be available with no prefix.\n\nFNC.horner(c, 1.6)\n\nThe above is the value of p(1.6).\n\nWhile the namespace does lead to a little extra typing, a nice side effect of using this paradigm is that if you type FNC. (including the period) and hit the Tab key, you will see a list of all the functions known in that namespace.\n\nThe multi-line string at the start of \n\nFunction 1.3.1 is documentation, which we can access using ?FNC.horner.\n\nmatlab\n\nExample 1.3.2\n\nHere we show how to use horner to evaluate a polynomial. First, we have to ensure that the book’s package is imported.\n\nimport fncbook as FNC\n\nHere is the help string for the function:\n\nhelp(FNC.horner)\n\nWe now define a vector of the coefficients of p(x)=(x−1)^3=x^3−3x^2+3x−1, in descending degree order. Note that the textbook’s functions are all in a namespace called FNC, to help distinguish them from other Python commands and modules.\n\nc = array([1, -3, 3, -1])\nprint(FNC.horner(c, 1.6))\n\nThe above is the value of p(1.6), up to a rounding error.","type":"content","url":"/algorithms#algorithms-as-code","position":3},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Writing your own functions"},"type":"lvl2","url":"/algorithms#writing-your-own-functions","position":4},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Writing your own functions"},"content":"Any collection of statements organized around solving a type of problem should probably be wrapped in a function. One clue is that if you find yourself copying and pasting code, perhaps with small changes in each instance, you should probably be writing a function instead.\n\nFunctions can be defined in text files with the extension .jl, at the command line (called the REPL prompt), or in notebooks.\n\nAs seen in \n\nFunction 1.3.1, one way to start a function definition is with the function keyword, followed by the function name and the input arguments in parentheses. For example, to represent the mathematical function e^{\\sin x}, we could usefunction myfun(x)\n    s = sin(x)\n    return exp(s)\nend\n\nThe return statement is used to end execution of the function and return one or more (comma-separated) values to the caller of the function. If an executing function reaches its end statement without encountering a return statement, then it returns the result of the most recent statement, but this is considered poor style.\n\nFor a function with a short definition like the one above, there is a more compact syntax to do the same thing:myfun(x) = exp(sin(x))\n\nYou can also define anonymous functions or lambda functions, which are typically simple functions that are provided as inputs to other functions. This is done with an arrow notation. For example, to plot the function above (in the Plots package) without permanently creating it, you could enterplot(x -> exp(sin(x)), 0, 6)\n\nAs in most languages, input arguments and variables defined within a function have scope limited to the function itself. However, they can access values defined within an enclosing scope. For instance:mycfun(x) = exp(c*sin(x))\nc = 1;  mycfun(3)   # returns exp(1*sin(3))\nc = 2;  mycfun(3)   # returns exp(2*sin(3))\n\nThere’s a lot more to be said about functions in Julia, but this is enough to get started.\n\nFunctions can be defined in text files with the extension .m, at the command line, or in Live Scripts.\n\nAs seen in \n\nFunction 1.3.1, one way to start a function definition is with the function keyword, followed one or more output arguments in brackets, the function name, and the input arguments in parentheses. For example, to represent the mathematical function e^{\\sin x}, we could use the following in a file called myfun.m:function [y] = myfun(x)\n    s = sin(x);\n    y = exp(s);\nend\n\nWhatever value is assigned to y when the function terminates will be returned as the output of the function.\n\nFor a function with a short definition like the one above, there is a more compact syntax to do the same thing:myfun = @(x) exp(sin(x));\n\nThe syntax on the right of the = above defines an anonymous function (called a lambda function in computer science), which can be used in place without giving it a name as we did here. We’ll have examples of doing this later on.\n\nAs in most languages, input arguments and variables defined within a function have scope limited to the function itself. However, they can access values defined within an enclosing scope, with those values being locked in at the time of creation. For instance:c = 1;\nmycfun = @(x) exp(c*sin(x));\nmycfun(3)   % returns exp(1*sin(3))\nc = 2;  \nmycfun(3)   % also returns exp(1*sin(3))\nmycfun = @(x) exp(c*sin(x));   % redefines mycfun\nmycfun(3)   % now returns exp(2*sin(3))\n\n\nThere’s a lot more to be said about functions, but this is enough to get started.\n\nFunctions can be defined in text files with the extension .py, at the command line (called the REPL prompt), or in notebooks.\n\nAs seen in \n\nFunction 1.3.1, one way to start a function definition is with the def keyword, followed by the function name and the input arguments in parentheses, ending with a colon. The statements for the body of the function must then all be indented. For example, to represent the mathematical function e^{\\sin x}, we could usedef myfun(x):\n    s = np.sin(x)\n    return np.exp(s)\n\nThe return statement is used to end execution of the function and return one or more (comma-separated) values to the caller of the function.\n\nTip\n\nIf an executing function reaches its end statement without encountering a return statement, then the output is undefined, which is a common source of bugs.\n\nFor a function with a short definition like the one above, there is a more compact syntax to do the same thing:myfun = lambda x : np.exp(np.sin(x))\n\nThe syntax on the right of the = above defines an anonymous function (called a lambda function in computer science), which can be used in place without giving it a name as we did here. We’ll have examples of doing this later on.\n\nAs in most languages, input arguments and variables defined within a function have scope limited to the function itself. However, they can access values defined within an enclosing scope. For instance:mycfun = lambda x : np.exp(c * np.sin(x))\nc = 1;  print(mycfun(3))   # exp(1*sin(3))\nc = 2;  print(mycfun(3))   # exp(2*sin(3))\n\nThere’s a lot more to be said about functions in Python, but this is enough to get started.","type":"content","url":"/algorithms#writing-your-own-functions","position":5},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Exercises"},"type":"lvl2","url":"/algorithms#exercises","position":6},{"hierarchy":{"lvl1":"Algorithms","lvl2":"Exercises"},"content":"Note\n\nThe exercises marked with a computer icon require the use of a computer. The others can be done by hand.\n\nWarning\n\nA polynomial is represented as a vector of coefficients in all three languages covered by this book. However, in Julia they are given in ascending degree order, which is most convenient programmatically, while in MATLAB and NumPy they are given in descending order, which is the way we usually write them. This difference makes writing the exercises universally a little awkward, so be advised.\n\n⌨ Write a function poly1(p) that returns the value of a polynomial p(x) = c_1 + c_2 x + \\cdots + c_n x^{n-1} at x=-1. You should do this directly, not by a call to or imitation of \n\nFunction 1.3.1. Test your function on r(x)=3x^3-x+1 and s(x)=2x^2-x.\n\n⌨  In statistics, one defines the variance of sample values x_1,\\ldots,x_n bys^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\overline{x})^2,\n\\qquad \\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i.\n\nWrite a function samplevar(x) that takes as input a vector x of any length and returns s^2 as calculated by the formula. You should test your function on the vectors ones(100) and rand(200). If you enter using Statistics in Julia, then you can compare to the results of the var function.\n\n⌨  Let x and y be vectors whose entries give the coordinates of the n vertices of a polygon, given in counterclockwise order. Write a function polygonarea(x,y) that computes and returns the area of the polygon using this formula based on Green’s theorem:A = \\frac{1}{2} \\left| \\sum_{k=1}^n x_k y_{k+1} - x_{k+1}y_k \\right|.\n\nHere n is the number of polygon vertices, and it’s understood that x_{n+1}=x_1 and y_{n+1}=y_1. (Note: The function abs computes absolute value.) Test your functions on a square and an equilateral triangle.","type":"content","url":"/algorithms#exercises","position":7},{"hierarchy":{"lvl1":"Problems and conditioning"},"type":"lvl1","url":"/conditioning","position":0},{"hierarchy":{"lvl1":"Problems and conditioning"},"content":"Let’s think a bit about what must be the easiest math problem you’ve dealt with in quite some time: adding 1 to a number. Formally, we describe this problem as a function f(x)=x+1, where x is any real number.\n\nOn a computer, x will be represented by its floating-point counterpart, \\fl(x). Given the property \n\n(1.1.5), we have \\fl(x)=x(1+\\epsilon) for some ε satisfying |\\epsilon| < \\macheps/2.  There is no error in representing the value 1.\n\nLet’s suppose that we are fortunate and that the addition proceeds exactly, with no additional errors. Then the machine result is just  {y} = x(1+\\epsilon)+1.\n\nWe can derive the relative error in this result:  \\frac{ |{y}-f(x)| }{ |f(x)| } = \\frac{ |(x+\\epsilon x+1) - (x+1)| }{ |x+1| }\n  = \\frac{ |\\epsilon x| }{ |x+1| } .\n\nThis error could be quite large if the denominator is small. In fact, we can make the relative error as large as we please by taking x very close to -1. This is essentially what happened in \n\nDemo 1.1.4.\n\nYou may have encountered this situation before when using significant digits for scientific calculations. Suppose we round all results to five decimal digits, and we add -1.0012 to 1.0000. The result is -0.0012, or -1.2\\times 10^{-3} in scientific notation. Notice that even though both operands are specified to five digits, it makes no sense to write more than two digits in the answer because there is no information in the problem beyond their decimal places.\n\nThis phenomenon is known as subtractive cancellation, or loss of significance. We may say that three digits were “lost” in the mapping from -1.0012 to -0.0012. There’s no way the loss could be avoided, regardless of the algorithm, once we decided to round off everything to a fixed number of digits.\n\nSubtractive cancellation\n\nSubtractive cancellation is a loss of accuracy that occurs when two numbers add or subtract to give a result that is much smaller in magnitude. It is one of the most common mechanisms introducing dramatic growth of errors in floating-point computation.\n\nIn double precision, all  the values are represented to about 16 significant decimal digits of precision, but it’s understood that subtractive cancellation may render some of those digits essentially meaningless.","type":"content","url":"/conditioning","position":1},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Condition numbers"},"type":"lvl2","url":"/conditioning#condition-numbers","position":2},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Condition numbers"},"content":"Now we consider problems more generally. As above, we represent a problem as a function f that maps a real data value x to a real result f(x). We abbreviate this situation by the notation f:\\real \\mapsto \\real, where \\real represents the real number set.\n\nWhen the problem f is approximated in floating point on a computer, the data x is represented as a floating-point value \\tilde{x}=\\fl(x). Ignoring all other sources of error, we define the quantitative measure   \\frac{ \\vphantom{\\dfrac{\\bigl|}{\\bigl|}}\\dfrac{|f(x)-f(\\tilde{x})|}{|f(x)|} }{%\n     \\vphantom{\\dfrac{\\bigl|}{\\bigl|}}\\dfrac{|x-\\tilde{x}|}{|x|} },\n\nwhich is the ratio of the relative changes in result and data. We make this expression more convenient if we recall that floating-point arithmetic gives \\tilde{x}=x(1+\\epsilon) for some value |\\epsilon|\\le \\macheps/2. Hence   \\dfrac{\\left|f(x)-f(x+\\epsilon x)\\right| } {|\\epsilon f(x)|}.\n\nFinally, we idealize what happens in a perfect computer by taking a limit as \\macheps\\to 0.\n\nCondition number (scalar function)\n\nThe relative condition number of a scalar function f(x) is   \\kappa_f(x) = \\lim_{\\epsilon\\to 0} \\dfrac{ |f(x)-f(x(1+\\epsilon))| }{ |\\epsilon f(x)| }.\n\nThe condition number is a ratio of the relative error of the output to the relative error of the input. It depends only on the problem and the data, not the computer or the algorithm.\n\nAssuming that f has at least one continuous derivative, we can simplify the expression \n\n(1.2.5) through some straightforward manipulations:\\begin{split}\n   \\kappa_f(x) &= \\lim_{\\epsilon\\to 0} \\left| \\dfrac{ f(x+\\epsilon x) - f(x) }{ \\epsilon f(x)}\n   \\right| \\\\\n  &= \\lim_{\\epsilon\\to 0}  \\left| \\dfrac{ f(x+\\epsilon x) - f(x) }{ \\epsilon x} \\cdot  \\frac{x}{f(x)}  \\right| \\\\\n   &= \\left| \\dfrac{ x f'(x)} {f(x)}  \\right|.\n\\end{split}\n\nIn retrospect, it should come as no surprise that the change in values of f(x) due to small changes in x involves the derivative of f. In fact, if we were making measurements of changes in absolute rather than relative terms, the condition number would be simply |f'(x)|.\n\nLet’s return to our “add 1” problem and generalize it slightly to f(x)=x-c for constant c. We compute, using \n\n(1.2.6),\\kappa_f(x)=\\left| \\frac{(x)(1)}{x-c} \\right| = \\left| \\frac{x}{x-c}\\right|.\n\nThe result is the relative change \n\n(1.2.2) normalized by the size of the perturbation ε. The condition number is large when |x|\\gg |x-c|. Considering that c can be negative, this result applies to both addition and subtraction. Furthermore, the situation is symmetric in x and c; that is, if we perturbed c and not x, the result would be |c|/|x-c|.\n\nAnother elementary operation is to multiply by a constant: f(x)=cx for nonzero c. We compute\\kappa_f(x) = \\left| \\dfrac{ x f'(x)} {f(x)}  \\right| = \\left| \\frac{(x)(c)}{cx} \\right| = 1.\n\nWe conclude that multiplication by a real number leads to the same  relative error in the result as in the data. In other words,  multiplication does not have the potential for cancellation error that addition does.\n\nCondition numbers of the major elementary functions are given in \n\nTable 1.2.1.\n\nTable 1.2.1:Relative condition numbers of elementary functions\n\nFunction\n\nCondition number\n\nf(x) = x + c\n\n\\kappa_f(x) = \\dfrac{\\lvert x \\rvert}{\\lvert x+c\\rvert}\n\nf(x) = cx\n\n\\kappa_f(x) = 1\n\nf(x) = x^p\n\n\\kappa_f(x) = \\lvert p \\rvert\n\nf(x) = e^x\n\n\\kappa_f(x) = \\lvert x \\rvert\n\nf(x) = \\sin(x)\n\n\\kappa_f(x) = \\lvert x\\cot(x) \\rvert\n\nf(x) = \\cos(x)\n\n\\kappa_f(x) = \\lvert x\\tan(x) \\rvert\n\nf(x) = \\log(x)\n\n\\kappa_f(x) = \\dfrac{1}{\\lvert \\log(x) \\rvert}\n\nAs you are asked to show in \n\nExercise 4, when two functions f and g are combined in a chain as h(x)=f(g(x)), the composite condition number is\\kappa_h(x) = \\kappa_f(g(x)) \\cdot \\kappa_g(x).","type":"content","url":"/conditioning#condition-numbers","position":3},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Estimating errors"},"type":"lvl2","url":"/conditioning#estimating-errors","position":4},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Estimating errors"},"content":"Refer back to the definition of \\kappa_f as a limit in \n\n(1.2.5). Approximately speaking, if |\\epsilon| is small, we expect\\left| \\dfrac{ f(x+\\epsilon x) - f(x) }{ f(x)}  \\right| \\approx \\kappa_f(x)\\, |\\epsilon|.\n\nThat is, whenever the data x is perturbed by a small amount, we expect that relative perturbation to be magnified by a factor of \\kappa_f(x) in the result.\n\nIf \\kappa_f \\approx 10^d, then we expect to lose up to d decimal digits of accuracy in computing f(x) from x.\n\nLarge condition numbers signal when errors cannot be expected to remain comparable in size to roundoff error. We call a problem poorly conditioned or ill-conditioned when \\kappa_f(x) is large, although there is no fixed threshold for the term.\n\nIf \\kappa_f \\approx 1/\\macheps, then we can expect the result to have a relative error of as much as 100% simply by expressing the data x in finite precision. Such a function is essentially not computable at this machine epsilon.\n\nConsider the problem f(x)= \\cos(x). By the table above, \\kappa_f(x) = |x \\tan x|. There are two different ways in which κ might become large:\n\nIf |x| is very large, then perturbations that are small relative to x may still be large compared to 1. Because |f(x)|\\le 1 for all x, this implies that the perturbation will be large relative to the result, too.\n\nThe condition number grows without bound as x approaches an odd integer multiple of \\pi/2, where f(x)=0. A perturbation which is small relative to a nonzero x may not be small relative to f(x) in such a case.\n\nYou may have noticed that for some functions, such as the square root, the condition number can be less than 1. This means that relative changes get smaller in the passage from input to output. However, every result in floating-point arithmetic is still subject to rounding error at the relative level of \\macheps. In practice, \\kappa_f<1 is no different from \\kappa_f=1.","type":"content","url":"/conditioning#estimating-errors","position":5},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Polynomial roots"},"type":"lvl2","url":"/conditioning#polynomial-roots","position":6},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Polynomial roots"},"content":"Most problems have multiple input and output values. These introduce complications into the formal definition of the condition number. Rather than worry over those details here, we can still look at variations in only one output value with respect to one data value at a time.\n\nConsider the problem of finding the roots of a quadratic polynomial; that is, the values of t for which at^2+bt+c=0. Here the data are the coefficients a, b, and c that define the polynomial, and the solution to the problem are the two (maybe complex-valued) roots r_1 and r_2. Formally, we might write f([a,b,c])=[r_1,r_2] using vector notation.\n\nLet’s pick one root r_1 and consider what happens to it as we vary just the leading coefficient a. This suggests a scalar function f(a)=r_1. Starting from ar_1^2 + br_1 + c = 0, we differentiate implicitly with respect to a while holding b and c fixed:r_1^2 + 2a r_1 \\left(\\frac{dr_1}{da}\\right) + b \\,\\frac{dr_1}{da} = 0.\n\nSolving for the derivative, we obtain\\frac{dr_1}{da} = \\frac{-r_1^2}{2a r_1 + b}.\n\nHence the condition number for the problem f(a)=r_1 is\\kappa_f(a)  = \\left|\\frac{a}{r_1} \\cdot \\frac{dr_1}{da} \\right| = \\left| \\frac{a r_1}{ 2a r_1 + b} \\right|\n= \\left| \\frac{r_1}{ r_1-r_2} \\right|,\n\nwhere in the last step we used the quadratic formula:|2ar_1 + b | = \\left| \\sqrt{b^2-4ac} \\, \\right| = |a(r_1 - r_2)|.\n\nBased on \n\n(1.2.13), we can expect poor conditioning in the rootfinding problem if and only if |r_1| \\gg |r_1-r_2|. Similar conclusions apply for r_2 and for variations with respect to the coefficients b and c.\n\nThe calculation in \n\nExample 1.2.4 generalizes to polynomials of higher degree.\n\nRoots of polynomials are ill-conditioned with respect to changes in the polynomial coefficients when they are much closer to each other than to the origin.\n\nThe condition number of a root can be arbitrarily large. In the extreme case of a repeated root, the condition number is formally infinite, which implies that the ratio of changes in the root to changes in the coefficients cannot be bounded.\n\nConditioning of polynomial roots\n\nExample 1.2.5\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nTip\n\nThe statement x,y = 10,20 makes individual assignments to both x and y.\n\nϵ = 1e-6   # type \\epsilon and then press Tab\na,b,c = 1/3,(-2-ϵ)/3,(1+ϵ)/3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4a*c)\nr₁ = (-b - d) / (2a)   # type r\\_1 and then press Tab\nr₂ = (-b + d) / (2a)\n(r₁, r₂)\n\nThe relative errors in these values are\n\n@show abs(r₁ - 1) / abs(1);\n@show abs(r₂ - (1+ϵ)) / abs(1+ϵ);\n\nThe condition number of each root is\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}.\n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps() / ϵ\n\nThis matches the observation pretty well.\n\nExample 1.2.5\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nep = 1e-6;\na = 1/3;             % coefficients of p...\nb = (-2 - ep) / 3;   % ...\nc = (1 + ep) / 3;    % ...in ascending order\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4*a*c);\nformat long   % show all digits\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative errors are\n\nTip\n\nPutting values inside square brackets creates a vector.\n\nformat short e\nerr = abs(r1 - 1) ./ abs(1)\nerr = abs(r2 - (1 + ep)) ./ abs(1 + ep)\n\nThe condition number of each root is\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}.\n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps / ep\n\nThis matches the observation pretty well.\n\nExample 1.2.5\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nTip\n\nThe statement x, y = 10, 20 makes individual assignments to both x and y.\n\nep = 1e-6   \na, b, c = 1/3, (-2 - ep) / 3, (1 + ep) / 3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b**2 - 4*a*c)\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\nprint(r1, r2)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative error in the value is\n\nprint(abs(r1 - 1) / abs(1))\nprint(abs(r2 - (1 + ep)) / abs(1 + ep))\n\nThe condition number of each root is\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}.\n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\nprint(finfo(float).eps / ep)\n\nThis matches the observation pretty well.","type":"content","url":"/conditioning#polynomial-roots","position":7},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Exercises"},"type":"lvl2","url":"/conditioning#exercises","position":8},{"hierarchy":{"lvl1":"Problems and conditioning","lvl2":"Exercises"},"content":"✍ Use \n\n(1.2.6) to derive the relative condition numbers of the following functions appearing in \n\nTable 1.2.1.\n\n(a) f(x) = x^p,\\quad\n(b) f(x) = \\log(x),\\quad\n(c) f(x) = \\cos(x),\\quad\n(d) f(x) = e^x.\n\n✍ Use the chain rule \n\n(1.2.9) to find the relative condition number of the given function. Then check your result by applying \n\n(1.2.6) directly.\n\n(a) f(x) = \\sqrt{x+5},\\quad\n(b) f(x) = \\cos(2\\pi x),\\quad\n(c) f(x) = e^{-x^2}.\n\n✍ Calculate the relative condition number of each function, and identify all values of x at which \\kappa_{f}(x)\\to\\infty (including limits as x\\to\\pm\\infty).\n\n(a) f(x) = \\tanh(x),\\quad\n(b) f(x) = \\dfrac{e^x-1}{x},\\quad\n(c) f(x) = \\dfrac{1-\\cos(x)}{x}.\n\n✍ Suppose that f and g are real-valued functions that have relative condition numbers \\kappa_f and \\kappa_g, respectively. Define a new function h(x)=f\\bigl(g(x)\\bigr). Show that for x in the domain of h, the relative condition number of h satisfies \n\n(1.2.9).\n\n✍ Suppose that f is a function with relative condition number \\kappa_f, and that f^{-1} is its inverse function. Show that the relative condition number of f^{-1} satisfies\\kappa_{f^{-1}}(x) = \\frac{1}{\\kappa_f\\Bigl( f^{-1}(x) \\Bigr)},\n\nprovided the denominator is nonzero.\n\n✍  Referring to the derivation of \n\n(1.2.13), derive an expression for the relative condition number of a root of ax^2+bx+c=0 due to perturbations in b only.\n\nThe polynomial x^2-2x+1 has a double root at 1. Let r_1(\\epsilon) and r_2(\\epsilon) be the roots of the perturbed polynomial x^2-(2+\\epsilon)x+1.\n\n(a) ✍/⌨ Using a computer or calculator, make a table with rows for \\epsilon = 10^{-2}, \n\n10-4, \n\n10-6, \\ldots, \n\n10-12 and columns for ε, r_1(\\epsilon), r_2(\\epsilon), |r_1(\\epsilon)-1|, and |r_2(\\epsilon)-1|.\n\n(b) ✍ Show that the observations of part (a) satisfy\\max\\{\\, |r_1(\\epsilon)-1|, |r_2(\\epsilon)-1| \\,\\} \\approx C \\epsilon^q\n\nfor some 0<q<1. (This supports the conclusion that \\kappa=\\infty at the double root.)\n\n✍ Generalize \n\n(1.2.13) to finding a root of the nth degree polynomial p(x) = a_nx^n + \\cdots + a_1 x + a_0, and show that the relative condition number of a root r with respect to perturbations only in a_k is\\kappa_r(a_k) = \\left| \\frac{a_k r^{k-1}}{p'(r)} \\right|.","type":"content","url":"/conditioning#exercises","position":9},{"hierarchy":{"lvl1":"Floating-point numbers"},"type":"lvl1","url":"/floating-point","position":0},{"hierarchy":{"lvl1":"Floating-point numbers"},"content":"The real number set \\real is infinite in two ways: it is unbounded and continuous. In most practical computing, the latter kind of infiniteness is much more consequential than the former, so we turn our attention there first.\n\nFloating-point numbers\n\nThe set \\float of floating-point numbers consists of zero and all numbers of the form  \\pm (1 + f) \\times 2^n,\n\nwhere n is an integer called the exponent, and 1+f is the significand, in which  f = \\sum_{i=1}^d b_i \\, 2^{-i}, \\qquad b_i\\in\\{0,1\\},\n\nfor a fixed integer d called the binary precision.\n\nEquation \n\n(1.1.2) represents the significand as a number in [1,2) in base-2 form. Equivalently,f = 2^{-d}\\, \\sum_{i=1}^{d} b_{i} \\, 2^{d-i} = 2^{-d} z\n\nfor an integer z in the set \\{0,1,\\ldots,2^d-1\\}. Consequently, starting at 2^n and ending just before 2^{n+1} there are exactly 2^d evenly spaced numbers belonging to \\float.\n\nSuppose d=2. Taking n=0 in \n\n(1.1.1), we enumerate1 + \\frac{0}{4}, \\: 1 + \\frac{1}{4}, \\: 1 + \\frac{2}{4}, \\: 1 + \\frac{3}{4}.\n\nThese are the only members of \\float in the semi-closed interval [1,2), and they are separated by spacing \\tfrac{1}{4}.\n\nTaking n=1 doubles each of the values in the list above, and n=-1 halves them. These give the floating-point numbers in [2,4) and [1/2,1), respectively. The spacing between them also is doubled and halved, respectively.\n\nObserve that the smallest element of \\float that is greater than 1 is 1+2^{-d}, and we call the difference machine epsilon.\n\nMachine epsilon\n\nFor a floating-point set with d binary digits of precision, machine epsilon (or machine precision) is \\macheps = 2^{-d}.\n\nWe define the rounding function \\fl(x) as the map from real number x to the nearest member of \\float. The distance between the floating-point numbers in [2^n,2^{n+1}) is 2^n\\macheps=2^{n-d}. As a result, every real x \\in [2^n,2^{n+1}) is no farther than 2^{n-d-1} away from a member of \\float. Therefore we conclude that |\\fl(x)-x| \\le \\tfrac{1}{2}(2^{n-d}), which leads to the bound\\frac{|\\fl(x)-x|}{|x|} \\le \\frac{2^{n-d-1}}{2^n} \\le  \\tfrac{1}{2}\\macheps.\n\nIn words, every real number is represented with a uniformly bounded relative precision. Inequality \n\n(1.1.5) holds true for negative x as well. In \n\nExercise 2 you are asked to show that an equivalent statement is that  \\fl(x)=x(1+\\epsilon) \\quad \\text{for some $|\\epsilon|\\le \\tfrac{1}{2}\\macheps$.}\n\nThe value of ε depends on x, but this dependence is not usually shown explicitly.","type":"content","url":"/floating-point","position":1},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Precision and accuracy"},"type":"lvl2","url":"/floating-point#precision-and-accuracy","position":2},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Precision and accuracy"},"content":"It may help to recast \n\n(1.1.1) and \n\n(1.1.2) in terms of base 10:\\pm \\left(b_0 + \\sum_{i=1}^d b_i \\, 10^{-i} \\right) \\times 10^n = \\pm (b_0.b_1b_2\\cdots b_d) \\times 10^n,\n\nwhere each b_i is in \\{0,1,\\ldots,9\\} and b_0\\neq 0. This is simply scientific notation with d+1 significant digits. For example, Planck’s constant is 6.626068\\times 10^{-34} m{}^2\\cdotkg/sec to seven digits. If we alter just the last digit from 8 to 9, the relative change is\\frac{0.000001\\times 10^{-34}}{6.626068\\times 10^{-34}} \\approx 1.51\\times 10^{-7}.\n\nWe therefore say that the constant is given with 7 decimal digits of precision. That’s in contrast to noting that the value is given to 40 decimal places. A major advantage of floating point is that the relative precision does not depend on the choice of physical units. For instance, when expressed in eV•sec, Planck’s constant is 4.135668\\times 10^{-15}, which still has 7 digits but only 21 decimal places.\n\nFloating-point precision functions the same way, except that computers prefer base 2 to base 10. The precision of a floating-point number is always d binary digits, implying a resolution of the real numbers according to \n\n(1.1.5).\n\nIt can be easy to confuse precision with accuracy, especially when looking at the result of a calculation on the computer. Every result is computed and represented using d binary digits, but not all of those digits may accurately represent an intended value. Suppose x is a number of interest and \\tilde{x} is an approximation to it. The absolute accuracy of \\tilde{x} is|\\tilde{x} - x|,\n\nwhile the relative accuracy is\\frac{|\\tilde{x} - x|}{|x|}.\n\nAbsolute accuracy has the same units as x, while relative accuracy is dimensionless. We can also express the relative accuracy as the number of accurate digits, computed in base 10 as-\\log_{10} \\left| \\frac{\\tilde{x}-x}{x} \\right|.\n\nWe often round this value down to an integer, but it does make sense to speak of “almost seven digits” or “ten and a half digits.”\n\nAbsolute and relative accuracy\n\nExample 1.1.2\n\nGetting started in Julia\n\nSee \n\nSetting up Julia for this book for instructions on how to install and use Julia for this book.\n\nRecall the grade-school approximation to the number π.\n\n@show p = 22/7;\n\nNot all the digits displayed for p are the same as those of π.\n\nTip\n\nThe value of pi is predefined and equivalent to π, which is entered by typing \\pi followed immediately by the Tab key.\n\n@show float(π);\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nTip\n\nA dollar sign $ in a string substitutes (or interpolates) the named variable or expression into the string.\n\nacc = abs(p-π)\nprintln(\"absolute accuracy = $acc\")\nprintln(\"relative accuracy = $(acc/π)\")\n\nHere we calculate the number of accurate digits in p.\n\nTip\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprintln(\"Number of accurate digits = $(-log10(acc/π))\")\n\nThis last value could be rounded down by using floor.\n\nExample 1.1.2\n\nGetting started in MATLAB\n\nSee \n\nSetting up MATLAB for this book for instructions on how to install functions for MATLAB for this book.\n\nRecall the grade-school approximation to the number π.\n\nTip\n\nThe number of digits displayed is controlled by format, but the underlying values are not affected by it.\n\nformat long\np = 22/7\n\nNot all the digits displayed for p are the same as those of π.\n\nTip\n\nThe value of pi is predefined.\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nabs_accuracy = abs(p - pi)\nrel_accuracy = abs(p - pi) / pi\n\nHere we calculate the number of accurate digits in p.\n\nTip\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nformat short\naccurate_digits = -log10(rel_accuracy)\n\nExample 1.1.2\n\nGetting started with Python\n\nSee \n\nSetting up Python for this book for guidance on how to set up Python for the demos in this book.\n\nRecall the grade-school approximation to the number π.\n\np = 22/7\nprint(p)\n\nNot all the digits displayed for p are the same as those of π.\n\nTip\n\nThe value of pi is predefined in the numpy package.\n\nprint(pi)\n\nThe absolute and relative accuracies of the approximation are as follows:\n\nTip\n\nWe often use \n\nPython f-strings to format numerical output.\n\nprint(f\"absolute accuracy: {abs(p - pi)}\")\n\nrel_acc = abs(p - pi) / pi\nprint(\"relative accuracy: {rel_acc:.4e}\")\n\nHere we calculate the number of accurate digits in p:\n\nTip\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprint(f\"accurate digits: {-log10(rel_acc):.1f}\")","type":"content","url":"/floating-point#precision-and-accuracy","position":3},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Double precision"},"type":"lvl2","url":"/floating-point#double-precision","position":4},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Double precision"},"content":"Most numerical computing today is done in the IEEE 754 standard. This defines single precision with d=23 binary digits for the fractional part f, and the more commonly used double precision with d=52. In double precision,\\macheps = 2^{-52} \\approx 2.2\\times 10^{-16}.\n\nWe often speak of double-precision floating-point numbers as having about 16 decimal digits. The 52-bit significand is paired with a sign bit and 11 binary bits to represent the exponent n in \n\n(1.1.1), for a total of 64 binary bits per floating-point number.\n\nFloating-point representation\n\nExample 1.1.3\n\nIn Julia, 1 and 1.0 are different values, because they have different types:\n\n@show typeof(1);\n@show typeof(1.0);\n\nThe standard choice for floating-point values is Float64, which is double precision using 64 binary bits. We can see all the bits by using bitstring.\n\nbitstring(1.0)\n\nThe first bit determines the sign of the number:\n\nTip\n\nSquare brackets concatenate the contained values into vectors.\n\n[bitstring(1.0), bitstring(-1.0)]\n\nThe next 11 bits determine the exponent (scaling) of the number, and so on.\n\n[bitstring(1.0), bitstring(2.0)]\n\nThe sign bit, exponent, and significand in \n\n(1.1.1) are all directly accessible.\n\nx = 3.14\n@show sign(x), exponent(x), significand(x);\n\nx = x / 8\n@show sign(x), exponent(x), significand(x);\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. You can get its value from the eps function in Julia. By default, it returns the value for double precision.\n\nTip\n\nTo call a function, including eps, you must use parentheses notation, even when there are no input arguments.\n\neps()\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps())\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nnextfloat(161.8)\n\nans - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\n@show floatmin(), floatmax();\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2^(-4)\n\nThere are some exceptions. A floating-point value can’t be used as an index into an array, for example, even if it is numerically equal to an integer. In such cases you use Int to convert it.\n\n@show 5.0, Int(5.0);\n\nIf you try to convert a noninteger floating-point value into an integer you get an InexactValue error. This occurs whenever you try to force a type conversion that doesn’t make clear sense.\n\nExample 1.1.3\n\nIn MATLAB, values are double-precision floats unless declared otherwise.\n\nfprintf('1 has type: %s', class(1))\nfprintf('1.0 has type: %s', class(1.0))\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. Its value is predefined as eps.\n\nTip\n\nWhile you can assign a different value to eps, doing so does not change any arithmetic. It’s generally a bad idea.\n\neps\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps)\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nx = 161.8 + 0.1*eps(161.8);\nx - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\nformat short e\n[realmin, realmax]\n\nExample 1.1.3\n\nPython has native int and float types.\n\nprint(f\"The type of {1} is {type(1)}\")\nprint(f\"The type of {float(1)} is {type(1.0)}\")\n\nThe numpy package has its own float types:\n\none = float64(1)\nprint(f\"The type of {one} is {type(one)}\")\n\nBoth float and float64 are double precision, using 64 binary bits per value. Although it is not normally necessary to do so, we can deconstruct a float into its significand and exponent:\n\nx = 3.14\nmantissa, exponent = frexp(x)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nmantissa, exponent = frexp(x / 8)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon, given here for double precision:\n\nmach_eps = finfo(float).eps\nprint(f\"machine epsilon is {mach_eps:.4e}\")\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nprint(f\"machine epsilon is 2 to the power {log2(mach_eps)}\")\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the significand. The actual range of positive values in double precision is\n\nfinf = finfo(float)\nprint(f\"range of positive values: [{finf.tiny}, {finf.max}]\")\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2**(-4)\n\nYou can convert a floating value to an integer by wrapping it in int.\n\nint(3.14)\n\nOur theoretical description of \\float did not place limits on the exponent, but in double precision its range is limited to -1022\\le n \\le 1023. Thus, the largest number is just short of 2^{1024}\\approx 2\\times 10^{308}, which is enough in most applications. Results that should be larger are said to overflow and will actually result in the value Inf. Similarly, the smallest positive number is 2^{-1022}\\approx 2\\times 10^{-308}, and smaller values are said to underflow to zero.\n\nNote the crucial difference between \\macheps=2^{-52}, which is the distance between 1 and the next larger double-precision number, and \n\n2-1022, which is the smallest positive double-precision number. The former has to do with relative precision, while the latter is about absolute precision. Getting close to zero always requires a shift in thinking to absolute precision because any finite error is infinite relative to zero.\n\nOne more double-precision value is worthy of note: NaN, which stands for Not a Number. It is the result of an undefined arithmetic operation such as 0/0.","type":"content","url":"/floating-point#double-precision","position":5},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Floating-point arithmetic"},"type":"lvl2","url":"/floating-point#floating-point-arithmetic","position":6},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Floating-point arithmetic"},"content":"Computer arithmetic is performed on floating-point numbers and returns floating-point results. We assume the existence of machine-analog operations for real functions such as +, -, ×, /, \\sqrt{\\quad}, and so on. Without getting into the details, we will suppose that each elementary machine operation creates a floating-point result whose relative error is bounded by \\macheps. For example, if x and y are in \\float, then for machine addition \\oplus we have the bound\\frac{ |(x \\oplus y)-(x+y)| }{ |x+y| } \\le \\macheps.\n\nHence the relative error in arithmetic is essentially the same as for the floating-point representation itself. However, playing by these rules can lead to disturbing results.\n\nFloating-point arithmetic oddity\n\nExample 1.1.4\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\ne = eps()/2\n(1.0 + e) - 1.0\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1.0 + (e - 1.0)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!\n\nExample 1.1.4\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\n( 1 + eps / 2 ) - 1\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1 - (1 - eps / 2)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!\n\nExample 1.1.4\n\nThere is no double precision number between 1 and 1+\\varepsilon_\\text{mach}. Thus, the following difference is zero despite its appearance.\n\neps = finfo(float).eps\ne = eps/2\nprint((1.0 + e) - 1.0)\n\nHowever, 1-\\varepsilon_\\text{mach}/2 is a double precision number, so it and its negative are represented exactly:\n\nprint(1.0 + (e - 1.0))\n\nThis is now the “correct” result. But we have found a rather shocking breakdown of the associative law of addition!\n\nThere are two ways to look at \n\nDemo 1.1.4. On one hand, its two versions of the result differ by less than 1.2\\times 10^{-16}, which is very small — not just in everyday terms, but with respect to the operands, which are all close to 1 in absolute value. On the other hand, the difference is as large as the exact result itself! We formalize and generalize this observation in the next section. In the meantime, keep in mind that exactness cannot be taken for granted in floating-point computation.\n\nWe should not expect that two mathematically equivalent results will be equal when computed in floating point, only that they be relatively close together.","type":"content","url":"/floating-point#floating-point-arithmetic","position":7},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Exercises"},"type":"lvl2","url":"/floating-point#exercises","position":8},{"hierarchy":{"lvl1":"Floating-point numbers","lvl2":"Exercises"},"content":"Note\n\nExercises marked with ✍ are intended to be done by hand or with the aid of a simple calculator. Exercises marked with ⌨ are intended to be solved using a computer.\n\n✍ Consider a floating-point set \\float defined by \n\n(1.1.1) and \n\n(1.1.2) with d=4.\n\n(a) How many elements of \\float are there in the real interval [1/2,4], including the endpoints?\n\n(b) What is the element of \\float closest to the real number 1/10? (Hint: Find the interval [2^n,2^{n+1}) that contains 1/10, then enumerate all the candidates in \\float.)\n\n(c) What is the smallest positive integer not in \\float? (Hint: For what value of the exponent does the spacing between floating-point numbers become larger than 1?)\n\n✍ Prove that \n\n(1.1.5) is equivalent to \n\n(1.1.6). This means showing first that \n\n(1.1.5) implies \n\n(1.1.6), and then separately that \n\n(1.1.6) implies \n\n(1.1.5).\n\n⌨ There are much better rational approximations to π than 22/7 as used in \n\nDemo 1.1.2. For each one below, find its absolute and relative accuracy, and (rounding down to an integer) the number of accurate digits.\n\n(a) 355/113\n\n(b) 103638/32989\n\n✍ IEEE 754 single precision specifies that 23 binary bits are used for the value f in the significand 1+f in \n\n(1.1.2). Because they need less storage space and can be operated on more quickly than double-precision values, single-precision values can be useful in low-precision applications. (They are supported as type Float32 in Julia.)\n\n(a) In base-10 terms, what is the first single-precision number greater than 1 in this system?\n\n(b) What is the smallest positive integer that is not a single-precision number? (See the hint to Exercise 1.)\n\n⌨ Julia defines a function nextfloat that gives the next-larger floating-point value of a given number. What is the next float past floatmax()? What is the next float past -Inf?\n\nThe terms machine epsilon, machine precision, and unit roundoff aren’t used consistently across references, but the differences are not consequential for our purposes.\n\nActually, there are some still-smaller denormalized numbers that have less precision, but we won’t use that level of detail.","type":"content","url":"/floating-point#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"An accessible but more advanced discussion of machine arithmetic and roundoff error can be found in Higham \n\nHigham (2002).\n\nInteresting and more advanced discussion of the numerical difficulties of finding the roots of polynomials can be found in the article by Wilkinson, “The Perfidious Polynomial” \n\nWilkinson (1984) and in the ripostes from Cohen, “Is the Polynomial so Perfidious?” \n\nCohen (1994) and from Trefethen,  “Six myths of polynomial interpolation and quadrature,” (Myth 6) \n\nTrefethen (2013).","type":"content","url":"/next","position":1},{"hierarchy":{"lvl1":"1. Introduction"},"type":"lvl1","url":"/overview","position":0},{"hierarchy":{"lvl1":"1. Introduction"},"content":"You must unlearn what you have learned.\n\nYoda, The Empire Strikes Back\n\nOur first step is to discretize the real numbers—specifically, to replace them with a finite surrogate set of numbers. This step keeps the time and storage requirements for operating with each number at constant levels, but virtually every data set and arithmetic operation is perturbed slightly away from its idealized mathematical value. We can easily keep the individual roundoff errors very small, so small that simple random accumulation is unlikely to bother us. However, some problems are extremely sensitive to these perturbations, a trait we quantify using a condition number. Problems with large condition numbers are difficult to solve accurately using finite precision. Furthermore, even when the condition number of a problem is not large, some algorithms for solving it allow errors to grow enormously. We call these algorithms unstable. In this chapter we discuss these ideas in simple settings before moving on to the more realistic problems in the rest of the book.\n\nSoftware\n\nInstructions for obtaining Julia and the codes used throughout the text can be found at\n\nhttps://​github​.com​/fncbook​/FundamentalsNumericalComputation​.jl\n\nThe installation process, which can take 5-10 minutes, only needs to be performed once.","type":"content","url":"/overview","position":1},{"hierarchy":{"lvl1":"Stability"},"type":"lvl1","url":"/stability","position":0},{"hierarchy":{"lvl1":"Stability"},"content":"If we solve a problem using a computer algorithm and see a large error in the result, we might suspect poor conditioning in the original mathematical problem. But algorithms can also be sources of errors. When error in the result of an algorithm exceeds what conditioning can explain, we call the algorithm unstable.","type":"content","url":"/stability","position":1},{"hierarchy":{"lvl1":"Stability","lvl2":"Case study"},"type":"lvl2","url":"/stability#case-study","position":2},{"hierarchy":{"lvl1":"Stability","lvl2":"Case study"},"content":"In \n\nExample 1.2.4 we showed that finding the roots of a quadratic polynomial ax^2 + b x+c is poorly conditioned if and only if the roots are close to each other relative to their size. Hence, for the polynomialp(x) = (x-10^6)(x-10^{-6}) = x^2 - (10^6+10^{-6})x + 1,\n\nfinding roots is a well-conditioned problem. An obvious algorithm for finding those roots is to directly apply the familiar quadratic formula,x_1 = \\frac{-b + \\sqrt{b^2-4ac}}{2a}, \\qquad\nx_2 = \\frac{-b - \\sqrt{b^2-4ac}}{2a}.\n\nInstability of the quadratic formula\n\nExample 1.4.1\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nTip\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n@show x₂ = (-b - sqrt(b^2 - 4a*c)) / 2a;\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6 - x₂) / 1e-6 \n@show accurate_digits = -log10(error);\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nExample 1.4.1\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nTip\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23 * 10^4.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a)\nx2 = (-b - sqrt(b^2 - 4*a*c)) / (2*a)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(x2 - 1e-6) / 1e-6 \naccurate_digits = -log10(error)\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nExample 1.4.1\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nTip\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\nx2 = (-b - sqrt(b**2 - 4*a*c)) / 2*a\nprint(x1, x2)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6 - x2) / 1e-6 \nprint(f\"There are {-log10(error):.2f} accurate digits.\")\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nDemo 1.4.1 suggests that the venerable quadratic formula is an unstable means of computing roots in finite precision. The roots themselves were not sensitive to the data or arithmetic—it’s the specific computational path we chose that caused the huge growth in errors.\n\nWe can confirm this conclusion by finding a different path that avoids subtractive cancellation. A little algebra using \n\n(1.4.2) confirms the additional formula x_1x_2=c/a.  So given one root r, we compute the other root using c/ar, which has only multiplication and division and therefore creates no numerical trouble.\n\nStable alternative to the quadratic formula\n\nExample 1.4.2\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\n@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\n@show x₂ = c / (a * x₁);\n\nAs you see in this output, Julia often suppresses trailing zeros in a decimal expansion. To be sure we have an accurate result, we compute its relative error.\n\nabs(x₂ - 1e-6) / 1e-6\n\nExample 1.4.2\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a);\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a*x1)\n\nThis matches the exact root to the displayed digits; to be sure we have an accurate result, we compute its relative error.\n\nabs(x2 - 1e-6) / 1e-6\n\nExample 1.4.2\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a * x1)\nprint(x1, x2)\n\nTo be sure we have an accurate result, we compute its relative error.\n\nprint(abs(x2 - 1e-6) / 1e-6)\n\nThe algorithms in \n\nDemo 1.4.1 and \n\nDemo 1.4.2 are equivalent when using real numbers and exact arithmetic. When results are perturbed by machine representation at each step, though, the effects may depend dramatically on the specific sequence of operations, thanks to the chain rule \n\n(1.2.9).\n\nThe sensitivity of a problem f(x) is governed only by \\kappa_f, but the sensitivity of an algorithm depends on the condition numbers of all of its individual steps.\n\nThis situation may seem hopelessly complicated. But the elementary operations we take for granted, such as those in \n\nTable 1.2.1, are well-conditioned in most circumstances. Exceptions usually occur when |f(x)| is much smaller than |x|, although not every such case signifies trouble. The most common culprit is simple subtractive cancellation.\n\nA practical characterization of instability is that results are much less accurate than the conditioning of the problem can explain. Typically one should apply an algorithm to test problems whose answers are well-known, or for which other programs are known to work well, in order to spot possible instabilities. In the rest of this book we will see some specific ways in which instability is manifested for different types of problems.","type":"content","url":"/stability#case-study","position":3},{"hierarchy":{"lvl1":"Stability","lvl2":"Backward error"},"type":"lvl2","url":"/stability#backward-error","position":4},{"hierarchy":{"lvl1":"Stability","lvl2":"Backward error"},"content":"In the presence of poor conditioning for a problem f(x), even just the act of rounding the data to floating point may introduce a large change in the result. It’s not realistic, then, to expect any algorithm \\tilde{f} to have a small error in the sense \\tilde{f}(x)\\approx f(x). There is another way to characterize the error, though, that can be a useful alternative measurement. Instead of asking, “Did you get nearly the right answer?”, we ask, “Did you answer nearly the right question?”\n\nBackward error\n\nLet \\tilde{f} be an algorithm for the problem f. Let y=f(x) be an exact result and \\tilde{y}=\\tilde{f}(x) be its approximation by the algorithm. If there is a value \\tilde{x} such that f(\\tilde{x}) = \\tilde{y}, then the relative backward error in \\tilde{y} is\\frac{ |\\tilde{x}-x| } { |x| }.\n\nThe absolute backward error is |\\tilde{x}-x|.\n\nBackward error measures the change to the original data that reproduces the result that was found by the algorithm. The situation is illustrated in \n\nFigure 1.4.1.\n\n\n\nFigure 1.4.1:Backward error is the difference between the original data and the data that exactly produces the computed value.\n\nBackward error\n\nExample 1.4.3\n\nFor this example we will use the Polynomials package, which is installed by the FNC package.\n\nTip\n\nIn the rest of the book, we do not show the using statement needed to load the book’s package, but you will need to enter it if you want to run the codes yourself.\n\nOur first step is to construct a polynomial with six known roots.\n\nusing Polynomials\nr = [-2.0, -1, 1, 1, 3, 6]\np = fromroots(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr̃ = sort(roots(p))   # type r\\tilde and then press Tab\n\nHere are the relative errors in each of the computed roots.\n\nTip\n\nThe @. notation at the start means to do the given operations on each element of the given vectors.\n\nprintln(\"Root errors:\") \n@. abs(r - r̃) / r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply fromroots to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np̃ = fromroots(r̃)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nc,c̃ = coeffs(p), coeffs(p̃)\nprintln(\"Coefficient errors:\") \n@. abs(c - c̃) / c\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.\n\nExample 1.4.3\n\nOur first step is to construct a polynomial with six known roots.\n\nTip\n\nThe ' operator is used for transposition. Here, we want to make r a column vector.\n\nr = [-2 ,-1, 1, 1, 3, 6]';\np = poly(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nrr = sort(roots(p))\n\nHere are the relative errors in each of the computed roots.\n\nTip\n\nThe ./ operator is used for element-wise division.\n\ndisp(\"Root errors:\") \nabs(r - rr) ./ r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\npp = poly(rr)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\ndisp(\"Coefficient errors:\") \nabs(p - pp) ./ abs(p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.\n\nExample 1.4.3\n\nOur first step is to construct a polynomial with six known roots.\n\nr = [-2, -1, 1, 1, 3, 6]\np = poly(r)\nprint(p)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr_computed = sort(roots(p))\nprint(r_computed)\n\nHere are the relative errors in each of the computed roots.\n\nprint(abs(r - r_computed) / r)\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np_computed = poly(r_computed)\nprint(p_computed)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nprint(abs(p - p_computed) / p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.\n\nSmall backward error is the best we can hope for in a poorly conditioned problem. Without getting into the formal details, know that if an algorithm always produces small backward errors, then it is stable. But the converse is not always true: some stable algorithms may produce a large backward error.\n\nOne stable algorithm that is not backward stable is floating-point evaluation for our old friend, f(x)=x+1. If |x|<\\epsilon_\\text{mach}/2, then the computed result is \\tilde{f}(x)=1, since there are no floating-point numbers between 1 and 1+\\epsilon_\\text{mach}. Hence the only possible choice for a real number \\tilde{x} satisfying \n\n(1.4.3) is \\tilde{x}=0. But then |\\tilde{x}-x|/|x|=1, which indicates 100% backward error!","type":"content","url":"/stability#backward-error","position":5},{"hierarchy":{"lvl1":"Stability","lvl2":"Exercises"},"type":"lvl2","url":"/stability#exercises","position":6},{"hierarchy":{"lvl1":"Stability","lvl2":"Exercises"},"content":"The formulasf(x)=\\frac{1-\\cos(x)}{\\sin(x)}, \\quad g(x) = \\frac{2\\sin^2(x/2)}{\\sin(x)},\n\nare mathematically equivalent, but they suggest evaluation algorithms that can behave quite differently in floating point.\n\n(a) ✍ Using \n\n(1.2.6), find the relative condition number of f. (Because f and g are equivalent, the condition number of g is the same.) Show that it approaches 1 as x\\to 0. (Hence it should be possible to compute the function accurately near zero.)\n\n(b) ⌨ Compute f(10^{-6}) using a sequence of four elementary operations. Using \n\nTable 1.2.1, make a table like the one in \n\nDemo 1.4.1 that shows the result of each elementary result and the numerical value of the condition number of that step.\n\n(c) ⌨ Repeat part (b) for g(10^{-6}), which has six elementary steps.\n\n(d) ✍ Based on parts (b) and (c), is the numerical value of f(10^{-6}) more accurate, or is g(10^{-6}) more accurate?\n\nLet f(x) = \\frac{e^x-1}{x}.\n\n(a) ✍ Find the condition number \\kappa_f(x). What is the maximum of \\kappa_f(x) over -1\\le x \\le 1?\n\n(b) ⌨  Use the “obvious” algorithm(exp(x) - 1) / x\n\nto compute f(x) at x=10^{-2},10^{-3},10^{-4},\\ldots,10^{-11}.\n\n(c) ⌨ Create a second algorithm from the first 8 terms of the Maclaurin series, i.e.,p(x) = 1 + \\frac{1}{2!}x + \\frac{1}{3!}x^2 + \\cdots + \\frac{1}{8!}x^8.\n\nEvaluate it at the same values of x as in part (b).\n\n(d) ⌨  Make a table of the relative difference between the two algorithms as a function of x. Which algorithm is more accurate, and why?\n\n⌨ The functionx = \\cosh(y) = \\frac{e^y + e^{-y}}{2}\n\ncan be inverted to yield a formula for \\operatorname{acosh}(x):\\operatorname{acosh}(x) = y = \\log\\bigl(x-\\sqrt{x^2-1}\\bigr).\n\nFor the steps below, define y_i=-4i and x_i=\\cosh(y_i) for i=1,\\dots,4. Hence y_i=\\operatorname{acosh}(x_i).\n\n(a) Find the relative condition number of evaluating f(x) = \\operatorname{acosh}(x). (You can use \n\n(1.4.7) or look up a formula for f' in a calculus book.)  Evaluate \\kappa_f at all the x_i. (You will find that the problem is well-conditioned at these inputs.)\n\n(b) Use \n\n(1.4.7) to approximate f(x_i) for all i. Compute the relative accuracy of the results. Why are some of the results so inaccurate?\n\n(c) An alternative formula isy = -2\\log\\left(\\sqrt{\\frac{x+1}{2}} + \\sqrt{\\frac{x-1}{2}}\\right).\n\nApply \n\n(1.4.8) to approximate f(x_i) for all i, again computing the relative accuracy of the results.\n\n⌨ (Continuation of \n\nExercise 1.3.2. Adapted from \n\nHigham (2002).) One drawback of the formula \n\n(1.3.3) for sample variance is that you must compute a sum for \\overline{x} before beginning another sum to find s^2. Some statistics textbooks quote a single-loop formula\\begin{split}\ns^2 &= \\frac{1}{n-1} \\left( u - \\tfrac{1}{n}v^2 \\right),\\\\\nu & = \\sum_{i=1}^n x_i^2, \\\\\nv &= \\sum_{i=1}^n x_i.\n\\end{split}\n\nTry this formula for these three datasets, each of which has a variance exactly equal to 1:x = [ 1e6, 1+1e6, 2+1e6 ]\nx = [ 1e7, 1+1e7, 2+1e7 ]\nx = [ 1e8, 1+1e8, 2+1e8 ]\n\nExplain the results.","type":"content","url":"/stability#exercises","position":7},{"hierarchy":{"lvl1":"Differentiation matrices"},"type":"lvl1","url":"/diffmats","position":0},{"hierarchy":{"lvl1":"Differentiation matrices"},"content":"In \n\nFinite differences we used finite differences to turn a discrete collection of function values into an estimate of the derivative of the function at a point. Just as with differentiation in elementary calculus, we can generalize differences at a point into an operation that maps discretized functions to discretized derivatives.","type":"content","url":"/diffmats","position":1},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Matrices for finite differences"},"type":"lvl2","url":"/diffmats#matrices-for-finite-differences","position":2},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Matrices for finite differences"},"content":"We first discretize the interval x\\in[a,b] into equal pieces of length h=(b-a)/n, leading to the nodesx_i=a+i h, \\qquad  i=0,\\ldots,n.\n\nNote again that our node indexing scheme starts at zero. Our goal is to find a vector \\mathbf{g} such that g_i \\approx f'(x_i) for i=0,\\ldots,n. Our first try is the forward difference formula \n\n(5.4.2),g_i = \\frac{f_{i+1}-f_i}{h}, \\qquad t=0,\\ldots,n-1.\n\nHowever, this leaves g_n undefined, because the formula would refer to the unavailable value f_{n+1}. For g_n we could resort to the backward differenceg_n = \\frac{f_{n}-f_{n-1}}{h}.\n\nWe can summarize the entire set of formulas by defining\\mathbf{f} = \n\\begin{bmatrix}\nf(x_0) \\\\[1mm] f(x_1) \\\\[1mm] \\vdots \\\\[1mm] f(x_{n-1}) \\\\[1mm] f(x_n)\n\\end{bmatrix}, \\quad\n\nand then the vector equation\\begin{bmatrix}\nf'(x_0) \\\\[1mm] f'(x_1) \\\\[1mm] \\vdots \\\\[1mm] f'(x_{n-1}) \\\\[1mm] f'(x_n)\n\\end{bmatrix}\n\\approx\n\\mathbf{D}_x \\mathbf{f}, \\qquad\n\\mathbf{D}_x\n= \\frac{1}{h}\n\\begin{bmatrix}\n-1 & 1 & & & \\\\[1mm]\n& -1 & 1 & & \\\\[1mm]\n& & \\ddots & \\ddots & \\\\[1mm]\n& & & -1 & 1 \\\\[1mm]\n& & & -1 & 1\n\\end{bmatrix}.\n\nHere as elsewhere, elements of \\mathbf{D}_x that are not shown are zero. We call \\mathbf{D}_x a differentiation matrix. Each row of \\mathbf{D}_x gives the weights of the finite-difference formula being used at one of the nodes.\n\nThe differentiation matrix \\mathbf{D}_x in \n\n(10.3.5) is not a unique choice. We are free to use whatever finite-difference formulas we like in each row. However, it makes sense to choose rows that are as similar as possible. Using second-order centered differences where possible and second-order one-sided formulas (see \n\nTable 5.4.2) at the boundary points leads to\\mathbf{D}_x = \\frac{1}{h}\n\\begin{bmatrix}\n-\\frac{3}{2} & 2    & -\\frac{1}{2}   &        &        &  \\\\[1mm]\n-\\frac{1}{2} & 0    & \\frac{1}{2}    &        &        &  \\\\[1mm]\n& -\\frac{1}{2} & 0      & \\frac{1}{2}    &        &  \\\\\n&      & \\ddots & \\ddots & \\ddots &  \\\\\n&      &        & -\\frac{1}{2}   & 0      & \\frac{1}{2} \\\\[1mm]\n&      &        & \\frac{1}{2}    & -2     & \\frac{3}{2}\n\\end{bmatrix}.\n\nThe differentiation matrices so far are banded matrices, i.e., all the nonzero values are along diagonals close to the main diagonal.","type":"content","url":"/diffmats#matrices-for-finite-differences","position":3},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Second derivative"},"type":"lvl2","url":"/diffmats#second-derivative","position":4},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Second derivative"},"content":"Similarly, we can define differentiation matrices for second derivatives. For example,\\begin{bmatrix}\nf''(x_0) \\\\[1mm] f''(x_1) \\\\[1mm] f''(x_2) \\\\[1mm] \\vdots \\\\[1mm] f''(x_{n-1}) \\\\[1mm] f''(x_n)\n\\end{bmatrix}\n\\approx\n\\frac{1}{h^2}\n\\begin{bmatrix}\n2 & -5 & 4      & -1     &        &     \\\\[1mm]\n1 & -2 & 1      &        &        &    \\\\[1mm]\n& 1  & -2     & 1      &        &    \\\\[1mm]\n&    & \\ddots & \\ddots & \\ddots &    \\\\[1mm]\n&        &        & 1      & -2 & 1 \\\\[1mm]\n&        &     -1  & 4      & -5 & 2\n\\end{bmatrix}\n\\begin{bmatrix}\nf(x_0) \\\\[1mm] f(x_1) \\\\[1mm] f(x_2) \\\\[1mm] \\vdots \\\\[1mm] f(x_{n-1}) \\\\[1mm] f(x_n)\n\\end{bmatrix} = \\mathbf{D}_{xx} \\mathbf{f}.\n\nWe have multiple choices again for \\mathbf{D}_{xx}, and it need not be the square of any particular \\mathbf{D}_x. As pointed out in \n\nFinite differences, squaring the first derivative is a valid approach but would place entries in \\mathbf{D}_{xx} farther from the diagonal than is necessary.\n\ndiffmat2\n\n\n\n\n\n\n\nTogether the matrices \n\n(10.3.6) and \n\n(10.3.7) give second-order approximations of the first and second derivatives at all nodes. These matrices, as well as the nodes x_0,\\ldots,x_n, are returned by \n\nFunction 10.3.1.\n\nDifferentiation matrices\n\nExample 10.3.1\n\nWe test first-order and second-order differentiation matrices for the function x + \\exp(\\sin 4x) over [-1,1].\n\nf = x -> x + exp(sin(4 * x));\n\nFor reference, here are the exact first and second derivatives.\n\ndf_dx = x -> 1 + 4 * exp(sin(4x)) * cos(4x);\nd2f_dx2 = x -> 4 * exp(sin(4x)) * (4 * cos(4x)^2 - 4 * sin(4x));\n\nWe discretize on equally spaced nodes and evaluate f at the nodes.\n\nt, Dₓ, Dₓₓ = FNC.diffmat2(18, [-1, 1])\ny = f.(t);\n\nThen the first two derivatives of f each require one matrix-vector multiplication.\n\nyₓ = Dₓ * y\nyₓₓ = Dₓₓ * y;\n\nThe results show poor accuracy for this small value of n.\n\nusing Plots\nplot(df_dx, -1, 1, layout = 2, xaxis = (L\"x\"), yaxis = (L\"f'(x)\"))\nscatter!(t, yₓ, subplot = 1)\nplot!(d2f_dx2, -1, 1, subplot = 2, xaxis = (L\"x\"), yaxis = (L\"f''(x)\"))\nscatter!(t, yₓₓ, subplot = 2)\n\nA convergence experiment confirms the order of accuracy. Because we expect an algebraic convergence rate, we use a log-log plot of the errors.\n\nn = @. round(Int, 2^(4:0.5:11))\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n    t, Dₓ, Dₓₓ = FNC.diffmat2(n, [-1, 1])\n    y = f.(t)\n    err[k, 1] = norm(df_dx.(t) - Dₓ * y, Inf)\n    err[k, 2] = norm(d2f_dx2.(t) - Dₓₓ * y, Inf)\nend\nplot(n, err, m = :o, label = [L\"f'\" L\"f''\"])\nplot!(n, 10 * 10 * n .^ (-2);\n    l = (:dash, :black),\n    label = \"2nd order\",\n    xaxis = (:log10, \"n\"),\n    yaxis = (:log10, \"max error\"),\n    title = \"Convergence of finite differences\")\n\nExample 10.3.1\n\nWe test first-order and second-order differentiation matrices for the function x + \\exp(\\sin 4x) over [-1,1].\n\nf = @(x) x + exp(sin(4*x));\n\nFor reference, here are the exact first and second derivatives.\n\ndf_dx = @(x) 1 + 4 * exp(sin(4*x)) .* cos(4*x);\nd2f_dx2 = @(x) 4 * exp(sin(4*x)) .* (4*cos(4*x).^2 - 4*sin(4*x));\n\nWe discretize on equally spaced nodes and evaluate f at the nodes.\n\n[t, Dx, Dxx] = diffmat2(12, [-1 1]);\ny = f(t);\n\nThen the first two derivatives of f each require one matrix-vector multiplication.\n\nyx = Dx * y;\nyxx = Dxx * y;\n\nThe results show poor accuracy for this small value of n.\n\nclf,  subplot(2, 1, 1)\nfplot(df_dx, [-1, 1]),  hold on\nplot(t, yx, 'ko')\nxlabel('x'),  ylabel('f''(x)')\nsubplot(2, 1, 2)\nfplot(d2f_dx2, [-1, 1]),  hold on\nplot(t, yxx, 'ko')\nxlabel('x'),  ylabel('f''''(x)')\n\nAn convergence experiment confirms the order of accuracy. Because we expect an algebraic convergence rate, we use a log-log plot of the errors.\n\nn = round( 2 .^ (4:.5:11)' );\nerr = zeros(length(n), 2);\nfor k = 1:length(n)\n    [t, Dx, Dxx] = diffmat2(n(k), [-1, 1]);\n    y = f(t);\n    err(k, 1) = norm(df_dx(t) - Dx * y, Inf);\n    err(k, 2) = norm(d2f_dx2(t) - Dxx * y, Inf);\nend\nclf\nloglog(n, err, 'o-'), hold on\nloglog(n, 100 * n.^(-2), 'k--')\nlegend(\"f'\", \"f''\", '2nd order')\nxlabel('n'),  ylabel('max error')\ntitle('Convergence of finite differences')\n\nExample 10.3.1\n\nWe test first-order and second-order differentiation matrices for the function x + \\exp(\\sin 4x) over [-1,1].\n\nf = lambda x: x + exp( sin(4 * x) )\n\nFor reference, here are the exact first and second derivatives.\n\ndf_dx = lambda x: 1 + 4 * exp(sin(4 * x)) * cos(4 * x)\nd2f_dx2 = lambda x: 4 * exp(sin(4 * x)) * (4 * cos(4 * x)**2 - 4 * sin(4 * x))\n\nWe discretize on equally spaced nodes and evaluate f at the nodes.\n\nt, Dx, Dxx = FNC.diffmat2(12, [-1, 1])\ny = f(t)\n\nThen the first two derivatives of f each require one matrix-vector multiplication.\n\nyx = Dx @ y\nyxx = Dxx @ y\n\nThe results show poor accuracy for this small value of n.\n\nx = linspace(-1, 1, 500)\nsubplot(2, 1, 1)\nplot(x, df_dx(x))\nplot(t, yx, \"ko\")\nxlabel(\"$x$\"),  ylabel(\"$f'(x)$\")\n\nsubplot(2, 1, 2)\nplot(x, d2f_dx2(x))\nplot(t, yxx, \"ko\")\nxlabel(\"$x$\"),  ylabel(\"$f''(x)$\");\n\nA convergence experiment confirms the order of accuracy. Because we expect an algebraic convergence rate, we use a log-log plot of the errors.\n\nN = array([int(2**k) for k in arange(4, 11.5, 0.5)])\nerr1 = zeros(len(N))\nerr2 = zeros(len(N))\nfor k, n in enumerate(N):\n    t, Dx, Dxx = FNC.diffmat2(n, [-1, 1])\n    y = f(t)\n    err1[k] = norm(df_dx(t) - Dx @ y, inf)\n    err2[k] = norm(d2f_dx2(t) - Dxx @ y, inf)\n\nloglog(N, err1, \"-o\", label=\"$f'$\")\nloglog(N, err2, \"-o\", label=\"$f''$\")\nplot(N, 10 * 10 / N**2, \"k--\", label=\"2nd order\")\nxlabel(\"$n$\"),  ylabel(\"max error\")\nlegend(loc=\"lower left\")\ntitle(\"Convergence of finite differences\");","type":"content","url":"/diffmats#second-derivative","position":5},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Spectral differentiation"},"type":"lvl2","url":"/diffmats#spectral-differentiation","position":6},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Spectral differentiation"},"content":"Recall that finite-difference formulas are derived in three steps:\n\nChoose a node index set S near node i.\n\nInterpolate with a polynomial using the nodes in S.\n\nDifferentiate the interpolant and evaluate at node i.\n\nWe can modify this process by using a global interpolant, either polynomial or trigonometric, as in \n\nChapter 9. Rather than choosing a different index set for each node, we use all of the nodes each time.\n\nIn a nonperiodic setting we use Chebyshev second-kind points for stability:x_k = -\\cos\\left(\\frac{k \\pi}{n}\\right), \\qquad k=0,\\ldots,n;\n\nthen the resulting Chebyshev differentiation matrix has entries  \\begin{gathered}\n    D_{00} = \\dfrac{2n^2+1}{6}, \\qquad D_{n n} = -\\dfrac{2n^2+1}{6}, \\\\\n    D_{ij} =\n    \\begin{cases}\n      -\\dfrac{x_i}{2(1-x_i^2)}, & i=j, \\\\[4mm]\n      \\dfrac{c_i}{c_j}\\, \\dfrac{(-1)^{i+j}}{x_i-x_j}, & i\\neq j,\n    \\end{cases}\n  \\end{gathered}\n\nwhere c_0=c_n=2 and c_i=1 for i=1,\\ldots,n-1. Note that this matrix is dense. The simplest way to compute a second derivative is by squaring \\mathbf{D}_x, as there is no longer any concern about the bandwidth of the result.\n\nFunction 10.3.2 returns these two matrices. The function uses a change of variable to transplant the standard [-1,1] for Chebyshev nodes to any [a,b]. It also takes a different approach to computing the diagonal elements of \\mathbf{D}_x than the formulas in \n\n(10.3.9) (see \n\nExercise 5).\n\ndiffcheb\n\nChebyshev differentiation matrices\n\n\"\"\"\n    diffcheb(n, xspan)\n\nCompute Chebyshev differentiation matrices on `n`+1 points in the\ninterval `xspan`. Returns a vector of nodes and the matrices for the\nfirst and second derivatives.\n\"\"\"\nfunction diffcheb(n, xspan)\n    x = [-cos(k * π / n) for k in 0:n]    # nodes in [-1,1]\n\n    # Off-diagonal entries.\n    c = [2; ones(n - 1); 2]    # endpoint factors\n    dij = (i, j) -> (-1)^(i + j) * c[i+1] / (c[j+1] * (x[i+1] - x[j+1]))\n    Dₓ = [dij(i, j) for i in 0:n, j in 0:n]\n\n    # Diagonal entries.\n    Dₓ[isinf.(Dₓ)] .= 0         # fix divisions by zero on diagonal\n    s = sum(Dₓ, dims = 2)\n    Dₓ -= diagm(s[:, 1])         # \"negative sum trick\"\n\n    # Transplant to [a,b].\n    a, b = xspan\n    x = @. a + (b - a) * (x + 1) / 2\n    Dₓ = 2 * Dₓ / (b - a)             # chain rule\n\n    # Second derivative.\n    Dₓₓ = Dₓ^2\n    return x, Dₓ, Dₓₓ\nend\n\nChebyshev differentiation matrices\n\nfunction [x,Dx,Dxx] = diffcheb(n,xspan)\n%DIFFCHEB   Chebyshev differentiation matrices.\n% Input:\n%   n      number of subintervals (integer)\n%   xspan  interval endpoints (vector)\n% Output:\n%   x      Chebyshev nodes in domain (length n+1)\n%   Dx     matrix for first derivative (n+1 by n+1)\n%   Dxx    matrix for second derivative (n+1 by n+1)\n\nx = -cos( (0:n)'*pi/n );    % nodes in [-1,1]\nDx = zeros(n+1);\nc = [2; ones(n-1,1); 2];    % endpoint factors\ni = (0:n)';                 % row indices\n\n% Off-diagonal entries\nfor j = 0:n\n  num = c(i+1).*(-1).^(i+j);\n  den = c(j+1)*(x-x(j+1));\n  Dx(:,j+1) = num./den;\nend\n\n% Diagonal entries\nDx(isinf(Dx)) = 0;          % fix divisions by zero on diagonal\nDx = Dx - diag(sum(Dx,2));  % \"negative sum trick\" \n  \n% Transplant to [a,b]\na = xspan(1);  b = xspan(2);\nx = a + (b-a)*(x+1)/2;\nDx = 2*Dx/(b-a);\n\n% Second derivative\nDxx = Dx^2;\n\nChebyshev differentiation matrices\n\ndef diffcheb(n, xspan):\n    \"\"\"\n    diffcheb(n, xspan)\n\n    Compute Chebyshev differentiation matrices on n+1 points in the\n    interval xspan. Return a vector of nodes, and the matrices for the first\n    and second derivatives.\n    \"\"\"\n    x = -np.cos(np.arange(n + 1) * np.pi / n)  # nodes in [-1,1]\n    Dx = np.zeros([n + 1, n + 1])\n    c = np.hstack([2.0, np.ones(n - 1), 2.0])  # endpoint factors\n\n    # Off-diagonal entries\n    Dx = np.zeros([n + 1, n + 1])\n    for i in range(n + 1):\n        for j in range(n + 1):\n            if i != j:\n                Dx[i, j] = (-1) ** (i + j) * c[i] / (c[j] * (x[i] - x[j]))\n\n    # Diagonal entries by the \"negative sum trick\"\n    for i in range(n + 1):\n        Dx[i, i] = -np.sum([Dx[i, j] for j in range(n + 1) if j != i])\n\n    # Transplant to [a,b]\n    a, b = xspan\n    x = a + (b - a) * (x + 1) / 2\n    Dx = 2 * Dx / (b - a)\n\n    # Second derivative\n    Dxx = Dx @ Dx\n\n    return x, Dx, Dxx\n\nChebyshev differentiation matrices\n\nExample 10.3.2\n\nHere is a 4\\times 4 Chebyshev differentiation matrix.\n\nt, Dₓ = FNC.diffcheb(3, [-1, 1])\nDₓ\n\nWe again test the convergence rate.\n\nf = x -> x + exp(sin(4 * x));\ndf_dx = x -> 1 + 4 * exp(sin(4 * x)) * cos(4 * x);\nd2f_dx2 = x -> 4 * exp(sin(4 * x)) * (4 * cos(4 * x)^2 - 4 * sin(4 * x));\n\nn = 5:5:70\nerr1 = zeros(size(n))\nerr2 = zeros(size(n))\nfor (k, n) in enumerate(n)\n    t, Dₓ, Dₓₓ = FNC.diffcheb(n, [-1, 1])\n    y = f.(t)\n    err1[k] = norm(df_dx.(t) - Dₓ * y, Inf)\n    err2[k] = norm(d2f_dx2.(t) - Dₓₓ * y, Inf)\nend\n\nSince we expect a spectral convergence rate, we use a semi-log plot for the error.\n\nplot(n, [err1 err2]; m = :o,\n    label=[L\"f'\" L\"f''\"],\n    xaxis=(L\"n\"),  yaxis = (:log10, \"max error\"),\n    title=\"Convergence of Chebyshev derivatives\")\n\nExample 10.3.2\n\nHere is a 4\\times 4 Chebyshev differentiation matrix.\n\n[t, Dx] = diffcheb(3, [-1, 1]);\nformat rat\nDx\n\nWe again test the convergence rate.\n\nf = @(x) x + exp(sin(4*x));\ndf_dx = @(x) 1 + 4 * exp(sin(4*x)) .* cos(4*x);\nd2f_dx2 = @(x) 4 * exp(sin(4*x)) .* (4*cos(4*x).^2 - 4*sin(4*x));\n\nn = 5:5:70;\nerr = zeros(length(n), 2);\nfor k = 1:length(n)\n    [t, Dx, Dxx] = diffcheb(n(k), [-1, 1]);\n    y = f(t);\n    err(k, 1) = norm(df_dx(t) - Dx * y, Inf);\n    err(k, 2) = norm(d2f_dx2(t) - Dxx * y, Inf);\nend\n\nSince we expect a spectral convergence rate, we use a semi-log plot for the error.\n\nclf,  format\nsemilogy(n, err, 'o-'), hold on\nlegend(\"f'\", \"f''\")\nxlabel('n'),  ylabel('max error')\ntitle('Convergence of finite differences')\n\nExample 10.3.2\n\nHere is a 4\\times 4 Chebyshev differentiation matrix.\n\nt, Dx, Dxx = FNC.diffcheb(3, [-1, 1])\nprint(Dx)\n\nWe again test the convergence rate.\n\nf = lambda x: x + exp(sin(4 * x))\ndf_dx = lambda x: 1 + 4 * exp(sin(4 * x)) * cos(4 * x)\nd2f_dx2 = lambda x: 4 * exp(sin(4 * x)) * (4 * cos(4 * x) ** 2 - 4 * sin(4 * x))\n\nN = range(5, 75, 5)\nerr1 = zeros(len(N))\nerr2 = zeros(len(N))\nerr = zeros((len(N), 2))\nfor k, n in enumerate(N):\n    t, Dx, Dxx = FNC.diffcheb(n, [-1, 1])\n    y = f(t)\n    err[k, 0] = norm(df_dx(t) - Dx @ y, inf)\n    err[k, 1] = norm(d2f_dx2(t) - Dxx @ y, inf)\n\nSince we expect a spectral convergence rate, we use a semi-log plot for the error.\n\nsemilogy(N, err, \"-o\")\nxlabel(\"$n$\"), ylabel(\"max error\")\nlegend([\"$f'$\", \"$f''$\"], loc=\"lower left\")\ntitle(\"Convergence of Chebyshev derivatives\");\n\nAccording to \n\nTheorem 9.3.1, the convergence of polynomial interpolation to f using Chebyshev nodes is spectral if f is analytic (at least having infinitely many derivatives) on the interval. The derivatives of f are also approximated with spectral accuracy.","type":"content","url":"/diffmats#spectral-differentiation","position":7},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Exercises"},"type":"lvl2","url":"/diffmats#exercises","position":8},{"hierarchy":{"lvl1":"Differentiation matrices","lvl2":"Exercises"},"content":"(a) ✍ Calculate \\mathbf{D}_x^2 using \n\n(10.3.5) to define \\mathbf{D}_x.\n\n(b) ⌨ Repeat the experiment of \n\nDemo 10.3.1, but using this version of \\mathbf{D}_x^2 to estimate f''. What is the apparent order of accuracy in f''?\n\n(a) ✍ Find the derivative of f(x) =\\operatorname{sign}(x)x^2 on the interval [-1,1]. (If this gives you trouble, use an equivalent piecewise definition of f.) What is special about this function at x=0?\n\n(b) ⌨ Adapt \n\nDemo 10.3.1 to operate on the function from part (a), computing only the first derivative. What is the observed order of accuracy?\n\n(c) ✍ Show that for even values of n, there is only one node at which the error for computing f' in part (b) is nonzero.\n\n⌨ To get a fourth-order accurate version of \\mathbf{D}_x, five points per row are needed, including two special rows at each boundary. For a fourth-order \\mathbf{D}_{xx}, five symmetric points per row are needed for interior rows and six points are needed for the rows near a boundary.\n\n(a) Modify \n\nFunction 10.3.1 to a function diffmat4, which outputs fourth-order accurate differentiation matrices. You may want to use \n\nFunction 5.4.1.\n\n(b) Repeat the experiment of \n\nDemo 10.3.1 using diffmat4 in place of \n\nFunction 10.3.1, and compare observed errors to fourth-order accuracy.\n\n✍ Explain in detail how lines 23-24 in \n\nFunction 10.3.2 correctly change the interval from [-1,1] to [a,b].\n\n(a) ✍ What is the derivative of a constant function?\n\n(b) ✍ Explain why for any reasonable differentiation matrix \\mathbf{D}, we should find \\displaystyle \\sum_{j=0}^nD_{ij}=0 for all i.\n\n(c) ✍ What does this have to do with \n\nFunction 10.3.2? Refer to specific line(s) in the function for your answer.\n\nDefine the (n+1)\\times (n+1) matrix \\mathbf{T} = \\displaystyle \\begin{bmatrix}\n 1 & & & \\\\ 1 & 1 & & \\\\ \\vdots & & \\ddots & \\\\ 1 & 1 & \\cdots & 1\n \\end{bmatrix}.\n\n(a) ✍ Write out \\mathbf{T}\\mathbf{u} for a generic vector \\mathbf{u} (start with a zero index). How is this like integration?\n\n(b) ✍ Find the inverse of \\mathbf{T} for any n.  (You can use Julia to find the pattern, but show that the result is correct in general.) What does this have to do with the inverse of integration?\n\nIn order to exploit this structure efficiently in Julia, these matrices first need to be constructed as or converted to sparse or tridiagonal form.","type":"content","url":"/diffmats#exercises","position":9},{"hierarchy":{"lvl1":"The Galerkin method"},"type":"lvl1","url":"/galerkin","position":0},{"hierarchy":{"lvl1":"The Galerkin method"},"content":"Using finite differences we defined a collocation method in which an approximation of the differential equation is required to hold at a finite set of nodes. In this section we present an alternative based on integration rather than differentiation. Our presentation will be limited to the linear BVPu'' = p(x)\\,u' + q(x)\\,u + r(x), \\quad a \\le x \\le b, \\quad u(a)=0,\\;\nu(b)=0.\n\nHowever, we will assume that the linear problem is presented in the equivalent form    - \\frac{d }{d x} \\Bigl[ c(x)\\, u'(x) \\Bigr] + s(x) \\, u(x) = f(x),\n    \\quad u(a)=0,\\; u(b)=0.\n\nSuch a transformation is always possible, at least in principle (see \n\nExercise 3), and the case when u(a) and u(b) are nonzero can also be incorporated (see \n\nExercise 2). The approach is also adaptable to Neumann conditions (see \n\nExercise 5). As with finite differences, a nonlinear problem is typically solved by using a Newton iteration to create a sequence of linear problems.","type":"content","url":"/galerkin","position":1},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Weak formulation"},"type":"lvl2","url":"/galerkin#weak-formulation","position":2},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Weak formulation"},"content":"Let \n\n(10.6.2) be multiplied by a generic function \\psi(x) called the test function, and then integrate both sides in x:\\begin{split}\n\\int_a^b f(x)\\psi(x) \\,dx  &= \\int_a^b \\bigl[ -(c(x)u'(x))'\\psi(x) +\ns(x)u(x)\\psi(x) \\bigr] \\,dx \\\\\n&= \\Bigl[-c(x)u'(x)\\psi(x) \\Bigr]_{\\,a}^{\\,b} + \\int_a^b \\bigl[ c(x)u'(x)\\psi'(x) + s(x)u(x)\\psi(x)\\bigr] \\, dx. \n\\end{split}\n\nThe last line above used an integration by parts.\n\nWe now make an important and convenient assumption about the test function. The first term in \n\n(10.6.3), consisting of boundary evaluations, disappears if we require that \\psi(a)=\\psi(b)=0. Doing so leads to  \\int_a^b \\bigl[ c(x)u'(x)\\psi'(x) + s(x)u(x)\\psi(x)\\bigr]  \\,dx = \\int_a^b f(x)\\psi(x) \\,dx,\n\nwhich is known as the weak form of the differential equation \n\n(10.6.2).\n\nWeak solution\n\nIf u(x) is a function such that \n\n(10.6.4) is satisfied for all valid choices of ψ, we say that u is a weak solution of the BVP \n\n(10.6.2).\n\nEvery solution of \n\n(10.6.2) (what we might now call the strong form of the problem) is a weak solution, but the converse is not always true. While the weak form might look odd, in many mathematical models it could be considered more fundamental than \n\n(10.6.2).","type":"content","url":"/galerkin#weak-formulation","position":3},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Galerkin conditions"},"type":"lvl2","url":"/galerkin#galerkin-conditions","position":4},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Galerkin conditions"},"content":"Our goal is to solve a finite-dimensional problem that approximates the weak form of the BVP. Let \\phi_0,\\phi_1,\\ldots,\\phi_m be linearly independent functions satisfying \\phi_i(a)=\\phi_i(b)=0. If we require\\psi(x) = \\sum_{i=1}^m z_i \\phi_i(x),\n\nthen \n\n(10.6.4) becomes, after some rearrangement,\\begin{split}\n  \\sum_{i=1}^m z_i \\left[ \\int_a^b  \\bigl[ c(x)u'(x)\\phi_i'(x)\\,dx  + s(x)u(x)\\phi_i(x) - f(x) \\phi_i(x)\\bigr] \\, d x \\right] = 0.\n\\end{split}\n\nOne way to satisfy this condition is to ensure that the term inside the brackets is zero for each possible value of i, that is,  \\int_a^b \\bigl[ c(x)u'(x)\\phi_i'(x)  +  s(x)u(x)\\phi_i(x)\\bigr] \\,dx = \\int_a^b f(x)\\phi_i(x) \\,dx\n\nfor i=1,\\ldots,m. The independence of the \\phi_i furthermore guarantees that this is the only possibility, so we no longer need to consider the z_i.\n\nNow that we have approximated the weak form of the BVP by a finite set of constraints, the next step is to represent the approximate solution by a finite set as well. A natural choice is to approximate u(x) the same way as we did the test function ψ, where the \\phi_j form a basis for representing the solution:  u(x) = \\sum_{j=1}^m w_j \\phi_j(x).\n\nSubstituting \n\n(10.6.8) into \n\n(10.6.7) implies\\int_a^b \\left\\{ c(x) \\Bigl[ \\sum_{j=1}^m w_j \\phi_j'(x) \\Bigr] \\phi_i'(x)  +\n  s(x)\\Bigl[ \\sum_{j=1}^m w_j \\phi_j(x) \\Bigr]\\phi_i(x) \\right\\} \\,dx = \\int_a^b f(x)\\phi_i(x) \\,dx\n\nfor i=1,\\ldots,m. This rearranges easily into  \\sum_{j=1}^m w_j \\left[ \\int_a^b c(x)\\phi_i'(x)\\phi_j'(x) \\,dx  +\n  \\int_a^b s(x)\\phi_i(x)\\phi_j(x) \\,dx \\right]  = \\int_a^b f(x)\\phi_i(x) \\,dx,\n\nstill for each i=1,\\ldots,m. These are the Galerkin conditions defining a numerical solution. They follow entirely from the BVP and the choice of the \\phi_i.\n\nThe conditions \n\n(10.6.10) are a linear system of equations for the unknown coefficients w_j. Define m\\times m matrices \\mathbf{K}  and \\mathbf{M}, and the vector \\mathbf{f}, by\\begin{split}\n    K_{ij} &= \\int_a^b c(x)\\phi_i'(x)\\phi_j'(x) \\,dx, \\quad i,j=0,\\ldots,m,\\\\\n    M_{ij} &= \\int_a^b s(x)\\phi_i(x)\\phi_j(x) \\,dx,\n    \\quad i,j=0,\\ldots,m,   \\\\\n    f_i &= \\int_a^b f(x)\\phi_i(x) \\,dx \\quad i=0,\\ldots,m. \n\\end{split}\n\nThen \n\n(10.6.10) is simply  (\\mathbf{K}+\\mathbf{M})\\mathbf{w} = \\mathbf{f}.\n\nThe matrix \\mathbf{K} is called the stiffness matrix and \\mathbf{M} is called the mass matrix. By their definitions, they are symmetric. The last piece of the puzzle is to make some selection of \\phi_1,\\ldots,\\phi_m and obtain a fully specified algorithm.\n\nSuppose we are given -u''+4u=x, with u(0)=u(\\pi)=0. We could choose the basis functions \\phi_k=\\sin(kx) for k=1,2,3. Then\\begin{align*}\n    M_{ij} & = 4 \\int_0^\\pi \\sin(ix) \\sin(jx)\\, dx, \\\\\n    K_{ij} & = ij \\int_0^\\pi \\cos(ix) \\cos(jx)\\, dx, \\\\\n    f_i &= \\int_0^\\pi x \\sin(ix)\\, dx.\n  \\end{align*}\n\nWith some calculation (or computer algebra), we find\\mathbf{M} = 2\\pi\n    \\begin{bmatrix}\n      1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\n    \\end{bmatrix}, \\qquad\n     \\mathbf{K} = \\frac{\\pi}{2}\n    \\begin{bmatrix}\n      1 & 0 & 0 \\\\ 0 & 4 & 0 \\\\ 0 & 0 & 9\n    \\end{bmatrix}, \\qquad\n    \\mathbf{f} = \\pi\n    \\begin{bmatrix}\n      1 \\\\ -1/2 \\\\ 1/3\n    \\end{bmatrix}.\n\nUpon solving the resulting diagonal linear system, the approximate solution is\\frac{2}{5}\\sin(x) - \\frac{1}{8} \\sin(2x) + \\frac{2}{39}\\sin(3x).","type":"content","url":"/galerkin#galerkin-conditions","position":5},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Finite elements"},"type":"lvl2","url":"/galerkin#finite-elements","position":6},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Finite elements"},"content":"One useful and general choice for the \\phi_i are the piecewise linear hat functions constructed in \n\nPiecewise linear interpolation. As usual, we select nodes a=t_0 < t_1 < \\cdots < t_n=b. Also defineh_i = t_i - t_{i-1}, \\qquad i=1,\\ldots,n.\n\nThen we set m=n-1, and the \\phi_i in \n\n(10.6.8) are  \\phi_i(x) =  H_i(x) =\n  \\begin{cases}\n      \\dfrac{x-t_{i-1}}{h_i} & \\text{if $x\\in[t_{i-1},t_i]$},\\\\[2.5ex]\n      \\dfrac{t_{i+1}-x}{h_{i+1}} & \\text{if\n          $x\\in[t_{i},t_{i+1}]$},\\\\[2.5ex]\n      0 & \\text{otherwise}.\n  \\end{cases}\n\nRecall that these functions are cardinal, i.e., H_i(t_i)=1 and H_i(t_j)=0 if i\\neq j. Hence  u(x) = \\sum_{j=1}^m w_j \\phi_j(x) = \\sum_{j=1}^{n-1} u_j H_j(x),\n\nwhere as usual u_j is the value of the numerical solution at t_j. Note that we omit H_0 and H_n, which equal one at the endpoints of the interval, because the boundary conditions on u render them irrelevant.\n\nThe importance of the hat function basis in the Galerkin method is that each one is nonzero in only two adjacent intervals. As a result, we shift the focus from integrations over the entire interval in \n\n(10.6.11) to integrations over each subinterval, I_k=[t_{k-1},t_k]. Specifically, we use    \\begin{split}\n      K_{ij} &= \\sum_{k=1}^{n} \\left[ \\int_{I_k} c(x) H_i'(x) H_j'(x) \\,dx\\right],\n               \\qquad i,j=1,\\ldots,n-1, \\\\\n        M_{ij} &= \\sum_{k=1}^{n} \\left[ \\int_{I_k} s(x)H_i(x)H_j(x) \\,dx\\right],\n         \\qquad i,j=1,\\ldots,n-1,  \\\\\n      f_i &= \\sum_{k=1}^{n} \\left[ \\int_{I_k}  f(x) H_i(x) \\,dx\\right]\n            \\qquad i=1,\\ldots,n-1. \n    \\end{split}\n\nStart with the first subinterval, I_1. The only hat function that is nonzero over I_1 is H_1(x). Thus the only integrals we need to consider over I_1 have i=j=1:\\int_{I_1} c(x) H_1'(x) H_1'(x) \\,dx, \\qquad  \\int_{I_1} s(x) H_1(x) H_1(x) \\,dx, \\qquad \\int_{I_1} f(x) H_1(x) \\,dx,\n\nwhich contribute to the sums for K_{11}, M_{11}, and f_1, respectively.\n\nBefore writing more formulas, we make one more very useful simplification. Unless the coefficient functions c(x), s(x), and f(x) specified in the problem are especially simple functions, the natural choice for evaluating all of the required integrals is numerical integration, say by the trapezoid formula. As it turns out, though, such integration is not really necessary. The fact that we have approximated the solution of the BVP by a piecewise linear interpolant makes the numerical method second-order accurate overall. It can be proven that the error is still second order if we replace each of the coefficient functions by a constant over I_k, namely the average of the endpoint values:c(x) \\approx \\overline{c}_k = \\frac{c(t_{k-1})+c(t_k)}{2} \\quad \\text{for $x\\in I_k$}.\n\nThus the integrals in \n\n(10.6.19) can be evaluated solely from the node locations. For instance,\\int_{I_1} c(x) H_1'(x) H_1'(x) \\,dx \\approx \\overline{c}_1 \\int_{t_0}^{t_1} h_1^{-2} \\, dx = \\frac{\\overline{c}_1}{h_1}.\n\nNow consider interval I_2=[t_1,t_2]. Here both H_1 and H_2 are nonzero, so there are contributions to all of the matrix elements K_{11}, K_{12}=K_{21}, K_{22}, to M_{11}, M_{12}=M_{21}, M_{22}, and to f_1 and f_2. Over I_2 we have H_2'= h_2^{-1} and H_{1}'= -h_2^{-1}. Hence the contributions to K_{11} and K_{22} in \n\n(10.6.19) are \\overline{c}_2/h_2, and the contributions to K_{12}=K_{21} are -\\overline{c}_2/h_2. We summarize the relationship by\\frac{\\overline{c}_k}{h_k}\n  \\begin{bmatrix}\n    1 & -1 \\\\ -1 & 1\n  \\end{bmatrix}\n  \\rightsquigarrow\n  \\begin{bmatrix}\n    K_{11} & K_{12} \\\\ K_{21} & K_{22}\n  \\end{bmatrix},\n\nwhere the squiggly arrow is meant to show that the values of the 2\\times 2 matrix on the left are added to the appropriate submatrix of \\mathbf{K} on the right. Similar expressions are obtained for contributions to \\mathbf{M} and \\mathbf{f} in \n\n(10.6.19); see below.\n\nIn general, over I_k for 1<k<n, we have H_k'= h_k^{-1} and H_{k-1}'=-h_k^{-1}. The stiffness matrix contributions over I_k become  \\frac{\\overline{c}_k}{h_k}\n  \\begin{bmatrix}\n    1 & -1 \\\\ -1 & 1\n  \\end{bmatrix}\n  \\rightsquigarrow\n  \\begin{bmatrix}\n    K_{k-1,k-1} & K_{k-1,k} \\\\ K_{k,k-1} & K_{k,k}\n  \\end{bmatrix}, \\qquad k=2,\\ldots,n-1.\n\nOne finds the contributions to the other structures by similar computations:  \\frac{\\overline{s}_k h_k}{6}\n  \\begin{bmatrix}\n    2 & 1 \\\\ 1 & 2\n  \\end{bmatrix}\n  \\rightsquigarrow\n  \\begin{bmatrix}\n    M_{k-1,k-1} & M_{k-1,k} \\\\ M_{k,k-1} & M_{k,k}\n  \\end{bmatrix}, \\qquad k=2,\\ldots,n-1,\n\nand  \\frac{\\overline{f}_k h_k}{2}\n  \\begin{bmatrix}\n    1 \\\\ 1\n  \\end{bmatrix}\n  \\rightsquigarrow\n  \\begin{bmatrix}\n    f_{k-1} \\\\ f_{k}\n  \\end{bmatrix}, \\qquad k=2,\\ldots,n-1.\n\nThe contribution from I_n affects just K_{n-1,n-1}, M_{n-1,n-1}, and f_{n-1}, and it produces formulas similar to those for I_1.\n\nEach I_k contributes to four elements of each matrix and two of the vector \\mathbf{f}, except for I_1 and I_n, which each contribute to just one element of each matrix and \\mathbf{f}. The spatially localized contributions to the matrices characterize a finite element method (FEM).  Putting together all of the contributions to \n\n(10.6.12) to form the complete algebraic system is often referred to as the assembly process.","type":"content","url":"/galerkin#finite-elements","position":7},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Implementation and convergence"},"type":"lvl2","url":"/galerkin#implementation-and-convergence","position":8},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Implementation and convergence"},"content":"Function 10.6.1 implements the piecewise linear FEM on the linear problem as posed in \n\n(10.6.4), using an equispaced grid. The code closely follows the description above.\n\nfem\n\nPiecewise linear finite elements for a linear BVP\n\n\"\"\"\n    fem(c, s, f, a, b, n)\n\nUse a piecewise linear finite element method to solve a two-point\nboundary value problem. The ODE is (`c`(x)u')' + `s`(x)u = `f`(x) on\nthe interval [`a`,`b`], and the boundary values are zero. The\ndiscretization uses `n` equal subintervals.\n\nReturn vectors for the nodes and the values of u.\n\"\"\"\nfunction fem(c, s, f, a, b, n)\n    # Define the grid.\n    h = (b - a) / n\n    x = @. a + h * (0:n)\n\n    # Templates for the subinterval matrix and vector contributions.\n    Ke = [1 -1; -1 1]\n    Me = (1 / 6) * [2 1; 1 2]\n    fe = (1 / 2) * [1; 1]\n\n    # Evaluate coefficent functions and find average values.\n    cval = c.(x)\n    cbar = (cval[1:n] + cval[2:n+1]) / 2\n    sval = s.(x)\n    sbar = (sval[1:n] + sval[2:n+1]) / 2\n    fval = f.(x)\n    fbar = (fval[1:n] + fval[2:n+1]) / 2\n\n    # Assemble global system, one interval at a time.\n    K = zeros(n - 1, n - 1)\n    M = zeros(n - 1, n - 1)\n    f = zeros(n - 1)\n    K[1, 1] = cbar[1] / h\n    M[1, 1] = sbar[1] * h / 3\n    f[1] = fbar[1] * h / 2\n    K[n-1, n-1] = cbar[n] / h\n    M[n-1, n-1] = sbar[n] * h / 3\n    f[n-1] = fbar[n] * h / 2\n    for k in 2:n-1\n        K[k-1:k, k-1:k] += (cbar[k] / h) * Ke\n        M[k-1:k, k-1:k] += (sbar[k] * h) * Me\n        f[k-1:k] += (fbar[k] * h) * fe\n    end\n\n    # Solve system for the interior values.\n    u = (K + M) \\ f\n    u = [0; u; 0]      # put the boundary values into the result\n    return x, u\nend\n\nPiecewise linear finite elements for a linear BVP\n\nfunction [x,u] = fem(c,s,f,a,b,n)\r\n%FEM     Piecewise linear finite elements for a linear BVP.\r\n% Input:\r\n%   c,s,f    coefficient functions of x describing the ODE (functions) \r\n%   a,b      domain of the independent variable (scalars)\r\n%   n        number of grid subintervals (scalar) \r\n% Output:\r\n%   x        grid points (vector, length n+1)\r\n%   u        solution values at x (vector, length n+1)\r\n\r\n% Define the grid.\r\nh = (b-a)/n;\r\nx = a + h*(0:n)';  \r\n\r\n% Templates for the subinterval matrix and vector contributions.\r\nKe = [1 -1; -1 1];\r\nMe = (1/6)*[2 1; 1 2];\r\nfe = (1/2)*[1; 1];\r\n\r\n% Evaluate coefficent functions and find average values.\r\ncval = c(x);   cbar = (cval(1:n)+cval(2:n+1)) / 2;\r\nsval = s(x);   sbar = (sval(1:n)+sval(2:n+1)) / 2;\r\nfval = f(x);   fbar = (fval(1:n)+fval(2:n+1)) / 2;\r\n\r\n% Assemble global system, one interval at a time.\r\nK = zeros(n-1,n-1);  M = zeros(n-1,n-1);  f = zeros(n-1,1);\r\nK(1,1) = cbar(1)/h;  M(1,1) = sbar(1)*h/3;  f(1) = fbar(1)*h/2;\r\nK(n-1,n-1) = cbar(n)/h;  M(n-1,n-1) = sbar(n)*h/3;  f(n-1) = fbar(n)*h/2;\r\nfor k = 2:n-1\r\n  K(k-1:k,k-1:k) = K(k-1:k,k-1:k) + (cbar(k)/h) * Ke;\r\n  M(k-1:k,k-1:k) = M(k-1:k,k-1:k) + (sbar(k)*h) * Me;\r\n  f(k-1:k) = f(k-1:k) + (fbar(k)*h) * fe;\r\nend  \r\n\r\n% Solve system for the interior values.\r\nu = (K+M) \\ f;\r\nu = [0; u; 0];      % put the boundary values into the result\n\nPiecewise linear finite elements for a linear BVP\n\ndef fem(c, s, f, a, b, n):\n    \"\"\"\n    fem(c, s, f, a, b, n)\n\n    Use a piecewise linear finite element method to solve a two-point boundary\n    value problem. The ODE is (c(x)u')' + s(x)u = f(x) on the interval\n    [a,b], and the boundary values are zero. The discretization uses n equal\n    subintervals.\n\n    Return vectors for the nodes and the values of u.\n    \"\"\"\n    # Define the grid.\n    h = (b - a) / n\n    x = np.linspace(a, b, n + 1)\n\n    # Templates for the subinterval matrix and vector contributions.\n    Ke = np.array([[1, -1], [-1, 1]])\n    Me = (1 / 6) * np.array([[2, 1], [1, 2]])\n    fe = (1 / 2) * np.array([1, 1])\n\n    # Evaluate coefficent functions and find average values.\n    cval = c(x)\n    cbar = (cval[:-1] + cval[1:]) / 2\n    sval = s(x)\n    sbar = (sval[:-1] + sval[1:]) / 2\n    fval = f(x)\n    fbar = (fval[:-1] + fval[1:]) / 2\n\n    # Assemble global system, one interval at a time.\n    K = np.zeros([n - 1, n - 1])\n    M = np.zeros([n - 1, n - 1])\n    f = np.zeros(n - 1)\n    K[0, 0] = cbar[0] / h\n    M[0, 0] = sbar[0] * h / 3\n    f[0] = fbar[0] * h / 2\n    K[-1, -1] = cbar[-1] / h\n    M[-1, -1] = sbar[-1] * h / 3\n    f[-1] = fbar[-1] * h / 2\n    for k in range(1, n - 1):\n        K[k - 1 : k + 1, k - 1 : k + 1] += (cbar[k] / h) * Ke\n        M[k - 1 : k + 1, k - 1 : k + 1] += (sbar[k] * h) * Me\n        f[k - 1 : k + 1] += (fbar[k] * h) * fe\n\n    # Solve system for the interior values.\n    u = np.linalg.solve(K + M, f)\n    u = np.hstack([0, u, 0])  # put the boundary values into the result\n\n    return x, u\n\nFinite element solution of a BVP\n\nWe solve the equation-(x^2u')' + 4 y = \\sin(\\pi x), \\qquad u(0)=u(1)=0,\n\nin whichc(x) = x^2, \\qquad s(x) = 4, \\qquad f(x)=\\sin(\\pi x).\n\nExample 10.6.2\n\nHere are the coefficient function definitions. Even though s is a constant, it has to be defined as a function for \n\nFunction 10.6.1 to use it.\n\nc = x -> x^2;\nq = x -> 4;\nf = x -> sin(π * x);\n\nusing Plots\nx, u = FNC.fem(c, q, f, 0, 1, 50)\nplot(x, u;\n    xaxis=(L\"x\"),  yaxis = (L\"u\"),\n    title = \"Solution by finite elements\", legend=:none)\n\nExample 10.6.2\n\nHere are the coefficient function definitions. Even though s is a constant, it has to be defined as a function for \n\nFunction 10.6.1 to use it.\n\nc = @(x) x.^2;\nq = @(x) 4 * ones(size(x));\nf = @(x) sin(pi * x);\n\n[x,u] = fem(c, q, f, 0, 1, 50);\nclf,  plot(x, u)\nxlabel('x'),  ylabel('u')\ntitle('Solution by finite elements')\n\nExample 10.6.2\n\nHere are the coefficient function definitions. Even though s is a constant, it has to be defined as a function for \n\nFunction 10.6.1 to use it.\n\nc = lambda x: x**2\nq = lambda x: 4 * ones(len(x))\nf = lambda x: sin(pi * x)\n\nx, u = FNC.fem(c, q, f, 0, 1, 50)\nplot(x, u)\nxlabel(\"$x$\"),  ylabel(\"$u$\")\ntitle(\"Solution by finite elements\");\n\nBecause piecewise linear interpolation on a uniform grid of size h is O(h^2) accurate, the accuracy of the FEM method based on linear interpolation as implemented here is similar to the second-order finite-difference method.","type":"content","url":"/galerkin#implementation-and-convergence","position":9},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Exercises"},"type":"lvl2","url":"/galerkin#exercises","position":10},{"hierarchy":{"lvl1":"The Galerkin method","lvl2":"Exercises"},"content":"⌨ For each linear BVP, use \n\nFunction 10.6.1 to solve the problem and plot the solution for n=40. Then for each n=10,20,40,\\ldots,640, compute the norm of the error. Make a log-log convergence plot of error versus n and compare graphically to second-order convergence.\n\n(a) -u''+u=-8 + 16 x^2 - x^4, \\quad u(0) =u(2) =0\n\nExact solution: x^2(4-x^2)\n\n(b) [(2+x)u']' +11x u = -e^x \\left(12 x^3+7 x^2+1\\right), \\quad u(-1) =u(1) =0\n\nExact solution: e^x \\left(1-x^2\\right)\n\n(c) u''+x(u'+u) = -x[4 \\sin(x)+5 x \\cos(x)], \\quad u(0) =u(2\\pi) =0\n\nExact solution: -x^2\\sin(x)\n\n✍  Suppose you want to solve the differential equation -[c(x)u']'+d(x)u = f(x), as in Equation \n\n(10.6.2), except with the boundary conditions u(a)=\\alpha, u(b)=\\beta. Find constants p and q such that if v(x)=u(x)+px+q, then v satisfies the same BVP, except that v(a)=v(b)=0 and f is replaced by a different function.\n\n✍  Suppose p(x)u''(x)+q(x)u'(x)+r(x)=0, and assume that p(x)\\neq 0 for all x in [a,b]. Let z(x) be any function satisfying z'=q/p. Show that the differential equation is equivalent to one in the form \n\n(10.6.2), and find the functions c(x), d(x), and f(x) in that equation. (Hint: Start by multiplying through the equation by \\exp(z).)\n\n✍ Derive \n\n(10.6.25), starting from the mass matrix definition in \n\n(10.6.19). You should replace s(x) by the constant \\overline{s}_k within interval I_k.\n\nSuppose the Dirichlet boundary conditions u(a)=u(b)=0 are replaced by the homogeneous Neumann conditions u'(a)=u'(b)=0.\n\n(a) ✍ Explain why the weak form \n\n(10.6.4) can be derived without any boundary conditions on the test function ψ.\n\n(b) ⌨ The result of part (a) suggests replacing \n\n(10.6.18) withu(x) = \\sum_{j=0}^{n} u_j H_j(x)\n\nand making \n\n(10.6.19) hold for all i,j from 0 to n. Modify \n\nFunction 10.6.1 to do this and thereby solve the Neumann problem. (Note that I_1 and I_n now each make multiple contributions, like all the other integration subintervals.)\n\n(c) ⌨ Test your function on the problemu''+u = -2 \\sin(x), \\quad u'(0)=u'(1)=0,\n\nwhose exact solution is (x-1)\\cos(x) - \\sin(x). Show second-order convergence.","type":"content","url":"/galerkin#exercises","position":11},{"hierarchy":{"lvl1":"Collocation for linear problems"},"type":"lvl1","url":"/linear","position":0},{"hierarchy":{"lvl1":"Collocation for linear problems"},"content":"Let us now devise a numerical method based on finite differences for the linear TPBVP  u'' + p(x)u' + q(x)u = r(x), \\quad u(a)=\\alpha,\\; u(b)=\\beta.\n\nThe first step is to select nodes x_0=a < x_1< \\cdots < x_n=b. For finite differences these will most likely be equally spaced, but for spectral differentiation they will be Chebyshev points.\n\nRather than solving for a function, we will solve for a vector of its approximate values at the nodes:    \\mathbf{u} =\n    \\begin{bmatrix}\n        u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{n-1} \\\\ u_n\n    \\end{bmatrix} \\approx\n    \\begin{bmatrix}\n        \\hat{u}(x_0) \\\\ \\hat{u}(x_1) \\\\ \\vdots \\\\ \\hat{u}(x_{n-1}) \\\\ \\hat{u}(x_{n})\n      \\end{bmatrix},\n\nwhere \\hat{u} is the exact solution of \n\n(10.4.1). If we so desire, we can use interpolation to convert the values (x_i,u_i) into a function after the solution is found.","type":"content","url":"/linear","position":1},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Collocation"},"type":"lvl2","url":"/linear#collocation","position":2},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Collocation"},"content":"Having defined values at the nodes as our unknowns, we impose approximations to the ODE at the same nodes.  This approach is known as collocation. Derivatives of the solution are found using differentiation matrices. For example,    \\begin{bmatrix}\n        \\hat{u}'(x_0) \\\\[1mm] \\hat{u}'(x_1) \\\\ \\vdots \\\\ \\hat{u}'(x_n)\n    \\end{bmatrix} \\approx \\mathbf{u}' = \\mathbf{D}_x \\mathbf{u},\n\nwith an appropriately chosen differentiation matrix \\mathbf{D}_x. Similarly, we define    \\begin{bmatrix}\n        \\hat{u}''(x_0) \\\\[1mm] \\hat{u}''(x_1) \\\\ \\vdots \\\\ \\hat{u}''(x_n)\n    \\end{bmatrix} \\approx \\mathbf{u}'' = \\mathbf{D}_{xx} \\mathbf{u},\n\nwith \\mathbf{D}_{xx} chosen in accordance with the node set.\n\nThe discrete form of \n\n(10.4.1) at the n+1 chosen nodes is    \\mathbf{u}'' + \\mathbf{P}\\mathbf{u}' + \\mathbf{Q}\\mathbf{u} = \\mathbf{r},\n\nwhere  \\begin{split}\n  \\mathbf{P} &= \\begin{bmatrix}\n        p(x_0) &  & \\\\\n        & \\ddots & \\\\\n        & & p(x_{n})\n    \\end{bmatrix},\n    \\qquad\n    \\mathbf{Q} =\n    \\begin{bmatrix}\n        q(x_0) &  & \\\\\n        & \\ddots & \\\\\n        & & q(x_{n})\n    \\end{bmatrix},\\\\\n    \\mathbf{r} &= \\begin{bmatrix}\n        r(x_0) \\\\ \\vdots  \\\\ r(x_n)\n    \\end{bmatrix}.\n\\end{split}\n\nIf we apply the definitions of \\mathbf{u}' and \\mathbf{u}'' and rearrange, we obtain  \\mathbf{L} \\mathbf{u} = \\mathbf{r}, \\qquad \\mathbf{L} =  \\mathbf{D}_{xx} + \\mathbf{P}\\mathbf{D}_x + \\mathbf{Q},\n\nwhich is a linear system of n+1 equations in n+1 unknowns.\n\nWe have not yet incorporated the boundary conditions. Those take the form of the additional linear conditions u_0=\\alpha and u_n=\\beta. We might regard this situation as an overdetermined system, suitable for linear least-squares. However, it’s usually preferred to impose the boundary conditions and collocation conditions exactly, so we need to discard two of the collocation equations to keep the system square. The obvious candidates for deletion are the collocation conditions at the two endpoints. We may express these deletions by means of a matrix that is an (n+1)\\times(n+1) identity with the first and last rows deleted:  \\mathbf{E} =\n  \\begin{bmatrix}\n  \t0      & 1      & 0      & \\cdots & 0      \\\\\n  \t\\vdots &        & \\ddots &        & \\vdots \\\\\n  \t0      & \\cdots & 0      & 1      & 0\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    \\mathbf{e}_1^T    \\\\ \\vdots \\\\ \\mathbf{e}_{n-1}^T\n  \\end{bmatrix},\n\nwhere as always \\mathbf{e}_k is the kth column (here starting from k=0) of an identity matrix. The product \\mathbf{E} \\mathbf{A} deletes the first and last rows of \\mathbf{A}, leaving a matrix that is (n-1)\\times(n+1). Similarly, \\mathbf{E}\\mathbf{r} deletes the first and last rows of \\mathbf{r}.\n\nFinally, we note that \\hat{u}(a)= \\mathbf{e}_0^T\\mathbf{u} and \\hat{u}(b)= \\mathbf{e}_n^T\\mathbf{u}, so the linear system including both the ODE and the boundary condition collocations is  \\begin{bmatrix}\n    \\mathbf{e}_0^T \\\\[1mm] \\mathbf{E}\\mathbf{L} \\\\[1mm]  \\mathbf{e}_n^T\n  \\end{bmatrix}\n  \\mathbf{u}\n  =\n  \\begin{bmatrix}\n  \\alpha \\\\[1mm] \\mathbf{E}\\mathbf{r} \\\\[1mm]  \\beta\n  \\end{bmatrix} \\qquad \\text{or} \\qquad \\mathbf{A}\\mathbf{u} = \\mathbf{b}.","type":"content","url":"/linear#collocation","position":3},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Implementation"},"type":"lvl2","url":"/linear#implementation","position":4},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Implementation"},"content":"Our implementation of linear collocation is \n\nFunction 10.4.1. It uses second-order finite differences but makes no attempt to exploit the sparsity of the matrices. It would be trivial to change the function to use spectral differentiation.\n\nbvplin\n\nSolution of a linear boundary-value problem\n\n\"\"\"\n    bvplin(p, q, r, xspan, lval, rval, n)\n\nUse finite differences to solve a linear bopundary value problem.\nThe ODE is u''+`p`(x)u'+`q`(x)u = `r`(x) on the interval `xspan`,\nwith endpoint function values given as `lval` and `rval`. There will\nbe `n`+1 equally spaced nodes, including the endpoints.\n\nReturns vectors of the nodes and the solution values.\n\"\"\"\nfunction bvplin(p, q, r, xspan, lval, rval, n)\n    x, Dₓ, Dₓₓ = diffmat2(n, xspan)\n\n    P = diagm(p.(x))\n    Q = diagm(q.(x))\n    L = Dₓₓ + P * Dₓ + Q     # ODE expressed at the nodes\n\n    # Replace first and last rows using boundary conditions.\n    z = zeros(1, n)\n    A = [[1 z]; L[2:n, :]; [z 1]]\n    b = [lval; r.(x[2:n]); rval]\n\n    # Solve the system.\n    u = A \\ b\n    return x, u\nend\n\nAbout the code\n\nNote that there is no need to explicitly form the row-deletion matrix \\mathbf{E} from \n\n(10.4.8). Since it only appears as left-multiplying \\mathbf{L} or \\mathbf{r}, we simply perform the row deletions as needed using indexing.\n\nSolution of a linear boundary-value problem\n\nfunction [x, u] = bvplin(p, q, r, a, b, ua, ub,n)\r\n% BVPLIN   Solve a linear boundary-value problem.\r\n% Input:\r\n%   p, q, r  u'' + pu' + qu = r (functions)\r\n%   a, b     endpoints of the domain (scalars)\r\n%   ua       value of u(a)\r\n%   ub       value of u(b)\r\n%   n        number of subintervals (integer)\r\n% Output:\r\n%   x       collocation nodes (vector, length n+1)\r\n%   u       solution at nodes (vector, length n+1)\r\n\r\n[x, Dx, Dxx] = diffmat2(n, [a, b]);\r\n\r\nP = diag(p(x));\r\nQ = diag(q(x));\r\nL = Dxx + P * Dx + Q;    % ODE expressed at the nodes\r\nr = r(x);    \r\n\r\n% Replace first and last rows using boundary conditions. \r\nI = speye(n+1); \r\nA = [ I(:, 1)'; L(2:n, :); I(:, n+1)' ];\r\n\r\nf = [ ua; r(2:n); ub ];\r\n\r\n% Solve the system.\r\nu = A \\ f;\n\nSolution of a linear boundary-value problem\n\ndef bvplin(p, q, r, xspan, lval, rval, n):\n    \"\"\"\n        bvplin(p, q, r, xspan, lval, rval, n)\n\n    Use finite differences to solve a linear bopundary value problem. The ODE is\n    u''+p(x)u'+q(x)u = r(x) on the interval xspan, with endpoint function\n    values given as lval and rval. There will be n+1 equally spaced nodes,\n    including the endpoints.\n\n    Return vectors of the nodes and the solution values.\n    \"\"\"\n    x, Dx, Dxx = diffmat2(n, xspan)\n\n    P = np.diag(p(x))\n    Q = np.diag(q(x))\n    L = Dxx + P @ Dx + Q  # ODE expressed at the nodes\n\n    # Replace first and last rows using boundary conditions.\n    I = np.eye(n + 1)\n    A = np.vstack([I[0], L[1:-1], I[-1]])\n    b = np.hstack([lval, r(x[1:-1]), rval])\n\n    # Solve the system.\n    u = np.linalg.solve(A, b)\n\n    return x, u\n\nAbout the code\n\nNote that there is no need to explicitly form the row-deletion matrix \\mathbf{E} from \n\n(10.4.8). Since it only appears as left-multiplying \\mathbf{L} or \\mathbf{r}, we simply perform the row deletions as needed using indexing.\n\nSolving a linear BVP\n\nWe solve the linear BVPu'' - (\\cos x) u' + (\\sin x) u = 0, \\quad u(0)=1, \\; u\\left(\\frac{3\\pi}{2}\\right)=\\frac{1}{e}.\n\nIts exact solution is u(x) = e^{\\sin x}.\n\nExample 10.4.1\n\nexact = x -> exp(sin(x));\n\nThe problem is presented above in our standard form, so we can identify the coefficient functions in the ODE. Each should be coded as a function.\n\np = x -> -cos(x);\nq = sin;\nr = x -> 0;      # function, not value\n\nWe solve the BVP and compare the result to the exact solution.\n\nx, u = FNC.bvplin(p, q, r, [0, 3π / 2], 1, exp(-1), 30);\n\nusing Plots\nplot(exact, 0, 3π / 2, layout = (2, 1), label = \"exact\")\nscatter!(x, u, m = :o,\n    subplot=1,  label=\"numerical\",\n    yaxis=(\"solution\"),\n    title=\"Solution of a linear BVP\")\nplot!(x, exact.(x) - u, subplot = 2, xaxis = L\"x\", yaxis = (\"error\"))\n\nExample 10.4.1\n\nexact = @(x) exp(sin(x));\n\nThe problem is presented above in our standard form, so we can identify the coefficient functions in the ODE. Each should be coded as a function.\n\np = @(x) -cos(x);\nq = @(x) sin(x);\nr = @(x) 0*x;      % not a scalar\n\nWe solve the BVP and compare the result to the exact solution.\n\n[x, u] = bvplin(p, q, r, 0, 3*pi/2, 1, exp(-1), 30);\n\nclf,  subplot(2, 1, 1)\nplot(x, u)\nylabel('solution')\ntitle('Solution of a linear BVP')\nsubplot(2, 1, 2)\nplot(x, exact(x) - u, 'o-')\nylabel('error')\n\nExample 10.4.1\n\nexact = lambda x: exp( sin(x) )\n\nThe problem is presented above in our standard form, so we can identify the coefficient functions in the ODE. Each should be coded as a function.\n\np = lambda x: -cos(x)\nq = sin\nr = lambda x: 0 * x    # must be a function\n\nWe solve the BVP and compare the result to the exact solution.\n\nx, u = FNC.bvplin(p, q, r, [0, pi/2], 1, exp(1), 25)\n\nsubplot(2, 1, 1)\nplot(x, u)\nylabel(\"solution\"),  title(\"Solution of the BVP\")\n\nsubplot(2, 1, 2)\nplot(x, exact(x) - u, \"-o\")\nylabel(\"error\");","type":"content","url":"/linear#implementation","position":5},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Accuracy and stability"},"type":"lvl2","url":"/linear#accuracy-and-stability","position":6},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Accuracy and stability"},"content":"We revisit \n\nDemo 10.2.3, which exposed instability in the shooting method, in order to verify second-order convergence.\n\nConvergence for a linear BVP\n\nThe BVP isu'' - \\lambda^2 u = \\lambda^2, \\quad  u(0)=-1, \\; u(1)=0,\n\nwith exact solution \\sinh(\\lambda x)/\\sinh(\\lambda) - 1.\n\nExample 10.4.2\n\nλ = 10\nexact = x -> sinh(λ * x) / sinh(λ) - 1;\n\nThe following functions define the ODE.\n\np = x -> 0\nq = x -> -λ^2\nr = x -> λ^2;\n\nWe compare the computed solution to the exact one for increasing n.\n\nn = 5 * [round(Int, 10^d) for d in 0:0.25:3]\nerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    x, u = FNC.bvplin(p, q, r, [0, 1], -1, 0, n)\n    err[k] = norm(exact.(x) - u, Inf)\nend\ndata = (n = n[1:4:end], err = err[1:4:end])\n@pt :header = [\"n\", \"inf-norm error\"] data\n\nEach factor of 10 in n reduces error by a factor of 100, which is indicative of second-order convergence.\n\nplot(n, err, m = :o,\n    label = \"observed\",\n    xaxis = (:log10, L\"n\"),\n    yaxis = (:log10, \"inf-norm error\"),\n    title = \"Convergence for a linear BVP\")\nplot!(n, 0.25 * n .^ (-2), l = (:dash, :gray), label = \"2nd order\")\n\nExample 10.4.2\n\nlambda = 10;\nexact = @(x) sinh(lambda * x) / sinh(lambda) - 1;\n\nThe following functions define the ODE.\n\np = @(x) zeros(size(x));            \nq = @(x) -lambda^2 * ones(size(x));\nr = @(x) lambda^2 * ones(size(x));\n\nWe compare the computed solution to the exact one for increasing n.\n\np = @(x) zeros(size(x));            \nq = @(x) -lambda^2 * ones(size(x));\nr = @(x) lambda^2 * ones(size(x));\nn = 2 * round(10.^(1:0.25:3)');\nerr = zeros(size(n));\nfor k = 1:length(n)\n    [x, u] = bvplin(p, q, r, 0, 1, -1, 0, n(k));\n    err(k) = norm(exact(x) - u, Inf);\nend\ntable(n, err, variableNames = [\"n\", \"inf-norm error\"])\n\nEach factor of 10 in n reduces error by a factor of 100, which is indicative of second-order convergence.\n\nclf,  loglog(n, err, 'o-')\nhold on, loglog(n, n.^(-2), 'k--')\nxlabel('n'),  ylabel('max error')\ntitle('Convergence for a linear BVP') \nlegend('obs. error', '2nd order')\n\nExample 10.4.2\n\nlamb = 10\nexact = lambda x: sinh(lamb * x) / sinh(lamb) - 1\n\nThe following functions define the ODE.\n\np = lambda x: zeros(size(x))\nq = lambda x: -(lamb**2) * ones(len(x))\nr = lambda x: lamb**2 * ones(len(x))\n\nWe compare the computed solution to the exact one for increasing n.\n\nN = array([int(2 * 10**d) for d in arange(1, 3.1, 0.25)])\nerr = zeros(len(N))\nresults = PrettyTable([\"n\", \"error\"])\nfor k, n in enumerate(N):\n    x, u = FNC.bvplin(p, q, r, [0, 1], -1, 0, n)\n    err[k] = norm(exact(x) - u, inf)\n    results.add_row([n, err[k]])\nprint(results)\n\nEach factor of 10 in n reduces error by a factor of 100, which is indicative of second-order convergence.\n\nloglog(N, err, \"-o\", label=\"observed\")\nloglog(N, 1 / N**2, \"--\", label=\"2nd order\")\nxlabel(\"$n$\"),  ylabel(\"max error\")\nlegend(),  title(\"Convergence of finite differences\");\n\nIf we write the solution \\mathbf{u} of Equation \n\n(10.4.9) as the exact solution minus an error vector \\mathbf{e}, i.e., \\mathbf{u} = \\hat{\\mathbf{u}} - \\mathbf{e}, we obtain\\begin{gather*}\n  \\mathbf{A} \\hat{\\mathbf{u}} - \\mathbf{A} \\mathbf{e} = \\mathbf{b}, \\\\\n  \\mathbf{e} = \\mathbf{A}^{-1} \\left[  \\mathbf{A} \\hat{\\mathbf{u}} - \\mathbf{b}  \\right] = \\mathbf{A}^{-1} \\boldsymbol{\\tau}(h),\n\\end{gather*}\n\nwhere \\boldsymbol{\\tau} is the truncation error of the finite differences (except at the boundary rows, where it is zero). It follows that \\|\\mathbf{e}\\| vanishes at the same rate as the truncation error if  \\| \\mathbf{A}^{-1}\\| is bounded above as h\\to 0. In the present context, this property is known as stability. Proving stability is too technical to walk through here, but stability is guaranteed under some reasonable conditions on the BVP.","type":"content","url":"/linear#accuracy-and-stability","position":7},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Exercises"},"type":"lvl2","url":"/linear#exercises","position":8},{"hierarchy":{"lvl1":"Collocation for linear problems","lvl2":"Exercises"},"content":"✍  For each boundary-value problem, verify that the given solution is correct. Then write out by hand for n=3 the matrices \\mathbf{D}_{xx}, \\mathbf{D}_x, \\mathbf{P}, and \\mathbf{Q}, and the vector \\mathbf{r}.\n\n(a) u'' + u = 0, \\quad u(0) =0, \\; u(3) = \\sin 3\n\nSolution: u(x) = \\sin x\n\n(b) u'' - \\frac{3}{x} u' + \\frac{4}{x^2} u = 0, \\quad u(1) =0,\\; u(4) = 32 \\log 2\n\nSolution: u(x) = x^2 \\log x\n\n(c)\nu'' - \\left(x+\\frac{1}{2}\\right)^{-1}\\, u' + 2\\left(x+\\frac{1}{2}\\right)^{-2}\\, u = 10\\left(x+\\frac{1}{2}\\right)^{-4}, \\quad u\\left(x+\\frac{1}{2}\\right)=1,\\; u\\left(x+\\frac{5}{2}\\right) = \\frac{1}{9}\n\nSolution: u(x) = \\left(x+\\frac{1}{2}\\right)^{-2}\n\n⌨  For each of the cases in the previous exercise, use \n\nFunction 10.4.1 to solve the problem with n=60 and make a plot of its error as a function of x. Then, for each n=10,20,40,\\ldots,640, find the infinity norm of the error. Make a log-log plot of error versus n and include a graphical comparison to second-order convergence.\n\n⌨ Modify \n\nFunction 10.4.1 to use spectral differentiation rather than second-order finite differences. For each of the cases in Exercise 1, solve the problem with n=5,10,15,\\ldots,40, finding the infinity norm of the error in each case. Make a log-linear plot of error versus n.\n\n⌨ Use \n\nFunction 10.4.1 to solve Bessel’s equation,x^2 u'' + x u' + x^2 y = 0, \\quad u(0.5)=1,\\; u(8) = 0.\n\nPlot the solution for n=100.\n\n⌨ The Airy equation is u''=x u. Its solution is exponential for x>0 and oscillatory for x<0. The exact solution is given by u=c_1 \\operatorname{Ai}(x) + c_2 \\operatorname{Bi}(x), where Ai and Bi are Airy functions. In Julia they are computed by airyai and airybi, respectively.\n\n(a) Suppose that u(-10) =-1, u(2) =1. By setting up and solving a 2\\times 2 linear system, find numerical values for c_1 and c_2. Plot the resulting exact solution.\n\n(b) Use \n\nFunction 10.4.1 with n=120 to find the solution with the boundary conditions in part (a). In a 2-by-1 subplot array, plot the finite-difference solution and its error. (The solution is not very accurate.)\n\n(c) Repeat part (b) with n=800.\n\nConsider the boundary-value problem \\epsilon u''+(1+\\epsilon)u'+u =0 over x\\in (0,1), with u(0)=0, u(1)=1.  As the parameter ε is decreased, the solution gets a thin region of high activity near x=0 called a boundary layer.\n\n(a) ✍ Verify that the exact solution to the problem isu(x) = \\frac{e^{-x}-e^{-x/\\epsilon}}{e^{\\,-1}-e^{\\,-1/\\epsilon}}.\n\nOn one graph, plot u(x) for \\epsilon=\\frac{1}{4},\\frac{1}{16},\\frac{1}{64}.\n\n(b) ⌨ Define N(\\epsilon) as the smallest integer value of n needed to make the max-norm error of the result of \n\nFunction 10.4.1 less than \n\n10-4. For each of the values \\epsilon = \\frac{1}{2},\\frac{1}{4},\\frac{1}{8}\\ldots,\\frac{1}{64}, estimate N(\\epsilon) by starting with n=50 and incrementing by 25 until the measured error is sufficiently small.\n\n(c) ⌨ Plot the error as a function of x for \\epsilon=\\frac{1}{64} and n=N(\\epsilon).  Compare the peak of the error to the graph from part (a).\n\n(d) ⌨ Develop a hypothesis for the leading-order behavior of N(\\epsilon). Plot the observed N(\\epsilon) and your hypothesis together on a log-log plot.\n\n(e) ✍ Finite-difference errors depend on the solution as well as on n. Given that this error decreases as O(n^{-2}), what does your hypothesis for N(\\epsilon) suggest about the behavior of the error for fixed n as \\epsilon\\to 0?","type":"content","url":"/linear#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-9","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"A text a bit above the level of this text is by Ascher and Petzold \n\nAscher & Petzold (1998), which covers shooting and finite-difference collocation methods for linear and nonlinear BVPs, with a number of theoretical and applications problems.  A graduate-level text solely on numerical solution of BVPs is by Ascher, Mattheij, and Russell \n\nAscher et al. (1995). Besides the shooting and finite-difference methods, it briefly discusses Galerkin and spline-based methods, and it goes into more depth on theoretical issues.  A more detailed treatment of the Galerkin method can be found in Quarteroni, Sacco, and Saleri \n\nQuarteroni et al. (2007).  An older and accessible treatment of Galerkin and finite element methods can be found in Strang and Fix \n\nStrang & Fix (1997).\n\nFor spectral methods, an introduction to BVPs may be found in Trefethen’s book \n\nTrefethen (2000), and a more theoretical take is in Quarteroni et al. \n\nQuarteroni et al. (2007).\n\nIn this chapter, a number of linear variable-coefficient BVPs for so-called special functions were mentioned: Bessel’s equation, Laguerre’s equation, etc.  These ODEs and their solutions arise in the solution of partial differential equations of mathematical physics, and were extensively characterized before prior to wide use of computers \n\nAbramowitz & Stegun (2013).  These special functions have come to be used for many things and are now available at \n\nhttps://​dlmf​.nist​.gov \n\nOlver et al. (2010).","type":"content","url":"/next-9","position":1},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions"},"type":"lvl1","url":"/nonlinear","position":0},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions"},"content":"Collocation for nonlinear differential equations operates on the same principle as for linear problems: replace functions by vectors and replace derivatives by differentiation matrices. But because the differential equation is nonlinear, the resulting algebraic equations are as well. We will therefore need to use a quasi-Newton or similar method as part of the solution process.\n\nWe consider the TPBVP \n\n(10.1.1), reproduced here:\\begin{split}\nu''(x) &= \\phi(x,u,u'), \\qquad a \\le x \\le b,\\\\\ng_1(u(a),u'(a)) &= 0,\\\\\ng_2(u(b),u'(b)) &= 0.\n\\end{split}\n\nAs in \n\nCollocation for linear problems, the function u(x) is replaced by a vector \\mathbf{u} of its approximated values at nodes x_0,x_1,\\ldots,x_n (see Equation \n\n(10.4.2)). We define derivatives of the sampled function as in \n\n(10.4.3) and \n\n(10.4.4), using suitable differentiation matrices \\mathbf{D}_x and \\mathbf{D}_{xx}.\n\nThe collocation equations, ignoring boundary conditions for now, are\\mathbf{D}_{xx} \\mathbf{u} - \\mathbf{r}(\\mathbf{u}) = \\boldsymbol{0},\n\nwherer_i(\\mathbf{u}) = \\phi(x_i,u_i,u_i'), \\qquad i=0,\\ldots,n.\n\nand \\mathbf{u}'=\\mathbf{D}_x\\mathbf{u}.\n\nWe impose the boundary conditions in much the same way as in \n\nCollocation for linear problems. Again define the rectangular boundary removal matrix \\mathbf{E} as in \n\n(10.4.8), and replace the equations in those two rows by the boundary conditions:\\mathbf{f}(\\mathbf{u}) =\n  \\begin{bmatrix}\n    \\mathbf{E} \\bigl( \\mathbf{D}_{xx}\\mathbf{u}  - \\mathbf{r}(\\mathbf{u}) \\bigr) \\\\[1mm]\n    g_1(u_0,u_0') \\\\[1mm]\n    g_2(u_n,u_n')\n  \\end{bmatrix}\n  = \\boldsymbol{0}.\n\nThe left-hand side of \n\n(10.5.4) is a nonlinear function of the unknowns in the vector \\mathbf{u}, so \n\n(10.5.4) is an (n+1)\\times 1 set of nonlinear equations, amenable to solution by the techniques of \n\nChapter 4.\n\nGiven the BVPu'' - \\sin(xu) + \\exp(xu')=0, \\quad u(0)=-2, \\; u'(3/2)=1,\n\nwe compare to the standard form \n\n(10.5.1) and recognize\\phi(x,u,u') = \\sin(xu)-\\exp(xu').\n\nSuppose n=3 for an equispaced grid, so that h=\\frac{1}{2}, x_0=0, x_1=\\frac{1}{2}, x_2=1, and x_3=\\frac{3}{2}. There are four unknowns. We compute\\begin{gather*}\n  \\mathbf{D}_{xx} = \\frac{1}{1/4}\n  \\begin{bmatrix}\n    2    & -5   & 4   & -1    \\\\ \n    1    & -2   & 1   & 0     \\\\\n    0    & 1    & -2  & 1     \\\\ \n   -1    &  4   &  -5 & 2\n  \\end{bmatrix}, \\quad\n  \\mathbf{D}_x = \\frac{1}{1}\n  \\begin{bmatrix}\n    -3 & 4 & -1 & 0         \\\\\n    -1 & 0  & 1 & 0       \\\\\n    0  & -1 & 0  & 1     \\\\ \n    0 & 1 & -4 & 3\n  \\end{bmatrix},\t\n  \\\\[2mm]\n  \\mathbf{E} \\mathbf{r}(\\mathbf{u}) =\n  \\begin{bmatrix}\n    \\sin\\left(\\frac{u_1}{2}\\right) - \\exp\\left(\\frac{u_2-u_0}{2}\\right)      \\\\[1mm]\n    \\sin(u_2) - \\exp\\left( u_3-u_1 \\right) \n  \\end{bmatrix},\n  \\\\[2mm]\n  \\mathbf{f}(\\mathbf{u}) =\n  \\begin{bmatrix}\n    (4u_0 -8u_1 + 4u_2) - \\sin\\left(\\frac{u_1}{2}\\right) + \\exp\\left(\\frac{u_2-u_0}{2}\\right) \\\\[1mm]\n    (4u_1 -8u_2 + 4u_3) - \\sin(u_2) + \\exp\\left( u_3-u_1 \\right) \\\\[1mm]\n    u_0 + 2                                             \\\\[1mm]\n    (u_1 - 4u_2 + 3u_3) - 1\n  \\end{bmatrix}.\n\\end{gather*}","type":"content","url":"/nonlinear","position":1},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions","lvl2":"Implementation"},"type":"lvl2","url":"/nonlinear#implementation","position":2},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions","lvl2":"Implementation"},"content":"Our implementation using second-order finite differences is \n\nFunction 10.5.1. It’s surprisingly short, considering how general it is, because we have laid a lot of groundwork already.\n\nbvp\n\nSolution of a nonlinear boundary-value problem\n\n\"\"\"\n    bvplin(p, q, r, xspan, lval, rval, n)\n\nUse finite differences to solve a linear bopundary value problem.\nThe ODE is u''+`p`(x)u'+`q`(x)u = `r`(x) on the interval `xspan`,\nwith endpoint function values given as `lval` and `rval`. There will\nbe `n`+1 equally spaced nodes, including the endpoints.\n\nReturns vectors of the nodes and the solution values.\n\"\"\"\nfunction bvplin(p, q, r, xspan, lval, rval, n)\n    x, Dₓ, Dₓₓ = diffmat2(n, xspan)\n\n    P = diagm(p.(x))\n    Q = diagm(q.(x))\n    L = Dₓₓ + P * Dₓ + Q     # ODE expressed at the nodes\n\n    # Replace first and last rows using boundary conditions.\n    z = zeros(1, n)\n    A = [[1 z]; L[2:n, :]; [z 1]]\n    b = [lval; r.(x[2:n]); rval]\n\n    # Solve the system.\n    u = A \\ b\n    return x, u\nend\n\nAbout the code\n\nThe nested function residual uses differentiation matrices computed externally to it, rather than computing them anew on each invocation. As in \n\nFunction 10.4.1, there is no need to form the row-deletion matrix \\mathbf{E} explicitly. In lines 23--24, we divide the values of g_1 and g_2 by a factor of h. This helps scale the residual components more uniformly and improves the robustness of convergence a bit.\n\nSolution of a nonlinear boundary-value problem\n\n  function [x,u] = bvp(phi, a, b, ga, gb, init)\n%BVP      Solve a boundary-value problem by finite differences\n%         with either Dirichlet or Neumann BCs.\n% Input:\n%   phi      defines u'' = phi(x,u,u') (function)\n%   a, b     endpoints of the domain (scalars)\n%   ga       residual boundary function of u(a), u'(a) \n%   gb       residual boundary function of u(b), u'(b) \n%   init     initial guess for the solution (length n+1 vector)\n% Output:\n%   x        nodes in x (vector, length n+1)\n%   u        values of u(x)  (vector, length n+1)\n%   res      function for computing the residual\n\nn = length(init) - 1;\n[x, Dx, Dxx] = diffmat2(n, [a, b]);\nh = x(2) - x(1);\n\nu = levenberg(@residual, init);\nu = u(:, end);\n\n    function f = residual(u)\n        % Computes the difference between u'' and phi(x,u,u') at the\n        % interior nodes and appends the error at the boundaries. \n        du_dx = Dx*u;                   % discrete u'\n        d2u_dx2 = Dxx*u;                % discrete u''\n        f = d2u_dx2 - phi(x,u,du_dx);\n        \n        % Replace first and last values by boundary conditions.\n        f(1) =   ga(  u(1),   du_dx(1)) / h;\n        f(end) = gb(u(end), du_dx(end)) / h;\n    end\n\nend\n\nSolution of a nonlinear boundary-value problem\n\ndef bvp(phi, xspan, ga, gb, init):\n    \"\"\"\n    bvp(phi, xspan, ga, gb, init)\n\n    Use finite differences to solve a two-point boundary value problem. \n    The ODE is u'' = phi(x, u, u') for x in (a,b). The functions \n    ga(u(a), u'(a)) and gb(u(b), u'(b)) specify the boundary conditions. \n    The value init is an initial guess for [u(a), u'(a)].\n\n    Return vectors for the nodes and the values of u.\n    \"\"\"\n    n = len(init) - 1\n    x, Dx, Dxx = diffmat2(n, xspan)\n    h = x[1] - x[0]\n    def residual(u):\n        # Compute the difference between u'' and phi(x,u,u') at the\n        # interior nodes and appends the error at the boundaries.\n        du_dx = Dx @ u  # discrete u'\n        d2u_dx2 = Dxx @ u  # discrete u''\n        f = d2u_dx2 - phi(x, u, du_dx)\n\n        # Replace first and last values by boundary conditions.\n        f[0] = ga(u[0], du_dx[0]) / h\n        f[n] = gb(u[n], du_dx[n]) / h\n        return f\n\n    u = levenberg(residual, init.copy())\n    return x, u[-1]\n\nAbout the code\n\nThe nested function residual uses differentiation matrices computed externally to it, rather than computing them anew on each invocation. As in \n\nFunction 10.4.1, there is no need to form the row-deletion matrix \\mathbf{E} explicitly. In lines 23--24, we divide the values of g_1 and g_2 by a factor of h. This helps scale the residual components more uniformly and improves the robustness of convergence a bit.\n\nIn order to solve a particular problem, we must write a function that computes ϕ for vector-valued inputs \\mathbf{x}, \\mathbf{u}, and \\mathbf{u}', and functions for the boundary conditions. We also have to supply init, which is an estimate of the solution used to initialize the quasi-Newton iteration. Since this argument is a vector of length n+1, it sets the value of n in the discretization.\n\nBVP for a nonlinear pendulum\n\nSuppose a damped pendulum satisfies the nonlinear equation \\theta'' + 0.05\\theta'+\\sin \\theta =0. We want to start the pendulum at \\theta=2.5 and give it the right initial velocity so that it reaches \\theta=-2 at exactly t=5. This is a boundary-value problem with Dirichlet conditions \\theta(0)=2.5 and \\theta(5)=-2.\n\nExample 10.5.2\n\nThe first step is to define the function ϕ that equals \\theta''.\n\nϕ = (t, θ, ω) -> -0.05 * ω - sin(θ);\n\nNext, we define the boundary conditions.\n\ng₁(u, du) = u - 2.5\ng₂(u, du) = u + 2;\n\nThe last ingredient is an initial estimate of the solution. Here we choose n=100 and a linear function between the endpoint values.\n\nTip\n\nThe collect function turns a range object into a true vector.\n\ninit = collect(range(2.5, -2, length = 101));\n\nWe find a solution with negative initial slope, i.e., the pendulum is initially pushed back toward equilibrium.\n\nusing Plots\nt, θ = FNC.bvp(ϕ, [0, 5], g₁, g₂, init)\nplot(t, θ;\n    xaxis=(L\"t\"),  yaxis=(L\"\\theta(t)\"),\n    title=\"Pendulum over [0,5]\" )\n\nIf we extend the time interval longer for the same boundary values, then the initial slope must adjust.\n\nt, θ = FNC.bvp(ϕ, [0, 8], g₁, g₂, init)\nplot(t, θ;\n    xaxis=(L\"t\"),  yaxis=(L\"\\theta(t)\"),\n    title=\"Pendulum over [0,8]\" )\n\nThis time, the pendulum is initially pushed toward the unstable equilibrium in the upright vertical position before gravity pulls it back down.\n\nExample 10.5.2\n\nSuppose a damped pendulum satisfies the nonlinear equation \\theta'' + 0.05\\theta'+\\sin \\theta =0. We want to start the pendulum at \\theta=2.5 and give it the right initial velocity so that it reaches \\theta=-2 at exactly t=5. This is a boundary-value problem with Dirichlet conditions \\theta(0)=2.5 and \\theta(5)=-2.\n\nThe first step is to define the function ϕ that equals \\theta''.\n\nphi = @(t,theta,omega) -0.05 * omega - sin(theta);\n\nNext, we define the boundary conditions.\n\nga = @(u, du) u - 2.5;\ngb = @(u, du) u + 2;\n\nThe last ingredient is an initial estimate of the solution. Here we choose n=100 and a linear function between the endpoint values.\n\ninit = linspace(2.5, -2, 101)';\n\nWe find a solution with negative initial slope, i.e., the pendulum is initially pushed back toward equilibrium.\n\n[t, theta] = bvp(phi, 0, 5, ga, gb, init);\nclf,  plot(t, theta)\nxlabel('t'),  ylabel('\\theta(t)')\ntitle('Pendulum over [0,5]')\n\nIf we extend the time interval longer for the same boundary values, then the initial slope must adjust.\n\n[t, theta] = bvp(phi, 0, 8, ga, gb, init);\nplot(t,theta)\nxlabel('t'),  ylabel('\\theta(t)')\ntitle('Pendulum over [0,8]')\n\nThis time, the pendulum is initially pushed toward the unstable equilibrium in the upright vertical position before gravity pulls it back down.\n\nExample 10.5.2\n\nThe first step is to define the function ϕ that equals \\theta''.\n\nphi = lambda t, theta, omega: -0.05 * omega - sin(theta)\n\nNext, we define the boundary conditions.\n\nga = lambda u, du: u - 2.5\ngb = lambda u, du: u + 2\n\nThe last ingredient is an initial estimate of the solution. Here we choose n=100 and a linear function between the endpoint values.\n\ninit = linspace(2.5, -2, 101)\n\nWe find a solution with negative initial slope, i.e., the pendulum is initially pushed back toward equilibrium.\n\nt, theta = FNC.bvp(phi, [0, 5], ga, gb, init)\nplot(t, theta)\nxlabel(\"$t$\")\nylabel(\"$\\theta(t)$\")\ntitle(\"Pendulum over [0,5]\");\n\nIf we extend the time interval longer for the same boundary values, then the initial slope must adjust.\n\nt, theta = FNC.bvp(phi, [0, 8], ga, gb, init)\nplot(t, theta)\nxlabel(\"$t$\")\nylabel(\"$\\theta(t)$\")\ntitle(\"Pendulum over [0,8]\");\n\nThis time, the pendulum is initially pushed toward the unstable equilibrium in the upright vertical position before gravity pulls it back down.\n\nThe initial solution estimate can strongly influence how quickly a solution is found, or whether the quasi-Newton iteration converges at all. In situations where multiple solutions exist, the initialization can determine which is found.\n\nBVP for a nonlinear MEMS device\n\nWe look for a solution to the parameterized membrane deflection problem from \n\nExample 10.1.2,w''+ \\frac{1}{r}w'= \\frac{\\lambda}{w^2},\\quad w'(0)=0,\\; w(1)=1.\n\nExample 10.5.3\n\nHere is the problem definition. We use a truncated domain to avoid division by zero at r=0.\n\ndomain = [eps(), 1]\nλ = 0.5\nϕ = (r, w, dwdr) -> λ / w^2 - dwdr / r\ng₁(w, dw) = dw\ng₂(w, dw) = w - 1;\n\nFirst we try a constant function as the initialization.\n\ninit = ones(301)\nr, w₁ = FNC.bvp(ϕ, domain, g₁, g₂, init)\n\nplot(r, w₁;\n    xaxis = (L\"r\"),  yaxis = (L\"w(r)\"), \n    title = \"Solution of the MEMS problem\")\n\nIt’s not necessary that the initialization satisfy the boundary conditions. In fact, by choosing a different constant function as the initial guess, we arrive at another valid solution.\n\ninit = 0.5 * ones(301)\nr, w₂ = FNC.bvp(ϕ, domain, g₁, g₂, init)\nplot!(r, w₂, title = \"Two solutions of the MEMS problem\")\n\nExample 10.5.3\n\nHere is the problem definition. We use a truncated domain to avoid division by zero at r=0.\n\nlambda = 0.5;\nphi = @(r,w,dwdr) lambda./w.^2 - dwdr./r;\nga = @(w, dw) dw;\ngb = @(w, dw) w - 1;\na = eps;  b = 1;\n\nFirst we try a constant function as the initialization.\n\ninit = ones(301, 1);\n[r, w1] = bvp(phi, a, b, ga, gb, init);\n\nclf,  plot(r, w1)\nxlabel('r'),  ylabel('w(r)')\ntitle('Solution of the MEMS BVP')\n\nIt’s not necessary that the initialization satisfy the boundary conditions. In fact, by choosing a different constant function as the initial guess, we arrive at another valid solution.\n\ninit = 0.5 * ones(301, 1);\n[r, w2] = bvp(phi, a, b, ga, gb, init);\nhold on,  plot(r, w2)\ntitle(\"Two solutions of the MEMS BVP\")\n\nExample 10.5.3\n\nHere is the problem definition. We use a truncated domain to avoid division by zero at r=0.\n\nlamb = 0.5\nphi = lambda r, w, dwdr: lamb / w**2 - dwdr / r\na, b = finfo(float).eps, 1\nga = lambda w, dw: dw\ngb = lambda w, dw: w - 1\n\nFirst we try a constant function as the initialization.\n\ninit = ones(201)\nr, w1 = FNC.bvp(phi, [a, b], ga, gb, init)\nplot(r, w1)\nfig, ax = gcf(), gca()\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\")\ntitle(\"Solution of the MEMS problem\");\n\nIt’s not necessary that the initialization satisfy the boundary conditions. In fact, by choosing a different constant function as the initial guess, we arrive at another valid solution.\n\nr, w2 = FNC.bvp(phi, [a, b], ga, gb, 0.5 * init)\nax.plot(r, w2)\nax.set_title(\"Multiple solutions of the MEMS problem\");\nfig","type":"content","url":"/nonlinear#implementation","position":3},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions","lvl2":"Parameter continuation"},"type":"lvl2","url":"/nonlinear#parameter-continuation","position":4},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions","lvl2":"Parameter continuation"},"content":"Sometimes the best way to get a useful initialization is to use the solution of a related easier problem, a technique known as parameter continuation.  In this approach, one solves the problem at an easy parameter value, and gradually changes the parameter value to the desired value. After each change, the most recent solution is used to initialize the iteration at the new parameter value.\n\nAllen–Cahn equation\n\nWe solve the stationary Allen–Cahn equation,\\epsilon u'' = u^3-u, \\quad 0 \\le x \\le 1, \\quad u'(0)=0, \\; u(1)=1.\n\nExample 10.5.4\n\nϕ = (x, u, dudx) -> (u^3 - u) / ϵ;\ng₁(u, du) = du\ng₂(u, du) = u - 1;\n\nFinding a solution is easy at larger values of ε.\n\nϵ = 0.05\ninit = collect(range(-1, 1, length = 141))\nx, u₁ = FNC.bvp(ϕ, [0, 1], g₁, g₂, init)\n\nplot(x, u₁;\n    label=L\"\\epsilon = 0.05\",  legend=:bottomright,\n    xaxis=(L\"x\"),  yaxis=(L\"u(x)\"),\n    title = \"Allen–Cahn solution\")\n\nHowever, finding a good initialization is not trivial for smaller values of ε. Note below that the iteration stops without converging to a solution.\n\nϵ = 0.002;\nx, z = FNC.bvp(ϕ, [0, 1], g₁, g₂, init);\n\nThe iteration succeeds if we use the first solution instead as the initialization here.\n\nx, u₂ = FNC.bvp(ϕ, [0, 1], g₁, g₂, u₁)\nplot!(x, u₂; label = L\"\\epsilon = 0.002\")\n\nIn this case we can continue further.\n\nϵ = 0.0005\nx, u₃ = FNC.bvp(ϕ, [0, 1], g₁, g₂, u₂)\nplot!(x, u₃, label = L\"\\epsilon = 0.0005\")\n\nExample 10.5.4\n\nepsilon = 0.05;\nphi = @(x, u, du_dx) (u.^3 - u) / epsilon;\nga = @(u, du) du;\ngb = @(u, du) u - 1;\n\nFinding a solution is easy at larger values of ε.\n\ninit = linspace(-1, 1, 141)';\n[x, u1] = bvp(phi, 0, 1, ga, gb, init);\nclf,  plot(x, u1, displayname=\"\\epsilon = 0.05\")\nxlabel('x'),  ylabel('u(x)')\ntitle('Allen-Cahn solution') \nlegend(location=\"northwest\")\n\nHowever, finding a good initialization is not trivial for smaller values of ε. Note below that the iteration stops without converging to a solution.\n\nepsilon = 0.002;\nphi = @(x, u, du_dx) (u.^3 - u) / epsilon;\n[x, z] = bvp(phi, 0, 1, ga, gb, init);\n\nThe iteration succeeds if we use the first solution instead as the initialization here.\n\n[x, u2] = bvp(phi, 0, 1, ga, gb, u1);\nhold on,  plot(x, u2, displayname=\"\\epsilon = 0.002\")\n\nIn this case we can continue further.\n\nepsilon = 0.0005;\nphi = @(x, u, du_dx) (u.^3 - u) / epsilon;\n[x, u3] = bvp(phi, 0, 1, ga, gb, u2);\nplot(x, u3, displayname=\"\\epsilon = 0.0005\")\n\nExample 10.5.4\n\nphi = lambda x, u, dudx: (u**3 - u) / epsilon\nga = lambda u, du: du\ngb = lambda u, du: u - 1\n\nFinding a solution is easy at larger values of ε.\n\nepsilon = 0.05\ninit = linspace(-1, 1, 141)\nx, u1 = FNC.bvp(phi, [0, 1], ga, gb, init)\n\nplot(x, u1, label=\"$\\\\epsilon = 0.05$\")\nfig, ax = gcf(), gca()\nxlabel(\"$x$\"),  ylabel(\"$u(x)$\")\nlegend(),  title(\"Allen-Cahn solution\");\n\nFinding a good initialization is not trivial for smaller values of ε. But the iteration succeeds if we use the first solution as the initialization at the smaller ε.\n\nepsilon = 0.002\nx, u2 = FNC.bvp(phi, [0, 1], ga, gb, u1)\nax.plot(x, u2, label=\"$\\\\epsilon = 0.002$\")\nax.legend()\nfig\n\nIn this case we can continue further.\n\nϵ = 0.0005\nx, u3 = FNC.bvp(phi, [0, 1], ga, gb, u2)\nax.plot(x, u3, label=\"$\\\\epsilon = 0.005$\")\nax.legend()\nfig","type":"content","url":"/nonlinear#parameter-continuation","position":5},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions","lvl2":"Exercises"},"type":"lvl2","url":"/nonlinear#exercises","position":6},{"hierarchy":{"lvl1":"Nonlinearity and boundary conditions","lvl2":"Exercises"},"content":"✍ This exercise is about the nonlinear boundary-value problemu'' = \\frac{3(u')^2}{u} , \\quad u(-1) = 1, \\; u(2) = \\frac{1}{2}.\n\n(a) Verify that the exact solution is u(x) =  ( x+2 )^{-1/2}.\n\n(b) Write out the finite-difference approximation \n\n(10.5.4) with a single interior point (n=2).\n\n(c) Solve the equation of part (b) for the lone interior value u_1.\n\n⌨\n(a) Use \n\nFunction 10.5.1 to solve the problem of Exercise 1 for n=80. In a 2-by-1 subplot array, plot the finite-difference solution and its error.\n\n(b) ⌨ For each n=10,20,40,\\ldots,640, find the infinity norm of the error on the same problem. Make a log-log plot of error versus n and include a graphical comparison to second-order convergence.\n\n⌨ (Adapted from \n\nAscher & Petzold (1998).) Use \n\nFunction 10.5.1 twice with n=200 to solveu'' +  e^{u+0.5} = 0, \\quad y(0) = y(1) = 0,\n\nwith initializations 7 \\sin(x) and \\frac{1}{4} \\sin(x). Plot the solutions together on one graph.\n\n⌨ Use \n\nFunction 10.5.1 to compute the solution to the Allen–Cahn equation in \n\nDemo 10.5.4 with \\epsilon=0.02. Determine numerically whether it is antisymmetric around the line x=0.5---that is, whether u(1-x)=-u(x). You should supply evidence that your answer is independent of n.\n\n⌨ Consider the pendulum problem from \n\nExample 10.1.1 with g=L=1. Suppose we want to release the pendulum from rest such that \\theta(5)=\\pi/2. Use \n\nFunction 10.5.1 with n=200 to find one solution that passes through \\theta=0, and another solution that does not. Plot \\theta(t) for both cases together.\n\n⌨ The BVPu'' = x \\operatorname{sign}(1-x) u, \\quad u(-6)=1, \\; u'(6)=0,\n\nforces u'' to be discontinuous at x=1, so finite differences may not converge to the solution at their nominal order of accuracy.\n\n(a) Solve the problem using \n\nFunction 10.5.1 with n=1400, and make a plot of the solution. Store the value at x=6 for use as a reference high-accuracy solution.\n\n(b) For each n=100,200,300,\\ldots,1000, apply \n\nFunction 10.5.1, and compute the error at x=6. Compare the convergence graphically to second order.\n\n⌨  The following nonlinear BVP was proposed by Carrier (for the special case b=1 in \n\nCarrier (1970)):\\epsilon u'' + 2(1-x^2)u +u^2 = 1, \\quad u(-1) = u(1) = 0.\n\nIn order to balance the different components of the residual, it’s best to implement each boundary condition numerically as u/\\epsilon=0.\n\n(a) Use \n\nFunction 10.5.1 to solve the problem with \\epsilon=0.003, n=200, and an initial estimate of all zeros. Plot the result; you should get a solution with 9 local maxima.\n\n(b) Starting with the result from part (a) as an initialization, continue the parameter through the sequence\\epsilon = 3\\times 10^{-3}, 3\\times 10^{-2.8}, 3\\times 10^{-2.6},\\ldots, 3\\times 10^{-1}.\n\nThe most recent solution should be used as the initialization for each new value of ε. Plot the end result for \\epsilon=0.3; it should have one interior local maximum.\n\n(c) Starting with the last solution of part (b), reverse the continuation steps to return to \\epsilon=0.003. Plot the result, which is an entirely different solution from part (a).\n\n⌨  \n\nDemo 10.5.3 finds two solutions at \\lambda=0.5. Continue both solutions by taking 50 steps from \\lambda=0.5 to \\lambda=0.79. Make a plot with λ on the horizontal axis and w(0) on the vertical axis, with one point to represent each solution found. You should get two paths that converge as λ approaches 0.79 from below.","type":"content","url":"/nonlinear#exercises","position":7},{"hierarchy":{"lvl1":"10. Boundary-value problems"},"type":"lvl1","url":"/overview-9","position":0},{"hierarchy":{"lvl1":"10. Boundary-value problems"},"content":"Don’t shoot! Don’t shoot!\n\nC3PO, Star Wars: A New Hope\n\nIn \n\n6. Initial-value problems for ODEs we examined how to solve initial-value problems (IVP) for ordinary differential equations (ODEs). In an IVP the supplemental conditions give complete information about the state of the system at one value of the independent variable. However, not all ODE problems come in this form. Instead we might have only partial information about the solution at two different points. Such ODE problems are called boundary-value problems (BVP).\n\nWe begin with a numerical method that attempts to treat a BVP using IVP methods. It’s unstable, so we turn to numerical methods that find the solution everywhere simultaneously. One of these directly uses a discrete form of the ODE to express the computational problem, while another first restates the ODE in terms of integration. Both methods lead to algebraic systems of equations to be solved for the entire solution all at once, using the methods of \n\n2. Linear systems of equations and \n\n4. Roots of nonlinear equations.","type":"content","url":"/overview-9","position":1},{"hierarchy":{"lvl1":"Shooting"},"type":"lvl1","url":"/shooting","position":0},{"hierarchy":{"lvl1":"Shooting"},"content":"One way to attack the TPBVP \n\n(10.1.1) is to adapt our IVP solving techniques from \n\nChapter 6 to it. Those techniques work only when we know the entire initial state, but we can allow that state to vary in order to achieve the stated conditions.\n\nThis is the idea behind the shooting method. Imagine adjusting your aiming point and power to sink a basketball shot from the free-throw line. The way in which you miss—too long, flat trajectory, etc.—informs how you will adjust for your next attempt.\n\nNaive shooting\n\nExample 10.2.1\n\nLet’s first examine the shooting approach for the TPBVP from \n\nExample 10.1.2 with \\lambda=0.6.\n\nTip\n\nThe character ϕ is typed as \\phiTab.\n\nλ = 0.6\nϕ = (r, w, dwdr) -> λ / w^2 - dwdr / r;\n\nWe convert the ODE to a first-order system in order to apply a numerical method. We also have to truncate the domain to avoid division by zero.\n\nf = (y, p, r) -> [y[2]; ϕ(r, y[1], y[2])]\na, b = eps(), 1.0;\n\nThe BVP specifies w'(0)=y_2(0)=0. We can try multiple values for the unknown w(0)=y_1(0) and plot the solutions.\n\nusing OrdinaryDiffEq, Plots\nplt = plot(\n    xaxis = (L\"x\"),  yaxis = (L\"w(x)\"),\n    title = \"Different initial values\",  legend = :bottomright)\n\nfor w0 in 0.4:0.1:0.9\n    IVP = ODEProblem(f, [w0, 0], (a, b))\n    y = solve(IVP, Tsit5())\n    plot!(y, idxs = [1], label = \"w(0) = $w0\")\nend\nplt\n\nOn the graph, it’s the curve starting at w(0)=0.8 that comes closest to the required condition w(1)=1, but it’s a bit too large.\n\nExample 10.2.1\n\nLet’s first examine the shooting approach for the TPBVP from \n\nExample 10.1.2 with \\lambda=0.6.\n\nlambda = 0.6;\nphi = @(r, w, dwdr) lambda ./ w.^2 - dwdr ./ r;\n\nWe convert the ODE to a first-order system in order to apply a numerical method. We also have to truncate the domain to avoid division by zero.\n\nf = @(r, w) [ w(2); phi(r, w(1), w(2)) ];\na = eps;  b = 1;\n\nThe BVP specifies w'(0)=y_2(0)=0. We can try multiple values for the unknown w(0)=y_1(0) and plot the solutions.\n\nclf\nivp = ode;\nivp.ODEFcn = f;\nivp.InitialTime = a;\nfor w0 = 0.4:0.1:0.9\n    ivp.InitialValue = [w0; 0];\n    sol = solve(ivp, a, b);\n    plot(sol.Time, sol.Solution(1, :))\n    hold on\nend\nxlabel('r'),  ylabel('w(r)')\ntitle('Solutions for multiple choices of w(0)')\n\nOn the graph, it’s the curve starting at w(0)=0.8 that comes closest to the required condition w(1)=1, but it’s a bit too large.\n\nExample 10.2.1\n\nLet’s first examine the shooting approach for the TPBVP from \n\nExample 10.1.2 with \\lambda=0.6.\n\nlamb = 0.6\nphi = lambda r, w, dw_dr: lamb / w**2 - dw_dr / r\n\nWe convert the ODE to a first-order system in order to apply a numerical method. We also have to truncate the domain to avoid division by zero.\n\nf = lambda r, y: hstack([y[1], phi(r, y[0], y[1])])\na, b = finfo(float).eps, 1\n\nThe BVP specifies w'(0)=y_2(0)=0. We can try multiple values for the unknown w(0)=y_1(0) and plot the solutions.\n\nfrom scipy.integrate import solve_ivp\nt = linspace(a, b, 400)\nfor w0 in arange(0.4, 1.0, 0.1):\n    sol = solve_ivp(f, [a, b], [w0, 0], t_eval=t)\n    plot(t, sol.y[0], label=f\"$w_0$ = {w0:.1f}\")\n\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\")\nlegend(),  grid(True)\ntitle(\"Solutions for choices of w(0)\");\n\nOn the graph, it’s the curve starting at w(0)=0.8 that comes closest to the required condition w(1)=1, but it’s a bit too large.\n\nWe can do much better than trial-and-error for the unknown part of the initial state. As usual, we can rewrite the ODE u''(x) = \\phi(x,u,u') in first-order form as\\begin{split}\ny_1' &= y_2,\\\\ \ny_2' &= \\phi(x,y_1,y_2).\n\\end{split}\n\nWe turn this into an IVP by specifying y(a)=s_1, y'(a)=s_2, for a vector \\mathbf{s} to be determined by the boundary conditions. Define the residual function \\mathbf{v}(\\mathbf{s}) by\\begin{split}\nv_1(s_1,s_2) &= g_1(y_1(a),y_2(a)) = g_1(s_1,s_2),\\\\ \nv_2(s_1,s_2) &= g_2(y_1(b),y_2(b)).\n\\end{split}\n\nThe dependence of v_2 on \\mathbf{s} is indirect, through the solution of the IVP for \\mathbf{y}(x). We now have a standard rootfinding problem that can be solved via the methods of \n\nChapter 4.","type":"content","url":"/shooting","position":1},{"hierarchy":{"lvl1":"Shooting","lvl2":"Implementation"},"type":"lvl2","url":"/shooting#implementation","position":2},{"hierarchy":{"lvl1":"Shooting","lvl2":"Implementation"},"content":"Our implementation of shooting is given in \n\nFunction 10.2.1. Note the structure: we use a rootfinding method that in turn relies on an IVP solver. This sort of arrangement is what makes us concerned with minimizing the number of objective function calls when rootfinding.\n\nshoot\n\nShooting method for a two-point boundary-value problem\n\n\"\"\"\n    shoot(ϕ, xspan, g₁, g₂, init)\n\nShooting method to solve a two-point boundary value problem with\nODE u'' = `ϕ`(x, u, u') for x in `xspan`, left boundary condition\n`g₁`(u,u')=0, and right boundary condition `g₂`(u,u')=0. The\nvalue `init` is an initial estimate for vector [u,u'] at x=a.\n\nReturns vectors for the nodes, the solution u, and derivative u'.\n\"\"\"\nfunction shoot(ϕ, xspan, g₁, g₂, init, tol = 1e-5)\n    # ODE posed as a first-order equation in 2 variables.\n    shootivp = (v, p, x) -> [v[2]; ϕ(x, v[1], v[2])]\n\n    # Evaluate the difference between computed and target values at x=b.\n    function objective(s)\n        IVP = ODEProblem(shootivp, s, float.(xspan))\n        sol = solve(IVP, Tsit5(), abstol = tol / 10, reltol = tol / 10)\n        x = sol.t\n        y = sol\n        return [g₁(s...), g₂(y.u[end]...)]\n    end\n\n    # Find the unknown quantity at x=a by rootfinding.\n    x = []\n    y = []   # these values will be overwritten\n    s = levenberg(objective, init, xtol = tol)[:, end]\n\n    # Use the stored last solution of the IVP.\n    u, du_dx = y[1, :], y[2, :]\n    return x, u, du_dx\nend\n\nAbout the code\n\nBecause x and y are assigned empty values in line 24, when the function objective runs it uses those values rather than new ones in local scope. Thus, line 19 updates them to hold the latest results of the IVP solver, saving the need to solve it again after levenberg has finished the rootfinding.\n\nThe error tolerance in the IVP solver is kept smaller than in the rootfinder, to prevent the rootfinder from searching in a noisy landscape. Finally, note how line 28 uses destructuring of eachrow(y) to assign the columns of y to separate names.\n\nShooting method for a two-point boundary-value problem\n\nfunction [x, u, du_dx] = shoot(phi, a, b, ga, gb, init, tol)\r\n%SHOOT   Shooting method for a two-point boundary-value problem.\r\n% Input:\r\n%   phi      defines u'' = phi(x, u, u') (function)\r\n%   a, b     endpoints of the domain (scalars)\r\n%   ga       residual boundary function of u(a), u'(a) \r\n%   gb       residual boundary function of u(b), u'(b) \r\n%   init     initial guess for u(a) and u'(a) (column vector)\r\n%   tol      error tolerance (scalar)\r\n% Output:\r\n%   x        nodes in x (length n+1)\r\n%   u        values of u(x)  (length n+1)\r\n%   du_dx    values of u'(x) (length n+1)\r\n\r\n% To be solved by the IVP solver\r\nfunction f = shootivp(x, y)\r\n  f = [ y(2); phi(x, y(1), y(2)) ];\r\nend\r\n\r\nivp = ode(ODEFcn=@shootivp);\r\nivp.InitialTime = a;\r\nivp.AbsoluteTolerance = tol / 10;\r\nivp.RelativeTolerance = tol / 10;\r\n\r\n% To be solved by levenberg\r\nfunction residual = objective(s)\r\n  ivp.InitialValue = s;\r\n  sol = solve(ivp, a, b);\r\n  x = sol.Time;  y = sol.Solution;\r\n  residual = [ga(y(1, 1), y(2, 1)); gb(y(1, end), y(2, end))];\r\nend\r\n\r\ny = [];    % shared variable\r\ns = levenberg(@objective, init, tol);\r\n\r\n% Don't need to solve the IVP again. It was done within the\r\n% objective function already.\r\nu = y(1, :);            % solution     \r\ndu_dx = y(2, :);         % derivative\r\n\r\nend\n\nShooting method for a two-point boundary-value problem\n\ndef shoot(phi, a, b, ga, gb, init):\n    \"\"\"\n    shoot(phi, a, b, ga, gb, init)\n\n    Use the shooting method to solve a two-point boundary value problem. \n    The ODE is u'' = phi(x, u, u') for x in (a,b). The functions \n    ga(u(a), u'(a)) and gb(u(b), u'(b)) specify the boundary conditions. \n    The value init is an initial guess for [u(a), u'(a)].\n\n    Return vectors for the nodes, the values of u, and the values of u'.\n    \"\"\"\n\n    # Tolerances for IVP solver and rootfinder.\n    tol = 1e-5\n    # To be solved by the IVP solver\n    def shootivp(x, y):\n        return np.array([y[1], phi(x, y[0], y[1])])\n\n    # Evaluate the difference between computed and target values at x=b.\n    def objective(s):\n        nonlocal x, y  # change these values in outer scope\n\n        x = np.linspace(a, b, 400)  # make decent plots on return\n        sol = solve_ivp(shootivp, [a, b], s, atol=tol/10, rtol=tol/10, t_eval=x)\n        x = sol.t\n        y = sol.y\n        residual = np.array([ga(y[0, 0], y[1, 0]), gb(y[0, -1], y[0, -1])])\n        return residual\n\n    # Find the unknown quantity at x=a by rootfinding.\n    x, y = [], []    # the values will be overwritten\n    s = levenberg(objective, init, tol)\n\n    # Don't need to solve the IVP again. It was done within the\n    # objective function already.\n    u = y[0]        # solution\n    du_dx = y[1]    # derivative\n\n    return x, u, du_dx\n\nShooting solution of a BVP\n\nExample 10.2.2\n\nWe revisit \n\nDemo 10.2.1 but let \n\nFunction 10.2.1 do the heavy lifting.\n\nλ = 0.6\nϕ = (r, w, dwdr) -> λ / w^2 - dwdr / r;\na, b = eps(), 1.0;\n\nWe specify the given and unknown endpoint values.\n\ng₁(w, dw) = dw       # w' = 0 at left\ng₂(w, dw) = w - 1    # w = 1 at right\nr, w, dw_dx = FNC.shoot(ϕ, (a, b), g₁, g₂, [0.8, 0])\nplot(r, w, title = \"Shooting solution\", xaxis = (L\"x\"), yaxis = (L\"w(x)\"))\n\nThe value of w at r=1, meant to be exactly one, was computed to be\n\n@show w[end];\n\nThe accuracy is consistent with the error tolerance used for the IVP solution. The initial value w(0) that gave this solution is\n\n@show w[1];\n\nExample 10.2.2\n\nWe revisit \n\nDemo 10.2.1 but let \n\nFunction 10.2.1 do the heavy lifting.\n\nlambda = 0.6;\nphi = @(r, w, dwdr) lambda ./ w.^2 - dwdr ./ r;   \na = eps;  b = 1;    % avoid r=0 in denominator\n\nWe specify the given and unknown endpoint values.\n\nga = @(u, du) du;\ngb = @(u, du) u - 1;\n\ninit = [0.8; 0];    % initial guess for u(a) and u'(a)\n[r, w, dwdx] = shoot(phi, a, b, ga, gb, init, 1e-5);\nclf,  plot(r, w)\ntitle('Correct solution')\nxlabel('r'),  ylabel('w(r)')\n\nThe value of w at r=1, meant to be exactly one, was computed to be\n\nformat long\nw(end)\n\nThe accuracy is consistent with the error tolerance used for the IVP solution. The initial value w(0) that gave this solution is\n\nw(1)\n\nExample 10.2.2\n\nWe revisit \n\nDemo 10.2.1 but let \n\nFunction 10.2.1 do the heavy lifting.\n\nlamb = 0.6\nphi = lambda r, w, dwdr: lamb / w**2 - dwdr / r\na, b = finfo(float).eps, 1\n\nWe specify the given and unknown endpoint values.\n\nga = lambda w, dw : dw       # w'=0 at left\ngb = lambda w, dw : w - 1    # w=1 at right\n\nIn this setting, we need to provide initial guesses for w(a) and w'(a).\n\ninit = array([0.8, 0])\nr, w, dw_dx = FNC.shoot(phi, a, b, ga, gb, init)\nplot(r, w)\ntitle(\"Shooting solution\")\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\");\n\nThe value of w at r=1, meant to be exactly one, was computed to be\n\nprint(f\"w at right end is {w[-1]}\")\n\nThe accuracy is consistent with the error tolerance used for the IVP solution by shoot. The initial value w(0) that gave this solution is\n\nprint(f\"w at left end is {w[0]}\")","type":"content","url":"/shooting#implementation","position":3},{"hierarchy":{"lvl1":"Shooting","lvl2":"Instability"},"type":"lvl2","url":"/shooting#instability","position":4},{"hierarchy":{"lvl1":"Shooting","lvl2":"Instability"},"content":"The accuracy of the shooting method should be comparable to those of the component pieces, the rootfinder, and the IVP solver. However, the shooting method is unstable for some problems. An example illustrates the trouble.\n\nInstability of shooting\n\nWe solve the problemu'' = \\lambda^2 u + \\lambda^2, \\quad 0\\le x \\le 1, \\quad u(0)=-1,\\; u(1)=0.\n\nThe exact solution is easily confirmed to beu(x) = \\frac{\\sinh(\\lambda x)}{\\sinh(\\lambda)} - 1.\n\nThis solution satisfies -1\\le u(x) \\le 0 for all x\\in[0,1]. Now we compute shooting solutions for several values of λ.\n\nExample 10.2.3\n\nplt = plot(\n    xaxis = (L\"x\"),\n    yaxis = ([-1.2, 0.5], L\"u(x)\"),\n    title = \"Shooting instability\",\n    leg = :topleft,\n)\nfor λ in 6:4:18\n    g₁(u, du) = u + 1\n    g₂(u, du) = u\n    ϕ = (x, u, du_dx) -> λ^2 * (u + 1)\n    x, u = FNC.shoot(ϕ, (0.0, 1.0), g₁, g₂, [-1, 0])\n    plot!(x, u, label = \"λ=$λ\")\nend\nplt\n\nThe numerical solutions evidently don’t satisfy the right boundary condition as λ increases, which makes them invalid.\n\nExample 10.2.3\n\nga = @(u, du) u + 1;\ngb = @(u, du) u;\nclf\nwarning off\nfor lambda = 16:4:28\n    phi = @(x, u, du_dx) lambda^2 * (u + 1);\n    [x, u, du_dx] = shoot(phi, 0.0, 1.0, ga, gb, [-1; 0], 1e-8);\n    plot(x, u, displayname=sprintf(\"lambda=%d\", lambda))\n    hold on\n    xlabel('x'),  ylabel('u(x)')\n    title('Shooting instability')\n    legend(location=\"northwest\");\nend\n\nThe numerical solution fails at the largest value of λ because the initial condition became infinite.\n\nExample 10.2.3\n\nga = lambda u, du : u + 1    # u=-1 at left\ngb = lambda u, du : u        # u= 0 at right\ninit = array([-1, 0])\nfor lamb in range(6, 22, 4):\n    phi = lambda x, u, du_dx: lamb**2 * u + lamb**2\n    x, u, du_dx = FNC.shoot(phi, 0.0, 1.0, ga, gb, init)\n    plot(x, u, label=f\"$\\\\lambda$ = {lamb:.1f}\")\n\nxlabel(\"$x$\"),  ylabel(\"$u(x)$\"),  ylim(-1.0, 0.25)\ngrid(True),  legend(loc=\"upper left\")\ntitle(\"Shooting instability\");\n\nThe numerical solutions evidently don’t satisfy the right boundary condition as λ increases, which makes them invalid.\n\nThe cause is readily explained. The solution to the ODE with u(0)=-1 and u'(0)=s_2  is    \\frac{s_2}{\\lambda}\\sinh(\\lambda x) - 1.\n\nIf x is a fixed value in [0,1], we compute that the absolute condition number of \n\n(10.2.5) with respect to s_2 is the magnitude of the partial derivative,\\left| \\frac{\\sinh\\lambda x}{\\lambda} \\right|,\n\nwhich grows rapidly with λ near x=1. With the IVP solution so sensitive to s_2, a numerical approach to find s_2 approximately is doomed.\n\nThe essence of the instability is that errors can grow exponentially away from the boundary at x=a, where the state is arbitrarily being set (see \n\nTheorem 6.1.2). Using shooting, acceptable accuracy near x=b therefore means requiring extraordinarily high accuracy near x=a.\n\nThe instability of shooting can be circumvented by breaking the interval into smaller pieces and thus limiting the potential for error growth. However, we do not go into these details. Instead, the methods in the rest of this chapter treat both ends of the domain symmetrically and solve over the whole domain at once.","type":"content","url":"/shooting#instability","position":5},{"hierarchy":{"lvl1":"Shooting","lvl2":"Exercises"},"type":"lvl2","url":"/shooting#exercises","position":6},{"hierarchy":{"lvl1":"Shooting","lvl2":"Exercises"},"content":"⌨ For each BVP in \n\nExercise 10.1.2 , use \n\nFunction 10.2.1 to compute the solution. Plot the solution and, separately, its error as functions of x.\n\n⌨ (Continuation of \n\nExercise 10.1.4.) Consider the pendulum from \n\nExample 10.1.1 with g=L=1. Suppose we want to release the pendulum from rest such that \\theta(5)=\\pi/2. Find one solution that passes through \\theta=0, and another solution that does not. Plot \\theta(t) for both cases together.\n\n⌨  (Continuation of \n\nExercise 10.1.5.) The stationary Allen–Cahn equation is\\epsilon u'' = u^3-u, \\qquad 0 \\le x \\le 1, \\qquad u(0)=-1, \\quad u(1)=1.\n\nAs \\epsilon\\rightarrow 0, the solution tends toward a step function transition between -1 and 1. By symmetry, u'(x)=-u'(1-x).\n\n(a) Use \n\nFunction 10.2.1 to solve the equation for \\epsilon=0.2. Plot the solution and compute the numerical value of u'(0)-u'(1).\n\n(b) Repeat for \\epsilon=0.02.\n\n(c) Repeat for \\epsilon=0.002. You will receive multiple warning messages. Does the result look like a valid solution?\n\n✍ Consider the linear TPBVP\\begin{split}\n    u'' &= p(x)u' + q(x)u + r(x),\\\\ \n    u'(a) &= 0, \\quad u(b)=\\beta.\n    \\end{split}\n\nThe shooting IVP uses the same ODE with initial data u(a)=s_1, u'(a)=s_2 to solve for a trial solution u(x). Definez(x) = \\frac{\\partial u}{\\partial s_1}.\n\nBy differentiating the IVP with respect to s_1, show that z satisfies the IVPz'' = p(x)z' + q(x)z, \\quad z(0)=1, \\; z'(0)=0.\n\nIt follows that z(x) is independent of s_1, and therefore u(x) is a linear function of s_1 at each fixed x. Use the same type of argument to show that u(x) is also a linear function of s_2, and explain why the residual function \\mathbf{v} in \n\n(10.2.2) is a linear function of \\mathbf{s}.","type":"content","url":"/shooting#exercises","position":7},{"hierarchy":{"lvl1":"Two-point BVP"},"type":"lvl1","url":"/tpbvp","position":0},{"hierarchy":{"lvl1":"Two-point BVP"},"content":"The initial-value problems of \n\n6. Initial-value problems for ODEs are characterized by an ordinary differential equation plus a value of the solution’s state at one value of the independent variable.\n\nIn a boundary-value problem, the state is not entirely given at any point. Instead, partial information is given at multiple values of the independent variable. We will focus on the most common type.\n\nTwo-point boundary-value problem (TPBVP)\\begin{split}\nu''(x) &= \\phi(x,u,u'), \\qquad a \\le x \\le b,\\\\\ng_1(u(a),u'(a)) &= 0,\\\\\ng_2(u(b),u'(b)) &= 0.\n\\end{split}\n\nThis TPBVP is said to be linear if the dependence of ϕ, g_1, and g_2 on the solution u(x) is linear. Specifically, this means that\\phi(x,u,u')=p(x)u' + q(x)u + r(x)\n\nfor some coefficient functions p, q, and r, and g_1 and g_2 are linear in each of their arguments.\n\nOften the domain of x in \n\n(10.1.1) is not explicitly stated but is implied by the definitions of g_1 and g_2 These functions are called boundary conditions. An IVP for the same ODE as in \n\n(10.1.1) would specify values for both u(a) and u'(a). Although this may look like a minor change, IVPs and BVPs are quite different. Conceptually, the difference is like that between time and space. In a typical IVP, in which the independent variable is often time, the initial value determines everything about the future course of the solution. Even in a simple BVP, however, the necessary information is spread across the domain, and there may be more than one way to satisfy the boundary conditions.\n\nCertain special cases of the boundary conditions have their own nomenclature.\n\nDirichlet, Neumann, and Robin conditions\n\nLet g_i be a boundary condition in \n\n(10.1.1), and let \\alpha,\\beta be constants.\n\nDirichlet condition: g_i(u,u') = u - \\alpha\n\nNeumann condition: g_i(u,u') = u' - \\alpha\n\nRobin condition: g_i(u,u') = u + \\beta u' - \\alpha\n\nWhen \\alpha=0 in the above, the condition is said to be homogeneous.\n\nAn ideal pendulum of length L satisfies the ODE \\theta'' + \\frac{g}{L}\\sin \\theta = 0, where \\theta(t) is the angle of the pendulum’s rod from straight downward, and g is gravitational acceleration.\n\nIf we pull the pendulum bob 1 radian and release it from rest, then we have an IVP with the initial condition \\theta(0)=1, \\theta'(0)=0. Everything about the future trajectory of the pendulum is completely determined by that condition. But if instead we want to know how far to pull up the pendulum bob initially so that it is in the downward position 2 seconds later, then we have the Neumann boundary condition \\theta'(0)=0 and the Dirichlet boundary condition \\theta(2)=0.\n\nClearly, one solution is \\theta(0)=0, and the pendulum never moves! But there is also an initial deflection such that \\theta(2)=0 momentarily as the pendulum finishes its first downward swing. There could be still more solutions in which the pendulum completes one or more half-periods before passing again through the downward position at just the right moment.\n\nWhile time can be the independent variable in a TPBVP, as in \n\nExample 10.1.1, it is often space, which has no intrinsic direction of information flow.\n\nA micromechanical electrically driven actuator consists of two flat disk-shaped surfaces in parallel, one at z=0 and the other at z=1. The surface at z=0 is a rigid metal plate. The surface at z=1 is an elastic membrane fixed only at its boundary. When the surfaces are given different electric potentials, the membrane deflects in response to the induced electric field, and the field is also a position of the deflection. Assuming circular symmetry, one may derive the ordinary differential equation \n\nPelesko & Driscoll (2006)\\frac{d^2w}{d r^2} + \\frac{1}{r}\\, \\frac{d w}{d r} = \\frac{\\lambda}{w^2},\n\nwhere w(r) is the vertical position of the membrane at radius r, and λ is proportional to the applied electric potential. We will use 0\\le r\\le 1. There are also the supplemental physical conditionsw'(0)=0, \\qquad w(1)=1,\n\nderived from the circular symmetry and fixing the edge of the membrane, respectively. This is a nonlinear boundary-value problem. The solution should respect 0<w(r)\\le 1 in order to be physically meaningful.","type":"content","url":"/tpbvp","position":1},{"hierarchy":{"lvl1":"Two-point BVP","lvl2":"Numerical solution"},"type":"lvl2","url":"/tpbvp#numerical-solution","position":2},{"hierarchy":{"lvl1":"Two-point BVP","lvl2":"Numerical solution"},"content":"We can solve the TPBVP \n\n(10.1.1) by recasting the problem as a first-order system in the usual way.\n\nSolving a TPBVP\n\nAs a system, the MEMS problem from \n\nExample 10.1.2 uses y_1=w, y_2=w' to obtain\\begin{split}\ny_1' &= y_2, \\\\\ny_2' &= \\frac{\\lambda}{y_1^2} - \\frac{y_2}{r}.\n\\end{split}\n\nThis has the form \\mathbf{y}' = \\mathbf{f}(r,\\mathbf{y}). The boundary conditions are y_2(0)=0 and y_1(1)=1.\n\nExample 10.1.3\n\nAs a system, the MEMS problem from \n\nExample 10.1.2 uses y_1=w, y_2=w' to obtain\\begin{split}\ny_1' &= y_2, \\\\\ny_2' &= \\frac{\\lambda}{y_1^2} - \\frac{y_2}{r}.\n\\end{split}\n\nWe will code an in-place form of this ODE, in which the first argument is used to return the computed values of y_1' and y_2'.\n\nTip\n\nThe in-place code here saves the computing time that would otherwise be needed to allocate memory for f repeatedly.\n\nfunction ode!(f, y, λ, r)\n    f[1] = y[2]\n    f[2] = λ / y[1]^2 - y[2] / r\n    return nothing\nend;\n\nNotice that the return value is irrelevant with the in-place style. We use the same style for the boundary conditions y_2(0)=0, y_1(1)=1.\n\nfunction bc!(g, y, λ, r)\n    g[1] = y[1][2]          # first node, second component = 0\n    g[2] = y[end][1] - 1    # last node, first component = 1\n    return nothing\nend;\n\nIn the bc! function, the y argument is just like an IVP solution from \n\nBasics of IVPs. Thus, y(0) is the value of the solution at x=0, and the second component of that value is what we wish to make zero. Similarly, y(1)[1] is the notation for y_1(1), which is supposed to equal 1.\n\nThe domain of the mathematical problem is r\\in [0,1]. However, there is a division by r in the ODE, so we want to avoid r=0 by truncating the domain a bit.\n\ndomain = (eps(), 1.0)\n\nWe need one last ingredient that is not part of the mathematical setup: an initial estimate for the solution. As we will see, this plays the same role as initialization in Newton’s method for rootfinding. Here, we try a constant value for each component.\n\nest = [1, 0]\n\nNow we set up and solve a BVProblem with the parameter value \\lambda=0.6.\n\nusing BoundaryValueDiffEq, OrdinaryDiffEq, Plots\nbvp = BVProblem(ode!, bc!, est, domain, 0.6)\ny = solve(bvp, Shooting(Tsit5()))\nplot(y;\n    label = [L\"w\" L\"w'\"],\n    legend = :right,\n    xlabel = L\"r\",\n    ylabel = \"solution\",\n    title = \"Solution of MEMS problem for λ=0.6\",\n)\n\nTo visual accuracy, the boundary conditions have been enforced. We can check them numerically.\n\n@show y(0)[2];    # y_2(0)\n@show y(1)[1];    # y_1(1)\n\nExample 10.1.3\n\nTo define the BVP, we need to define some functions. (For this simple problem, we will use anonymous functions, but for a more substantial one, it would be better to use separate files.) The first defines \\mathbf{f}(x, \\mathbf{y}).\n\nlambda = 0.6;\nbvpfcn = @(r, y) [ y(2); lambda / y(1)^2 - y(2) / r  ];    % column vector\n\nOur second function defines the boundary conditions. It takes \\mathbf{y}(a) and \\mathbf{y}(b) as arguments and returns a vector of residuals; i.e., values that should be zero when the boundary conditions are satisfied.\n\nbcfcn = @(ya, yb) [ ya(2); yb(1) - 1 ];    % y_2(a) = 0;  y_1(b) = 1\n\nThe third function we define isn’t part of the mathematical formulation. Rather, it provides an initial guess for the solution. Here we choose both components to be constant.\n\ny_init = @(r) [ 1; 0 ];\n\nNow we can solve the BVP using the bvp4c function. We need to specify the nodes on which to solve the problem. The domain of the mathematical problem is r\\in [0,1].But since there is a division by r in the ODE, we want to avoid r=0 by truncating the domain a tiny bit.\n\nnodes = linspace(eps, 1, 61);\nsol_init = bvpinit(nodes, y_init);\nsol = bvp4c(bvpfcn, bcfcn, sol_init);\nplot(sol.x, sol.y, '-o')\nxlabel('r'), ylabel('y(r)')\ntitle('Solution of the membrane problem')\nlegend(\"w(r)\", \"w'(r)\", location=\"east\");\n\nIt’s smart to check visually that the boundary conditions are satisfied.\n\nExample 10.1.3\n\nTo solve this problem, we have to define functions for the ODE and boundary conditions. The first returns the computed values of y_1' and y_2'.\n\nlamb = 0.6\ndef ode(r, y):\n    return array([\n        y[1],\n        lamb / y[0]**2 - y[1] / r\n    ])\n\nTo encode the boundary conditions y_2(0)=0, y_1(2)=1, we define a function for their residual values.\n\ndef bc(ya, yb):    # given y(a), y(b)\n    return array([\n        ya[1],\n        yb[0] - 1\n    ])\n\nThe domain of the mathematical problem is r\\in [0,1]. However, there is a division by r in the ODE, so we want to avoid r=0 by truncating the domain a bit.\n\na, b = finfo(float).eps, 1\n\nWe need one last ingredient that is not part of the mathematical setup: an initial estimate for the solution. As we will see, this plays the same role as initialization in Newton’s method for rootfinding. Here, we try a constant value for each component.\n\nr = linspace(a, b, 50)\ny_init = vstack([ones(r.size), zeros(r.size)])\n\nNow we can solve the problem using solve_bvp from scipy.integrate.\n\nfrom scipy.integrate import solve_bvp\nsol = solve_bvp(ode, bc, r, y_init)\nprint(f\"Solved at {sol.x.size} nodes.\")\nplot(sol.x, sol.y[0])\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\")\ntitle(\"Solution of MEMS problem for $\\\\lambda=0.6$\");\n\nCharacterizing the conditioning of a TPBVP theoretically is difficult. There are some numerical tools going by the name  sensitivity analysis, but the details are too lengthy for us to explore here.","type":"content","url":"/tpbvp#numerical-solution","position":3},{"hierarchy":{"lvl1":"Two-point BVP","lvl2":"Exercises"},"type":"lvl2","url":"/tpbvp#exercises","position":4},{"hierarchy":{"lvl1":"Two-point BVP","lvl2":"Exercises"},"content":"✍ In each case, explain whether the TPBVP is linear or nonlinear.\n\n(a) x^2 u'' +xu' + (x^2 - 1) u = 0, \\quad u(0) =1,\\; u(4) =0 \\qquad (Bessel equation)\n\n(b) u'' - u u' = 1, \\quad u(0) = u'(1) = 1\n\n(c) u'' + u = 1, \\quad u(0) = u(1) u'(1) = 1\n\n(d) \\epsilon u'' +2(1-x^2) u +u^2  = 1, \\quad u(-1) = u(1) = 0 \\qquad (Carrier equation \n\nCarrier (1970))\n\n(e) u u'' = 3(u')^2, \\quad u(-1) = 1, \\; u(2) = \\frac{1}{2}\n\n✍ For each BVP, verify that the given solution is valid, i.e., check that the differential equation and the boundary conditions are satisfied.\n\n(a) u'' - 2xu' + 8 u = 0, \\quad u(0) = 1, \\; u(1) = -\\frac{5}{3}\\qquad (Hermite equation)\n\nSolution: u(x) = \\frac{4}{3}x^4-4x^2+1\n\n(b) xu'' + (1-x) u' + 3 u = 0, \\quad u(0) =1, \\; u'(1) =-\\frac{1}{2} \\qquad (Laguerre equation)\n\nSolution: u(x) = \\frac{1}{6}(6-18x+9x^2-x^3)\n\n(c) (1-x^2)u'' - xu' + 25u = 0, \\quad u'(0) = 5, \\; u\\left(\\frac{1}{2}\\right) = \\frac{1}{2} \\qquad (Chebyshev equation)\n\nSolution: u(x) = T_5(x) = 16x^5-20x^3+5x\n\n(d) (1-x^2) u'' -2xu' + 12 u = 0, \\quad u(0)+2u'(0) = -3, \\; u(1) = 1 \\qquad (Legendre equation)\n\nSolution: u(x) = P_3(x) = \\frac{1}{2}(5x^3-3x)\n\n(e) u u'' = 3(u')^2, \\quad u(-1) = 1, \\; u(2) = \\frac{1}{2}\n\nSolution: u(x) =  ( x+2 )^{-1/2}\n\n⌨ For each TPBVP in Exercise 2, use solve to find the solution. Plot the solution and separately plot the error as a function of x. (In some cases you will need to truncate the domain to avoid division by zero.)\n\n⌨ Consider the pendulum from \n\nExample 10.1.1 with g=L=1. Suppose we want to release the pendulum from rest such that \\theta(5)=\\pi/2. Find one solution that passes through \\theta=0 and another solution that does not. Plot \\theta(t) for both cases together. (Hint: Vary the initial estimate for the solution.)\n\n⌨  The stationary Allen–Cahn equation is a model of phase changes, such as the change from liquid to solid. In one spatial dimension it can be written as\\epsilon u'' = u^3-u, \\qquad 0 \\le x \\le 1, \\qquad u(0)=-1, \\quad u(1)=1.\n\nAs \\epsilon\\rightarrow 0, the solution tends toward a step function transition between -1 and 1. By symmetry, u'(x)=-u'(1-x).\n\n(a) Use \n\nFunction 10.2.1 with initial solution estimates (u=-1,u'=0) to solve the equation for \\epsilon=0.2. Plot the solution.\n\n(b) Repeat part (a) for \\epsilon=0.02.\n\n(c) Repeat part (a) for \\epsilon=0.002. (This is a difficult problem for the default method.) Try a few different initializations for u, and plot all the results. Do any seem to be valid solutions of the BVP?","type":"content","url":"/tpbvp#exercises","position":5},{"hierarchy":{"lvl1":"Absolute stability"},"type":"lvl1","url":"/absstab-diffusion","position":0},{"hierarchy":{"lvl1":"Absolute stability"},"content":"In \n\nThe method of lines we applied several different time stepping methods to a linear, constant coefficient problem in the form\\mathbf{u}'(t)=\\mathbf{A}\\mathbf{u}(t).\n\nAll of these methods are zero-stable in the sense of \n\nZero-stability of multistep methods, in the limit as the time step size \\tau \\to 0. Yet for some experiments with fixed τ, as in \n\nDemo 11.2.2, we have observed exponential growth in the different limit n\\to \\infty.\n\nObserve that if \\mathbf{A} has the eigenvalue decomposition \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1}, then\\begin{align*}\n  \\mathbf{u}'&=(\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1})\\mathbf{u},\\\\\n  (\\mathbf{V}^{-1} \\mathbf{u}') &= \\mathbf{D} (\\mathbf{V}^{-1} \\mathbf{u}), \\\\\n  \\mathbf{y}' &= \\mathbf{D} \\mathbf{y},\n\\end{align*}\n\nwhere \\mathbf{y}(t)=\\mathbf{V}^{-1}\\mathbf{u}(t). Because \\mathbf{D} is diagonal, the dynamics of the components of \\mathbf{y} are completely decoupled: each row is a self-contained equation of the form y_j'=\\lambda_j y_j, where \\lambda_j is an eigenvalue of \\mathbf{A}.\n\nThe diagonalization argument suggests that we can look at the scalar problemsy' = \\lambda y, \\quad y(0)=1,\n\narising from the eigenvalues. These eigenvalues may not be real numbers, so in this section, i stands for the imaginary unit, not an integer index. If we write λ in real and imaginary parts as \\lambda=\\alpha + i\\beta, then by Euler’s identity, the exact solution of \n\n(11.3.3) has magnitude\\bigl |e^{(\\alpha+i\\beta)t} \\bigr| = \\bigl |e^{\\alpha t} \\bigr| \\cdot \\bigl |e^{i \\beta t} \\bigr| = e^{\\alpha t}.\n\nSolutions of \n\n(11.3.3) are bounded as t\\to\\infty if and only if \\alpha = \\operatorname{Re} \\lambda \\le 0.\n\nWe now consider the counterpart of this observation for the solution produced by a numerical IVP solver.\n\nAbsolute stability\n\nLet λ be a complex number, and let y_0,y_1,y_2,\\ldots,y_n be the numerical solution at times 0,\\tau,2\\tau,\\ldots,n\\tau of \n\n(11.3.3) using a Runge–Kutta or multistep method with fixed stepsize τ. Then the method is said to be absolutely stable at \\zeta = \\tau\\lambda if |y_n| is bounded above as n\\to\\infty.\n\nThe fact that absolute stability depends only on the product \\zeta = \\tau\\lambda, and not independently on the individual factors, is a result of how the IVP solvers are defined, as we will see below. Since λ has units of inverse time according to \n\n(11.3.3), ζ is dimensionless.","type":"content","url":"/absstab-diffusion","position":1},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Stability regions"},"type":"lvl2","url":"/absstab-diffusion#stability-regions","position":2},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Stability regions"},"content":"Each numerical IVP solver has its own collection of ζ values for which it is absolutely stable.\n\nStability region\n\nThe stability region of an IVP solver is the collection of all \\zeta\\in\\complex for which the method is absolutely stable.\n\nConsider an Euler discretization of y'=\\lambda y:y_{k+1} = y_k + \\tau( \\lambda y_k) =   (1+ \\zeta ) y_k.\n\nGiven that y_0=1 by \n\n(11.3.3), we easily deduce that y_k = (1+\\zeta)^k for all k, and therefore|y_k| = |1+\\zeta|^k.\n\nHence |y_k| remains bounded above as k\\to \\infty if and only if |1+\\zeta| \\le 1. Because ζ is a complex number, it’s easiest to interpret this condition geometrically:|\\zeta + 1 | = |\\zeta - (-1) | \\le 1.\n\nThat is, the distance in the plane from ζ to the point -1 is less than or equal to 1. This description defines a closed disk of radius 1 centered at (-1,0).\n\nThe backward Euler method discretizes \n\n(11.3.3) asy_{k+1} = y_k + \\tau( \\lambda y_{k+1}) \\quad \\Rightarrow \\quad y_{k+1} =  \\frac{1}{1-\\zeta} y_k.\n\nTherefore, y_k=(1-\\zeta)^{-k} for all k, and absolute stability requires |1-\\zeta|^{-1} \\le 1, or|\\zeta-1|\\ge 1.\n\nThis inequality describes the region outside of the open disk of radius 1 centered at 1 on the real axis of the complex plane.\n\nThe improved Euler method IE2 defined in \n\n(6.4.6) discretizes \n\n(11.3.3) as{y}_{i+1} = y_i +  \\zeta \\left( y_i + \\tfrac{1}{2}\\zeta y_i \\right) = (1 + \\zeta + \\tfrac{1}{2}\\zeta^2) y_i.\n\nThe stability region consists of all ζ such that | 1 + \\zeta + \\tfrac{1}{2}\\zeta^2 | \\le 1. Although it is not elementary to describe this region geometrically, its boundary points satisfy1 - e^{i\\theta} + \\zeta + \\tfrac{1}{2}\\zeta^2 = 0\n\nfor some real θ, and thus we can use the quadratic formula to find all the boundary points.\n\nStability regions for the most common IVP integrators are given in \n\nFigure 11.3.1 and \n\nFigure 11.3.2.  Note that those for the implicit Adams-Moulton methods are larger than those for the explicit Adams-Bashforth methods of the same order.  For the implicit backward differentiation methods, the exteriors of the curves provide large regions of stability, but significant portions of the imaginary axis may be excluded.  Finally, while the single-step Runge-Kutta methods have smaller regions of stability, those of orders 3 and 4 do include significant portions of the imaginary axis.\n\n\n\nFigure 11.3.1:Stability regions for Adams–Bashforth methods of order 1–4 (left) and Adams–Moulton methods of order 2–5 (right). The plots are in the complex ζ-plane.\n\n\n\nFigure 11.3.2:Stability regions for backward differentiation methods of order 1–4 (left, exteriors of curves) and Runge–Kutta methods of order 1–4 (right). The plots are in the complex ζ-plane.\n\nFor any particular method and value of λ in \n\n(11.3.3), we can use the stability region to deduce which, if any, values of the time step τ will give bounded solutions. Both the magnitude and the argument (angle) of λ play a role in determining such constraints.\n\nSuppose \\lambda=-4 and Euler’s method is applied. Since the time step is always positive, \\zeta=-4\\tau is always on the negative real axis. The only part of that line that lies within the stability region of Euler as derived in \n\nExample 11.3.1 is the real interval [-2,0]. Hence we require \\zeta\\ge -2, or \\tau \\le 1/2. By contrast, the stability region of backward Euler includes the entire negative real axis, so absolute stability is unconditional, i.e., assured regardless of τ.\n\nNow suppose instead that \\lambda=i, so that \\zeta=i\\tau. Clearly ζ is always on the positive imaginary axis. But no part of this axis, aside from the origin, lies in the stability region of Euler’s method, so it is unconditionally unstable in this circumstance. The conclusion for backward Euler is the opposite; any value of τ will do, because the entire imaginary axis is within the stability region.\n\nExample 11.3.4 does not contradict our earlier statements about the zero stability and convergence of Euler’s method in general, even for the case \\lambda=i. But those statements are based on the limit \\tau\\to 0 for t in a finite interval [a,b]. Both this limit and the limit t\\to \\infty imply the number of steps n goes to infinity, but the limits behave differently.\n\nThe fact that implicit methods have larger stability regions than their explicit counterparts is the primary justification for using them. While they have larger work requirements per step, they sometimes can take steps that are orders of magnitude larger than explicit methods and still remain stable.\n\nWhen adaptive time stepping methods are used, as in most software for IVPs, the automatically determined time step is chosen to satisfy absolute stability requirements (otherwise errors grow exponentially). This phenomenon was manifested in \n\nDemo 11.2.5: in the explicit IVP method rk23, error control forced tiny step sizes compared to those used by Rodas4P, which is based on implicit methods.","type":"content","url":"/absstab-diffusion#stability-regions","position":3},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Heat equation"},"type":"lvl2","url":"/absstab-diffusion#heat-equation","position":4},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Heat equation"},"content":"Now we return to the semidiscretization \n\n(11.2.5) of the heat equation, which was solved by Euler in \n\nDemo 11.2.2 and backward Euler in \n\nDemo 11.2.4.\n\nStability regions and the heat equation\n\nExample 11.3.5\n\nEuler and Backward Euler time-stepping methods were used to solve \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nm = 40\n_, _, Dₓₓ = FNC.diffper(m, [0, 1]);\n\nThe eigenvalues of this matrix are real and negative:\n\nusing Plots\nλ = eigvals(Dₓₓ)\nscatter(real(λ), imag(λ);\n    title=\"Eigenvalues\",\n    frame=:zerolines,  aspect_ratio=1,\n    xaxis=(\"Re λ\"),  yaxis=(\"Im λ\", (-1000, 1000)))\n\nThe Euler method is absolutely stable in the region |\\zeta+1| \\le 1 in the complex plane:\n\nphi = 2π * (0:360) / 360\nz = @. cis(phi) - 1;    # unit circle shifted to the left by 1\n\nplot(Shape(real(z), imag(z));\n    color=RGB(.8, .8, 1),\n    xaxis=(\"Re ζ\"),  yaxis=(\"Im ζ\"),\n    aspect_ratio=1,  frame=:zerolines,\n    title=\"Stability region\")\n\nIn order to get inside this region, we have to find τ such that \\lambda \\tau > -2 for all eigenvalues λ. This is an upper bound on τ.\n\nλ_min = minimum(λ)\n@show max_τ = -2 / λ_min;\n\nHere we plot the resulting values of \\zeta=\\lambda \\tau.\n\nζ = λ * max_τ\nscatter!(real(ζ), imag(ζ), title=\"Stability region and ζ values\")\n\nIn backward Euler, the region is |\\zeta-1|\\ge 1. Because they are all on the negative real axis, all of the ζ values will fit no matter what τ is chosen.\n\nplot(Shape([-6, 6, 6, -6], [-6, -6, 6, 6]), color=RGB(.8, .8, 1))\nz = @. cis(phi) + 1;   # unit circle shifted right by 1\nplot!(Shape(real(z), imag(z)), color=:white)\n\nscatter!(real(ζ), imag(ζ);\n    xaxis=([-4, 2], \"Re ζ\"),  yaxis=([-3, 3], \"Im ζ\"),\n    aspect_ratio=1,  frame=:zerolines,\n    title=\"Stability region and ζ values\")\n\nExample 11.3.5\n\nEuler and Backward Euler time-stepping methods were used to solve \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nm = 40;  \n[x, Dx, Dxx] = diffper(m, [0, 1]);\n\nThe eigenvalues of this matrix are real and negative:\n\nlambda = eig(Dxx);\nclf\nplot(real(lambda), imag(lambda), 'o')\naxis equal, grid on\nxlabel('Re \\lambda'),  ylabel('Im \\lambda')\ntitle('Eigenvalues')\n\nThe Euler method is absolutely stable in the region |\\zeta+1| \\le 1 in the complex plane:\n\nphi = linspace(0, 2*pi, 361);\nz = exp(1i*phi) - 1;   % unit circle shifted to the left by 1\nfill(real(z), imag(z), [.8, .8, 1])\naxis equal,  grid on\nxlabel('Re \\lambda'),  ylabel('Im \\lambda')\ntitle('Stability region')\n\nIn order to get inside this region, we have to find τ such that \\lambda \\tau > -2 for all eigenvalues λ. This is an upper bound on τ.\n\nlambda_min = min(lambda)\nmax_tau = -2 / lambda_min\n\nHere we plot the resulting values of \\zeta=\\lambda \\tau.\n\nzeta = lambda * max_tau;\nhold on\nplot(real(zeta), imag(zeta), 'o')\ntitle('Stability region and \\zeta values')\n\nIn backward Euler, the region is |\\zeta-1|\\ge 1. Because they are all on the negative real axis, all of the ζ values will fit no matter what τ is chosen.\n\nclf,  fill([-6, 6, 6, -6],[-6, -6, 6, 6],[.8, .8, 1])\nhold on\nz = exp(1i*phi) + 1;   % unit circle shifted right by 1\nfill(real(z), imag(z), 'w')\nplot(real(zeta), imag(zeta), 'o')\naxis equal,  axis([-4, 2, -3, 3]), grid on\nxlabel('Re \\lambda'),  ylabel('Im \\lambda')\ntitle('Stability region and \\zeta values')\n\nExample 11.3.5\n\nEuler and Backward Euler time-stepping methods were used to solve \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nm = 40\nDxx = FNC.diffper(m, [0, 1])[2]\n\nThe eigenvalues of this matrix are real and negative:\n\nfrom scipy.linalg import eigvals\nlamb = eigvals(Dxx)\nplot(real(lamb), imag(lamb), \"o\")\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\ntitle(\"Eigenvalues\");\n\nThe Euler method is absolutely stable in the region |\\zeta+1| \\le 1 in the complex plane:\n\nphi = 2 * pi * arange(361) / 360\nz = exp(1j * phi) - 1  # unit circle shifted to the left by 1\n\nfill(real(z), imag(z), color=(0.8, 0.8, 1))\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\naxis(\"equal\")\ntitle(\"Stability region\");\n\nIn order to get inside this region, we have to find τ such that \\lambda \\tau > -2 for all eigenvalues λ. This is an upper bound on τ.\n\nlambda_min = min(real(lamb))\nmax_tau = -2 / lambda_min\nprint(f\"predicted max time step is {max_tau:.3e}\")\n\nHere we plot the resulting values of \\zeta=\\lambda \\tau.\n\nzeta = lamb * max_tau\nfill(real(z), imag(z), color=(0.8, 0.8, 1))\nplot(real(zeta), imag(zeta), \"o\")\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\naxis(\"equal\")\ntitle(\"Stability region and $\\zeta$ values\");\n\nIn backward Euler, the region is |\\zeta-1|\\ge 1. Because they are all on the negative real axis, all of the ζ values will fit no matter what τ is chosen.\n\nfill([-6, 6, 6, -6], [-6, -6, 6, 6], color=(0.8, 0.8, 1))\nz = exp(1j * phi) + 1\n# unit circle shifted right by 1\nfill(real(z), imag(z), color=\"w\")\n\nplot(real(zeta), imag(zeta), \"o\")\naxis([-4, 2, -3, 3])\naxis(\"equal\")\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\ntitle(\"Stability region and $\\\\zeta$ values\");\n\nThe matrix \\mathbf{D}_{xx} occurring in \n\n(11.2.5) for semidiscretization of the periodic heat equation has eigenvalues that can be found explicitly. Assuming that x\\in[0,1) (with periodic boundary conditions), for which h=1/m, then the eigenvalues are\\lambda_j =  -4m^2 \\sin^2 \\left( \\frac{j\\pi}{m} \\right), \\qquad j = 0,\\ldots,m-1.\n\nThis result agrees with the observation in \n\nDemo 11.3.5 that the eigenvalues are real and negative. Furthermore, they lie within the interval [-4m^2,0]. In Euler time integration, this implies that -4\\tau m^2\\ge -2, or \\tau\\ge 1/(2m^2)=O(m^{-2}). For backward Euler, there is no time step restriction, and we say that backward Euler is unconditionally stable for this problem.\n\nIn summary, three things happen as h\\to 0:\n\nThe spatial discretization becomes more accurate like O(h^2).\n\nThe size of the matrix increases like O(h^{-1}).\n\nIf we use an explicit time stepping method, then absolute stability requires O(h^{-2}) steps.\n\nThe last restriction becomes rather burdensome as h\\to 0, i.e., as we improve the spatial discretization, which is why implicit methods are preferred for diffusion. While any convergent IVP solver will get the right solution as \\tau\\to 0, the results are exponentially large nonsense until τ is small enough to satisfy absolute stability.","type":"content","url":"/absstab-diffusion#heat-equation","position":5},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Exercises"},"type":"lvl2","url":"/absstab-diffusion#exercises","position":6},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Exercises"},"content":"✍ Use an eigenvalue decomposition to write the system\\mathbf{u}'(t) =\n    \\begin{bmatrix}\n      0 & 4 \\\\\n      -4 & 0\n    \\end{bmatrix} \\mathbf{u}(t)\n\nas an equivalent diagonal system.\n\n✍ For each system, state whether its solutions are bounded as t\\to \\infty.\n\n(a) \\mathbf{u}'(t) =\n \\displaystyle \\begin{bmatrix}\n   1 & 3 \\\\\n   3 & 1\n \\end{bmatrix} \\mathbf{u}(t)\n\n(b) \\mathbf{u}'(t) =\n \\displaystyle \\begin{bmatrix}\n   -1 & 3 \\\\\n   -3 & -1\n \\end{bmatrix} \\mathbf{u}(t)\n\n(c) \\mathbf{u}'(t) =\n \\displaystyle \\begin{bmatrix}\n   0 & 4 \\\\\n   -4 & 0\n \\end{bmatrix} \\mathbf{u}(t)\n\n✍ Using \n\nFigure 11.3.1 and \n\nFigure 11.3.2, estimate the time step restriction (if any) for the system\\mathbf{u}'(t) =\n    \\begin{bmatrix}\n      -4 & 0 & 0 \\\\\n      0 & -2 & 0 \\\\\n      0 & 0 & -0.5\n    \\end{bmatrix} \\mathbf{u}(t)\n\nfor the following IVP methods:\n\n(a) RK4 \\qquad\n(b) AM4 \\qquad\n(c) AB2\n\n✍ Using \n\nFigure 11.3.1 and \n\nFigure 11.3.2, find the time step restriction (if any) for the system\\mathbf{u}'(t) =\n    \\begin{bmatrix}\n      -1 & 0 & 0 \\\\\n      0 & 0 & 4 \\\\\n      0 & -4 & 0\n    \\end{bmatrix} \\mathbf{u}(t)\n\nfor the following IVP methods:\n\n(a) RK4 \\qquad\n(b) AM4 \\qquad\n(c) AB3\n\n✍ Of the following methods, which would be unsuitable for a problem having eigenvalues on the imaginary axis?  Justify your answer(s).\n\n(a) AM2 \\qquad\n(b) AB2 \\qquad\n(c) RK2 \\qquad\n(d) RK3\n\n✍ Of the following methods, which would have a time step restriction for a problem with real, negative eigenvalues?  Justify your answer(s).\n\n(a) AM2 \\qquad\n(b) AM4 \\qquad\n(c) BD4 \\qquad\n(d) RK4\n\n✍ Let \\mathbf{D}_{xx} be m\\times m and given by \n\n(11.2.4). For any integer k \\in \\{0,\\ldots,m-1\\}, define \\omega = \\exp(2i k\\pi/m) and \\mathbf{v} = \\bigl[ 1,\\; \\omega,\\; \\omega^2,\\; \\ldots,\\; \\omega^{m-1} \\bigr]. Show that \\mathbf{v} is an eigenvector of \\mathbf{D}_{xx}, with eigenvalue\\lambda =  -4m^2 \\sin^2 \\left( \\frac{k\\pi}{m} \\right).\n\n(This establishes that the eigenvalues all lie within the real interval [-4m^2,0].)\n\n✍ (a) Derive an algebraic inequality equivalent to absolute stability for the AM2 (trapezoid) formula.\n\n✍ (b) Argue that the inequality in part (a) is equivalent to the restriction \\operatorname{Re} \\zeta\\le 0. (Hint: Complex magnitude is equivalent to distance in the plane.)\n\nIn Chapter 6 we used h rather than τ to denote the time step size, but now we  reserve h for spacing in the x direction.","type":"content","url":"/absstab-diffusion#exercises","position":7},{"hierarchy":{"lvl1":"Black–Scholes equation"},"type":"lvl1","url":"/blackscholes","position":0},{"hierarchy":{"lvl1":"Black–Scholes equation"},"content":"Suppose that at time t=0 you buy a stock whose share price is S(t). At a later time, if S(t)>S(0), you can sell the stock and make money. But if S(t)<S(0), you stand to lose money—potentially, your entire investment. You may prefer to mitigate this risk.\n\nOne way to do so is to buy a call option instead of the stock. This is a contract with a fixed strike time T and strike price K that gives you the right to buy the stock from the contract issuer at cost K at time T.\n\nSuppose S(T)>K. Then you could buy the stock at price K and instantly resell it at price S(T), so you make profit S(T)-K. On the other hand, if S(T)\\le K, there is no advantage to exercising the option because the stock is less valuable than the guaranteed purchase price. However, you have lost only what you paid for the option. These observations are summarized by the payoff function  H(S) = \\max\\{ S-K, 0 \\} = (S-K)_+.\n\nWhat is the fair market value of the option contract? This question is answered to close approximation by the famous Black–Scholes equation,  \\frac{\\partial v}{\\partial t} + \\frac{1}{2} \\sigma^2 S^2 \\frac{\\partial^2 v}{\\partial S^2}\n  + rS \\frac{\\partial v}{\\partial S} - r v = 0,\n\nwhere r is the risk-free interest rate (i.e., what you could earn with a very safe investment), and σ is the volatility of the stock (essentially, the standard deviation in the rate of return for the stock). In the Black–Scholes model, both r and σ are assumed to be known and constant.\n\nThe value v(S,t) of the option depends on the time t and on the stock price S, which may be varied independently. At the strike time, the payoff condition v(S,T)=H(S) is imposed, and the goal is to solve the equation backward in time to find v(S,0). Equation \n\n(11.1.2) is a time-dependent partial differential equation, or evolutionary PDE.","type":"content","url":"/blackscholes","position":1},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"Initial and boundary conditions"},"type":"lvl2","url":"/blackscholes#initial-and-boundary-conditions","position":2},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"Initial and boundary conditions"},"content":"Equation \n\n(11.1.2) has independent variables t and S. Because of the first-order derivative in time, we require an initial value for the dependent variable.\n\nIn order to follow the usual convention of having time flow forward instead of backward, we define a new variable \\eta=T-t, in which case \n\n(11.1.2) becomes\t- v_\\eta + \\frac{1}{2} \\sigma^2 S^2 v_{SS} + rS v_S - r v  = 0,\n\nnow defined for 0\\le \\eta \\le T. Here we have adopted the common notation of using subscripts for partial derivatives. In the new time variable we have the initial condition  v(S,0) = H(S),\n\nand the goal is to find v(S,\\eta) for \\eta>0. Henceforth we will simply rename the η variable as t again, with the understanding that it runs in the opposite direction to actual time in this application.\n\nWe have not yet specified the domain of the independent variable S. Stock prices cannot be negative, so S= 0 is the left end. In principle, S is not bounded from above. There are different ways to handle that fact computationally, but here we choose to truncate the domain at some positive value S_\\text{max}.\n\nBecause \n\n(11.1.2) has two derivatives in S, we also require a condition at each end of its domain. At S=0, both the stock and the option are worthless, so we impose v=0 there. In light of the payoff function H, initially the value v has slope equal to 1 at S=S_\\text{max}, and we choose to enforce that condition for all time. We summarize the boundary conditions as\\begin{split}\n  v(0,t) &= 0, \\\\\n  \\frac{\\partial v}{\\partial S}(S_\\text{max},t) &= 1.\n\\end{split}\n\nAt the left we have a homogeneous Dirichlet condition, and at the right we have a nonhomogeneous Neumann condition.\n\nThe complete problem consists of \n\n(11.1.3),  \n\n(11.1.4), and \n\n(11.1.5).\nAn evolutionary PDE has both initial and boundary conditions and is sometimes called an initial-boundary-value problem or IBVP as a result. Solving it numerically requires aspects of methods for both IVPs and BVPs.","type":"content","url":"/blackscholes#initial-and-boundary-conditions","position":3},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"The heat equation"},"type":"lvl2","url":"/blackscholes#the-heat-equation","position":4},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"The heat equation"},"content":"The Black–Scholes equation can be transformed by a change of variables into a simpler canonical PDE.\n\nHeat equation\n\nThe heat equation or diffusion equation in one dimension isu_t = k u_{xx},\n\nwhere k is a constant diffusion coefficient.\n\nThe heat equation is the archetype differential equation for the class known as parabolic PDEs. A diffusive process is one in which velocity is proportional to the gradient of the solution. Thus, rapid changes in the solution flatten out quickly.\n\nSolutions of the heat equation smooth out quickly and become as flat as the boundary conditions allow.\n\nConsider the following diffusion problem on\\begin{align*}\n  \\text{PDE:} \\quad &  u_t = u_{xx}, \\quad 0 < x < 1, \\; t > 0, \\\\[1mm]\n  \\text{BC:} \\quad &  u(0,t) = u(1,t) = 0,\\quad t \\ge 0, \\\\[1mm]\n  \\text{IC:} \\quad &  u(x,0) = \\sin (\\pi x), \\quad  0 \\le x \\le 1.\n\\end{align*}\n\nWe can show that the solution is \\hat{u}(x,t) = e^{- \\pi^2 t} \\sin (\\pi x) by verifying its correctness in the PDE, the initial conditions, and the boundary conditions. We start by computing the partial derivatives\\begin{align*}\n  \\frac{\\partial \\hat{u}}{\\partial t} & = \\left(- \\pi^2 e^{- \\pi^2 t} \\right)\\sin (\\pi x), \\\\\n  \\frac{\\partial^2 \\hat{u}}{\\partial x^2} & = e^{- \\pi^2 t} \\left[ - \\pi^2 \\sin (\\pi x)\\right].\n\\end{align*}\n\nThese are clearly equal, so the PDE is satisfied.\n\nSubstituting either x=0 or x=1 causes \\hat{u}=0, so the boundary conditions are satisfied. Finally, substitution of t=0 into u does indeed recover the initial condition \\hat{u}(x,0) = \\sin (\\pi x).\n\nIn certain cases there are explicit formulas describing the solution of \n\n(11.1.6) and hence \n\n(11.1.2). These provide a lot of insight and can lead to practical solutions. But the exact solutions are fragile in the sense that minor changes to the model can make them impractical or invalid. By contrast, numerical methods are often more robust to such changes.","type":"content","url":"/blackscholes#the-heat-equation","position":5},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"A naive numerical solution"},"type":"lvl2","url":"/blackscholes#a-naive-numerical-solution","position":6},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"A naive numerical solution"},"content":"Let’s return to the Black–Scholes equation \n\n(11.1.3), rewritten here as  v_t = \\frac{1}{2} \\sigma^2 S^2 v_{SS} + rS v_S - r v,\n\nsubject to the initial condition \n\n(11.1.4) and the boundary conditions \n\n(11.1.5).  We now try to solve it numerically, without any transformation tricks or other insight. Define\\begin{split}\n  x_i &= ih, \\quad h=\\frac{S_\\text{max}}{m}, \\qquad i = 0,\\ldots,m,  \\\\\n  t_j &= j \\tau, \\quad \\tau = \\frac{T}{n}, \\qquad j = 0,\\ldots,n.\n\\end{split}\n\nObserve that we have used the more conventional x and t in place of S and η. The result is a grid function \\mathbf{V} whose entries are V_{ij} \\approx v(x_i,t_j). By the initial condition \n\n(11.1.4), we set V_{i,0} = H(x_i) for all i.\n\nFor the moment, let us pretend that i is unbounded in both directions. Replacing the derivatives in \n\n(11.1.9) with some simple finite-difference formulas, we get  \\frac{V_{i,j+1} - V_{i,j}}{\\tau} = \n  + \\frac{\\sigma^2 x_i^2}{2} \\frac{V_{i+1,j}-2V_{i,j}+V_{i-1,j}}{h^2}\n  + r x_i \\frac{V_{i+1,j}- V_{i-1,j}}{2h}  - rV_{i,j}.\n\nWe can rearrange \n\n(11.1.11) into  V_{i,j+1} = V_{i,j} + \\frac{\\lambda \\sigma^2 x_i^2}{2} (V_{i+1,j}-2V_{i,j}+V_{i-1,j})\n   + \\frac{r x_i \\mu}{2}  (V_{i+1,j}- V_{i-1,j})  - r \\tau V_{i,j},\n\nwhere\\lambda = \\frac{\\tau}{h^2}, \\qquad \\mu = \\frac{\\tau}{h}.\n\nIf we put j=0 into \n\n(11.1.12), then everything on the right-hand side is known for each value of i, and thus we can get values for V_{i,1}. We can then use j=1 and get all of V_{i,2}, and so on.\n\nNow we take the boundaries on x into account. The value V_{0,j+1} is zero, so we don’t even need to compute the solution using \n\n(11.1.12) at i=0. At i=m, or x_i=S_\\text{max}, things are trickier. We don’t know V_{m,j+1} explicitly and would like to solve for it, yet formula \n\n(11.1.12) refers to the fictitious value V_{m+1,j} when i=m. This is where the Neumann condition must be applied. If the value V_{m+1,j} did exist, then we could discretize that condition as  \\frac{V_{m+1,j}-V_{m-1,j}}{2h} = 1.\n\nWe can therefore solve \n\n(11.1.14) for the fictitious V_{m+1,j} and use it where called for in the right-hand side of \n\n(11.1.12).\n\nFD solution of Black–Scholes\n\nExample 11.1.2\n\nWe consider the Black–Scholes problem for the following parameter values:\n\nSmax = 8 \nT = 6\nK, σ, r = (3, 0.06, 0.08);\n\nWe discretize space and time.\n\nm = 200;  h = Smax / m;\nx = h * (0:m)\nn = 1000;  τ = T / n;\nt = τ * (0:n)\nλ = τ / h^2\nμ = τ / h;\n\nWe set the initial condition and then march forward in time.\n\nV = zeros(m+1, n+1)\nV[:, 1] = @. max(0, x - K)\nfor j in 1:n\n    # Fictitious value from Neumann condition.\n    Vfict = 2h + V[m, j]\n    Vj = [ V[:, j]; Vfict ]\n    # First row is zero by the Dirichlet condition.\n    for i in 2:m+1 \n        diff1 = (Vj[i+1] - Vj[i-1])\n        diff2 = (Vj[i+1] - 2Vj[i] + Vj[i-1])\n        V[i,j+1] = Vj[i] +\n            (λ * σ^2 * x[i]^2 / 2) * diff2 +\n            (r * x[i] * μ) / 2 * diff1 -\n            (r * τ) * Vj[i]\n    end \nend\n\nHere is a plot of the solution after every 250 time steps.\n\nusing Plots\nidx = 1:250:n+1\nlabel = reshape([\"t = $t\" for t in t[idx]], 1, length(idx))\nplot(x, V[:, idx]; \n    label, legend=:topleft,\n    xaxis=(\"stock price\"),  yaxis=(\"option value\"),\n    title=\"Black–Scholes solution\")\n\nAlternatively, here is an animation of the solution.\n\nanim = @animate for j in 1:10:n+1\n    plot(x, V[:, j];\n        xaxis=(L\"S\"),  yaxis=([0,6],L\"v(S,t)\"),\n        title=\"Black–Scholes solution\",\n        dpi=150,    \n        label=@sprintf(\"t = %.2f\", t[j]))\nend\nmp4(anim, \"figures/black-scholes-6.mp4\")\n\nThe results are easy to interpret, recalling that the time variable really means time until strike. Say you are close to the option’s strike time. If the current stock price is, say, S=2, then it’s not likely that the stock will end up over the strike price K=3, and therefore the option has little value. On the other hand, if presently S=3, then there are good odds that the option will be exercised at the strike time, and you will need to pay a substantial portion of the stock price in order to take advantage. As the time to strike increases, there is an expectation that the stock price is more likely to rise somewhat, making the value of the option larger at each fixed S.\n\nExample 11.1.2\n\nWe consider the Black–Scholes problem for the following parameter values:\n\nSmax = 8;  T = 6;\nK = 3;  sigma = 0.06;  r = 0.08;\n\nWe discretize space and time.\n\nm = 200;  h = Smax / m;\nx = h * (0:m)';\nn = 1000;  tau = T / n;\nt = tau * (0:n)';\nlambda = tau / h^2;  mu = tau / h;\n\nWe set the initial condition and then march forward in time.\n\nV = zeros(m+1, n+1);\nV(:, 1) = max(0, x-K);\nfor j = 1:n\n    % Fictitious value from Neumann condition.\n    Vfict = 2*h + V(m, j);\n    Vj = [ V(:, j); Vfict ];\n    % First row is zero by the Dirichlet condition.\n    for i = 2:m+1 \n        diff1 = (Vj(i+1) - Vj(i-1));\n        diff2 = (Vj(i+1) - 2*Vj(i) + Vj(i-1));\n        V(i, j+1) = Vj(i) ...\n            + (lambda * sigma^2* x(i)^2/2) * diff2  ...\n            + (r*mu * x(i))/2 * diff1 - r*tau * Vj(i);\n    end \nend\n\nHere is a plot of the solution after every 250 time steps.\n\nindex_times = 1:250:n+1;\nshow_times = t(index_times);\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2f\", t(j));\n    plot(x, V(:, j), displayname=str) \n    hold on\nend\ntitle('Black-Scholes solution')\nxlabel('stock price'),  ylabel('option value')\naxis tight,  grid on\nlegend(location=\"northwest\")\n\nAlternatively, here is an animation of the solution.\n\nclf\nplot(x, V(:,1))\nhold on,  grid on\naxis([0, 8, 0, 6])\ntitle('Black-Scholes solution') \nxlabel('stock price'),  ylabel('option value')\nvid = VideoWriter(\"figures/black-scholes-6.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid)\nfor frame = 1:10:n+1\n    cla, plot(x, V(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.4, 5.2, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThe results are easy to interpret, recalling that the time variable really means time until strike. Say you are close to the option’s strike time. If the current stock price is, say, S=2, then it’s not likely that the stock will end up over the strike price K=3, and therefore the option has little value. On the other hand, if presently S=3, then there are good odds that the option will be exercised at the strike time, and you will need to pay a substantial portion of the stock price in order to take advantage. As the time to strike increases, there is an expectation that the stock price is more likely to rise somewhat, making the value of the option larger at each fixed S.\n\nExample 11.1.2\n\nWe consider the Black–Scholes problem for the following parameter values:\n\nSmax, T = 8, 6\nK = 3\nsigma = 0.06\nr = 0.08\n\nWe discretize space and time.\n\nm = 200\nh = Smax / m\nx = h * arange(m+1)\nn = 1000\ntau = T / n\nt = tau * arange(n+1)\nlamb, mu = tau / h**2, tau / h\n\nWe set the initial condition and then march forward in time.\n\nV = zeros([m + 1, n + 1])\nV[:, 0] = maximum(0, x - K)\nfor j in range(n):\n    # Fictitious value from Neumann condition.\n    Vfict = 2 * h + V[m-1, j]\n    Vj = hstack([V[:, j], Vfict])\n    # First row is zero by the Dirichlet condition.\n    for i in range(1, m+1):\n        diff1 = Vj[i+1] - Vj[i-1]\n        diff2 = Vj[i+1] - 2 * Vj[i] + Vj[i-1]\n        V[i, j+1] = (\n            Vj[i]\n            + (lamb * sigma**2 * x[i] ** 2 / 2) * diff2\n            + (r * x[i] * mu) / 2 * diff1\n            - r * tau * Vj[i]\n        )\n\nHere is a plot of the solution after every 250 time steps.\n\nselect_times = 250 * arange(5)\nshow_times = t[select_times]\n\nfor j, col in enumerate(select_times):\n    plot(x, V[:, col], label=f\"t={show_times[j]:.1f}\")\n\nlegend()\nxlabel(\"stock price\"),  ylabel(\"option value\")\ntitle(\"Black-Scholes solution\");\n\nAlternatively, here is an animation of the solution.\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 8), ylim=(0, 6))\nax.grid()\nax.set_title(\"Black-Scholes solution\")\n\nline, = ax.plot([], [], '-', lw=2)\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(j):\n    line.set_data(x, V[:, j])\n    time_text.set_text(f\"t = {t[j]:.2f}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, n+1, 10), blit=True);\nanim.save(\"figures/black-scholes-6.mp4\", fps=30)\nclose()\n\nThe results are easy to interpret, recalling that the time variable really means time until strike. Say you are close to the option’s strike time. If the current stock price is, say, S=2, then it’s not likely that the stock will end up over the strike price K=3, and therefore the option has little value. On the other hand, if presently S=3, then there are good odds that the option will be exercised at the strike time, and you will need to pay a substantial portion of the stock price in order to take advantage. As the time to strike increases, there is an expectation that the stock price is more likely to rise somewhat, making the value of the option larger at each fixed S.\n\nEverything in \n\nDemo 11.1.2 seems to go smoothly. However, trouble lurks just around the corner.\n\nTrouble with the FD solution\n\nExample 11.1.3\n\nLet’s try to do everything the same as in \n\nDemo 11.1.2, but extending the simulation time to T=8.\n\nT = 8;\n\nm = 200;  h = Smax / m;\nx = h*(0:m)\nn = 1000;  τ = T / n;\nt = τ*(0:n)\nλ = τ / h^2;  μ = τ / h;\n\nfor j in 1:n\n    # Fictitious value from Neumann condition.\n    Vfict = 2h + V[m,j]\n    Vj = [ V[:, j]; Vfict ]\n    # First row is zero by the Dirichlet condition.\n    for i in 2:m+1 \n        diff1 = (Vj[i+1] - Vj[i-1])\n        diff2 = (Vj[i+1] - 2Vj[i] + Vj[i-1])\n        V[i,j+1] = Vj[i] +\n            (λ * σ^2 * x[i]^2 / 2) * diff2 +\n            (r * x[i] * μ) / 2 * diff1 -\n            (r * τ) * Vj[i]\n    end   \nend\n\nidx = 1:250:n+1\nlabel = reshape([\"t = $t\" for t in t[idx]], 1, length(idx))\nplot(x, V[:, idx];\n    label, legend=:topleft,\n    title=\"Black–Scholes solution\",\n    xaxis=(\"stock price\"),  yaxis=(\"option value\",[0, 6]))\n\nanim = @animate for j in 1:10:n+1 \n    plot(x, V[:, j];\n        xaxis=(L\"S\"),  yaxis=([0,6],L\"v(S,t)\"),\n        title=\"Black–Scholes solution...?\",\n        dpi=150,  label=@sprintf(\"t = %.2f\",t[j]))\nend\nmp4(anim, \"figures/black-scholes-8.mp4\")\n\nThis so-called solution is nonsense!\n\nExample 11.1.3\n\nLet’s try to do everything the same as in \n\nDemo 11.1.2, but extending the simulation time to T=8.\n\nT = 8;\nn = 1000;  tau = T / n;\nt = tau*(0:n)';\nlambda = tau / h^2;  mu = tau / h;\nfor j = 1:n\n    % Fictitious value from Neumann condition.\n    Vfict = 2*h + V(m,j);\n    Vj = [ V(:,j); Vfict ];\n    % First row is zero by the Dirichlet condition.\n    for i = 2:m+1 \n        diff1 = (Vj(i+1) - Vj(i-1));\n        diff2 = (Vj(i+1) - 2*Vj(i) + Vj(i-1));\n        V(i,j+1) = Vj(i) ...\n             + (lambda*sigma^2 * x(i)^2/2) * diff2  ...\n             + (r*mu * x(i))/2 * diff1 - r*tau * Vj(i);\n    end   \nend\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2f\", t(j));\n    plot(x, V(:, j), displayname=str) \n    hold on\nend\ntitle('Black-Scholes instability')\nxlabel('stock price'),  ylabel('option value')\naxis tight,  grid on\nlegend(location=\"northwest\")\n\nclf\nplot(x, V(:,1))\nhold on,  grid on\naxis([0, 8, 0, 6])\ntitle('Black-Scholes solution...?') \nxlabel('stock price'),  ylabel('option value')\nvid = VideoWriter(\"figures/black-scholes-8.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:10:n+1\n    cla, plot(x, V(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.4, 5.2, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThis so-called solution is nonsense!\n\nExample 11.1.3\n\nLet’s try to do everything the same as in \n\nDemo 11.1.2, but extending the simulation time to T=8.\n\nT = 8\nn = 1000;  tau = T / n\nt = tau * arange(n + 1)\nlamb, mu = tau / h**2, tau / h\n\nV = zeros([m+1, n+1])\nV[:, 0] = maximum(0, x - K)\nfor j in range(n):\n    # Fictitious value from Neumann condition.\n    Vfict = 2 * h + V[m - 1, j]\n    Vj = hstack([V[:, j], Vfict])\n    # First row is zero by the Dirichlet condition.\n    for i in range(1, m + 1):\n        diff1 = Vj[i + 1] - Vj[i - 1]\n        diff2 = Vj[i + 1] - 2 * Vj[i] + Vj[i - 1]\n        V[i, j + 1] = (\n            Vj[i]\n            + (lamb * sigma**2 * x[i] ** 2 / 2) * diff2\n            + (r * x[i] * mu) / 2 * diff1\n            - r * tau * Vj[i]\n        )\n\nselect_times = 250 * arange(5)\nshow_times = t[select_times]\n\nfor j, col in enumerate(select_times):\n    plot(x, V[:, col], label=f\"t={show_times[j]:.1f}\")\n\nlegend()\nxlabel(\"stock price\")\nylim([0, 6]);  ylabel(\"option value\")\ntitle(\"Black-Scholes solution\");\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 8), ylim=(0, 6))\nax.grid()\nax.set_title(\"Black-Scholes solution...?\")\n\nline, = ax.plot([], [], '-', lw=2)\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(j):\n    line.set_data(x, V[:, j])\n    time_text.set_text(f\"t = {t[j]:.2f}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, n+1), blit=True);\nanim.save(\"figures/black-scholes-8.mp4\", fps=24)\nclose()\n\nThis so-called solution is nonsense!\n\nThe explosive growth of error in \n\nDemo 11.1.3 suggests that there is instability at work. Understanding the source of that instability comes later in this chapter. First, though, we consider a general and robust strategy for solving evolutionary PDEs.","type":"content","url":"/blackscholes#a-naive-numerical-solution","position":7},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"Exercises"},"type":"lvl2","url":"/blackscholes#exercises","position":8},{"hierarchy":{"lvl1":"Black–Scholes equation","lvl2":"Exercises"},"content":"✍ Show that u(x,t) = e^{-4 \\pi^2 t} \\cos (2 \\pi x)  is a solution to the IBVP\\begin{align*}\n      \\text{PDE:} \\quad & \\frac{\\partial u}{\\partial t} = \\frac{\\partial^2 u}{\\partial x^2},\\quad 0<x<1,\\; t > 0, \\\\\n      \\text{BC:} \\quad &  \\frac{\\partial u}{\\partial x}(0,t) = \\frac{\\partial u}{\\partial x}(1,t) = 0,\\quad t > 0, \\\\\n      \\text{IC:} \\quad & u(x,0) = \\cos (2 \\pi x),\\quad 0 \\le x \\le 1.\n    \\end{align*}\n\n✍ Show that u(x,t) = t^{-1/2} \\exp(-x^2/4t) solves the heat equation \n\n(11.1.6) at any value of t>0.\n\n✍ Equation \n\n(11.1.11) results from applying finite differences to the derivatives in \n\n(11.1.9), including a forward difference for the term v_t.\n\n(a) Write out the method that results if a backward difference is used for v_t instead.\n\n(b) Explain why modifying the code from \n\nDemo 11.1.2 to implement this formula requires the use of matrix algebra.\n\n⌨ In this problem you are asked to revisit \n\nDemo 11.1.2 in order to examine the instability phenomenon more closely.\n\n(a) Leaving other parameters alone, let m=100. To the nearest ten, find the minimum value of n that leads to a stable (i.e., not exponentially growing) solution.\n\n(b) Repeat (a) for m=120,140,\\ldots,200. Make a table of the minimum stable n for each m. Is the relationship n=O(m), or something else?\n\nWe discuss only so-called European options; American options are more difficult computationally.\n\nThe t variable in the heat equation is not the same as either backward or forward time in \n\n(11.1.2).","type":"content","url":"/blackscholes#exercises","position":9},{"hierarchy":{"lvl1":"Boundaries"},"type":"lvl1","url":"/boundaries","position":0},{"hierarchy":{"lvl1":"Boundaries"},"content":"So far we have considered the method of lines for problems with periodic end conditions, which is much like having no boundary at all. How can boundary conditions be incorporated into this technique?\n\nSuppose we are given a nonlinear PDE of the form  u_t = \\phi(t,x,u,u_x,u_{xx}), \\quad  a \\le x \\le b.\n\nNot all such PDEs are parabolic (essentially, including diffusion), but we will assume this to be the case. Suppose also that the solution is subject to the boundary conditions\\begin{split}\n  g_1\\left( u(a,t), \\frac{\\partial u}{\\partial x}(a,t) \\right) &= 0, \\\\\n  g_2\\left( u(b,t), \\frac{\\partial u}{\\partial x}(b,t) \\right) &= 0. \\\\ \n\\end{split}\n\nThese include Dirichlet, Neumann, and Robin conditions, which are the linear cases of \n\n(11.5.2).","type":"content","url":"/boundaries","position":1},{"hierarchy":{"lvl1":"Boundaries","lvl2":"Boundary removal"},"type":"lvl2","url":"/boundaries#boundary-removal","position":2},{"hierarchy":{"lvl1":"Boundaries","lvl2":"Boundary removal"},"content":"As usual, we replace u(x,t) by the semidiscretized \\mathbf{u}(t), where u_i(t)\\approx \\hat{u}(x_i,t) and i=0,\\ldots,m. We require the endpoints of the interval to be included in the discretization, that is, x_0=a and x_m=b. Then we have a division of the semidiscrete unknown \\mathbf{u}(t) into interior and boundary nodes:  \\mathbf{u} =\n  \\begin{bmatrix}\n    u_0 \\\\ \\mathbf{v} \\\\ u_m\n  \\end{bmatrix},\n\nwhere \\mathbf{v} are the solution values over the interior of the interval. The guiding principle is to let the interior unknowns \\mathbf{v} be governed by a discrete form of the PDE, while the endpoint values are chosen to satisfy the boundary conditions. As a result, we will develop an initial-value problem for the interior unknowns only:  \\frac{d \\mathbf{v}}{d t} = \\mathbf{f}(t,\\mathbf{v}).\n\nThe boundary conditions are used only in the definition of \\mathbf{f}. As in \n\nNonlinearity and boundary conditions, define\\mathbf{u}' = \\mathbf{D}_x \\mathbf{u}.\n\nThen Equation \n\n(11.5.2) takes the form\\begin{split}\n  g_1( u_0, u'_0 ) &= 0, \\\\\n  g_2( u_m, u'_m ) &= 0.\n\\end{split}\n\nGiven a value of \\mathbf{v} for the interior nodes, Equation \n\n(11.5.6) may be considered a system of two equations for the unknown boundary values u_0 and u_m. This system will be a linear one for Dirichlet, Neumann, and Robin conditions.\n\nRecall the Black–Scholes PDE \n\n(11.1.9),u_t = \\frac{1}{2} \\sigma^2 x^2 u_{xx} + rx u_x - ru,\n\nsubject to u(0)=0 and u_x(S_\\text{max})=1. These imply u_0=0 and\\frac{ \\tfrac{1}{2} u_{m-2} -2u_{m-1} + \\tfrac{3}{2} u_{m}}{h} = 1.\n\nHence\\begin{bmatrix}\n    1 & 0 \\\\ 0 & \\frac{3}{2}\n\\end{bmatrix}  \\begin{bmatrix}\n  u_0 \\\\ u_m\n\\end{bmatrix} =\n\\begin{bmatrix}\n  0 \\\\ h\n\\end{bmatrix} -\n\\begin{bmatrix}\n  0 & \\cdots & 0 & 0 \\\\\n  0 & \\cdots & -\\frac{1}{2} & 2\n\\end{bmatrix}\n\\mathbf{v}.\n\nReturning to \n\nExample 11.5.1, suppose we use a global Chebyshev differentiation matrix for \\mathbf{D}_x in \n\n(11.5.6). Then u_0=0 andD_{m0} u_0 + D_{m1}u_1 + \\cdots + D_{mm}u_m = 1.\n\nHence\\begin{bmatrix}\n    1 & 0 \\\\ D_{m0} & D_{mm}\n  \\end{bmatrix}  \\begin{bmatrix}\n  u_0 \\\\ u_m\n\\end{bmatrix} =\n\\begin{bmatrix}\n  0 \\\\ 1\n\\end{bmatrix} -\n\\begin{bmatrix}\n  0 & \\cdots & 0 & 0 \\\\\n  D_{m1} & \\cdots & D_{m,m-2}& D_{m,m-1}\n\\end{bmatrix}\n\\mathbf{v}.","type":"content","url":"/boundaries#boundary-removal","position":3},{"hierarchy":{"lvl1":"Boundaries","lvl2":"Implementation"},"type":"lvl2","url":"/boundaries#implementation","position":4},{"hierarchy":{"lvl1":"Boundaries","lvl2":"Implementation"},"content":"The steps to evaluate \\mathbf{f} in \n\n(11.5.4) now go as follows.\n\nTime derivative for parabolic PDE\n\nGiven a value of t and \\mathbf{v},\n\nUse \n\n(11.5.6) to solve for u_0 and u_m.\n\nAssemble the total vector \\mathbf{u} from \n\n(11.5.3).\n\nUse the spatial semidiscretization to evaluate ϕ at all the nodes.\n\nIgnore the boundary nodes to get the value of \\mathbf{f}(t,\\mathbf{v}) in \n\n(11.5.4).\n\nOur full implementation of the method of lines for \n\n(11.5.1)--\n\n(11.5.2) is given in \n\nFunction 11.5.2. It uses \n\nFunction 10.3.2 (diffcheb) to set up a Chebyshev discretization. The nested function extend performs steps 1--2 of \n\nAlgorithm 11.5.1 by calling \n\nFunction 4.6.3 (levenberg) to solve the potentially nonlinear system \n\n(11.5.6). Then it sets up and solves an IVP, adding steps 3--4 of \n\nAlgorithm 11.5.1 within the ode! function. Finally, it returns the node vector x and a function of t that applies extend to \\mathbf{v}(t) to compute \\mathbf{u}(t).\n\nparabolic\n\nSolution of parabolic PDEs by the method of lines\n\n\"\"\"\n    parabolic(ϕ, xspan, m, g₁, g₂, tspan, init)\n\nSolve a parabolic PDE by the method of lines. The PDE is\n∂u/∂t = `ϕ`(t, x, u, ∂u/∂x, ∂^2u/∂x^2), `xspan` gives the space\ndomain, m gives the degree of a Chebyshev spectral discretization,\n`g₁` and `g₂` are functions of (u,∂u/∂x) at the domain ends that\nshould be made zero, `tspan` is the time domain, and `init` is a\nfunction of x that gives the initial condition. Returns a vector\n`x` and a function of t that gives the semidiscrete solution at `x`.\n\"\"\"\nfunction parabolic(ϕ, xspan, m, g₁, g₂, tspan, init)\n    x, Dₓ, Dₓₓ = diffcheb(m, xspan)\n    int = 2:m    # indexes of interior nodes\n\n    function extend(v)\n        function objective(ubc)\n            u₀, uₘ = ubc\n            uₓ = Dₓ * [u₀; v; uₘ]\n            return [g₁(u₀, uₓ[1]), g₂(uₘ, uₓ[end])]\n        end\n        ubc = levenberg(objective, [0, 0])[end]\n        return [ubc[1]; v; ubc[2]]\n    end\n\n    function ode!(f, v, p, t)\n        u = extend(v)\n        uₓ, uₓₓ = Dₓ * u, Dₓₓ * u\n        @. f = ϕ(t, x[int], u[int], uₓ[int], uₓₓ[int])\n    end\n\n    ivp = ODEProblem(ode!, init.(x[int]), float.(tspan))\n    u = solve(ivp)\n\n    return x, t -> extend(u(t))\nend\n\nAbout the code\n\nLine 29 uses the macro @. to assign into the vector f elementwise. Without it, the function would allocate space for the result of phi and then change f to point at that vector, and that would defeat the purpose of using the preallocated f for speed.\n\nSolution of parabolic PDEs by the method of lines\n\nfunction [x, u] = parabolic(phi, xspan, m, ga, gb, tspan, init)\n% PARABOLIC   Solve parabolic PDE by the method of lines.\n% Input:\n%   phi      defines ∂u/∂t = phi(t, x, u, ∂u/∂x, ∂^2u/∂x^2) \n%   xspan    spatial domain\n%   m        number of spatial nodes\n%   ga, gb   boundary conditions as functions of u and ∂u/∂x\n%   tspan    time interval\n%   init     initial condition as a function of x\n% Output:       \n%   x        spatial nodes (vector)\n%   u        function for the solution u(t) at nodes\n\n    [x, Dx, Dxx] = diffcheb(m, xspan);\n    int = 2:m;    % indexes of interior nodes\n\n    function u = extend(v)\n        function residual = objective(ubc)\n            ua = ubc(1);  ub = ubc(2);\n            ux = Dx * [ua; v; ub];\n            residual = [ga(ua, ux(1)); gb(ub, ux(end))];\n        end\n        ubc = levenberg(@objective, [0, 0]);\n        ubc = ubc(:, end);\n        u = [ubc(1); v; ubc(2)];\n    end\n\n    function f = mol_ode(t, v, p)\n        u = extend(v);\n        ux = Dx * u;\n        uxx = Dxx * u;\n        f = phi(t, x(int), u(int), ux(int), uxx(int));\n    end\n\n    ivp = ode(ODEFcn=@mol_ode);\n    ivp.InitialTime = tspan(1);\n    ivp.InitialValue = init(x(int));\n    ivp.Solver = \"stiff\";\n    sol = solutionFcn(ivp, tspan(1), tspan(2));\n    u = @(t) extend(sol(t));\nend\n\nSolution of parabolic PDEs by the method of lines\n\ndef parabolic(phi, xspan, m, ga, gb, tspan, init):\n    \"\"\"\n        parabolic(phi, xspan, m, ga, gb, tspan, init)\n\n    Solve a parabolic PDE by the method of lines. The PDE is \n    ∂u/∂t = phi(t,x,u,∂u/∂x,∂^2u/∂x^2), xspan gives the space \n    domain, m gives the degree of a Chebyshev spectral discretization, ga and gb are functions of (u,∂u/∂x) at the domain ends that should be made zero, tspan is the time domain, and init is a function of x that gives the initial condition. Returns a vector x and a function of t that gives the semidiscrete solution at x. \n    \"\"\"   \n    x, Dx, Dxx = diffcheb(m, xspan)\n    int = range(1, m)    # indexes of interior nodes\n\n    def extend(v):\n        def objective(ubc):\n            u0, um = ubc\n            ux = Dx @ np.hstack([u0, v, um])\n            return np.array([ga(u0, ux[1]), gb(um, ux[-1])])\n        ubc = levenberg(objective, np.array([0, 0]))[-1]\n        return np.hstack([ubc[0], v, ubc[-1]])\n\n    def ode(t, v):\n        u = extend(v)\n        ux, uxx = Dx @ u, Dxx @ u\n        return phi(t, x[int], u[int], ux[int], uxx[int])\n\n    u0 = init(x[int])\n    sol = solve_ivp(ode, tspan, u0, method=\"BDF\", dense_output=True)\n\n    return x, lambda t: extend(sol.sol(t))\n\nIn many specific problems, extend does more work than is truly necessary. Dirichlet boundary conditions, for instance, define u_0 and u_m directly, and there is no need to solve a nonlinear system. \n\nExercise 6 asks you to modify the code to take advantage of this case. The price of solving a more general set of problems in \n\nFunction 11.5.2 is some speed in such special cases.\n\nHeat equation with Dirichlet boundary conditions\n\nLet’s solve the heat equation u_t=u_{xx} on [-1,1], subject to the Dirichlet boundary conditions u(-1,t)=0, u(1,t)=2.\n\nExample 11.5.3\n\nFirst, we define functions for the PDE and each boundary condition.\n\nϕ = (t, x, u, uₓ, uₓₓ) -> uₓₓ\ng₁ = (u, uₓ) -> u\ng₂ = (u, uₓ) -> u - 2;\n\nOur next step is to write a function to define the initial condition. This one satisfies the boundary conditions exactly.\n\ninit = x -> 1 + sinpi(x/2) + 3 * (1-x^2) * exp(-4x^2);\n\nNow we can use \n\nFunction 11.5.2 to solve the problem.\n\nusing Plots\nx, u = FNC.parabolic(ϕ, (-1, 1), 60, g₁, g₂, (0, 0.75), init)\nplt = plot(\n    xlabel=L\"x\",  ylabel=L\"u(x,t)\",\n    legend=:topleft,  title=\"Solution of the heat equation\")\nfor t in 0:0.1:0.4\n    plot!(x, u(t), label=@sprintf(\"t=%.2f\", t))\nend\nplt\n\nanim = @animate for t in range(0,0.75,length=201) \n    plot(x, u(t);\n        label=@sprintf(\"t=%.2f\", t),  legend=:topleft,\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (0, 4.2)), \n        title=\"Heat equation\",  dpi=150)\nend\nmp4(anim, \"figures/boundaries-heat.mp4\", fps=30)\n\nExample 11.5.3\n\nFirst, we define functions for the PDE and each boundary condition.\n\nphi = @(t, x, u, ux, uxx) uxx;\nga = @(u, ux) u;\ngb = @(u, ux) u - 2;\n\nOur next step is to write a function to define the initial condition. This one satisfies the boundary conditions exactly.\n\ninit = @(x) 1 + sin(pi * x/2) + 3 * (1 - x.^2) .* exp(-4*x.^2);\n\nNow we can use \n\nFunction 11.5.2 to solve the problem.\n\n[x, u] = parabolic(phi, [-1, 1], 60, ga, gb, [0, 0.75], init);\n\nclf\nfor t = 0:0.1:0.5\n    str = sprintf(\"t = %.2f\", t);\n    plot(x, u(t), displayname=str)\n    hold on\nend\nxlabel(\"x\"),  ylabel(\"u(x,t)\")\nlegend()\ntitle(\"Heat equation with Dirichlet boundaries\")\n\nclf\nplot(x, u(0))\nhold on,  grid on\naxis([-1, 1, 0, 4.2])\ntitle('Heat equation with Dirichlet boundaries') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/boundaries-heat.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 0.75, 201)\n    cla, plot(x, u(t))\n    str = sprintf(\"t = %.3f\", t);\n    text(-0.9, 3.8, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 11.5.3\n\nFirst, we define functions for the PDE and each boundary condition.\n\nphi = lambda t, x, u, ux, uxx: uxx\nga = lambda u, ux: u\ngb = lambda u, ux: u - 2\n\nOur next step is to write a function to define the initial condition. This one satisfies the boundary conditions exactly.\n\ninit = lambda x: 1 + sin(pi * x/2) + 3 * (1 - x**2) * exp(-4*x**2)\n\nNow we can use \n\nFunction 11.5.2 to solve the problem.\n\nx, u = FNC.parabolic(phi, (-1, 1), 60, ga, gb, (0, 0.75), init)\n\nfor t in arange(0,0.5,0.1):\n    plot(x, u(t), label=f\"t={t:.2f}\")\nxlabel(\"$x$\"),  ylabel(\"$u(x,t)$\")\nlegend()\ntitle(\"Heat equation with Dirichlet boundaries\");\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(-1, 1), ylim=(0, 4.2))\n\nline, = ax.plot([], [], '-')\nax.set_title(\"Heat equation with Dirichlet boundaries\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(t):\n    line.set_data(x, u(t))\n    time_text.set_text(f\"t = {t:.2e}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=linspace(0, 0.75, 201), blit=True)\nanim.save(\"figures/boundaries-heat.mp4\", fps=30)\nclose()\n\nHeat equation with nonlinear source\n\nWe solve a heat equation with a nonlinear source term,u_t = u^2 + u_{xx}.\n\nOne interpretation of this PDE is an exothermic chemical reaction whose rate increases with temperature. We solve over x \\in [0,1] with homogeneous conditions of different kinds.\n\nExample 11.5.4\n\nϕ = (t, x, u, uₓ, uₓₓ) -> u^2 + uₓₓ\ng₁ = (u, uₓ) -> u\ng₂ = (u, uₓ) -> uₓ\ninit = x -> 400x^4 * (1 - x)^2\nx, u = FNC.parabolic(ϕ, (0, 1), 60, g₁, g₂, (0, 0.1), init);\n\nanim = @animate for t in range(0, 0.1, length=101) \n    plot(x, u(t);\n        label=@sprintf(\"t=%.4f\", t),  legend=:topleft,\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (0, 10)),\n        dpi=150, title=\"Heat equation with source\")\nend\nmp4(anim, \"figures/boundaries-source.mp4\", fps=30)\n\nExample 11.5.4\n\nphi = @(t, x, u, ux, uxx) u.^2 + uxx;\nga = @(u, ux) u;\ngb = @(u, ux) ux;\n\ninit = @(x) 400 * x.^4 .* (1 - x).^2;\n[x, u] = parabolic(phi, [0, 1], 60, ga, gb, [0, 0.1], init);\n\nclf\nplot(x, u(0))\nhold on,  grid on\naxis([0, 1, 0, 10])\ntitle(\"Heat equation with source\")\nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/boundaries-source.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 0.1, 101)\n    cla, plot(x, u(t))\n    str = sprintf(\"t = %.3f\", t);\n    text(0.05, 9.2, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 11.5.4\n\nphi = lambda t, x, u, ux, uxx: u**2 + uxx\nga = lambda u, ux: u\ngb = lambda u, ux: ux\ninit = lambda x: 400 * x**4 * (1 - x)**2\nx, u = FNC.parabolic(phi, (0, 1), 60, ga, gb, (0, 0.1), init);\n\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 1), ylim=(0, 10))\n\nline, = ax.plot([], [], '-')\nax.set_title(\"Heat equation with source\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=linspace(0, 0.1, 101), blit=True)\nanim.save(\"figures/boundaries-source.mp4\", fps=30)\nclose()\n\nFinally, we return to the example of the Black–Scholes equation from \n\nBlack–Scholes equation.\n\nBlack–Scholes equation with mixed boundary conditions\n\nWe solve the Black–Scholes PDE \n\n(11.1.2) with initial condition u(x,0) = \\max\\{0,x-K\\} and the boundary conditions u(0,t)=0 and u_x(S_\\text{max},t)=1. We choose S_\\text{max}=8, r=0.08, \\sigma=0.06, and K=3.\n\nExample 11.5.5\n\nK = 3;  σ = 0.06;  r = 0.08;  Smax = 8;\nϕ = (t, x, u, uₓ, uₓₓ) -> σ^2/2 * (x^2 * uₓₓ) + r*x*uₓ - r*u\ng₁ = (u, uₓ) -> u\ng₂ = (u, uₓ) -> uₓ - 1;\n\nu₀ = x -> max(0, x - K)\nx, u = FNC.parabolic(ϕ, (0, Smax), 80, g₁, g₂, (0, 15), u₀);\n\nanim = @animate for t in range(0, 15, 151) \n    plot(x, u(t);\n        label=@sprintf(\"t=%.4f\", t),  legend=:topleft,\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (-0.5, 8)), \n        dpi=150,  title=\"Black–Scholes equation\")\nend\nmp4(anim, \"figures/boundaries-bs.mp4\", fps=30)\n\nRecall that u is the value of the call option, and time runs backward from the strike time. The longer the horizon, the more value the option has due to anticipated growth in the stock price.\n\nExample 11.5.5\n\nK = 3;  sigma = 0.06;  r = 0.08;  Smax = 8;\nphi = @(t, x, u, ux, uxx) sigma.^2/2 * (x.^2 .* uxx) + r * x.*ux - r*u;\nga = @(u, ux) u;\ngb = @(u, ux) ux - 1;\n\ninit = @(x) max(0, x - K);\n[x, u] = parabolic(phi, [0, Smax], 80, ga, gb, [0, 15], init);\n\nclf\nplot(x, u(0))\nhold on,  grid on\naxis([0, Smax, -0.1, 8])\ntitle(\"Black–Scholes equation with boundaries\")\nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/boundaries-bs.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 15, 151)\n    cla, plot(x, u(t))\n    str = sprintf(\"t = %.1f\", t);\n    text(0.5, 7.1, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nRecall that u is the value of the call option, and time runs backward from the strike time. The longer the horizon, the more value the option has due to anticipated growth in the stock price.\n\nExample 11.5.5\n\nK = 3;  sigma = 0.06;  r = 0.08;  Smax = 8;\nphi = lambda t, x, u, ux, uxx: sigma**2/2 * (x**2 * uxx) + r*x*ux - r*u\nga = lambda u, ux: u\ngb = lambda u, ux: ux - 1\n\nu0 = lambda x: maximum(0, x - K)\nx, u = FNC.parabolic(phi, (0, Smax), 80, ga, gb, (0, 15), u0);\n\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, Smax), ylim=(-0.5, 8))\n\nline, = ax.plot([], [], '-')\nax.set_title(\"Black–Scholes equation with boundaries\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=linspace(0, 15, 151), blit=True)\nanim.save(\"figures/boundaries-bs.mp4\", fps=30)\nclose()\n\nRecall that u is the value of the call option, and time runs backward from the strike time. The longer the horizon, the more value the option has due to anticipated growth in the stock price.","type":"content","url":"/boundaries#implementation","position":5},{"hierarchy":{"lvl1":"Boundaries","lvl2":"Exercises"},"type":"lvl2","url":"/boundaries#exercises","position":6},{"hierarchy":{"lvl1":"Boundaries","lvl2":"Exercises"},"content":"✍ Suppose second-order finite differences with m=3 are used to discretize the heat equation on x \\in [0,2], with boundary conditions u_x(0,t)=0 and u_x(2,t)=1. If at some time t, u_1=1 and u_2=2, set up and solve the equations \n\n(11.5.6) for u_0 and u_m.\n\n⌨ Use \n\nFunction 11.5.2 to solve the heat equation for 0\\le x \\le 5 with initial condition u(x,0)=x(5-x) and subject to the boundary conditions u(0,t)=0, u(5,t)-u_x(5,t)=5. Plot the solution at t=1 and find the value of u(2.5,1).\n\nConsider \n\nDemo 11.5.4, combining diffusion with a nonlinear source term.\n\n(a) ✍ Suppose we ignore the diffusion. Use separation of variables (or computer algebra) to solve the IVP u_t=u^2, u(0) = A>0. What happens as t\\to 1/A from below?\n\n(b) ⌨ Try to continue the solution in the demo to t=1. What happens?\n\n(c) ⌨ Let the initial condition be u(x,0) = C x^4(1-x)^2; the demo uses C=400. To the nearest 10, find a critical value C_0 such that the solution approaches zero asymptotically if C < C_0, but not otherwise.\n\n⌨ The Allen–Cahn equation is used as a model for systems that prefer to be in one of two stable states. The governing PDE isu_t = u(1-u^2) + \\epsilon u_{xx}.\n\nFor this problem, assume \\epsilon=10^{-3}, -1\\le x \\le 1, boundary conditions u(\\pm 1,t) = -1 and initial conditionu(x,0) = -1 + \\beta (1-x^2) e^{-20x^2},\n\nwhere β is a parameter. Use \n\nFunction 11.5.2 with m=199.\n\n(a) Solve the problem with \\beta=1.1 up to time t=8, plotting the solution at 6 equally spaced times. (You should see the solution decay down to the constant value -1.)\n\n(b) Solve again with \\beta = 1.6. (This time the part of the bump will grow to just about reach u=1, and stay there.)\n\n⌨ The Fisher equation is u_t=u_{xx} + u - u^2. Assume that 0\\le x \\le 6 and that the boundary conditions are u_x(0,t)=u(6,t)=0.\n\n(a) For the initial condition u(x,0) = \\frac{1}{2}[1+\\cos(\\pi x/2)], use \n\nFunction 11.5.2 with m=80 to solve the Fisher equation and plot the solution at times t=0,0.5,\\ldots,3. What is u(0,3)?\n\n(b) Repeat part (a), but increase the final time until it appears that the solution has reached a steady state (i.e., stopped changing in time). Find an accurate value of u(0,t) as t \\to \\infty.\n\n(c) If we set u_t=0 in the Fisher equation at steady state, we get a TPBVP in u(x). Use \n\nFunction 10.5.1 with m=300 to solve this BVP, and make sure that the value at x=0 matches the result of part (b) to at least four digits.\n\n⌨ Modify \n\nFunction 11.5.2 for the special case of Dirichlet boundary conditions, in which \n\n(11.5.2) becomes simplyu(a,t) = \\alpha,\\; u(b,t)=\\beta.\n\nYour function should accept numbers α and β as input arguments in place of g_1 and g_2. Test your function on the problem in \n\nDemo 11.5.3.\n\n⌨ Modify \n\nFunction 11.5.2 for the special case of homogeneous Neumann boundary conditions. There is no longer any need for the input arguments for g_1 and g_2. Your implementation should solve a 2\\times 2 linear system of equations to find the boundary values within the nested function extend. Test your function on the heat equation on x \\in [0,4], t\\in [0,1] with initial condition u(x,0)=x^2(4-x)^4.\n\nAn important advanced feature of Julia is multiple dispatch, which allows you to make multiple definitions of a function for different sequences and types of input arguments. Thus, addition to the original \n\nFunction 11.5.2, we could also define a modified version in which g₁ and g₂ are of numeric type for the Dirichlet case. The correct version would be chosen (dispatched) depending on how the boundary conditions were supplied by the caller, allowing us speed when possible and generality as a fallback.","type":"content","url":"/boundaries#exercises","position":7},{"hierarchy":{"lvl1":"The method of lines"},"type":"lvl1","url":"/methodlines","position":0},{"hierarchy":{"lvl1":"The method of lines"},"content":"Our strategy in \n\nBlack–Scholes equation was to discretize both the time and space derivatives using finite differences, then rearrange so that we could march the solution forward through time. It was partially effective, but as \n\nDemo 11.1.3 shows, not a sure thing, for reasons we look into starting in the next section.\n\nFirst, though, we want to look at a broader version of the discretization approach. To introduce ideas, let’s use the simpler heat equation, u_t = u_{xx}, as a model. Because boundaries always complicate things, we will start by doing the next best thing to having no boundaries at all: periodic end conditions. Specifically, we will solve the PDE over 0\\le x < 1 and require at all times thatu(x+1,t)=u(x,t) \\quad \\text{for all $x$}.\n\nThis is a little different from simply u(1,t)=u(0,t), as \n\nFigure 11.2.1 illustrates.\n\n\n\nFigure 11.2.1:Left: A function whose values are the same at the endpoints of an interval does not necessarily extend to a smooth periodic function. Right: For a truly periodic function, the function values and all derivatives match at the endpoints of one period.","type":"content","url":"/methodlines","position":1},{"hierarchy":{"lvl1":"The method of lines","lvl2":"Semidiscretization"},"type":"lvl2","url":"/methodlines#semidiscretization","position":2},{"hierarchy":{"lvl1":"The method of lines","lvl2":"Semidiscretization"},"content":"As always, we use \\hat{u} when we specifically refer to the exact solution of the PDE. In order to avoid carrying along redundant information about the function, we use x_i = ih only for i=0,\\ldots,m-1, where h=1/m, and it’s understood that a reference to x_m is silently translated to one at x_0. More generally, we have the identity  \\hat{u}(x_i,t) = \\hat{u}\\bigl(x_{(i \\bmod{m})},t \\bigr)\n\nfor the exact solution \\hat{u} at any value of i.\n\nNext we define a vector \\mathbf{u} by\\mathbf{u}(t) = \\begin{bmatrix} u_0(t) \\\\ u_1(t) \\\\ \\vdots \\\\ u_n(t) \\end{bmatrix}.\n\nThis step is called semidiscretization, since space is discretized but time is not. As in \n\nChapter 10, we will replace u_{xx} with multiplication of \\mathbf{u} by a differentiation matrix \\mathbf{D}_{xx}. The canonical choice is the three-point finite-difference formula \n\n(5.4.12), which in light of the periodicity \n\n(11.2.2) leads to\\mathbf{D}_{xx} = \\frac{1}{h^2}\n  \\begin{bmatrix}\n  -2 & 1 & & & 1 \\\\\n  1 & -2 & 1 & & \\\\\n  & \\ddots & \\ddots & \\ddots & \\\\\n  & & 1 & -2 & 1 \\\\\n  1 &  & & 1 & -2\n  \\end{bmatrix}.\n\nNote well how the first and last rows have elements that “wrap around” from one end of the domain to the other by periodicity. Because we will be using this matrix quite a lot, we create \n\nFunction 11.2.1 to compute it, as well as the corresponding second-order first derivative matrix \\mathbf{D}_x for periodic end conditions.\n\ndiffper\n\nDifferentiation matrices for periodic end conditions\n\n\"\"\"\n    diffper(n, xspan)\n\nConstruct 2nd-order differentiation matrices for functions with\nperiodic end conditions, using `n` unique nodes in the interval\n`xspan`. Returns a vector of nodes and the matrices for the first\nand second derivatives.\n\"\"\"\nfunction diffper(n, xspan)\n    a, b = xspan\n    h = (b - a) / n\n    x = @. a + h * (0:n-1)   # nodes, omitting the repeated data\n\n    # Construct Dx by diagonals, then correct the corners.\n    dp = fill(0.5 / h, n-1)       # superdiagonal\n    dm = fill(-0.5 / h, n-1)      # subdiagonal\n    Dx = diagm(-1 => dm, 1 => dp)\n    Dx[1, n] = -1 / 2h\n    Dx[n, 1] = 1 / 2h\n\n    # Construct Dxx by diagonals, then correct the corners.\n    d0 = fill(-2 / h^2, n)        # main diagonal\n    dp = ones(n-1) / h^2          # superdiagonal and subdiagonal\n    Dxx = diagm(-1 => dp, 0 => d0, 1 => dp)\n    Dxx[1, n] = 1 / h^2\n    Dxx[n, 1] = 1 / h^2\n\n    return x, Dx, Dxx\nend\n\nDifferentiation matrices for periodic end conditions\n\nfunction [x,Dx,Dxx] = diffper(n,xspan)\n%DIFFPER   Differentiation matrices for periodic end conditions. \n% Input:\n%   n      number of subintervals (integer)\n%   xspan  endpoints of domain (vector)\n% Output:\n%   x    equispaced nodes (length n)\n%   Dx   matrix for first derivative (n by n)\n%   Dxx  matrix for second derivative (n by n)\n\na = xspan(1);  b = xspan(2);\nh = (b-a)/n;\nx = a + h*(0:n-1)';   % nodes, omitting the repeated data\n\n% Construct Dx by diagonals, then correct the corners.\ndp = 0.5*ones(n-1,1)/h;      % superdiagonal\ndm = -0.5*ones(n-1,1)/h;     % subdiagonal\nDx = diag(dm,-1) + diag(dp,1);\nDx(1,n) = -1/(2*h);\nDx(n,1) = 1/(2*h);\n\n% Construct Dxx by diagonals, then correct the corners.\nd0 =  -2*ones(n,1)/h^2;      % main diagonal\ndp =  ones(n-1,1)/h^2;       % superdiagonal\ndm =  dp;                    % subdiagonal\nDxx = diag(dm,-1) + diag(d0) + diag(dp,1);\nDxx(1,n) = 1/(h^2);\nDxx(n,1) = 1/(h^2);\n    \n\nDifferentiation matrices for periodic end conditions\n\ndef diffper(n, xspan):\n    \"\"\"\n    diffper(n, xspan)\n\n    Construct 2nd-order differentiation matrices for functions with periodic end\n    conditions, using `n` unique nodes in the interval `xspan`. Return a vector of\n    nodes and the  matrices for the first and second derivatives.\n    \"\"\"\n    a, b = xspan\n    h = (b - a) / n\n    x = a + h * np.arange(n)  # nodes, omitting the repeated data\n\n    # Construct Dx by diagonals, then correct the corners.\n    dp = 0.5 / h * np.ones(n - 1)  # superdiagonal\n    dm = -0.5 / h * np.ones(n - 1)  # subdiagonal\n    Dx = np.diag(dm, -1) + np.diag(dp, 1)\n    Dx[0, -1] = -1 / (2 * h)\n    Dx[-1, 0] = 1 / (2 * h)\n\n    # Construct Dxx by diagonals, then correct the corners.\n    d0 = -2 / h**2 * np.ones(n)  # main diagonal\n    dp = np.ones(n - 1) / h**2  # superdiagonal and subdiagonal\n    Dxx = np.diag(d0) + np.diag(dp, -1) + np.diag(dp, 1)\n    Dxx[0, -1] = 1 / (h**2)\n    Dxx[-1, 0] = 1 / (h**2)\n\n    return x, Dx, Dxx\n\nThe PDE u_t=u_{xx} is now approximated by the semidiscrete problem  \\frac{d \\mathbf{u}(t)}{d t} = \\mathbf{D}_{xx} \\mathbf{u}(t),\n\nwhich is simply a linear, constant-coefficient system of ordinary differential equations. Given the initial values \\mathbf{u}(0) obtained from u(x_i,0), we have an initial-value problem that we already know how to solve!\n\nSemidiscretization is often called the method of lines. Despite the name, it is not exactly a single method because both space and time discretizations have to be specified in order to get a concrete algorithm. The key concept is the separation of those two discretizations, and in that way, it’s related to separation of variables in analytic methods for the heat equation.\n\nSuppose we solve \n\n(11.2.5) using the Euler IVP integrator \n\n(6.2.5) from \n\nEuler’s method (and also AB1 from \n\nMultistep methods). We select a time step τ and discrete times t_j=j\\tau, j=0,1,\\ldots,n. We can discretize the vector \\mathbf{u} in time as well to get a sequence \\mathbf{u}_j \\approx \\mathbf{u}(t_j) for varying j. (Remember the distinction in notation between \\mathbf{u}_j, which is a vector, and u_j, which is a single element of a vector.)\n\nThus, a fully discrete method for the heat equation is\\mathbf{u}_{j+1} = \\mathbf{u}_j + \\tau ( \\mathbf{D}_{xx} \\mathbf{u}_j) = (\\mathbf{I} + \\tau \\mathbf{D}_{xx} ) \\mathbf{u}_j.\n\nForward Euler for the heat equation\n\nExample 11.2.2\n\nLet’s implement the method of \n\nExample 11.2.1 with second-order space semidiscretization.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1]);\ntfinal = 0.15 \nn = 2400           # number of time steps\nτ = tfinal / n     # time step    \nt = τ * (0:n)      # time values\n\nNext we set an initial condition. It isn’t mathematically periodic, but the end values and derivatives are so small that for numerical purposes it may as well be.\n\nusing Plots\nU = zeros(m, n+1);\nU[:, 1] = @. exp( -60 * (x - 0.5)^2 )\nplot(x, U[:, 1];\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\"),\n    title=\"Initial condition\")\n\nThe Euler time stepping simply multiplies \\mathbf{u}_j by the constant matrix in \n\n(11.2.6) at each time step. Since that matrix is sparse, we will declare it as such, even though the run-time savings may not be detectable for this small value of m.\n\nusing SparseArrays\nA = sparse(I + τ * Dxx)\nfor j in 1:n\n    U[:, j+1] = A * U[:, j]\nend\n\nplot_idx = 1:10:31\nplot_times = round.(t[plot_idx], digits=4)\nlabels = [\"t = $t\" for t in plot_times]\nplot(x, U[:, plot_idx];\n    label=reshape(labels, 1, :),  legend=:topleft,  \n    title=\"Heat equation by forward Euler\",\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\", [-0.25, 1]))\n\nThings seem to start well, with the initial peak widening and shrinking. But then there is a nonphysical growth in the solution.\n\nanim = @animate for j in 1:101\n    plot(x, U[:, j];\n    label=@sprintf(\"t=%.5f\", t[j]),\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", [-1, 2]),\n    dpi=150,  title=\"Heat equation by forward Euler\")\nend\nmp4(anim, \"figures/diffusionFE.mp4\")\n\nThe growth in norm is exponential in time.\n\nM = vec( maximum(abs, U, dims=1) )   \nplot(t[1:1000], M[1:1000];\n    xaxis=(L\"t\"),  yaxis=(:log10, L\"\\max_x |u(x,t)|\"),\n    title=\"Nonphysical growth\")\n\nExample 11.2.2\n\nLet’s implement the method of \n\nExample 11.2.1 with second-order space semidiscretization.\n\nm = 100;  \n[x, Dx, Dxx] = diffper(m, [0, 1]);\nIx = eye(m);\n\nNext we set an initial condition. It isn’t mathematically periodic, but the end values and derivatives are so small that for numerical purposes it may as well be.\n\ntfinal = 0.15;  n = 2400;  \ntau = tfinal / n;  t = tau * (0:n)';\nU = zeros(m, n+1);\nU(:, 1) = exp( -60*(x - 0.5).^2 );\n\nThe Euler time stepping simply multiplies the solution vector by the constant matrix in \n\n(11.2.6) at each time step. Since that matrix is sparse, we will declare it as such, even though the run-time savings may not be detectable for this small value of m.\n\nA = sparse(Ix + tau * Dxx);\nfor j = 1:n\n    U(:, j+1) = A * U(:,j);\nend\n\nindex_times = 1:10:31;\nshow_times = t(index_times);\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2e\", t(j));\n    plot(x, U(:, j), displayname=str) \n    hold on\nend\nlegend(location=\"northwest\")\nxlabel('x'), ylabel('u(x,t)')\ntitle('Heat equation by forward Euler')\n\nYou see above that things seem to start well, with the initial peak widening and shrinking. But then there is a nonphysical growth in the solution.\n\nclf\nindex_times = 1:101;\nplot(x, U(:, 1))\nhold on,  grid on\naxis([0, 1, -1, 2])\ntitle('Heat equation by forward Euler') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/diffusionFE.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = index_times\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.3f\", t(frame));\n    text(0.05, 0.92, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThe growth in norm is exponential in time.\n\nM = max(abs(U), [], 1);     % max in each column\nclf,  semilogy(t, M)\nxlabel('t'), ylabel('max_x |u(x,t)|') \ntitle('Nonphysical growth')\n\nExample 11.2.2\n\nLet’s implement the method of \n\nExample 11.2.1 with second-order space semidiscretization.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1])\n\ntfinal = 0.15  \nn = 2400                 # number of time steps  \ntau = tfinal / n         # time step\nt = tau * arange(n+1)    # time values\n\nNext we set an initial condition. It isn’t mathematically periodic, but the end values and derivatives are so small that for numerical purposes it may as well be.\n\nU = zeros([m, n+1])\nU[:, 0] = exp(-60 * (x - 0.5) ** 2)\nplot(x, U[:, 0])\nxlabel(\"x\");  ylabel(\"u(x,0)\")\ntitle(\"Initial condition\");\n\nThe Euler time stepping simply multiplies the solution vector by the constant matrix in \n\n(11.2.6) at each time step. Since that matrix is sparse, we will declare it as such, even though the run-time savings may not be detectable for this small value of m.\n\nimport scipy.sparse as sp\nI = sp.eye(m)\nA = I + tau * sp.csr_array(Dxx)\nfor j in range(n):\n    U[:, j+1] = A @ U[:, j]\n\nplot(x, U[:, :31:10])\nylim([-0.25, 1])\nxlabel(\"$x$\");  ylabel(\"$u(x,t)$\")\nlegend([f\"$t={tj:.2e}$\" for tj in t[:60:20]])\ntitle(\"Heat equation by forward Euler\");\n\nYou see above that things seem to start well, with the initial peak widening and shrinking. But then there is a nonphysical growth in the solution.\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 1), ylim=(-1, 2))\nax.grid()\n\nline, = ax.plot([], [], '-', lw=2)\nax.set_title(\"Heat equation by forward Euler\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(j):\n    line.set_data(x, U[:, j])\n    time_text.set_text(f\"t = {t[j]:.2e}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, 100), blit=True)\nanim.save(\"figures/diffusionFE.mp4\", fps=24)\nclose()\n\nThe growth in norm is exponential in time.\n\nM = abs(U).max(axis=0)  # max in each column\nsemilogy(t[:500], M[:500])\nxlabel(\"$t$\");  ylabel(\"$\\\\max_x |u(x,t)|$\")\ntitle(\"Nonphysical growth\");\n\nThe method in \n\nExample 11.2.1 and \n\nDemo 11.2.2 is essentially the same one we used for the Black–Scholes equation in \n\nBlack–Scholes equation. By changing the time integrator, we can get much better results.\n\nAn alternative time discretization of \n\n(11.2.5) is to use the backward Euler (AM1) method, resulting in\\begin{split}\n    \\mathbf{u}_{j+1} &= \\mathbf{u}_j + \\tau (\\mathbf{D}_{xx} \\mathbf{u}_{j+1})\\\\\n    (\\mathbf{I} - \\tau \\mathbf{D}_{xx}) \\mathbf{u}_{j+1} &= \\mathbf{u}_j.\n\\end{split}\n\nBecause backward Euler is an implicit method, a linear system must be solved for \\mathbf{u}_{j+1} at each time step.\n\nBackward Euler for the heat equation\n\nExample 11.2.4\n\nNow we apply backward Euler to the heat equation. We will reuse the setup from \n\nDemo 11.2.2. Since the matrix in \n\n(11.2.7) never changes during the time stepping, we do the necessary LU factorization only once.\n\nusing SparseArrays\nB = sparse(I - τ * Dxx)\nfactor = lu(B)\nfor j in 1:n\n    U[:, j+1] = factor \\ U[:, j]\nend\n\nusing Plots\nidx = 1:600:n+1\ntimes = round.(t[idx], digits=4)\nlabel = reshape([\"t = $t\" for t in times], 1, length(idx))\nplot(x,U[:, idx];\n    label, legend=:topleft,\n    title=\"Heat equation by backward Euler\",\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\", [0, 1]))\n\nanim = @animate for j in 1:20:n+1\n    plot(x, U[:, j];\n    label=@sprintf(\"t=%.5f\", t[j]),\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", [0, 1]),\n    dpi=150,  title=\"Heat equation by backward Euler\")\nend\nmp4(anim, \"figures/diffusionBE.mp4\")\n\nThis solution looks physically plausible, as the large concentration in the center diffuses outward until the solution is essentially constant. Observe that the solution remains periodic in space for all time.\n\nExample 11.2.4\n\nNow we apply backward Euler to the heat equation. Mathematically this means multiplying by the inverse of a matrix, but we interpret that numerically as a linear system solution. We will reuse the setup from \n\nDemo 11.2.2.\n\nB = sparse(Ix - tau * Dxx);\n[l, u] = lu(B);\nfor j = 1:n\n    U(:, j+1) = u \\ (l \\ U(:, j));\nend\n\nindex_times = 1:600:n+1;\nshow_times = t(index_times);\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2e\", t(j));\n    plot(x, U(:, j), displayname=str) \n    hold on\nend\nlegend(location=\"northwest\")\nxlabel('x'), ylabel('u(x,t)')\ntitle('Heat equation by backward Euler')\n\nclf\nindex_times = 1:24:n+1;\nplot(x, U(:, 1))\nhold on,  grid on\naxis([0, 1, -0.25, 1])\ntitle('Heat equation by backward Euler') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/diffusionBE.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = index_times\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.3f\", t(frame));\n    text(0.05, 0.92, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThis solution looks physically plausible, as the large concentration in the center diffuses outward until the solution is essentially constant. Observe that the solution remains periodic in space for all time.\n\nExample 11.2.4\n\nNow we apply backward Euler to the heat equation. Mathematically this means multiplying by the inverse of a matrix, but we interpret that numerically as a linear system solution. We will reuse the setup from \n\nDemo 11.2.2.\n\nfrom scipy.sparse.linalg import spsolve\nB = sp.csr_matrix(I - tau * Dxx)\nfor j in range(n):\n    U[:, j + 1] = spsolve(B, U[:, j])\n\nplot(x, U[:, ::500])\nxlabel(\"$x$\")\nylabel(\"$u(x,t)$\")\nlegend([f\"$t={tj:.2g}$\" for tj in t[::500]])\ntitle(\"Heat equation by backward Euler\");\n\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 1), ylim=(-0.25, 1))\nax.grid()\n\nline, = ax.plot([], [], '-', lw=2)\nax.set_title(\"Backward Euler\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, n+1, 20), blit=True)\nanim.save(\"figures/diffusionBE.mp4\", fps=30)\nclose()\n\nThis solution looks physically plausible, as the large concentration in the center diffuses outward until the solution is essentially constant. Observe that the solution remains periodic in space for all time.\n\nDemo 11.2.4 suggests that implicit time stepping methods have an important role in diffusion. We will analyze the reason in the next few sections.","type":"content","url":"/methodlines#semidiscretization","position":3},{"hierarchy":{"lvl1":"The method of lines","lvl2":"Black-box IVP solvers"},"type":"lvl2","url":"/methodlines#black-box-ivp-solvers","position":4},{"hierarchy":{"lvl1":"The method of lines","lvl2":"Black-box IVP solvers"},"content":"Instead of coding one of the Runge–Kutta or multistep formulas directly for a method of lines solution, we could use any of the IVP solvers from Chapter 6, or a solver from the DifferentialEquations package, to solve the ODE initial-value problem \n\n(11.2.5).\n\nAdaptive time stepping for the heat equation\n\nExample 11.2.5\n\nWe set up the semidiscretization and initial condition in x just as before.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1])\nu0 = @. exp( -60*(x - 0.5)^2 );\n\nNow, however, we apply \n\nFunction 6.5.2 (rk23) to the initial-value problem \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nusing OrdinaryDiffEq\ntfinal = 0.25\nODE = (u, p, t) -> Dxx * u  \nIVP = ODEProblem(ODE, u0, (0, tfinal))\nt, u = FNC.rk23(IVP, 1e-5);\n\nWe check that the resulting solution looks realistic.\n\nplt = plot(\n    title=\"Heat equation by rk23\",\n    legend=:topleft,  \n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\", [0, 1]))\nfor idx in 1:600:n+1\n    plot!(x, u[idx]; label=\"t = $(round.(t[idx], digits=4))\")\nend\nplt\n\nanim = @animate for j in 1:20:1600\n    plot(x, u[j];\n    label=@sprintf(\"t=%.4f\", t[j]),\n      xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", [0, 1]),\n      dpi=150,  title=\"Heat equation by rk23\")\nend\nmp4(anim, \"figures/diffusionRK23.mp4\")\n\nThe solution appears to be correct. But the number of time steps that were selected automatically is surprisingly large, considering how smoothly the solution changes.\n\nprintln(\"Number of time steps for rk23: $(length(t)-1)\")\n\nNow we apply a solver from DifferentialEquations.\n\nu = solve(IVP, Rodas4P());\nprintln(\"Number of time steps for Rodas4P: $(length(u.t) - 1)\")\n\nThe number of steps selected is reduced by a factor of more than 100!\n\nExample 11.2.5\n\nWe set up the semidiscretization and initial condition in x just as before.\n\nm = 100;  \n[x, Dx, Dxx] = diffper(m, [0, 1]);\nIx = eye(m);\nu0 = exp( -60 * (x - 0.5).^2 );\n\nNow, however, we apply a standard solver using solve_ivp to the initial-value problem \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\ntfinal = 0.05;\nf = @(t, u, p) Dxx * u;\nivp = ode(ODEFcn=f);\nivp.InitialTime = 0;\nivp.InitialValue = u0;\nivp.Solver = 'ode45';\n[u, sol] = solutionFcn(ivp, 0, tfinal);\n\nclf\nfor t = linspace(0, 0.05, 5)\n    str = sprintf(\"t = %.3f\", t);\n    plot(x, u(t), displayname=str)\n    hold on\nend\nxlabel(\"x\"),  ylabel(\"u(x,t)\")\nlegend()\ntitle(\"Heat equation by ode45\")\n\nThe solution appears to be correct. But the number of time steps that were selected automatically is surprisingly large, considering how smoothly the solution changes.\n\ntime_steps_ode45 = length(sol.Time) - 1\n\nNow we apply a different solver called BDF.\n\nivp.Solver = \"ode15s\";\n[u, sol] = solutionFcn(ivp, 0, tfinal);\ntime_steps_ode15s = length(sol.Time) - 1\n\nThe number of steps selected was reduced by a factor of 20!\n\nExample 11.2.5\n\nWe set up the semidiscretization and initial condition in x just as before.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1])\nu0 = exp(-60 * (x - 0.5) ** 2)\n\nNow, however, we apply a standard solver using solve_ivp to the initial-value problem \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nfrom scipy.integrate import solve_ivp\ntfinal = 0.05\nf = lambda t, u: Dxx @ u\nsol = solve_ivp(f, [0, tfinal], u0, method=\"RK45\", dense_output=True)\n\nt = linspace(0, 0.05, 5)\nplot(x, sol.sol(t))\nxlabel(\"$x$\"),  ylabel(\"$u(x,t)$\")\nlegend([f\"$t={tj:.4g}$\" for tj in t])\ntitle(\"Heat equation by RK45\");\n\nThe solution appears to be correct. But the number of time steps that were selected automatically is surprisingly large, considering how smoothly the solution changes.\n\nprint(f\"RK45 took {len(sol.t) - 1} steps\")\n\nNow we apply a different solver called BDF.\n\nsol = solve_ivp(f, [0, tfinal], u0, method=\"BDF\")\nprint(f\"BDF took {len(sol.t) - 1} steps\")\n\nThe number of steps selected was reduced by a factor of 20!\n\nThe adaptive time integrators can all produce solutions. But, as seen in \n\nDemo 11.2.5, they are not equivalent in every important sense. Whether we choose to implement a method directly with a fixed step size, or automatically with adaptation, there is something crucial to understand about the semidiscrete problem \n\n(11.2.5) that will occupy our attention in the next two sections.","type":"content","url":"/methodlines#black-box-ivp-solvers","position":5},{"hierarchy":{"lvl1":"The method of lines","lvl2":"Exercises"},"type":"lvl2","url":"/methodlines#exercises","position":6},{"hierarchy":{"lvl1":"The method of lines","lvl2":"Exercises"},"content":"⌨ Revisit \n\nDemo 11.2.2. For each m=20,30,\\dots,120 points in space, let n=20,30,40,\\dots in turn until you reach the smallest n such that the numerical solution remains bounded above by 2 for all time; call this value N(m). Make a log-log plot of N(m) as a function of m. If you suppose that N=O(m^p) for a simple rational number p, what is a reasonable hypothesis for p?\n\nIn \n\nDemo 11.2.5, as t\\to \\infty the solution u(x,t) approaches a value that is constant in both space and time.\n\n(a) ⌨ Set m=400 and use Rodas4P, as shown in \n\nDemo 11.2.5, to find this constant value to at least eight digits of accuracy.\n\n(b) ✍ Prove that \\int_0^1 u(x,t) \\,dx is constant in time.\n\n(c) ⌨ Use \n\nFunction 5.6.1 on the initial condition function, and compare to the result of part (a).\n\n✍ Apply the trapezoid IVP formula (AM2) to the semidiscretization \n\n(11.2.5) and derive what is known as the Crank–Nicolson method:(\\mathbf{I} - \\tfrac{1}{2}\\tau \\mathbf{D}_{xx}) \\mathbf{u}_{j+1} =  (\\mathbf{I} + \\tfrac{1}{2}\\tau\n\\mathbf{D}_{xx}) \\mathbf{u}_{j}.\n\nNote that each side of the method is evaluated at a different time level.\n\n⌨ Repeat \n\nDemo 11.2.4 using the Crank–Nicolson method \n\n(11.2.8). Then try for n=240 as well, which uses a time step ten times larger than before. Does the solution remain stable?\n\nThe PDE u_t = 2u + u_{xx} combines growth with diffusion.\n\n(a) ✍ Derive an equation analogous to \n\n(11.2.7) that combines second-order semidiscretization in space with the backward Euler solver in time.\n\n(b) ⌨ Apply your formula from part (a) to solve this PDE with periodic boundary conditions for the same initial condition as in \n\nDemo 11.2.4. Use  m=200 points in space and n=1000 time levels. Plot the solution on one graph at times t=0,0.04,0.08,\\ldots,0.2, or animate the solution over 0\\le t \\le 0.2.\n\n✍ In this problem, you will analyze the convergence of the explicit method given by \n\n(11.2.6).  Recall that the discrete approximation u_{i,j} approximates the solution at x_i and t_j.\n\n(a) Write the method in scalar form asu_{i,j+1} = (1-2\\lambda) u_{i,j} + \\lambda u_{i+1,j} + \\lambda u_{i-1,j},\n\nwhere \\lambda = \\tau/h^2>0.\n\n(b) Taylor series of the exact solution \\hat{u} imply that\\begin{align*}\n        \\hat{u}_{i,j+1} &= u_{i,j} + \\frac{\\partial \\hat{u}}{\\partial t} (x_i,t_j) \\tau + O(\\tau^2),\\\\\n        % \\frac{\\partial^2 u}{\\partial t^2} (x_i,\\bar{t}) \\frac{\\tau^2}{2}\n          \\hat{u}_{i\\pm1,j} &= \\hat{u}_{i,j} \\pm \\frac{\\partial \\hat{u}}{\\partial x} (x_i,t_j) h + \\frac{\\partial^2 \\hat{u}}{\\partial x^2} (x_i,t_j)\n      \\frac{h^2}{2} \\pm \\frac{\\partial^3 \\hat{u}}{\\partial x^3} (x_i,t_j)\n      \\frac{h^3}{6}+  O(h^4).\n      %\\frac{\\partial^4 u}{\\partial x^4} (\\bar{x}_\\pm,t_j) \\frac{h^4}{24}.\n      \\end{align*}\n\nUse these to show that\\begin{align*}\n          \\hat{u}_{i,j+1} & = \\left[ (1-2\\lambda) \\hat{u}_{i,j} + \\lambda \\hat{u}_{i+1,j} + \\lambda \\hat{u}_{i-1,j}\\right]\n          +  O\\Bigl(\\tau^2+h^2 \\Bigr)\\\\\n          &= F\\left( \\lambda,\\hat{u}_{i,j}, \\hat{u}_{i+1,j} , \\hat{u}_{i-1,j}\\right) + O\\Bigl(\\tau^2+h^2\\Bigr).\n      \\end{align*}\n\n(The last line should be considered a definition of the function F.)\n\n(c) The numerical solution satisfiesu_{i,j+1}=F\\bigl( \\lambda,u_{i,j}, u_{i+1,j} , u_{i-1,j}\\bigr)\n\nexactly. Using this fact, subtract u_{i,j+1} from both sides of the last line in part (b) to show thate_{i,j+1} = F\\left( \\lambda,e_{i,j}, e_{i+1,j} ,e_{i-1,j}\\right)  + O\\Bigl(\\tau^2+h^2\\Bigr),\n\nwhere e_{i,j}=\\hat{u}_{i,j}-u_{i,j} is the error in the numerical solution for all i and j .\n\n(d) Define E_j as the maximum of |e_{i,j}| over all values of i, and use the result of part (c) to show that if \\lambda<1/2 is kept fixed as h and τ approach zero, then for sufficiently small τ and h,E_{j+1}  = E_{j} + O\\Bigl(\\tau^2+h^2\\Bigr) \\le E_{j} + K_j\\bigl(\\tau^2+h^2\\bigr)\n\nfor a positive K_j independent of τ and h.\n\n(e) If the initial conditions are exact, then E_0=0. Use this to show finally that if the K_j are bounded above and \\lambda<1/2 is kept fixed, then E_n = O(\\tau) as \\tau\\to 0.","type":"content","url":"/methodlines#exercises","position":7},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-10","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"There are many texts on PDEs; a fairly popular undergraduate level text is by Haberman \n\nHaberman (1998).  A more advanced treatment is by\nOckendon et al. \n\nOckendon et al. (2003).\n\nFor a more traditional and analytical take on full discretization of the heat equation, one may consult Smith \n\nSmith (1985) or Morton and Mayers \n\nMorton & Mayers (2005).\n\nSeveral examples of using the method of lines with spectral method approximation may be found in Trefethen’s text \n\nTrefethen (2000).  A classic text on using spectral methods on the PDEs from fluid mechanics is Canuto et al. \n\nCanuto et al. (1988).  The literature on the complex computational fluid dynamics is vast, but one comprehensive monograph is by Roache \n\nRoache (1998).\n\nFor a first-hand account of the development of numerical methods for equations governing reservoir simulations (close to the heat equation), see the \n\narticle by D. W. Peaceman, reprinted from \n\nNash (1990).  Those were early days in computing!","type":"content","url":"/next-10","position":1},{"hierarchy":{"lvl1":"11. Diffusion equations"},"type":"lvl1","url":"/overview-10","position":0},{"hierarchy":{"lvl1":"11. Diffusion equations"},"content":"That’s impossible, even for a computer.\n\nWedge Antilles, Star Wars: A New Hope\n\nTo this point we have considered only ordinary differential equations, those having only one independent variable. In the rest of this book, we introduce the huge topic of solving partial differential equations (PDEs). We begin by pairing time with space.\n\nAs we have seen with initial- and boundary-value problems, the crucial difference between time and space is that information can flow only forward in time. PDEs that include both time and space variables are sometimes referred to as initial-boundary-value problems (IBVPs), because they bear characteristics of both types. As with IVP methods, our IBVP methods advance a solution in time. Like BVP methods, the boundary values must be respected, and all values in space are represented simultaneously.\n\nFinally, while we usually refer to “time” and “space,” the independent variables can be more abstract. (One such example is introduced in the next section.) However, they are all time-like or space-like. Mathematical analysis presented in courses on PDEs can be used to determine definitively what type of PDE one is dealing with.","type":"content","url":"/overview-10","position":1},{"hierarchy":{"lvl1":"Stiffness"},"type":"lvl1","url":"/stiffness","position":0},{"hierarchy":{"lvl1":"Stiffness"},"content":"In \n\nAbsolute stability we analyzed time step constraints for the semidiscrete heat equation \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u} in terms of stability regions and the eigenvalues \\lambda_j of the matrix. Since all the eigenvalues are negative and real, the one farthest from the origin, at about -4/h^2, determines the specific time step restriction. For an explicit method, or any method with a finite intersection with the negative real axis, the conclusion is \\tau=O(h^2).\n\nFor the Euler and backward Euler solvers, stability is not the only cause of a severely limited time step. Both methods are first-order accurate, with truncation errors that are O(\\tau). Since the spatial discretization we chose is second-order accurate, then we should choose \\tau=O(h^2) for accuracy as well as stability.\n\nThis calculus changes for second-order IVP solvers. When both time and space are discretized at second order, the total truncation error is O(h^2+\\tau^2), so it makes sense to use \\tau=O(h) for accuracy reasons alone. Therefore, a stability restriction of \\tau=O(h^2) is much more strict.\n\nProblems for which the time step is dictated by stability rather than accuracy are referred to as stiff. Stiffness is not a binary condition but a spectrum. It can arise in nonlinear problems and in problems having nothing to do with diffusion. Except for the mildest instances of stiffness, an implicit time stepping method is the best choice.","type":"content","url":"/stiffness","position":1},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Linearization"},"type":"lvl2","url":"/stiffness#linearization","position":2},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Linearization"},"content":"Why should the model equation y'=\\lambda y of absolute stability have wide relevance? Through diagonalization, it is easily generalized to  \\mathbf{u}'=\\mathbf{A} \\mathbf{u} for a constant matrix \\mathbf{A}. But that is still a severely limited type of problem.\n\nConsider a general vector nonlinear system\\mathbf{u}'=\\mathbf{f}(t,\\mathbf{u}).\n\nThe key to making a connection with absolute stability is to look not at an exact solution but to perturbations of one. Such perturbations always exist in real numerical solutions, such as those due to roundoff error, for example. But if we assume the perturbations are tiny, then we can use linear approximations to describe their evolution. If we conclude from such an approximation that the perturbation may grow without bound, then we must seriously question the value of the numerical solution.\n\nLet’s introduce more precision into the discussion. Suppose that \\hat{\\mathbf{u}}(t) is an exact solution that we wish to track, and that a perturbation has pushed us to a nearby solution curve \\hat{\\mathbf{u}}(t) + \\mathbf{v}(t). Substituting this solution into the governing ODE and appealing to a multidimensional Taylor series, we derive\\begin{split}\n[\\hat{\\mathbf{u}}(t) + \\mathbf{v}(t)]' &= \\mathbf{f}\\bigl(t,\\hat{\\mathbf{u}}(t) + \\mathbf{v}(t)\\bigr), \\\\\n\\hat{\\mathbf{u}}'(t) + \\mathbf{v}'(t) &= \\mathbf{f}\\left(t, \\hat{\\mathbf{u}}(t)\\right) + \\mathbf{J}(t) \\mathbf{v}(t) + O\\bigl( \\|\\mathbf{v}(t)\\|^2 \\bigr).\n\\end{split}\n\nWe have introduced the Jacobian matrix \\mathbf{J}, with entriesJ_{ij} = \\frac{\\partial f_i}{\\partial u_j}(t,\\hat{\\mathbf{u}}(t)).\n\nBy dropping the higher-order terms, which are negligible at least initially, we derive a linear ODE for the evolution of the perturbation.\n\nLinearization of an ODE\n\nA linearization of system \n\n(11.4.1) at an exact solution \\hat{\\mathbf{u}}(t) is\\mathbf{v}'(t) = \\mathbf{J}(t) \\mathbf{v}(t),\n\nwhere \\mathbf{v}(t) is a perturbation to the exact solution, and \\mathbf{J} is the Jacobian matrix \n\n(11.4.3).\n\nThe Oregonator is a well-known ODE system modeling a chemical oscillator and is given by\\begin{split}\nu_1'  & = s[u_2(1-u_1) + u_1(1-q u_1)], \\\\\nu_2'  & = s^{-1}(u_3-u_2-u_1u_2),      \\\\\nu_3'  & = w(u_1-u_3),\n\\end{split}\n\nwhere s, q, and w are constants. Linearization about an exact (albeit unknown) solution \\hat{\\mathbf{u}}(t) leads to the Jacobian\\mathbf{J} (t) =\n\\begin{bmatrix}\n  s(1 -\\hat{u}_2 - 2q\\hat{u}_1) & s(1-\\hat{u}_1)  & 0             \\\\\n  -\\hat{u}_2/s          & -(1+\\hat{u}_1)/s & 1/s           \\\\\n  w                  & 0             & -w\n\\end{bmatrix}.","type":"content","url":"/stiffness#linearization","position":3},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Freezing time"},"type":"lvl2","url":"/stiffness#freezing-time","position":4},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Freezing time"},"content":"While \n\n(11.4.4) is linear, the Jacobian matrix in it is time-dependent, which makes analysis difficult. If a perturbation is introduced at a moment t=t_\\star, we freeze the Jacobian there and consider\\mathbf{v}'=\\mathbf{A}\\mathbf{v}, \\quad \\mathbf{A}=\\mathbf{J}(t_\\star).\n\nThis equation is of the type we used in \n\nAbsolute stability to discuss the absolute stability of IVP solvers. This suggests the following.\n\nRule of thumb for absolute stability\n\nThe eigenvalues of the Jacobian appearing in the linearization about an exact solution, after scaling by the time step τ, must lie in the stability region of the IVP solver.\n\nWe have not stated a theorem here because we made several approximations and assumptions along the way that are not trivial to quantify. Nevertheless, if the rule of thumb is violated, we should expect perturbations to the exact solution to grow significantly with time, eventually rendering the numerical solution useless. Note that roundoff error is constantly introducing perturbations, so the rule of thumb applies along the entire trajectory of the numerical solution.\n\nSolution of the Oregonator\n\nExample 11.4.2\n\nIn \n\nExample 11.4.1 we derived a Jacobian matrix for the Oregonator model. Here is a numerical solution of the ODE.\n\nusing OrdinaryDiffEq, Plots\nfunction ode(u,p,t)\n    s,w,q = p\n    f = [ \n        s * ( u[2]*(1 - u[1]) + u[1]*(1 - q*u[1]) ),\n        (u[3] - u[2] - u[1] * u[2]) / s,   \n        w * (u[1] - u[3])\n        ]\n    return f\nend\ns, w, q = (77.27, .161, 8.375e-6)\noregon = ODEProblem(ode, [1., 2, 3], (0., 500.), [s, w, q])\nsol = solve(oregon)\nplot(sol, yscale=:log10, legend=:none, title=\"Solution of the Oregonator\")\n\nAt each value of the numerical solution, we can compute the eigenvalues of the Jacobian. Here we plot all of those eigenvalues in the complex plane.\n\nt,u = sol.t[1:2:end], sol.u[1:2:end]\nλ = fill(0.0im, length(t), 3)\nfor (k, u) in enumerate(u)\n    J = [\n    s*(1-u[2]-2q*u[1]) s*(1-u[1])        0 \n         -u[2]/s       -(1+u[1])/s     1/s \n            w               0           -w\n        ]\n    λ[k, :] .= eigvals(J)\nend\n\nscatter(real(λ), imag(λ), t;\n    xaxis=(\"Re(λ)\", 25000*(-5:2:-1)),  ylabel=\"Im(λ)\",  zlabel=\"t\",\n    title=\"Oregonator eigenvalues\")\n\nYou can see that there is one eigenvalue that ranges over a wide portion of the negative real axis and dominates stability considerations.\n\nExample 11.4.2\n\nIn \n\nExample 11.4.1 we derived a Jacobian matrix for the Oregonator model. Here is a numerical solution of the ODE.\n\nq = 8.375e-6;  s = 77.27;  w = 0.161;\nf = @(t, u, p) [ s*(u(2)- u(1) * u(2) + u(1) - q * u(1)^2);...\n    (-u(2) - u(1) * u(2) + u(3)) / s; ...\n    w*(u(1) - u(3)) ];\n\nivp = ode(ODEFcn=f);\nivp.InitialTime = 0;\nivp.InitialValue = [1; 2; 3];\nivp.Solver = \"ode15s\";\nsol = solve(ivp, 0, 500); \nclf,  semilogy(sol.Time, sol.Solution)\nxlabel('t'),  ylabel('u(t)')\ntitle('Oregonator')\n\nAt each value of the numerical solution, we can compute the eigenvalues of the Jacobian. Here we plot all of those eigenvalues in the complex plane.\n\nJ = @(u) [ -s*(u(2)+1-2*q*u(1)), s*(1-u(1)), 0; ...\n    -u(2)/s, (-1-u(1))/s, 1/s; ...\n    w,0,-w];\n\nt = sol.Time;\nu = sol.Solution;\nlambda = zeros(length(t) - 1, 3);\nfor j = 1:length(t)-1\n    lambda(j, :) = eig(J(u(:, j)));\nend\nplot3(real(lambda), imag(lambda), t(1:end-1), 'o')\nxlabel(\"Re $\\\\lambda$\"),  ylabel(\"Im $\\\\lambda$\"),  zlabel(\"$t$\")\ntitle(\"Oregonator eigenvalues\")\n\nYou can see that there is one eigenvalue that ranges over a wide portion of the negative real axis and dominates stability considerations.\n\nExample 11.4.2\n\nIn \n\nExample 11.4.1 we derived a Jacobian matrix for the Oregonator model. Here is a numerical solution of the ODE.\n\nfrom scipy.integrate import solve_ivp\nq, s, w = (8.375e-6, 77.27, 0.161)\n\ndef ode(t, u):\n    return array(\n        [\n            s * (u[1] - u[0] * u[1] + u[0] - q * u[0]**2),\n            (-u[1] - u[0] * u[1] + u[2]) / s,\n            w * (u[0] - u[2]),\n        ]\n    )\n\nu0 = array([1.0, 2.0, 3.0])\ntspan = (0, 500)\nstart = timer()\nsol = solve_ivp(ode, tspan, u0, method=\"BDF\")\nsemilogy(sol.t, sol.y.T)\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\ntitle(\"Oregonator\");\n\nAt each value of the numerical solution, we can compute the eigenvalues of the Jacobian. Here we plot all of those eigenvalues in the complex plane.\n\nJ = lambda u: array(\n    [\n        [-s * (u[1] + 1 - 2 * q * u[0]), s * (1 - u[0]), 0],\n        [-u[1] / s, (-1 - u[0]) / s, 1 / s],\n        [w, 0, -w],\n    ]\n)\n\nfrom scipy.linalg import eigvals\n\nlamb = array([eigvals(J(u)) for u in sol.y.T])\nax = figure().add_subplot(projection='3d')\nfor i in range(3):\n    ax.plot(real(lamb[:, i]), imag(lamb[:, i]), sol.t, \".\")\nax.set_xlabel(\"Re $\\\\lambda$\")\nax.set_ylabel(\"Im $\\\\lambda$\")\nax.set_zlabel(\"$t$\")\nax.set_title(\"Oregonator eigenvalues\");\n\nYou can see that there is one eigenvalue that ranges over a wide portion of the negative real axis and dominates stability considerations.","type":"content","url":"/stiffness#freezing-time","position":5},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Multiple time scales"},"type":"lvl2","url":"/stiffness#multiple-time-scales","position":6},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Multiple time scales"},"content":"The solution to y' = \\lambda y, y(0)=1 is \\exp(\\lambda t). If λ is real, this solution grows or decays by a factor of e at t=1/|\\lambda|. If \\lambda = i\\omega is imaginary, then the solution has sines and cosines of frequency ω. A complex λ combines these effects.\n\nWe may regard |\\lambda|^{-1}, which has units of time, as a characteristic time scale of dynamics due to eigenvalue λ.\n\nA Jacobian matrix with eigenvalues at different orders of magnitude therefore implies multiple time scales that the IVP solver needs to cope with. Say |\\lambda_1|\\gg |\\lambda_2|. Any explicit integrator will have a bounded stability region and therefore impose a time step restriction proportional to |\\lambda_1|^{-1}. Any good adaptive integrator will obey such a restriction naturally to control the error. But to observe the “slow” part of the solution, the simulation must go on for a time on the order of |\\lambda_2|^{-1}, which is much longer.\n\nIn \n\nDemo 11.4.2, for example, you can see a combination of fast changes and slow evolution.\n\nStiff solver for the Oregonator\n\nExample 11.4.3\n\nThe Rodas4P solver is good for stiff problems, and needs few time steps to solve the Oregonator from \n\nDemo 11.4.2.\n\noregon = remake(oregon, tspan=(0., 25.))\nsol = solve(oregon, Rodas4P())\nprintln(\"Number of time steps for Rodas4P: $(length(sol.t) - 1)\")\n\nBut if we apply \n\nFunction 6.5.2 to the problem, the step size will be made small enough to cope with the large negative eigenvalue.\n\nt,u = FNC.rk23(oregon,1e-4)\nprintln(\"Number of time steps for RK23: $(length(t) - 1)\")\n\nStarting from the eigenvalues of the Jacobian matrix, we can find an effective \\zeta(t) by multiplying with the local time step size. The values of \\zeta(t) for each time level are plotted below and color coded by component of the diagonalized system.\n\nλ = fill(1.0im, length(t),3)\nfor (k, u) in enumerate(u)\n    J = [\n    s*(1-u[2]-2q*u[1]) s*(1-u[1])        0 \n         -u[2]/s       -(1+u[1])/s     1/s \n            w               0           -w\n        ]\n    λ[k, :] .= eigvals(J)\nend\n\nζ = diff(t) .* λ[1:end-1,:]\nscatter(real(ζ), imag(ζ), m=2,\n    xlabel=\"Re(ζ)\",  ylabel=\"Im(ζ)\",\n    title=\"Oregonator stability\")\n\nRoughly speaking, the ζ values stay within or close to the RK2 stability region in \n\nFigure 11.3.2. Momentary departures from the region are possible, but time stepping repeatedly in that situation would cause instability.\n\nExample 11.4.3\n\nThe ode15s solver is good for stiff problems and needs few time steps to solve the Oregonator from \n\nDemo 11.4.2.\n\ntic,  sol = solve(ivp, 0, 26); \ntime_ode15s = toc\nnum_steps_ode15s = length(sol.Time) - 1\n\nBut if we apply \n\nFunction 6.5.2 to the problem, the step size will be made small enough to cope with the large negative eigenvalue.\n\ntic, [t, u] = rk23(ivp, 0, 26, 1e-5);\ntime_rk23 = toc\nnum_steps_rk23 = length(t) - 1\n\nStarting from the eigenvalues of the Jacobian matrix, we can find an effective \\zeta(t) by multiplying with the local time step size. The values of \\zeta(t) for each time level are plotted below and color coded by component of the diagonalized system.\n\nzeta = zeros(length(t) - 1, 3);\nfor j = 1:length(t)-1\n    lambda = eig(J(u(:, j)));\n    zeta(j, :) = (t(j+1) - t(j)) * lambda;\nend\nplot(zeta, 'o')\naxis equal, grid on\nxlabel('Re \\zeta'),  ylabel('Im \\zeta')\ntitle(\"Oregonator stability\")\n\nRoughly speaking, the ζ values stay within or close to the RK2 stability region in \n\nFigure 11.3.2. Momentary departures from the region are possible, but time stepping repeatedly in that situation would cause instability.\n\nExample 11.4.3\n\nThe BDF solver is good for stiff problems and needs few time steps to solve the Oregonator from \n\nDemo 11.4.2.\n\ntspan = (0, 25)\nstart = timer()\nsol = solve_ivp(ode, tspan, u0, method=\"BDF\")\nprint(f\"stiff solver took {timer() - start:.3f} seconds with {len(sol.t) - 1} time steps\")\n\nBut if we apply \n\nFunction 6.5.2 to the problem, the step size will be made small enough to cope with the large negative eigenvalue.\n\nstart = timer()\nt, u = FNC.rk23(ode, tspan, u0, 1e-6)\nprint(f\"rk23 solver took {timer() - start:.3f} seconds with {len(t) - 1} time steps\")\n\nStarting from the eigenvalues of the Jacobian matrix, we can find an effective \\zeta(t) by multiplying with the local time step size. The values of \\zeta(t) for each time level are plotted below and color coded by component of the diagonalized system.\n\nzeta = zeros([len(t)- 1, 3]) + 0j    # complex array\nfor i in range(len(t) - 1):\n    dt = t[i+1] - t[i]\n    lamb = eigvals(J(u[:, i]))\n    zeta[i] = lamb * dt\nplot(real(zeta), imag(zeta), \".\")\naxis(\"equal\")\nxlabel(\"Re $\\\\zeta$\")\nylabel(\"Im $\\\\zeta$\")\ntitle(\"Oregonator stability\");\n\nRoughly speaking, the ζ values stay within or close to the RK2 stability region in \n\nFigure 11.3.2. Momentary departures from the region are possible, but time stepping repeatedly in that situation would cause instability.","type":"content","url":"/stiffness#multiple-time-scales","position":7},{"hierarchy":{"lvl1":"Stiffness","lvl2":"A-stability"},"type":"lvl2","url":"/stiffness#a-stability","position":8},{"hierarchy":{"lvl1":"Stiffness","lvl2":"A-stability"},"content":"In general, the larger the stability region, the more generous the stability time step restriction will be. In the specific context of a semidiscretization of the heat equation, we observed that the eigenvalues of the Jacobian reached a distance O(h^{-2}) on the negative real axis. Consequently, any stability region that is bounded in the negative real direction will have a \\tau=O(h^2) restriction; only the leading constant will change.\n\nHence it is desirable in stiff problems generally, and diffusion problems in particular, to have a stability region that is unbounded in at least the negative real direction.\n\nA(α)- and A-stability\n\nA stability region that includes a sector of angle α in both directions from the negative real axis is called A(α)-stable. A time stepping method whose stability region contains the entire left half-plane is called A-stable.\n\nFor the heat equation, A(α)-stability for any \\alpha>0 suffices for unconditional stability.\n\nAn A-stable method has a stability region that includes all eigenvalues having nonpositive real part. In other words, all perturbations which ought to be bounded in time actually are. When an A-stable method is used, time step size can be based on accuracy considerations alone.\n\nReferring to \n\nFigure 11.3.1 and \n\nFigure 11.3.2, the backward Euler (AM1) and trapezoid (AM2) formulas are the only A-stable methods we have encountered. In fact, more accurate A-stable methods are not easy to come by.\n\nSecond Dahlquist stability barrier\n\nAn A-stable linear multistep method must be implicit and have order of accuracy no greater than 2.\n\nHence the trapezoid formula is as accurate as we can hope for in the family of A-stable linear multistep methods. The situation with Runge–Kutta methods is a little different, but not a great deal more favorable; we do not go into the details.","type":"content","url":"/stiffness#a-stability","position":9},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Exercises"},"type":"lvl2","url":"/stiffness#exercises","position":10},{"hierarchy":{"lvl1":"Stiffness","lvl2":"Exercises"},"content":"✍ Write the mechanical oscillator x''+cx'+kx=0 as a first-order linear system, \\mathbf{u}'=\\mathbf{A}\\mathbf{u}. Show that if c=k+1, this system is stiff as k\\to\\infty.\n\nThis exercise is about the IVP u'=\\cos(t) - 200(u-\\sin(t)), u(0)=0.\n\n(a) ✍ Show that u(t) = \\sin(t) is the exact solution, and find the linearization about this solution.\n\n(b) ✍ Find the lone eigenvalue of the Jacobian. What other time scale is also relevant in the solution?\n\n(c) ⌨ Use \n\nFunction 6.7.1 (ab4) to solve the IVP over t\\in[0,\\pi/2] with n=800,850,900,\\ldots,1200 steps. By comparing to the exact solution, show that the method gets either no accurate digits or at least 11 accurate digits.\n\nIn \n\nExample 6.3.4 we derived the following system for two pendulums hanging from a rod:\\begin{align*}\n      u_1' &= u_3, \\\\\n      u_2' &= u_4, \\\\\n      u_3' &= -\\gamma u_3 - \\frac{g}{L}\\sin u_1 + k(u_2-u_1), \\\\\n      u_4' &= -\\gamma u_4 - \\frac{g}{L}\\sin u_2 + k(u_1-u_2).\n    \\end{align*}\n\n(a) ✍ Use the approximation \\sin(x) \\approx x to write the problem as a linear system.\n\n(b) ⌨ Compute the eigenvalues of the linear system with \\gamma=0.1, g/L=1, and k=10^d for d=0,1,\\ldots,5. How fast does the ratio of largest to smallest eigenvalue (in magnitude) grow, as a function of k?\n\nThe equation u'=u^2-u^3 is a simple model for combustion of a flame ball in microgravity. (This problem is adapted from section 7.9 of \n\nMoler (2010).) After “ignition,” the exact solution rapidly approaches 1.\n\n(a) ⌨ Solve the problem with initial condition u(0) =0.001 for 0\\le t \\le 2000, using \n\nFunction 6.4.2 with n=2000 steps. Plot the solution.\n\n(b) ✍ Find the 1\\times 1 Jacobian of this system, and use it with \n\nFigure 11.3.2 to derive an upper bound on the time step of RK4 when u=1.\n\n(c) ⌨ Repeat part (a) with n=200,300,\\ldots,1000, and make a table of the error at the final time, assuming the exact solution is 1. How do the results relate to part (b)?\n\nThe van der Pol equation is a famous nonlinear oscillator given by  y'' - \\mu(1-y^2)y' + y = 0,\n\nwhere \\mu\\ge 1 is a constant.\n\n(a) ✍ Write the equation as a first-order system and find its Jacobian.\n\n(b) ✍ Find the eigenvalues of the Jacobian when y=\\pm 2 and y'=0.\n\n(c) ⌨ Solve the problem solve with \\mu=500, y(0) = y'(0) = 1, for 0\\le t \\le 2000. Plot y(t) as a function of t.\n\n(d) ⌨ Define M(t) as the minimum (i.e., most negative) real part of the eigenvalues of the Jacobian using the computed solution at time t. Evaluate M for each t=0,2,4,6,\\ldots,2000, and plot M(t). Explain how your plot relates to parts (b) and (c).","type":"content","url":"/stiffness#exercises","position":11},{"hierarchy":{"lvl1":"Absolute stability"},"type":"lvl1","url":"/absstab-advection","position":0},{"hierarchy":{"lvl1":"Absolute stability"},"content":"The CFL criterion gives a necessary condition for convergence. It suggests, but cannot confirm, that a step size of O(h) may be adequate in the advection equation. More details emerge when we adopt the semidiscretization point of view.\n\nLet the advection equation \n\n(12.2.1) over [0,1] be subjected to periodic end conditions. Suppose we use the central-difference matrix \\mathbf{D}_x defined in \n\n(12.1.7) to discretize the space derivative, leaving us with\\mathbf{u}' = -c \\mathbf{D}_x \\mathbf{u}.\n\nTo apply an IVP solver, we need to compare the stability region of the solver with the eigenvalues of -c \\mathbf{D}_x, as in \n\nAbsolute stability. You can verify (see \n\nExercise 1) that for m points in [0,1), these are  \\lambda_k = - i\\, c m \\sin \\left( \\frac{2\\pi k}{m} \\right), \\qquad k = 0,\\ldots,m-1.\n\nTwo things stand out about these eigenvalues: they are purely imaginary, which is consistent with conservation of magnitude, and they extend no farther than O(m)=O(h^{-1}) away from the origin. These characteristics suggest how to analyze the use of different time-stepping methods by referring to stability regions.\n\nEigenvalues for advection\n\nExample 12.3.1\n\nFor c=1 we get purely imaginary eigenvalues.\n\nusing Plots\nx, Dₓ = FNC.diffper(40, [0, 1])\nλ = eigvals(Dₓ);\nscatter(real(λ), imag(λ);\n    aspect_ratio = 1,  frame=:zerolines,\n    xlabel=\"Re λ\",  ylabel=\"Im λ\", \n    title=\"Eigenvalues for pure advection\",  legend=:none)\n\nLet’s choose a time step of \\tau=0.1 and compare to the stability regions of the Euler and backward Euler time steppers (shown as shaded regions):\n\nzc = @. cispi(2 * (0:360) / 360);     # points on |z|=1\nz = zc .- 1;                          # shift left by 1\nplot(Shape(real(z), imag(z)), color=RGB(.8, .8, 1))\nζ = 0.1 * λ\nscatter!(real(ζ), imag(ζ);\n    aspect_ratio=1,  frame=:zerolines,\n    xaxis=(\"Re ζ\", [-5, 5]),  yaxis=(\"Im ζ\", [-5, 5]),\n    title=\"Euler for advection\")\n\nIn the Euler case it’s clear that no real value of \\tau>0 is going to make ζ values fit within the stability region. Any method whose stability region includes none of the imaginary axis is an unsuitable choice for advection.\n\nz = zc .+ 1;                        # shift circle right by 1\nplot(Shape([-6, 6, 6, -6], [-6, -6, 6, 6]), color=RGB(.8, .8, 1))\nplot!(Shape(real(z), imag(z)), color=:white)\nscatter!(real(ζ), imag(ζ);\n    aspect_ratio=1,  frame=:zerolines,\n    xaxis=(\"Re ζ\", [-5, 5]),  yaxis=(\"Im ζ\", [-5, 5]),\n    title=\"Backward Euler for advection\")\n\nThe A-stable backward Euler time stepping tells the exact opposite story: it will be absolutely stable for any choice of the time step τ.\n\nExample 12.3.1\n\nFor c=1 we get purely imaginary eigenvalues.\n\n[x, Dx] = diffper(40, [0, 1]);\nlambda = eig(Dx);\nclf\nscatter(real(lambda), imag(lambda))\naxis equal,  grid on\ntitle('Eigenvalues for pure advection')\n\nLet’s choose a time step of \\tau=0.1 and compare to the stability regions of the Euler and backward Euler time steppers (shown as shaded regions):\n\nzc = exp( 1i * linspace(0,2*pi,361)' );    % points on |z|=1\nz = zc - 1;    % shift circle left by 1\nclf,  fill(real(z), imag(z), [.8, .8, 1])\nhold on,  scatter(real(0.1*lambda), imag(0.1*lambda))\naxis equal,  axis square\naxis([-5, 5, -5, 5]),  grid on\ntitle('Euler')\n\nIn the Euler case it’s clear that no real value of \\tau>0 is going to make ζ values fit within the stability region. Any method whose stability region includes none of the imaginary axis is an unsuitable choice for advection.\n\nclf,  fill([-6, 6, 6, -6],[-6, -6, 6, 6], [.8, .8, 1])\nz = zc + 1;   % shift circle right by 1\nhold on,  scatter(real(0.1*lambda), imag(0.1*lambda))\nfill(real(z), imag(z), 'w')\naxis equal,  axis square\naxis([-5 5 -5 5]),  grid on\ntitle('backward Euler')\n\nThe A-stable backward Euler time stepping tells the exact opposite story: it will be absolutely stable for any choice of the time step τ.\n\nExample 12.3.1\n\nFor c=1 we get purely imaginary eigenvalues.\n\nfrom scipy.linalg import eigvals\nx, Dx, Dxx = FNC.diffper(40, [0, 1])\nlamb = eigvals(Dx)\n\nplot(real(lamb), imag(lamb), \"o\")\naxis([-40, 40, -40, 40])\naxis(\"equal\")\ntitle(\"Eigenvalues for pure advection\");\n\nLet’s choose a time step of \\tau=0.1 and compare to the stability regions of the Euler and backward Euler time steppers (shown as shaded regions):\n\nzc = exp(2j * pi * arange(361) / 360)\n# points on |z|=1\n\nz = zc - 1    # shift circle left by 1\nfill(real(z), imag(z), color=(0.8, 0.8, 1))\nplot(real(0.1 * lamb), imag(0.1 * lamb), \"o\")\naxis([-5, 5, -5, 5]),  axis(\"equal\")\ntitle(\"Euler\");\n\nIn the Euler case it’s clear that no real value of \\tau>0 is going to make ζ values fit within the stability region. Any method whose stability region includes none of the imaginary axis is an unsuitable choice for advection.\n\nz = zc + 1    # shift circle right by 1\nfill([-6, 6, 6, -6], [-6, -6, 6, 6], color=(0.8, 0.8, 1))\nfill(real(z), imag(z), color=\"w\")\nplot(real(0.1 * lamb), imag(0.1 * lamb), \"o\")\naxis([-5, 5, -5, 5])\naxis(\"equal\")\ntitle(\"Backward Euler\");\n\nThe A-stable backward Euler time stepping tells the exact opposite story: it will be absolutely stable for any choice of the time step τ.\n\nMany PDEs that conserve quantities will have imaginary eigenvalues, causing Euler and some other IVP methods to fail regardless of step size. Diffusion problems, in which the eigenvalues are negative and real, are compatible with a wider range of integrators, though possibly with onerous step size requirements due to stiffness.\n\nThe location of eigenvalues near \\pm ic/h also confirms what the CFL condition was suggesting. In order to use RK4, for example, whose stability region intersects the imaginary axis at around \\pm 2.8i, the time step stability restriction is \\tau c/h \\le 2.8, or \\tau=O(h). This is much more favorable than for diffusion, whose eigenvalues were as large as O(h^{-2}), and it makes explicit IVP methods much more attractive for advection problems than for diffusion.","type":"content","url":"/absstab-advection","position":1},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Advection–diffusion equations"},"type":"lvl2","url":"/absstab-advection#advection-diffusion-equations","position":2},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Advection–diffusion equations"},"content":"The traffic flow equation \n\n(12.1.4) combines a nonlinear advection with a diffusion term. The simplest linear problem with the same feature is the advection–diffusion equationu_t+c u_x=\\epsilon u_{xx}.\n\nThe parameter ε controls the relative strength between the two mechanisms, and the eigenvalues accordingly vary between the purely imaginary ones of advection and the negative real ones of diffusion.\n\nEigenvalues for advection–diffusion\n\nExample 12.3.2\n\nThe eigenvalues of advection-diffusion are near-imaginary for \\epsilon\\approx 0 and get closer to the negative real axis as ε increases.\n\nplt = plot(\n    legend=:topleft,\n    aspect_ratio=1,\n    xlabel=\"Re ζ\",  ylabel=\"Im ζ\",\n    title=\"Eigenvalues for advection-diffusion\")\nx, Dₓ, Dₓₓ = FNC.diffper(40, [0, 1]);\nfor ϵ in [0.001, 0.01, 0.05]\n    λ = eigvals(-Dₓ + ϵ*Dₓₓ)\n    scatter!(real(λ), imag(λ), m=:o, label=\"\\\\epsilon = $ϵ\")\nend\nplt\n\nExample 12.3.2\n\nThe eigenvalues of advection-diffusion are near-imaginary for \\epsilon\\approx 0 and get closer to the negative real axis as ε increases.\n\n[x, Dx, Dxx] = diffper(40, [0, 1]);\ntau = 0.1;\nclf\nfor ep = [0.001 0.01 0.05]\n  lambda = eig(-Dx + ep*Dxx);\n  str = sprintf(\"\\\\epsilon = %.3f\", ep);\n  scatter(real(tau*lambda), imag(tau*lambda), displayname=str)\n  hold on\nend\naxis equal,  grid on\nlegend(location='northwest')\ntitle('Eigenvalues for advection-diffusion')\n\nExample 12.3.2\n\nThe eigenvalues of advection-diffusion are near-imaginary for \\epsilon\\approx 0 and get closer to the negative real axis as ε increases.\n\nx, Dx, Dxx = FNC.diffper(40, [0, 1])\ntau = 0.1\nfor ep in [0.001, 0.01, 0.05]:\n    lamb = eigvals(-Dx + ep * Dxx)\n    plot(real(tau * lamb), imag(tau * lamb), \"o\", label=f\"epsilon={ep:.1g}\")\naxis(\"equal\")\nlegend()\ntitle(\"Eigenvalues for advection-diffusion\");\n\nIn a nonlinear problem, the eigenvalues come from the linearization about an exact solution, as in \n\nStiffness.","type":"content","url":"/absstab-advection#advection-diffusion-equations","position":3},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Boundary effects"},"type":"lvl2","url":"/absstab-advection#boundary-effects","position":4},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Boundary effects"},"content":"Boundary conditions can have a dramatic effect on the eigenvalues of the semidiscretization. For instance, \n\nDemo 12.2.6 solves linear advection u_t=u_x on [0,1] with the homogeneous inflow condition u(0,t)=0. Exclusion of the boundary node from the semidiscretization \\mathbf{u} to get the interior vector \\mathbf{v} is equivalent to\\mathbf{v} = \\mathbf{E} \\mathbf{u}, \\quad   \\mathbf{u} = \\begin{bmatrix}  \\mathbf{v} \\\\ 0 \\end{bmatrix} = \\mathbf{E}^T \\mathbf{v},\n\nwhere \\mathbf{E} is the (m+1)\\times (m+1) identity with the last row deleted. The ODE on the interior nodes is\\frac{d\\mathbf{v}}{dt} = \\mathbf{E} \\left( \\mathbf{D}_x \\mathbf{u} \\right) = \\mathbf{E} \\mathbf{D}_x \\mathbf{E}^T \\mathbf{v}.\n\nAs a result, we conclude that \\mathbf{A} = \\mathbf{E} \\mathbf{D}_x \\mathbf{E}^T is the appropriate matrix for determining the eigenvalues of the semidiscretization. More simply, we can simply delete the last row and last column from \\mathbf{D}_x.\n\nEigenvalues for an inflow boundary\n\nExample 12.3.3\n\nDeleting the last row and column places all the eigenvalues of the discretization into the left half of the complex plane.\n\nx, Dₓ, _ = FNC.diffcheb(40, [0, 1])\nA = Dₓ[1:end-1, 1:end-1];     # delete last row and column\nλ = eigvals(A);\n\nscatter(real(λ), imag(λ);\n    m=3,  aspect_ratio=1,\n    legend=:none,  frame=:zerolines,\n    xaxis=([-300, 100], \"Re λ\"),  yaxis=(\"Im λ\"),\n    title=\"Eigenvalues of advection with zero inflow\")\n\nNote that the rightmost eigenvalues have real part at most\n\nmaximum(real(λ))\n\nConsequently all solutions decay exponentially to zero as t\\to\\infty. This matches our observation of the solution: eventually, everything flows out of the domain.\n\nExample 12.3.3\n\nDeleting the last row and column places all the eigenvalues of the discretization into the left half of the complex plane.\n\n[x, Dx, Dxx] = diffcheb(40, [0, 1]);\nA = -Dx(2:end, 2:end);    % leave out first row and column\nlambda = eig(A);\n\nclf\nscatter(real(lambda), imag(lambda))\naxis equal,  grid on \ntitle('Eigenvalues of advection with zero inflow')\n\nNote that the rightmost eigenvalues have real part at most\n\nmax(real(lambda))\n\nConsequently all solutions decay exponentially to zero as t\\to\\infty. This matches our observation of the solution: eventually, everything flows out of the domain.\n\nExample 12.3.3\n\nDeleting the last row and column places all the eigenvalues of the discretization into the left half of the complex plane.\n\nfrom scipy.linalg import eigvals\nx, Dx, Dxx = FNC.diffcheb(40, [0, 1])\nA = -Dx[1:, 1:]  # leave out first row and column\n\nlamb = eigvals(A)\nplot(real(lamb), imag(lamb), \"o\")\nxlim(-300, 100),  axis(\"equal\"),  grid(True)\ntitle(\"Eigenvalues of advection with zero inflow\");\n\nNote that the rightmost eigenvalues have real part at most\n\nprint(f\"rightmost extent of eigenvalues: {max(real(lamb)):.3g}\")\n\nConsequently all solutions decay exponentially to zero as t\\to\\infty. This matches our observation of the solution: eventually, everything flows out of the domain.","type":"content","url":"/absstab-advection#boundary-effects","position":5},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Exercises"},"type":"lvl2","url":"/absstab-advection#exercises","position":6},{"hierarchy":{"lvl1":"Absolute stability","lvl2":"Exercises"},"content":"✍ Let \\mathbf{D}_{x} be m\\times m and given by \n\n(12.2.2). For any integer k \\in \\{0,\\ldots,m-1\\}, define \\omega = \\exp(2ik\\pi/m) and \\mathbf{v} = \\bigl[ 1,\\; \\omega,\\; \\omega^2,\\; \\ldots,\\; \\omega^{m-1} \\bigr]. Show that \\mathbf{v} is an eigenvector of \\mathbf{D}_{x}, with eigenvalue\\lambda =  i\\, m  \\sin \\frac{2k\\pi}{m}.\n\n(See also \n\nExercise 11.3.7.)\n\n⌨ Refer to the semidiscretization of the advection–diffusion equation on x\\in[0,1] with c=1, \\epsilon=0.01, and periodic end conditions in \n\nDemo 12.3.2. For m=100, find the upper bound on τ that gives absolute stability for Euler time stepping. (Hint: The stability region of Euler is the set of complex values whose distance from -1 is less than or equal to one. The effect of τ is to uniformly scale that distance for the eigenvalues.)\n\n⌨ Refer to the semidiscretization in \n\nDemo 12.3.3. Find the upper bound on τ that gives absolute stability for Euler time stepping. (See the hint in the previous exercise.)\n\n⌨ Modify \n\nDemo 12.3.3 so that it produces the eigenvalues of the problem u_t+u_x=0 with an outflow condition u(1,t)=0. What is the behavior of solutions as t\\to\\infty?","type":"content","url":"/absstab-advection#exercises","position":7},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-11","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The numerical solution of advection and wave equations, particularly nonlinear conservation laws, is still an active area of research.  A more detailed treatment on finite-difference methods for scalar problems is in LeVeque \n\nLeVeque (2007).  An accessible treatment of nonlinear conservation laws can be found in the monograph by LeVeque \n\nLeVeque (1992).   Recent monographs aimed at hyperbolic PDEs, both scalar equations and systems, are from Trangenstein \n\nTrangenstein (2009) and LeVeque \n\nLeVeque (2002).\n\nA wide-ranging view of computational mathematics relating to conservation laws (in many cases, nonlinear versions of the advection equation) can be found in \n\nPeter Lax’s oral history.","type":"content","url":"/next-11","position":1},{"hierarchy":{"lvl1":"12. Advection equations"},"type":"lvl1","url":"/overview-11","position":0},{"hierarchy":{"lvl1":"12. Advection equations"},"content":"Now, let’s see if we can’t figure out what you are, my little friend. And where you come from.\n\nObi-Wan Kenobi, Star Wars: A New Hope\n\nNow that we have seen PDEs with both time and space variables, we have a new wrinkle to add. Some of these equations behave like those of the previous chapter, creating diffusive effects. Others, though, are about propagation or advection—generally, the behavior of waves.\n\nWave behavior is very different from diffusion. In idealized cases, waves travel with a finite speed and conserve energy, whereas diffusion smooths out features quickly and is associated with the dissipation of energy. There are many numerical methods that are specialized for purely advective problems, but we will consider only the method of lines approach from \n\nChapter 11. Along the way we will see that wave-like behavior leads to some different conclusions about how to make these methods effective.","type":"content","url":"/overview-11","position":1},{"hierarchy":{"lvl1":"Traffic flow"},"type":"lvl1","url":"/traffic","position":0},{"hierarchy":{"lvl1":"Traffic flow"},"content":"Have you ever been driving on a highway when you suddenly came upon a traffic jam? Maybe you had to brake harder than you would like to admit, endured a period of bumper-to-bumper progress, and experienced a much more gradual emergence from dense traffic than the abrupt entry into it. The mathematics of this phenomenon are well understood.\n\nConsider a one-dimensional road extending in the x direction. We represent the vehicles by a continuous density function \\rho(x).  The flow rate or flux of vehicles, expressed as the number of cars per unit time crossing a fixed point on the road, is denoted by q. We assume that this flux depends on the local density of cars. It’s reasonable to suppose that the flux will be zero when \\rho=0 (no cars), reach a maximum q_m at some \\rho=\\rho_m, and approach zero again as the density approaches a critical density \\rho_c. These conditions are met by the modelQ_0(\\rho) = \\frac{4 q_m \\rho_m \\rho (\\rho-\\rho_c) (\\rho_m-\\rho_c)}{[\\rho (\\rho_c-2 \\rho_m)+\\rho_c \\rho_m]^2}.\n\nObservations (\n\nWhitham (1974), Chapter 3) suggest that good values for a three-lane highway are \\rho_c = 1080 vehicles per km, \\rho_m=380 vehicles per km, and q_m=4500 vehicles per hour. In addition, we want to account for the fact that drivers anticipate slowing down or speeding up when they perceive changes in density, and therefore useq=Q_0(\\rho)-\\epsilon \\rho_x\n\nfor a small \\epsilon > 0.","type":"content","url":"/traffic","position":1},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Conservation laws"},"type":"lvl2","url":"/traffic#conservation-laws","position":2},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Conservation laws"},"content":"Conservation laws play a major role in science and engineering. They are typically statements that matter, energy, momentum, or some other meaningful quantity cannot be created or destroyed. In one dimension they take the formu_t + q_x = 0,\n\nwhere u represents a conserved quantity and q represents the flux (flow rate) of u. Using this in our traffic flow, we arrive at the evolutionary PDE  \\rho_t + Q_0'(\\rho) \\rho_x = \\epsilon \\rho_{xx}.\n\nNote that Q_0' has the dimensions of (cars per time) over (cars per length), or length over time. We recognize the first and last terms as indicative of diffusion, but the middle term has a different effect. A similar term appears in the Black–Scholes equation.","type":"content","url":"/traffic#conservation-laws","position":3},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Advection equation"},"type":"lvl2","url":"/traffic#advection-equation","position":4},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Advection equation"},"content":"Let’s momentarily consider a simpler, more fundamental PDE.\n\nAdvection equation\n\nThe advection equation in one dimension is  u_t + cu_x = 0,\n\nwhere c is constant.\n\nThe advection equation is the archetype of a hyperbolic PDE, which is a separate class from the parabolic PDEs. By comparison with \n\n(12.1.3), we can interpret \n\n(12.1.5) as having a flux proportional to the gradient.\n\nIt’s easy to produce a solution of \n\n(12.1.5). Let u(t,x)=\\psi(x-c t), where ψ is any differentiable function of one variable. Then the chain rule says thatu_t + cu_x = \\psi'(x-c t)\\cdot(-c)  + c [\\psi'(x-c t)] = 0,\n\nand the PDE is satisfied. The form of the solution tells us that u remains constant along any path with x-c t=a for a constant a, i.e., x=a + c t. So if c>0, a fixed value of u moves rightward with speed |c|, and if c<0, it moves leftward with speed |c|.\n\nSolutions to the advection equation propagates with constant speed and fixed shape.\n\nWe can solve \n\n(12.1.5) by the method of lines as in \n\nChapter 11. We need the second-order first-derivative matrix for periodic end conditions,  \\mathbf{D}_x =\n \\frac{1}{2h}\n    \\begin{bmatrix}\n      0 & 1 & & & -1 \\\\\n      -1 & 0 & 1 & & \\\\\n      & \\ddots & \\ddots & \\ddots & \\\\\n      & & -1 & 0 & 1 \\\\\n      1 & & & -1 & 0\n    \\end{bmatrix}.\n\nThis matrix is returned by \n\nFunction 11.2.1.\n\nAdvection equation\n\nWe solve the advection equation on [-4,4] with periodic end conditions using the method of lines.\n\nExample 12.1.1\n\nIn the following definition we allow the velocity c to be specified as a parameter in the ODEProblem.\n\nx, Dₓ, Dₓₓ = FNC.diffper(300, [-4, 4]);\nf = (u, c, t) -> -c * (Dₓ*u);\n\nThe following initial condition isn’t mathematically periodic, but the deviation is less than machine precision. We specify RK4 as the solver.\n\nusing OrdinaryDiffEq\nu_init = @. 1 + exp( -3x^2 )\nIVP = ODEProblem(f, u_init, (0., 4.), 2)\nsol = solve(IVP, RK4());\n\nusing Plots\nplt = plot(\n    legend=:bottomleft,\n    title=\"Advection with periodic boundary\",\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\"))\nfor t in (0:4) * 2/3\n    plot!(x, sol(t), label=@sprintf(\"t=%.1f\", t))\nend\nplt\n\nAn animation shows the solution nicely. The bump moves with speed 2 to the right, reentering on the left as it exits to the right because of the periodic conditions.\n\nanim = @animate for t in range(0, 4, 120) \n    plot(x, sol(t),\n        title=@sprintf(\"Advection equation, t = %.2f\", t),\n        xaxis=(L\"x\"),  yaxis=([1, 2], L\"u(x,t)\"),\n        dpi=150)\nend\nmp4(anim, \"figures/advection-periodic.mp4\")\n\nExample 12.1.1\n\nIn the following definition we allow the velocity c to be specified as a parameter.\n\n[x, Dx, Dxx] = diffper(300, [-4, 4]);\nf = @(t, u, c) -c * (Dx*u);\nivp = ode(ODEFcn=f);\nivp.Parameters = 2;\nivp.InitialTime = 0;\nivp.RelativeTolerance = 1e-5;\n\nThe following initial condition isn’t mathematically periodic, but the deviation is less than machine precision. We specify RK4 as the solver.\n\nu_init = 1 + exp(-3*x.^2);\nivp.InitialValue = u_init;\nt = linspace(0, 3, 201);\nsol = solve(ivp, t);\nU = sol.Solution;\n\nwaterfall(x, t(1:5:end), U(:, 1:5:end)')\nview(-13, 65)\nxlabel('x'), ylabel('t'), zlabel('u(x,t)')\ntitle('Advection equation')\n\nAn animation shows the solution nicely. The bump moves with speed 2 to the right, reentering on the left as it exits to the right because of the periodic conditions.\n\nclf\nplot(x, U(:, 1))\nhold on,  grid on\naxis([-4, 4, 0.9, 2.1])\ntitle('Advection equation with periodic boundary') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/advection-periodic.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(-3.5, 1.9, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 12.1.1\n\nIn the following definition we allow the velocity c to be specified as a parameter in the ODEProblem.\n\nx, Dx, Dxx = FNC.diffper(300, [-4, 4])\nf = lambda t, u: -c * (Dx @ u)\n\nThe following initial condition isn’t mathematically periodic, but the deviation is less than machine precision. We specify RK4 as the solver.\n\nfrom scipy.integrate import solve_ivp\nu_init = 1 + exp(-3 * x**2)\nc = 2\nsol = solve_ivp(f, [0, 3.0], u_init, method=\"Radau\", dense_output=True)\n\nfor t in arange(0, 3, 2/3):\n    plot(x, sol.sol(t), label=f\"t = {t:.1f}\")\nlegend()\nxlabel(\"$x$\"),  ylabel(\"$u(x,t)$\")\ntitle(\"Advection with periodic boundary\");\n\nAn animation shows the solution nicely. The bump moves with speed 2 to the right, reentering on the left as it exits to the right because of the periodic conditions.\n\nfrom matplotlib import animation\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(0.9, 2.1)\nax.set_title(\"Advection equation with periodic boundary\")\n\ndef snapshot(t):\n    curve.set_ydata(sol.sol(t))\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 3, 201)\n    )\nanim.save(\"figures/advection-periodic.mp4\", fps=30)\nclose()\n\nIf you look carefully at \n\nDemo 12.1.1, you’ll notice that we used the time integrator RK4, a nonstiff method. As we will see later in this chapter, the pure advection equation is not inherently stiff.","type":"content","url":"/traffic#advection-equation","position":5},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Solutions for traffic flow"},"type":"lvl2","url":"/traffic#solutions-for-traffic-flow","position":6},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Solutions for traffic flow"},"content":"Returning to the traffic flow PDE \n\n(12.1.4), we can interpret the conservation law as advection at velocity Q_0'(\\rho).  The dependence of velocity on the solution is different from the linear PDE \n\n(12.1.5) and is the key to the peculiar behavior of traffic jams. In particular, the velocity is low at high density, and higher at low density.  The term on the right side of \n\n(12.1.4) provides a bit of diffusion, and the parameter ε determines the balance between the two effects—advection effects dominate if ε is small.\n\nExact solutions of \n\n(12.1.4) are much harder to come by than for the standard advection equation, but the method of lines is still effective.\n\nTraffic flow model\n\nWe solve for traffic flow using periodic boundary conditions.\n\nExample 12.1.2\n\nThe following are parameters and a function relevant to defining the problem.\n\nρc = 1080;  ρm = 380;  q_m = 10000;\ndQ0 = ρ -> 4q_m * ρc^2 * (ρc-ρm) * ρm * (ρm-ρ) / (ρ*(ρc-2*ρm) + ρc*ρm)^3;\n\nHere we create a discretization on m=800 points.\n\nx, Dₓ, Dₓₓ = FNC.diffper(800, [0, 4]);\n\nNext we define the ODE resulting from the method of lines.\n\node = (ρ, ϵ, t) -> -dQ0.(ρ) .* (Dₓ*ρ) + ϵ * (Dₓₓ*ρ);\n\nOur first initial condition has moderate density with a small bump. Because of the diffusion present, we use a stiff solver for the IVP.\n\nρ_init = @. 400 + 10 * exp( -20*(x-3)^2 )\nIVP = ODEProblem(ode, ρ_init, (0., 1.), 0.02)\nsol = solve(IVP, Rodas4P());\n\nplt = plot(\n    legend=:topleft, \n    title=\"Traffic flow\",\n    xaxis=(L\"x\"),  yaxis=(\"car density\"))\nfor t in 0:0.2:1\n    plot!(x, sol(t), label=@sprintf(\"t=%.1f\", t))\nend\nplt\n\nThe bump slowly moves backward on the roadway, spreading out and gradually fading away due to the presence of diffusion.\n\nanim = @animate for t in range(0,0.9,91) \n    plot(x, sol(t);\n        xaxis=(L\"x\"),  yaxis=([400,410], \"density\"),\n        dpi=150,  title=@sprintf(\"Traffic flow, t=%.2f\",t))\nend\nmp4(anim, \"figures/traffic-small.mp4\")\n\nNow we use an initial condition with a larger bump. Note that the scale on the y-axis is much different for this solution.\n\nρ_init = @. 400 + 80 * exp( -16*(x - 3)^2 )\nIVP = ODEProblem(ode, ρ_init, (0., 0.5), 0.02)\nsol = solve(IVP, Rodas4P());\n\nplt = plot(\n    legend=:topleft,\n    title=\"Traffic jam\",\n    xaxis=(L\"x\"),  yaxis=(\"car density\"))\nfor t in range(0, 0.5, 11)\n    plot!(x, sol(t), label=@sprintf(\"t=%.1f\", t))\nend\nplt\n\nanim = @animate for t in range(0, 0.5, 101) \n    plot(x, sol(t);\n        xaxis=(L\"x\"),  yaxis=([400,480], \"density\"),\n        dpi=150,  title=@sprintf(\"Traffic jam, t=%.2f\",t))\nend\nmp4(anim,\"figures/traffic-jam.mp4\")\n\nIn this case the density bump travels backward along the road. It also steepens on the side facing the incoming traffic and decreases much more slowly on the other side. A motorist would experience this as an abrupt increase in density, followed by a much more gradual decrease in density and resulting gradual increase in speed. (You also see some transient, high-frequency oscillations. These are caused by instabilities, as we discuss in simpler situations later in this chapter.)\n\nExample 12.1.2\n\nThe following are parameters and a function relevant to defining the problem.\n\nrho_c = 1080;  rho_m = 380;  q_m = 10000;\nQ0prime = @(rho) 4*q_m*rho_c^2 * (rho_c - rho_m) * rho_m ...\n    *(rho_m - rho) ./ ((rho_c - 2*rho_m) * rho + rho_c * rho_m).^3;\nep = 0.02;\n\nHere we create a discretization on m=800 points.\n\n[x, Dx, Dxx] = diffper(800, [0, 4]);\n\nNext we define the ODE resulting from the method of lines.\n\nodefun = @(t, rho) -Q0prime(rho) .* (Dx*rho) + ep * (Dxx*rho);\nivp = ode(ODEFcn=odefun);\nivp.InitialTime = 0;\nivp.RelativeTolerance = 1e-5;\n\nOur first initial condition has moderate density with a small bump. Because of the diffusion present, we use a stiff solver for the IVP.\n\nrho_init = 400 + 10 * exp(-20*(x-3).^2);\nivp.InitialValue = rho_init;\n\nt = linspace(0, 1, 101);\nsol = solve(ivp, t);\nRHO = sol.Solution;\n\nclf\nfor plot_idx = 1:20:101\n    str = sprintf(\"t = %.2f\", t(plot_idx));\n    plot(x, RHO(:, plot_idx), displayname=str)\n    hold on\nend\nxlabel('x'),  ylabel('car density')\ntitle('Traffic flow') \nlegend(location=\"northwest\")\n\nThe bump slowly moves backward on the roadway, spreading out and gradually fading away due to the presence of diffusion.\n\nclf\nplot(x, RHO(:, 1))\nhold on,  grid on\naxis([0, 4, 398, 410])\ntitle('Traffic flow') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/traffic-small.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, RHO(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.2, 409, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nNow we use an initial condition with a larger bump. Note that the scale on the y-axis is much different for this solution.\n\nrho_init = 400 + 80 * exp( -16*(x - 3).^2 );\nivp.InitialValue = rho_init;\nt = linspace(0, 0.5, 81);\nsol = solve(ivp, t);\nRHO = sol.Solution;\n\nclf\nfor plot_idx = 1:16:81\n    str = sprintf(\"t = %.2f\", t(plot_idx));\n    plot(x, RHO(:, plot_idx), displayname=str)\n    hold on\nend\nxlabel('x'),  ylabel('car density')\ntitle('Traffic jam') \nlegend(location=\"northwest\")\n\nclf\nplot(x, RHO(:, 1))\nhold on,  grid on\naxis([0, 4, 395, 480])\ntitle('Traffic jam') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/traffic-jam.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, RHO(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.2, 470, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nIn this case the density bump travels backward along the road. It also steepens on the side facing the incoming traffic and decreases much more slowly on the other side. A motorist would experience this as an abrupt increase in density, followed by a much more gradual decrease in density and resulting gradual increase in speed. (You also see some transient, high-frequency oscillations. These are caused by instabilities, as we discuss in simpler situations later in this chapter.)\n\nExample 12.1.2\n\nThe following are parameters and a function relevant to defining the problem.\n\nrho_c = 1080\nrho_m = 380\nq_m = 10000\nQ0prime = (\n    lambda rho: q_m\n    * 4\n    * rho_c**2\n    * (rho_c - rho_m)\n    * rho_m\n    * (rho_m - rho)\n    / (rho * (rho_c - 2 * rho_m) + rho_c * rho_m) ** 3\n)\n\nHere we create a discretization on m=800 points.\n\nx, Dx, Dxx = FNC.diffper(800, [0, 4])\n\nNext we define the ODE resulting from the method of lines.\n\node = lambda t, rho: -Q0prime(rho) * (Dx @ rho) + ep * (Dxx @ rho)\n\nOur first initial condition has moderate density with a small bump. Because of the diffusion present, we use a stiff solver for the IVP.\n\nrho_init = 400 + 10 * exp(-20 * (x - 3) ** 2)\nep = 0.02\nsol = solve_ivp(ode, [0, 1.0], rho_init, method=\"Radau\", dense_output=True)\n\nfor t in linspace(0, 1, 6):\n    plot(x, sol.sol(t), label=f\"t = {t:.1f}\")\n\nxlabel(\"$x$\"),  ylabel(\"car density\")\nlegend(),  title(\"Traffic flow\");\n\nThe bump slowly moves backward on the roadway, spreading out and gradually fading away due to the presence of diffusion.\n\nfig, ax = subplots()\ncurve = ax.plot(x, rho_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"density\")\nax.set_ylim(400, 410)\nax.set_title(\"Traffic flow\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 1, 101)\n    )\nanim.save(\"figures/traffic-small.mp4\", fps=30)\nclose()\n\nNow we use an initial condition with a larger bump. Note that the scale on the y-axis is much different for this solution.\n\nrho_init = 400 + 80 * exp(-16 * (x - 3) ** 2)\nsol = solve_ivp(ode, [0, 0.5], rho_init, method=\"Radau\", dense_output=True)\n\nfor t in linspace(0, 0.5, 6):\n    plot(x, sol.sol(t), label=f\"t = {t:.1f}\")\n\nxlabel(\"$x$\"),  ylabel(\"car density\")\nlegend(),  title(\"Traffic jam\");\n\nfig, ax = subplots()\ncurve = ax.plot(x, rho_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"density\")\nax.set_ylim(400, 480)\nax.set_title(\"Traffic jam\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 0.5, 101)\n    )\nanim.save(\"figures/traffic-jam.mp4\", fps=30)\nclose()\n\nIn this case the density bump travels backward along the road. It also steepens on the side facing the incoming traffic and decreases much more slowly on the other side. A motorist would experience this as an abrupt increase in density, followed by a much more gradual decrease in density and resulting gradual increase in speed. (You also see some transient, high-frequency oscillations. These are caused by instabilities, as we discuss in simpler situations later in this chapter.)\n\nThe phenomenon in the second plot of \n\nDemo 12.1.2 is called a shock wave. The underlying mathematics is not much different from the shock wave that comes off of the wing of a supersonic aircraft in the form of a sonic boom, or from cresting waves under certain conditions in the ocean. In the absence of diffusion (\\epsilon=0), the shock becomes a jump discontinuity in the solution, which breaks down both the finite differences and the original PDE, requiring different approaches. For many applications, the addition of a small amount of diffusion is appropriate and simple. However, we will first try to come to terms with pure advection in a linear problem.","type":"content","url":"/traffic#solutions-for-traffic-flow","position":7},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Exercises"},"type":"lvl2","url":"/traffic#exercises","position":8},{"hierarchy":{"lvl1":"Traffic flow","lvl2":"Exercises"},"content":"✍ By the analogy between \n\n(12.1.4) and \n\n(12.1.5), use \n\n(12.1.1) to confirm that constant traffic density moves backward (right to left) for \\rho_m<\\rho<\\rho_c, as observed in \n\nDemo 12.1.2. (Note that the derivative of Q_0 is given in the code for the example.)\n\n⌨ (a) Using as large a discretization and as small a dissipation parameter ε  as you can get away with, perform experiments to estimate the speed of the shockwave in \n\nDemo 12.1.2 between times t=0.11 and t=0.15. (Hint: You can use argmax to locate the peak of the solution vector at a particular time.)\n\n(b) Theory predicts that the speed of the shockwave is the average of Q_0' evaluated at the values of ρ at the top and bottom of the shock. Perform this calculation and compare to the result of part (a).\n\n⌨ The simplest model that includes both diffusion and nonlinear advection is the viscous Burgers equation, u_t+u u_x=\\epsilon u_{xx}. Assume periodic end conditions on -4\\le x < 4, let \\epsilon=0.04, and suppose u(x,0)=e^{-2x^2}. Solve the problem numerically with m=200, plotting the solution on one graph at times t=0,0.5,1,\\ldots,3. (You should see that the bump decays but also steepens as it moves to the right.)\n\n⌨ The Kuramoto–Sivashinsky equation, u_t+u u_x=-u_{xx}-\\epsilon u_{xxxx}, exhibits solutions that are considered chaotic. Assume periodic end conditions, \\epsilon=0.05, and initial condition u(x,0)=1+e^{-2x^2}. Using the method of lines, solve the problem numerically with m=200 for -4\\le x \\le 4 and 0\\le t \\le 20. (You should discretize the fourth derivative as repeated second derivatives.) Make an animation of the plot (preferred), or plot the solution as a surface over x and t.\n\n⌨ (Adapted from \n\nTrefethen (2000).) Consider the problem u_t + c(x) u_x =0, for 0 \\le x \\le 2\\pi, with periodic boundary conditions and variable speed c(x) = 0.2 + \\sin^2(x-1). This problem has a solution that is T-periodic in time, for some T\\approx 13.\n\n(a) Find this value T accurately to 10 digits by converting the integral T\n = \\int_0^T \\,dt to an integral in x via \\frac{dx}{dt}=c(x), then applying numerical integration.\n\n(b) Using u(x,0) =e^{\\sin x}, solve the PDE numerically for 0\\le t \\le T using the answer from part (a). Make an animation of the solution, or a surface plot of the solution as a function of x and t.\n\n(c)  Adjust the accuracy in time and space until you can verify that \\|u(x,T)-u(x,0)\\|_\\infty < 0.03.","type":"content","url":"/traffic#exercises","position":9},{"hierarchy":{"lvl1":"Upwinding and stability"},"type":"lvl1","url":"/upwind","position":0},{"hierarchy":{"lvl1":"Upwinding and stability"},"content":"Let’s focus on the constant-velocity linear advection equation,  u_t + c u_x = 0, \\quad u(0,x)=u_0(x).\n\nFor now, we suppose there are no boundaries. Keep in mind that c is a velocity, not a speed: if c>0, solutions travel rightward, and if c<0, they travel leftward.\n\nIn \n\nTraffic flow we argued that u(x,t)=\\psi(x-ct) is a solution of \n\n(12.2.1). It’s therefore clear that u(x,t)=u_0(x-ct).\n\nDomain of dependence\n\nLet u(x,t) be the solution of an evolutionary PDE with initial condition u_0(x). The  domain of dependence of the solution at (x,t) is the set of all x such that u_0(x) can possibly affect u(x,t). If this domain of dependence lies entirely in one direction relative to x, then that direction is called the upwind direction of the PDE, and its opposite is the downwind direction.\n\nIn the advection equation, the domain of dependence at (x,t) is the single point \\{x-ct\\}, and the upwind direction is to the left or to the right of x if c is positive or negative, respectively.\n\nAny numerical method we choose has an analogous property.\n\nNumerical domain of dependence\n\nLet U_{i,j} be the approximate solution of an evolutionary PDE at x=x_i, t=t_j from a numerical method, when the initial condition is given by U_{i,0} for all i. The numerical domain of dependence of the method at (x_i,t_j) is the set of all x_i such that U_{i,0} can possibly affect U_{i,j}.\n\nIn \n\n(12.2.1), suppose we discretize u_x by a centered difference,  u_x(x_i,t_j) \\approx \\frac{U_{i+1,j}-U_{i-1,j}}{2h}.\n\nIf we use the Euler time discretization, then  \\mathbf{u}_{j+1} = (\\mathbf{I} - c \\tau \\mathbf{D}_x) \\mathbf{u}_j,\n\nwhere τ is the time step. Because the matrix in this time step is tridiagonal, the entry U_{i,j} can depend directly only on U_{i-1,j}, U_{i,j}, and U_{i+1,j}. Going back another time step, the dependence extends to space positions i-2 and i+2, and so on. When we reach the initial time, the dependence of U_{i,j} reaches from x_{i-j} to x_{i+j}, or between x_i-jh and x_i+jh. If we ignore boundaries, the situation is illustrated in \n\nFigure 12.2.1. As \\tau,h\\rightarrow 0, the numerical domain of dependence fills in the shaded region in the figure, but that region itself does not change.\n\n\n\nFigure 12.2.1:Numerical domain of dependence for the explicit time stepping scheme in \n\nExample 12.2.1. If  τ and h are infinitesimally small, the shaded region is filled in.","type":"content","url":"/upwind","position":1},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"The CFL condition"},"type":"lvl2","url":"/upwind#the-cfl-condition","position":2},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"The CFL condition"},"content":"We now state an important principle about a required relationship between the domains of dependence.\n\nCourant–Friedrichs–Lewy (CFL) condition\n\nIn order for a numerical method for an advection equation to converge to the correct solution, the limiting numerical domain of dependence must contain the exact domain of dependence.\n\nCaution\n\nThe CFL condition is a necessary criterion for convergence, but not a sufficient one. For instance, we could define U_{i,j} to be any weighted convergent sum of all values of U_{i,0}. While that would make the numerical domain of dependence equal to the entire real line, this method has nothing to do with solving any PDE correctly!\n\nAlthough we will not provide the rigor behind this theorem, its conclusion is not difficult to justify. If the CFL condition does not hold, the exact solution at (x,t) could be affected by a change in the initial data while having no effect on the numerical solution. Hence there is no way for the method to get the solution correct for all problems. By contradiction, then, the CFL criterion is necessary for convergence.\n\nReturning to \n\nExample 12.2.1, the numerical domain of dependence depicted in \n\nFigure 12.2.1 contains the exact domain of dependence \\{x_i-c t_j\\} only if x_i-j h \\le x_i -c t_j \\le x_i+jh, or |c j\\tau|\\le j h. That is,  \\frac{h}{\\tau} \\ge |c|, \\quad  \\tau,h\\rightarrow 0.\n\nEquation \n\n(12.2.4) is the implication of the CFL condition for the stated discretization. Notice that h/\\tau is the speed at which information moves in the numerical method; thus, it is common to restate the CFL condition in terms of speeds.\n\nThe CFL condition required that the maximum propagation speed in the numerical method be at least as large as the maximum speed in the original PDE problem.\n\nWe can rearrange \n\n(12.2.4) to imply a necessary time step restriction \\tau \\le h/|c|. This restriction for advection is much less severe than the \\tau = O(h^2) restriction we derived for Euler in the heat equation in \n\nStiffness, which is our first indication that advection is less stiff than diffusion.\n\nThe CFL condition in action\n\nWe solve linear advection with velocity c=2 and periodic end conditions. The initial condition is numerically, though not mathematically, periodic.\n\nExample 12.2.3\n\nFor time stepping, we use the adaptive explicit method RK4.\n\nusing OrdinaryDiffEq\nm = 400;\nx, Dₓ = FNC.diffper(m, [0, 1])\nu_init = x -> exp( -80 * (x - 0.5)^2 )\node = (u, c, t) -> -c * (Dₓ*u)\nIVP = ODEProblem(ode, u_init.(x), (0., 2.), 2.)\nu = solve(IVP, RK4());\n\nusing Plots\nt = range(0, 2, 81);\nU = reduce(hcat, u(t) for t in t)\ncontour(x, t, U'; \n    color=:redsblues,  clims=(-1, 1),\n    xaxis=(L\"x\"),  yaxis=(L\"t\"),\n    title=\"Linear advection\",  right_margin=3Plots.mm)\n\nIn the space-time plot above, you can see the initial hump traveling rightward at constant speed. It fully traverses the domain once for each integer multiple of t=1/2.\n\nIf we cut h by a factor of 2 (i.e., double m), then the CFL condition suggests that the time step should be cut by a factor of 2 also.\n\nprintln(\"Number of time steps for m = 400: $(length(u.t))\")\n\nm = 800;\nx, Dₓ = FNC.diffper(m, [0, 1])\nIVP = ODEProblem(ode, u_init.(x), (0., 2.), 2.)\nu = solve(IVP, RK4())\nprintln(\"Number of time steps for m = 800: $(length(u.t))\")\n\nExample 12.2.3\n\n[x, Dx] = diffper(400, [0, 1]);\nc = 2;  \nivp = ode(ODEFcn = @(t, u) -c * (Dx*u));\nivp.RelativeTolerance = 1e-5;\nivp.InitialTime = 0;\nu_init = exp( -80*(x - 0.5).^2 );\nivp.InitialValue = u_init;\n\n[u, sol] = solutionFcn(ivp, 0, 2);\n\nclf\nt = linspace(0, 2, 81);\ncontour(x, t, u(t)', 12)\nxlabel('x'),  ylabel('t')\ntitle('Linear advection')\n\nIn the space-time plot above, you can see the initial hump traveling rightward at constant speed. It fully traverses the domain once for each integer multiple of t=1/2.\n\nIf we cut h by a factor of 2 (i.e., double m), then the CFL condition suggests that the time step should be cut by a factor of 2 also.\n\nnum_steps_400 = length(sol.Time) - 1\n\n[x, Dx] = diffper(800, [0, 1]);\nivp.ODEFcn = @(t, u) -c * (Dx*u);\nivp.InitialValue = exp( -80*(x - 0.5).^2 );\n[u, sol] = solutionFcn(ivp, 0, 2);\n\nnum_steps_800 = length(sol.Time) - 1\nratio = num_steps_800 / num_steps_400\n\nExample 12.2.3\n\nFor time stepping, we use the adaptive explicit method RK45.\n\nx, Dx, Dxx = FNC.diffper(400, [0, 1])\nu_init = exp(-80 * (x - 0.5) ** 2)\nc = 2\node = lambda t, u: -c * (Dx @ u)\nsol = solve_ivp(ode, (0, 2), u_init, method=\"RK45\", dense_output=True)\nu = sol.sol\n\nt = linspace(0, 2, 81)\nU = vstack([u(tj) for tj in t])\ncontour(x, t, U, levels=arange(0.15, 1.0, 0.2))\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Linear advection\");\n\nIn the space-time plot above, you can see the initial hump traveling rightward at constant speed. It fully traverses the domain once for each integer multiple of t=1/2.\n\nIf we cut h by a factor of 2 (i.e., double m), then the CFL condition suggests that the time step should be cut by a factor of 2 also.\n\nprint(f\"{len(sol.t) - 1} time steps taken for m = 400\")\n\nx, Dx, Dxx = FNC.diffper(800, [0, 1])\nu_init = exp(-80 * (x - 0.5) ** 2)\nsol = solve_ivp(ode, (0, 2), u_init, method=\"RK45\", dense_output=True)\nprint(f\"{len(sol.t) - 1} time steps taken for m = 800\")\n\nConsider what happens in \n\nExample 12.2.1 if we replace Euler by backward Euler. Instead of \n\n(12.2.3), we get\\begin{align*}\n\t(\\mathbf{I} + c \\tau \\mathbf{D}_x)\\mathbf{u}_{j+1} &=  \\mathbf{u}_j, \\\\\n\t\\mathbf{u}_{j+1} &= (\\mathbf{I} + c \\tau \\mathbf{D}_x)^{-1} \\mathbf{u}_j.\n\\end{align*}\n\nThe inverse of a tridiagonal matrix is not necessarily tridiagonal, and in fact U_{i,j+1} depends on all of the data at time level j. Thus the numerical domain of dependence includes the entire real line, and the CFL condition is always satisfied.\n\nExample 12.2.4 is a special case of a more general conclusion.\n\nAn explicit time discretization must obey \\tau = O(h) as h\\to 0 in order to solve \n\n(12.2.1), while an implicit method is typically unrestricted by the CFL condition.","type":"content","url":"/upwind#the-cfl-condition","position":3},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"Upwinding"},"type":"lvl2","url":"/upwind#upwinding","position":4},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"Upwinding"},"content":"There are other ways to discretize the u_x term in the advection equation \n\n(12.2.1). The implications of the CFL criterion may differ greatly depending on which is chosen.\n\nSuppose we use the backward difference  u_x(x_i,t_j)  \\approx \\frac{U_{i,j}-U_{i-1,j}}{h}\n\ntogether with an explicit scheme in time. Then U_{i,j} depends only on points to the left of x_i., i.e., the upwind direction of the numerical method is to the left. But if c<0,\nthe upwind direction of the PDE is to the right. Hence it is impossible to satisfy the CFL condition.\n\nPairing the forward difference  u_x(x_i,t_j)  \\approx \\frac{U_{i+1,j}-U_{i,j}}{h}\n\nwith explicit time stepping leads to the inverse conclusion: its upwind direction is to the right, and it must fail if c>0.\n\nIt’s clear that when the domain of dependence and the numerical method both have a directional preference, they must agree.\n\nUpwinding\n\nIf a numerical method has an upwinding direction, it must be the same as the upwind direction of the PDE.\n\nIt might seem like one should always use a centered difference scheme so that upwinding is not an issue. However, at a shock front, this requires differencing across a jump in the solution, which causes its own difficulties.","type":"content","url":"/upwind#upwinding","position":5},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"Inflow boundary condition"},"type":"lvl2","url":"/upwind#inflow-boundary-condition","position":6},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"Inflow boundary condition"},"content":"Now suppose that \n\n(12.2.1) is posed on the finite domain x \\in [a,b].\nSince the PDE has only a first-order derivative in x, we should have only one boundary condition. Should it be specified at the left end, or the right end?\n\nIf we impose a condition at the downwind side of the domain, there is no way for that boundary information to propagate into the interior of the domain as time advances. On the other hand, for points close to the upwind boundary, the domain of dependence eventually wants to move past the left boundary. This is impossible, so instead the domain of dependence has to stay there.\n\nIn summary, we require an inflow condition on the PDE. For c>0 this is at the left end, and for c<0 it is at the right end. This requirement is true of the exact PDE as well as any discretization of it.\n\nUpwind versus downwind\n\nExample 12.2.6\n\nIf we solve advection over [0,1] with velocity c=-1, the right boundary is in the upwind/inflow direction. Thus a well-posed boundary condition is u(1,t)=0.\n\nWe’ll pattern a solution after \n\nFunction 11.5.2. Since u(x_m,t)=0, we define the ODE interior problem \n\n(11.5.4) for \\mathbf{v} without u_m. For each evaluation of \\mathbf{v}', we must extend the data back to x_m first.\n\nm = 100\nx, Dₓ = FNC.diffmat2(m, [0, 1])\n\ninterior = 1:m\nextend = v -> [v; 0]\n\nfunction ode!(f, v, c, t)\n    u = extend(v)\n    uₓ = Dₓ * u\n    @. f = -c * uₓ[interior]\nend;\n\nNow we solve for an initial condition that has a single hump.\n\ninit = @. exp( -80*(x[interior] - 0.5)^2 )\nivp = ODEProblem(ode!, init, (0., 1), -1)\nu = solve(ivp);\n\nt = range(0, 0.75, 80)\nU = reduce(hcat, extend(u(t)) for t in t)\ncontour(x, t, U';\n    color=:blues,  clims=(0, 1), \n    xaxis=(L\"x\"),  yaxis=(L\"t\"),\n    title=\"Advection with inflow BC\")\n\nWe find that the hump gracefully exits out the downwind end.\n\nanim = @animate for t in range(0, 1, 161) \n    plot(x, extend(u(t));\n        label=@sprintf(\"t = %.4f\", t), \n        xaxis=(L\"x\"),  yaxis=(L\"u(x, t)\", (0, 1)), \n        title=\"Advection equation with inflow BC\",  dpi=150)\nend\nmp4(anim,\"figures/advection-inflow.mp4\")\n\nIf instead of u(1,t)=0 we were to try to impose the downwind condition u(0,t)=0, we only need to change the index of the interior nodes and where to append the zero value.\n\ninterior = 2:m+1\nextend = v -> [0; v]\n\ninit = @. exp( -80*(x[interior] - 0.5)^2 )\nivp = ODEProblem(ode!, init, (0., 0.25), -1)\nu = solve(ivp);\n\nt = range(0, 0.2, 61)\nU = reduce(hcat, extend(u(t)) for t in t)\ncontour(x, t, U'; \n    color=:redsblues,  clims=(-1, 1),\n    xaxis=(L\"x\"),  yaxis=(L\"t\"), \n    title=\"Advection with outflow BC\",  right_margin=3Plots.mm)\n\nThis time, the solution blows up as soon as the hump runs into the boundary because there are conflicting demands there.\n\nanim = @animate for t in range(0, 0.2, 41) \n    plot(x, extend(u(t));\n        label=@sprintf(\"t = %.4f\", t),\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (0, 1)), \n        title=\"Advection equation with outflow BC\",  dpi=150)\nend\nmp4(anim,\"figures/advection-outflow.mp4\")\n\nExample 12.2.6\n\nIf we solve advection over [0,1] with velocity c=-1, the right boundary is in the upwind/inflow direction. Thus a well-posed boundary condition is u(1,t)=0.\n\nWe’ll pattern a solution after \n\nFunction 11.5.2. Since u(x_m,t)=0, we define the ODE interior problem \n\n(11.5.4) for \\mathbf{v} without u_m. For each evaluation of \\mathbf{v}', we must extend the data back to x_m first.\n\nm = 100;  c = -1;\n[x, Dx] = diffmat2(m, [0, 1]);\nchop = @(u) u(1:m);  \nextend = @(v) [v; 0];\nodefun = @(t, v) -c * chop( Dx * extend(v) );\nivp = ode(ODEFcn = odefun);\nivp.RelativeTolerance = 1e-5;\nivp.InitialTime = 0;\n\nNow we solve for an initial condition that has a single hump.\n\nu_init = exp( -80*(x - 0.5).^2 );\nivp.InitialValue = chop(u_init);\nsol = solutionFcn(ivp, 0, 1);\nu = @(t) [sol(t); zeros(1, length(t))];    % extend to zero at right\n\nt = linspace(0, 1, 81);\nclf,  contour(x, t, u(t)', 0.15:0.2:1)\nxlabel x,  ylabel t\ntitle('Advection with inflow BC')\n\nWe find that the hump gracefully exits out the downwind end.\n\nclf\nplot(x, u(0))\nhold on\naxis([0, 1, -0.05, 1.05])\ntitle('Advection with inflow BC') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/advection-inflow.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, u(t(frame)))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.08, 0.85, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nIf instead of u(1,t)=0 we were to try to impose the downwind condition u(0,t)=0, we only need to change the index of the interior nodes and where to append the zero value.\n\nchop = @(u) u(2:m+1);  \nextend = @(v) [0; v];\nivp.ODEFcn = @(t, v) -c * chop( Dx * extend(v) );\nivp.InitialValue = chop(u_init);\nsol = solutionFcn(ivp, 0, 1);\nu = @(t) [zeros(1, length(t)); sol(t)];\n\ncontour(x, t, u(t)', 0.15:0.2:1)\nxlabel x,  ylabel t\ntitle('Advection with outflow BC')\n\nThis time, the solution blows up as soon as the hump runs into the boundary because there are conflicting demands there.\n\nclf\nplot(x, u(0))\nhold on\naxis([0, 1, -0.05, 1.05])\ntitle('Advection with outflow BC') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/advection-outflow.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:45\n    cla, plot(x, u(t(frame)))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.08, 0.85, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 12.2.6\n\nIf we solve advection over [0,1] with velocity c=-1, the right boundary is in the upwind/inflow direction. Thus a well-posed boundary condition is u(1,t)=0.\n\nWe’ll pattern a solution after \n\nFunction 11.5.2. Since u(x_m,t)=0, we define the ODE interior problem \n\n(11.5.4) for \\mathbf{v} without u_m. For each evaluation of \\mathbf{v}', we must extend the data back to x_m first.\n\nm = 80\nx, Dx, Dxx = FNC.diffmat2(m, [0, 1])\n\nchop = lambda u : u[:-1]\nextend = lambda v: hstack([v, 0])\n\node = lambda t, v: -c * chop( Dx @ extend(v) )\nc = -1\n\nNow we solve for an initial condition that has a single hump.\n\nu_init = exp(-80 * (x - 0.5) ** 2)\nsol = solve_ivp(ode, (0, 1), chop(u_init), method=\"RK45\", dense_output=True)\nu = lambda t: extend(sol.sol(t))\n\nt = linspace(0, 1, 80)\nU = [u(tj) for tj in t]\ncontour(x, t, U, levels=arange(0.15, 1.0, 0.2))\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Advection with inflow BC\");\n\nWe find that the hump gracefully exits out the downwind end.\n\nfrom matplotlib import animation\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-0.1, 1.1)\nax.set_title(\"Advection with inflow BC\")\n\ndef snapshot(t):\n    curve.set_ydata(u(t))\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 1, 101)\n    )\nanim.save(\"figures/advection-inflow.mp4\", fps=30)\nclose()\n\nIf, instead of u(1,t)=0, we were to try to impose the downwind condition u(0,t)=0, we only need to change the index of the interior nodes and where to append the zero value.\n\nchop = lambda u : u[1:]\nextend = lambda v: hstack([0, v])\n\nsol = solve_ivp(ode, (0, 1), chop(u_init), method=\"RK45\", dense_output=True)\nu = lambda t: extend(sol.sol(t))\n\nU = [u(tj) for tj in t]\nclf\ncontour(x, t, U, levels=arange(0.15, 1.0, 0.2))\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Outflow boundary condition\");\n\nThis time, the solution blows up as soon as the hump runs into the boundary because there are conflicting demands there.\n\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-0.1, 1.1)\nax.set_title(\"Advection with outflow BC\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 0.5, 51)\n    )\nanim.save(\"figures/advection-outflow.mp4\", fps=30)\nclose()","type":"content","url":"/upwind#inflow-boundary-condition","position":7},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"Exercises"},"type":"lvl2","url":"/upwind#exercises","position":8},{"hierarchy":{"lvl1":"Upwinding and stability","lvl2":"Exercises"},"content":"✍ Suppose you want to model the weather, including winds up to speed 200 km/hr, using an explicit method with a second-order centered spatial discretization. If the shortest time step you can take is 4 hr, what is the CFL limit on the spatial resolution of the model? Is this a lower bound or an upper bound?\n\n✍ Suppose you want to model the traffic on a high-speed freeway using an explicit method with a second-order centered spatial discretization. Derive a CFL condition on the allowable time step, stating your assumptions carefully.\n\n✍ For the heat equation, the domain of dependence at any (x,t) with t>0 is all of x \\in (-\\infty,\\infty). Show that the CFL condition implies that \\tau/h\\to 0 is required for convergence as h\\to 0.\n\n✍ Suppose you wish to solve u_t = u u_x for x\\in[-1,1].\n\n(a) If u(x,0) = -2+\\sin(\\pi x),  which end of the domain is the inflow?\n\n(b) Does the answer to part (a) change if u(x,0) = 1 + e^{-16x^2}?","type":"content","url":"/upwind#exercises","position":9},{"hierarchy":{"lvl1":"The wave equation"},"type":"lvl1","url":"/wave","position":0},{"hierarchy":{"lvl1":"The wave equation"},"content":"Closely related to the advection equation is the wave equation,    u_{tt} - c^2 u_{xx} = 0.\n\nThis is our first PDE having a second derivative in time. As in the advection equation, u(x,t)=\\phi(x-ct) is a solution of \n\n(12.4.1), but now so is u(x,t)=\\phi(x+c t) for any twice-differentiable ϕ (see \n\nExercise 2). Thus, the wave equation supports advection in both directions simultaneously.\n\nWe will use x \\in [0,1] and t>0 as the domain. Because u has two derivatives in t and in x, we need two boundary conditions. We will use the Dirichlet conditionsu(0,t) = u(1,t) = 0, \\qquad t \\ge 0,\n\nand two initial conditions,\\begin{split}\nu(x,0) &= f(x), \\qquad 0 \\le x \\le 1,  \\\\\nu_t(x,0) &= g(x), \\qquad 0 \\le x \\le 1. \n\\end{split}\n\nOne approach is to discretize both the u_{tt} and u_{xx} terms using finite differences:\\frac{1}{\\tau^2}(U_{i,j+1} - 2U_{i,j} + U_{i,j-1}) = \\frac{c^2}{h^2}\n(U_{i+1,j} - 2U_{i,j} + U_{i-1,j}).\n\nThis equation can be rearranged to solve for U_{i,j+1} in terms of values at time levels j and j-1. Rather than pursue this method, however, we will turn to the method of lines.","type":"content","url":"/wave","position":1},{"hierarchy":{"lvl1":"The wave equation","lvl2":"First-order system"},"type":"lvl2","url":"/wave#first-order-system","position":2},{"hierarchy":{"lvl1":"The wave equation","lvl2":"First-order system"},"content":"In order to be compatible with the standard IVP solvers that we have encountered, we must recast \n\n(12.4.1) as a first-order system in time. Using our typical methodology, we would define y=u_t and derive\\begin{split}\n  u_t &= y, \\\\\n  y_t &= c^2 u_{xx}.\n\\end{split}\n\nHowever, there is another, less obvious option for reducing to a first-order system:\\begin{split}\n    u_t &= z_x, \\\\\n    z_t &= c^2 u_{x}.\n\\end{split}\n\nThis second form is appealing in part because it’s equivalent to Maxwell’s equations for electromagnetism. In the Maxwell form we typically replace the velocity initial condition in \n\n(12.4.3) with a condition on z, which may be physically more relevant in some applications:\\begin{split}\nu(x,0) &= f(x), \\qquad 0 \\le x \\le 1,  \\\\\nz(x,0) &= g(x), \\qquad 0 \\le x \\le 1.\n\\end{split}\n\nBecause waves travel in both directions, there is no preferred upwind direction. This makes a centered finite difference in space appropriate. Before application of the boundary conditions, semidiscretization of \n\n(12.4.6) leads to  \\begin{bmatrix}\n    \\mathbf{u}'(t) \\\\[2mm]  \\mathbf{z}'(t)\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    \\boldsymbol{0} & \\mathbf{D}_x \\\\[2mm] c^2 \\mathbf{D}_x & \\boldsymbol{0}\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\mathbf{u}(t) \\\\[2mm] \\mathbf{z}(t)\n  \\end{bmatrix}.\n\nThe boundary conditions \n\n(12.4.2) suggest that we should remove both of the end values of \\mathbf{u} from the discretization, but retain all of the \\mathbf{z} values. We use \\mathbf{w}(t) to denote the vector of all the unknowns in the semidiscretization. When computing \\mathbf{w}'(t), we extract the \\mathbf{u} and \\mathbf{z} components, and we use dedicated functions for padding with the zero end values or chopping off the zeros as necessary.\n\nWave equation with boundaries\n\nWe solve the wave equation \n\n(12.4.6) with speed c=2, subject to \n\n(12.4.2) and initial conditions \n\n(12.4.7).\n\nExample 12.4.1\n\nm = 200\nx, Dₓ = FNC.diffcheb(m, [-1, 1]);\n\nThe boundary values of u are given to be zero, so they are not unknowns in the ODEs. Instead they are added or removed as necessary.\n\nextend = v -> [0; v; 0]\nchop = u -> u[2:m];\n\nThe following function computes the time derivative of the system at interior points.\n\node = function(w, c, t)\n    u = extend(w[1:m-1])\n    z = w[m:2m]\n    du_dt = Dₓ * z\n    dz_dt = c^2 * (Dₓ * u)\n    return [ chop(du_dt); dz_dt ]\nend;\n\nOur initial condition is a single hump for u.\n\nu_init = @. exp( -100*(x + 0.5)^2 )\nz_init = -u_init\nw_init = [ chop(u_init); z_init ];\n\nBecause the wave equation is hyperbolic, we can use a nonstiff explicit solver.\n\nusing OrdinaryDiffEq\nIVP = ODEProblem(ode, w_init ,(0., 2.), 2)\nw = solve(IVP, RK4());\n\nWe plot the results for the original u variable only. Its interior values are at indices 1:m-1 of the composite \\mathbf{w} variable.\n\nusing Plots\nt = range(0, 2, 80)\nU = [extend(w(t)[1:m-1]) for t in t]\ncontour(x, t, hcat(U...)';\n    levels=24,\n    color=:redsblues,  clims=(-1, 1),\n    xlabel=L\"x\",  ylabel=L\"t\",\n    title=\"Wave equation\",  right_margin=3Plots.mm)\n\nanim = @animate for t in range(0 ,2, 120)\n    plot(x, extend(w(t)[1:m-1]);\n        label=@sprintf(\"t=%.3f\",t),\n        xaxis=(L\"x\"),  yaxis=([-1, 1], L\"u(x,t)\"),\n        dpi=150,  title=\"Wave equation\")\nend\nmp4(anim, \"figures/wave-boundaries.mp4\")\n\nThe original hump breaks into two pieces of different amplitudes, each traveling with speed c=2. They pass through one another without interference. When a hump encounters a boundary, it is perfectly reflected, but with inverted shape. At time t=2, the solution looks just like the initial condition.\n\nExample 12.4.1\n\nc = 2;  m = 200;\n[x, Dx] = diffcheb(m, [-1, 1]);\n\nThe boundary values of u are given to be zero, so they are not unknowns in the ODEs. Instead they are added or removed as necessary.\n\nchop = @(u) u(2:m);\nextend = @(v) [0; v; 0];\n\nThe following function computes the time derivative of the system at interior points.\n\nfunction dw_dt = wave(t, w, param)\n    [c, m, Dx, chop, extend] = param{:};\n    u = extend(w(1:m-1));\n    z = w(m:2*m);\n    du_dt = Dx * z;\n    dz_dt = c.^2 .* (Dx * u);\n    dw_dt = [ chop(du_dt); dz_dt ];\nend\n\nOur initial condition is a single hump for u.\n\nu_init = exp( -100*x.^2 );\nz_init = -u_init;\nw_init = [ chop(u_init); z_init ];\n\nBecause the wave equation is hyperbolic, we can use a nonstiff explicit solver.\n\nivp = ode(ODEFcn=@f124wave);\nivp.InitialTime = 0;\nivp.InitialValue = w_init;\nivp.RelativeTolerance = 1e-4;\nivp.Parameters = {c, m, Dx, chop, extend};\nt = linspace(0, 2, 101);\nsol = solve(ivp, t);\n\nWe plot the results for the original u variable only. Its interior values are at indices 1:m-1 of the composite \\mathbf{w} variable.\n\nW = sol.Solution;\nn = length(t)-1;\nU = [ zeros(1, n+1); W(1:m-1, :); zeros(1, n+1) ];\n\ncmap = zeros(256, 3);\ncmap(129:end, 1) = 2/3;\ncmap(1:128, 2) = linspace(1, 0, 128);\ncmap(129:256, 2) = linspace(0, 1, 128);\ncmap(1:128, 3) = linspace(1, 0.5, 128);\ncmap(129:256, 3) = linspace(0.5, 1, 128);\ncmap = hsv2rgb(cmap);\n\nclf,  contour(x, t, U', 24, linewidth=2)\ncolormap(cmap),  clim([-1, 1])\nxlabel x,  ylabel t\ntitle(\"Wave equation with boundaries\")\n\nclf\nplot(x, U(:, 1))\nhold on\naxis([-1, 1, -1.05, 1.05])\ntitle(\"Wave equation with boundaries\") \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/wave-boundaries.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(-0.92, 0.85, str, fontsize=16);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThe original hump breaks into two pieces of different amplitudes, each traveling with speed c=2. They pass through one another without interference. When a hump encounters a boundary, it is perfectly reflected, but with inverted shape. At time t=2, the solution looks just like the initial condition.\n\nExample 12.4.1\n\nm = 200\nx, Dx, Dxx = FNC.diffmat2(m, [-1, 1])\n\nThe boundary values of u are given to be zero, so they are not unknowns in the ODEs. Instead they are added or removed as necessary.\n\nchop = lambda u: u[1:-1]\nextend = lambda v: hstack([0, v, 0])\n\nThe following function computes the time derivative of the system at interior points.\n\ndef dw_dt(t, w):\n    u = extend(w[:m-1])\n    z = w[m-1:]\n    du_dt = Dx @ z\n    dz_dt = c**2 * (Dx @ u)\n    return hstack([chop(du_dt), dz_dt])\n\nOur initial condition is a single hump for u.\n\nu_init = exp(-100 * x**2)\nz_init = -u_init\nw_init = hstack([chop(u_init), z_init])\n\nBecause the wave equation is hyperbolic, we can use a nonstiff explicit solver.\n\nc = 2\nsol = solve_ivp(dw_dt, (0, 2), w_init, dense_output=True)\nu = lambda t: extend(sol.sol(t)[:m-1])   # extract the u component\n\nWe plot the results for the original u variable only. Its interior values are at indices 1:m-1 of the composite \\mathbf{w} variable.\n\nt = linspace(0, 2, 80)\nU = [u(tj) for tj in t]\ncontour(x, t, U, levels=24, cmap=\"RdBu\", vmin=-1, vmax=1)\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Wave equation with boundaries\");\n\nfrom matplotlib import animation\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-1.05, 1.05)\nax.set_title(\"Wave equation with boundaries\")\n\ndef snapshot(t):\n    curve.set_ydata(u(t))\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 2, 161)\n    )\nanim.save(\"figures/wave-boundaries.mp4\", fps=30)\nclose()\n\nThe original hump breaks into two pieces of different amplitudes, each traveling with speed c=2. They pass through one another without interference. When a hump encounters a boundary, it is perfectly reflected, but with inverted shape. At time t=2, the solution looks just like the initial condition.","type":"content","url":"/wave#first-order-system","position":3},{"hierarchy":{"lvl1":"The wave equation","lvl2":"Variable speed"},"type":"lvl2","url":"/wave#variable-speed","position":4},{"hierarchy":{"lvl1":"The wave equation","lvl2":"Variable speed"},"content":"An interesting situation is when the wave speed c changes discontinuously, as when light passes from one material into another. For this we must replace the term c^2 in \n\n(12.4.8) with the matrix \\operatorname{diag}\\bigl(c^2(x_0),\\ldots,c^2(x_m)\\bigr).\n\nWave equation with variable speed\n\nWe now use a wave speed that is discontinuous at x=0; to the left, c=1, and to the right, c=2.\n\nExample 12.4.2\n\nThe ODE implementation has to change slightly.\n\node = function(w,c,t)\n    u = extend(w[1:m-1])\n    z = w[m:2m]\n    du_dt = Dₓ*z\n    dz_dt = c.^2 .* (Dₓ*u)\n    return [ chop(du_dt); dz_dt ]\nend;\n\nThe variable wave speed is passed as an extra parameter through the IVP solver.\n\nc = @. 1 + (sign(x)+1)/2\nIVP = ODEProblem(ode, w_init, (0., 5.), c)\nw = solve(IVP, RK4());\n\nt = range(0, 5, 80)\nU = [extend(w(t)[1:m-1]) for t in t]\ncontour(x, t, hcat(U...)';\n    color=:redsblues,  clims=(-1,1),\n    levels=24,\n    xlabel=L\"x\",  ylabel=L\"t\",\n    title=\"Wave equation\",\n    right_margin=3Plots.mm\n    )\n\nanim = @animate for t in range(0,5,181)\n    plot(Shape([-1, 0, 0, -1], [-1, -1, 1, 1]), color=RGB(.8, .8, .8), l=0, label=\"\")\n    plot!(x, extend(w(t, idxs=1:m-1));\n        label=@sprintf(\"t=%.2f\", t), \n        xaxis=(L\"x\"),  yaxis=([-1, 1], L\"u(x,t)\"),\n        dpi=150,  title=\"Wave equation, variable speed\")\nend\nmp4(anim, \"figures/wave-speed.mp4\")\n\nEach pass through the interface at x=0 generates a reflected and transmitted wave. By conservation of energy, these are both smaller in amplitude than the incoming bump.\n\nExample 12.4.2\n\nWe now use a wave speed that is discontinuous at x=0.\n\nm = 120;\n[x, Dx] = diffcheb(m, [-1, 1]);\nc = 1 + (sign(x) + 1) / 2;\nchop = @(u) u(2:m);\nextend = @(v) [0; v; 0];\n\nu_init = exp( -100*(x + 0.5).^2 );\nz_init = -u_init;\nivp.InitialValue = [ chop(u_init); z_init ]; \nivp.Parameters = {c, m, Dx, chop, extend};\nsol = solve(ivp, t);\nW = sol.Solution;\nU = [ zeros(1, n+1); W(1:m-1, :); zeros(1, n+1) ];\n\nclf,  contour(x, t, U', 24, linewidth=2)\ncolormap(cmap),  clim([-1, 1])\nxlabel x,  ylabel t\ntitle(\"Wave equation with variable speed\")\n\nclf\nplot(x, U(:, 1))\nhold on\naxis([-1, 1, -1.05, 1.05])\ntitle(\"Wave equation with variable speed\") \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/wave-speed.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(-0.92, 0.85, str, fontsize=16);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nEach pass through the interface at x=0 generates a reflected and transmitted wave. By conservation of energy, these are both smaller in amplitude than the incoming bump.\n\nExample 12.4.2\n\nThe variable wave speed is set to be re-used\n\nm = 120\nx, Dx, Dxx = FNC.diffcheb(m, [-1, 1])\nc = 1 + (sign(x) + 1) / 2\nu_init = exp(-100 * x**2)\nz_init = -u_init\nw_init = hstack([chop(u_init), z_init])\n\nsol = solve_ivp(dw_dt, (0, 5), w_init, dense_output=True, method=\"Radau\")\nu = lambda t: extend(sol.sol(t)[:m-1])\n\nt = linspace(0, 5, 150)\nU = [u(tj) for tj in t]\ncontour(x, t, U, levels=24, cmap=\"RdBu\", vmin=-1, vmax=1)\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Wave equation with variable speed\");\n\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-1.05, 1.05)\nax.set_title(\"Wave equation with variable speed\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 5, 251)\n    )\nanim.save(\"figures/wave-speed.mp4\", fps=30)\nclose()\n\nEach pass through the interface at x=0 generates a reflected and transmitted wave. By conservation of energy, these are both smaller in amplitude than the incoming bump.","type":"content","url":"/wave#variable-speed","position":5},{"hierarchy":{"lvl1":"The wave equation","lvl2":"Exercises"},"type":"lvl2","url":"/wave#exercises","position":6},{"hierarchy":{"lvl1":"The wave equation","lvl2":"Exercises"},"content":"✍ Consider the Maxwell equations \n\n(12.4.6) with smooth solution u(x,t) and z(x,t).\n\n(a) Show that u_{tt} = c^2 u_{xx}.\n\n(b) Show that z_{tt} = c^2 z_{xx}.\n\n✍ Suppose that \\phi(s) is any twice-differentiable function.\n\n(a) Show that u(x,t) = \\phi(x-c t) is a solution of u_{tt}=c^2u_{xx}. (As in the advection equation, this is a traveling wave of velocity c.)\n\n(b) Show that u(x,t) = \\phi(x+c t) is another solution of u_{tt}=c^2u_{xx}. (This is a traveling wave of velocity -c.)\n\n✍ Show that the following is a solution to the wave equation u_{tt}=c^2u_{xx} with initial and boundary conditions \n\n(12.4.2) and \n\n(12.4.3):u(x,t) = \\frac{1}{2} \\left[ f(x-ct)+f(x+ct)\\right] + \\frac{1}{2c} \\int_{x-ct}^{x+ct} g(\\xi) \\, d\\xi\n\nThis is known as D’Alembert’s solution.\n\n⌨ Suppose the wave equation has homogeneous Neumann conditions on u at each boundary instead of Dirichlet conditions. Using the Maxwell formulation \n\n(12.4.6), we have z_t=c^2u_x, so z is constant in time at each boundary. Therefore, the endpoint values of \\mathbf{z} can be taken from the initial condition and removed from the ODE, while the entire \\mathbf{u} vector is now part of the ODE.\n\nModify \n\nDemo 12.4.1 to solve the PDE there with Neumann instead of Dirichlet conditions, and make an animation or space-time portrait of the solution. In what major way is it different from the Dirichlet case?\n\n⌨ The equations u_t=z_x-\\sigma u, z_t=c^2u_{xx} model electromagnetism in an imperfect conductor. Repeat \n\nDemo 12.4.2 with \\sigma(x)=2+2\\operatorname{sign}(x). (This causes waves in the half-domain x>0 to decay in time.)\n\nThe nonlinear sine–Gordon equation u_{tt}-u_{xx}=\\sin u has interesting solutions.\n\n(a) ✍ Write the equation as a first-order system in the variables u and v=u_t.\n\n(b) ⌨ Assume periodic end conditions on [-10,10] and discretize at m=200 points. Let u(x,0) = \\pi e^{-x^2} and u_t(x,0) = 0. Solve the system using RK4 between t=0 and t=50, and make a plot or animation of the solution.\n\nThe deflections of a stiff beam, such as a ruler, are governed by the PDE u_{tt}=-u_{xxxx}.\n\n(a) ✍ Show that the beam PDE is equivalent to the first-order system\\begin{align*}\n    u_t &= v_{xx}, \\\\\n    v_t &= -u_{xx}.\n    \\end{align*}\n\n(b) ⌨ Assuming periodic end conditions on [-1,1], use m=100, let u(x,0) =\\exp(-24x^2), v(x,0) = 0, and simulate the solution of the beam equation for 0\\le t \\le 1 using \n\nFunction 6.7.2 with n=100 time steps. Make a plot or animation of the solution.","type":"content","url":"/wave#exercises","position":7},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection"},"type":"lvl1","url":"/diffadv","position":0},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection"},"content":"We next describe how to apply the method of lines to PDEs of the form  u_t = \\phi(u,u_x,u_y,u_{xx},u_{xy},u_{yy}), \\quad (x,y)\\in [a,b]\\times [c,d].\n\nThe PDE may be of either parabolic or hyperbolic type, with the primary difference being potential restrictions on the time step size. To keep descriptions and implementations relatively simple, we will consider only periodic conditions, or Dirichlet boundary conditions imposed on all the edges of the rectangular domain.\n\nAs described in \n\nTensor-product discretizations, the rectangular domain is discretized by a grid (x_i,y_j) for i=0,\\ldots,m and j=0,\\ldots,n. The solution is semidiscretized as a matrix \\mathbf{U}(t) such that U_{ij}\\approx u(x_i,y_j,t). Terms involving the spatial derivatives of u are readily replaced by discrete counterparts: \\mathbf{D}_x\\mathbf{U} for u_x, \\mathbf{U}\\mathbf{D}_{y}^T for u_y, and so on.","type":"content","url":"/diffadv","position":1},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Matrix and vector shapes"},"type":"lvl2","url":"/diffadv#matrix-and-vector-shapes","position":2},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Matrix and vector shapes"},"content":"Our destination is an IVP that can be solved by a Runge–Kutta or multistep solver. These solvers are intended for vector problems, but our unknowns naturally have a matrix shape, which is the most convenient for the differentiation formulas \n\n(13.1.8) and \n\n(13.1.9). Fortunately, it’s easy to translate back and forth between a matrix and an equivalent vector.\n\nvec and unvec operations\n\nLet \\mathbf{A} be an m\\times n matrix. Define the vec function as stacking the columns of \\mathbf{A} into a vector, i.e.,\\operatorname{vec}(\\mathbf{A}) =\n\\begin{bmatrix}\nA_{11} \\\\ \\vdots \\\\ A_{m1}  \\\\ \\vdots  \\\\ A_{1n} \\\\ \\vdots \\\\ A_{m n}\n\\end{bmatrix}.\n\nLet \\mathbf{z} be a vector of length m n. Define the unvec function as the inverse of vec:\\operatorname{unvec}(\\mathbf{z}) = \\begin{bmatrix}\n  z_1 & z_{m+1} & \\cdots & z_{m(n-1)+1} \\\\\n  z_2 & z_{m+2} & \\cdots & z_{m(n-1)+2} \\\\\n  \\vdots & \\vdots & & \\vdots \\\\\n  z_m & z_{2m} & \\cdots & z_{m n} \\\\\n\\end{bmatrix}.\n\nThe function vec is built-in to Julia, whereas unvec is a particular use case of the reshape function.\n\nReshaping for grid functions\n\nExample 13.2.1\n\nm = 2;\nn = 3;\nV = rand(1:9, m, n);\nv = vec(V)\n\nThe unvec operation is the inverse of vec.\n\nunvec = z -> reshape(z, m, n)\nunvec(v)\n\nExample 13.2.1\n\nm = 4;  n = 3;\nx = linspace(0, 2, m+1);\ny = linspace(-3, 0, n+1);\n\nf = @(x, y) cos(0.75*pi * x .* y - 0.5*pi * y);\n[mtx, X, Y, vec, unvec] = tensorgrid(x, y);\nF = mtx(f);\ndisp(\"function on a 4x3 grid:\")\ndisp(F)\n\ndisp(\"vec(F):\")\ndisp(vec(F))\n\nThe unvec operation is the inverse of vec.\n\ndisp(\"unvec(vec(F)):\")\ndisp(unvec(vec(F)))\n\nExample 13.2.1\n\nm, n = 4, 3\nx = linspace(0, 2, m+1)\ny = linspace(-3, 0, n+1)\n\nf = lambda x, y: cos(0.75 * pi * x * y - 0.5 * pi * y)\nmtx, X, Y, vec, unvec, _ = FNC.tensorgrid(x, y)\nF = mtx(f)\nprint(f\"function on a {m}x{n} grid:\")\nwith printoptions(precision=4, suppress=True):\n    print(F)\n\nprint(\"vec(F):\")\nwith printoptions(precision=4, suppress=True):\n    print(vec(F))\n\nThe unvec operation is the inverse of vec.\n\nprint(\"unvec(vec(F)):\")\nwith printoptions(precision=4, suppress=True):\n    print(unvec(vec(F)))","type":"content","url":"/diffadv#matrix-and-vector-shapes","position":3},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Periodic end conditions"},"type":"lvl2","url":"/diffadv#periodic-end-conditions","position":4},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Periodic end conditions"},"content":"If the boundary conditions are periodic, then the unknowns in the method of lines are the elements of the matrix \\mathbf{U}(t) representing grid values of the numerical solution. For the purposes of an IVP solution, this matrix is equivalent to the vector \\mathbf{u}(t) defined as \\mathbf{u}=\\operatorname{vec}(\\mathbf{U}).\n\nHeat equation in 2D\n\nWe will solve a 2D heat equation, u_t = 0.1(u_{xx} + u_{yy}), on the square [-1,1]\\times[-1,1], with periodic behavior in both directions.\n\nExample 13.2.2\n\nm, n = (60, 25)\nx, Dx, Dxx = FNC.diffper(m, [-1, 1])\ny, Dy, Dyy = FNC.diffper(n, [-1, 1])\nmtx = f -> [f(x, y) for x in x, y in y]\nunvec = z -> reshape(z, m, n);\n\nNote that the initial condition should also be periodic on the domain.\n\nusing Plots\nu_init = (x, y) -> sin(4 * π * x) * exp(cos(π * y))\nU₀ = mtx(u_init)\nM = maximum(abs, U₀)\ncontour(x, y, U₀';\n    color=:redsblues,  clims=(-M, M), \n    aspect_ratio=1,\n    xaxis=(\"x\", (-1, 1)),  yaxis=(\"y\", (-1, 1)), \n    title=\"Initial condition\" )\n\nThis function computes the time derivative for the unknowns. The actual calculations take place using the matrix shape.\n\nfunction du_dt(u, α, t)\n    U = unvec(u)\n    Uxx = Dxx * U\n    Uyy = U * Dyy'            # 2nd partials\n    du_dt = α * (Uxx + Uyy)    # PDE\n    return vec(du_dt)\nend;\n\nSince this problem is parabolic, a stiff integrator is appropriate.\n\nusing OrdinaryDiffEq\nIVP = ODEProblem(du_dt, vec(U₀), (0, 0.2), 0.1)\nsol = solve(IVP, Rodas4P());\n\nHere is an animation of the solution.\n\nTip\n\nHere clims are set so that colors remain at fixed values throughout the animation.\n\nanim = @animate for t in range(0, 0.2, 81)\n    surface(x, y, unvec(sol(t))';\n        color=:redsblues,  clims=(-M, M),\n        xaxis=(L\"x\", (-1, 1)), \n        yaxis=(L\"y\", (-1, 1)), \n        zlims=(-M, M),\n        title=@sprintf(\"Heat equation, t=%.3f\", t),\n        dpi=150, colorbar=:none)\nend\nmp4(anim, \"figures/2d-heat.mp4\");\n\nExample 13.2.2\n\nm = 60;  n = 40;\n[x, Dx, Dxx] = diffper(m, [-1, 1]);\n[y, Dy, Dyy] = diffper(n, [-1, 1]);\n[mtx, X, Y, vec, unvec] = tensorgrid(x, y);\n\nNote that the initial condition should also be periodic on the domain.\n\nU0 = sin(4*pi*X) .* exp( cos(pi*Y) );\nclf,  surf(X', Y', U0')\nmx = max(abs(vec(U0)));\nclim([-mx, mx]),  shading interp\ncolormap(redsblues)\nxlabel('x'),  ylabel('y')  \ntitle('Initial condition')\n\nThis function computes the time derivative for the unknowns. The actual calculations take place using the matrix shape.\n\nfunction du_dt = timederiv(t, u, p)\n    [alpha, Dxx, Dyy, vec, unvec] = p{:};\n    U = unvec(u);\n    Uxx = Dxx * U;  Uyy = U * Dyy';     % 2nd partials\n    dU_dt = alpha * (Uxx + Uyy);  % PDE\n    du_dt = vec(dU_dt);\nend\n\nSince this problem is parabolic, a stiff integrator is appropriate.\n\nivp = ode(ODEFcn=@f13_2_heat);\nivp.InitialTime = 0;\nivp.InitialValue = vec(U0);\nivp.Parameters = {0.1, Dxx, Dyy, vec, unvec};\nivp.Solver = \"stiff\";\nsol = solutionFcn(ivp, 0, 0.2);\nU = @(t) unvec(sol(t));\n\nsurf(X', Y', U(0.05)')\nclim([-mx, mx]),  shading interp\ncolormap(redsblues)\nxlabel('x'),  ylabel('y')  \ntitle('Solution at t = 0.05')\n\nHere is an animation of the solution.\n\nTip\n\nHere clims are set so that colors remain at fixed values throughout the animation.\n\ntitle('Heat equation on a periodic domain')\nvid = VideoWriter(\"figures/2d-heat.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 0.2, 61)\n    cla, surf(X', Y', U(t)')\n    zlim([-3, 3]),  clim([-mx, mx])\n    shading interp\n    str = sprintf(\"t = %.2f\", t);\n    text(-0.9, 0.75, 2, str, fontsize=14);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 13.2.2\n\nm, n = 60, 40\nx, Dx, Dxx = FNC.diffper(m, [-1, 1])\ny, Dy, Dyy = FNC.diffper(n, [-1, 1])\nmtx, X, Y, vec, unvec, _ = FNC.tensorgrid(x, y)\n\nNote that the initial condition should also be periodic on the domain.\n\nu_init = lambda x, y: sin(4 * pi * x) * exp(cos(pi * y))\nU0 = mtx(u_init)\nmx = max(abs(U0))\npcolormesh(X, Y, U0, vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\naxis(\"equal\"),  colorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\")\ntitle(\"Initial condition\");\n\nThis function computes the time derivative for the unknowns. The actual calculations take place using the matrix shape.\n\nalpha = 0.1\ndef du_dt(t, u):\n    U = unvec(u)\n    Uyy = Dxx @ U\n    Uxx = U @ Dyy.T\n    dU_dt = alpha * (Uxx + Uyy)  # PDE\n    return vec(dU_dt)\n\nSince this problem is parabolic, a stiff integrator is appropriate.\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(du_dt, (0, 0.2), vec(U0), method=\"BDF\", dense_output=True)\nU = lambda t: unvec(sol.sol(t))\n\npcolormesh(X.T, Y.T, U(0.02).T, \n    vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\naxis(\"equal\"),  colorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\")\ntitle(\"Heat equation, t=0.02\");\n\nHere is an animation of the solution.\n\nTip\n\nHere clims are set so that colors remain at fixed values throughout the animation.\n\nfrom matplotlib import animation\nfig, ax = subplots()\nobj = ax.pcolormesh(X, Y, U(0), vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\"),  ax.set_ylabel(\"$y$\")\nax.set_aspect(\"equal\")\nax.set_title(\"Heat equation on a periodic domain\")\ndef snapshot(t):\n    global obj\n    obj.remove()\n    obj = ax.pcolormesh(X, Y, U(t), vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(fig, snapshot, frames=linspace(0, 0.2, 41))\nanim.save(\"figures/heat-2d.mp4\", fps=30)\nclose()","type":"content","url":"/diffadv#periodic-end-conditions","position":5},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Dirichlet conditions"},"type":"lvl2","url":"/diffadv#dirichlet-conditions","position":6},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Dirichlet conditions"},"content":"In \n\nBoundaries we coped with boundary conditions by removing the boundary values from the vector of unknowns being solved in the semidiscretized ODE. Each evaluation of the time derivative required us to extend the values to include the boundaries before applying differentiation matrices in space. We proceed similarly here, except that we have changes in the shape as well as boundary conditions to consider.\n\nSuppose we are given a matrix \\mathbf{U} that represents the solution on an (m+1)\\times (n+1) grid, including boundary values. Then we define\\operatorname{pack}(\\mathbf{U}) = \\operatorname{vec}(\\mathbf{E}_x \\mathbf{U} \\mathbf{E}_y^T),\n\nwhere\\mathbf{E}_x = \\begin{bmatrix}\n  0 & 1 & 0 & \\cdots & 0 & 0 \\\\\n  0 & 0 & 1 & \\cdots & 0 & 0 \\\\\n   &  &  & \\ddots &  & \\\\\n  0 & 0 & 0 & \\cdots & 1 & 0\n\\end{bmatrix}\n\nis (m-1)\\times (m+1), and \\mathbf{E}_y is analogous but of size (n-1)\\times (n+1). The left multiplication in \n\n(13.2.4) deletes the first and last row of \\mathbf{U} and the right multiplication deletes its first and last column. All that remains, then, are the interior values, which are converted into a vector by the vec operator.\n\nFor the inverse transformation, let us be given a vector \\mathbf{w} of interior solution values. Then we define\\operatorname{unpack}(\\mathbf{w}) = \\mathbf{E}_x^T \\cdot \\operatorname{unvec}(\\mathbf{w}) \\cdot \\mathbf{E}_y.\n\nThis operator reshapes the vector to a grid of interior values, then appends one extra zero row and column on each side of the grid.\n\nNow suppose the ODE unknowns for the interior solution values are in the vector \\mathbf{w}(t). When we form \\operatorname{unpack}(\\mathbf{w}), we reinterpret the values on the tensor-product grid and then extend these values to zero around the boundary. If the boundary values are given as g(x,y), then g has to be evaluated at the boundary nodes of the grid and inserted into the grid function matrix. Then the grid values are used to compute partial derivatives in x and y, the discrete form of the PDE is evaluated, and we pack the result as the computation of \\mathbf{w}'.\n\nAdvection-diffusion equation in 2D\n\nWe will solve an advection-diffusion problem, u_t + u_x = 1 + \\epsilon(u_{xx} + u_{yy}), where u=0 on the boundary of the square [-1,1]^2. The outline of our approach is based on \n\nFunction 11.5.2 for parabolic PDEs in one space dimension.\n\nExample 13.2.3\n\nThe first step is to define a discretization of the domain.\n\nm, n = 50, 36\nx, Dx, Dxx = FNC.diffcheb(m, [-1, 1])\ny, Dy, Dyy = FNC.diffcheb(n, [-1, 1])\nmtx, X, Y, _ = FNC.tensorgrid(x, y)\nU₀ = mtx( (x, y) -> (1 + y) * (1 - x)^4 * (1 + x)^2 * (1 - y^4) );\n\nThere are really two grids now: the full grid and the subset grid of interior points. Since the IVP unknowns are on the interior grid, that is the one we need to change shapes on. We also need the functions extend and chop to add and remove boundary values.\n\nchop = U -> U[2:m, 2:n]\nextend = U -> [zeros(m+1) [zeros(1, n-1); U; zeros(1, n-1)] zeros(m+1)]\nunvec = u -> reshape(u, m-1, n-1)\npack = U -> vec(chop(U))\nunpack = w -> extend(unvec(w))\n\nNow we can define and solve the IVP using a stiff solver.\n\nfunction dw_dt(w, ϵ, t)\n    U = unpack(w)\n    Ux, Uxx = Dx * U, Dxx * U\n    Uyy = U * Dyy'\n    du_dt = @. 1 - Ux + ϵ * (Uxx + Uyy)\n    return pack(du_dt)\nend\n\nIVP = ODEProblem(dw_dt, pack(U₀), (0.0, 2), 0.05)\nw = solve(IVP, Rodas4P());\n\nWhen we evaluate the solution at a particular value of t, we get a vector of the interior grid values. The same unpack function above converts this to a complete matrix of grid values.\n\nU = t -> unpack(w(t))\ncontour(x, y, U(0.5)';\n    fill=true,  color=:blues,  levels=20, l=0,\n    aspect_ratio=1,  xlabel=L\"x\",  ylabel=L\"y\",\n    title=\"Solution at t = 0.5\")\n\nanim = @animate for t in 0:0.02:2\n    U = unpack(w(t))\n    surface(x, y, U';\n        layout=(1, 2),  size=(640, 320),\n        xlabel=L\"x\",  ylabel=L\"y\",  zaxis=((0, 2), L\"u(x,y)\"),\n        color=:blues,  alpha=0.66,  clims=(0, 2), colorbar=:none,\n        title=\"Advection-diffusion\",  dpi=150)\n    contour!(x, y, U'; \n        levels=24, \n        aspect_ratio=1,  subplot=2, \n        xlabel=L\"x\",  ylabel=L\"y\",\n        color=:blues,  clims=(0, 2),  colorbar=:none,\n        title=@sprintf(\"t = %.2f\", t))\nend\nmp4(anim, \"figures/2d-advdiff.mp4\");\n\nExample 13.2.3\n\nThe first step is to define a discretization of the domain and the initial state.\n\nm = 50;  n = 40;\n[x, Dx, Dxx] = diffcheb(m, [-1, 1]);\n[y, Dy, Dyy] = diffcheb(n, [-1, 1]);\n[mtx, X, Y] = tensorgrid(x, y);\nu_init = @(x, y) (1+y) .* (1-x).^4 .* (1+x).^2 .* (1-y.^4);\n\nThere are really two grids now: the full grid and the subset grid of interior points. Since the IVP unknowns are on the interior grid, that is the one we need to change shapes on. We also need the functions extend and chop to add and remove boundary values.\n\n[~, ~, ~, vec, unvec] = tensorgrid(x(2:m), y(2:n));\nchop = @(U) U(2:m, 2:n);\nz = zeros(1, n-1);\nextend = @(U) [ zeros(m+1, 1) [z; U; z] zeros(m+1, 1)];\npack = @(U) vec(chop(U));\nunpack = @(u) extend(unvec(u));\n\nNow we can define and solve the IVP using a stiff solver.\n\nfunction du_dt = timederiv(t, u, p)\n    [ep, Dx, Dxx, Dy, Dyy, pack, unpack] = p{:};\n    U = unpack(u);\n    Uxx = Dxx * U;  Uyy = U * Dyy'; \n    dU_dt = 1 - Dx * U + ep * (Uxx + Uyy);  % PDE\n    du_dt = pack(dU_dt);\nend\n\nivp = ode(ODEFcn=@f13_2_advdiff);\nivp.InitialTime = 0;\nivp.InitialValue = pack(mtx(u_init));\nivp.Parameters = {0.05, Dx, Dxx, Dy, Dyy, pack, unpack};\nivp.Solver = \"stiff\";\nsol = solutionFcn(ivp, 0, 2);\n\nWhen we evaluate the solution at a particular value of t, we get a vector of the interior grid values. The same unpack function above converts this to a complete matrix of grid values.\n\nU = @(t) unpack(sol(t));\n\nclf,  pcolor(X', Y', U(0.5)')\nclim([0, 2]), shading interp\naxis equal,  colormap(sky), colorbar\ntitle('Advection-diffusion at t = 0.5')  \nxlabel('x'),  ylabel('y')\n\nhold on\nvid = VideoWriter(\"figures/2d-advdiff.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\ntitle(\"Advection-diffusion in 2d\")\nfor t = linspace(0, 2, 81)\n    cla, pcolor(X', Y', U(t)')\n    shading interp\n    str = sprintf(\"t = %.2f\", t);\n    text(-1.5, 0.75, str, fontsize=14);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 13.2.3\n\nThe first step is to define a discretization of the domain.\n\nm, n = 50, 36\nx, Dx, Dxx = FNC.diffcheb(m, [-1, 1])\ny, Dy, Dyy = FNC.diffcheb(n, [-1, 1])\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nu_init = lambda x, y: (1 + y) * (1 - x)**4 * (1 + x)**2 * (1 - y**4)\n\nThere are really two grids now: the full grid and the subset grid of interior points. Since the IVP unknowns are on the interior grid, that is the one we need to change shapes on. We also need the functions extend and chop to add and remove boundary values.\n\n_, _, _, vec, unvec, _ = FNC.tensorgrid(x[1:-1], y[1:-1])\n\ndef chop(U):\n    return U[1:-1, 1:-1]\n\ndef extend(U):\n    UU = zeros((m+1, n+1))\n    UU[1:-1, 1:-1] = U\n    return UU\n\npack = lambda U: vec(chop(U))          # restrict to interior, then vectorize\nunpack = lambda u: extend(unvec(u))    # unvectorize, then extend to boundary\n\nNow we can define and solve the IVP using a stiff solver.\n\nep = 0.05\ndef dw_dt(t, w):\n    U = unpack(w)\n    Uyy = Dxx @ U\n    Uxx = U @ Dyy.T \n    dU_dt = 1 - Dx @ U + ep * (Uxx + Uyy)\n    return pack(dU_dt)\n\nU0 = mtx(u_init)\nsol = solve_ivp(dw_dt, (0, 2), pack(U0), method=\"BDF\", dense_output=True)\n\nWhen we evaluate the solution at a particular value of t, we get a vector of the interior grid values. The same unpack function above converts this to a complete matrix of grid values.\n\nU = lambda t: unpack(sol.sol(t))    # function of time on the grid\n\npcolormesh(X.T, Y.T, U(0.5).T, cmap=\"Blues\", shading=\"gouraud\")\ncolorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\")\naxis(\"equal\"),  title(\"Solution at t=0.5\");\n\nfig, ax = subplots()\nobj = ax.pcolormesh(X.T, Y.T, U(0).T, vmin=0, vmax=2, cmap=\"Blues\", shading=\"gouraud\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\"),  ax.set_ylabel(\"$y$\")\nax.set_aspect(\"equal\")\nax.set_title(\"Advection-diffusion in 2d\")\ndef snapshot(t):\n    global obj\n    obj.remove()\n    obj = ax.pcolormesh(X.T, Y.T, U(t).T, vmin=0, vmax=2, cmap=\"Blues\", shading=\"gouraud\")\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(fig, snapshot, frames=linspace(0, 2, 81))\nanim.save(\"figures/advdiff-2d.mp4\", fps=30)\nclose()\n\nThe wave equation introduces a little additional complexity. First, we write the 2D wave equation u_{tt}=c^2(u_{xx}+u_{yy}) in first-order form as\\begin{split}\n    u_t &= v, \\\\\n    v_t &= c^2(u_{xx}+u_{yy}).\n\\end{split}\n\nNow the grid unknowns are a pair of matrices \\mathbf{U}(t) and \\mathbf{V}(t). Typical boundary conditions would prescribe u on all of the boundary and let v be unspecified. Since the boundary values of \\mathbf{U} are prescribed, those values are omitted from the semidiscretization IVP, while all of \\mathbf{V} is included. All of these unknowns need to be packed into and unpacked from a single vector \\mathbf{w}(t) for the IVP solver.\n\nWave equation in 2D\n\nWe solve the wave equation with c=1 on the square [-2,2]\\times[-2,2], where u=0 on the boundary.\n\nExample 13.2.4\n\nWe start with the discretization and initial condition.\n\nm, n = 40, 40\nx, Dx, Dxx = FNC.diffcheb(m, [-2, 2])\ny, Dy, Dyy = FNC.diffcheb(n, [-2, 2])\nmtx, X, Y, _ = FNC.tensorgrid(x, y)\nU₀ = mtx( (x, y) -> (x + 0.2) * exp(-12 * (x^2 + y^2)) )\nV₀ = zeros(size(U₀));\n\nNote that because u is known on the boundary, while v is unknown over the full grid, there are two different sizes of vec/unvec operations. We also need to define functions to pack grid unknowns into a vector and to unpack them. When the unknowns for u are packed, the boundary values are chopped off, and these are restored when unpacking.\n\n_, _, _, unvec_v, _ = FNC.tensorgrid(x, y)\n_, _, _, unvec_u, _ = FNC.tensorgrid(x[2:m], y[2:n])\nchop = U -> U[2:m, 2:n]\nextend = U -> [zeros(m+1) [zeros(1, n-1); U; zeros(1, n-1)] zeros(m+1)]\npack = (U, V) -> [vec(chop(U)); vec(V)]\nN = (m-1) * (n-1)    # number of interior unknowns\nunpack = w -> ( extend(unvec_u(w[1:N])), unvec_v(w[N+1:end]) )\n\nWe can now define and solve the IVP. Since this problem is hyperbolic, not parabolic, a nonstiff integrator is faster than a stiff one.\n\nfunction dw_dt(w, c, t)\n    U, V = unpack(w)\n    du_dt = V\n    dv_dt = c^2 * (Dxx * U + U * Dyy')\n    return pack(du_dt, dv_dt)\nend\n\nIVP = ODEProblem(dw_dt, pack(U₀, V₀), (0, 4.0), 1)\nsol = solve(IVP, Tsit5())\nU = t -> unpack(sol(t))[1]\n\nanim = @animate for t in 0:4/100:4\n    Ut = U(t)\n    surface(x, y, Ut';\n        layout=(1, 2), size=(640, 320),\n        xlabel=L\"x\",  ylabel=L\"y\",  zaxis=((-0.1, 0.1), L\"u(x,y)\"),\n        color=:redsblues,  alpha=0.66,  clims=(-0.1, 0.1), colorbar=:none,\n        title=\"Wave equation\",  dpi=150)\n    contour!(x, y, Ut'; \n        levels=24,  subplot=2, \n        aspect_ratio=1,\n        xlabel=L\"x\",  ylabel=L\"y\",\n        color=:redsblues,  clims=(-0.1, 0.1), \n        colorbar=:none,  title=@sprintf(\"t = %.2f\", t))\nend\nmp4(anim, \"figures/2d-wave.mp4\");\n\nExample 13.2.4\n\nWe start with the discretization and initial condition.\n\nm = 40; n = 42;\n[x, Dx, Dxx] = diffcheb(m, [-2, 2]);\n[y, Dy, Dyy] = diffcheb(n, [-2, 2]);\n[mtx, X, Y] = tensorgrid(x, y);\n\nu_init = @(x, y) (x+0.2) .* exp(-12*(x.^2 + y.^2));\nU0 = mtx(u_init);\nV0 = zeros(size(U0));\n\nNote that because u is known on the boundary, while v is unknown over the full grid, there are two different sizes of vec/unvec operations. We also need to define functions to pack grid unknowns into a vector and to unpack them. When the unknowns for u are packed, the boundary values are chopped off, and these are restored when unpacking.\n\n[~, ~, ~, vec_v, unvec_v] = tensorgrid(x, y);\n[~, ~, ~, vec_u, unvec_u] = tensorgrid(x(2:m), y(2:n));\n\nchop = @(U) U(2:m, 2:n);\nz = zeros(1, n-1);\nextend = @(U) [ zeros(m+1, 1) [z; U; z] zeros(m+1, 1)];\npack = @(U, V) [vec_u(chop(U)); vec_v(V)];\nN = (m-1) * (n-1);\nunpack = @(u) f13_2_wave_unpack(u, N, unvec_u, unvec_v, extend);\n\nfunction [U, V] = unpack(w, N, unvec_u, unvec_v, extend)\n    U = extend( unvec_u(w(1:N)) );\n    V = unvec_v(w(N+1:end));\nend\n\nWe can now define and solve the IVP. Since this problem is hyperbolic, not parabolic, a nonstiff integrator is faster than a stiff one.\n\nfunction dw_dt = timederiv(t, w, p)\n    [Dxx, Dyy, pack, unpack] = p{:};\n    [U, V] = unpack(w);\n    dU_dt = V;\n    dV_dt = Dxx * U + U * Dyy';\n    dw_dt = pack(dU_dt, dV_dt);\nend\n\nivp = ode(ODEFcn=@f13_2_wave);\nivp.InitialTime = 0;\nivp.InitialValue = pack(U0, V0);\nivp.Parameters = {Dxx, Dyy, pack, unpack};\nivp.Solver = \"nonstiff\";\nsol = solutionFcn(ivp, 0, 4);\n\nclf\n[U, V] = unpack(sol(0.5));\npcolor(X', Y', U')\naxis equal,  clim([-0.1, 0.1])\ncolormap(redsblues),  shading interp\nxlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Wave equation at t = 0.5\")\n\nhold on\nvid = VideoWriter(\"figures/2d-wave.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\ntitle(\"Wave equation in 2d\")\nfor t = linspace(0, 4, 121)\n    [U, V] = unpack(sol(t));\n    cla, pcolor(X, Y, U)\n    shading interp\n    str = sprintf(\"t = %.2f\", t);\n    text(-3, 1.75, str, fontsize=14);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 13.2.4\n\nWe start with the discretization and initial condition.\n\nm, n = 40, 42\nx, Dx, Dxx = FNC.diffcheb(m, [-2, 2])\ny, Dy, Dyy = FNC.diffcheb(n, [-2, 2])\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\n\nU0 = mtx(lambda x, y: (x + 0.2) * exp(-12 * (x**2 + y**2)))\nV0 = zeros(U0.shape)\n\nNote that because u is known on the boundary, while v is unknown over the full grid, there are two different sizes of vec/unvec operations. We also need to define functions to pack grid unknowns into a vector and to unpack them. When the unknowns for u are packed, the boundary values are chopped off, and these are restored when unpacking.\n\n_, _, _, vec_v, unvec_v, _ = FNC.tensorgrid(x, y)\n_, _, _, vec_u, unvec_u, _ = FNC.tensorgrid(x[1:-1], y[1:-1])\n\ndef extend(U):\n    UU = zeros((m+1, n+1))\n    UU[1:-1, 1:-1] = U\n    return UU\n\ndef chop(U):\n    return U[1:-1, 1:-1]\n\ndef pack(U, V): \n    return hstack([vec_u(chop(U)), vec_v(V)])\n\nN = (m-1) * (n-1)\ndef unpack(w):\n    U = extend(unvec_u(w[:N]))\n    V = unvec_v(w[N:])\n    return U, V\n\nWe can now define and solve the IVP. Since this problem is hyperbolic, not parabolic, a nonstiff integrator is faster than a stiff one.\n\ndef dw_dt(t, w):\n    U, V = unpack(w)\n    dU_dt = V\n    dV_dt = Dxx @ U + U @ Dyy.T\n    return pack(dU_dt, dV_dt)\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(dw_dt, (0, 4), pack(U0, V0), method=\"RK45\", dense_output=True)\nU = lambda t: unpack(sol.sol(t))[0]\n\nfig, ax = subplots()\nobj = ax.pcolormesh(X, Y, U(0), vmin=-0.1, vmax=0.1, cmap=\"RdBu\", shading=\"gouraud\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\"),  ax.set_ylabel(\"$y$\")\nax.set_aspect(\"equal\")\nax.set_title(\"Wave equation in 2d\")\n\ndef snapshot(t):\n    global obj\n    obj.remove()\n    obj = ax.pcolormesh(X, Y, U(t), vmin=-0.1, vmax=0.1, cmap=\"RdBu\", shading=\"gouraud\")\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(fig, snapshot, frames=linspace(0, 4, 91))\nanim.save(\"figures/wave-2d.mp4\", fps=30);\nclose()","type":"content","url":"/diffadv#dirichlet-conditions","position":7},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Exercises"},"type":"lvl2","url":"/diffadv#exercises","position":8},{"hierarchy":{"lvl1":"Two-dimensional diffusion and advection","lvl2":"Exercises"},"content":"⌨  For the given u(x,y), make a plot of the given quantity on the square [-2,2]^2 using appropriate differentiation matrices.\n\n(a) u(x,y) = \\exp(x-y^2); plot u_{xx}+u_{yy}\n\n(b) u(x,y) =\\cos (\\pi x)+\\sin (\\pi y); plot u_x+u_y\n\n(c) u(x,y) =\\exp(-x^2-4y^2); plot x u_y\n\n⌨ Following \n\nDemo 13.2.2 as a model, solve the Allen–Cahn equation u_t=u(1-u^2)+0.001(u_{xx}+u_{yy}) on the square [-1,1]^2 with periodic conditions, taking u(x,y,0)=\\sin(\\pi x)\\cos(2\\pi y). Use m=n=60 to solve up to t=4, and make an animation of the result.\n\n⌨ Following \n\nDemo 13.2.3 as a model, solve u_t=y u_x-u_y+0.03(u_{xx}+u_{yy}) on the square [-1,1]^2, with u(x,y,0)=(1-x^2)(1-y^2) and homogeneous Dirichlet boundary conditions. Use m=n=40 to solve up to t=2, and make an animation of the result.\n\n⌨ Following \n\nDemo 13.2.4 as a model, solve u_{tt}=u_{xx}+u_{yy}+\\cos(7t) on the square [-1,1]^2, with u(x,y,0)=x(1-x^6)(1-y^2), u_t(x,y,0)=0, subject to homogeneous Dirichlet boundary conditions. Take m=n=60 to solve between t=0 and t=12, and make an animation of the result.\n\nFrom Maxwell’s equations we can find a way to convert the wave equation to a first-order form that, unlike \n\n(13.2.7), uses only first-order derivatives in space:\\begin{split}\nu_t &= c^2(v_y - w_x),\\\\\nv_t &= u_y, \\\\\nw_t &= -u_x,\n\\end{split}\n\nsubject to u=0 on the boundary.\n\n(a) ✍ Show that a solution of \n\n(13.2.8) satisfies u_t=c^2(u_{xx}+u_{yy}).\n\n(b) ⌨ Solve \n\n(13.2.8) with c=2 in the rectangle x\\in[-3,3], y\\in[-1,1], u(x,y,0) = \\exp(x-x^2)(9-x^2)(1-y^2), and v=w=0 at t=0. Use m=50 for x and n=25 for y, solve for 0\\le t \\le 6, and make an animation of the solution.\n\nYou might wonder why we use linear algebra to define the extension and deletion of boundary values rather than directly accessing row and column indices in the grid function. The linear algebra approach allows DifferentialEquations to compute the Jacobian matrix of the implicit IVP solver quickly using automatic differentiation tools, greatly speeding up the solution process. Since the matrices in our expressions are sparse, multiplications by them do not affect running time perceptibly.","type":"content","url":"/diffadv#exercises","position":9},{"hierarchy":{"lvl1":"Laplace and Poisson equations"},"type":"lvl1","url":"/laplace","position":0},{"hierarchy":{"lvl1":"Laplace and Poisson equations"},"content":"Consider the heat equation u_t=u_{xx}+u_{yy}. After a long time, the distribution of temperature will stop changing. This steady-state solution must satisfy the PDE u_{xx}+u_{yy}=0, which is our third and final canonical PDE.\n\nLaplace and Poisson equations\n\nThe Poisson equation in two dimensions isu_{xx} + u_{yy} = f(x,y).\n\nA common notation for it is \\Delta u = f, where Δ is known as the Laplacian operator.\n\nThe function f is sometimes called a forcing function. If f is identically zero, then \n\n(13.3.1) is the Laplace equation.\n\nThe Laplace/Poisson equation is the archetype of an elliptic PDE. All linear, constant-coefficient PDEs with no higher than second derivatives can be classified as either parabolic, hyperbolic, or elliptic. No time variable appears in \n\n(13.3.1). Although variable names are arbitrary, elliptic PDEs often do represent systems at steady state.\n\nIn order to get a fully specified problem, the Laplace or Poisson equations must be complemented with a boundary condition. Because both x and y are spatial variables, this is our first encounter with a boundary condition that is not imposed simply at a pair of points. We consider only the Dirichlet condition u(x,y)=g(x,y) around the entire boundary.","type":"content","url":"/laplace","position":1},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Sylvester equation"},"type":"lvl2","url":"/laplace#sylvester-equation","position":2},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Sylvester equation"},"content":"With the unknown solution represented by its values \\mathbf{U}=\\mtx(u) on a rectangular grid, and second-derivative finite-difference or spectral differentiation matrices \\mathbf{D}_{xx} and \\mathbf{D}_{yy}, the Poisson equation \n\n(13.3.1) becomes the discrete equation   \\mathbf{D}_{xx}\\mathbf{U} + \\mathbf{U} \\mathbf{D}_{yy}^T = \\mathbf{F},\n\nwhere \\mathbf{F}=\\mtx(f). Equation \n\n(13.3.2), with an unknown matrix \\mathbf{U} multiplied on the left and right in different terms, is known as a Sylvester equation. We will use a new matrix operation to solve it.","type":"content","url":"/laplace#sylvester-equation","position":3},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Kronecker product"},"type":"lvl2","url":"/laplace#kronecker-product","position":4},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Kronecker product"},"content":"Kronecker product\n\nLet \\mathbf{A} be m\\times n and \\mathbf{B} be p\\times q. The Kronecker product \\mathbf{A}\\otimes \\mathbf{B} is the mp\\times nq matrix given by    \\mathbf{A}\\otimes \\mathbf{B} =\n    \\begin{bmatrix}\n    A_{11} \\mathbf{B} & A_{12}\\mathbf{B} & \\cdots & A_{1n}\\mathbf{B} \\\\\n    A_{21} \\mathbf{B} & A_{22}\\mathbf{B} & \\cdots & A_{2n}\\mathbf{B} \\\\\n    \\vdots & \\vdots &  & \\vdots \\\\\n    A_{m1} \\mathbf{B} & A_{m2}\\mathbf{B} & \\cdots & A_{mn}\\mathbf{B}\n    \\end{bmatrix}.\n\nKronecker product\n\nExample 13.3.1\n\nA = [1 2; -2 0]\n\nB = [1 10 100; -5 5 3]\n\nApplying the definition manually, we get\n\nA_kron_B = [\n    A[1, 1]*B A[1, 2]*B;\n    A[2, 1]*B A[2, 2]*B\n    ]\n\nThat result should be the same as the following.\n\nkron(A, B)\n\nExample 13.3.1\n\nA = [1, 2; -2, 0];\nB = [1, 10, 100; -5, 5, 3];\ndisp(\"A:\")\ndisp(A)\ndisp(\"B:\")\ndisp(B)\n\nApplying the definition manually, we get\n\nA_kron_B = [\n    A(1,1)*B  A(1,2)*B;\n    A(2,1)*B  A(2,2)*B\n    ]\n\nBut it makes more sense to use kron.\n\nkron(A, B)\n\nExample 13.3.1\n\nA = array([[1, 2], [-2, 0]])\nB = array([[1, 10, 100], [-5, 5, 3]])\nprint(\"A:\")\nprint(A)\nprint(\"B:\")\nprint(B)\n\nApplying the definition manually, we get\n\nA_kron_B = vstack([ hstack([A[0, 0] * B, A[0, 1] * B]), hstack([A[1, 0] * B, A[1, 1] * B]) ])\nprint(A_kron_B)\n\nBut it makes more sense to use kron from NumPy, or the scipy.sparse version when sparsity is to be preserved.\n\nkron(A, B)\n\nThe Kronecker product obeys several natural-looking identities:\n\nKronecker product identities\n\nGiven matrices for which the non-Kronecker operations make sense, the following hold.\n\n\\mathbf{A}\\otimes (\\mathbf{B} + \\mathbf{C})   = \\mathbf{A}\\otimes \\mathbf{B} + \\mathbf{A}\\otimes \\mathbf{C}\n\n(\\mathbf{A} + \\mathbf{B}) \\otimes \\mathbf{C}   = \\mathbf{A}\\otimes \\mathbf{C} + \\mathbf{B}\\otimes \\mathbf{C}\n\n(\\mathbf{A} \\otimes \\mathbf{B}) \\otimes \\mathbf{C}   =  \\mathbf{A} \\otimes (\\mathbf{B} \\otimes \\mathbf{C})\n\n(\\mathbf{A} \\otimes \\mathbf{B})^T  =  \\mathbf{A}^T \\otimes \\mathbf{B}^T\n\n(\\mathbf{A} \\otimes \\mathbf{B})^{-1}  =  \\mathbf{A}^{-1} \\otimes \\mathbf{B}^{-1}\n\n(\\mathbf{A} \\otimes \\mathbf{B})(\\mathbf{C}\\otimes \\mathbf{D})  =  (\\mathbf{A}\\mathbf{C}) \\otimes (\\mathbf{B}\\mathbf{D})\n\nFor the vec operation defined in \n\nDefinition 13.2.1 and matrices of compatible sizes,\\operatorname{vec}(\\mathbf{A}\\mathbf{B}\\mathbf{C}^T) = ({\\mathbf{C}}\\otimes {\\mathbf{A}})\\operatorname{vec}(\\mathbf{B}).\n\n(Partial proof.) These all boil down to algebraic manipulations. For instance, for item 5, let \\mathbf{Z}=\\mathbf{A}^{-1}. Then\\begin{align*}\n\\bigl(\\mathbf{A} \\otimes \\mathbf{B}\\bigr) \\bigl(\\mathbf{A}^{-1} \\otimes \\mathbf{B}^{-1}\\bigr) &=     \\begin{bmatrix}\n    A_{11} \\mathbf{B} & A_{12}\\mathbf{B} & \\cdots & A_{1n}\\mathbf{B} \\\\\n    A_{21} \\mathbf{B} & A_{22}\\mathbf{B} & \\cdots & A_{2n}\\mathbf{B} \\\\\n    \\vdots & \\vdots &  & \\vdots \\\\\n    A_{n1} \\mathbf{B} & A_{n2}\\mathbf{B} & \\cdots & A_{n n}\\mathbf{B}\n    \\end{bmatrix} \\,     \\begin{bmatrix}\n    Z_{11} \\mathbf{B}^{-1} & Z_{12}\\mathbf{B}^{-1} & \\cdots & Z_{1n}\\mathbf{B}^{-1} \\\\\n    Z_{21} \\mathbf{B}^{-1} & Z_{22}\\mathbf{B}^{-1} & \\cdots & Z_{2n}\\mathbf{B}^{-1} \\\\\n    \\vdots & \\vdots &  & \\vdots \\\\\n    Z_{n1} \\mathbf{B}^{-1} & Z_{n2}\\mathbf{B}^{-1} & \\cdots & Z_{n n}\\mathbf{B}^{-1}\n    \\end{bmatrix}  \\\\[1mm]\n  &= \\begin{bmatrix}\n    (A_{11} Z_{11} + \\cdots +  A_{1n}Z_{n1})\\mathbf{I}_n & \\cdots & (A_{11} Z_{1n} + \\cdots +  A_{1n}Z_{n n})\\mathbf{I}_n \\\\\n    \\vdots &  & \\vdots \\\\\n    (A_{n1} Z_{11} + \\cdots +  A_{n n}Z_{n1})\\mathbf{I}_n & \\cdots & (A_{n1} Z_{1n} + \\cdots +  A_{n n}Z_{n n})\\mathbf{I}_n\n    \\end{bmatrix} \\\\ & = (\\mathbf{A}\\mathbf{Z}) \\otimes \\mathbf{I}_n \\\\ & = \\mathbf{I}_{2n}.\n\\end{align*}","type":"content","url":"/laplace#kronecker-product","position":5},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Poisson as a linear system"},"type":"lvl2","url":"/laplace#poisson-as-a-linear-system","position":6},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Poisson as a linear system"},"content":"We can use \n\n(13.3.4) to express the Sylvester form \n\n(13.3.2) of the discrete Poisson equation as an ordinary linear system. First, we pad \n\n(13.3.2) with identity matrices,\\mathbf{D}_{xx}\\mathbf{U} \\mathbf{I}_{y} + \\mathbf{I}_{x} \\mathbf{U} \\mathbf{D}_{yy}^T = \\mathbf{F},\n\nwhere \\mathbf{I}_{x} and \\mathbf{I}_{y} are the (m+1)\\times (m+1) and (n+1)\\times (n+1) identities, respectively. Upon taking the vec of both sides and applying \n\n(13.3.4), we obtain\\begin{split}\n\\underbrace{\\bigl[ ({\\mathbf{I}_{y}} \\otimes {\\mathbf{D}_{xx}}) + ({\\mathbf{D}_{yy}}\\otimes {\\mathbf{I}_{x}})\\bigr]}_{\\mathbf{A}} \\, \\underbrace{\\operatorname{vec}(\\mathbf{U})}_{\\mathbf{u}} &=\n  \\underbrace{\\operatorname{vec}(\\mathbf{F})}_{\\mathbf{b}}  \\\\[1mm] \\mathbf{A} \\mathbf{u} &= \\mathbf{b}.\n\\end{split}\n\nThis is in the form of a standard linear system in (m+1)(n+1) variables.\n\nBoundary conditions of the PDE must yet be applied to modify \n\n(13.3.7). As has been our practice for one-dimensional boundary-value problems, we replace the collocation equation for the PDE at each boundary point with an equation that assigns that boundary point its prescribed value. The details are a bit harder to express algebraically in the two-dimensional geometry, though, than in the 1D case.\n\nSay that N=(m+1)(n+1) is the number of entries in the unknown \\mathbf{U}, and let B be a subset of \\{1,\\dots,N\\} such that i\\in B if and only if (x_i,y_i) is on the boundary. Then for each i\\in B, we want to replace row i of the system \\mathbf{A}\\mathbf{u}=\\mathbf{b} with the equation%:label: pois2bcrep\n  \\mathbf{e}_i^T \\mathbf{u} = g(x_i,y_i).\n\nHence from \\mathbf{A} we should subtract away its ith row and add \\mathbf{e}_i^T back in. When this is done for all i\\in B, the result is the replacement of the relevant rows of \\mathbf{A} with relevant rows of the identity:  \\tilde{\\mathbf{A}} = \\mathbf{A} - \\mathbf{I}_B\\mathbf{A} +\\mathbf{I}_B,\n\nwhere \\mathbf{I}_B is a matrix with zeros everywhere except for ones at (i,i) for all i\\in B. A similar expression can be derived for the modification of \\mathbf{b}. However, rather than implementing a literal interpretation of \n\n(13.3.9), the changes to \\mathbf{A} and \\mathbf{b} are made more easily through logical indexing. A small example is more illuminating than further description.\n\nPoisson equation as a linear system\n\nExample 13.3.2\n\nWe make a crude discretization for illustrative purposes.\n\nm, n = 6, 5\nx, Dx, Dxx = FNC.diffmat2(m, [0, 3])\ny, Dy, Dyy = FNC.diffmat2(n, [-1, 1])\nmtx, X, Y, unvec, is_boundary = FNC.tensorgrid(x, y)\n\nNext, we evaluate ϕ on the grid to get the forcing vector of the linear system.\n\nϕ = (x, y) -> x^2 - y + 2\nb = vec(mtx(ϕ));\n\nHere are the coefficients for the PDE collocation, before any modifications are made for the boundary conditions. The combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\nusing SparseArrays, Plots\nA = kron(I(n+1), sparse(Dxx)) + kron(sparse(Dyy), I(m+1))\nspy(A;\n    color=:blues,  m=3,\n    title=\"System matrix before boundary conditions\")\n\nThe number of equations is equal to (m+1)(n+1), which is the total number of points on the grid.\n\nN = length(b)\n\nThe combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\n\n\nWe now use the Boolean array that indicates where the boundary points lie in the grid.\n\nspy(sparse(is_boundary);\n    m=3,  color=:darkblue, \n    legend=:none,  title=\"Boundary points\",\n    xaxis=(\"column index\", [0, n+2]), \n    yaxis=(\"row index\", [0, m+2]))\n\nIn order to impose Dirichlet boundary conditions, we replace the boundary rows of the system by rows of the identity.\n\nI_N = I(N)\nidx = vec(is_boundary)\nA[idx, :] .= I_N[idx, :];     # Dirichlet conditions\n\nspy(A;\n    color=:blues,  m=3,\n    title=\"System matrix with boundary conditions\")\n\nFinally, we must replace the rows in the vector \\mathbf{b} by the boundary values being assigned to the boundary points. Here, we let the boundary values be zero everywhere.\n\nb[idx] .= 0;                 # Dirichlet values\n\nNow we can solve for \\mathbf{u} and reinterpret it as the matrix-shaped \\mathbf{U}, the solution on our grid.\n\nu = A \\ b\nU = unvec(u)\n\nExample 13.3.2\n\nWe make a crude discretization for illustrative purposes.\n\nm = 6;  n = 5;\n[x, Dx, Dxx] = diffmat2(m, [0, 3]);\n[y, Dy, Dyy] = diffmat2(n, [-1, 1]);\n[mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y);\n\nNext, we define ϕ and evaluate it on the grid to get the forcing vector of the linear system.\n\nphi = @(x, y) x.^2 - y + 2;\nb = vec(mtx(phi));\n\nHere are the coefficients for the PDE collocation, before any modifications are made for the boundary conditions. The combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\nA = kron(speye(n+1), sparse(Dxx)) + kron(sparse(Dyy), speye(m+1));\nclf,  spy(A)\ntitle(\"System matrix before boundary conditions\")\n\nThe number of equations is equal to (m+1)(n+1), which is the total number of points on the grid.\n\nN = length(b)\n\nWe now use the Boolean array that indicates where the boundary points lie in the grid.\n\nspy(is_boundary)\ntitle(\"Boundary points\")\n\nIn order to impose Dirichlet boundary conditions, we replace the boundary rows of the system by rows of the identity.\n\nTip\n\nChanging rows of a sparse array requires that the operands be in a particular sparse representation called lil. The conversion isn’t done automatically because it can be slow and you are encouraged to avoid it when possible. We’re just trying to keep things conceptually simple here.\n\nI = speye(N);\nidx = vec(is_boundary);\nA(idx, :) = I(idx, :);\n\nspy(A)\ntitle(\"System matrix with boundary conditions\")\n\nFinally, we must replace the rows in the vector \\mathbf{b} by the boundary values being assigned to the boundary points. Here, we let the boundary values be zero everywhere.\n\nb(idx) = 0;\n\nNow we can solve for \\mathbf{u} and reinterpret it as the matrix-shaped \\mathbf{U}, the solution on our grid.\n\nu = A \\ b;\nU = unvec(u)\n\nExample 13.3.2\n\nWe make a crude discretization for illustrative purposes.\n\nm, n = 5, 6\nx, Dx, Dxx = FNC.diffmat2(m, [0, 3])\ny, Dy, Dyy = FNC.diffmat2(n, [-1, 1])\nmtx, X, Y, vec, unvec, is_boundary = FNC.tensorgrid(x, y)\n\nNext, we define ϕ and evaluate it on the grid to get the forcing vector of the linear system.\n\nf = lambda x, y: x**2 - y + 2\nb = vec(mtx(f))\n\nHere are the coefficients for the PDE collocation, before any modifications are made for the boundary conditions. The combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\nimport scipy.sparse as sp\nDxx = sp.lil_matrix(Dxx)\nDyy = sp.lil_matrix(Dyy)\nIx = sp.eye(m+1)\nIy = sp.eye(n+1)\nA = sp.kron(Iy, Dxx) + sp.kron(Dyy, Ix)\n\nspy(A)\ntitle(\"Matrix before imposing BC\");\n\nThe number of equations is equal to (m+1)(n+1), which is the total number of points on the grid.\n\nN = len(b)\n\nWe now use the Boolean array that indicates where the boundary points lie in the grid.\n\nspy(is_boundary)\ntitle(\"Boundary points\");\n\nIn order to impose Dirichlet boundary conditions, we replace the boundary rows of the system by rows of the identity.\n\nTip\n\nChanging rows of a sparse array requires that the operands be in a particular sparse representation called lil. The conversion isn’t done automatically because it can be slow and you are encouraged to avoid it when possible. We’re just trying to keep things conceptually simple here.\n\nI = sp.eye(N, format=\"lil\")\nidx = vec(is_boundary)\nA = A.tolil()\nA[idx, :] = I[idx, :];    # Dirichlet conditions\n\nspy(A)\ntitle(\"Matrix with Dirichlet BC imposed\");\n\nFinally, we must replace the rows in the vector \\mathbf{b} by the boundary values being assigned to the boundary points. Here, we let the boundary values be zero everywhere.\n\nb[idx] = 0\n\nNow we can solve for \\mathbf{u} and reinterpret it as the matrix-shaped \\mathbf{U}, the solution on our grid.\n\nfrom scipy.sparse.linalg import spsolve\nu = spsolve(A.tocsr(), b)\nU = unvec(u)\nwith printoptions(precision=4, suppress=True):\n    print(U)","type":"content","url":"/laplace#poisson-as-a-linear-system","position":7},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Implementation"},"type":"lvl2","url":"/laplace#implementation","position":8},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Implementation"},"content":"Function 13.3.1 is our code to solve the Poisson equation.\n\npoissonfd\n\nSolution of Poisson’s equation by finite differences\n\n\"\"\"\n    poissonfd(f, g, m, xspan, n, yspan)\n\nSolve Poisson's equation on a rectangle by finite differences.\nFunction `f` is the forcing function and function `g` gives the\nDirichlet boundary condition. The rectangle is the tensor product of\nintervals `xspan` and `yspan`,  and the discretization uses `m`+1\nand `n`+1 points in the two coordinates.\n\nReturns vectors defining the grid and a matrix of grid solution values.\n\"\"\"\nfunction poissonfd(f, g, m, xspan, n, yspan)\n    # Discretize the domain.\n    x, Dx, Dxx = FNC.diffmat2(m, xspan)\n    y, Dy, Dyy = FNC.diffmat2(n, yspan)\n    mtx, X, Y, unvec, is_boundary = tensorgrid(x, y)\n    N = (m+1) * (n+1)   # total number of unknowns\n\n    # Form the collocated PDE as a linear system.\n    A = kron(I(n+1), sparse(Dxx)) + kron(sparse(Dyy), I(m+1))\n    b = vec(mtx(f))\n\n    # Apply Dirichlet condition.\n    scale = maximum(abs, A[n+2, :])\n    idx = vec(is_boundary)\n    A[idx, :] = scale * I(N)[idx, :]        # Dirichet assignment\n    b[idx] = scale * g.(X[idx], Y[idx])    # assigned values\n\n    # Solve the linear system and reshape the output.\n    u = A \\ b\n    return x, y, unvec(u)\nend\n\nSolution of Poisson’s equation by finite differences\n\nfunction [X, Y, U] = poissonfd(f,g,m,xspan,n,yspan)\r\n%POISSONFD   Solve Poisson's equation by finite differences.\r\n% Input:\r\n%   f            forcing function (function of x,y)\r\n%   g            boundary condition (function of x,y)\r\n%   m            number of grid points in x (integer)\r\n%   xspan        endpoints of the domain of x (2-vector)\r\n%   n            number of grid points in y (integer)\r\n%   yspan        endpoints of the domain of y (2-vector)\r\n%\r\n% Output:\r\n%   U            solution (m+1 by n+1)\r\n%   X,Y          grid matrices (m+1 by n+1)\r\n\r\n% Discretize the domain.\r\n[x, Dx, Dxx] = diffmat2(m, xspan);\r\n[y, Dy, Dyy] = diffmat2(n, yspan);\r\n[mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y);\r\n\r\n% Form the collocated PDE as a linear system. \r\nIx = speye(m+1);  Iy = speye(n+1);\r\nA = kron(Iy, sparse(Dxx)) + kron(sparse(Dyy), Ix);  % Laplacian matrix\r\nb = vec(mtx(f));\r\n\r\n% Replace collocation equations on the boundary.\r\nscale = max(abs(A(n+2, :)));\r\nI = speye(size(A));\r\nidx = vec(is_boundary);\r\nA(idx, :) = scale * I(idx, :);           % Dirichet assignment\r\nb(idx) = scale * g( X(idx),Y(idx) );     % assigned values\r\n\r\n% Solve the linear sytem and reshape the output.\r\nu = A \\ b;\r\nU = unvec(u);\n\nSolution of Poisson’s equation by finite differences\n\ndef poissonfd(f, g, m, xspan, n, yspan):\n    \"\"\"\n    poissonfd(f, g, m, xspan, n, yspan)\n\n    Solve Poisson's equation on a rectangle by finite differences. Function f is the\n    forcing function and function g gives the  Dirichlet boundary condition. The rectangle\n    is the tensor product of intervals xspan and yspan,  and the discretization uses\n    m+1 and n+1 points in the two coordinates.\n\n    Return matrices of the solution values, and the coordinate functions, on the grid.\n    \"\"\"\n    # Discretize the domain.\n    x, Dx, Dxx = diffmat2(m, xspan)\n    y, Dy, Dyy = diffmat2(n, yspan)\n    mtx, X, Y, vec, unvec, is_boundary = tensorgrid(x, y)\n    N = (m+1) * (n+1)    # total number of unknowns\n\n    # Form the collocated PDE as a linear system.\n    Dxx = sp.lil_matrix(Dxx)\n    Dyy = sp.lil_matrix(Dyy)\n    A = sp.kron(sp.eye(n+1, format=\"lil\"), Dxx) + sp.kron(Dyy, sp.eye(m+1, format=\"lil\"))\n    b = vec(mtx(f))\n\n    # Apply Dirichlet condition.\n    idx = vec(is_boundary)\n    scale = np.max(abs(A[n+1, :]))\n    I = sp.eye(N, format=\"lil\")\n    A[idx, :] = scale * I[idx, :]         # Dirichet assignment\n    X_bd, Y_bd = vec(X)[idx], vec(Y)[idx]\n    b[idx] = scale * g(X_bd, Y_bd)    # assigned values\n\n    # Solve the linear sytem and reshape the output.\n    u = scipy.sparse.linalg.spsolve(A.tocsr(), b)\n    U = unvec(u)\n    return U, X, Y\n\nWe use \n\nDemo 13.3.2 as a template: create the linear system, modify it for the boundary conditions, solve it using backslash, and reshape to get a grid function. The matrix is N=(m+1)(n+1) on each side and very sparse, so we take care to use sparse matrices in the code to exploit that structure. There is a small but important change from \n\nDemo 13.3.2: the boundary conditions are rescaled to read \\sigma u(x,y)=\\sigma g(x,y), where σ is the largest element of a row of \\mathbf{A}. This tweak improves the condition number of the final matrix.\n\nPoisson equation in 2D\n\nWe can engineer an example by choosing the solution first. Let u(x,y)=\\sin(3xy-4y). Then one can derive f=\\Delta u = -\\sin(3xy-4y)\\bigl(9y^2+(3x-4)^2\\bigr) for the forcing function and use g=u on the boundary.\n\nExample 13.3.3\n\nFirst we define the problem on [0,1]\\times[0,2].\n\nf = (x, y) -> -sin(3x * y - 4y) * (9y^2 + (3x - 4)^2);\ng = (x, y) -> sin(3x * y - 4y);\nxspan = [0, 1];\nyspan = [0, 2];\n\nHere is the finite-difference solution.\n\nx, y, U = FNC.poissonfd(f, g, 40, xspan, 60, yspan);\n\nsurface(x, y, U';\n    color=:viridis,\n    title=\"Solution of Poisson's equation\",\n    xaxis=(L\"x\"),  yaxis=(L\"y\"),  zaxis=(L\"u(x,y)\"),\n    right_margin=3Plots.mm,  camera=(70, 50))\n\nThe error is a smooth function of x and y. It must be zero on the boundary; otherwise, we have implemented boundary conditions incorrectly.\n\nerror = [g(x, y) for x in x, y in y] - U;\nM = maximum(abs, error)\ncontour(x, y, error';\n    levels=17, \n    clims=(-M, M), color=:redsblues, \n    colorbar=:bottom,  aspect_ratio=1,\n    title=\"Error\", \n    xaxis=(L\"x\"),  yaxis=(L\"y\"),\n    right_margin=7Plots.mm)\nplot!([0, 1, 1, 0, 0], [0, 0, 2, 2, 0], l=(2, :black))\n\nExample 13.3.3\n\nFirst we define the problem on [0,1]\\times[0,2].\n\nf = @(x, y) -sin(3*x .* y - 4*y) .* (9*y.^2 + (3*x - 4).^2);\ng = @(x, y) sin(3*x .* y - 4*y);\nxspan = [0, 1];\nyspan = [0, 2];\n\nHere is the finite-difference solution.\n\n[X, Y, U] = poissonfd(f, g, 40, xspan, 60, yspan);\n\nclf, surf(X', Y', U')\ncolormap(parula),  shading interp\ncolorbar\ntitle(\"Solution of Poisson's equation\")\nxlabel(\"x\"),  ylabel(\"y\"),  zlabel(\"u(x,y)\")\n\nSince this is an artificial problem with a known solution, we can plot the error, which is a smooth function of x and y. It must be zero on the boundary; otherwise, we have implemented boundary conditions incorrectly.\n\nerr = g(X, Y) - U;\nmx = max(abs(vec(err)));\npcolor(X', Y', err')\ncolormap(redsblues),  shading interp\nclim([-mx, mx]),  colorbar\naxis equal,  xlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Error\")\n\nExample 13.3.3\n\nFirst we define the problem on [0,1]\\times[0,2].\n\nf = lambda x, y: -sin(3 * x * y - 4 * y) * (9 * y**2 + (3 * x - 4) ** 2)\ng = lambda x, y: sin(3 * x * y - 4 * y)\nxspan = [0, 1]\nyspan = [0, 2]\n\nHere is the finite-difference solution.\n\nU, X, Y = FNC.poissonfd(f, g, 50, xspan, 80, yspan)\n\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar(), title(\"Solution of Poisson's equation\");\n\nSince this is an artificial problem with a known solution, we can plot the error, which is a smooth function of x and y. It must be zero on the boundary; otherwise, we have implemented boundary conditions incorrectly.\n\nerror = g(X, Y) - U    # because we set up g as the exact solution\nM = max(abs(error))\n\npcolormesh(X.T, Y.T, error.T, vmin=-M, vmax=M, cmap=\"RdBu\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar(),  title(\"Error\");","type":"content","url":"/laplace#implementation","position":9},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Accuracy and efficiency"},"type":"lvl2","url":"/laplace#accuracy-and-efficiency","position":10},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Accuracy and efficiency"},"content":"In \n\nFunction 13.3.1 we used second-order finite differences for the discretization. Let’s simplify the discussion by assuming that m=n. The error in the solution can be expected to be O(n^{-2}).\n\nThe matrix \\mathbf{A} has size N=O(n^2). The upper and lower bandwidths of the matrix \\mathbf{A} are both O(n). It can be shown that the matrix is symmetric and negative definite, so sparse Cholesky factorization can be applied to -\\mathbf{A}, taking O(n^2N)=O(n^4) operations.\n\nAs n increases, the truncation error decreases while the operation count increases. The growth in operations is faster than the corresponding decrease in error, making it costly to get high accuracy. Suppose we have fixed running time T at our disposal. Then n=O(T^{1/4}), and the convergence is O(1/\\sqrt{T}). For example, reduction of the error by a factor of 10 requires 100 times the computational effort.\n\nIf we chose a Chebyshev spectral discretization instead, the calculus changes. Provided that the solution is smooth, we expect convergence at a rate K^{-n} for some K>1. However, the system matrix is no longer sparse nor symmetric, and solution by LU factorization takes O(N^3)=O(n^6) flops. Hence as a function of running time T, we expect a convergence rate on the order of K^{-T^{1/6}}. It’s not simple to compare this directly to the finite-difference case. In the long run, the spectral method will be much more efficient, but if the accuracy requirement is undemanding, second-order finite differences may be faster. For the specific case of Poisson’s equation on a rectangle, there are specialized fast solution methods that are beyond the scope of this discussion.","type":"content","url":"/laplace#accuracy-and-efficiency","position":11},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Exercises"},"type":"lvl2","url":"/laplace#exercises","position":12},{"hierarchy":{"lvl1":"Laplace and Poisson equations","lvl2":"Exercises"},"content":"✍ Using general 2\\times 2 matrices, verify identities 4 and 6 in \n\nTheorem 13.3.1.\n\n✍ Prove that the matrix \\mathbf{A} defined in \n\n(13.3.7) is symmetric if \\mathbf{D}_{xx} and \\mathbf{D}_{yy} are symmetric.\n\n⌨  Use \n\nFunction 13.3.1 to solve the following problems on [0,1]\\times[0,1] using m=n=50. In each case, make a plot of the solution and a plot of the error.\n\n(a) u_{xx}+u_{yy} = 2x^2[x^2(x-1)+(10x-6)(y^2-y)], with u=0 on the boundary.\n\nSolution: u(x,y) = x^4(1-x)y(1-y).\n\n(b) u_{xx}+u_{yy} = \\left(16 x^2 + (1-4 y)^2\\right) \\sinh (4 x y-x),  with u=\\sinh(4xy-x) on the boundary.\n\nSolution: u(x,y) = \\sin(4\\pi x)).\n\n(c) u_{xx}+u_{yy} = -(20\\pi^2) \\sin (4\\pi x) \\cos (2\\pi y), with u = \\sin (4\\pi x) \\cos (2\\pi y) on the boundary.\n\nSolution: u(x,y) = \\sin (4\\pi x) \\cos (2\\pi y).\n\n⌨ For each case in Exercise 3, solve the problem using  \n\nFunction 13.3.1 with m=n=20,30,40,\\ldots,120. For each numerical solution compute the maximum absolute error on the grid. On a log-log plot, compare the convergence of the error as a function of n to theoretical second-order accuracy.\n\n⌨ Copy \n\nFunction 13.3.1 to a new function named poischeb, and modify it to use a Chebyshev discretization rather than finite differences. For each item in \n\nExercise 3, solve the problem using poischeb for m=n=10,15,20,\\ldots,40. For each numerical solution compute the maximum absolute error on the grid. Show the convergence of the error as a function of n on a log-linear plot.\n\n⌨ Sometimes boundary conditions are specified using a piecewise definition, with a different formula for each side of the domain. Use \n\nFunction 13.3.1 with m=n=60 to solve the Laplace equation on [0,1]^2 with boundary conditionsu(0,y) = u(1,y) \\equiv 0, \\quad u(x,0) = \\sin(3\\pi x), \\quad u(x,1) = e^{2x}(x-x^2).\n\nMake a surface plot of your numerical solution.","type":"content","url":"/laplace#exercises","position":13},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-12","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"Trefethen \n\nTrefethen (2000) discusses techniques for tensor-product geometry, including eigenvalue problems and problems posed on a disk. Both Iserles \n\nIserles (1996) and Morton and Mayers \n\nMorton & Mayers (2005) discuss finite differences at curved boundaries and present introductions to the finite element method in two dimensions.","type":"content","url":"/next-12","position":1},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs"},"type":"lvl1","url":"/nonlinear-1","position":0},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs"},"content":"Many nonlinear elliptic PDEs include references to the Laplacian operator.\n\nRecall the micromechanical deflector modeled in a disk by \n\n(10.1.3). A fully two-dimensional equivalent is (see \n\nPelesko & Driscoll (2006))\\Delta u - \\frac{\\lambda}{(u+1)^2} = 0.\n\nThis may be posed on any region, with u=0 specified everywhere on the boundary.\n\nMore generally, we want to solve the nonlinear equation\\phi(x,y,u,u_x,u_y,u_{xx},u_{yy}) = 0\n\nin the interior of a rectangle R, subject to the Dirichlet conditionu(x,y) = g(x,y)\n\non the boundary of R.","type":"content","url":"/nonlinear-1","position":1},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs","lvl2":"Implementation"},"type":"lvl2","url":"/nonlinear-1#implementation","position":2},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs","lvl2":"Implementation"},"content":"In order to solve for as few unknowns as possible, we use a Chebyshev discretization of the domain. The core idea is to formulate collocation equations at the grid points based on discrete approximations of \n\n(13.4.2) and \n\n(13.4.3). If the PDE is nonlinear, then these equations are also nonlinear and are to be solved by a quasi-Newton iteration. \n\nFunction 13.4.1 is our implementation.\n\nelliptic\n\nSolution of elliptic PDE by Chebyshev collocation\n\n\"\"\"\n    elliptic(ϕ, g, m, xspan, n, yspan)\n\nSolve the elliptic PDE\n    `ϕ`(x, y, u, u_x, u_xx, u_y, u_yy) = 0\non the rectangle `xspan`x`yspan`, subject to `g`(x,y)=0 on the boundary. Uses\n`m`+1 points in x by `n`+1 points in y in a Chebyshev discretization. Returns\nvectors defining the grid and a matrix of grid solution values.\n\"\"\"\nfunction elliptic(ϕ, g, m, xspan, n, yspan)\n    # Discretize the domain.\n    x, Dx, Dxx = diffcheb(m, xspan)\n    y, Dy, Dyy = diffcheb(n, yspan)\n    mtx, X, Y, unvec, is_boundary = tensorgrid(x, y)\n    N = (m+1) * (n+1)   # total number of unknowns\n\n    # Identify boundary locations and evaluate the boundary condition.\n    idx = vec(is_boundary)\n    gb = g.(X[idx], Y[idx])\n\n    # Evaluate the PDE+BC residual.\n    function residual(u)\n        U = unvec(u)\n        R = ϕ(X, Y, U, Dx * U, Dxx * U, U * Dy', U * Dyy')    # PDE\n        @. R[idx] = u[idx] - gb                               # boundary residual\n        return vec(R)\n    end\n\n    # Solve the equation.\n    u = levenberg(residual, vec(zeros(size(X))))[end]\n    U = unvec(u)\n\n    return function (ξ, η)\n        v = [chebinterp(x, u, ξ) for u in eachcol(U)]\n        return chebinterp(y, v, η)\n    end\nend\n\nAbout the code\n\nThe boundary values are accessed using Boolean indexing. One advantage of this style, though it is not exploited here, is that the complementary points can also be accessed via the Boolean NOT operator !. Note that any indexing array either has to be the same size as the object of the indexing, or a vector with the same number of elements. In this function, for example, X[idx], X[isboundary], and u[idx] would all be valid, but u[isboundary] would not be.\n\nSolution of elliptic PDE by Chebyshev collocation\n\nfunction u = elliptic(phi, g, m, xspan, n, yspan)\n%ELLIPTIC   Solve an elliptic PDE in 2d.\n% Input:\n%   phi          defines phi)(x,y,u,u_x,u_xx,u_y,u_yy) = 0 (function)\n%   g            boundary condition (function)\n%   m, xspan     size and interval of x discretization (integer, 2-vector)\n%   n, yspan     size and interval of y discretization (integer, 2-vector)\n% Output:\n%   U            solution (n+1 by n+1)\n%   X,Y          coordinate matrices (n+1 by n+1)\n\n    % Discretize the domain.\n    [x, Dx, Dxx] = diffcheb(m, xspan);\n    [y, Dy, Dyy] = diffcheb(n, yspan);\n    [mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y);\n\n    % Identify boundary locations and evaluate the boundary condition.\n    idx = vec(is_boundary);\n    gb = g(X(idx), Y(idx));\n\n    % Evaluate the PDE+BC residual.\n    function r = residual(u)\n        U = unvec(u);\n        R = phi(X, Y, U, Dx * U, Dxx * U, U * Dy', U * Dyy');  % PDE\n        R(idx) = u(idx) - gb;                                  % boundary\n        r = vec(R);\n    end\n\n    % Solve the equation.\n    u = levenberg(@residual, vec(zeros(size(X))));\n    U = unvec(u(:, end));\n\n    function u = evaluate(xi, eta)\n        v = zeros(1, n+1);\n        for j = 1:n+1\n            v(j) = chebinterp(x, U(:, j), xi);\n        end\n        u = chebinterp(y, v, eta);\n    end\n\n    u = @evaluate;\nend\n\nfunction f = chebinterp(x, v, xi)\n    n = length(x) - 1;\n    w = (-1.0) .^ (0:n)';\n    w([1, n+1]) = w([1, n+1]) / 2;\n\n    terms = w ./ (xi - x(:));\n    if any(isinf(terms))     % exactly at a node\n        f = v(xi == x);\n    else\n        f = sum(v(:) .* terms) / sum(terms);\n    end\nend\n\n\nSolution of elliptic PDE by Chebyshev collocation\n\ndef elliptic(f, g, m, xspan, n, yspan):\n    \"\"\"\n    newtonpde(f, g, m, xspan, n, yspan)\n\n    Newton's method with finite differences to solve the PDE f(u,x,y,disc)=0 on the\n    rectangle xspan \\times yspan, subject to g(x,y)=0 on the boundary. Use m+1\n    points in x by n+1 points in y.\n\n    Return matrices of the solution values, and the coordinate functions, on the grid.\n    \"\"\"\n    from scipy.sparse.linalg import spsolve\n    x, Dx, Dxx = diffcheb(m, xspan)\n    y, Dy, Dyy = diffcheb(n, yspan)\n    mtx, X, Y, vec, unvec, is_boundary = tensorgrid(x, y)\n\n    # Evaluate the boundary condition at the boundary nodes.\n    idx = vec(is_boundary)\n    X_bd, Y_bd = vec(X)[idx], vec(Y)[idx]\n    g_bd = g(X_bd, Y_bd)\n\n    # Evaluate the PDE+BC residual.\n    def residual(u):\n        U = unvec(u)\n        R = f(X, Y, U, Dx @ U, Dxx @ U, U @ Dy.T, U @ Dyy.T)    # PDE\n        r = vec(R)\n        r[idx] = u[idx] - g_bd                                  # BC\n        return r\n    \n    # Solve the equation.\n    u = levenberg(residual, vec(np.zeros(X.shape)))[-1]\n    U = unvec(u)\n\n    def evaluate(xi, eta):\n        v = [chebinterp(y, u, eta) for u in U]\n        return chebinterp(x, v, xi)\n    \n    return np.vectorize(evaluate)\n\nFunction 13.4.1 first defines the discretization and then computes all the values of g at the boundary nodes. It uses \n\nFunction 4.6.3 as the nonlinear solver, and it translates back and forth between vector and grid shapes for the unknowns. After the discrete PDE is collocated at the grid points, the boundary terms are replaced by the boundary residual.\n\nLines 38–41, which produce the value returned by \n\nFunction 13.4.1, provide a function that evaluates the numerical solution anywhere in the domain, as is explained next.","type":"content","url":"/nonlinear-1#implementation","position":3},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs","lvl2":"Off-grid evaluation"},"type":"lvl2","url":"/nonlinear-1#off-grid-evaluation","position":4},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs","lvl2":"Off-grid evaluation"},"content":"A Chebyshev grid is clustered close to the boundary of the domain, and the grid values may be accurate even for modest grid sizes. As a result, simple piecewise interpolation to evaluate off the grid, as is done by plotting routines, may be unacceptably inaccurate. Instead, we should use the global polynomial interpolation that is foundational to the Chebyshev spectral method.\n\nLet \\mathbf{U} be a matrix of solution values on the Chebyshev grid, defining a function u(x,y), and let (\\xi,\\eta) be a point where we want to evaluate u(x,y). Column \\mathbf{u}_j of the grid matrix represents values spanning all the x_i while y is fixed at y_j. Therefore, we can define an interpolating polynomial p_j(x) based on the values in \\mathbf{u}_j.\n\nNow let v_j = p_j(\\xi) for j=1,\\ldots,n. The vector \\mathbf{v} is a discretization of u(\\xi,y) at the Chebyshev nodes in y. It defines an interpolating polynomial q(y), and finally we have u(\\xi,\\eta)=q(\\eta). You can think of the total process as reducing one dimension at a time through the action of evaluating a polynomial interpolant at a point.\n\nThe function returned by \n\nFunction 13.4.1 performs interpolation as described above, using a helper function chebinterp (not shown). The helper performs the evaluation of a polynomial interpolant in one variable using a modified implementation of \n\nFunction 9.2.1 that exploits the barycentric weights for Chebyshev nodes given in \n\n(9.3.3).\n\nMEMS model in 2D\n\nWe solve the PDE\\Delta u - \\frac{\\lambda}{(u+1)^2} = 0\n\non the rectangle [0,2.5] \\times [0,1], with a zero Dirichlet condition on the boundary.\n\nExample 13.4.2\n\nAll we need to define are ϕ from \n\n(13.4.2) for the PDE, and a trivial zero function for the boundary condition.\n\nλ = 1.5\nϕ = (X, Y, U, Ux, Uxx, Uy, Uyy) -> @. Uxx + Uyy - λ / (U + 1)^2;\ng = (x, y) -> 0;\n\nHere is the solution for m=15, n=8.\n\nu = FNC.elliptic(ϕ, g, 15, [0, 2.5], 8, [0, 1]);\n\nusing Plots\nx = range(0, 2.5, 100)\ny = range(0, 1, 50)\nU = [u(x, y) for x in x, y in y]\ncontourf(x, y, U';\n    color=:blues,  l=0,\n    aspect_ratio=1,\n    xlabel=L\"x\",  ylabel=L\"y\",  zlabel=L\"u(x,y)\",\n    title=\"Deflection of a MEMS membrane\",\n    right_margin=3Plots.mm)\n\nIn the absence of an exact solution, how can we be confident that the solution is accurate? First, the Levenberg iteration converged without issuing a warning, so we should feel confident that the discrete equations were solved. We can check the boundary values easily. For example,\n\nx_test = range(0, 2.5, 100)\nnorm([u(x, 0) - g(x, 0) for x in x_test], Inf)\n\nAssuming that we encoded the PDE correctly, the remaining source error is truncation from the discretization. We can estimate that by refining the grid a bit and seeing how much the numerical solution changes.\n\nx_test = range(0, 2.5, 6)\ny_test = range(0, 1, 6)\nmtx_test, _ = FNC.tensorgrid(x_test, y_test)\nmtx_test(u)\n\nu = FNC.elliptic(ϕ, g, 25, [0, 2.5], 14, [0, 1]);\nmtx_test(u)\n\nThe original solution seems to be accurate to about four digits.\n\nExample 13.4.2\n\nAll we need to define are ϕ from \n\n(13.4.2) for the PDE, and a trivial zero function for the boundary condition.\n\nlambda = 1.5;\nphi = @(X, Y, U, Ux, Uxx, Uy, Uyy) Uxx + Uyy - lambda ./ (U + 1).^2;\ng = @(x, y) zeros(size(x));\n\nHere is the solution for m=15, n=8.\n\nu = elliptic(phi, g, 15, [0, 2.5], 8, [0, 1]);\ndisp(sprintf(\"solution at (2, 0.6) is %.7f\", u(2, 0.6)))\n\nx = linspace(0, 2.5, 91);\ny = linspace(0, 1, 51);\n[mtx, X, Y] = tensorgrid(x, y);\nclf,  pcolor(x, y, mtx(u)')\ncolormap(flipud(sky)),  shading interp,  colorbar\naxis equal\nxlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Deflection of a MEMS membrane\")\n\nIn the absence of an exact solution, how can we be confident that the solution is accurate? First, the Levenberg iteration converged without issuing a warning, so we should feel confident that the discrete equations were solved. Assuming that we encoded the PDE correctly, the remaining source of error is truncation from the discretization. We can estimate that by refining the grid a bit and seeing how much the numerical solution changes.\n\nx_test = linspace(0, 2.5, 6);\ny_test = linspace(0, 1 , 5);\nmtx_test = tensorgrid(x_test, y_test);\nformat long\nmtx_test(u)\n\nu = elliptic(phi, g, 25, [0, 2.5], 14, [0, 1]);\nmtx_test(u)\n\nThe original solution seems to be accurate to about four digits.\n\nExample 13.4.2\n\nAll we need to define are ϕ from \n\n(13.4.2) for the PDE, and a trivial zero function for the boundary condition.\n\nlamb = 1.5\nphi = lambda x, y, u, ux, uxx, uy, uyy: uxx + uyy - lamb / (u + 1)**2\ng = lambda x, y: 0\n\nHere is the solution for m=15, n=8.\n\nu = FNC.elliptic(phi, g, 15, [0, 2.5], 8, [0, 1])\n\nprint(f\"solution at (2, 0.6) is {u(2, 0.6):.7f}\")\n\nx = linspace(0, 2.5, 90)\ny = linspace(0, 1, 60)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nU = mtx(u)\n\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar()\ntitle(\"Solution of the MEMS equation in 2d\");\n\nIn the absence of an exact solution, how can we be confident that the solution is accurate? First, the Levenberg iteration converged without issuing a warning, so we should feel confident that the discrete equations were solved. We can check the boundary values easily. For example,\n\nerr = norm(u(x, 0) - g(x, 0), inf)\nprint(f\"max error on bottom edge: {err:.2e}\")\n\nAssuming that we encoded the PDE correctly, the remaining source error is truncation from the discretization. We can estimate that by refining the grid a bit and seeing how much the numerical solution changes.\n\nx_test = linspace(0, 2.5, 6)\ny_test = linspace(0, 1, 6)\nmtx_test, X_test, Y_test, _, _, _ = FNC.tensorgrid(x_test, y_test)\n\nwith printoptions(precision=7, suppress=True):\n    print(mtx_test(u))\n\nu = FNC.elliptic(phi, g, 25, [0, 2.5], 14, [0, 1])\nwith printoptions(precision=7, suppress=True):\n    print(mtx_test(u))\n\nThe original solution seems to be accurate to about four digits.\n\nSteady advection-diffusion in 2D\n\nThe steady-state limit of an advection-diffusion equation is1 - u_x - 2u_y + \\epsilon \\, \\Delta u = 0.\n\nHere we solve it with a homogeneous Dirichlet condition on the square [-1,1]^2.\n\nExample 13.4.3\n\nϕ = (X, Y, U, Ux, Uxx, Uy, Uyy) -> @. 1 - Ux - 2Uy + 0.05 * (Uxx + Uyy)\ng = (x, y) -> 0\nu = FNC.elliptic(ϕ, g, 32, [-1, 1], 32, [-1, 1]);\n\nx = y = range(-1, 1, 80)\nU = [u(x, y) for x in x, y in y]\ncontourf(x, y, U';\n    color=:viridis, \n    aspect_ratio=1,\n    xlabel=L\"x\",  ylabel=L\"y\",  zlabel=L\"u(x,y)\",\n    title=\"Steady advection–diffusion\")\n\nExample 13.4.3\n\nphi = @(X, Y, U, Ux, Uxx, Uy, Uyy) 1 - Ux - 2*Uy + 0.05*(Uxx + Uyy);\ng = @(x, y) zeros(size(x));\nu = elliptic(phi, g, 32, [-1, 1], 32, [-1, 1]);\n\nx = linspace(-1, 1, 80);\ny = x;\nmtx = tensorgrid(x, y);\nclf,  pcolor(x, y, mtx(u)')\ncolormap(parula),  shading interp,  colorbar\naxis equal,  xlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Steady advection–diffusion\")\n\nExample 13.4.3\n\nphi = lambda x, y, u, ux, uxx, uy, uyy: 1 - ux - 2*uy + 0.05 * (uxx + uyy)\ng = lambda x, y: 0\nu = FNC.elliptic(phi, g, 32, [-1, 1], 32, [-1, 1])\n\nx = y = linspace(-1, 1, 70)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nU = mtx(u)\n\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar()\ntitle(\"Steady advection–diffusion\");\n\nSteady Allen–Cahn in 2D\n\nThe stationary Allen–Cahn equation in two dimensions isu(1-u^2)+\\epsilon \\, \\Delta u = 0.\n\nExample 13.4.4\n\nThe following defines the PDE and a nontrivial Dirichlet boundary condition for the square [0,1]^2.\n\nϕ = (X, Y, U, Ux, Uxx, Uy, Uyy) -> @. U * (1 - U^2) + 0.05 * (Uxx + Uyy)\ng = (x, y) -> tanh(5 * (x + 2y - 1));\n\nWe solve the PDE and then plot the result.\n\nu = FNC.elliptic(ϕ, g, 36, [0, 1], 36, [0, 1]);\n\nx = y = range(0, 1, 80)\nU = [u(x, y) for x in x, y in y]\ncontourf(x, y, U';\n    color=:viridis, \n    aspect_ratio=1,\n    xlabel=L\"x\",  ylabel=L\"y\",  zlabel=L\"u(x,y)\", \n    title=\"Steady Allen-Cahn\",\n    right_margin=3Plots.mm)\n\nExample 13.4.4\n\nThe following defines the PDE and a nontrivial Dirichlet boundary condition for the square [0,1]^2.\n\nphi = @(X, Y, U, Ux, Uxx, Uy, Uyy) U .* (1-U.^2) + 0.05*(Uxx + Uyy);\ng = @(x, y) tanh(5*(x + 2*y - 1));\n\nWe solve the PDE and then plot the result.\n\nu = elliptic(phi, g, 36, [0, 1], 36, [0, 1]);\n\nx = linspace(0, 1, 80);\ny = x;\nmtx = tensorgrid(x, y);\nclf,  pcolor(x, y, mtx(u)')\ncolormap(parula),  shading interp,  colorbar\naxis equal,  xlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Steady Allen–Cahn\")\n\nExample 13.4.4\n\nThe following defines the PDE and a nontrivial Dirichlet boundary condition for the square [0,1]^2.\n\nphi = lambda x, y, u, ux, uxx, uy, uyy: u * (1 - u**2) + 0.05 * (uxx + uyy)\ng = lambda x, y: tanh(5 * (x + 2*y - 1))\n\nWe solve the PDE and then plot the result.\n\nu = FNC.elliptic(phi, g, 36, [0, 1], 36, [0, 1])\n\nx = y = linspace(0, 1, 70)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nU = mtx(u)\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar(),  title(\"Steady Allen–Cahn equation\");","type":"content","url":"/nonlinear-1#off-grid-evaluation","position":5},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs","lvl2":"Exercises"},"type":"lvl2","url":"/nonlinear-1#exercises","position":6},{"hierarchy":{"lvl1":"Nonlinear elliptic PDEs","lvl2":"Exercises"},"content":"⌨ (a) Solve for the steady state ofu_t = - u_y - x - 2 + \\epsilon ( u_{xx} + u_{yy} )\n\nfor \\epsilon=1 in [-1,1]\\times[-1,1], subject to a homogeneous Dirichlet boundary condition. Use m=n=30 points and plot the solution.\n\n(b) Repeat part (a) for \\epsilon=0.1, which weakens the influence of diffusion relative to advection.\n\n⌨ A soap film stretched on a wire frame above the (x,y) plane assumes a shape u(x,y) of minimum area and is governed by\\begin{align*}\n      \\operatorname{div} \\, \\left( \\frac{\\operatorname{grad} u}{\\sqrt{1 + u_x^2 + u_y^2}} \\right) &= 0 \\text{ in region $R$},\\\\\n      u(x,y) &= g(x,y) \\text{ on the boundary of $R$}.\n    \\end{align*}\n\nSolve the equation on [-1,1]^2 with boundary value u(x,y)=\\tanh(y-2x), and make a surface plot of the result. (Hints: Don’t try to rewrite the PDE. Instead, modify \n\nFunction 13.4.1 so that ϕ is called with arguments (U,Dx,Dy), and compute the PDE in the form given. Also, since convergence is difficult in this problem, use the boundary data over the whole domain as the initial value for levenberg.)\n\nModify \n\nFunction 13.4.1 to solve \n\n(13.4.2) on [a,b] \\times [c,d] with the mixed boundary conditionsu = 0, \\text{ if } x=a \\text{ or } y = d, \\qquad  \\frac{\\partial u}{\\partial n} = 0, \\text{ if } x=b \\text{ or } y = c,\n\nwhere \\frac{\\partial}{\\partial n} is the derivative in the direction of the outward normal. Either condition can be used at a corner point. (Hint: Define index vectors for each side of the domain.) Apply your solver to the PDE \\Delta u + \\sin(3\\pi x) = 0 on [0,1]^2, and make a contour plot of the solution. Why do the level curves intersect two of the sides only at right angles?\n\nThe interpolation algorithm in \n\nFunction 13.4.1 is inefficient when u is to be evaluated on a finer grid, as for plotting. A more careful version could re-use the same values v_j = p_j(\\xi) for multiple values of η.","type":"content","url":"/nonlinear-1#exercises","position":7},{"hierarchy":{"lvl1":"13. Two-dimensional problems"},"type":"lvl1","url":"/overview-12","position":0},{"hierarchy":{"lvl1":"13. Two-dimensional problems"},"content":"You have taken your first step into a larger world.\n\nObi-Wan Kenobi, Star Wars: A New Hope\n\nWe have graduated from ODEs, usually having either time or space as the independent variable, to PDEs in which both space and time are represented simultaneously. The final innovation in this book is to consider problems with two space dimensions. We will confine ourselves to the simplest possible class of two-dimensional regions, leaving aside the major issue of the geometry of the domain. Even so there are many important and valuable mathematical models within this constraint.\n\nFirst we explore how to add another space dimension to the two classes of PDE encountered so far: the parabolic and hyperbolic equations. Last comes the third major class of PDE: elliptic equations. These problems omit time altogether and therefore are used to represent steady-state phenomena.","type":"content","url":"/overview-12","position":1},{"hierarchy":{"lvl1":"Tensor-product discretizations"},"type":"lvl1","url":"/tensorprod","position":0},{"hierarchy":{"lvl1":"Tensor-product discretizations"},"content":"As you learned when starting double integration in vector calculus, the simplest extension of an interval to two dimensions is a rectangle. We will use a particular notation for rectangles:  [a,b] \\times [c,d] = \\bigl\\{ (x,y)\\in\\mathbb{R}^2 : a\\le x \\le b,\\; c\\le y \\le d \\bigr\\}.\n\nThe × in this notation is called a tensor product, and a rectangle is the fundamental example of a tensor-product domain. The implication of the tensor product is that each variable independently varies over a fixed set. The simplest three-dimensional tensor-product domain is the cuboid [a,b]\\times[c,d]\\times[e,f]. When the interval is the same in each dimension (that is, the region is a square or a cube), we may write [a,b]^2 or [a,b]^3. We will limit our discussion to two dimensions henceforth.\n\nThe discretization of a two-dimensional tensor-product domain is straightforward.\n\nTensor-product grid\n\nGiven discretizations of two intervals,a= x_0< x_1 < \\cdots < x_m = b,  \\qquad c = y_0 < y_1 < \\cdots < y_n = d,\n\nthen a tensor-product grid on [a,b]\\times[c,d] is the set  \\bigl\\{ (x_i,y_j): i=0,\\ldots,m,\\; j=0,\\ldots,n \\bigr\\}.","type":"content","url":"/tensorprod","position":1},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Functions on grids"},"type":"lvl2","url":"/tensorprod#functions-on-grids","position":2},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Functions on grids"},"content":"The double indexing of the grid set \n\n(13.1.3) implies an irresistible connection to matrices. Corresponding to any function  f(x,y) defined on the rectangle is an (m+1)\\times(n+1) matrix \\mathbf{F} defined by collecting the values of f at the points in the grid. This transformation of a function to a matrix is so important that we give it a formal name:\\mathbf{F} = \\mtx(f) = \\Bigl[f(x_i,y_j)\\Bigr]_{\\substack{i=0,\\ldots,m\\\\j=0,\\ldots,n}}.\n\nCaution\n\nThere is potential for confusion because the first dimension of a matrix varies in the vertical direction, while the first coordinate x varies horizontally. In fact, the Julia plotting routines we use expect the transpose of this arrangement, so that x varies along columns and y along rows.\n\nLet the interval [0,2] be divided into m=4 equally sized pieces, and let [1,3] be discretized in n=2 equal pieces. Then the grid in the rectangle [0,2]\\times[1,3] is given by all points (i/2,1+j) for all choices i=0,1,2,3,4 and j=0,1,2. If f(x,y)=\\sin(\\pi xy), then\\mtx(f) =\n    \\begin{bmatrix}\n    \\sin(\\pi\\cdot 0\\cdot 1) & \\sin(\\pi\\cdot0\\cdot 2) & \\sin(\\pi\\cdot0\\cdot 3) \\\\[1mm]\n    \\sin\\left(\\pi\\cdot\\tfrac{1}{2} \\cdot 1 \\right) & \\sin\\left(\\pi\\cdot\\tfrac{1}{2} \\cdot 2 \\right) & \\sin\\left(\\pi\\cdot\\tfrac{1}{2} \\cdot 3 \\right) \\\\[1mm]\n    \\sin\\left(\\pi \\cdot 1 \\cdot 1 \\right) & \\sin\\left(\\pi \\cdot 1 \\cdot 2 \\right) & \\sin\\left(\\pi \\cdot 1 \\cdot 3 \\right) \\\\[1mm]\n    \\sin\\left(\\pi\\cdot \\tfrac{3}{2} \\cdot 1 \\right) & \\sin\\left(\\pi\\cdot\\tfrac{3}{2} \\cdot 2 \\right) & \\sin\\left(\\pi\\cdot\\tfrac{3}{2} \\cdot 3 \\right) \\\\[1mm]\n    \\sin\\left(\\pi \\cdot 2 \\cdot 1 \\right) & \\sin\\left(\\pi \\cdot 2 \\cdot 2 \\right) & \\sin\\left(\\pi \\cdot 2 \\cdot 3 \\right)\n    \\end{bmatrix}\n    = \\begin{bmatrix}\n    0 & 0 & 0 \\\\ 1 & 0 & -1 \\\\ 0 & 0 & 0 \\\\ -1 & 0 & 1 \\\\ 0 & 0 & 0\n    \\end{bmatrix}.\n\nFunctions on 2D grids\n\nExample 13.1.2\n\nHere is the grid from \n\nExample 13.1.1.\n\nm = 4\nx = range(0, 2, m+1)\nn = 2\ny = range(1, 3, n+1);\n\nFor a given f(x,y) we can find \\operatorname{mtx}(f) by using a comprehension syntax.\n\nf = (x, y) -> cos(π * x * y - y)\nF = [f(x, y) for x in x, y in y]\n\nWe can make a nice plot of the function by first choosing a much finer grid. However, the contour and surface plotting functions expect the transpose of mtx(f).\n\nTip\n\nTo emphasize departures from a zero level, use a colormap such as redsblues, and use clims to set balanced color differences.\n\nusing Plots\nm, n = 80, 60\nx = range(0, 2, m+1);\ny = range(1, 3, n+1);\nF = [f(x, y) for x in x, y in y]\ncontour(x, y, F';\n    levels=21,  aspect_ratio=1,\n    color=:redsblues,  clims=(-1, 1),\n    xlabel=\"x\",  ylabel=\"y\" )\n\nExample 13.1.2\n\nHere is the grid from \n\nExample 13.1.1.\n\nm = 4;   \nx = linspace(0, 2, m+1);\nn = 2;   \ny = linspace(1, 3, n+1);\n\nFor a given f(x,y) we can find \\operatorname{mtx}(f) by using a comprehension syntax.\n\n[mtx, X, Y] = tensorgrid(x, y);\nf = @(x, y) cos(pi * x .* y - y);\nF = mtx(f)\n\nWe can make a nice plot of the function by first choosing a much finer grid. However, the contour and surface plotting functions expect the transpose of mtx(f).\n\nTip\n\nTo emphasize departures from a zero level, use a colormap such as redsblues and set the color limits to be symmetric around zero.\n\nWarning\n\nThe contour and surface plotting functions expect the transpose of the outputs of mtx. If you forget to do that, the x and y axes will be swapped.\n\nm = 80;  x = linspace(0, 2, m+1);\nn = 60;  y = linspace(1, 3, n+1);\n[mtx, X, Y] = tensorgrid(x, y);\nF = mtx(f);\n\npcolor(X', Y', F')\nshading interp\ncolormap(redsblues),  colorbar\naxis equal\nxlabel(\"x\"),  ylabel(\"y\")\n\nExample 13.1.2\n\nHere is the grid from \n\nExample 13.1.1.\n\nm = 4\nx = linspace(0, 2, m+1)\nn = 2\ny = linspace(1, 3, n+1)\n\nFor a given f(x,y) we can find \\operatorname{mtx}(f) by using a comprehension syntax.\n\nf = lambda x, y: cos(pi * x * y - y)\nF = array( [ [f(xi, yj) for yj in y] for xi in x ] )\nprint(F)\n\nWe can make a nice plot of the function by first choosing a much finer grid. However, the contour and surface plotting functions expect the transpose of mtx(f).\n\nTip\n\nTo emphasize departures from a zero level, use a colormap such as RdBu and set the color limits to be symmetric around zero.\n\nWarning\n\nThe contour and surface plotting functions expect the transpose of the outputs of mtx. If you forget to do that, the x and y axes will be swapped.\n\nm, n = 80, 70\nx = linspace(0, 2, m+1)\ny = linspace(1, 3, n+1)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nF = mtx(f)\n\npcolormesh(X.T, Y.T, F.T, cmap=\"RdBu\", vmin=-1, vmax=1, shading=\"gouraud\")\naxis(\"equal\"),  colorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\");","type":"content","url":"/tensorprod#functions-on-grids","position":3},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Parameterized surfaces"},"type":"lvl2","url":"/tensorprod#parameterized-surfaces","position":4},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Parameterized surfaces"},"content":"We are not limited to rectangles by tensor products. Many regions and surfaces may be parameterized by means of x(u,v), y(u,v), and z(u,v), where u and v lie in a rectangle. Such “logically rectangular” surfaces include the unit disk,\\left\\{\n\\begin{aligned}\nx &= u \\cos v, \\\\\ny &= u \\sin v,\\\\\n\\end{aligned}\n\\right.\n\\qquad \\qquad\n\\left.\n\\begin{aligned}\n0 & \\le u < 1, \\\\\n0 &\\le v \\le 2\\pi,\n\\end{aligned}\n\\right.\n\nand the unit sphere,\\left\\{\n\\begin{aligned}\nx &= \\cos u \\sin v,\\\\\ny &= \\sin u \\sin v,\\\\\nz &= \\cos v,\n\\end{aligned}\n\\right.\n\\qquad \\qquad\n  \\left.\n\\begin{aligned}\n0 & \\le u < 2\\pi, \\\\\n0 &\\le v \\le \\pi.\n\\end{aligned}\n\\right.\n\nFunctions on parameterized surfaces\n\nExample 13.1.3\n\nFor a function given in polar form, such as f(r,\\theta)=1-r^4, construction of a function over the unit disk is straightforward using a grid in (r,\\theta) space.\n\nr = range(0, 1, 41)\nθ = range(0, 2π, 81)\nF = [1 - r^4 for r in r, θ in θ]\nplot(r, θ, F';\n    legend=:none, \n    color=:viridis,  fill=true,\n    xlabel=\"r\",  ylabel=\"θ\", \n    title=\"A polar function\")\n\nOf course, we are used to seeing such plots over the (x,y) plane, not the (r,\\theta) plane.\n\nIn such functions the values along the line r=0 must be identical, and the values on the line \\theta=0 should be identical to those on \\theta=2\\pi. Otherwise the interpretation of the domain as the unit disk is nonsensical. If the function is defined in terms of x and y, then those can be defined in terms of r and θ using \n\n(13.1.6).\n\nExample 13.1.3\n\nFor a function given in polar form, such as f(r,\\theta)=1-r^4, construction of a function over the unit disk is straightforward using a grid in (r,\\theta) space.\n\nr = linspace(0, 1, 41);\ntheta = linspace(0, 2*pi, 121);\n[mtx, R, Theta] = tensorgrid(r, theta);\nF = mtx(@(r, theta) 1 - r.^4);\nclf,  colormap(parula)\ncontourf(R', Theta', F', 20)\nshading flat\nxlabel(\"r\"),  ylabel(\"\\theta\"), \ntitle(\"A polar function\")\n\nOf course, we are used to seeing such plots over the (x,y) plane, not the (r,\\theta) plane. For this we create matrices for the coordinate functions x and y.\n\nX = R .* cos(Theta);  Y = R .* sin(Theta);\ncontourf(X', Y', F', 20)\naxis equal,  shading interp  \nxlabel('x'),  ylabel('y')\ntitle('Function over the unit disk')\n\nIn such functions the values along the line r=0 must be identical, and the values on the line \\theta=0 should be identical to those on \\theta=2\\pi. Otherwise the interpretation of the domain as the unit disk is nonsensical. If the function is defined in terms of x and y, then those can be defined in terms of r and θ using \n\n(13.1.6).\n\nExample 13.1.3\n\nFor a function given in polar form, such as f(r,\\theta)=1-r^4, construction of a function over the unit disk is straightforward using a grid in (r,\\theta) space.\n\nr = linspace(0, 1, 41)\ntheta = linspace(0, 2*pi, 121)\nmtx, R, Theta, _, _, _ = FNC.tensorgrid(r, theta)\n\nF = mtx(lambda r, theta: 1 - r**4)    \n\ncontourf(R.T, Theta.T, F.T, levels=20)\ncolorbar()\nxlabel(\"$r$\"),  ylabel(\"$\\\\theta$\");\n\nOf course, we are used to seeing such plots over the (x,y) plane, not the (r,\\theta) plane. For this we create matrices for the coordinate functions x and y.\n\nX, Y = R * cos(Theta), R * sin(Theta)\ncontourf(X.T, Y.T, F.T, levels=20)\ncolorbar(),  axis(\"equal\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nIn such functions the values along the line r=0 must be identical, and the values on the line \\theta=0 should be identical to those on \\theta=2\\pi. Otherwise the interpretation of the domain as the unit disk is nonsensical. If the function is defined in terms of x and y, then those can be defined in terms of r and θ using \n\n(13.1.6).","type":"content","url":"/tensorprod#parameterized-surfaces","position":5},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Partial derivatives"},"type":"lvl2","url":"/tensorprod#partial-derivatives","position":6},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Partial derivatives"},"content":"In order to solve boundary-value problems in one dimension by collocation, we replaced an unknown function u(x) by a vector of its values at selected nodes and discretized the derivatives in the equation using differentiation matrices. We use the same ideas in the 2D case: we represent a function by its values on a grid, and multiplication by differentiation matrices to construct discrete analogs of the partial derivatives \\frac{\\partial u}{\\partial x} and \\frac{\\partial u}{\\partial y}.\n\nConsider first \\frac{\\partial u}{\\partial x}. In the definition of this partial derivative, the independent variable y is held constant. Note that y is constant within each column of \\mathbf{U} = \\mtx(u). Thus, we may regard a single column \\mathbf{u}_j as a discretized function of x and, as usual, left-multiply by a differentiation matrix \\mathbf{D}_x such as \n\n(10.3.6). We need to do this for each column of \\mathbf{U} by \\mathbf{D}_x, which is accomplished by \\mathbf{D}_x \\mathbf{U}. Altogether,  \\mtx\\left( \\frac{\\partial u}{\\partial x} \\right) \\approx \\mathbf{D}_x \\, \\mtx(u).\n\nThis relation is not an equality, because the left-hand side is a discretization of the exact partial derivative, while the right-hand side is a\nfinite-difference approximation. Yet it is a natural analog for partial differentiation when we are given not u(x,y) but only the grid value matrix \\mathbf{U}.\n\nNow we tackle \\frac{\\partial u}{\\partial y}. Here the inactive coordinate x is held fixed within each row of \\mathbf{U}. However, if we transpose \\mathbf{U}, then the roles of rows and columns are swapped, and now y varies independently down each column. This is analogous to the situation for the x-derivative, so we left-multiply by a finite-difference matrix \\mathbf{D}_y, and then transpose the entire result to restore the roles of x and y in the grid. Fortunately, linear algebra allows us to express the sequence transpose–left-multiply–transpose more compactly:\\mtx\\left( \\frac{\\partial u}{\\partial y} \\right) \\approx \\Bigl(\\mathbf{D}_y \\mathbf{U}^T\\Bigr)^T = \\mtx(u)\\, \\mathbf{D}_y^T.\n\nKeep in mind that the differentiation matrix \\mathbf{D}_x is based on the discretization x_0,\\ldots,x_m, and as such it must be (m+1)\\times (m+1). On the other hand, \\mathbf{D}_y is based on y_0,\\ldots,y_n and is (n+1)\\times (n+1). This is exactly what is needed dimensionally to make the products in \n\n(13.1.8) and \n\n(13.1.9) consistent. More subtly, if the differentiation is based on equispaced grids in each variable, the value of h in a formula such as \n\n(5.4.8) will be different for \\mathbf{D}_x and \\mathbf{D}_y.\n\nNumerical partial derivatives\n\nExample 13.1.4\n\nWe define a function and, for reference, its two exact partial derivatives.\n\nu = (x, y) -> sin(π * x * y - y);\n∂u_∂x = (x, y) -> π * y * cos(πx * y - y);\n∂u_∂y = (x, y) -> (π * x - 1) * cos(π * x * y - y);\n\nWe use an equispaced grid and second-order finite differences as implemented by diffmat2.\n\nm = 80;\nx, Dx, _ = FNC.diffmat2(m, [0, 2]);\nn = 60;\ny, Dy, _ = FNC.diffmat2(n, [1, 3]);\nmtx = (f, x, y) -> [f(x, y) for x in x, y in y]\nU = mtx(u, x, y)\n∂xU = Dx * U\n∂yU = U * Dy';\n\nNow we compare the exact \\frac{\\partial u}{\\partial y} with its finite-difference approximation.\n\nM = maximum(abs, ∂yU)    # find the range of the result\nplot(layout=(1, 2), \n    aspect_ratio=1,   clims=(-M, M), \n    xlabel=\"x\", ylabel=\"y\")\ncontour!(x, y, mtx(∂u_∂y, x, y)';\n    levels=15,  subplot=1,\n    color=:redsblues,\n    title=\"∂u/∂y\")\ncontour!(x, y, ∂yU';\n    levels=15,  subplot=2,\n    color=:redsblues, \n    title=\"approximation\")\n\nTo the eye there is little difference to be seen, though the results have no more than a few correct digits at these discretization sizes:\n\nexact = mtx(∂u_∂y, x, y)\n# Relative difference in Frobenius norm:\nnorm(exact - ∂yU) / norm(exact)\n\nExample 13.1.4\n\nWe define a function and, for reference, its two exact partial derivatives.\n\nu = @(x, y) sin(pi * x .* y - y);\ndu_dx = @(x, y) pi * y .* cos(pi * x .* y - y);\ndu_dy = @(x, y) (pi * x - 1) .* cos(pi * x .* y - y);\n\nWe will use an equispaced grid and second-order finite differences as implemented by diffmat2. First, we have a look at a plots of the exact partial derivatives.\n\nm = 80;  [x, Dx] = diffmat2(m, [0, 2]);\nn = 60;  [y, Dy] = diffmat2(n, [1, 4]);\n[mtx, X, Y] = tensorgrid(x, y);\nU = mtx(u);\ndU_dX = mtx(du_dx);\ndU_dY = mtx(du_dy);\n\nclf,  subplot(1, 2, 1)\npcolor(X', Y', dU_dX')\naxis equal,  shading interp\ntitle('∂u/∂x')\nsubplot(1, 2, 2)\npcolor(X', Y', dU_dY')\naxis equal,  shading interp\ntitle('∂u/∂y')\n\nNow we compare the exact partial derivatives with their finite-difference approximations. Since these are signed errors, we use a colormap that is symmetric around zero.\n\nerr = dU_dX - Dx * U;\nsubplot(1, 2, 1)\npcolor(X', Y', err')\ncolorbar,  clim([-.4, .4])\naxis equal,  shading interp\ntitle('error in ∂u/∂x')\n\nerr = dU_dY - U * Dy';\nsubplot(1,2,2)\npcolor(X', Y', err')\ncolorbar,  clim([-.1, .1])\naxis equal,  shading interp\ncolormap(redsblues)\ntitle('error in ∂u/∂y')\n\nNot surprisingly, the errors are largest where the derivatives themselves are largest.\n\nExample 13.1.4\n\nWe define a function and, for reference, its two exact partial derivatives.\n\nu = lambda x, y: sin(pi * x * y - y)\ndu_dx = lambda x, y: pi * y * cos(pi * x * y - y)\ndu_dy = lambda x, y: (pi * x - 1) * cos(pi * x * y - y)\n\nWe will use an equispaced grid and second-order finite differences as implemented by diffmat2. First, we have a look at a plots of the exact partial derivatives.\n\nm, n = 80, 60\nx, Dx, Dxx = FNC.diffmat2(m, [0, 2])\ny, Dy, Dyy = FNC.diffmat2(n, [1, 4])\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\n\nU = mtx(u)\ndU_dX = mtx(du_dx)\ndU_dY = mtx(du_dy)\n\nsubplot(1, 2, 1)\ncontourf(X.T, Y.T, dU_dX.T)\ntitle(\"$u$\"),  axis(\"equal\")\nsubplot(1, 2, 2)\ncontourf(X.T, Y.T, dU_dY.T)\ntitle(\"$\\\\partial u/\\\\partial y$\"),  axis(\"equal\");\n\nNow we compare the exact partial derivatives with their finite-difference approximations. Since these are signed errors, we use a colormap that is symmetric around zero.\n\nsubplot(1, 2, 1)\npcolormesh(X, Y, Dx @ U  - dU_dX, shading=\"gouraud\", cmap=\"RdBu\", vmin=-0.4, vmax=0.4)\ncolorbar()\ntitle(\"error in $\\\\partial u/\\\\partial x$\"),  axis(\"equal\")\nsubplot(1, 2, 2)\npcolormesh(X, Y, U @ Dy.T - dU_dY, shading=\"gouraud\", cmap=\"RdBu\", vmin=-0.1, vmax=0.1)\ncolorbar()\ntitle(\"error in $\\\\partial u/\\\\partial y$\"),  axis(\"equal\");\n\nNot surprisingly, the errors are largest where the derivatives themselves are largest.","type":"content","url":"/tensorprod#partial-derivatives","position":7},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Exercises"},"type":"lvl2","url":"/tensorprod#exercises","position":8},{"hierarchy":{"lvl1":"Tensor-product discretizations","lvl2":"Exercises"},"content":"⌨ In each part, make side-by-side surface and contour plots of the given function over the given domain.\n\n(a) f(x,y) = 2y + e^{x-y}, \\quad[0,2]\\times[-1,1]\n\n(b) f(x,y) = \\tanh[5(x+xy-y^3)], \\quad[-2,2]\\times[-1,1]\n\n(c) f(x,y) = \\exp \\bigl[-6(x^2+y^2-1)^2 \\bigr], \\quad[-2,2]\\times[-2,2]\n\n⌨ For each function in \n\nExercise 1, make side-by-side surface plots of f_x and f_y using Chebyshev spectral differentiation.\n\n⌨ For each function in \n\nExercise 1, make a contour plot of the mixed derivative f_{xy} using Chebyshev spectral differentiation.\n\n⌨ In each case, make a plot of the function given in polar or Cartesian coordinates over the unit disk.\n\n(a) f(r,\\theta) = r^2 - 2r\\cos \\theta\n\n(b) f(r,\\theta) = e^{-10r^2}\n\n(c) f(x,y) = xy - 2 \\sin (x)\n\n⌨ Plot f(x,y,z)=x y - x z - y z as a function on the unit sphere.(Use `aspect_ratio=1` in a plot call to get equal aspect ratios for the axes.)\n\n⌨ Plot f(x,y,z)=x y - x z - y z as a function on the cylinder r=1 for -1\\le z \\le 2.(Use `aspect_ratio=1` in a plot call to get equal aspect ratios for the axes.)","type":"content","url":"/tensorprod#exercises","position":9},{"hierarchy":{"lvl1":"Conditioning of linear systems"},"type":"lvl1","url":"/condition-number","position":0},{"hierarchy":{"lvl1":"Conditioning of linear systems"},"content":"We are ready to consider the conditioning of solving the square linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}. In this problem, the data are \\mathbf{A} and \\mathbf{b}, and the solution is \\mathbf{x}. Both data and result are multidimensional, so we will use norms to measure their magnitudes.\n\nThe motivation for the definition of relative condition number in Chapter 1 was to quantify the response of the result to perturbations of the data. For simplicity, we start by allowing perturbations to \\mathbf{b} only while \\mathbf{A} remains fixed.\n\nLet \\mathbf{A}\\mathbf{x}=\\mathbf{b} be perturbed to  \\mathbf{A}(\\mathbf{x}+\\mathbf{h}) = \\mathbf{b}+\\mathbf{d}.\n\nThe condition number should be the relative change in the solution divided by relative change in the data,  \\frac{\\quad\\dfrac{\\| \\mathbf{h} \\| }{\\| \\mathbf{x} \\| }\\quad}{\\dfrac{\\| \\mathbf{d} \\| }{\\| \\mathbf{b} \\|}} \n  = \\frac{\\| \\mathbf{h} \\|\\;\\| \\mathbf{b} \\| }{\\| \\mathbf{d} \\|\\; \\| \\mathbf{x} \\| }.\n\nWe can bound \\| \\mathbf{h} \\| in terms of \\| \\mathbf{d} \\|:\\begin{split}\n  \\mathbf{A}\\mathbf{x} +  \\mathbf{A} \\mathbf{h} &= \\mathbf{b} + \\mathbf{d}, \\\\\n  \\mathbf{A} \\mathbf{h} &= \\mathbf{d},\\\\\n  \\mathbf{h} &= \\mathbf{A}^{-1} \\mathbf{d},\\\\\n  \\| \\mathbf{h} \\| &\\le \\| \\mathbf{A}^{-1}\\| \\,\\| \\mathbf{d} \\|,\n\\end{split}\n\nwhere we have applied \\mathbf{A}\\mathbf{x}=\\mathbf{b} and \n\n(2.7.8).\nSince also \\mathbf{b}=\\mathbf{A}\\mathbf{x} implies \\| \\mathbf{b} \\|\\le\n\\| \\mathbf{A} \\|\\, \\| \\mathbf{x} \\|, we derive   \\frac{\\| \\mathbf{h} \\|\\; \\| \\mathbf{b} \\|}{\\| \\mathbf{d} \\|\\; \\| \\mathbf{x} \\|} \n   \\le \\frac{\\bigl(\\| \\mathbf{A}^{-1} \\|\\, \\| \\mathbf{d} \\|\\bigr)\n    \\bigl(\\| \\mathbf{A} \\|\\,\\| \\mathbf{x} \\|\\bigr)}{\\| \\mathbf{d} \\|\\,\\| \\mathbf{x} \\|} \n    = \\| \\mathbf{A}^{-1}\\| \\, \\| \\mathbf{A} \\|.\n\nIt is possible to show that this bound is tight, in the sense that the inequalities are in fact equalities for some choices of \\mathbf{b} and \\mathbf{d}. This result motivates a new definition.\n\nMatrix condition number\n\nThe matrix condition number of an invertible square matrix \\mathbf{A} is\\kappa(\\mathbf{A}) = \\| \\mathbf{A}^{-1}\\| \\, \\| \\mathbf{A} \\|.\n\nThis value depends on the choice of norm; a subscript on κ such as 1, 2, or ∞ is used if clarification is needed. If \\mathbf{A} is singular, we define \\kappa(\\mathbf{A}) = \\infty.","type":"content","url":"/condition-number","position":1},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Main result"},"type":"lvl2","url":"/condition-number#main-result","position":2},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Main result"},"content":"The matrix condition number \n\n(2.8.5) is equal to the condition number of solving a linear system of equations. Although we derived this fact above only for perturbations of \\mathbf{b}, a similar statement holds when \\mathbf{A} is perturbed.\n\nUsing a traditional Δ notation for the perturbation in a quantity, we can write the following.\n\nConditioning of linear systems\n\nIf \\mathbf{A}(\\mathbf{x} + \\Delta \\mathbf{x}) = \\mathbf{b} + \\Delta \\mathbf{b}, then\\frac{\\| \\Delta \\mathbf{x} \\|}{\\| \\mathbf{x} \\|} \\le \\kappa(\\mathbf{A}) \\frac{\\| \\Delta \\mathbf{b} \\|}{\\| \\mathbf{b} \\|}.\n\nIf (\\mathbf{A}+\\Delta \\mathbf{A}) (\\mathbf{x} + \\Delta \\mathbf{x}) = \\mathbf{b}, then\\frac{\\| \\Delta \\mathbf{x} \\|}{\\| \\mathbf{x} \\|} \\le \\kappa(\\mathbf{A}) \\frac{\\| \\Delta \\mathbf{A} \\|}{\\| \\mathbf{A} \\|},\n\nin the limit \\| \\Delta \\mathbf{A} \\| \\to 0.\n\nNote that for any induced matrix norm,  1 = \\| \\mathbf{I} \\| = \\| \\mathbf{A} \\mathbf{A}^{-1} \\| \\le \\| \\mathbf{A} \\|\\, \\| \\mathbf{A}^{-1} \\| = \\kappa(\\mathbf{A}).\n\nA condition number of 1 is the best we can hope for—in that case, the relative perturbation of the solution has the same size as that of the data.  A condition number of size 10^t indicates that in floating-point arithmetic, roughly t digits are lost (i.e., become incorrect) in computing the solution \\mathbf{x}. And if \\kappa(\\mathbf{A}) > \\epsilon_\\text{mach}^{-1}, then for computational purposes the matrix is effectively singular.\n\nMatrix condition number\n\nExample 2.8.1\n\nJulia has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nTip\n\nType \\kappa followed by Tab to get the Greek letter κ.\n\nA = [ 1 / (i + j) for i in 1:6, j in 1:6 ]\nκ = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = 1:6\nb = A * x\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\n# type \\Delta then Tab to get Δ\nΔA = randn(size(A));  ΔA = 1e-10 * (ΔA / opnorm(ΔA));\nΔb = randn(size(b));  Δb = 1e-10 * normalize(Δb);\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + ΔA) \\ (b + Δb))\nΔx = new_x - x\n\nHere is the relative error in the solution.\n\n@show relative_error = norm(Δx) / norm(x);\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprintln(\"Upper bound due to b: $(κ * norm(Δb) / norm(b))\")\nprintln(\"Upper bound due to A: $(κ * opnorm(ΔA) / opnorm(A))\")\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n@show rounding_bound = κ * eps();\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = [ 1 / (i + j) for i=1:14, j=1:14 ];\nκ = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = κ*eps()\n\nLet’s put that prediction to the test.\n\nx = 1:14\nb = A * x  \nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.\n\nExample 2.8.1\n\nMATLAB has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6 case.\n\nA = hilb(6)\nkappa = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = (1:6)';\nb = A * x;\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\ndA = randn(size(A));  dA = 1e-10 * (dA / norm(dA));\ndb = randn(size(b));  db = 1e-10 * (db / norm(db));\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + dA) \\ (b + db));\ndx = new_x - x;\n\nHere is the relative error in the solution.\n\nrelative_error = norm(dx) / norm(x)\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nupper_bound_b = (kappa * norm(db) / norm(b))\nupper_bound_A = (kappa * norm(dA) / norm(A))\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\nrounding_bound = kappa * eps\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = hilb(14);\nkappa = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = kappa * eps\n\nLet’s put that prediction to the test.\n\nx = (1:14)';  b = A * x;\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.\n\nExample 2.8.1\n\nThe function cond from numpy.linalg is used to computes matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nA = array([ \n    [1/(i + j + 2) for j in range(6)] \n    for i in range(6) \n    ])\nprint(A)\n\nfrom numpy.linalg import cond\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nNext we engineer a linear system problem to which we know the exact answer.\n\nx_exact = 1.0 + arange(6)\nb = A @ x_exact\n\nNow we perturb the data randomly with a vector of norm \n\n10-12.\n\ndA = random.randn(6, 6)\ndA = 1e-12 * (dA / norm(dA, 2))\ndb = random.randn(6)\ndb = 1e-12 * (db / norm(db, 2))\n\nWe solve the perturbed problem using built-in pivoted LU and see how the solution was changed.\n\nx = linalg.solve(A + dA, b + db) \ndx = x - x_exact\n\nHere is the relative error in the solution.\n\nprint(f\"relative error is {norm(dx) / norm(x_exact):.2e}\")\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprint(f\"b_bound: {kappa * 1e-12 / norm(b):.2e}\")\nprint(f\"A_bound: {kappa * 1e-12 / norm(A, 2):.2e}\")\n\nEven if we don’t make any manual perturbations to the data, machine epsilon does when we solve the linear system numerically.\n\nx = linalg.solve(A, b)\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nBecause \\kappa\\approx 10^8, it’s possible to lose 8 digits of accuracy in the process of passing from A and b to x. That’s independent of the algorithm; it’s inevitable once the data are expressed in double precision.\n\nLarger Hilbert matrices are even more poorly conditioned.\n\nA = array([ [1/(i+j+2) for j in range(14)] for i in range(14) ])\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nBefore we compute the solution, note that κ exceeds 1/eps. In principle we therefore might end up with an answer that is completely wrong (i.e., a relative error greater than 100%).\n\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nx_exact = 1.0 + arange(14)\nb = A @ x_exact  \nx = linalg.solve(A, b)\n\nWe got an answer. But in fact, the error does exceed 100%:\n\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")","type":"content","url":"/condition-number#main-result","position":3},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Residual and backward error"},"type":"lvl2","url":"/condition-number#residual-and-backward-error","position":4},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Residual and backward error"},"content":"Suppose that \\mathbf{A}\\mathbf{x}=\\mathbf{b} and \\tilde{\\mathbf{x}} is a computed estimate of the solution \\mathbf{x}. The most natural quantity to study is the error, \\mathbf{x}-\\tilde{\\mathbf{x}}. Normally we can’t compute it because we don’t know the exact solution. However, we can compute something related.\n\nResidual of a linear system\n\nFor the problem \\mathbf{A}\\mathbf{x}=\\mathbf{b}, the residual at a solution estimate \\tilde{\\mathbf{x}} is  \\mathbf{r} = \\mathbf{b} - \\mathbf{A}\\tilde{\\mathbf{x}}.\n\nObviously, a zero residual means that \\tilde{\\mathbf{x}}=\\mathbf{x}, and we have the exact solution. What happens more generally? Note that \\mathbf{A}\\tilde{\\mathbf{x}}=\\mathbf{b}-\\mathbf{r}. That is, \\tilde{\\mathbf{x}} solves the linear system problem for a right-hand side that is changed by -\\mathbf{r}. This is precisely what is meant by backward error.\n\nHence residual and backward error are the same thing for a linear system. What is the connection to the (forward) error? We can reconnect with \n\n(2.8.6) by the definition \\mathbf{h} = \\tilde{\\mathbf{x}}-\\mathbf{x}, in which case\\mathbf{d} = \\mathbf{A}(\\mathbf{x}+\\mathbf{h})-\\mathbf{b}=\\mathbf{A}\\mathbf{h} = -\\mathbf{r}.\n\nThus \n\n(2.8.6) is equivalent to  \\frac{\\| \\mathbf{x}-\\tilde{\\mathbf{x}} \\|}{\\| \\mathbf{x} \\|} \\le\n  \\kappa(\\mathbf{A}) \\frac{\\| \\mathbf{r} \\|}{\\| \\mathbf{b} \\|}.\n\nEquation \n\n(2.8.11) says that the gap between relative error and the relative residual is a multiplication by the matrix condition number.\n\nWhen solving a linear system, all that can be expected is that the backward error, not the error, is small.","type":"content","url":"/condition-number#residual-and-backward-error","position":5},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Exercises"},"type":"lvl2","url":"/condition-number#exercises","position":6},{"hierarchy":{"lvl1":"Conditioning of linear systems","lvl2":"Exercises"},"content":"⌨ Refer to \n\nDemo 2.8.1 for the definition of a Hilbert matrix. Make a table of the values of \\kappa(\\mathbf{H}_n) in the 2-norm for n=2,3,\\ldots,16. Speculate as to why the growth of κ appears to slow down at n=13.\n\n⌨ The purpose of this problem is to verify, like in \n\nDemo 2.8.1, the error bound\\frac{\\| \\mathbf{x}-\\tilde{\\mathbf{x} \\|}}{\\| \\mathbf{x} \\|} \\le \\kappa(\\mathbf{A})\n\\frac{\\| \\mathbf{h} \\|}{\\| \\mathbf{b} \\|}.\n\nHere \\tilde{\\mathbf{x}} is a numerical approximation to the exact solution \\mathbf{x}, and \\mathbf{h} is an unknown perturbation caused by machine roundoff. We will assume that \\| \\mathbf{d} \\|/\\| \\mathbf{b} \\| is roughly eps().\n\nFor each n=10,20,\\ldots,70 let A = matrixdepot(\"prolate\",n,0.4) and let \\mathbf{x} have components x_k=k/n for k=1,\\ldots,n. Define b=A*x and let \\tilde{\\mathbf{x}} be the solution produced numerically by backslash.\n\nMake a table including columns for n, the condition number of \\mathbf{A}, the observed relative error in \\tilde{\\mathbf{x}}, and the right-hand side of the inequality above. You should find that the inequality holds in every case.\n\n⌨ \n\nExercise 2.3.7 suggests that the solutions of linear systems\\mathbf{A} = \\begin{bmatrix} 1 & -1 & 0 & \\alpha-\\beta & \\beta \\\\ 0 & 1 & -1 &\n  0 & 0 \\\\ 0 & 0 & 1 & -1 & 0 \\\\ 0 & 0 & 0 & 1 & -1  \\\\ 0 & 0 & 0 & 0 & 1\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix} \\alpha \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\n\nbecome less accurate as β increases. Using \\alpha=0.1 and \\beta=10,100,\\ldots,10^{12}, make a table with columns for β, |x_1-1|, and the condition number of the matrix.\n\n⌨ Let \\mathbf{A}_n denote the (n+1)\\times(n+1) version of the Vandermonde matrix in Equation \n\n(2.1.3) based on the equally spaced interpolation nodes t_i=i/n for i=0,\\ldots,n. Using the 1-norm, graph \\kappa(\\mathbf{A}_n) as a function of n for n=4,5,6,\\ldots,20, using a log scale on the y-axis. (The graph is nearly a straight line.)\n\n⌨ The matrix \\mathbf{A} in \n\n(2.6.2) has unpivoted LU factors given in \n\n(2.6.3) as a function of parameter ε. For \\epsilon = 10^{-2},10^{-4},\\ldots,10^{-10}, make a table with columns for ε, \\kappa(\\mathbf{A}), \\kappa(\\mathbf{L}), and \\kappa(\\mathbf{U}). (This shows that solution via unpivoted LU factorization is arbitrarily unstable.)\n\n✍  Define \\mathbf{A}_n as the n\\times n matrix \\displaystyle\\begin{bmatrix}\n   1 & -2 & & &\\\\\n   & 1 & -2 & & \\\\\n   & & \\ddots & \\ddots & \\\\\n   & & & 1 & -2 \\\\\n   & & & & 1\n \\end{bmatrix}.\n\n(a) Write out \\mathbf{A}_2^{-1} and \\mathbf{A}_3^{-1}.\n\n(b) Write out \\mathbf{A}_n^{-1} in the general case n>1. (If necessary, look at a few more cases in Julia until you are certain of the pattern.) Make a clear argument why it is correct.\n\n(c) Using the ∞-norm, find \\kappa(\\mathbf{A}_n).\n\n✍ (a) Prove that for n\\times n nonsingular matrices \\mathbf{A} and \\mathbf{B}, \\kappa(\\mathbf{A}\\mathbf{B})\\le \\kappa(\\mathbf{A})\\kappa(\\mathbf{B}).\n\n(b) Show by means of an example that the result of part (a) cannot be an equality in general.\n\n✍  Let \\mathbf{D} be a diagonal n\\times n matrix, not necessarily invertible. Prove that in the 1-norm,\\kappa(\\mathbf{D}) = \\frac{\\max_i |D_{ii}|}{\\min_i |D_{ii}|}.\n\n(Hint: See \n\nExercise 2.7.10.)","type":"content","url":"/condition-number#exercises","position":7},{"hierarchy":{"lvl1":"Efficiency of matrix computations"},"type":"lvl1","url":"/efficiency","position":0},{"hierarchy":{"lvl1":"Efficiency of matrix computations"},"content":"Predicting how long an algorithm will take to solve a particular problem, on a particular computer, as written in a particular way in a particular programming language, is an enormously difficult undertaking. It’s more practical to predict how the required time will scale as a function of the size of the problem. In the case of a linear system of equations, the problem size is n, the number of equations and variables in the system.  Because expressions of computational time are necessarily approximate, it’s customary to suppress all but the term that is dominant as n\\to\\infty. We first need to build some terminology for these expressions.","type":"content","url":"/efficiency","position":1},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Asymptotic analysis"},"type":"lvl2","url":"/efficiency#asymptotic-analysis","position":2},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Asymptotic analysis"},"content":"Asymptotic notation\n\nLet f(n) and g(n) be positive-valued functions. We say f(n)=O(g(n)) (read “f is big-O of g”) as n\\rightarrow \\infty if f(n)/g(n) is bounded above as n\\to\\infty.\n\nWe say f(n)\\sim g(n) (read “f is asymptotic to g”) as n\\rightarrow \\infty if f(n)/g(n)\\rightarrow 1 as n\\rightarrow\\infty.\n\nOne immediate consequence is that f\\sim g implies f=O(g).\n\nConsider the functions f(n) = a_1 n^3 + b_1 n^2 + c_1 n and g(n) = a_2 n^3 in the limit n\\to \\infty.  Then    \\lim_{n \\to \\infty} \\frac{f(n)}{g(n)}\n    = \\lim_{n \\to \\infty} \\frac{a_1 + b_1n^{-1} + c_1n^{-2}}{a_2} =\n    \\frac{a_1}{a_2} .\n\nSince a_1/a_2 is a constant, f(n) = O(g(n)); if a_1=a_2, then f \\sim g.\n\nConsider f(n) = \\sin (1/n), g(n)=1/n and h(n) = 1/n^2. For large n, Taylor’s theorem with remainder implies thatf(n) = \\frac{1}{n} - \\cos(1/\\xi)\\frac{1}{6 n^3},\n\nwhere n<\\xi<\\infty.  But\\lim_{n\\to \\infty} \\frac{f}{g} = \\lim_{n\\to \\infty} 1-\\cos(1/\\xi)\\frac{1}{6 n^2} = 1,\n\nand so f \\sim g.  On the other hand, comparing f and h, we find\\lim_{n\\to \\infty} \\frac{f}{h} = \\lim_{n\\to \\infty}  n-\\cos(1/\\xi)\\frac{1}{6 n} = \\infty,\n\nso we cannot say that f = O(h). A consideration of h/f will show that h = O(f), however.\n\nIt’s conventional to use asymptotic notation that is as specific as possible. For instance, while it is true that n^2+n=O(n^{10}), it’s more informative, and usually expected, to say n^2+n=O(n^2). There are additional notations that enforce this requirement strictly, but we will just stick to the informal understanding.\n\nThere is a memorable way to use asymptotic notation to simplify sums:\\begin{split}\n  \\sum_{k=1}^n k&\\sim \\frac{n^2}{2} = O(n^2), \\text{ as $n\\to\\infty$}, \\\\\n  \\sum_{k=1}^n k^2 &\\sim \\frac{n^3}{3} = O(n^3), \\text{ as $n\\to\\infty$}, \\\\\n  &\\vdots \\\\\n  \\sum_{k=1}^n k^p &\\sim \\frac{n^{p+1}}{p+1} = O(n^{p+1}), \\text{ as $n\\to\\infty$}.\n\\end{split}\n\nThese formulas greatly resemble the definite integral of x^p.\n\n\\begin{align*}\n\\sum_{k=1}^{n-1} 4k^2 + 3 & = 4 \\left( \\sum_{k=1}^{n-1} k^2\\right)  + 3 \\sum_{k=1}^{n-1} 1\\\\ \n&\\sim 4 \\left( \\frac{1}{3} (n-1)^3 \\right) + 3(n-1) \\\\ \n& = \\frac{4}{3} (n^3 - 3n^2 + 3n - 1)  + 3n - 3 \\\\ \n&\\sim \\frac{4}{3} n^3.\n\\end{align*}","type":"content","url":"/efficiency#asymptotic-analysis","position":3},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Flop counting"},"type":"lvl2","url":"/efficiency#flop-counting","position":4},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Flop counting"},"content":"Traditionally, in numerical linear algebra we count floating-point operations, or flops for short. In our interpretation each scalar addition, subtraction, multiplication, division, and square root counts as one flop. Given any algorithm, we simply add up the number of scalar flops and ignore everything else.\n\nFloating-point operations in matrix-vector multiplication\n\nExample 2.5.4\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = randn(n, n)\nx = rand(n)\ny = zeros(n)\nfor i in 1:n\n    for j in 1:n\n        y[i] += A[i, j] * x[j]    # 1 multiply, 1 add\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. Note that Julia is unusual in that loops have a variable scope separate from its enclosing code. Thus, for n in n below means that inside the loop, the name n will take on each one of the values that were previously assigned to the vector n.\n\nTip\n\nThe push! function attaches a new value to the end of a vector.\n\nn = 1000:1000:5000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:80; A * x; end\n    push!(t, time)\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\n@pt :header = [\"size\", \"time (sec.)\"] [n t]\n\nLooking at the timings just for n=2000 and n=4000, they have ratio\n\nTip\n\nThe expression n.==4000 here produces a vector of Boolean (true/false) values the same size as n. This result is used to index within t, accessing only the value for which the comparison is true.\n\n@show t[n.==4000] ./ t[n.==2000];\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nExample 2.5.4\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6;\nA = magic(n);\nx = ones(n,1);\ny = zeros(n,1);\nfor i = 1:n\n    for j = 1:n\n        y(i) = y(i) + A(i,j)*x(j);   % 2 flops\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication, using tic and toc to time the operation.\n\nn = (500:500:5000)';\nt = zeros(size(n));\nfor k = 1:length(n)\n    A = randn(n(k), n(k));  x = randn(n(k), 1);\n    tic    % start a timer\n    for j = 1:200      % repeat 100 times\n        A*x;\n    end\n    time = toc;           % read the timer\n    t(k) = time / 200;   % seconds per instance\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\ntable(n, t, 'variablenames', [\"size\", \"time\"])\n\nLooking at the timings just for n=2500 and n=5000, they have ratio\n\nTip\n\nThe expression n==5000 here produces a vector of Boolean (true/false) values the same size as n. This result is used to index within t, accessing only the value for which the comparison is true.\n\nt(n==5000) / t(n==2500)\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(5000)^2}{2(2500)^2}=4.\n\nExample 2.5.4\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = random.rand(n, n)\nx = ones(n)\ny = zeros(n)\nfor i in range(n):\n    for j in range(n):\n        y[i] += A[i, j] * x[j]   # 2 flops\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. We assume that flops dominate the computation time and thus measure elapsed time.\n\nN = 400 * arange(1, 11)\nt = []\nprint(\"  n           t\")\nfor i, n in enumerate(N):\n    A = random.randn(n, n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(50): A @ x\n    t.append(timer() - start)\n    print(f\"{n:5}   {t[-1]:10.3e}\")\n\nThe reason for doing multiple repetitions at each value of n above is to avoid having times so short that the resolution of the timer is a factor.\n\nLooking at the timings just for n=2000 and n=4000, they have ratio:\n\nprint(t[9] / t[4])\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nSuppose that the running time t of an algorithm obeys a function that is O(n^p). For sufficiently large n, t\\approx Cn^p for a constant C should be a good approximation. Hence  t \\approx Cn^p \\qquad \\Longleftrightarrow \\qquad \\log t \\approx p(\\log n) + \\log C.\n\nSo we expect that a graph of \\log t as a function of \\log n will be a straight line of slope p.\n\nAsymptotics in log-log plots\n\nExample 2.5.5\n\nLet’s repeat the experiment of the previous figure for more, and larger, values of n.\n\nrandn(5,5)*randn(5);  # throwaway to force compilation\n\nn = 400:200:6000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:50; A * x; end\n    push!(t, time)\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nscatter(n, t, label=\"data\", legend=false,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time (sec)\"),\n    title=\"Timing of matrix-vector multiplications\")\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nplot!(n, t[end] * (n/n[end]).^2, l=:dash,\n    label=L\"O(n^2)\", legend=:topleft)\n\nExample 2.5.5\n\nLet’s repeat the previous experiment for more, and larger, values of n.\n\nn = (400:400:6000)';\nt = zeros(size(n));\nfor k = 1:length(n)\n    A = randn(n(k), n(k));  x = randn(n(k), 1);\n    tic    % start a timer\n    for j = 1:100      % repeat ten times\n        A*x;\n    end\n    time = toc;          % read the timer\n    t(k) = time / 100;   % seconds per instance\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nclf    % clear any existing figure\nloglog(n, t, 'o-')\nxlabel('size of matrix')\nylabel('time (sec)')\ntitle('Timing of matrix-vector multiplications')\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nhold on\nloglog(n, 0.5 * t(end) * (n / n(end)).^2, 'k--')\naxis tight\nlegend('data', 'O(n^2)', 'location', 'southeast')\n\nExample 2.5.5\n\nLet’s repeat the experiment of the previous example for more, and larger, values of n.\n\nN = arange(400, 6200, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(20): A@x\n    t[i] = timer() - start\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables, but is formatted more neatly.\n\nfig, ax = subplots()\nax.loglog(N, t, \"-o\", label=\"observed\")\nylabel(\"elapsed time (sec)\");\nxlabel(\"$n$\");\ntitle(\"Timing of matrix-vector multiplications\");\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nax.loglog(N, t[-1] * (N/N[-1])**2, \"--\", label=\"$O(n^2)$\")\nax.legend();  fig","type":"content","url":"/efficiency#flop-counting","position":5},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Solution of linear systems"},"type":"lvl2","url":"/efficiency#solution-of-linear-systems","position":6},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Solution of linear systems"},"content":"Recall the steps of \n\nAlgorithm 2.4.2 for the system \\mathbf{A}\\mathbf{x}=\\mathbf{b}:\n\nFactor \\mathbf{L}\\mathbf{U}=\\mathbf{A} using Gaussian elimination.\n\nSolve \\mathbf{L}\\mathbf{z}=\\mathbf{b} for \\mathbf{z} using forward substitution.\n\nSolve \\mathbf{U}\\mathbf{x}=\\mathbf{z} for \\mathbf{x} using backward substitution.\n\nThe second and third steps are solved by \n\nFunction 2.3.1 and \n\nFunction 2.3.2. Only one line in each of these functions dominates the arithmetic. Take forwardsub, for instance. It has a single flop in line 11.  Line 13 computessum( L[i,j]*x[j] for j in 1:i-1 )\n\nThis line requires i-1 multiplications and (i-2) additions, for a total of 2i-3 flops. Line 14 adds two more flops. These lines are performed within a loop as i ranges from 1 to n, so the total count is  1 + \\sum_{i=1}^n (2i-3) = 1 - 3n + 2 \\sum_{i=1}^n i.\n\nIt is not hard to find an exact formula for the sum, but we use \n\n(2.5.5) to simplify it to \\sim n^2. After all, since flop counting is only an approximation of true running time, why bother with the more complicated exact expression? An analysis of backward substitution yields the same result.\n\nSolving a triangular n\\times n system by forward or backward substitution takes \\sim n^2 flops asymptotically.\n\nBefore counting flops for the LU factorization, we have to admit that \n\nFunction 2.4.1 is not written as economically as it could be. Recall from our motivating example in \n\nDemo 2.4.3 that we zero out the first row and column of \\mathbf{A} with the first outer product, the second row and column with the second outer product, and so on. There is no good reason to do multiplications and additions with values known to be zero, so we could replace lines 15–19 of lufact withfor k in 1:n-1\n    U[k,k:n] = Aₖ[k,k:n]\n    L[k:n,k] = Aₖ[k:n,k]/U[k,k]\n    Aₖ[k:n,k:n] -= L[k:n,k]*U[k,k:n]'\nend\n\nWe will use the following handy fact.\n\nThe range k:n, where k\\le n, has n-k+1 elements.\n\nLine 17 above divides each element of the vector Aₖ[k:n,k] by a scalar. Hence the number of flops equals the length of the vector, which is n-k+1.\n\nLine 18 has an outer product followed by a matrix subtraction. The definition \n\n(A.5) of the outer product makes it clear that that computation takes one flop (multiplication) per element of the result, which here results in (n-k+1)^2 flops. The number of subtractions is identical.\n\nAltogether the factorization takes\\sum_{k=1}^{n-1} n-k + 1 + 2(n-k+1)^2.\n\nThere are different ways to simplify this expression. We will make a change of summation index using j=n-k. The endpoints of the sum are j=n-1 when k=1 and j=1 when k=n-1. Since the order of terms in a sum doesn’t matter, we get\\begin{align*}\n\\sum_{j=1}^{n-1} 1+j+2(j+1)^2 &=  \\sum_{j=1}^{n-1} 3 + 5j + 2j^2 \\\\\n  & \\sim  3(n-1) + \\frac{5}{2}(n-1)^2 + \\frac{2}{3}(n-1)^3 \\\\\n  & \\sim \\frac{2}{3}n^3.\n\\end{align*}\n\nWe have proved the following.\n\nEfficiency of LU factorization\n\nThe LU factorization of an n\\times n matrix takes \\sim\\frac{2}{3}n^3 flops as n\\to \\infty. This dominates the flops for solving an n\\times n linear system.\n\nFloating-point operations in LU factorization\n\nExample 2.5.6\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nTip\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nlu(randn(3, 3));   # throwaway to force compilation\n\nn = 400:400:4000\nt = []\nfor n in n\n    A = randn(n, n)  \n    time = @elapsed for j in 1:12; lu(A); end\n    push!(t, time)\nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nscatter(n, t, label=\"data\", legend=:topleft,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time\"))\nplot!(n, t[end ]* (n/n[end]).^3, l=:dash, label=L\"O(n^3)\")\n\nExample 2.5.6\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nTip\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nn = (200:100:2400)';\nt = zeros(size(n));\nfor k = 1:length(n)\n    A = randn(n(k), n(k));  \n    tic    % start a timer\n    for j = 1:6,  [L, U] = lu(A);  end\n    time = toc;\n    t(k) = time / 6;  \nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nclf\nloglog(n, t, 'o-')\nhold on\nloglog(n, 0.5 * t(end) * (n/n(end)).^3, 'k--')\naxis tight\nxlabel('size of matrix'), ylabel('time (sec)')\ntitle('Timing of LU factorization')\nlegend('lu','O(n^3)','location','southeast');\n\nExample 2.5.6\n\nWe’ll test the conclusion of O(n^3) flops experimentally using the lu function imported from scipi.linalg.\n\nfrom scipy.linalg import lu\nN = arange(200, 2600, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    start = timer()\n    for j in range(5): lu(A)\n    t[i] = timer() - start\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nloglog(N, t, \"-o\", label=\"obseved\")\nloglog(N, t[-1] * (N / N[-1])**3, \"--\", label=\"$O(n^3)$\")\nlegend();\nxlabel(\"$n$\");\nylabel(\"elapsed time (sec)\");\ntitle(\"Timing of LU factorizations\");\n\nIn practice, flops are not the only aspect of an implementation that occupies significant time. Our position is that counting flops as a measure of performance is a useful oversimplification. We will assume that LU factorization (and as a result, the solution of a linear system of n equations) requires a real-world time that is roughly O(n^3). This growth rate is a great deal more tolerable than, say, O(2^n), but it does mean that for (at this writing) n greater than 10,000 or so, something other than general LU factorization will have to be used.","type":"content","url":"/efficiency#solution-of-linear-systems","position":7},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Exercises"},"type":"lvl2","url":"/efficiency#exercises","position":8},{"hierarchy":{"lvl1":"Efficiency of matrix computations","lvl2":"Exercises"},"content":"✍ The following are asymptotic assertions about the limit n\\rightarrow\\infty. In each case, prove the statement true or false.\n\n(a) n^2 = O(\\log n),\\quad\n(b) n^{a} = O(n^b) if a\\le b,\\quad\n(c) e^n \\sim e^{2n},\\quad\n(d) n+\\sqrt{n}\\sim n+2\\sqrt{n}.\n\n✍ The following are asymptotic assertions about the limit h\\to 0. In each case, prove the statement true or false.\n\n(a) h^2\\log(h) = O(h^3),\\quad\n(b) h^{a} = O(h^b) if a < b,\\quad\n(c) \\sin(h) \\sim h,\\quad\n(d) (e^{2h}-1)\\sim h.\n\n✍ Show that the inner product of two n-vectors takes exactly 2n-1 flops.\n\n✍ Show that the multiplication of two n\\times n matrices takes \\sim 2n^3 flops.\n\n✍ This problem is about evaluation of a polynomial c_1 + c_2 x + \\cdots + c_{n}x^{n-1}.\n\n(a) Here is a little code to do the evaluation.y = c[1]\nxpow = 1\nfor i in 2:n\n    xpow *= x\n    y += c[i]*xpow\nend\n\nAssuming that x is a scalar, how many flops does this function take, as a function of n?\n\n(b) Compare the count from (a) to the flop count for Horner’s algorithm, \n\nFunction 1.3.1.\n\nThe exact sums for p=1,2 in \n\n(2.5.5) are as follows:\\sum_{k=1}^{n} k = \\frac{n(n+1)}{2}, \\qquad \n\\sum_{k=1}^{n} k^2 = \\frac{n(n+1)(2n+1)}{6}.\n\n(a) ✍  Use these to find the exact result for \n\n(2.5.9).\n\n(b) ⌨ Plot the ratio of your result from (a) and the asymptotic result 2n^3/3 for all n=10^{1+0.03i}, i=0,\\dots,100, using a log scale for n and a linear scale for the ratio. (The curve should approach 1 asymptotically.)\n\n✍ Show that for any nonnegative constant integer m,\\sum_{k=0}^{n-m} k^p \\sim \\frac{n^{p+1}}{p+1}.\n\n⌨ The UpperTriangular and LowerTriangular matrix types cause specialized algorithms to be invoked by the backslash. DefineA = rand(1000,1000)\nB = tril(A)\nC = LowerTriangular(B)\nb = rand(1000)\n\nUsing @elapsed with the backslash solver, time how long it takes to solve the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b} 100 times; then, do the same for matrices \\mathbf{B} and \\mathbf{C}. Is the timing for \\mathbf{B} closer to \\mathbf{A} or to \\mathbf{C}? (Hint: Remember to make one timing run without recording results, so that compilation time is not counted.)\n\nMore precisely, O(g) and \\sim g are sets of functions, and \\sim g is a subset of O(g). That we write f=O(g) rather than f\\in O(g) is a quirk of convention.","type":"content","url":"/efficiency#exercises","position":9},{"hierarchy":{"lvl1":"Linear systems"},"type":"lvl1","url":"/linear-systems","position":0},{"hierarchy":{"lvl1":"Linear systems"},"content":"We now attend to the central problem of this chapter: Given a square, n\\times n matrix \\mathbf{A} and an n-vector \\mathbf{b}, find an n-vector \\mathbf{x} such that \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Writing out these equations, we obtain\\begin{split}\n  A_{11}x_1 + A_{12}x_2 + \\cdots + A_{1n}x_n &= b_1, \\\\\n  A_{21}x_1 + A_{22}x_2 + \\cdots + A_{2n}x_n &= b_2, \\\\\n  \\vdots  \\\\\n  A_{n1}x_1 + A_{n2}x_2 + \\cdots + A_{nn}x_n &= b_n.\n\\end{split}\n\nIf \\mathbf{A} is invertible, then the mathematical expression of the solution is \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b} because\\begin{split}\n  \\mathbf{A}^{-1}\\mathbf{b} = \\mathbf{A}^{-1} (\\mathbf{A} \\mathbf{x}) = (\\mathbf{A}^{-1}\\mathbf{A}) \\mathbf{x} = \\mathbf{I} \\mathbf{x}\n  = \\mathbf{x}.\n\\end{split}\n\nWhen \\mathbf{A} is singular, then \\mathbf{A}\\mathbf{x}=\\mathbf{b} may have no solution or\ninfinitely many solutions.\n\nIf we define\\mathbf{S} =  \\begin{bmatrix}\n\t0 & 1\\\\0 & 0\n\\end{bmatrix},\n\nthen it is easy to check that for any real value of α we have\\mathbf{S}\n\\begin{bmatrix}\n\t\\alpha \\\\ 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\t1 \\\\ 0\n\\end{bmatrix}.\n\nHence the linear system \\mathbf{S}\\mathbf{x}=\\mathbf{b} with \\mathbf{b}=\\begin{bmatrix} 1\\\\0\\end{bmatrix} has infinitely many solutions. For most other choices of \\mathbf{b}, the system has no solution.","type":"content","url":"/linear-systems","position":1},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Don’t use the inverse"},"type":"lvl2","url":"/linear-systems#dont-use-the-inverse","position":2},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Don’t use the inverse"},"content":"Matrix inverses are indispensable for mathematical discussion and derivations. However, as you may remember from a linear algebra course, they are not trivial to compute from the entries of the original matrix. You might be surprised to learn that matrix inverses play almost no role in scientific computing.\n\nImportant\n\nComputing the inverse of a matrix is not a good way to solve a linear system of equations.\n\nIn fact, when we encounter an expression such as \\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b} in computing, we interpret it as “solve the linear system \\mathbf{A} \\mathbf{x} = \\mathbf{b}” and apply whatever algorithm is most expedient based on what we know about \\mathbf{A}.\n\nAs demonstrated in \n\nDemo 2.1.1, the backslash (the \\ symbol, not to be confused with the slash / used in web addresses) invokes a linear system solution.\n\nIn MATLAB, the backslash operator \\ is used to solve linear systems.\n\nIn Python, the numpy.linalg.solve function is used to solve linear systems.\n\nSolving linear systems\n\nExample 2.3.2\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1, 2, 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A * x\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = [0 1; 0 0]\nb = [1, -1]\nx = A \\ b    # throws an error\n\nIn this case we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nTip\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nExample 2.3.2\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1; 2; 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A*x\n\nIf the matrix \\mathbf{A} is singular, you may get a warning and nonsense result.\n\nA = [0 1; 0 0]\nb = [1; -1]\nx = A \\ b\n\nIn this case, we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nTip\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nExample 2.3.2\n\nFor a square matrix A, the command solve(A, B) from numpy.linalg is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = array([[1, 0, -1], [2, 2, 1], [-1, -3, 0]])\nb = array([1, 2, 3])\n\nx = linalg.solve(A, b)\nprint(x)\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision(relative to the elements in the data).\n\nresidual = b - A @ x\nprint(residual)\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = array([[0, 1], [0, 0]])\nb = array([1, -1])\nlinalg.solve(A, b)    # error, singular matrix\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, a numerical solution becomes trickier. Detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. We’re headed toward a more robust way to fully describe this situation.","type":"content","url":"/linear-systems#dont-use-the-inverse","position":3},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Triangular systems"},"type":"lvl2","url":"/linear-systems#triangular-systems","position":4},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Triangular systems"},"content":"The solution process is especially easy to demonstrate for a system with a triangular matrix. For example, consider the lower triangular system  \\begin{bmatrix}\n    4 & 0 & 0 & 0 \\\\\n    3 & -1 & 0 & 0 \\\\\n    -1 & 0 & 3 & 0 \\\\\n    1 & -1 & -1 & 2\n  \\end{bmatrix} \\mathbf{x} =\n  \\begin{bmatrix}\n    8 \\\\ 5 \\\\ 0 \\\\ 1\n  \\end{bmatrix}.\n\nThe first row of this system states simply that 4x_1=8, which is easily solved as x_1=8/4=2. Now, the second row states that 3x_1-x_2=5. As x_1 is already known, it can be replaced to find that x_2 = -(5-3\\cdot 2)=1. Similarly, the third row gives x_3=(0+1\\cdot 2)/3 = 2/3, and the last row yields x_4=(1-1\\cdot 2 + 1\\cdot 1 + 1\\cdot 2/3)/2 = 1/3. Hence the solution is  \\mathbf{x} =\n  \\begin{bmatrix} 2 \\\\ 1 \\\\ 2/3 \\\\ 1/3\n  \\end{bmatrix}.\n\nThe process just described is called forward substitution. In the 4\\times 4 lower triangular case of \\mathbf{L}\\mathbf{x}=\\mathbf{b} it leads to the formulas\\begin{split}\n  x_1 &= \\frac{b_1}{L_{11}}, \\\\\n  x_2 &= \\frac{b_2 - L_{21}x_1}{L_{22}}, \\\\\n  x_3 &= \\frac{b_3 - L_{31}x_1 - L_{32}x_2}{L_{33}}, \\\\\n  x_4 &= \\frac{b_4 - L_{41}x_1 - L_{42}x_2 - L_{43}x_3}{L_{44}}.\n\\end{split}\n\nFor upper triangular systems \\mathbf{U}\\mathbf{x}=\\mathbf{b} an analogous process of backward substitution begins by solving for the last component x_n=b_n/U_{nn} and working backward. For the 4\\times 4 case we have  \\begin{bmatrix}\n    U_{11} & U_{12} & U_{13} & U_{14} \\\\\n    0 & U_{22} & U_{23} & U_{24} \\\\\n    0 & 0 & U_{33} & U_{34} \\\\\n    0 & 0 & 0 & U_{44}\n  \\end{bmatrix} \\mathbf{x} =\n  \\begin{bmatrix}\n    b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4\n  \\end{bmatrix}.\n\nSolving the system backward, starting with x_4 first and then proceeding in descending order, gives\\begin{split}\n  x_4 &= \\frac{b_4}{U_{44}}, \\\\\n  x_3 &= \\frac{b_3 - U_{34}x_4}{U_{33}}, \\\\\n  x_2 &= \\frac{b_2 - U_{23}x_3 - U_{24}x_4}{U_{22}}, \\\\\n  x_1 &= \\frac{b_1 - U_{12}x_2 - U_{13}x_3 - U_{14}x_4}{U_{11}}.\n\\end{split}\n\nIt should be clear that forward or backward substitution fails if and only if one of the diagonal entries of the system matrix is zero. We have essentially proved the following theorem.\n\nTriangular singularity\n\nA triangular matrix is singular if and only if at least one of its diagonal elements is zero.","type":"content","url":"/linear-systems#triangular-systems","position":5},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Implementation"},"type":"lvl2","url":"/linear-systems#implementation","position":6},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Implementation"},"content":"Consider how to implement the sequential process implied by Equation \n\n(2.3.7). It seems clear that we want to loop through the elements of \\mathbf{x} in order. Within each iteration of that loop, we have an expression whose length depends on the iteration number. This leads to a nested loop structure.\n\nforwardsub\n\nForward substitution\n\n\"\"\"\n    forwardsub(L,b)\n\nSolve the lower-triangular linear system with matrix `L` and\nright-hand side vector `b`.\n\"\"\"\nfunction forwardsub(L, b)\n    n = size(L, 1)\n    x = zeros(n)\n    x[1] = b[1] / L[1, 1]\n    for i in 2:n\n        s = sum(L[i, j] * x[j] for j in 1:i-1)\n        x[i] = (b[i] - s) / L[i, i]\n    end\n    return x\nend\n\nAbout the code\n\nThe sum in line 12 gives an error if i equals 1, so that case is taken care of before the loop starts.\n\nForward substitution\n\n\"\"\"\n    forwardsub(L,b)\n\nSolve the lower-triangular linear system with matrix `L` and\nright-hand side vector `b`.\n\"\"\"\nfunction forwardsub(L, b)\n    n = size(L, 1)\n    x = zeros(n)\n    x[1] = b[1] / L[1, 1]\n    for i in 2:n\n        s = sum(L[i, j] * x[j] for j in 1:i-1)\n        x[i] = (b[i] - s) / L[i, i]\n    end\n    return x\nend\n\nAbout the code\n\nThe sum in line 12 gives an error if i equals 1, so that case is taken care of before the loop starts.\n\nForward substitution\n\ndef forwardsub(L,b):\n    \"\"\"\n     forwardsub(L,b)\n\n    Solve the lower-triangular linear system with matrix L and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n):\n        s = L[i,:i] @ x[:i]\n        x[i] = ( b[i] - s ) / L[i, i]\n    return x\n\nThe implementation of backward substitution is much like forward substitution and is given in \n\nFunction 2.3.2.\n\nbacksub\n\nBackward substitution\n\n\"\"\"\n    backsub(U,b)\n\nSolve the upper-triangular linear system with matrix `U` and\nright-hand side vector `b`.\n\"\"\"\nfunction backsub(U, b)\n    n = size(U, 1)\n    x = zeros(n)\n    x[n] = b[n] / U[n, n]\n    for i in n-1:-1:1\n        s = sum(U[i, j] * x[j] for j in i+1:n)\n        x[i] = (b[i] - s) / U[i, i]\n    end\n    return x\nend\n\nBackward substitution\n\n\"\"\"\n    backsub(U,b)\n\nSolve the upper-triangular linear system with matrix `U` and\nright-hand side vector `b`.\n\"\"\"\nfunction backsub(U, b)\n    n = size(U, 1)\n    x = zeros(n)\n    x[n] = b[n] / U[n, n]\n    for i in n-1:-1:1\n        s = sum(U[i, j] * x[j] for j in i+1:n)\n        x[i] = (b[i] - s) / U[i, i]\n    end\n    return x\nend\n\nBackward substitution\n\ndef backsub(U,b):\n    \"\"\"\n    backsub(U,b)\n\n    Solve the upper-triangular linear system with matrix U and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n-1, -1, -1):\n        s = U[i, i+1:] @ x[i+1:]\n        x[i] = ( b[i] - s ) / U[i, i]\n    return x\n\nTriangular systems of equations\n\nExample 2.3.3\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nTip\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = rand(1.:9., 5, 5)\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L,b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext we’ll engineer a problem to which we know the exact answer. Use \\alpha Tab and \\beta Tab to get the Greek letters.\n\nTip\n\nThe notation 0=>ones(5) creates a Pair. In diagm, pairs indicate the position of a diagonal and the elements that are to be placed on it.\n\nα = 0.3;\nβ = 2.2;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nU\n\nx_exact = ones(5)\nb = [α, 0, 0, 0, 1]\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nα = 0.3;\nβ = 1e12;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nb = [α, 0, 0, 0, 1]\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with 16! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.\n\nExample 2.3.3\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nTip\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = randi(9, 5, 5);\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5);\nx = forwardsub(L, b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext, we’ll engineer a problem to which we know the exact answer.\n\nTip\n\nThe eye function creates an identity matrix. The diag function uses 0 as the main diagonal, positive integers as superdiagonals, and negative integers as subdiagonals.\n\nalpha = 0.3;\nbeta = 2.2;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta]\n\nx_exact = ones(5);\nb = [alpha; 0; 0; 0; 1];\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = backsub(U, b);\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta];\nb = [alpha; 0; 0; 0; 1];\n\nx = backsub(U, b);\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.\n\nExample 2.3.3\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nA = 1 + floor(9 * random.rand(5, 5))\nL = tril(A)\nprint(L)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L, b)\nprint(x)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L @ x\n\nNext we’ll engineer a problem to which we know the exact answer.\n\nalpha = 0.3;\nbeta = 2.2;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nprint(U)\n\nx_exact = ones(5)\nb = array([alpha, 0, 0, 0, 1])\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nb = array([alpha, 0, 0, 0, 1])\n\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! But the source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.\n\nThe example in \n\nDemo 2.3.3 is our first clue that linear system problems may have large condition numbers, making inaccurate solutions inevitable in floating-point arithmetic. We will learn how to spot such problems in \n\nConditioning of linear systems. Before reaching that point, however, we need to discuss how to solve general linear systems, not just triangular ones.","type":"content","url":"/linear-systems#implementation","position":7},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Exercises"},"type":"lvl2","url":"/linear-systems#exercises","position":8},{"hierarchy":{"lvl1":"Linear systems","lvl2":"Exercises"},"content":"✍ Find a vector \\mathbf{b} such that the system \\begin{bmatrix} 0&1\\\\0&0 \\end{bmatrix} \\mathbf{x}=\\mathbf{b} has no solution.\n\n✍ Solve the following triangular systems by hand.\n\n(a) \\displaystyle \\begin{aligned}\n   -2x_1  &= -4 \\\\\n     x_1  - x_2        &= 2 \\\\\n    3x_1 + 2x_2  + x_3 &= 1\n   \\end{aligned} \\quad\n(b) \\displaystyle \\begin{bmatrix}\n     4 & 0 & 0 & 0 \\\\\n     1 & -2 & 0 & 0 \\\\\n     -1 & 4 & 4 & 0 \\\\\n     2 & -5 & 5 & 1\n   \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix}\n     -4 \\\\ 1 \\\\ -3 \\\\ 5\n   \\end{bmatrix}\\quad\n(c) \\displaystyle \\begin{aligned}\n    3x_1 +  2x_2  +  x_3      &= 1 \\\\\n            x_2   -  x_3      &= 2 \\\\\n                     2 x_3    &= -4\n   \\end{aligned}\n\n⌨ Use \n\nFunction 2.3.1 or \n\nFunction 2.3.2 to solve each system from the preceding exercise. Verify that the solution is correct by computing \\mathbf{L}\\mathbf{x} and subtracting \\mathbf{b}.\n\n⌨  Use \n\nFunction 2.3.2 to solve the following systems.  Verify that the solution is correct by computing \\mathbf{U}\\mathbf{x} and subtracting \\mathbf{b}.\n\n(a) \\;\\begin{bmatrix}\n   3 & 1 & 0  \\\\\n   0 & -1 & -2  \\\\\n   0 & 0 & 3  \\\\\n \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix}\n   1 \\\\ 1 \\\\ 6\n \\end{bmatrix}\\qquad\n(b) \\;\\begin{bmatrix}\n   3 & 1 & 0 & 6 \\\\\n   0 & -1 & -2 & 7 \\\\\n   0 & 0 & 3 & 4 \\\\\n   0 & 0 & 0 & 5\n \\end{bmatrix} \\mathbf{x} = \\begin{bmatrix}\n   4 \\\\ 1 \\\\ 1 \\\\ 5\n \\end{bmatrix}\n\nSuppose a string is stretched with tension τ horizontally between two anchors at x=0 and x=1. At each of the n-1 equally spaced positions x_k=k/n, k=1,\\ldots,n-1, we attach a little mass m_i and allow the string to come to equilibrium. This causes vertical displacement of the string. Let q_k be the amount of displacement at x_k. If the displacements are not too large, then an approximate force balance equation isn \\tau (q_k - q_{k-1}) + n\\tau (q_k - q_{k+1}) =\nm_k g, \\qquad k=1,\\ldots,n-1,\n\nwhere g=-9.8 m/s2 is the acceleration due to gravity, and we define q_0=0 and q_n=0 due to the anchors. This defines a linear system for q_1,\\ldots,q_{n-1}.\n\n(a) ✍ Show that the force balance equations can be written as a linear system \\mathbf{A}\\mathbf{q}=\\mathbf{f}, where \\mathbf{q} is a vector of the unknown displacements and \\mathbf{A} is a tridiagonal matrix (i.e., A_{ij}=0 if |i-j|>1) of size (n-1)\\times(n-1).\n\n(b) ⌨  Let \\tau=10 N, and m_k=(1/10n) kg for every k. Using backslash, find the displacements when n=8 and n=40, and superimpose plots of \\mathbf{q} over 0\\le x \\le 1 for the two cases. (Be sure to include the zero values at x=0 and x=1 in your plots.)\n\n(c) ⌨  Repeat (b) for the case m_k = (k/5n^2) kg.\n\n⌨  If \\mathbf{B}\\in\\mathbb{R}^{n \\times p} has columns \\mathbf{b}_1,\\ldots,\\mathbf{b}_p, then we can pose p linear systems at once by writing \\mathbf{A} \\mathbf{X} = \\mathbf{B}, where \\mathbf{X} is n\\times p. Specifically, this equation implies \\mathbf{A} \\mathbf{x}_j = \\mathbf{b}_j for j=1,\\ldots,p.\n\n(a) Modify \n\nFunction 2.3.1 and \n\nFunction 2.3.2 so that they solve the case where the second input is n\\times p for p\\ge 1.\n\n(b) If \\mathbf{A} \\mathbf{X}=\\mathbf{I}, then \\mathbf{X}=\\mathbf{A}^{-1}. Use this fact to write a function ltinverse that uses your modified forwardsub to compute the inverse of a lower triangular matrix. Test your function on at least two nontrivial matrices. (We remind you here that this is just an exercise; matrix inverses are rarely a good idea in numerical practice!)\n\n⌨ \n\nDemo 2.3.3 showed solutions of \\mathbf{A}\\mathbf{x}=\\mathbf{b}, where\\mathbf{A} = \\begin{bmatrix} 1 & -1 & 0 & \\alpha-\\beta & \\beta \\\\ 0 & 1 & -1 &\n  0 & 0 \\\\ 0 & 0 & 1 & -1 & 0 \\\\ 0 & 0 & 0 & 1 & -1  \\\\ 0 & 0 & 0 & 0 & 1\n\\end{bmatrix}, \\quad\n\\mathbf{b} = \\begin{bmatrix} \\alpha \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}.\n\nUse \n\nFunction 2.3.2 to solve with \\alpha=0.1 and \\beta=10,100,10^3,\\ldots,10^{12}, tabulating the values of β and |x_1-1|. (This kind of behavior is explained in \n\nConditioning of linear systems.)","type":"content","url":"/linear-systems#exercises","position":9},{"hierarchy":{"lvl1":"LU factorization"},"type":"lvl1","url":"/lu","position":0},{"hierarchy":{"lvl1":"LU factorization"},"content":"A major tool in numerical linear algebra is to factor a given matrix into terms that are individually easier to deal with than the original. In this section we derive a means to express a square matrix using triangular factors, which will allow us to solve a linear system using forward and backward substitution.","type":"content","url":"/lu","position":1},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Outer products"},"type":"lvl2","url":"/lu#outer-products","position":2},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Outer products"},"content":"Our derivation of the factorization hinges on an expression of matrix products in terms of vector outer products. If  \\mathbf{u}\\in\\real^m and \\mathbf{v}\\in\\real^n, then the outer product of these vectors is the m\\times n matrix\\mathbf{u} \\mathbf{v}^T =\n\\begin{bmatrix}\nu_1 v_1 & u_1 v_2 & \\cdots & u_1 v_n \\\\u_2 v_1 & u_2 v_2 & \\cdots & u_2 v_n \\\\ \\vdots & \\vdots & & \\vdots \\\\ u_m v_1 & u_m v_2 & \\cdots & u_m v_n\n\\end{bmatrix}.\n\nWe illustrate the connection of outer products to matrix multiplication by a small example.\n\nAccording to the usual definition of matrix multiplication,\\begin{align*}\n\t\\small\n\t\\begin{bmatrix}\n\t\t4 & -1  \\\\ -3 & 5 \\\\ -2 &  6\t  \n\t\\end{bmatrix}\n\t\\begin{bmatrix}\n\t\t2 & -7 \\\\ -3 & 5 \t  \n\t\\end{bmatrix}\n\t& = \n\t\\small\n\t\\begin{bmatrix}\n\t\t(4)(2) + (-1)(-3)  &  (4)(-7) + (-1)(5)   \\\\ \n\t\t(-3)(2) + (5)(-3)  &  (-3)(-7) + (5)(5)  \\\\ \n\t\t(-2)(2) + (6)(-3)  &  (-2)(-7) + (6)(5)  \n\t\\end{bmatrix}.  \n\\end{align*}\n\nIf we break this up into the sum of two matrices, however, each is an outer product.\\begin{align*}\n\t& = \n\t\\small\n\t\\begin{bmatrix}\n\t\t(4)(2)   &  (4)(-7)    \\\\ \n\t\t(-3)(2)   &  (-3)(-7)    \\\\ \n\t\t(-2)(2) &  (-2)(-7) \n\t\\end{bmatrix} + \n\t\\begin{bmatrix}\n\t\t(-1)(-3)  &  (-1)(5)  \\\\ \n\t\t(5)(-3)  &  (5)(5)  \\\\ \n\t\t(6)(-3)  &  (6)(5) \n\t\\end{bmatrix}\\\\[2mm]\n\t& = \n\t\\small\n\t\\begin{bmatrix}\n\t\t4 \\\\ -3 \\\\ -2 \n\t\\end{bmatrix} \n\t\\begin{bmatrix}\n\t\t2 & -7 \n\t\\end{bmatrix} \\: + \\:\n\t\\begin{bmatrix}\n\t\t-1 \\\\ 5 \\\\ 6 \n\t\\end{bmatrix} \n\t\\begin{bmatrix}\n\t\t-3 & 5 \n\t\\end{bmatrix}.\n\\end{align*}\n\nNote that the vectors here are columns of the left-hand matrix and rows of the right-hand matrix. The matrix product is defined only if there are equal numbers of these.\n\nIt is not hard to derive the following generalization of \n\nExample 2.4.1 to all matrix products.\n\nMatrix multiplication by outer products\n\nWrite the columns of \\mathbf{A} as \\mathbf{a}_1,\\dots,\\mathbf{a}_n and the rows of \\mathbf{B} as \\mathbf{b}_1^T,\\dots,\\mathbf{b}_n^T. Then\\mathbf{A}\\mathbf{B} = \\sum_{k=1}^n \\mathbf{a}_k \\mathbf{b}_k^T.","type":"content","url":"/lu#outer-products","position":3},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular product"},"type":"lvl2","url":"/lu#triangular-product","position":4},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular product"},"content":"Equation \n\n(2.4.4) has some interesting structure for the product \\mathbf{L}\\mathbf{U}, where \\mathbf{L} is n\\times n and lower triangular (i.e., zero above the main diagonal) and \\mathbf{U} is n\\times n and upper triangular (zero below the diagonal).\n\nTriangular outer products\n\nExample 2.4.2\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( rand(1:9, 3, 3) )\n\nU = triu( rand(1:9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nTip\n\nAlthough U[1,:] is a row of U, it is a vector, and as such it has a default column interpretation.\n\nL[:, 1] * U[1, :]'\n\nL[:, 2] * U[2, :]'\n\nL[:, 3] * U[3, :]'\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nExample 2.4.2\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( randi(9, 3, 3) )\n\nU = triu( randi(9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nL(:, 1) * U(1, :)\n\nL(:, 2) * U(2, :)\n\nL(:, 3) * U(3, :)\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nExample 2.4.2\n\nWe explore the outer product formula for two random triangular matrices.\n\nfrom numpy.random import randint\nL = tril(randint(1, 10, size=(3, 3)))\nprint(L)\n\nU = triu(randint(1, 10, size=(3, 3)))\nprint(U)\n\nHere are the three outer products appearing in the sum in \n\n(2.4.4):\n\nprint(outer(L[:, 0], U[0, :]))\n\nprint(outer(L[:, 1], U[1, :]))\n\nprint(outer(L[:, 2], U[2, :]))\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nLet the columns of \\mathbf{L} be written as \\boldsymbol{\\ell}_k and the rows of \\mathbf{U} be written as \\mathbf{u}_k^T. Then the first row of \\mathbf{L}\\mathbf{U} is\\mathbf{e}_1^T \\sum_{k=1}^n  \\boldsymbol{ℓ}_k \\mathbf{u}_k^T = \\sum_{k=1}^n (\\mathbf{e}_1^T \\boldsymbol{\\ell}_k) \\mathbf{u}_k^T = L_{11} \\mathbf{u}_1^T.\n\nLikewise, the first column of \\mathbf{L}\\mathbf{U} is\\left( \\sum_{k=1}^n \\mathbf{ℓ}_k \\mathbf{u}_k^T\\right) \\mathbf{e}_1 = \\sum_{k=1}^n \\mathbf{\\ell}_k (\\mathbf{u}_k^T \\mathbf{e}_1) = U_{11}\\boldsymbol{\\ell}_1.\n\nThese two calculations are enough to derive one of the most important algorithms in scientific computing.","type":"content","url":"/lu#triangular-product","position":5},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular factorization"},"type":"lvl2","url":"/lu#triangular-factorization","position":6},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Triangular factorization"},"content":"Our goal is to factor a given n\\times n matrix \\mathbf{A} as the triangular product \\mathbf{A}=\\mathbf{L}\\mathbf{U}. It turns out that we have n^2+n total nonzero unknowns in the two triangular matrices, so we set L_{11}=\\cdots = L_{nn}=1, making \\mathbf{L} a unit lower triangular matrix.\n\nLU factorization\n\nExample 2.4.3\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA₁ = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = diagm(ones(4))\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[1, :] = A₁[1, :]\nU\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 1] = A₁[:, 1] / U[1, 1]\nL\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[2, :] = A₂[2, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nL\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[3, :] = A₃[3, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\nFinally, we pick up the last unknown in the factors.\n\nU[4, 4] = A₄[4, 4];\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA₁ - L * U\n\nIIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nExample 2.4.3\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = eye(4);\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU(1, :) = A_1(1, :)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL(:, 1) = A_1(:, 1) / U(1, 1)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU(2, :) = A_2(2, :)\nL(:, 2) = A_2(:, 2) / U(2, 2)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU(3, :) = A_3(3, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\nFinally, we pick up the last unknown in the factors.\n\nU(4, 4) = A_4(4, 4);\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L * U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nExample 2.4.3\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = array([\n     [2,    0,    4,    3], \n     [-4,    5,   -7,  -10], \n     [1,   15,    2,   -4.5],\n     [-2,    0,    2,  -13]\n        ])\nL = eye(4)\nU = zeros((4, 4));\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[0, :] = A_1[0, :]\nprint(U)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 0] = A_1[:, 0] / U[0, 0]\nprint(L)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - outer(L[:, 0],  U[0, :])\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[1, :] = A_2[1, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nprint(L)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - outer(L[:, 1], U[1, :])\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[2, :] = A_3[2, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\n\nFinally, we pick up the last unknown in the factors.\n\nU[3, 3] = A_4[3, 3]\n\nWe now have all of \\mathbf{L},\n\nprint(L)\n\nand all of \\mathbf{U},\n\nprint(U)\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L @ U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nWe have arrived at the linchpin of solving linear systems.\n\nLU factorization\n\nGiven n\\times n matrix \\mathbf{A}, its LU factorization is\\mathbf{A} = \\mathbf{L}\\mathbf{U},\n\nwhere \\mathbf{L} is a unit lower triangular matrix and \\mathbf{U} is an upper triangular matrix.\n\nThe outer product algorithm for LU factorization seen in \n\nDemo 2.4.3 is coded as \n\nFunction 2.4.1.\n\nlufact\n\nLU factorization (not stable)\n\n\"\"\"\n    lufact(A)\n\nCompute the LU factorization of square matrix `A`, returning the\nfactors.\n\"\"\"\nfunction lufact(A)\n    n = size(A, 1)        # detect the dimensions from the input\n    L = diagm(ones(n))   # ones on main diagonal, zeros elsewhere\n    U = zeros(n, n)\n    Aₖ = float(copy(A))  # make a working copy\n\n    # Reduction by outer products\n    for k in 1:n-1\n        U[k, :] = Aₖ[k, :]\n        L[:, k] = Aₖ[:, k] / U[k, k]\n        Aₖ -= L[:, k] * U[k, :]'\n    end\n    U[n, n] = Aₖ[n, n]\n    return LowerTriangular(L), UpperTriangular(U)\nend\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out two subtle Julia issues. First, vectors and matrix variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement Aₖ=A just clones the array reference of A into the variable Aₖ. Any changes made to entries of Aₖ would then also be made to entries of A because they refer to the same location in memory. In this context we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nThe second issue is that even when A has all integer entries, its LU factors may not. So we convert Aₖ to floating point so that line 17 will not fail due to the creation of floating-point values in an integer matrix. An alternative would be to require the caller to provide a floating-point array in the first place.\n\nLU factorization (not stable)\n\nfunction [L, U] = lufact(A)\r\n% LUFACT   LU factorization (demo only--not stable!).\r\n% Input:\r\n%   A    square matrix\r\n% Output:\r\n%   L,U  unit lower triangular and upper triangular such that LU=A\r\n\r\nn = size(A, 1);     % detect the dimensions from the input\r\nL = eye(n);         % ones on main diagonal, zeros elsewhere\r\nU = zeros(n, n);\r\nA_k = A;            % make a working copy \r\n\r\n% Reduction by outer products\r\nfor k = 1:n-1\r\n    U(k, :) = A_k(k, :);\r\n    L(:, k) = A_k(:,k) / U(k, k);\r\n    A_k = A_k -  L(:, k) * U(k, :);\r\nend\r\nU(n, n) = A_k(n, n);\r\nL = tril(L); U = triu(U);    % force exact triangularity\n\nLU factorization (not stable)\n\ndef lufact(A):\n    \"\"\"\n    lufact(A)\n\n    Compute the LU factorization of square matrix A, returning the\n    factors.\n    \"\"\"\n    n = A.shape[0]     # detect the dimensions from the input\n    L = np.eye(n)      # ones on main diagonal, np.zeros elsewhere\n    U = np.zeros((n, n))\n    A_k = np.copy(A)   # make a working np.copy \n\n    # Reduction by np.outer products\n    for k in range(n-1):\n        U[k, :] = A_k[k, :]\n        L[:, k] = A_k[:, k] / U[k,k]\n        A_k -= np.outer(L[:,k], U[k,:])\n    U[n-1, n-1] = A_k[n-1, n-1]\n    return L, U\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out a subtle issue. Array variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement A_k = A would just clone the array reference of A into the new variable. Any changes made to entries of A_k would then also be made to entries of A, because they refer to the same location in memory. In this context, we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.","type":"content","url":"/lu#triangular-factorization","position":7},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Gaussian elimination and linear systems"},"type":"lvl2","url":"/lu#gaussian-elimination-and-linear-systems","position":8},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Gaussian elimination and linear systems"},"content":"In your first matrix algebra course, you probably learned a triangularization technique called Gaussian elimination or row elimination to solve a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}. In most presentations, you form an augmented matrix [\\mathbf{A}\\;\\mathbf{b}] and do row operations until the system reaches an upper triangular form, followed by backward substitution. LU factorization is equivalent to Gaussian elimination in which no row swaps are performed, and the elimination procedure produces the factors if you keep track of the row multipliers appropriately.\n\nLike Gaussian elimination, the primary use of LU factorization is to solve a linear system. It reduces a given linear system to two triangular ones. From this, solving \\mathbf{A}\\mathbf{x}=\\mathbf{b} follows immediately from associativity:\\mathbf{b} = \\mathbf{A} \\mathbf{x} = (\\mathbf{L} \\mathbf{U}) \\mathbf{x} = \\mathbf{L} (\\mathbf{U} \\mathbf{x}).\n\nDefining \\mathbf{z} = \\mathbf{U} \\mathbf{x} leads to the following.\n\nSolution of linear systems by LU factorization (unstable)\n\nFactor \\mathbf{L}\\mathbf{U}=\\mathbf{A}.\n\nSolve \\mathbf{L}\\mathbf{z}=\\mathbf{b} for \\mathbf{z} using forward substitution.\n\nSolve \\mathbf{U}\\mathbf{x}=\\mathbf{z} for \\mathbf{x} using backward substitution.\n\nA key advantage of the factorization point of view is that it depends only on the matrix \\mathbf{A}. If systems are to be solved for a single \\mathbf{A} but multiple different versions of \\mathbf{b}, then the factorization approach is more efficient, as we’ll see in \n\nEfficiency of matrix computations.\n\nSolving a linear system by LU factors\n\nExample 2.4.4\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4,9,9,4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A*x\n\nExample 2.4.4\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4; 9; 9; 4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\n[L, U] = lufact(A)\nz = forwardsub(L, b);\nx = backsub(U, z);\n\nA check on the residual assures us that we found the solution.\n\nb - A * x\n\nExample 2.4.4\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = array([\n    [2, 0, 4, 3], \n    [-4, 5, -7, -10], \n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nb = array([4, 9, 9, 4])\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A @ x\n\nAs noted in the descriptions of \n\nFunction 2.4.1 and \n\nAlgorithm 2.4.2, the LU factorization as we have seen it so far is not stable for all matrices. In fact, it does not always even exist. The missing element is the row swapping allowed in Gaussian elimination. We will address these issues in \n\nRow pivoting.","type":"content","url":"/lu#gaussian-elimination-and-linear-systems","position":9},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Exercises"},"type":"lvl2","url":"/lu#exercises","position":10},{"hierarchy":{"lvl1":"LU factorization","lvl2":"Exercises"},"content":"✍ For each matrix, produce an LU factorization by hand.\n\n(a) \\quad \\displaystyle \\begin{bmatrix}\n 2 & 3 & 4 \\\\\n 4 & 5 & 10 \\\\\n 4 & 8 & 2\n \\end{bmatrix}\\qquad\n(b) \\quad \\displaystyle \\begin{bmatrix}\n 6 & -2 & -4 & 4\\\\\n 3 & -3 & -6 & 1 \\\\\n -12 & 8 & 21 & -8 \\\\\n -6 & 0 & -10 & 7\n \\end{bmatrix}\n\n⌨ The matrices\\mathbf{T}(x,y) = \\begin{bmatrix}\n  1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ x & y & 1\n\\end{bmatrix},\\qquad\n\\mathbf{R}(\\theta) = \\begin{bmatrix}\n  \\cos\\theta & \\sin \\theta & 0 \\\\ -\\sin\\theta & \\cos \\theta & 0 \\\\ 0 & 0 & 1\n\\end{bmatrix}\n\nare used to represent translations and rotations of plane points in computer graphics. For the following, let\\mathbf{A} = \\mathbf{T}(3,-1)\\mathbf{R}(\\pi/5)\\mathbf{T}(-3,1), \\qquad \\mathbf{z} = \\begin{bmatrix}\n  2 \\\\ 2 \\\\ 1\n\\end{bmatrix}.\n\n(a) Find \\mathbf{b} = \\mathbf{A}\\mathbf{z}.\n\n(b) Use \n\nFunction 2.4.1 to find the LU factorization of \\mathbf{A}.\n\n(c) Use the factors with triangular substitutions in order to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}, and find \\mathbf{x}-\\mathbf{z}.\n\n⌨ Define\\mathbf{A}= \\begin{bmatrix}\n  1 & 0 & 0 & 0 & 10^{12} \\\\\n  1 & 1 & 0 & 0 & 0 \\\\\n  0 & 1 & 1 & 0 & 0 \\\\\n  0 & 0 & 1 & 1 & 0 \\\\\n  0 & 0 & 0 & 1 & 0\n\\end{bmatrix},\n\\quad \\hat{\\mathbf{x}} = \\begin{bmatrix}\n  0 \\\\ 1/3 \\\\ 2/3 \\\\ 1 \\\\ 4/3\n\\end{bmatrix},\n\\quad \\mathbf{b} = \\mathbf{A}\\hat{\\mathbf{x}}.\n\n(a) Using \n\nFunction 2.4.1 and triangular substitutions, solve the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, showing the result. To the nearest integer, how many accurate digits are in the result? (The answer is much less than the full 16 of double precision.)\n\n(b) Repeat part (a) with \n\n1020 as the element in the upper right corner. (The result is even less accurate. We will study the causes of such low accuracy in \n\nConditioning of linear systems.)\n\n⌨ Let\\mathbf{A} = \n\t\\begin{bmatrix}\n     1 & 1 & 0 & 1 & 0 & 0 \\\\\n     0 & 1 & 1 & 0 & 1 & 0 \\\\\n     0 & 0 & 1 & 1 & 0 & 1 \\\\\n     1 & 0 & 0 & 1 & 1 & 0 \\\\\n     1 & 1 & 0 & 0 & 1 & 1 \\\\\n     0 & 1 & 1 & 0 & 0 & 1\n    \\end{bmatrix}.\n\nVerify computationally that if \\mathbf{A}=\\mathbf{L}\\mathbf{U} is the LU factorization, then the elements of \\mathbf{L}, \\mathbf{U}, \\mathbf{L}^{-1}, and \\mathbf{U}^{-1} are all integers. Do not rely just on visual inspection of the numbers; perform a more definitive test.\n\n⌨ \n\nFunction 2.4.1 factors \\mathbf{A}=\\mathbf{L}\\mathbf{U} in such a way that \\mathbf{L} is a unit lower triangular matrix—that is, has all ones on the diagonal. It is also possible to define the factorization so that \\mathbf{U} is a unit upper triangular matrix instead. Write a function lufact2 that uses \n\nFunction 2.4.1 without modification to produce this version of the factorization. (Hint: Begin with the standard LU factorization of \\mathbf{A}^T.) Demonstrate on a nontrivial 4\\times 4 example.\n\nWhen computing the determinant of a matrix by hand, it’s common to use cofactor expansion and apply the definition recursively. But this is terribly inefficient as a function of the matrix size.\n\n(a) ✍ Explain using determinant properties why, if \\mathbf{A}=\\mathbf{L}\\mathbf{U} is an LU factorization,  \\det(\\mathbf{A}) = U_{11}U_{22}\\cdots U_{nn}=\\prod_{i=1}^n U_{ii}.\n\n(b) ⌨ Using the result of part (a), write a function determinant(A) that computes the determinant using \n\nFunction 2.4.1. Test your function on at least two nontriangular 5\\times 5 matrices, comparing your result to the result of the standard det function.","type":"content","url":"/lu#exercises","position":11},{"hierarchy":{"lvl1":"Computing with matrices"},"type":"lvl1","url":"/matrices","position":0},{"hierarchy":{"lvl1":"Computing with matrices"},"content":"Attention\n\nWe recommend that you review the linear algebra material in \n\nReview of linear algebra before reading this section.\n\nAt a reductive level, a matrix is a table of numbers that obeys certain algebraic laws. But matrices are pervasive in scientific computation, mainly because they represent linear operations on vectors. Moreover, vectors go far beyond the three-dimensional representations of physical quantities you learned about in calculus.","type":"content","url":"/matrices","position":1},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Notation"},"type":"lvl2","url":"/matrices#notation","position":2},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Notation"},"content":"We use capital letters in bold to refer to matrices, and lowercase bold letters for vectors. All named vectors in this book are column vectors. The bold symbol \\boldsymbol{0} may refer to a vector of all zeros or to a zero matrix, depending on context; we use 0 as the scalar zero only.\n\nTo refer to a specific element of a matrix, we use the uppercase name of the matrix without boldface, as in A_{24} to mean the (2,4) element of \\mathbf{A}. To refer to an element of a vector, we use just one subscript, as in x_3. If you see a boldface character with one or more subscripts, then you know that it is a matrix or vector that belongs to a sequence or indexed collection.\n\nWe will have frequent need to refer to the individual columns of a matrix as vectors. Our convention is to use a lowercase bold version of the matrix name with a subscript to represent the column number. Thus, \\mathbf{a}_1,\\mathbf{a}_2,\\ldots,\\mathbf{a}_n are the columns of the m\\times n matrix \\mathbf{A}. Conversely, whenever we define a sequence of vectors \\mathbf{v}_1,\\ldots,\\mathbf{v}_p, we can implicitly consider them to be columns of a matrix \\mathbf{V}. Sometimes we might write \\mathbf{V}=\\bigl[ \\mathbf{v}_j \\bigr] to emphasize the connection.\n\nThe notation \\mathbf{A}^T is used for the transpose of a matrix, whether it is real or complex. In the case of complex matrices, it’s almost always more desirable to use the adjoint \\mathbf{A}^*, which is the transpose with the complex conjugate of each element.  If \\mathbf{A} is real, then \\mathbf{A}^*=\\mathbf{A}^T. A symmetric matrix is a square matrix such that \\mathbf{A}^T=\\mathbf{A}.\n\nThe identity matrix of size n is denoted \\mathbf{I}, or sometimes \\mathbf{I}_n if emphasizing the size is important in context. For columns of the identity we break with our usual naming convention and denote them by \\mathbf{e}_j.","type":"content","url":"/matrices#notation","position":3},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Block matrix expressions"},"type":"lvl2","url":"/matrices#block-matrix-expressions","position":4},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Block matrix expressions"},"content":"We will often find it useful to break a matrix into separately named pieces. For example, we might write  \\mathbf{A} =\n  \\begin{bmatrix}\n    \\mathbf{A}_{11} & \\mathbf{A}_{12} & \\mathbf{A}_{13} \\\\\n    \\mathbf{A}_{21} & \\mathbf{A}_{22} & \\mathbf{A}_{23}\n  \\end{bmatrix}, \\qquad\n  \\mathbf{B} =\n  \\begin{bmatrix}\n    \\mathbf{B}_1 \\\\ \\mathbf{B}_2 \\\\ \\mathbf{B}_3\n  \\end{bmatrix}.\n\nIt’s understood that blocks that are on top of one another have the same number of columns, and blocks that are side by side have the same number of rows. Typically, if the blocks all have compatible dimensions, then they can be multiplied as though the blocks were scalars. For instance, continuing with the definitions above, we say that \\mathbf{A} is block-2\\times 3 and \\mathbf{B} is block-3\\times 1, so we can write  \\mathbf{A} \\mathbf{B} =\n  \\begin{bmatrix}\n    \\mathbf{A}_{11}\\mathbf{B}_1 + \\mathbf{A}_{12}\\mathbf{B}_2 + \\mathbf{A}_{13}\\mathbf{B}_3 \\\\\n    \\mathbf{A}_{21}\\mathbf{B}_1 + \\mathbf{A}_{22}\\mathbf{B}_2 + \\mathbf{A}_{23}\\mathbf{B}_3\n  \\end{bmatrix},\n\nprovided that the individual block products are well-defined. For transposes we have, for example,  \\mathbf{A}^T =\n  \\begin{bmatrix}\n    \\mathbf{A}_{11}^T & \\mathbf{A}_{21}^T \\\\[2mm]\n    \\mathbf{A}_{12}^T & \\mathbf{A}_{22}^T \\\\[2mm]\n    \\mathbf{A}_{13}^T & \\mathbf{A}_{23}^T\n  \\end{bmatrix}.","type":"content","url":"/matrices#block-matrix-expressions","position":5},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Vector and matrix basics"},"type":"lvl2","url":"/matrices#vector-and-matrix-basics","position":6},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Vector and matrix basics"},"content":"Vectors and matrices are integral to scientific computing. All modern languages provide ways to work with them beyond manipulation of individual elements.\n\nMatrix operations\n\nExample 2.2.1\n\nIn Julia, vectors and matrices are one-dimensional and two-dimensional arrays, respectively. Square brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nTip\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ 1 2 3 4 5; 50 40 30 20 10\n    π sqrt(2) exp(1) (1+sqrt(5))/2 log(3) ]\n\nm, n = size(A)\n\nA vector is not quite the same thing as a matrix: it has only one dimension, not two. Separate its elements by commas or semicolons:\n\nx = [ 3, 3, 0, 1, 0 ]\nsize(x)\n\nFor some purposes, however, an n-vector in Julia is treated like having a column shape. Note the difference if we use spaces instead of commas inside the brackets:\n\ny = [ 3 3 0 1 0 ]\nsize(y)\n\nThis 1\\times 5 matrix is not equivalent to a vector.\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nIf x is simply a vector, then its transpose has a row shape.\n\nx'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              # start:stop\n\nz = 0:3:12           # start:step:stop\n\n(Ranges are not strictly considered vectors, but they behave identically in most circumstances.) Instead of specifying the step size, you can give the number of points in the range if you use range.\n\ns = range(-1, 1, 5)\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within square brackets.\n\nTip\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A[2, end-1]\n\nx[2]\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA[1:2, end-2:end]    # first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA[:, 1:2:end]        # all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nTip\n\nUse diagm to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diagm( [-1, 0, -5] )   # create a diagonal matrix\n\n@show size(A), size(B);\nBA = B * A     # matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nTip\n\nErrors are formally called exceptions in Julia.\n\nA * B    # throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    # same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x .^ 2\n\ntwo_to_x = 2 .^ x\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, expect scalars as operands. However, you can broadcast any function, including ones that you have defined, across a vector or array by using a special dot syntax.\n\nTip\n\nA dot added to the end of a function name means to apply the function elementwise to an array.\n\nshow(cos.(π * x))    # broadcast to a function\n\nRather than dotting multiple individual functions, you can use @. before an expression to broadcast everything within it.\n\nshow(@. cospi( (x + 1)^3) )    # broadcast an entire expression\n\nExample 2.2.1\n\nIn MATLAB, every numerical value is treated like a matrix. A matrix with one row or one column is interpreted as a vector, and a 1\\times 1 matrix is interpreted as a scalar.\n\nSquare brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nTip\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ \n    1       2      3             4      5; \n    50     40     30            20     10\n    pi sqrt(2) exp(1) (1+sqrt(5))/2 log(3) \n    ]\n\nm, n = size(A)\n\nx = [ 3, 3, 0, 1, 0 ];   % row vector\nsize(x)\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              % start:stop\n\nz = 0:3:12           % start:step:stop\n\nInstead of specifying the step size, you can give the number of points in the range if you use linspace.\n\ns = linspace(-1, 1, 5)    % row result\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within parentheses.\n\nTip\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A(2, end-1)\n\nx(2)\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA(1:2, end-2:end)    % first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA(:, 1:2:end)        % all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nTip\n\nUse diag to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diag([-1, 0, -5])   % create a diagonal matrix\n\nsize(A)\nsize(B)\n\nBA = B * A     % matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nTip\n\nErrors are formally called exceptions in Julia.\n\nA * B    % throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    % same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x .^ 2\n\ntwo_to_x = 2 .^ x\n\nTip\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, can operate elementwise on vectors and matrices.\n\ncos(pi * x)\n\nExample 2.2.1\n\nNote\n\nWhile NumPy does have distinct representations for matrices and 2D arrays, use of the explicit matrix class is officially discouraged. We follow this advice here and use arrays to represent both matrices and vectors. :::{index}\nsee: Python; size, Python; shape\n::: \n\nA vector is created using square brackets and commas to enclose and separate its entries.\n\nx = array([3, 3, 0, 1, 0 ])\nprint(x.shape)\n\nTo construct a matrix, you nest the brackets to create a “vector of vectors”. The inner vectors are the rows.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    [pi, sqrt(2), exp(1), (1+sqrt(5))/2, log(3)] \n    ])\n\nprint(A)\nprint(A.shape)\n\nIn this text, we treat all vectors as equivalent to matrices with a single column. That isn’t true in NumPy, because even an n \\times 1 array has two dimensions, unlike a vector.\n\narray([[3], [1], [2]]).shape\n\nYou can concatenate arrays with compatible dimensions using hstack and vstack.\n\nprint( hstack([A, A]) )\n\nprint( vstack([A, A]) )\n\nTransposing a matrix is done by appending .T to it.\n\nprint(A.T)\n\nFor matrices with complex values, we usually want instead the adjoint or hermitian, which is .conj().T.\n\nprint((x + 1j).conj().T)\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a vector with evenly spaced entries between two endpoints, you have two options.\n\nprint(arange(1, 7, 2))   # from 1 to 7 (not inclusive), step by 2\n\nprint(linspace(-1, 1, 5))   # from -1 to 1 (inclusive), with 5 total values\n\nThe practical difference between these is whether you want to specify the step size in arange or the number of points in linspace.\n\nAccessing an element is done by giving one (for a vector) or two index values in square brackets. In Python, indexing always starts with zero, not 1.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    linspace(-5, 5, 5) \n    ])\nx = array([3, 2, 0, 1, -1 ])\n\nprint(\"row 2, col 3 of A:\", A[1, 2])\nprint(\"first element of x:\", x[0])\n\nThe indices can be ranges, in which case a slice or block of the matrix is accessed. You build these using a colon in the form start:stop. However, the last value of this range is stop-1, not stop.\n\nprint(A[1:3, 0:2])    # rows 2 and 3, cols 1 and 2\n\nIf start or stop is omitted, the range extends to the first or last index.\n\nprint(x[1:])  # elements 2 through the end\n\nprint(A[:2, 0])  # first two rows in column 1\n\nNotice in the last case above that even when the slice is in the shape of a column vector, the result is just a vector with one dimension and neither row nor column shape.\n\nThere are more variations on the colon ranges. A negative value means to count from the end rather than the beginning. And a colon by itself means to include everything from the relevant dimension.\n\nprint(A[:-1, :])    # all rows up to the last, all columns\n\nFinally, start:stop:step means to step size or stride other than one. You can mix this with the other variations.\n\nprint(x[::2])  # all the odd indexes\n\nprint(A[:, ::-1])  # reverse the columns\n\nThe matrix and vector senses of addition, subtraction, and scalar multiplication and division are all handled by the usual symbols. Two matrices of the same size (what NumPy calls shape) are operated on elementwise.\n\nprint(A - 2 * ones([3, 5]))  # subtract two from each element\n\nIf one operand has a smaller number of dimensions than the other, Python tries to broadcast it in the “missing” dimension(s), and the operation proceeds if the resulting shapes are identical.\n\nprint(A - 2)    # subtract two from each element\n\nu = array([1, 2, 3, 4, 5])\nprint(A - u)    # repeat this row for every row of A\n\nv = array([1, 2, 3])\nprint(A - v)  # broadcasting this would be 3x3, so it's an error\n\nprint(A - v.reshape([3, 1]))    # broadcasts to each column of A ```{index} \nsee: Python; matrix multiplication, Python; \\@\n``` \n\nMatrix–matrix and matrix–vector products are computed using @ or matmul.\n\nB = diag([-1, 0, -5])    # create a diagonal 3x3\nprint(B @ A)    # matrix product\n\nAB is undefined for these matrix sizes.\n\nprint(A @ B)    # incompatible sizes\n\nThe multiplication operator * is reserved for elementwise multiplication. Both operands have to be the same size, after any potential broadcasts.\n\nprint(B * A)    # not the same size, so it's an error\n\nprint((A / 2) * A)    # elementwise\n\nTo raise to a power elementwise, use a double star. This will broadcast as well.\n\nprint(B)\nprint(B**3)\n\nprint(x)\nprint(2.0**x)\n\nDanger\n\nIf A is a matrix, A**2 is not the same as mathematically raising it to the power 2.\n\nMost of the mathematical functions, such as cos, sin, log, exp and sqrt, expecting scalars as operands will be broadcast to arrays.\n\nprint(cos(pi * x))","type":"content","url":"/matrices#vector-and-matrix-basics","position":7},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Row and column operations"},"type":"lvl2","url":"/matrices#row-and-column-operations","position":8},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Row and column operations"},"content":"A critical identity in matrix multiplication is  \\mathbf{A} \\mathbf{e}_j = \\mathbf{a}_j.\n\nMultiplication on the right by column j of the identity reproduces the jth column of a matrix.\n\nFurthermore, the expression  \\mathbf{A}\n  \\begin{bmatrix}\n    \\mathbf{e}_1 & \\mathbf{e}_3 & \\mathbf{e}_5\n  \\end{bmatrix}\n\nreproduces three columns. An equivalent expression in Julia would be A[:,1:2:5].\n\nWe can extend the same idea to rows by using the general identity (\\mathbf{R}\\mathbf{S})^T=\\mathbf{S}^T\\mathbf{R}^T. Let \\mathbf{B}=\\mathbf{A}^T have columns \\bigl[ \\mathbf{b}_j \\bigr], and note  (\\mathbf{b}_j)^T = (\\mathbf{B} \\mathbf{e}_j)^T = \\mathbf{e}_j^T \\mathbf{B}^T = \\mathbf{e}_j^T \\mathbf{A}.\n\nBut \\mathbf{e}_j^T is the jth row of \\mathbf{I}, and \\mathbf{b}_j^T is the transpose of the jth column of \\mathbf{B}, which is the jth row of \\mathbf{A} by \\mathbf{B}=\\mathbf{A}^T. Thus, multiplication on the left by row j of the identity extracts the jth row. Extracting the single element (i,j) from the matrix is, therefore, \\mathbf{e}_i^T \\mathbf{A} \\mathbf{e}_j.\n\nBeing able to extract specific rows and columns of a matrix via algebra makes it straightforward to do row- and column-oriented operations, such as linear combinations.\n\nSay that \\mathbf{A} has five columns. Adding twice the third column of \\mathbf{A} to its first column is done by\\mathbf{A}(\\mathbf{e}_1+2\\mathbf{e}_3).\n\nSuppose we want to do this operation “in place,” meaning replacing the first column of \\mathbf{A} with this value and leaving the other four columns of \\mathbf{A} alone. We can replace \\mathbf{A} with  \\mathbf{A}\n  \\begin{bmatrix}\n    \\mathbf{e}_1+2\\mathbf{e}_3 & \\mathbf{e}_2 & \\mathbf{e}_3 & \\mathbf{e}_4 & \\mathbf{e}_5\n  \\end{bmatrix}.\n\nThe Julia equivalent isA[:, 1] += 2A[:, 3]\n\nThe += operator means to increment the item on the left-hand side. There are similar interpretations for -= and *=.\n\nThe MATLAB equivalent isA(:, 1) = A(:, 1) + 2 * A(:, 3)\n\nThe NumPy equivalent isA[:, 0] += 2 * A[:, 2]\n\nThe += operator means to increment the item on the left-hand side. There are similar interpretations for -= and *=","type":"content","url":"/matrices#row-and-column-operations","position":9},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Exercises"},"type":"lvl2","url":"/matrices#exercises","position":10},{"hierarchy":{"lvl1":"Computing with matrices","lvl2":"Exercises"},"content":"✍ Suppose\\mathbf{C} =\n    \\begin{bmatrix}\n      \\mathbf{I} & \\mathbf{A} \\\\ -\\mathbf{I} & \\mathbf{B}\n    \\end{bmatrix}.\n\nUsing block notation, find \\mathbf{C}^2 and \\mathbf{C}^3.\n\n⌨  Let\\mathbf{A} =\n\\begin{bmatrix}\n  2 & 1 & 1 & 0 \\\\ 0 & -1 & 4 & 1 \\\\ 2 & 2 & 0 & -2 \\\\ 1 & 3 & -1\n  & 5\n\\end{bmatrix},\n\\quad\n\\mathbf{B} =\n\\begin{bmatrix}\n  3 & -1 & 0 & 2 \\\\ 7 & 1 & 0 & 2\n\\end{bmatrix},\\mathbf{u} =\n\\begin{bmatrix}\n  2 \\\\ -1 \\\\ 3 \\\\ 1\n\\end{bmatrix},\n\\quad\n\\mathbf{v} =\n\\begin{bmatrix}\n  \\pi \\\\ e\n\\end{bmatrix}.\n\n(Do not round off the values in \\mathbf{v}—find them using native Julia commands.) For each expression below, use Julia to find the result, or explain why the result does not exist.\n\n(a) \\mathbf{A}\\mathbf{B},\\quad\n(b) \\mathbf{B} \\mathbf{A},\\quad\n(c) \\mathbf{v}^T \\mathbf{B},\\quad\n(d) \\mathbf{B} \\mathbf{u},\\quad\n(e) \\bigl[ \\, \\mathbf{u}\\:\\: \\mathbf{A}\\mathbf{u} \\:\\: \\mathbf{A}^2 \\mathbf{u} \\:\\: \\mathbf{A}^3 \\mathbf{u} \\bigr].\n\n⌨  Let\\mathbf{u} =\n\\begin{bmatrix}\n  1\\\\3\\\\5\\\\7\\\\9\\\\11\n\\end{bmatrix}, \\qquad\n\\mathbf{v} =\n\\begin{bmatrix}\n  -60 \\\\ -50 \\\\ -40 \\\\ -30 \\\\ -20 \\\\ -10\n\\end{bmatrix}.\n\nFind the inner products \\mathbf{u}^T\\mathbf{v} and \\mathbf{v}^T\\mathbf{u} and the outer products \\mathbf{u}\\mathbf{v}^T and \\mathbf{v}\\mathbf{u}^T.\n\n⌨ In Julia, give a demonstration of the identity (\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T for some arbitrarily chosen 3\\times 4 matrix \\mathbf{A} and 4\\times 2 matrix \\mathbf{B}.\n\n✍ Prove that if \\mathbf{A} and \\mathbf{B} are invertible, then (\\mathbf{A}\\mathbf{B})^{-1}=\\mathbf{B}^{-1}\\mathbf{A}^{-1}. (In producing the inverse, it follows that \\mathbf{A}\\mathbf{B} is invertible as well.)\n\n✍ Suppose \\mathbf{B} is an arbitrary 4\\times 3 matrix. In each part below a matrix \\mathbf{A} is described in terms of \\mathbf{B}. Express \\mathbf{A} as a product of \\mathbf{B} with one or more other matrices.\n\n(a) \\mathbf{A}\\in\\mathbb{R}^{4 \\times 1} is the result of adding the first column of \\mathbf{B} to -2 times the last column of \\mathbf{B}.\n\n(b) The rows of \\mathbf{A}\\in\\mathbb{R}^{4 \\times 3} are the rows of \\mathbf{B} in order 4,3,2,1.\n\n(c) The first column of \\mathbf{A}\\in\\mathbb{R}^{4 \\times 3} is 1 times the first column of \\mathbf{B}, the second column of \\mathbf{A} is 2 times the second column of \\mathbf{B},\nand the third column of \\mathbf{A} is 3 times the third column of \\mathbf{B}.\n\n(d) A is the scalar sum of all elements of \\mathbf{B}.\n\n(a) ✍ Prove that for real vectors \\mathbf{v} and \\mathbf{w} of the same length, the inner products \\mathbf{v}^T\\mathbf{w} and \\mathbf{w}^T\\mathbf{v} are equal.\n\n(b) ✍ Prove true, or give a counterexample for, the equivalent statement about outer products, \\mathbf{v}\\mathbf{w}^T and \\mathbf{w}\\mathbf{v}^T.\n\nThis aspect of our notation is slightly unusual. More frequently one would see the lowercase a_{24} in this context. We feel that our notation lends more consistency and clarity to expressions with mixed symbols, and it is more like how computer code is written.\n\nThe conjugate of a complex number is found by replacing all references to the imaginary unit i by -i.","type":"content","url":"/matrices#exercises","position":11},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-1","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The underlying theory for linear systems is covered in numerous linear algebra textbooks.  Some popular choices include those by Strang \n\nStrang (2016), Lay \n\nLay (2012), and Leon \n\nLeon (2006), but there are many other good choices.\n\nMore advanced texts specifically on numerical linear algebra include the classic texts by Trefethen and Bau \n\nTrefethen & III (1997) and Golub and Van Loan \n\nGolub & Van Loan (1996).\n\nNumerical analysis of the fundamental algorithms is emphasized in Higham \n\nHigham (2002); there are many interesting quotations there as well.  Here is a sample:\n\nMany years ago we made out of half a dozen transformers a simple and rather inaccurate machine for solving simultaneous equations—the solutions being represented as flux in the cores of the transformers.  During the course of our experiments we set the machine to solve the equations—\\begin{split}\n& X+Y+Z=1 \\\\\n& X+Y+Z=2 \\\\\n& X+Y+Z=3\n\\end{split}\n\nThe machine reacted sharply—it blew the main fuse and put all the lights out. (B. V. Bowden, The Organization of a Typical Machine, 1953)\n\nThe reader may find historical information on numerical linear algebra of interest at the SIAM website, \n\nhttp://​history​.siam​.org.  The materials include presentations, oral histories, articles and links on a wide range of topics in numerical analysis and scientific computing including numerical linear algebra.","type":"content","url":"/next-1","position":1},{"hierarchy":{"lvl1":"Vector and matrix norms"},"type":"lvl1","url":"/norms","position":0},{"hierarchy":{"lvl1":"Vector and matrix norms"},"content":"The manipulations on matrices and vectors so far in this chapter have been algebraic, much like those in an introductory linear algebra course. In order to progress to the analysis of the algorithms we have introduced, we need a way to measure the size of vectors and matrices—size in the sense of magnitude or distance, not the number of rows and columns.","type":"content","url":"/norms","position":1},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Vector norms"},"type":"lvl2","url":"/norms#vector-norms","position":2},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Vector norms"},"content":"For vectors, we use a norm \\| \\cdot \\|, which is a function from \\real^n to \\real with the following properties for all n-vectors \\mathbf{x},\\mathbf{y} and scalars α:\\begin{align*}\n\n\\norm{\\mathbf{x}} &\\ge 0, \\\\\n\\norm{\\mathbf{x}} &=0 \\;\\Leftrightarrow \\; \\mathbf{x}=\\boldsymbol{0}, \\\\\n\\norm{\\alpha \\mathbf{x}} &= \\abs{\\alpha}\\, \\norm{\\mathbf{x}}, \\\\\n\\norm{\\mathbf{x}+\\mathbf{y}} & \\le \\norm{\\mathbf{x}} + \\norm{\\mathbf{y}}.\n\\end{align*}\n\nThe last of these properties is known as the triangle inequality. It is natural to interpret \\| \\mathbf{x} \\|=\\| \\mathbf{x}-\\boldsymbol{0} \\| as the distance from \\mathbf{x} to the origin and \\| \\mathbf{x}-\\mathbf{y} \\| as the distance from \\mathbf{x} to \\mathbf{y}. We will be using only the three most important vector norms, defined as follows.\n\nCommon vector norms\n\n2-norm: \\quad \\twonorm{\\mathbf{x}} = \\left( \\displaystyle \\sum_{i=1}^n |x_i|^2 \\right)^{\\frac{1}{2}} = \\sqrt{\\rule[1mm]{0pt}{0.75em}\\mathbf{x}^T \\mathbf{x}}\n\n∞-norm or max-norm:  \\quad \\infnorm{ \\mathbf{x}} = \\displaystyle \\max_{i=1,\\dots,n} |x_i|\n\n1-norm: \\quad \\onenorm{\\mathbf{x}} = \\displaystyle \\sum_{i=1}^n |x_i| \n\nThe 2-norm corresponds to ordinary Euclidean distance.\n\nIn any norm, we refer to a vector \\mathbf{x} satisfying \\| \\mathbf{x} \\|=1 as a unit vector. For any nonzero vector \\mathbf{v} we can find a unit vector through the normalization \\mathbf{x}=\\mathbf{v}/\\|\\mathbf{v}\\|. Thus, we can interpret  \\mathbf{v} = \\| \\mathbf{v} \\| \\,\\cdot\\, \\frac{\\mathbf{v}}{\\| \\mathbf{v} \\|}\n\nas writing a nonzero vector \\mathbf{v} in magnitude–direction form.\n\nVector norms\n\nGiven the vector \\mathbf{x}= \\bigl[ 2 ,\\, -3 ,\\, 1 ,\\, -1 \\bigr]^T, we have\\begin{align*}\n    \\| \\mathbf{x} \\|_2 &= \\sqrt{ 4 + 9 + 1 + 1 } = \\sqrt{15}, \\\\[1ex]\n    \\| \\mathbf{x} \\|_\\infty &= \\max\\{ 2,3,1,1 \\} = 3,\\\\[1ex]\n    \\| \\mathbf{x} \\|_1 &= 2 + 3 + 1 + 1 = 7.\n\\end{align*}\n\nExample 2.7.1\n\nIn Julia the LinearAlgebra package has a norm function for vector norms.\n\nx = [2, -3, 1, -1]\ntwonorm = norm(x)         # or norm(x,2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nThere is also a normalize function that divides a vector by its norm, making it a unit vector.\n\nnormalize(x, Inf)\n\nExample 2.7.1\n\nx = [2; -3; 1; -1];\ntwonorm = norm(x)    % or norm(x, 2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nExample 2.7.1\n\nThe norm function from numpy.linalg computes vector norms.\n\nfrom numpy.linalg import norm\nx = array([2, -3, 1, -1])\nprint(norm(x))       # 2-norm by default\n\nprint(norm(x, inf))\n\nprint(norm(x, 1))\n\nNote\n\nMost of the time, when just \\| \\mathbf{x} \\| is written, the 2-norm is implied. However, in this section we use it to mean a generic, unspecified vector norm.\n\nWe say that a sequence of vectors \\mathbf{x}_1,\\mathbf{x}_2,\\ldots converges to \\mathbf{x} if  \\lim_{k\\rightarrow\\infty} \\norm{\\mathbf{x}_k - \\mathbf{x}} = 0.\n\nBy definition, a sequence is convergent in the infinity norm if and only if it converges componentwise. The same is true for a convergent sequence in any norm.\n\nNorm equivalence\n\nIn a finite-dimensional space, convergence in any norm implies convergence in all norms.","type":"content","url":"/norms#vector-norms","position":3},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Matrix norms"},"type":"lvl2","url":"/norms#matrix-norms","position":4},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Matrix norms"},"content":"Although we view matrices as two-dimensional, we can also interpret them as vectors: simply stack the columns on top of one another. Hence we can define matrix norms via vector norms. This is sometimes done with the vector 2-norm and leads to the matrix Frobenius norm:\\| \\mathbf{A} \\|_F = \\left( \\sum_{i,j} |A_{ij}|^2 \\right)^{1/2}. This is the norm computed by the `norm` function in Julia. \n\nHowever, it often proves to be more useful to define matrix norms differently.\n\nInduced matrix norm\n\nGiven a vector norm \\| \\cdot \\|_p, we define an induced matrix norm for any m\\times n matrix \\mathbf{A} as\\| \\mathbf{A} \\|_{p} = \\max_{\\| \\mathbf{x} \\|_p=1} \\| \\mathbf{A}\\mathbf{x} \\|_p =\n\\max_{\\mathbf{x}\\neq \\boldsymbol{0}} \\frac{\\| \\mathbf{A}\\mathbf{x} \\|_p}{\\| \\mathbf{x} \\|_p}.\n\nThe last equality above follows from linearity (as shown in \n\nExercise 5).  It is derived from the interpretation of a matrix as a linear operator between \\real^n and \\real^m. Thus in the 2-norm, for instance,\\| \\mathbf{A} \\|_2 = \\max_{\\| \\mathbf{x} \\|_2=1} \\| \\mathbf{A}\\mathbf{x} \\|_2.\n\nFor the rest of this section we will continue to omit subscripts when we want to refer to an unspecified induced norm; after this section, an unsubscripted norm is understood to be the 2-norm.\n\nThe definition of an induced matrix norm may seem oddly complicated. However, there are some key properties that follow directly from the definition.\n\nNorm inequalities\n\nLet \\| \\cdot \\| designate a matrix norm and the vector norm that induced it. Then for all matrices and vectors of compatible sizes,\\| \\mathbf{A}\\mathbf{x} \\| \\le \\| \\mathbf{A} \\|\\cdot \\| \\mathbf{x} \\|.\n\nFor all matrices of compatible sizes,\\| \\mathbf{A}\\mathbf{B} \\| \\le \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\|.\n\nFor a square matrix \\mathbf{A},\\| \\mathbf{A}^k \\| \\le \\| \\mathbf{A} \\|^k \\text{ for any integer $k\\ge 0$.}\n\nThe first result is trivial if \\mathbf{x}=\\boldsymbol{0}; otherwise,\\frac{ \\| \\mathbf{A}\\mathbf{x} \\| }{\\| \\mathbf{x} \\|} \\le\n\\max_{\\mathbf{x}\\neq \\boldsymbol{0}}  \\frac{\\| \\mathbf{A}\\mathbf{x} \\|}{\\| \\mathbf{x} \\|} = \\| \\mathbf{A} \\|.\n\nInequality \n\n(2.7.9) then follows because\\| \\mathbf{A}\\mathbf{B}\\mathbf{x} \\| =\\| \\mathbf{A}(\\mathbf{B}\\mathbf{x}) \\|\\le \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B}\\mathbf{x} \\| \\le\n\\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\|\\cdot\\| \\mathbf{x} \\|,\n\nand then\\| \\mathbf{A}\\mathbf{B} \\| = \\max_{\\mathbf{x}\\neq \\boldsymbol{0}} \\frac{\\| \\mathbf{A}\\mathbf{B}\\mathbf{x} \\|}{\\| \\mathbf{x} \\|} \\le\n\\max_{\\mathbf{x}\\neq \\boldsymbol{0}} \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\| = \\| \\mathbf{A} \\|\\cdot\\| \\mathbf{B} \\|.\n\nFinally,  \n\n(2.7.10) results from repeated application of \n\n(2.7.9).\n\nOne can interpret the definition of an induced norm geometrically.  Each vector \\mathbf{x} on the unit “sphere” (as defined by the chosen vector norm) is mapped to its image \\mathbf{A}\\mathbf{x}, and the norm of \\mathbf{A} is the radius of the smallest “sphere” that encloses all such images.\n\nIn addition, two of the vector norms we have encountered lead to equivalent formulas that are easy to compute from the matrix elements.\n\nMatrix ∞-norm and 1-norm\\| \\mathbf{A} \\|_\\infty = \\max_{1\\le \\,i \\,\\le n} \\sum_{j=1}^n |A_{ij}|,\\| \\mathbf{A} \\|_1 = \\max_{1\\le \\,j\\, \\le n} \\sum_{i=1}^n |A_{ij}|.\n\nA mnemonic for these is that the ∞ symbol extends horizontally while the 1 character extends vertically, each indicating the direction of the summation in its formula. Also, both formulas give the same result for m\\times 1 matrices as the vector norm. In both cases you must take absolute values of the matrix elements first.\n\nMatrix norms\n\nExample 2.7.2\n\nA = [ 2 0; 1 -1 ]\n\nIn Julia, one uses norm for vector norms and for the Frobenius norm of a matrix, which is like stacking the matrix into a single vector before taking the 2-norm.\n\nFronorm = norm(A)\n\nMost of the time we want to use opnorm, which is an induced matrix norm. The default is the 2-norm.\n\ntwonorm = opnorm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = opnorm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nTip\n\nUse sum to sum along a dimension of a matrix. You can also sum over the entire matrix by omitting the dims argument.\nThe maximum and minimum functions also work along one dimension or over an entire matrix. To get both values at once, use extrema.\n\n# Sum down the rows (1st matrix dimension):\nmaximum( sum(abs.(A), dims=1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = opnorm(A, Inf)\n\n # Sum across columns (2nd matrix dimension):\nmaximum( sum(abs.(A), dims=2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nTip\n\nYou can use functions as values, e.g., as elements of a vector.\n\n# Construct 601 unit column vectors.\nθ = 2π * (0:1/600:1)   # type \\theta then Tab\nx = [ fun(t) for fun in [cos, sin], t in θ ];\n\nTo create an array of plots, start with a plot that has a layout argument, then do subsequent plot! calls with a subplot argument.\n\nplot(aspect_ratio=1, layout=(1, 2),\n    xlabel=L\"x_1\",  ylabel=L\"x_2\")\nplot!(x[1, :], x[2, :], subplot=1, title=\"Unit circle\")\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse.\n\nplot!(Ax[1, :], Ax[2, :], \n    subplot=2, title=\"Image under x → Ax\")\n\nThat ellipse just touches the circle of radius \\|\\mathbf{A}\\|_2.\n\nplot!(twonorm*x[1, :], twonorm*x[2, :], subplot=2, l=:dash)\n\nExample 2.7.2\n\nA = [ 2 0; 1 -1 ]\n\nThe default matrix norm is the 2-norm.\n\ntwonorm = norm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = norm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nTip\n\nUse sum to sum along a dimension of a matrix. The max and min functions also work along one dimension.\n\n% Sum down the rows (1st matrix dimension):\nmax( sum(abs(A), 1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = norm(A, Inf)\n\n% Sum across columns (2nd matrix dimension):\nmax( sum(abs(A), 2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nTip\n\nYou can use functions as values, e.g., as elements of a vector.\n\ntheta = linspace(0, 2*pi, 601);\nx = [ cos(theta); sin(theta) ];    % 601 unit column vectors\nclf\nsubplot(1, 2, 1)\nplot(x(1, :), x(2, :)), axis equal\ntitle('Unit circle in 2-norm')\nxlabel('x_1')\nylabel(('x_2'));\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2:\n\nsubplot(1,2,2), plot(Ax(1,:), Ax(2,:)), axis equal\nhold on, plot(twonorm * x(1,:), twonorm * x(2,:), '--')\ntitle('Image of Ax, with ||A||')\nxlabel('x_1')\nylabel(('x_2'));\n\nExample 2.7.2\n\nfrom numpy.linalg import norm\nA = array([ [2, 0], [1, -1] ])\n\nThe default matrix norm is not the 2-norm. Instead, you must provide the 2 explicitly.\n\nprint(norm(A, 2))\n\nYou can get the 1-norm as well.\n\nprint(norm(A, 1))\n\nThe 1-norm is equivalent to\n\nprint(max( sum(abs(A), axis=0)) )  # sum down the rows\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\nprint(norm(A, inf))\n\nprint(max( sum(abs(A), axis=1)) )  # sum across columns\n\nHere we illustrate the geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\ntheta = linspace(0, 2*pi, 601)\nx = vstack([cos(theta), sin(theta)])  # 601 unit columns\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x simply by using a matrix multiplication.\n\ny = A @ x\n\nWe plot the unit circle on the left and the image of all mapped vectors on the right:\n\nsubplot(1,2,1)\nplot(x[0, :], x[1, :])\naxis(\"equal\")\ntitle(\"Unit circle\")\nxlabel(\"$x_1$\")\nylabel(\"$x_2$\")\n\nsubplot(1,2,2)\nplot(y[0, :], y[1, :])\nplot(norm(A, 2) * x[0, :], norm(A,2) * x[1, :],\"--\")\naxis(\"equal\")\ntitle(\"Image under map\")\nxlabel(\"$y_1$\")\nylabel(\"$y_2$\");\n\nAs seen on the right-side plot, the image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2.\n\nThe geometric interpretation of the matrix 2-norm shown in \n\nDemo 2.7.2, as the radius of the smallest circle (or sphere or hypersphere in higher dimensions) containing the images of all unit vectors, is not a practical means of computing the norm. Nor is there a simple formula like \n\n(2.7.14) or \n\n(2.7.15) for it. The computation of the matrix 2-norm is discussed further in Chapter 7.","type":"content","url":"/norms#matrix-norms","position":5},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Exercises"},"type":"lvl2","url":"/norms#exercises","position":6},{"hierarchy":{"lvl1":"Vector and matrix norms","lvl2":"Exercises"},"content":"✍ Why is the vector 1-norm also called the taxicab norm?\n\n✍ (a) Draw the unit “circle” in the ∞-norm, i.e., the set of all vectors \\mathbf{x}\\in\\real^2 such that \\| \\mathbf{x} \\|_\\infty=1.\n\n(b) Draw the unit “circle” in the 1-norm.\n\n✍ Prove that for all vectors \\mathbf{x}\\in\\real^n,\n\n(a) \\| \\mathbf{x} \\|_\\infty \\le \\| \\mathbf{x} \\|_2; \\qquad\n(b) \\| \\mathbf{x} \\|_2 \\le \\| \\mathbf{x} \\|_1.\n\n✍ Prove that for any vectors \\mathbf{x}, \\mathbf{y} in \\real^n, |\\mathbf{x}^T\\mathbf{y}| \\le \\| \\mathbf{x} \\|_1\\| \\mathbf{y} \\|_\\infty.\n\n✍ Prove using \n\nDefinition 2.7.2 that for any induced matrix norm, matrix \\mathbf{A}, and scalar c, \\| c\\mathbf{A} \\| = |c|\\cdot \\| \\mathbf{A} \\|.\n\n✍ Let \\mathbf{A} =\n \\displaystyle \\begin{bmatrix}\n   -1 & 1 \\\\ 2 & 2\n \\end{bmatrix}.\n\n(a) Find all vectors satisfying \\|\\mathbf{x}\\|_\\infty=1 and \\| \\mathbf{A}\\mathbf{x} \\|_\\infty=\\| \\mathbf{A} \\|_\\infty.\n\n(b) Find a vector satisfying \\|\\mathbf{x}\\|_1=1 and \\| \\mathbf{A}\\mathbf{x} \\|_1=\\| \\mathbf{A} \\|_1.\n\n(c) Find a vector satisfying \\|\\mathbf{x}\\|_2=1 such that \\| \\mathbf{A}\\mathbf{x} \\|_2=\\| \\mathbf{A} \\|_2. (Hint: A unit two-dimensional vector is a function only of its angle with the x_1-axis. Use the definition of \\|\\mathbf{A}\\|_2 as the maximum of \\|\\mathbf{A}\\mathbf{x}\\|_2, which is a also a function of the angle.)\n\n✍ Prove the equivalence of the two formulas for a matrix norm in \n\n(2.7.6).\n\n✍ Prove that for any induced matrix norm and nonsingular matrix \\mathbf{A}, \\| \\mathbf{A}^{-1} \\| \\ge (\\| \\mathbf{A} \\|)^{-1}. (Hint: Apply \n\nTheorem 2.7.2.)\n\n✍ (a) Prove that for any \\mathbf{v}\\in \\real^n,\\| \\mathbf{v} \\|_p \\ge \\max_{i=1,\\ldots,n} |v_i|,\n\nwhere p=1, 2, or ∞.\n\n(b) Prove that for any \\mathbf{A}\\in\\real^{n \\times n},\\| \\mathbf{A} \\|_p \\ge \\max_{i,j=1,\\ldots,n} |A_{ij}|,\n\nwhere p=1, 2, or ∞. (Hint: For p=2, rearrange \n\n(2.7.8) for a well-chosen particular value of \\mathbf{x}.)\n\n✍ Prove using \n\nDefinition 2.7.2 that if \\mathbf{D} is a diagonal matrix, then \\|\\mathbf{D}\\|_2 = \\max_{i} |D_{ii}|. You may assume the matrix is real and square, but that does not affect the result or the proof in any significant way. (Hint: Let M=\\max_{i} |D_{ii}|. Proceed in two stages, showing that \\|\\mathbf{D}\\|_2\\ge M and separately that \\|\\mathbf{D}\\|_2\\le M.)\n\n✍ Suppose that \\mathbf{A} is {n\\times n} and that \\| \\mathbf{A} \\|<1 in some induced matrix norm.\n\n(a) Show that (\\mathbf{I}-\\mathbf{A}) is nonsingular. (Hint: Use the definition of an induced matrix norm to show that if (\\mathbf{I}-\\mathbf{A})\\mathbf{x}=\\boldsymbol{0} for all nonzero \\mathbf{x}, then \\| \\mathbf{A} \\|\\ge 1.)\n\n(b) Show that \\lim_{m\\rightarrow \\infty} \\mathbf{A}^m = \\boldsymbol{0}. (For matrices as with vectors, we say \\mathbf{B}_m \\rightarrow \\mathbf{L} if \\| \\mathbf{B}_m-\\mathbf{L} \\| \\rightarrow 0.)\n\n(c) Use (a) and (b) to show that we may obtain the geometric series(\\mathbf{I}-\\mathbf{A})^{-1} = \\sum_{k=0}^\\infty \\mathbf{A}^k.\n\n(Hint: Start with \\left(\\sum_{k=0}^m \\mathbf{A}^k\\right)(\\mathbf{I}-\\mathbf{A}) and take the limit.)\n\nThe same statements work for vectors with complex entries, with complex modulus in place of absolute values.\n\nColumn stacking is actually how matrices are stored in memory within Julia and is known as column-major order. MATLAB and FORTRAN also use column-major order, while C and Python use row-major order, in which the rows are stacked.","type":"content","url":"/norms#exercises","position":7},{"hierarchy":{"lvl1":"2. Linear systems of equations"},"type":"lvl1","url":"/overview-1","position":0},{"hierarchy":{"lvl1":"2. Linear systems of equations"},"content":"It’s all a lot of simple tricks and nonsense.\n\nHan Solo, Star Wars: A New Hope\n\nOne of the most frequently encountered tasks in scientific computation is the solution of the linear system of equations \\mathbf{A} \\mathbf{x}=\\mathbf{b} for a given square matrix \\mathbf{A} and vector \\mathbf{b}.  This problem can be solved in a finite number of steps, using an algorithm equivalent to Gaussian elimination. Describing the algorithm is mostly an exercise in organizing some linear algebra.\n\nAnalyzing the algorithm requires new tools. Because the computations will take place in floating point, we must first discuss a system for measuring the “size” of a perturbation to a vector or matrix data. Once that is understood, we find that the conditioning of the square linear system problem is quite straightforward to describe. Finally, we will see that the algorithm may change when certain things are known about the matrix \\mathbf{A}.","type":"content","url":"/overview-1","position":1},{"hierarchy":{"lvl1":"Row pivoting"},"type":"lvl1","url":"/pivoting","position":0},{"hierarchy":{"lvl1":"Row pivoting"},"content":"As mentioned in \n\nLU factorization, the \\mathbf{A}=\\mathbf{L}\\mathbf{U} factorization is not stable for every nonsingular \\mathbf{A}. Indeed, the factorization does not always even exist.\n\nFailure of naive LU factorization\n\nExample 2.6.1\n\nHere is a previously encountered matrix that factors well.\n\nA = [2 0 4 3 ; -4 5 -7 -10 ; 1 15 2 -4.5 ; -2 0 2 -13];\nL, U = FNC.lufact(A)\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[2, 4], :] = A[[4, 2], :]  \nL, U = FNC.lufact(A)\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[1, :] = A[1, :]\nL[:, 1] = A[:, 1] / U[1, 1]\nA -= L[:, 1] * U[1, :]'\n\nThe next step is U[2, :] = A[2, :], which is also OK. But then we are supposed to divide by U[2, 2], which is zero. The algorithm cannot continue.\n\nExample 2.6.1\n\nHere is a previously encountered matrix that factors well.\n\nA = [\n    2 0 4 3\n    -4 5 -7 -10\n    1 15 2 -4.5\n    -2 0 2 -13\n    ];\n[L, U] = lufact(A);\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA([2, 4], :) = A([4, 2], :);    % swap rows 2 and 4\n[L, U] = lufact(A);\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU(1, :) = A(1, :);\nL(:, 1) = A(:, 1) / U(1, 1)\nA = A - L(:, 1) * U(1, :)\n\nThe next step is U(2, :) = A(2, :), which is also OK. But then we are supposed to divide by U(2, 2), which is zero. The algorithm cannot continue.\n\nExample 2.6.1\n\nHere is a previously encountered matrix that factors well.\n\nA = array([\n    [2, 0, 4, 3],\n    [-4, 5, -7, -10],\n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nL, U = FNC.lufact(A)\nprint(L)\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[1, 3], :] = A[[3, 1], :]  \nL, U = FNC.lufact(A)\nprint(L)\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[0, :] = A[0, :]\nL[:, 0] = A[:, 0] / U[0, 0]\nA -= outer(L[:, 0],  U[0, :])\nprint(A)\n\nThe next step is U[1, :] = A[1, :], which is also OK. But then we are supposed to divide by U[1, 1], which is zero. The algorithm cannot continue.\n\nIn \n\nLU factorization we remarked that LU factorization is equivalent to Gaussian elimination with no row swaps. However, those swaps are necessary in situations like those encountered in \n\nDemo 2.6.1, in order to avoid division by zero. We will find a modification of the outer product procedure that allows us to do the same thing.","type":"content","url":"/pivoting","position":1},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Choosing a pivot"},"type":"lvl2","url":"/pivoting#choosing-a-pivot","position":2},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Choosing a pivot"},"content":"The diagonal element of \\mathbf{U} that appears in the denominator of line 17 of \n\nFunction 2.4.1 is called the pivot element of its column. In order to avoid a zero pivot, we will use the largest available element in the column we are working on as the pivot. This technique is known as row pivoting.\n\nRow pivoting\n\nWhen performing elimination in column j, choose as the pivot the element in column j that is largest in absolute value. (In case of ties, choose the lowest row index.)\n\nRow pivoting in LU factorization\n\nExample 2.6.2\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA₁ = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nTip\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs.(A₁[:, 1]) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = zeros(4,4),zeros(4,4)\nU[1, :] = A₁[i, :]\nL[:, 1] = A₁[:, 1] / U[1, 1]\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n@show i = argmax( abs.(A₂[:, 2]) ) \nU[2, :] = A₂[i, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n@show i = argmax( abs.(A₃[:, 3]) ) \nU[3, :] = A₃[i, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\n@show i = argmax( abs.(A₄[:, 4]) ) \nU[4, :] = A₄[i, :]\nL[:, 4] = A₄[:, 4] / U[4, 4];\n\nWe do have a factorization of the original matrix:\n\nA₁ - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nExample 2.6.2\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nTip\n\nThe second output of max returns the location of the largest element of a vector. The ~ symbol is used to ignore the value of the first output.\n\n[~, i] = max( abs(A_1(:, 1)) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL = zeros(4, 4);\nU = zeros(4, 4);\nU(1, :) = A_1(i, :);\nL(:, 1) = A_1(:, 1) / U(1, 1);\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n[~, i] = max( abs(A_2(:, 2)) )\nU(2, :) = A_2(i, :);\nL(:, 2) = A_2(:, 2) / U(2, 2);\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n[~, i] = max( abs(A_3(:, 3)) ) \nU(3, :) = A_3(i, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\n[~, i] = max( abs(A_4(:, 4)) ) \nU(4, :) = A_4(i, :);\nL(:, 4) = A_4(:, 4) / U(4, 4);\n\nWe do have a factorization of the original matrix:\n\nA_1 - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nExample 2.6.2\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nTip\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs(A_1[:, 0]) )\nprint(i)\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = eye(4), zeros((4, 4))\nU[0, :] = A_1[i, :]\nL[:, 0] = A_1[:, 0] / U[0, 0]\nA_2 = A_1 - outer(L[:, 0], U[0, :])\nprint(A_2)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\ni = argmax( abs(A_2[:, 1]) ) \nprint(f\"new pivot row is {i}\")\nU[1, :] = A_2[i, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nA_3 = A_2 - outer(L[:, 1], U[1, :])\nprint(A_3)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\ni = argmax( abs(A_3[:, 2]) ) \nprint(f\"new pivot row is {i}\")\nU[2, :] = A_3[i, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\nprint(A_4)\n\ni = argmax( abs(A_4[:, 3]) ) \nprint(f\"new pivot row is {i}\")\nU[3, :] = A_4[i, :]\nL[:, 3] = A_4[:, 3] / U[3, 3];\n\nWe do have a factorization of the original matrix:\n\nA_1 - L @ U\n\nAnd \\mathbf{U} has the required structure:\n\nprint(U)\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nprint(L)\n\nWe will return to the loss of triangularity in \\mathbf{L} momentarily. First, though, there is a question left to answer: what if at some stage, all the elements of the targeted column are zero, i.e., there are no available pivots? Fortunately that loose end ties up nicely, although a proof is a bit beyond our scope here.\n\nRow pivoting\n\nThe row-pivoted LU factorization runs to completion if and only if the original matrix is invertible.\n\nA linear system with a singular matrix has either no solution or infinitely many solutions. Either way, a technique other than LU factorization is needed to handle it.","type":"content","url":"/pivoting#choosing-a-pivot","position":3},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Permutations"},"type":"lvl2","url":"/pivoting#permutations","position":4},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Permutations"},"content":"Even though the resulting \\mathbf{L} in \n\nDemo 2.6.2 is no longer of unit lower triangular form, it is close. In fact, all that is needed is to reverse the order of its rows.\n\nPivoting as row permutation\n\nExample 2.6.3\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1. If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A[[4, 3, 2, 1], :]\nL, U = FNC.lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nU\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nL\n\nExample 2.6.3\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1. If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A([4, 3, 2, 1], :);\n[L, U] = lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nU\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nL\n\nExample 2.6.3\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1 (with NumPy indices being one less). If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A[[3, 2, 1, 0], :]\nL, U = FNC.lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nprint(U)\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nprint(L)\n\nIn principle, if the permutation of rows implied by the pivot locations is applied all at once to the original \\mathbf{A}, no further pivoting is needed. In practice, this permutation cannot be determined immediately from the original \\mathbf{A}; the only way to find it is to run the algorithm. Having obtained it at the end, though, we can use it to state a simple relationship.\n\nPLU factorization\n\nGiven n\\times n matrix \\mathbf{A}, the PLU factorization is a unit lower triangular \\mathbf{L}, an upper triangular \\mathbf{U}, and a permutation i_1,\\ldots,i_n of the integers 1,\\ldots,n, such that\\tilde{\\mathbf{A}} = \\mathbf{L}\\mathbf{U},\n\nwhere rows 1,\\ldots,n of \\tilde{\\mathbf{A}} are rows i_1,\\ldots,i_n of \\mathbf{A}.\n\nFunction 2.6.2 shows our implementation of PLU factorization.\n\nplufact\n\nLU factorization with partial pivoting\n\n\"\"\"\n    plufact(A)\n\nCompute the PLU factorization of square matrix `A`, returning the\ntriangular factors and a row permutation vector.\n\"\"\"\nfunction plufact(A)\n    n = size(A, 1)\n    L = zeros(n, n)\n    U = zeros(n, n)\n    p = fill(0, n)\n    Aₖ = float(copy(A))\n\n    # Reduction by outer products\n    for k in 1:n\n        p[k] = argmax(abs.(Aₖ[:, k]))    # best pivot in column k\n        U[k, :] = Aₖ[p[k], :]\n        L[:, k] = Aₖ[:, k] / U[k, k]\n        if k < n    # no update needed on last iteration\n            Aₖ -= L[:, k] * U[k, :]'\n        end\n    end\n    return LowerTriangular(L[p, :]), U, p\nend\n\nLU factorization with partial pivoting\n\n\"\"\"\n    plufact(A)\n\nCompute the PLU factorization of square matrix `A`, returning the\ntriangular factors and a row permutation vector.\n\"\"\"\nfunction plufact(A)\n    n = size(A, 1)\n    L = zeros(n, n)\n    U = zeros(n, n)\n    p = fill(0, n)\n    Aₖ = float(copy(A))\n\n    # Reduction by outer products\n    for k in 1:n\n        p[k] = argmax(abs.(Aₖ[:, k]))    # best pivot in column k\n        U[k, :] = Aₖ[p[k], :]\n        L[:, k] = Aₖ[:, k] / U[k, k]\n        if k < n    # no update needed on last iteration\n            Aₖ -= L[:, k] * U[k, :]'\n        end\n    end\n    return LowerTriangular(L[p, :]), U, p\nend\n\nLU factorization with partial pivoting\n\ndef plufact(A):\n    \"\"\"\n        plufact(A)\n\n    Compute the PLU factorization of square matrix A, returning the\n    triangular factors and a row permutation vector.\n    \"\"\"\n    n = A.shape[0]\n    L = np.zeros((n, n))\n    U = np.zeros((n, n))\n    p = np.zeros(n, dtype=int)\n    A_k = np.copy(A)\n\n    # Reduction by np.outer products\n    for k in range(n):\n        p[k] = np.argmax(abs(A_k[:, k]))\n        U[k, :] = A_k[p[k], :]\n        L[:, k] = A_k[:, k] / U[k, k]\n        if k < n-1:\n            A_k -= np.outer(L[:, k], U[k, :])\n    return L[p, :], U, p\n\nIdeally, the PLU factorization takes \\sim \\frac{2}{3}n^3 flops asymptotically, just like LU without pivoting. The implementation in \n\nFunction 2.6.2 does not achieve this optimal flop count, however. Like \n\nFunction 2.4.1, it does unnecessary operations on structurally known zeros for the sake of being easier to understand.","type":"content","url":"/pivoting#permutations","position":5},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Linear systems"},"type":"lvl2","url":"/pivoting#linear-systems","position":6},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Linear systems"},"content":"The output of \n\nFunction 2.6.2 is a factorization of a row-permuted \\mathbf{A}. Therefore, given a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, we have to permute \\mathbf{b} the same way before applying forward and backward substitution. This is equivalent to changing the order of the equations in a linear system, which does not affect its solution.\n\nPLU factorization for solving linear systems\n\nExample 2.6.4\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = rand(1:20, 4, 4)\nL, U, p = FNC.plufact(A)\nA[p,:] - L * U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4)\nz = FNC.forwardsub(L,b[p])\nx = FNC.backsub(U,z)\n\nA residual check is successful:\n\nb - A*x\n\nExample 2.6.4\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = randi(20, 4, 4);\n[L, U, p] = plufact(A);\nA(p, :) - L * U    % should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4, 1);\nz = forwardsub(L, b(p));\nx = backsub(U, z)\n\nA residual check is successful:\n\nb - A*x\n\nExample 2.6.4\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = random.randn(4, 4)\nL, U, p = FNC.plufact(A)\nA[p, :] - L @ U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = random.randn(4)\nz = FNC.forwardsub(L, b[p])\nx = FNC.backsub(U, z)\n\nA residual check is successful:\n\nb - A @ x\n\nThe lu function from the built-in package LinearAlgebra returns the same three outputs as \n\nFunction 2.6.2. If you only request one output, it will be a factorization object that can be used with a backslash. This is useful when you want to solve with multiple versions of \\mathbf{b} but do the factorization only once.\n\nBuilt-in PLU factorization\n\nExample 2.6.5\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500)   # 500x500 with normal random entries\nA \\ rand(500)          # force compilation\n@elapsed for k=1:50; A \\ rand(500); end\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\nfactored = lu(A)     # store factorization result\nfactored \\ rand(500)   # force compilation\n@elapsed for k=1:50; factored \\ rand(500); end\n\nExample 2.6.5\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500);    % 500x500 with normal random entries\ntic; for k=1:50; A \\ rand(500, 1); end; toc\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\n[L, U, p] = lu(A, 'vector');    % keep factorization result\ntic\nfor k=1:50\n    b = rand(500, 1);\n    U \\ (L \\ b(p));\nend\ntoc\n\nExample 2.6.5\n\nIn linalg.solve, the matrix A is PLU-factored, followed by two triangular solves. If we want to do those steps seamlessly, we can use the lu_factor and lu_solve from scipy.linalg.\n\nfrom scipy.linalg import lu_factor, lu_solve\nA = random.randn(500, 500) \nb = ones(500)  \nLU, perm = lu_factor(A)\nx = lu_solve((LU, perm), b)\n\nWhy would we ever bother with this? In \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per matrix, but solve with multiple right-hand sides.\n\nstart = timer()\nfor k in range(50): linalg.solve(A, random.rand(500))\nprint(f\"elapsed time for 50 full solves: {timer() - start}\")\n\nstart = timer()\nLU, perm = lu_factor(A)\nfor k in range(50): lu_solve((LU, perm), random.rand(500))\nprint(f\"elapsed time for 50 shortcut solves: {timer() - start}\")","type":"content","url":"/pivoting#linear-systems","position":7},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Stability"},"type":"lvl2","url":"/pivoting#stability","position":8},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Stability"},"content":"There is one detail of the row pivoting algorithm that might seem arbitrary: why choose the pivot of largest magnitude in a column, rather than, say, the uppermost nonzero in the column? The answer is numerical stability.\n\nStability of PLU factorization\n\nLet\\mathbf{A} =\n  \\begin{bmatrix}\n    -\\epsilon & 1 \\\\ 1 & -1\n  \\end{bmatrix}.\n\nIf \\epsilon=0, LU factorization without pivoting fails for \\mathbf{A}. But if \\epsilon\\neq 0, we can go without pivoting, at least in principle.\n\nExample 2.6.6\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nϵ = 1e-12\nA = [-ϵ 1; 1 -1]\nb = A * [1, 1]\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nϵ = 1e-20; A = [-ϵ 1; 1 -1]\nb = A * [1, 1]\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b\n\nExample 2.6.6\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1, 1]:\n\nep = 1e-12\nA = [-ep 1; 1 -1];\nb = A * [1; 1];\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20; A = [-ep 1; 1 -1];\nb = A * [1; 1];\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b\n\nExample 2.6.6\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nep = 1e-12\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20;\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nprint(linalg.solve(A, b))\n\nThe factors of this \\mathbf{A} without pivoting are found to be  \\mathbf{L} = \n  \\begin{bmatrix}\n    1 & 0 \\\\ -\\epsilon^{-1} & 1 \n  \\end{bmatrix}, \\qquad \n  \\mathbf{U} = \n  \\begin{bmatrix}\n    -\\epsilon & 1 \\\\ 0 & \\epsilon^{-1}-1 \n  \\end{bmatrix}.\n\nFor reasons we will quantify in \n\nConditioning of linear systems, the solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b} is well-conditioned, but the problems of solving \\mathbf{L}\\mathbf{z}=\\mathbf{b} and \\mathbf{U}\\mathbf{x}=\\mathbf{z} have condition numbers essentially 1/\\epsilon^2 each. Thus, for small ε, solution of the original linear system by unpivoted LU factorization is highly unstable.\n\nSomewhat surprisingly, solving \\mathbf{A}\\mathbf{x}=\\mathbf{b} via PLU factorization is technically also unstable. In fact, examples of unstable solutions are well-known, but they have been nonexistent in practice. While there is a lot of evidence and some reasoning about why this is the case, the situation is not completely understood. Yet PLU factorization remains the algorithm of choice for general linear systems.","type":"content","url":"/pivoting#stability","position":9},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Exercises"},"type":"lvl2","url":"/pivoting#exercises","position":10},{"hierarchy":{"lvl1":"Row pivoting","lvl2":"Exercises"},"content":"✍ Perform by hand the pivoted LU factorization of each matrix.\n\n(a) \\quad \\displaystyle \\begin{bmatrix}\n 2 & 3 & 4 \\\\\n 4 & 5 & 10 \\\\\n 4 & 8 & 2\n \\end{bmatrix},\\qquad\n(b) \\quad \\displaystyle \\begin{bmatrix}\n 1 & 4 & 5 & -5 \\\\\n -1 & 0 & -1 & -5 \\\\\n 1 & 3 & -1 & 2 \\\\\n 1 & -1 & 5 & -1 \n \\end{bmatrix}.\n\n✍ Let \\mathbf{A} be a square matrix and \\mathbf{b} be a column vector of compatible length. Here is correct Julia code to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}:L,U,p = lu(A)\nx = U \\ (L\\b[p])\n\nSuppose instead you replace the last line above withx = U \\ L \\ b[p]\n\nMathematically in terms of \\mathbf{L}, \\mathbf{U}, \\mathbf{p}, and \\mathbf{b}, what vector is found?\n\n✍ Suppose that A is a 4\\times 6 matrix in Julia and you defineB = A[end:-1:1,end:-1:1]\n\nShow that \\mathbf{B} = \\mathbf{P} \\mathbf{A} \\mathbf{Q} for certain matrices \\mathbf{P} and \\mathbf{Q}.\n\n✍ An n\\times n permutation matrix \\mathbf{P} is a reordering of the rows of an identity matrix such that \\mathbf{P} \\mathbf{A}  has the effect of moving rows 1,2,\\ldots,n of \\mathbf{A} to new positions i_1,i_2,\\ldots,i_n. Then \\mathbf{P} can be expressed as\\mathbf{P} = \\mathbf{e}_{i_1}\\mathbf{e}_1^T + \\mathbf{e}_{i_2}\\mathbf{e}_2^T + \\cdots + \\mathbf{e}_{i_n}\\mathbf{e}_n^T.\n\n(a) For the case n=4 and i_1=3, i_2=2, i_3=4, i_4=1, write out separately, as matrices, all four of the terms in the sum. Then add them together to find \\mathbf{P}.\n\n(b) Use the formula in the general case to show that \\mathbf{P}^{-1}=\\mathbf{P}^T.\n\nBecause unpivoted LU factorization is not useful, in practice the term LU factorization mostly refers to pivoted LU.","type":"content","url":"/pivoting#exercises","position":11},{"hierarchy":{"lvl1":"Polynomial interpolation"},"type":"lvl1","url":"/polyinterp","position":0},{"hierarchy":{"lvl1":"Polynomial interpolation"},"content":"The United States carries out a census of its population every 10 years. Suppose we want to know the population at times in between the census years, or to estimate future populations. One technique is to find a polynomial that passes through all of the data points.\n\nPolynomial interpolation\n\nGiven n points (t_1,y_1),\\ldots,(t_n,y_n), where the t_i are all distinct, the polynomial interpolation problem is to find a polynomial p of degree less than n such that p(t_i)=y_i for all i.\n\nAs posed in \n\nDefinition 2.1.1, the polynomial interpolation problem has a unique solution. Once the interpolating polynomial is found, it can be evaluated anywhere to estimate or predict values.","type":"content","url":"/polyinterp","position":1},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Interpolation as a linear system"},"type":"lvl2","url":"/polyinterp#interpolation-as-a-linear-system","position":2},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Interpolation as a linear system"},"content":"Given data (t_i,y_i) for i=1,\\ldots,n, we seek a polynomialp(t) = c_1 + c_{2} t + c_3t^2 +  \\cdots + c_{n} t^{n-1},\n\nsuch that y_i=p(t_i) for all i. These conditions are used to determine the coefficients c_1\\ldots,c_n:\\begin{split}\n c_1 + c_2 t_1 + \\cdots + c_{n-1}t_1^{n-2} + c_nt_1^{n-1} &= y_1, \\\\\n c_1 + c_2 t_2 + \\cdots + c_{n-1}t_2^{n-2} + c_nt_2^{n-1} &= y_2, \\\\\n c_1 + c_2 t_3 + \\cdots + c_{n-1}t_3^{n-2} + c_nt_3^{n-1} &= y_3, \\\\\n \\vdots \\qquad & \\\\\n c_1 + c_2 t_n + \\cdots + c_{n-1}t_n^{n-2} + c_nt_n^{n-1} &= y_n.\n \\end{split}\n\nThese equations form a linear system for the coefficients c_i:  \\begin{bmatrix}\n    1 & t_1 & \\cdots & t_1^{n-2} & t_1^{n-1} \\\\\n    1 & t_2 & \\cdots & t_2^{n-2} & t_2^{n-1} \\\\\n    1 & t_3 & \\cdots & t_3^{n-2} & t_3^{n-1} \\\\\n    \\vdots & \\vdots &  & \\vdots & \\vdots \\\\\n    1 & t_n & \\cdots & t_n^{n-2} & t_n^{n-1} \\\\\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    c_1  \\\\\n    c_2  \\\\\n    c_3 \\\\\n    \\vdots \\\\\n    c_n\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    y_1  \\\\\n    y_2  \\\\\n    y_3 \\\\\n    \\vdots \\\\\n    y_n\n  \\end{bmatrix},\n\nor more simply, \\mathbf{V} \\mathbf{c} = \\mathbf{y}. The matrix \\mathbf{V} is of a special type.\n\nVandermonde matrix\n\nGiven distinct values t_1,\\ldots,t_n, a Vandermonde matrix for these values is the n\\times n matrix appearing in \n\n(2.1.3).\n\nPolynomial interpolation can therefore be posed as a linear system of equations with a Vandermonde matrix.\n\nLinear system for polynomial interpolation\n\nAttention\n\nRecall that the demos in this and later chapters omit the statementusing FundamentalsNumericalComputation\n\nthat is needed to run some of the statements.\n\nExample 2.1.1\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982, 2000, 2010, 2015]; \npop = [1008.18, 1262.64, 1337.82, 1374.62];\n\nIt’s convenient to measure time in years since 1980. We use .- to subtract a scalar from every element of a vector. We will also use a floating-point value in the subtraction, so the result is also in double precision.\n\nTip\n\nA dotted operator such as .- or .* acts elementwise, broadcasting scalar values to match up with elements of an array.\n\nt = year .- 1980.0\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nTip\n\nAn expression inside square brackets and ending with a for statement is called a comprehension. It’s often an easy and readable way to construct vectors and matrices.\n\nV = [ t[i]^j for i in 1:4, j in 0:3 ]\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nTip\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V * c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in ascending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\nTip\n\nThe Polynomials package has functions to make working with polynomials easy and efficient.\n\nusing Polynomials\np = Polynomial(c)    # construct a polynomial\np(2005-1980)         # include the 1980 time shift\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nTip\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nusing Plots\nscatter(t, y;\n    label=\"actual\",  legend=:topleft,\n    xlabel=\"years since 1980\",  ylabel=\"population (millions)\", \n    title=\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval. The dot after the name of the polynomial is a universal way to apply a function to every element of an array, a technique known as broadcasting.\n\nThe range function constructs evenly spaced values given the endpoints and either the number of values, or the step size between them.\n\nAdding a dot to the end of a function name causes it to be broadcast, i.e., applied to every element of a vector or matrix.\n\n# Choose 500 times in the interval [0,35].\ntt = range(0, 35, 500)\n\n# Evaluate the polynomial at all the vector components.\nyy = p.(tt)\n\nforeach(println, yy[1:4])\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nTip\n\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\nBy convention, functions whose names end with the bang ! change the value or state of something, in addition to possibly returning output.\n\nplot!(tt, yy, label=\"interpolant\")\n\nExample 2.1.1\n\nWe create two column vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982; 2000; 2010; 2015]; \npop = [1008.18; 1262.64; 1337.82; 1374.62];\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980;\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nTip\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V * c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in descending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\np = @(t) polyval(c, t - 1980);  % include the 1980 time shift\np(2005)\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nTip\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nscatter(year, y)\nxlabel(\"years since 1980\")\nylabel(\"population (millions)\")\ntitle(\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval.\n\nTip\n\nThe linspace function constructs evenly spaced values given the endpoints and the number of values.\n\ntt = linspace(1980, 2015, 500);    % 500 times in the interval [1980, 2015]\nyy = p(tt);                        % evaluate p at all the vector elements\nyy(1:4)\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nTip\n\nUse hold on to add to an existing plot rather than replacing it.\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\n\nhold on \nplot(tt, yy)\nlegend(\"data\", \"interpolant\", \"location\", \"northwest\");\n\nExample 2.1.1\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = arange(1980, 2020, 10)   # from 1980 to 2020 by 10\npop = array([984.736, 1148.364, 1263.638, 1330.141])\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980\ny = pop\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\nprint(V)\n\nTo solve a linear system \\mathbf{V} \\mathbf{c} = \\mathbf{y} for the vector of polynomial coefficients, we use solve (imported from numpy.linalg):\n\nc = linalg.solve(V, y)\nprint(c)\n\nThe algorithms used by solve are the main topic of this chapter. As a check on the solution, we can compute the residual \\mathbf{y} - \\mathbf{V} \\mathbf{c}, which should be small (near machine precision).\n\nTip\n\nMatrix multiplication in NumPy is done with @ or matmul.\n\nprint(y - V @ c)\n\nBy our definitions, the coefficients in c are given in descending order of power in t. We can use the resulting polynomial to estimate the population of China in 2005:\n\np = poly1d(c)          # construct a polynomial\nprint(p(2005 - 1980))     # apply the 1980 time shift\n\nThe official figure was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points. Then we add a plot of the interpolant, taking care to shift the t variable back to actual years.\n\nscatter(year, y, color=\"k\", label=\"data\");\ntt = linspace(0, 30, 300)   # 300 times from 1980 to 2010\nplot(1980 + tt, p(tt), label=\"interpolant\");\nxlabel(\"year\");\nylabel(\"population (millions)\");\ntitle(\"Population of China\");\nlegend();","type":"content","url":"/polyinterp#interpolation-as-a-linear-system","position":3},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/polyinterp#exercises","position":4},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Exercises"},"content":"Suppose you want to interpolate the points (-1,0), (0,1), (2,0), (3,1), and (4,2) by a polynomial of as low a degree as possible.\n\n(a) ✍ What is the maximum necessary degree of this polynomial?\n\n(b) ✍ Write out a linear system of equations for the coefficients of the interpolating polynomial.\n\n(c) ⌨ Solve the system in (b) numerically.\n\n(a) ✍ Say you want to find a cubic polynomial p such that p(-1) =-2, p'(-1) =1, p(1) = 0, and p'(1) =-1. (This is known as a Hermite interpolant.) Write out a linear system of equations for the coefficients of p.\n\n(b) ⌨ Numerically solve the linear system in part (a) and make a plot of p over -1 \\le x \\le 1.\n\n⌨ Here are population figures (in millions) for three countries over a 30-year period (from United Nations World Population Prospects, 2019).\n\n\n\n1990\n\n2000\n\n2010\n\n2020\n\nUnited States\n\n252.120\n\n281.711\n\n309.011\n\n331.003\n\nIndia\n\n873.278\n\n1,056.576\n\n1,234.281\n\n1,380.004\n\nPoland\n\n37.960\n\n38.557\n\n38.330\n\n37.847\n\n(a) Use cubic polynomial interpolation to estimate the population of the USA in 2005.\n\n(b) Use cubic polynomial interpolation to estimate when the population of Poland peaked during this time period.\n\n(c) Use cubic polynomial interpolation to make a plot of the Indian population over this period. Your plot should be well labeled and show a smooth curve as well as the original data points.\n\n⌨ Here are the official population figures for the state of Delaware, USA, every ten years from 1790 to 1900: 59096, 64273, 72674, 72749, 76748, 78085, 91532, 112216, 125015, 146608, 168493, 184735. For this problem, uset = \\frac{\\text{year} - 1860}{10}\n\nas the independent (time) variable.\n\n(a) Using only the data from years 1860 to 1900, plot the interpolating polynomial over the same range of years. Add the original data points to your plot as well.\n\n(b) You might assume that adding more data will make the interpolation better. But this is not always the case. Use all the data above to create an interpolating polynomial of degree 11, and then plot that polynomial over the range 1860 to 1900. In what way is this fit clearly inferior to the previous one? (This phenomenon is studied in \n\nChapter 9.)\n\nWe’re quite certain that the U.S. Census Bureau uses more sophisticated modeling techniques than the one we present here!","type":"content","url":"/polyinterp#exercises","position":5},{"hierarchy":{"lvl1":"Exploiting matrix structure"},"type":"lvl1","url":"/structure","position":0},{"hierarchy":{"lvl1":"Exploiting matrix structure"},"content":"A common situation in computation is that a problem has certain properties or structure that can be used to get a faster or more accurate solution. There are many properties of a matrix that can affect LU factorization. For example, an n \\times n matrix A is diagonally dominant if  |A_{ii}| > \\sum_{\\substack{j=1\\\\ j \\neq i}}^{n} |A_{ij}| \\hskip 0.25in \\text{for each } i=1,\\ldots,n.\n\nIt turns out that a diagonally dominant matrix is guaranteed to be invertible, and row pivoting is not required for stability.\n\nWe next consider three important types of matrices that cause the LU factorization to be specialized in some important way.","type":"content","url":"/structure","position":1},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Banded matrices"},"type":"lvl2","url":"/structure#banded-matrices","position":2},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Banded matrices"},"content":"Bandwidth\n\nA matrix \\mathbf{A} has upper bandwidth b_u if j-i > b_u implies A_{ij}=0, and lower bandwidth b_\\ell if i-j > b_\\ell implies A_{ij}=0. We say the total bandwidth is b_u+b_\\ell+1. When b_u=b_\\ell=1, we have the important case of a tridiagonal matrix.\n\nBanded matrices\n\nExample 2.9.1\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nTip\n\nUse fill to create an array of a given size, with each element equal to a provided value.\n\nA = diagm( -1 => [4, 3, 2, 1, 0], \n    0 => [2, 2, 0, 2, 1, 2], \n    1 => fill(-1, 5) )\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nTip\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\n@show diag_main = diag(A);\n@show diag_minusone = diag(A, -1);\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\nL, U = FNC.lufact(A)\nL\n\nU\n\nExample 2.9.1\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nA = [ 2 -1  0  0  0  0\n      4  2 -1  0  0  0\n      0  3  0 -1  0  0\n      0  0  2  2 -1  0\n      0  0  0  1  1 -1\n      0  0  0  0  0  2 ];\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nTip\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\ndiag_main = diag(A, 0)'\ndiag_plusone = diag(A, 1)'\ndiag_minusone = diag(A,-1)'We can also put whatever numbers we like onto any diagonal with `diag`.\n\nA = A + diag([5 8 6 7], 2)\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\n[L, U] = lufact(A)\n\nExample 2.9.1\n\nHere is a matrix with both lower and upper bandwidth equal to one. Such a matrix is called tridiagonal.\n\nA = array([ \n    [2, -1,  0,  0,  0,  0],\n    [4,  2, -1,  0,  0,  0],\n    [0,  3,  0, -1,  0,  0],\n    [0,  0,  2,  2, -1,  0],\n    [0,  0,  0,  1,  1, -1],\n    [0,  0,  0,  0,  0,  2 ]\n    ])\n\nWe can extract the elements on any diagonal using the diag command. The “main” or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nprint( diag(A) )\n\nprint( diag(A, 1) )\n\nprint( diag(A, -1) )\n\nWe can also construct matrices by specifying a diagonal with the diag function.\n\nA = A + diag([pi, 8, 6, 7], 2)\nprint(A)\n\nL, U = FNC.lufact(A)\nprint(L)\n\nprint(U)\n\nObserve above that the lower and upper bandwidths of \\mathbf{A} are preserved in the factor matrices.\n\nIf row pivoting is not used, the \\mathbf{L} and \\mathbf{U} factors preserve the lower and upper bandwidths of \\mathbf{A}. This fact implies computational savings in both the factorization and the triangular substitutions because the zeros appear predictably and we can skip multiplication and addition with them.\n\nThe number of flops needed by LU factorization without pivoting is O(b_u b_\\ell n) when the upper and lower bandwidths are b_u and b_\\ell.\n\nIn order to exploit the savings offered by sparsity, we would need to make modifications to \n\nFunction 2.4.1 and the triangular substitution routines. Alternatively, we can get Julia to take advantage of the structure automatically by converting the matrix into a special type called sparse. Sparse matrices are covered in more detail in Chapters 7 and 8.","type":"content","url":"/structure#banded-matrices","position":3},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric matrices"},"type":"lvl2","url":"/structure#symmetric-matrices","position":4},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric matrices"},"content":"Symmetric matrix\n\nA square matrix \\mathbf{A} satisfying \\mathbf{A}^T = \\mathbf{A} is called symmetric.\n\nSymmetric matrices arise frequently in applications because many types of interactions, such as gravitation and social-network befriending, are inherently symmetric. Symmetry in linear algebra simplifies many properties and algorithms. As a rule of thumb, if your matrix has symmetry, you want to exploit and preserve it.\n\nIn \\mathbf{A}=\\mathbf{L}\\mathbf{U} we arbitrarily required the diagonal elements of \\mathbf{L}, but not \\mathbf{U}, to be one. That breaks symmetry, so we need to modify the goal to\\mathbf{A}=\\mathbf{L}\\mathbf{D}\\mathbf{L}^T,\n\nwhere \\mathbf{L} is unit lower triangular and \\mathbf{D} is diagonal. To find an algorithm for this factorization, we begin by generalizing \n\n(2.4.4) a bit without furnishing proof.\n\nLinear combination of outer products\n\nLet \\mathbf{D} be an n\\times n diagonal matrix with diagonal elements d_1,d_2,\\ldots,d_n, and suppose \\mathbf{A} and \\mathbf{B} are n\\times n as well. Write the columns of \\mathbf{A} as \\mathbf{a}_1,\\dots,\\mathbf{a}_n and the rows of \\mathbf{B} as \\mathbf{b}_1^T,\\dots,\\mathbf{b}_n^T. Then\\mathbf{A}\\mathbf{D}\\mathbf{B} = \\sum_{k=1}^n d_k \\mathbf{a}_k \\mathbf{b}_k^T.\n\nLet’s derive the LDLT factorization for a small example.\n\nSymmetric LDLT factorization\n\nExample 2.9.2\n\nWe begin with a symmetric \\mathbf{A}.\n\nA₁ = [  2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = diagm(ones(4))\nd = zeros(4)\nd[1] = A₁[1, 1]\nL[:, 1] = A₁[:, 1] / d[1]\nA₂ = A₁ - d[1] * L[:, 1] * L[:, 1]'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[2] = A₂[2, 2]\nL[:, 2] = A₂[:, 2] / d[2]\nA₃ = A₂ - d[2] * L[:, 2] * L[:, 2]'\n\nWe continue working our way down the diagonal.\n\nd[3] = A₃[3, 3]\nL[:, 3] = A₃[:, 3] / d[3]\nA₄ = A₃ - d[3] * L[:, 3] * L[:, 3]'\nd[4] = A₄[4, 4]\n@show d;\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nopnorm(A₁ - (L * diagm(d) * L'))\n\nExample 2.9.2\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = [ 2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4);\nd = zeros(4, 1);\nd(1) = A_1(1, 1);\nL(:, 1) = A_1(:, 1) / d(1);\nA_2 = A_1 - d(1) * L(:, 1) * L(:, 1)'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd(2) = A_2(2, 2);\nL(:, 2) = A_2(:, 2) / d(2);\nA_3 = A_2 - d(2) * L(:, 2) * L(:, 2)'\n\nWe continue working our way down the diagonal.\n\nd(3) = A_3(3, 3);\nL(:, 3) = A_3(:, 3) / d(3);\nA_4 = A_3 - d(3) * L(:, 3) * L(:, 3)'\nd(4) = A_4(4, 4);\nd\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nnorm(A_1 - (L * diag(d) * L'))\n\nExample 2.9.2\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = array([\n    [2,     4,     4,     2],\n    [4,     5,     8,    -5],\n    [4,     8,     6,     2],\n    [2,    -5,     2,   -26]\n    ])\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4)\nd = zeros(4)\nd[0] = A_1[0, 0]\nL[:, 0] = A_1[:, 0] / d[0]\nA_2 = A_1 - d[0] * outer(L[:, 0], L[:, 0])\nprint(A_2)\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[1] = A_2[1, 1]\nL[:, 1] = A_2[:, 1] / d[1]\nA_3 = A_2 - d[1] * outer(L[:, 1], L[:, 1])\nprint(A_3)\n\nWe continue working our way down the diagonal.\n\nd[2] = A_3[2, 2]\nL[:, 2] = A_3[:, 2] / d[2]\nA_4 = A_3 - d[2] * outer(L[:, 2], L[:, 2])\nprint(A_4)\n\nWe have arrived at the desired factorization.\n\nd[3] = A_4[3, 3]\nprint(\"diagonal of D:\")\nprint(d)\nprint(\"L:\")\nprint(L)\n\nThis should be comparable to machine roundoff:\n\nprint(norm(A_1 - (L @ diag(d) @ L.T), 2) / norm(A_1))\n\nIn practice we don’t actually have to carry out any arithmetic in the upper triangle of \\mathbf{A} as we work, since the operations are always the mirror image of those in the lower triangle. As a result, it can be shown that LDLT factorization takes about half as much work as the standard LU.\n\nLDLT factorization on an n \\times n symmetric matrix, when successful, takes \\sim \\frac{1}{3}n^3 flops.\n\nJust as pivoting is necessary to stabilize LU factorization, the LDLT factorization without pivoting may be unstable or even fail to exist. We won’t go into the details, because our interest is in specializing the factorization to matrices that also possess another important property.","type":"content","url":"/structure#symmetric-matrices","position":5},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric positive definite matrices"},"type":"lvl2","url":"/structure#sec-spd","position":6},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Symmetric positive definite matrices"},"content":"Suppose that \\mathbf{A} is n\\times n and \\mathbf{x}\\in\\mathbb{R}^n. Observe that \\mathbf{x}^T\\mathbf{A}\\mathbf{x} is the product of 1\\times n, n\\times n, and n\\times 1 matrices, so it is a scalar, sometimes referred to as a quadratic form. It can be expressed as  \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = \\sum_{i=1}^n \\sum_{j=1}^n A_{ij}x_ix_j.\n\nSymmetric positive definite matrix\n\nA real n\\times n matrix \\mathbf{A} is called a symmetric positive definite matrix (or SPD matrix) if it is symmetric and, for all nonzero \\mathbf{x}\\in\\mathbb{R}^n,  \\mathbf{x}^T \\mathbf{A} \\mathbf{x} > 0.\n\nThe definiteness property is usually difficult to check directly from the definition. There are some equivalent conditions, though. For instance, a symmetric matrix is positive definite if and only if its eigenvalues are all real positive numbers. SPD matrices have important properties and appear in applications in which the definiteness is known for theoretical reasons.\n\nLet us consider what definiteness means to the LDLT factorization. We compute  0 < \\mathbf{x}^T\\mathbf{A}\\mathbf{x} = \\mathbf{x}^T \\mathbf{L} \\mathbf{D} \\mathbf{L}^T \\mathbf{x} = \\mathbf{z}^T \\mathbf{D} \\mathbf{z},\n\nwhere \\mathbf{z}=\\mathbf{L}^T \\mathbf{x}. Note that since \\mathbf{L} is unit lower triangular, it is nonsingular, so \\mathbf{x}=\\mathbf{L}^{-T}\\mathbf{z}. By taking \\mathbf{z}=\\mathbf{e}_k for k=1,\\ldots,n, we can read the equalities from right to left and conclude that D_{kk}>0 for all k. That permits us to write a kind of square root formula:  \\mathbf{D} =\n  \\begin{bmatrix}\n    D_{11} &        &        & \\\\\n           & D_{22} &        & \\\\\n           &        & \\ddots & \\\\\n           &        &        & D_{nn}\n  \\end{bmatrix}\n=   \\begin{bmatrix}\n    \\sqrt{D_{11}} &        &        & \\\\\n           & \\sqrt{D_{22}} &        & \\\\\n           &        & \\ddots & \\\\\n           &        &        & \\sqrt{D_{nn}}\n  \\end{bmatrix}^{\\,2}\n= \\bigl( \\mathbf{D}^{1/2} \\bigr)^2.\n\nNow we have \\mathbf{A}=\\mathbf{L}\\mathbf{D}^{1/2}\\mathbf{D}^{1/2}\\mathbf{L}^T= \\mathbf{R}^T \\mathbf{R}, where \\mathbf{R} =\\mathbf{D}^{1/2}\\mathbf{L}^T is an upper triangular matrix whose diagonal entries are positive.\n\nCholesky factorization\n\nAny SPD matrix \\mathbf{A} may be factored as\\mathbf{A} = \\mathbf{R}^T \\mathbf{R},\n\nwhere \\mathbf{R} is an upper triangular matrix with positive diagonal elements. This is called the Cholesky factorization.\n\nWhile the unpivoted LDLT factorization is not stable and not even always possible, in the SPD case one can prove that pivoting is not necessary for the existence nor the stability of the Cholesky factorization.\n\nCholesky factorization of an n \\times n SPD matrix takes \\sim \\frac{1}{3}n^3 flops.\n\nThe speed and stability of the Cholesky factorization make it the top choice for solving linear systems with SPD matrices. As a side benefit, the Cholesky algorithm fails (in the form of an imaginary square root or division by zero) if and only if the matrix \\mathbf{A} is not positive definite. This is often the best way to test the definiteness of a symmetric matrix about which nothing else is known.\n\nCholesky factorization\n\nExample 2.9.3\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = rand(1.0:9.0, 4, 4)\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nTip\n\nThe cholesky function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix. However, it does not check for symmetry.\n\ncholesky(B)    # throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A\ncf = cholesky(B)\n\nWhat’s returned is a factorization object. Another step is required to extract the factor as a matrix:\n\nR = cf.U\n\nHere we validate the factorization:\n\nopnorm(R' * R - B) / opnorm(B)\n\nExample 2.9.3\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = magic(4) + eye(4);\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nTip\n\nThe chol function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix.\n\nWarning\n\nThe chol function does not check for symmetry. It may give a nonsensical result if the input is not symmetric.\n\nchol(B)    % throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A;\nR = chol(B)\n\nHere we validate the factorization:\n\nnorm(R' * R - B) / norm(B)\n\nExample 2.9.3\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = 1.0 + floor(9 * random.rand(4, 4))\nB = A + A.T\nprint(B)\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nfrom numpy.linalg import cholesky\ncholesky(B)    # raises an exception, not positive definite\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization:\n\nB = A.T @ A\nR = cholesky(B)\nprint(R)\n\nprint(norm(R @ R.T - B) / norm(B))","type":"content","url":"/structure#sec-spd","position":7},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Exercises"},"type":"lvl2","url":"/structure#exercises","position":8},{"hierarchy":{"lvl1":"Exploiting matrix structure","lvl2":"Exercises"},"content":"✍  For each matrix, use \n\n(2.9.1) to determine whether it is diagonally dominant.\\mathbf{A} =\n\\begin{bmatrix}\n3  & 1  & 0 & 1  \\\\\n0  & -2 & 0 & 1  \\\\\n-1 & 0  & 4 & -1 \\\\\n0  & 0  & 0 & 6\n\\end{bmatrix},\n\\quad\n\\mathbf{B} =\n\\begin{bmatrix}\n1  & 0  & 0  & 0 & 0  \\\\\n0  & 1  & 0  & 0 & 0  \\\\\n0  & 0  & 1  & 0 & 0  \\\\\n0  & 0  & 0  & 1 & 0  \\\\\n0  & 0  & 0  & 0 & 0\n\\end{bmatrix},\n\\quad \\mathbf{C} =\n\\begin{bmatrix}\n2  & -1 & 0  & 0      \\\\\n-1 & 2  & -1 & 0      \\\\\n0  & -1 & 2  & -1     \\\\\n0  & 0  & -1 & 2\n\\end{bmatrix}.\n\n⌨ For each matrix, use inspection or cholesky in Julia to determine whether it is SPD.\\mathbf{A} =\n\\begin{bmatrix}\n1 & 0 & -1 \\\\ 0 & 4 & 5 \\\\ -1 & 5 & 10\n\\end{bmatrix},\n\\qquad\n\\mathbf{B} =\n\\begin{bmatrix}\n1 & 0 & 1 \\\\ 0 & 4 & 5 \\\\ -1 & 5 & 10\n\\end{bmatrix},\n\\qquad\n\\mathbf{C} =\n\\begin{bmatrix}\n1 & 0 & 1 \\\\ 0 & 4 & 5 \\\\ 1 & 5 & 1\n\\end{bmatrix}.\n\n✍ Show that the diagonal entries of a symmetric positive definite matrix are positive numbers. (Hint: Apply certain special cases of \n\n(2.9.5).)\n\n⌨ Using \n\nFunction 2.4.1 as a guide, write a functionfunction luband(A,upper,lower)\n\nthat accepts upper and lower bandwidth values and returns LU factors (without pivoting) in a way that avoids doing arithmetic using the locations that are known to stay zero. (Hint: Refer to the more efficient form of lufact given in \n\nEfficiency of matrix computations.)\n\nTest your function on the matrix with elementsA_{ij} = \\begin{cases} \\frac{1}{i+j}, & -1 \\le i-j \\le 2,\\\\ \n    0 & \\text{otherwise.} \\end{cases}\n\n⌨ The Tridiagonal matrix type invokes a specialized algorithm for solving a linear system.\n\n(a) Set n=1000 and t=0.  In a loop that runs 50 times, generate a linear system viaA = triu( tril(rand(n,n),1), -1)\nb = ones(n)\n\nUsing @elapsed, increment t by the time it takes to perform A\\b. Print out the final value of t.\n\n(b) Repeat the experiment of part (a), but generate the matrix viaA = Tridiagonal(rand(n,n))\n\nWhat is the ratio of running times for part (a) and (b)?\n\n(c) Now perform the experiment of part (b) for n=1000,1200,1400,\\ldots,3000, keeping the total time for each value of n in a vector. Plot running time as a function of n on a log-log scale. Is the time most like O(n), O(n^2), or O(n^3)? (If the answer is unclear, try increasing the number of solves per value of n to 100 or more.)\n\n✍ Prove that if \\mathbf{A} is any real invertible square matrix, then \\mathbf{A}^T\\mathbf{A} is SPD. (Hint: First show that \\mathbf{x}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{x} \\ge 0 for all \\mathbf{x}. Then explain why zero is ruled out if \\mathbf{x}\\neq \\boldsymbol{0}.)\n\nExcept for this diagonal, positive definite case, it’s not trivial to define the square root of a matrix, so don’t generalize the notation used here.","type":"content","url":"/structure#exercises","position":9},{"hierarchy":{"lvl1":"Fitting functions to data"},"type":"lvl1","url":"/fitting","position":0},{"hierarchy":{"lvl1":"Fitting functions to data"},"content":"In \n\nPolynomial interpolation we saw how a polynomial can be used to interpolate data—that is, derive a continuous function that evaluates to give a set of prescribed values. But interpolation may not be appropriate in many applications.\n\nInterpolating temperature data\n\nExample 3.1.1\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = 1955:5:2000\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n       0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n    \nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", \n    legend=:bottomright)\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = @. (year - 1950) / 10\nn = length(t)\nV = [ t[i]^j for i in 1:n, j in 0:n-1 ]\nc = V \\ temp\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\nTip\n\nIf you plot a function, then the points are chosen automatically to make a smooth curve.\n\nusing Polynomials, Plots\np = Polynomial(c)\nf = yr -> p((yr - 1950) / 10)\nplot!(f, 1955, 2000, label=\"interpolant\")\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nExample 3.1.1\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nt = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\nscatter(t, y), axis tight\nxlabel('year')\nylabel(('anomaly ({\\circ}C)'));\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (t - 1950) / 10;  \nn = length(t);\nV = ones(n, 1);    % t^0\nfor j = 1:n-1\n    V(:, j+1) = t .* V(:,j);\nend\nc = V \\ y;    % solve for coefficients\n\nWe created the Vandermonde matrix columns in increasing-degree order. Thus, the coefficients in c also follow that ordering, which is the opposite of what MATLAB uses. We need to flip the coefficients before using them in polyval.\n\np = @(year) polyval(c(end:-1:1), (year - 1950) / 10);\nhold on\nfplot(p, [1955, 2000])    % plot the interpolating function\n\nExample 3.1.1\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = arange(1955,2005,5)\ny = array([ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ])\n\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (year - 1950) / 10\nV = vander(t)\nc = linalg.solve(V, y)\nprint(c)\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\np = poly1d(c)    # convert to a polynomial\ntt = linspace(1955, 2000, 500)\nax.plot(tt, p((tt - 1950) / 10), label=\"interpolant\")\nax.legend();\nfig\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nIn many cases we can get better results by relaxing the interpolation requirement. In the polynomial case this allows us to lower the degree of the polynomial, which limits the number of local max and min points. Let (t_i,y_i) for i=1,\\ldots,m be the given points. We will represent the data by the polynomialy \\approx f(t) = c_1 + c_2t + \\cdots + c_{n-1} t^{n-2} + c_n t^{n-1},\n\nwith n<m. Just as in \n\n(2.1.3), we can express a vector of f-values by a matrix-vector multiplication. In other words, we seek an approximation\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_m \\end{bmatrix} \\approx\n\\begin{bmatrix}\nf(t_1)                               \\\\\nf(t_2)                               \\\\\nf(t_3)                               \\\\\n\\vdots                               \\\\\nf(t_m)\n\\end{bmatrix} =\n\\begin{bmatrix}\n1      & t_1    & \\cdots & t_1^{n-1} \\\\\n1      & t_2    & \\cdots & t_2^{n-1} \\\\\n1      & t_3    & \\cdots & t_3^{n-1} \\\\\n\\vdots & \\vdots &        & \\vdots    \\\\\n1      & t_m    & \\cdots & t_m^{n-1} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1                                  \\\\\nc_2                                  \\\\\n\\vdots                               \\\\\nc_n\n\\end{bmatrix}\n= \\mathbf{V} \\mathbf{c}.\n\nNote that \\mathbf{V} has the same structure as the Vandermonde matrix in \n\n(2.1.3) but is m\\times n, thus taller than it is wide. It’s impossible in general to satisfy m conditions with n<m variables, and we say the system is overdetermined. Rather than solving the system exactly, we have to find a best approximation. Below we specify precisely what is meant by this, but first we note that Julia uses the same backslash notation to solve the problem in both the square and overdetermined cases.\n\nFitting temperature data\n\nExample 3.1.2\n\nHere are the 5-year temperature averages again.\n\nyear = 1955:5:2000\nt = @. (year - 1950) / 10\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n          0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nTip\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = [ t.^0 t ]    # Vandermonde-ish matrix\n@show size(V)\nc = V \\ temp\np = Polynomial(c)\n\nf = yr -> p((yr - 1955) / 10)\nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", leg=:bottomright)\nplot!(f, 1955, 2000, label=\"linear fit\")\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [ t[i]^j for i in 1:length(t), j in 0:3 ]   \n@show size(V);\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nTip\n\nThe definition of f above is in terms of p. When p is changed, then f calls the new version.\n\np = Polynomial( V \\ temp )\nplot!(f, 1955, 2000, label=\"cubic fit\")\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nExample 3.1.2\n\nHere are the 5-year temperature averages again.\n\nyear = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nTip\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nt = (year - 1955) / 10;    % better matrix conditioning later\nV = [ t.^0 t ];            % Vandermonde-ish matrix\nsize(V)\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\n\nclf\nscatter(year, y), axis tight\nxlabel('year'), ylabel('anomaly ({\\circ}C)')\nhold on\nfplot(f, [1955, 2000])\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [t.^0, t.^1, t.^2, t.^3];    % Vandermonde-ish matrix  \nsize(V)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nTip\n\nThe definition of f above is in terms of c. When c is changed, then f has to be redefined.\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\nfplot(f, [1955, 2000]) \nlegend('data', 'linear', 'cubic', 'Location', 'northwest');\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nExample 3.1.2\n\nHere are the 5-year temperature averages again.\n\nyear = arange(1955, 2005, 5)\ny = array([-0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560])\nt = (year - 1950) / 10\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nTip\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = array([ [t[i], 1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nfrom numpy.linalg import lstsq\nc, res, rank, sv = lstsq(V, y)\np = poly1d(c)\nf = lambda year: p((year - 1950) / 10)\n```{code-cell}\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"linear fit\")\n\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\nax.legend();\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = array([ [t[i]**3,t[i]**2,t[i],1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nTip\n\nThe definition of f above is in terms of c. When c is changed, f is updated with it.\n\nc, res, rank, sv = lstsq(V, y, rcond=None)\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"cubic fit\")\nfig\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.","type":"content","url":"/fitting","position":1},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"The least-squares formulation"},"type":"lvl2","url":"/fitting#the-least-squares-formulation","position":2},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"The least-squares formulation"},"content":"In the most general terms, our fitting functions take the formf(t) = c_1 f_1(t) + \\cdots + c_n f_n(t)\n\nwhere f_1,\\ldots,f_n are all known functions with no undetermined parameters. This leaves only c_1,\\ldots,c_n to be determined. The essential feature of a linear least-squares problem is that the fit depends only linearly on the unknown parameters. For instance, a function of the form f(t)=c_1 + c_2 e^{c_3 t} is not of this type.\n\nAt each observation (t_i,y_i), we define a residual, y_i - f(t_i). A sensible formulation of the fitting criterion is to minimize  R(c_1,\\ldots,c_n) = \\sum_{i=1}^m\\, [ y_i - f(t_i) ]^2,\n\nover all possible choices of parameters c_1,\\ldots,c_n. We can apply linear algebra to write the problem in the form R=\\mathbf{r}^T \\mathbf{r}, where\\mathbf{r} =\n\\begin{bmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\y_{m-1} \\\\ y_m\n\\end{bmatrix} -\n\\begin{bmatrix}\nf_1(t_1) & f_2(t_1) & \\cdots & f_n(t_1) \\\\[1mm]\nf_1(t_2) & f_2(t_2) & \\cdots & f_n(t_2) \\\\[1mm]\n& \\vdots \\\\\nf_1(t_{m-1}) & f_2(t_{m-1}) & \\cdots & f_n(t_{m-1}) \\\\[1mm]\nf_1(t_m) & f_2(t_m) & \\cdots & f_n(t_m) \\\\[1mm]\n\\end{bmatrix}\n\\begin{bmatrix}\nc_1 \\\\ c_2 \\\\ \\vdots \\\\ c_n\n\\end{bmatrix}.\n\nRecalling that \\mathbf{r}^T\\mathbf{r}=\\| \\mathbf{r} \\|_2^2, and renaming the variables to standardize the statement, we arrive at the general linear least-squares problem.\n\nLinear least-squares problem\n\nGiven \\mathbf{A}\\in\\mathbb{R}^{m \\times n} and \\mathbf{b}\\in\\mathbb{R}^m, with m>n, find\\argmin_{{\\mathbf{x}\\in \\mathbb{R}^n}} \\, \\twonorm{\\mathbf{b}-\\mathbf{A} \\mathbf{x}}^2.\n\nThe notation argmin above means to find an \\mathbf{x} that produces the minimum value.\n\nWhile we could choose to minimize in any vector norm, the 2-norm is the most common and convenient choice. For the rest of this chapter we exclusively use the 2-norm. In the edge case m=n for a nonsingular \\mathbf{A}, the definitions of the linear least-squares and linear systems problems coincide: the solution of  \\mathbf{A}\\mathbf{x}=\\mathbf{b}  implies \\mathbf{r}=\\boldsymbol{0}, which is a global minimum of \\| \\mathbf{r} \\|_2^2 \\ge 0.","type":"content","url":"/fitting#the-least-squares-formulation","position":3},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Change of variables"},"type":"lvl2","url":"/fitting#change-of-variables","position":4},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Change of variables"},"content":"The most familiar and common case of a polynomial least-squares fit is the straight line, f(t) = c_1 + c_2 t. Certain other fit functions can be transformed into this situation. For example, suppose we want to fit data using g(t)= a_1 e^{a_2 t}. Then\\log y \\approx \\log g(t) = (\\log a_1) + a_2 t = c_1 + c_2 t.\n\nWhile the fit of the y_i to g(t) is nonlinearly dependent on fitting parameters, the fit of \\log y to a straight line is a linear problem. Similarly, the power-law relationship y\\approx f(t)=a_1 t^{a_2} is equivalent to\\log y \\approx (\\log a_1) + a_2 (\\log t).\n\nThus, the variable z=\\log y can be fit linearly in terms of the variable s=\\log t. In practice these two cases—exponential fit and power law—are easily detected by using log-linear or log-log plots, respectively.\n\nFitting a power law\n\nFinding numerical approximations to π has fascinated people for millennia. One famous formula is\\displaystyle \\frac{\\pi^2}{6} = 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\cdots.\n\nSay s_k is the sum of the first k terms of the series above, and p_k = \\sqrt{6s_k}. Here is a fancy way to compute these sequences in a compact code.\n\nExample 3.1.3\n\na = [1/k^2 for k=1:100] \ns = cumsum(a)        # cumulative summation\np = @. sqrt(6*s)\n\nscatter(1:100, p;\n    title=\"Sequence convergence\",\n    xlabel=L\"k\",  ylabel=L\"p_k\")\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nϵ = @. abs(π - p)    # error sequence\nscatter(1:100, ϵ;\n    title=\"Convergence of errors\",\n    xaxis=(:log10,L\"k\"),  yaxis=(:log10,\"error\"))\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nk = 1:100\nV = [ k.^0 log.(k) ]     # fitting matrix\nc = V \\ log.(ϵ)          # coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[1]), c[2];\n@show b;\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nplot!(k, a * k.^b, l=:dash, label=\"power-law fit\")\n\nExample 3.1.3\n\nk = (1:100)';\na = 1./k.^2;      % sequence\ns = cumsum(a);    % cumulative summation\np = sqrt(6*s);\nclf\nplot(k, p, 'o-')\nxlabel('k'), ylabel('p_k')\ntitle('Sequence converging to \\pi')\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p);    % error sequence\nloglog(k, ep, 'o')\ntitle('Convergence')\nxlabel('k'), ylabel('|p_k - \\pi|'), axis tight\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = [ k.^0, log(k) ];    % fitting matrix\nc = V \\ log(ep)          % coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na = exp(c(1)),  b = c(2)\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nhold on\nloglog(k, a * k.^b)\nlegend('sequence', 'power-law fit');\n\nExample 3.1.3\n\na = array([1 / (k+1)**2 for k in range(100)])\ns = cumsum(a)        # cumulative summation\np = sqrt(6*s)\n\nplot(range(100), p, \"o\")\nxlabel(\"$k$\") \nylabel(\"$p_k$\") \ntitle(\"Sequence convergence\");\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p)    # error sequence\nloglog(range(100), ep, \"o\")\nxlabel(\"$k$\") \nylabel(\"error\") \ntitle(\"Sequence convergence\");\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = array([ [1, log(k+1)] for k in range(100) ])     # fitting matrix\nc = lstsq(V, log(ep), rcond=None)[0]           # coefficients of linear fit\nprint(c)\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[0]), c[1]\nprint(f\"b: {b:.3f}\")\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nloglog(range(100), ep, \"o\", label=\"sequence\")\nk = arange(1,100)\nplot(k, a*k**b, \"--\", label=\"power fit\")\nxlabel(\"$k$\");  ylabel(\"error\"); \nlegend(); title(\"Sequence convergence\");","type":"content","url":"/fitting#change-of-variables","position":5},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Exercises"},"type":"lvl2","url":"/fitting#exercises","position":6},{"hierarchy":{"lvl1":"Fitting functions to data","lvl2":"Exercises"},"content":"✍ Suppose f is a twice-differentiable, nonnegative real function. Show that if there is an x^* such that f'(x^*)=0 and f''(x^*)>0, then x^* is a local minimizer of the function [f(x)]^2.\n\n⌨  Here are counts of the U.S. population in millions from the census performed every ten years, beginning with 1790 and ending with 2010.3.929, 5.308, 7.240, 9.638, 12.87, 17.07, 23.19, 31.44, 39.82, 50.19, 62.95, 76.21,\n92.22, 106.0, 122.8, 132.2, 150.7, 179.3, 203.3, 226.5, 248.7, 281.4, 308.7\n\n(a) Find a best-fitting cubic polynomial for the data. Plot the data as points superimposed on a (smooth) graph of the cubic over the full range of time. Label the axes. What does the fit predict for the population in the years 2000, 2010, and 2020?\n\n(b) Look up the actual U.S. population in 2000, 2010, and 2020 and compare to the predictions of part (a).\n\n⌨  The following are weekly box office earnings (in dollars) in the U.S. for the 2012 film The Hunger Games. (Source: \n\nboxofficemojo.com.)189_932_838, 79_406_327, 46_230_374, 26_830_921, 18_804_290,\n13_822_248, 7_474_688, 6_129_424, 4_377_675, 3_764_963, 2_426_574,\n1_713_298, 1_426_102, 1_031_985, 694_947, 518_242, 460_578, 317_909\n\n(Note that Julia lets you use _ where you would normally put a comma in a long number.) Fit these values to a function of the form y(t)\\approx a e^{b t}. Plot the data together with the fit using standard linear scales on the axes, and then plot them again using a log scale on the vertical axis.\n\n⌨  In this problem you are trying to find an approximation to the periodic function g(t)=e^{\\sin(t-1)} over one period, 0 < t \\le 2\\pi. As data, definet_i = \\frac{2\\pi i}{60}, \\; y_i = g(t_i), \\quad i=1,\\ldots,60.\n\n(a) Find the coefficients of the least-squares fit  y(t) \\approx c_1 + c_2t + \\cdots + c_7 t^6.\n\nSuperimpose a plot of the data values as points with a curve showing the fit.\n\n(b) Find the coefficients of the least-squares fity \\approx d_1 + d_2\\cos(t) + d_3\\sin(t) + d_4\\cos(2t) + d_5\\sin(2t).\n\nUnlike part (a), this fitting function is itself periodic. Superimpose a plot of the data values as points with a curve showing the fit.\n\n⌨ Define the following data in Julia.t = 0:.5:10\ny = tanh.(t)\n\n(a) Fit the data to a cubic polynomial. Plot the data together with the polynomial fit over the interval 0 \\le t \\le 10.\n\n(b) Fit the data to the function c_1 + c_2z + c_3z^2 + c_4z^3, where z=t^2/(1+t^2). Plot the data together with the fit. What feature of z makes this fit much better than the original cubic?\n\n⌨  One series for finding π is\\frac{\\pi}{2} = 1 + \\frac{1}{3} + \\frac{1\\cdot 2}{3\\cdot5} + \\frac{1\\cdot 2\\cdot 3}{3\\cdot 5\\cdot 7} + \\cdots.\n\nDefine s_k to be the sum of the first k terms on the right-hand side, and let e_k=|s_k-\\pi/2|.\n\n(a) Calculate e_k for k=1,\\ldots,20, and plot the sequence on a log-linear scale.\n\n(b) Determine a and b in a least-squares fit e_k \\approx a \\cdot b^k, and superimpose the fit on the plot from part (a).\n\n⌨  Kepler found that the orbital period τ of a planet depends on its mean distance R from the sun according to \\tau=c R^{\\alpha} for a simple rational number α. Perform a linear least-squares fit from the following table in order to determine the most likely simple rational value of α.\n\nPlanet\n\nDistance from sun in Mkm\n\nOrbital period in days\n\nMercury\n\n57.59\n\n87.99\n\nVenus\n\n108.11\n\n224.7\n\nEarth\n\n149.57\n\n365.26\n\nMars\n\n227.84\n\n686.98\n\nJupiter\n\n778.14\n\n4332.4\n\nSaturn\n\n1427\n\n10759\n\nUranus\n\n2870.3\n\n30684\n\nNeptune\n\n4499.9\n\n60188\n\n✍ Show that finding a fit of the formy(t) \\approx \\frac{a}{t+b}\n\ncan be transformed into a linear fitting problem (with different undetermined coefficients) by rewriting the equation.\n\n✍ Show how to find the constants a and b in a data fitting problem of the form y(t)\\approx t/(at+b) for t>1 by transforming it into a linear least-squares fitting problem.","type":"content","url":"/fitting#exercises","position":7},{"hierarchy":{"lvl1":"Computing QR factorizations"},"type":"lvl1","url":"/house","position":0},{"hierarchy":{"lvl1":"Computing QR factorizations"},"content":"It is possible to compute a thin QR factorization using the outer product formula \n\n(2.4.4), as we did with LU. However, to stably compute the factorization, a better strategy is to introduce zeros into the lower triangle, one column at a time, using orthogonal matrices. Thanks to \n\nTheorem 3.3.2, the product of orthogonal matrices will also be orthogonal.","type":"content","url":"/house","position":1},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Householder reflections"},"type":"lvl2","url":"/house#householder-reflections","position":2},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Householder reflections"},"content":"We will use a particular type of orthogonal matrix.\n\nHouseholder reflector\n\nA Householder reflector is a matrix of the form  \\mathbf{P} = \\mathbf{I} - 2 \\mathbf{v} \\mathbf{v}^T,\n\nwhere \\mathbf{v} is any unit vector (in the 2-norm).\n\nIn \n\nExercise 2 you are asked to show that such a \\mathbf{P} is necessarily orthogonal. Note that for any vector \\mathbf{x} of appropriate dimension,  \\mathbf{P}\\mathbf{x} = \\mathbf{x} - 2 \\mathbf{v} (\\mathbf{v}^T\\mathbf{x}).\n\nThe reason \\mathbf{P} is called a reflector is sketched in \n\nFigure 3.4.1.\n\n\n\nFigure 3.4.1:A Householder reflector. Because \\mathbf{v} is a unit vector, \\mathbf{v}^T\\mathbf{x} is the component of \\mathbf{x} in the direction of \\mathbf{v}. Hence subtracting (\\mathbf{v}^T\\mathbf{x})\\mathbf{v} projects \\mathbf{x} into a hyperplane orthogonal to \\mathbf{v}. By subtracting off twice as much, we get the reflection of \\mathbf{x} through the hyperplane instead.\n\nGiven a vector \\mathbf{z}, we can choose \\mathbf{v} so that \\mathbf{P} reflects \\mathbf{z} onto the x_1-axis—i.e., so that \\mathbf{P}\\mathbf{z} is nonzero only in the first element. Because orthogonal matrices preserve the 2-norm, we must have\\mathbf{P}\\mathbf{z} =\n\\begin{bmatrix}\n\\pm \\| \\mathbf{z} \\|\\\\0 \\\\ \\vdots \\\\ 0\n\\end{bmatrix} = \\pm \\| \\mathbf{z} \\| \\mathbf{e}_1.\n\n(Recall that \\mathbf{e}_k is the kth column of the identity matrix.) We choose the positive sign above for our discussion, but see \n\nFunction 3.4.1 and \n\nExercise 4 for important computational details. Let  \\mathbf{w} = \\| \\mathbf{z} \\| \\mathbf{e}_1-\\mathbf{z}, \\quad \\mathbf{v} = \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|}.\n\nIf it turns out that \\mathbf{w}=\\boldsymbol{0}, then \\mathbf{z} is already in the target form and we can take \\mathbf{P}=\\mathbf{I}.  Otherwise, we have the following.\n\nHouseholder reflector\n\nLet \\mathbf{v} be defined by \n\n(3.4.4) and let \\mathbf{P} be given by \n\n(3.4.1). Then \\mathbf{P} is symmetric and orthogonal, and \\mathbf{P}\\mathbf{z}=\\| \\mathbf{z} \\|\\mathbf{e}_1.\n\nThe proofs of symmetry and orthogonality are left to \n\nExercise 2. For the last fact, we use \n\n(3.4.2) to compute\\mathbf{P}\\mathbf{z} = \\mathbf{z} - 2 \\frac{\\mathbf{w}^T \\mathbf{z}}{\\mathbf{w}^T\\mathbf{w}} \\mathbf{w}.\n\nSince \\mathbf{e}_1^T\\mathbf{z}=z_1,\\begin{split}\n    \\mathbf{w}^T\\mathbf{w} &= \\| \\mathbf{z} \\|^2 - 2 \\| \\mathbf{z} \\| z_1 + \\mathbf{z}^T\\mathbf{z}\n    = 2\\| \\mathbf{z} \\|(\\| \\mathbf{z} \\|-z_1),\\\\\n    \\mathbf{w}^T\\mathbf{z} &= \\| \\mathbf{z} \\|z_1 - \\mathbf{z}^T\\mathbf{z} = -\\| \\mathbf{z} \\|\\bigl(\\| \\mathbf{z} \\|-z_1\\bigr),\n\\end{split}\n\nleading finally to\\mathbf{P}\\mathbf{z} = \\mathbf{z} - 2\\cdot\n\\frac{-\\| \\mathbf{z} \\| \\bigl(\\| \\mathbf{z} \\|-z_1\\bigr)}{2\\| \\mathbf{z} \\| \\bigl(\\| \\mathbf{z} \\|-z_1\\bigr)} \\mathbf{w}\n= \\mathbf{z} + \\mathbf{w} = \\| \\mathbf{z} \\|\\mathbf{e}_1.","type":"content","url":"/house#householder-reflections","position":3},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Factorization algorithm"},"type":"lvl2","url":"/house#factorization-algorithm","position":4},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Factorization algorithm"},"content":"The QR factorization is computed by using successive Householder reflections to introduce zeros in one column at a time. We first show the process for a small numerical example in \n\nDemo 3.4.1.\n\nHouseholder QR factorization\n\nExample 3.4.1\n\nWe will use Householder reflections to produce a QR factorization of a random matrix.\n\nTip\n\nThe rand function can select randomly from within the interval [0,1], or from a vector or range that you specify.\n\nA = rand(float(1:9), 6, 4)\nm,n = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nTip\n\nI can stand for an identity matrix of any size, inferred from the context when needed.\n\nz = A[:, 1];\nv = normalize(z - norm(z) * [1; zeros(m-1)])\nP₁ = I - 2v * v'   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nP₁ * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}\\mathbf{A}.\n\nA = P₁ * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[2:m, 2]\nv = normalize(z - norm(z) * [1; zeros(m-2)])\nP₂ = I - 2v * v'\n\nWe now apply this reflector to rows 2 and below only.\n\nA[2:m, :] = P₂ * A[2:m, :]\nA\n\nWe need to iterate the process for the last two columns.\n\nfor j in 3:n\n    z = A[j:m, j]\n    v = normalize(z - norm(z) * [1; zeros(m-j)])\n    P = I - 2v * v'\n    A[j:m, :] = P * A[j:m, :]\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)\n\nExample 3.4.1\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = magic(6);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A(:, 1);\nv = z - norm(z) * eye(m,1);\nP_1 = eye(m) - 2 / (v' * v) * (v * v');\n\nWe check that this reflector introduces zeros as it should:\n\nP_1 * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A(2:m, 2);\nv = z - norm(z) * eye(m-1, 1);\nP_2 = eye(m-1) - 2 / (v' * v) * (v * v');\n\nWe now apply this reflector to rows 2 and below only.\n\nA(2:m, 2:n) = P_2 * A(2:m, 2:n)\n\nWe need to iterate the process for the last two columns.\n\nfor j = 3:n\n    z = A(j:m,j);\n    k = m-j+1;\n    v = z - norm(z) * eye(k, 1);\n    P = eye(k) - 2 / (v' * v) * (v * v');\n    A(j:m, j:n) = P * A(j:m, j:n);\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = A\n\nExample 3.4.1\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nm, n = A.shape\nprint(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A[:, 0]\nv = z - norm(z) * hstack([1, zeros(m-1)])\nP_1 = eye(m) - (2 / dot(v, v)) * outer(v, v)   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nprint(P_1 @ z)\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 @ A\nprint(A)\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[1:, 1]\nv = z - norm(z) * hstack([1, zeros(m-2)])\nP_2 = eye(m-1) - (2 / dot(v, v)) * outer(v, v)\n\nWe now apply this reflector to rows 2 and below only.\n\nA[1:, 1:] = P_2 @ A[1:, 1:]\nprint(A)\n\nWe need to iterate the process for the last two columns.\n\nfor j in [2, 3]:\n    z = A[j:, j]\n    v = z - norm(z) * hstack([1, zeros(m-j-1)])\n    P = eye(m-j) - (2 / dot(v, v)) * outer(v, v)\n    A[j:, j:] = P @ A[j:, j:]\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)\nprint(R)\n\nYou may be wondering what happened to \\mathbf{Q} in \n\nDemo 3.4.1. Each Householder reflector is orthogonal but not full-size. We have to pad it out to represent algebraically the fact that a block of the first rows is left alone. Given a reflector \\mathbf{P}_k that is of square size m-k+1, we define\\mathbf{Q}_k =\n\\begin{bmatrix}\n\\mathbf{I}_{k-1} & \\boldsymbol{0} \\\\ \\boldsymbol{0} & \\mathbf{P}_k\n\\end{bmatrix}.\n\nIt is easy to show that \\mathbf{Q}_k is also orthogonal. Then the algorithm produces  \\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1 \\mathbf{A} = \\mathbf{R}.\n\nBut \\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1 is orthogonal too, and we multiply on the left by its transpose to get \\mathbf{A}=\\mathbf{Q}\\mathbf{R}, where \\mathbf{Q} =  (\\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1)^T. We don’t even need to form these matrices explicitly. Writing\\mathbf{Q}^T = \\mathbf{Q}_n \\mathbf{Q}_{n-1}\\cdots \\mathbf{Q}_1 = \\mathbf{Q}_n \\Bigl( \\mathbf{Q}_{n-1}\\bigl(\\cdots (\\mathbf{Q}_1\\mathbf{I})\\cdots\\bigr)\\Bigr),\n\nwe can build \\mathbf{Q}^T iteratively by starting with the identity and doing the same row operations as on \\mathbf{A}. That process uses much less memory than building the \\mathbf{Q}_k matrices explicitly.\n\nThe algorithm we have described is encapsulated in \n\nFunction 3.4.1. There is one more refinement in it, however. As indicated by \n\n(3.4.2), the application of a reflector \\mathbf{P} to a vector does not require the formation of the matrix \\mathbf{P} explicitly.\n\nqrfact\n\nQR factorization by Householder reflections\n\n\"\"\"\n    qrfact(A)\n\nQR factorization by Householder reflections. Returns Q and R.\n\"\"\"\nfunction qrfact(A)\n    m, n = size(A)\n    Qt = diagm(ones(m))\n    R = float(copy(A))\n    for k in 1:n\n        z = R[k:m, k]\n        w = [-sign(z[1]) * norm(z) - z[1]; -z[2:end]]\n        nrmw = norm(w)\n        if nrmw < eps()\n            continue    # already in place; skip this iteration\n        end\n        v = w / nrmw\n        # Apply the reflection to each relevant column of R and Q\n        for j in k:n\n            R[k:m, j] -= v * (2 * (v' * R[k:m, j]))\n        end\n        for j in 1:m\n            Qt[k:m, j] -= v * (2 * (v' * Qt[k:m, j]))\n        end\n    end\n    return Qt', triu(R)\nend\n\nQR factorization by Householder reflections\n\nfunction [Q,R] = qrfact(A)\r\n% QRFACT   QR factorization by Householder reflections.\r\n% (demo only--not efficient)\r\n% Input:\r\n%   A      m-by-n matrix\r\n% Output:\r\n%   Q,R    A=QR, Q m-by-m orthogonal, R m-by-n upper triangular\r\n\r\n[m,n] = size(A);\r\nQ = eye(m);\r\nfor k = 1:n\r\n  z = A(k:m,k);\r\n  v = [ -sign(z(1))*norm(z) - z(1); -z(2:end) ];\r\n  nrmv = norm(v);\r\n  if nrmv < eps, continue, end       % nothing is done in this iteration\r\n  v = v / nrmv;                      % removes v'*v in other formulas\r\n  % Apply the reflection to each relevant column of A and Q\r\n  for j = 1:n\r\n    A(k:m,j) = A(k:m,j) - v*( 2*(v'*A(k:m,j)) );\r\n  end\r\n  for j = 1:m\r\n    Q(k:m,j) = Q(k:m,j) - v*( 2*(v'*Q(k:m,j)) );\r\n  end\r\nend\r\n\r\nQ = Q';\r\nR = triu(A);                         % enforce exact triangularity\n\nQR factorization by Householder reflections\n\ndef qrfact(A):\n    \"\"\"\n        qrfact(A)\n\n    QR factorization by Householder reflections. Returns Q and R.\n    \"\"\"\n    m, n = A.shape\n    Qt = np.eye(m)\n    R = np.copy(A)\n    for k in range(n):\n        z = R[k:, k]\n        w = np.hstack((-np.sign(z[0]) * np.linalg.norm(z) - z[0], -z[1:]))\n        nrmw = np.linalg.norm(w)\n        if nrmw < np.finfo(float).eps: continue    # skip this iteration\n        v = w / nrmw\n        # Apply the reflection to each relevant column of R and Q\n        for j in range(k, n):\n            R[k:, j] -= 2 * np.dot(v, R[k:, j]) * v\n        for j in range(m):\n            Qt[k:, j] -= 2 * np.dot(v, Qt[k:, j]) * v \n    return Qt.T, np.triu(R)","type":"content","url":"/house#factorization-algorithm","position":5},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Q-less QR and least squares"},"type":"lvl2","url":"/house#q-less-qr-and-least-squares","position":6},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Q-less QR and least squares"},"content":"In \n\nDemo 3.3.1 it was seen that the \\mathbf{Q} output of Julia’s qr function is not a standard matrix. The reason is that Equation \n\n(3.3.8) shows that in order to solve the linear least-squares problem, all we need from \\mathbf{Q} is the computation of \\hat{\\mathbf{Q}}^T\\mathbf{b}. Referring again to \n\n(3.4.10) and \n\n(3.4.2), the special structure of the reflectors is such that for this computation, we only need to apply code similar to lines 18 and 21 of \n\nFunction 3.4.1 for each of the Householder vectors \\mathbf{v} that is constructed.\n\nThis observation leads to the idea of the Q-less QR factorization, in which the full or thin \\mathbf{Q} is never computed explicitly. This is the variant used by Julia’s qr. The returned value Q used within \n\nFunction 3.3.2 is of a special type that allows Julia to perform Q'*b efficiently for the least-squares solution.\n\nIn \n\nExercise 8 you are asked to derive the following result about the Q-less factorization.\n\nQ-less QR factorization by Householder reflections takes \\sim(2mn^2-\\frac{2}{3}n^3) flops.\n\nThe flop count quoted in \n\nTheorem 3.4.2 dominates the running time for least-squares solution via QR. Compared to the count from \n\nTheorem 3.2.3 for solution by the normal equations, the flops are essentially identical when m=n, but the QR solution is about twice the cost when m\\gg n. The redeeming quality of the QR route is better stability, which we do not discuss here.","type":"content","url":"/house#q-less-qr-and-least-squares","position":7},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Exercises"},"type":"lvl2","url":"/house#exercises","position":8},{"hierarchy":{"lvl1":"Computing QR factorizations","lvl2":"Exercises"},"content":"⌨ Find a Householder reflector \\mathbf{P} such that\\mathbf{P}\n\\begin{bmatrix}\n  2 \\\\ 9 \\\\ -6\n\\end{bmatrix} =\n\\begin{bmatrix}\n  11\\\\0\\\\0\n\\end{bmatrix}.\n\n✍ Prove the unfinished items in \n\nTheorem 3.4.1, namely that a Householder reflector \\mathbf{P} is symmetric and orthogonal.\n\n✍ Let \\mathbf{P} be a Householder reflector as in \n\n(3.4.1).\n\n(a) Find a vector \\mathbf{u} such that \\mathbf{P}\\mathbf{u} = -\\mathbf{u}. (\n\nFigure 3.4.1 may be of help.)\n\n(b) What algebraic condition is necessary and sufficient for a vector \\mathbf{x} to satisfy \\mathbf{P}\\mathbf{x}=\\mathbf{x}? In n dimensions, how many such linearly independent vectors are there?\n\n✍ Under certain circumstances, computing the vector \\mathbf{v} in \n\n(3.4.4) could lead to subtractive cancellation, which is why line 12 of \n\nFunction 3.4.1 reads as it does. Devise an example that causes subtractive cancellation if \n\n(3.4.4) is used.\n\n✍ Suppose QR factorization is used to compute the solution of a square linear system, \\mathbf{A}\\mathbf{x}=\\mathbf{b}, i.e., let m=n.\n\n(a) Find an asymptotic flop count for this procedure, and compare it to the LU factorization algorithm.\n\n(b) Show that \\kappa_2(\\mathbf{A}) = \\kappa_2(\\mathbf{R}).\n\n✍ Prove that \\kappa_2(\\mathbf{A})=\\kappa_2(\\mathbf{R}) when \\mathbf{A} is not square.  (Be careful! You can’t take an inverse of \\mathbf{A} or \\mathbf{R}.)\n\nAnother algorithmic technique for orthogonally introducing zeros into a matrix is the   Givens rotation. Given a 2-vector [\\alpha,\\, \\beta], it defines an angle θ such that\\begin{bmatrix}\n  \\cos(\\theta) & \\sin(\\theta) \\\\ -\\sin(\\theta) & \\cos(\\theta)\n\\end{bmatrix}\n\\begin{bmatrix}\n  \\alpha \\\\ \\beta\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  \\sqrt{\\alpha^2 + \\beta^2} \\\\ 0\n\\end{bmatrix}.\n\n(a) ✍ Given α and β, show how to compute \\cos \\theta and \\sin \\theta without evaluating any trig functions.\n\n(b) ⌨ Given the vector \\mathbf{z}=[1\\;2\\;3\\;4\\;5]^T, use Julia to find a sequence of Givens rotations that transforms \\mathbf{z} into the vector \\| \\mathbf{z} \\|\\mathbf{e}_1. (Hint: You can operate only on pairs of elements at a time, introducing a zero at the lower of the two positions.)\n\n✍ Derive the result of \n\nTheorem 3.4.2 by analyzing \n\nFunction 3.4.1 without lines 20–22.\n\n✍ Suppose m=Kn for constant K \\ge 1 as both m and n go to infinity. Show that the flop counts from \n\nTheorem 3.4.2  and \n\nTheorem 3.2.3 have a ratio of 1 when K=1 and approaches 2 as K\\to \\infty.","type":"content","url":"/house#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-2","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The least-squares problem has been widely studied and used, and only seems to become more important in this era of ever-increasing amounts of data.  A good reference for numerical methods is the monograph by Björck \n\nBjörck (1996).  Some theoretical results can be found in Higham \n\nHigham (2002); a brief and advanced discussion can be found in Golub and Van Loan \n\nGolub & Van Loan (1996).\n\nNote that a vast literature can also be found in statistics for what is referred to as data regression, or simply regression. Nonlinear methods for least-squares fitting of data will be discussed in the following chapter.\n\nIn modern applications one may have to deal with so-called online fitting, in which new data must continually be incorporated with old. More recent sources address related issues, e.g., in  Hansen, Pereyra, and Scherer \n\nHansen et al. (2013) and in Teunissen \n\nTeunissen (2001).  The problem of geodesy and GPS positioning are discussed in some detail in Strang and Borre \n\nStrang & Borre (1997); for these applications, they describe how the updating of least squares leads to Kalman filtering.","type":"content","url":"/next-2","position":1},{"hierarchy":{"lvl1":"The normal equations"},"type":"lvl1","url":"/normaleqns","position":0},{"hierarchy":{"lvl1":"The normal equations"},"content":"We now solve the general linear least-squares problem in \n\nDefinition 3.1.1. That is, given \\mathbf{A}\\in\\mathbb{R}^{m \\times n} and \\mathbf{b}\\in\\mathbb{R}^m, with m>n, find the \\mathbf{x}\\in\\mathbb{R}^n that minimizes \\| \\mathbf{b} - \\mathbf{A}\\mathbf{x} \\|_2.\n\nThere is a concise explicit solution. In the following proof we make use of the elementary algebraic fact that for two vectors \\mathbf{u} and \\mathbf{v},  (\\mathbf{u}+\\mathbf{v})^T(\\mathbf{u}+\\mathbf{v}) = \\mathbf{u}^T\\mathbf{u} + \\mathbf{u}^T\\mathbf{v} + \\mathbf{v}^T\\mathbf{u}\n  + \\mathbf{v}^T\\mathbf{v} = \\mathbf{u}^T\\mathbf{u} + 2\\mathbf{v}^T\\mathbf{u} + \\mathbf{v}^T\\mathbf{v}.\n\nIf \\mathbf{x} satisfies \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=\\boldsymbol{0}, then \\mathbf{x} solves the linear least-squares problem, i.e., \\mathbf{x} minimizes \\| \\mathbf{b}-\\mathbf{A}\\mathbf{x} \\|_2.\n\nLet \\mathbf{y}\\in \\mathbb{R}^n be any vector. Then\n\\mathbf{A}(\\mathbf{x}+\\mathbf{y})-\\mathbf{b}=\\mathbf{A}\\mathbf{x}-\\mathbf{b}+\\mathbf{A}\\mathbf{y}, and\\begin{split}\n    \\| \\mathbf{A}(\\mathbf{x}+\\mathbf{y})-\\mathbf{b} \\|_2^2 &=\n    [(\\mathbf{A}\\mathbf{x}-\\mathbf{b})+(\\mathbf{A}\\mathbf{y})]^T[(\\mathbf{A}\\mathbf{x}-\\mathbf{b})+(\\mathbf{A}\\mathbf{y})]\\\\\n    &= (\\mathbf{A}\\mathbf{x}-\\mathbf{b})^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b}) + 2(\\mathbf{A}\\mathbf{y})^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b}) + (\\mathbf{A}\\mathbf{y})^T(\\mathbf{A}\\mathbf{y})\\\\\n    &= \\| \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|_2^2 + 2\\mathbf{y}^T \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b}) + \\| \\mathbf{A}\\mathbf{y} \\|_2^2 \\\\\n    &= \\| \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|_2^2 + \\| \\mathbf{A}\\mathbf{y} \\|_2^2 \\\\\n    & \\ge \\| \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|_2^2.\n  \\end{split}\n\nNormal equations\n\nGiven \\mathbf{A}\\in \\real^{m\\times n} and \\mathbf{b}\\in \\real^{m}, the normal equations for the linear least-squares problem \\operatorname{argmin}\\| \\mathbf{b}- \\mathbf{A} \\mathbf{x}\\| are \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=\\boldsymbol{0}, or equivalently,\\mathbf{A}^T\\mathbf{A}\\mathbf{x}=\\mathbf{A}^T\\mathbf{b}.\n\nThe normal equations have a geometric interpretation, as shown in \n\nFigure 3.2.1. The vector in the range (column space) of \\mathbf{A} that lies closest to \\mathbf{b} makes the vector difference \\mathbf{A}\\mathbf{x}-\\mathbf{b} perpendicular to the range. Thus for any \\mathbf{z}, we must have (\\mathbf{A} \\mathbf{z})^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=0, which is satisfied if \\mathbf{A}^T(\\mathbf{A}\\mathbf{x}-\\mathbf{b})=\\boldsymbol{0}.\n\n\n\nFigure 3.2.1:Geometry of the normal equations. The smallest residual is orthogonal to the range of the matrix \\mathbf{A}.","type":"content","url":"/normaleqns","position":1},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Pseudoinverse and definiteness"},"type":"lvl2","url":"/normaleqns#pseudoinverse-and-definiteness","position":2},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Pseudoinverse and definiteness"},"content":"If we associate the left-hand side of the normal equations as (\\mathbf{A}^T\\mathbf{A})\\,\\mathbf{x}, we recognize \n\n(3.2.3) as a square n\\times n linear system to solve for \\mathbf{x}.\n\nPseudoinverse\n\nIf \\mathbf{A}\\in\\real^{m\\times n}  with m>n, its \n\npseudoinverse is the n\\times m matrix\\mathbf{A}^+ = (\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T.\n\nMathematically, the overdetermined least-squares problem \\mathbf{A}\\mathbf{x}\\approx \\mathbf{b} has the solution \\mathbf{x}=\\mathbf{A}^+\\mathbf{b}.\n\nComputationally we can generalize the observation about Julia from Chapter 2: backslash is equivalent mathematically to left-multiplication by the inverse (in the square case) or pseudoinverse (in the rectangular case) of a matrix. One can also compute the pseudoinverse directly using pinv, but as with matrix inverses, this is rarely necessary in practice.\n\nThe matrix \\mathbf{A}^T\\mathbf{A} appearing in the pseudoinverse has some important properties.\n\nFor any real m\\times n matrix \\mathbf{A} with m\\ge n, the following are true:\n\n\\mathbf{A}^T\\mathbf{A} is symmetric.\n\n\\mathbf{A}^T \\mathbf{A} is singular if and only if the columns of \\mathbf{A} are linearly dependent. (Equivalently, if and only if the rank of \\mathbf{A} is less than n.)\n\nIf \\mathbf{A}^T\\mathbf{A} is nonsingular, then it is positive definite.\n\nThe first part is left as \n\nExercise 3. For the second part, suppose that \\mathbf{A}^T\\mathbf{A}\\mathbf{z}=\\boldsymbol{0}. Note that \\mathbf{A}^T\\mathbf{A} is singular if and only if \\mathbf{z} may be nonzero. Left-multiplying by \\mathbf{z}^T, we find that0 = \\mathbf{z}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{z}=(\\mathbf{A}\\mathbf{z})^T(\\mathbf{A}\\mathbf{z}) = \\| \\mathbf{A}\\mathbf{z} \\|_2^2,\n\nwhich is equivalent to \\mathbf{A}\\mathbf{z}=\\boldsymbol{0}. Then \\mathbf{z} may be nonzero if and only if the columns of \\mathbf{A} are linearly dependent.\n\nFinally, we can repeat the manipulations above to show that for any nonzero n-vector \\mathbf{v}, \\mathbf{v}^T(\\mathbf{A}^T\\mathbf{A})\\mathbf{v}=\\| \\mathbf{A}\\mathbf{v} \\|_2^2\\ge 0, and equality is not possible thanks to the second part of the theorem.","type":"content","url":"/normaleqns#pseudoinverse-and-definiteness","position":3},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Implementation"},"type":"lvl2","url":"/normaleqns#implementation","position":4},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Implementation"},"content":"The definition of the pseudoinverse involves taking the inverse of a matrix, so it is not advisable to use the pseudoinverse computationally. Instead, we use the definition of the normal equations to set up a linear system, which we already know how to solve. In summary, the steps for solving the linear least squares problem \\mathbf{A}\\mathbf{x}\\approx\\mathbf{b} are:\n\nSolution of linear least squares by the normal equations\n\nCompute \\mathbf{N}=\\mathbf{A}^T\\mathbf{A}.\n\nCompute \\mathbf{z} = \\mathbf{A}^T\\mathbf{b}.\n\nSolve the n\\times n linear system \\mathbf{N}\\mathbf{x} = \\mathbf{z} for \\mathbf{x}.\n\nSteps 1 and 3 of \n\nAlgorithm 3.2.1 dominate the flop count.\n\nIn the last step we can exploit the fact, proved in \n\nTheorem 3.2.2, that \\mathbf{N} is symmetric and positive definite, and use Cholesky factorization as in \n\nExploiting matrix structure. This detail is included in \n\nFunction 3.2.2.\n\nlsnormal\n\nSolution of least squares by the normal equations\n\n\"\"\"\n    lsnormal(A, b)\n\nSolve a linear least-squares problem by the normal equations.\nReturns the minimizer of ||b-Ax||.\n\"\"\"\nfunction lsnormal(A, b)\n    N = A' * A\n    z = A' * b\n    R = cholesky(N).U\n    w = forwardsub(R', z)                   # solve R'z=c\n    x = backsub(R, w)                       # solve Rx=z\n    return x\nend\n\nAbout the code\n\nThe syntax on line 9 is a field reference to extract the matrix we want from the structure returned by cholesky.\n\nSolution of least squares by the normal equations\n\nfunction x = lsnormal(A,b)\r\n% LSNORMAL   Solve linear least squares by normal equations.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\nN = A'*A;  z = A'*b;\r\nR = chol(N);\r\nw = forwardsub(R',z);                   % solve R'z=c\r\nx = backsub(R,w);                       % solve Rx=z\n\nSolution of least squares by the normal equations\n\ndef lsnormal(A, b):\n    \"\"\"\n    lsnormal(A, b)\n    \n    Solve a linear least squares problem by the normal equations. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    N = A.T @ A\n    z = A.T @ b\n    R = scipy.linalg.cholesky(N)\n    w = forwardsub(R.T, z)                   # solve R'z=c\n    x = backsub(R, w)                        # solve Rx=z\n    return x\n\nAbout the code\n\ncholesky is imported from scipy.linalg.\n\nSolution of linear least squares by the normal equations takes \\sim (mn^2 + \\frac{1}{3}n^3) flops.","type":"content","url":"/normaleqns#implementation","position":5},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Conditioning and stability"},"type":"lvl2","url":"/normaleqns#conditioning-and-stability","position":6},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Conditioning and stability"},"content":"We have already used A\\b as the native way to solve the linear least-squares problem \\mathbf{A}\\mathbf{x}\\approx\\mathbf{b} in Julia. The algorithm employed by the backslash does not proceed through the normal equations, because of instability.\n\nThe conditioning of the linear least-squares problem relates changes in the solution \\mathbf{x} to those in the data, \\mathbf{A} and \\mathbf{b}. A full accounting of the condition number is too messy to present here, but we can get the main idea. We start by generalizing our previous definition of the matrix condition number.\n\nMatrix condition number (rectangular case)\n\nIf \\mathbf{A} is m\\times n with m > n, then its condition number is defined to be\\kappa(\\mathbf{A}) = \\|\\mathbf{A}\\|_2 \\cdot \\|\\mathbf{A}^{+}\\|_2.\n\nIf the rank of  \\mathbf{A} is less than n (i.e., if it has linearly dependent columns), then \\kappa(\\mathbf{A})=\\infty.\n\nProvided that the minimum residual norm \\|\\mathbf{b}-\\mathbf{A}\\mathbf{x}\\| is relatively small, the conditioning of the linear least-squares problem is close to \\kappa(\\mathbf{A}).\n\nAs an algorithm, the normal equations begin by computing the data for the n\\times n system (\\mathbf{A}^T\\mathbf{A})\\mathbf{x} = \\mathbf{A}^T \\mathbf{b}. When these equations are solved, perturbations to the data can be amplified by a factor \\kappa(\\mathbf{A}^T\\mathbf{A}).\n\nThe following can be proved using results in Chapter 7.\n\nCondition number in the normal equations\n\nIf \\mathbf{A} is m\\times n with m > n, then\\kappa(\\mathbf{A}^T\\mathbf{A}) = \\kappa(\\mathbf{A})^2.\n\nThis squaring of the condition number in the normal equations is the cause of instability. If \\kappa(\\mathbf{A}) is large, the squaring of it can destabilize the normal equations: while the solution of the least-squares problem is sensitive, finding it via the normal equations makes it doubly so.\n\nInstability in the normal equations\n\nExample 3.2.1\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nTip\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = range(0, 3, 400)\nf = [ x -> sin(x)^2, x -> cos((1 + 1e-7) * x)^2, x -> 1. ]\nA = [ f(t) for t in t, f in f ]\n@show κ = cond(A);\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1., 2, 1]\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b\n@show observed_error = norm(x_BS - x) / norm(x);\n@show error_bound = κ * eps();\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A' * A\nx_NE = N \\ (A'*b)\n@show observed_err = norm(x_NE - x) / norm(x);\n@show digits = -log10(observed_err);\n\nExample 3.2.1\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nTip\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nkappa = cond(A)\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1; 2; 1];\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b;\nobserved_err = norm(x_BS - x) / norm(x)\nmax_err = kappa * eps\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A'*A;\nx_NE = N\\(A'*b);\nobserved_err = norm(x_NE - x) / norm(x)\ndigits = -log10(observed_err)\n\nExample 3.2.1\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nfrom numpy.linalg import cond\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nkappa = cond(A)\nprint(f\"cond(A) is {kappa:.3e}\")\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = array([1, 2, 1])\nb = A @ x\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nfrom numpy.linalg import lstsq\nx_BS = lstsq(A, b, rcond=None)[0]\nprint(f\"observed error: {norm(x_BS - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {kappa * finfo(float).eps:.3e}\")\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A.T @ A\nx_NE = linalg.solve(N, A.T @ b)\nrelative_err = norm(x_NE - x) / norm(x)\nprint(f\"observed error: {relative_err:.3e}\")\nprint(f\"accurate digits: {-log10(relative_err):.2f}\")","type":"content","url":"/normaleqns#conditioning-and-stability","position":7},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Exercises"},"type":"lvl2","url":"/normaleqns#exercises","position":8},{"hierarchy":{"lvl1":"The normal equations","lvl2":"Exercises"},"content":"✍ Work out the least-squares solution when\\mathbf{A} = \\begin{bmatrix}\n  2 & -1 \\\\\n  0 & 1 \\\\\n  -2 & 2\n\\end{bmatrix}, \\qquad \\mathbf{b} =\n\\begin{bmatrix}\n  1\\\\-5\\\\6\n\\end{bmatrix}.\n\n✍ Use \n\n(3.2.4) to find the pseudoinverse \\mathbf{A}^+ of the matrix \\mathbf{A}=\\begin{bmatrix}1&-2&3\\end{bmatrix}^T.\n\n✍ Prove the first statement of \n\nTheorem 3.2.2: \\mathbf{A}^T\\mathbf{A} is symmetric for any m\\times n matrix \\mathbf{A} with m \\ge n.\n\n✍ Prove that if \\mathbf{A} is an invertible square matrix, then \\mathbf{A}^+=\\mathbf{A}^{-1}.\n\n(a) ✍ Show that for any m\\times n \\mathbf{A} with m>n for which \\mathbf{A}^T\\mathbf{A} is nonsingular, \\mathbf{A}^+\\mathbf{A} is the n\\times n identity.\n\n(b) ⌨ Show using an example in Julia that \\mathbf{A}\\mathbf{A}^+ is not an identity matrix. (This matrix has rank no greater than n, so it can’t be an m\\times m identity.)\n\n✍ Prove that the vector \\mathbf{A}\\mathbf{A}^+\\mathbf{b} is the vector in the column space (i.e., range) of \\mathbf{A} that is closest to \\mathbf{b} in the sense of the 2-norm.\n\n✍ Show that the flop count for \n\nFunction 3.2.2 is asymptotically \\sim 2m n^2 + \\tfrac{1}{3}n^3. (In finding the asymptotic count you can ignore terms like m n whose total degree is less than 3.)\n\n⌨ Let t_1,\\ldots,t_m be m equally spaced points in [0,2\\pi]. In this exercise, use m=500.\n\n(a) Let \\mathbf{A}_\\beta be the matrix in \n\n(3.1.2) that corresponds to fitting data with the function c_1 + c_2 \\sin(t) + c_3 \\cos(\\beta t). Using the identity \n\n(3.2.7), make a table of the condition numbers of \\mathbf{A}_\\beta for \\beta = 2,1.1,1.01,\\ldots,1+10^{-8}.\n\n(b) Repeat part (a) using the fitting function c_1 + c_2 \\sin^2(t) + c_3 \\cos^2(\\beta t).\n\n(c) Why does it make sense that \\kappa\\bigl(\\mathbf{A}_\\beta\\bigr)\\to \\infty as \\beta\\to 1 in part (b) but not in part (a)?\n\n✍ ⌨  When \\mathbf{A} is m\\times n with rank less than n, the pseudoinverse is still defined and can be computed using pinv from LinearAlgebra. However, the behavior in this case is not always intuitive. Let\\mathbf{A}_s =\n\\begin{bmatrix}\n  1 & 1 \\\\ 0 & 0 \\\\ 0 & s\n\\end{bmatrix}.\n\nThen \\mathbf{A}_0 has rank equal to 1. Demonstrate experimentally that \\mathbf{A}_0^+\\neq \\lim_{s\\to 0} \\mathbf{A}_s^+.","type":"content","url":"/normaleqns#exercises","position":9},{"hierarchy":{"lvl1":"3. Overdetermined linear systems"},"type":"lvl1","url":"/overview-2","position":0},{"hierarchy":{"lvl1":"3. Overdetermined linear systems"},"content":"I must have hit pretty close to the mark to get her all riled up like that, huh, kid?\n\nHan Solo, The Empire Strikes Back\n\nSo far we have considered \\mathbf{A}\\mathbf{x}=\\mathbf{b} only when \\mathbf{A} is a square matrix. In this chapter we consider how to interpret and solve the problem for an m\\times n matrix where m>n—and in practice, m is often much larger than n. This is called an overdetermined linear system because, in general, the system has more equations to satisfy than the variables allow. The complementary underdetermined case m<n turns up less frequently and will not be considered in this book.\n\nSince we cannot solve all of the system’s equations, we need to define what the “best possible” answer is. There are multiple useful options, but the most important version of the overdetermined problem occurs using the least squares—the sum of the squares of the equation residuals is minimized. This is far from an arbitrary choice. Mathematically, we recognize the sum-of-squares as a vector 2-norm and therefore tied to inner products; physically, the 2-norm may coincide with energy, which is often minimized by natural systems; and statistically, least squares leads to the estimates of maximum likelihood for certain models. Furthermore, the solution of the least-squares problem requires only linear algebra and is about as easily to compute as in the square case.\n\nThe linear least-squares problem serves as our introduction to the vast field of optimization. It is one of the simplest problems of this type. We will see an extension to a nonlinear version in the next chapter.","type":"content","url":"/overview-2","position":1},{"hierarchy":{"lvl1":"The QR factorization"},"type":"lvl1","url":"/qr","position":0},{"hierarchy":{"lvl1":"The QR factorization"},"content":"Sets of vectors satisfying a certain property are useful both theoretically and computationally.\n\nOrthogonal vectors\n\nTwo vectors \\mathbf{u} and \\mathbf{v} in \\mathbb{R}^n are orthogonal if \\mathbf{u}^T\\mathbf{v}=0. We say that a collection of vectors \\mathbf{q}_1,\\ldots,\\mathbf{q}_k is orthogonal ifi \\neq j \\quad \\Rightarrow \\quad \\mathbf{q}_i^T\\mathbf{q}_j = 0.\n\nIf \n\n(3.3.1) applies and also \\mathbf{q}_i^T\\mathbf{q}_i=1 for all i=1,\\ldots,n, we say the vectors are orthonormal.\n\nIn two and three dimensions, orthogonality is the same as perpendicularity.\n\nOrthogonal vectors simplify inner products. For example, if \\mathbf{q}_1 and \\mathbf{q}_2 are orthogonal, then\\| \\mathbf{q}_1 - \\mathbf{q}_2 \\|_2^2 = (\\mathbf{q}_1-\\mathbf{q}_2)^T(\\mathbf{q}_1-\\mathbf{q}_2)\n= \\mathbf{q}_1^T\\mathbf{q}_1 - 2 \\mathbf{q}_1^T\\mathbf{q}_2 + \\mathbf{q}_2^T\\mathbf{q}_2\n= \\|\\mathbf{q}_1\\|_2^2 + \\|\\mathbf{q}_2\\|_2^2.\n\nAs in the rest of this chapter, we will be using the 2-norm exclusively.\n\nEquation \n\n(3.3.2) is the key to the computational attractiveness of orthogonality. \n\nFigure 3.3.1 shows how nonorthogonal vectors can allow a multidimensional version of subtractive cancellation, in which \\|\\mathbf{x}-\\mathbf{y}\\| is much smaller than \\|\\mathbf{x}\\| and \\|\\mathbf{y}\\|. As the figure illustrates, orthogonal vectors do not allow this phenomenon. By \n\n(3.3.2), the magnitude of a vector difference or sum is larger than the magnitudes of the original vectors.\n\n\n\nFigure 3.3.1:Nonorthogonal vectors can cause cancellation when subtracted, but orthogonal vectors never do.\n\nAddition and subtraction of vectors are guaranteed to be well conditioned when the vectors are orthogonal.","type":"content","url":"/qr","position":1},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal and ONC matrices"},"type":"lvl2","url":"/qr#orthogonal-and-onc-matrices","position":2},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal and ONC matrices"},"content":"Statements about orthogonal vectors are often made more easily in matrix form. Let \\mathbf{Q} be an n\\times k matrix whose columns \\mathbf{q}_1, \\ldots, \\mathbf{q}_k are orthogonal vectors. The orthogonality conditions \n\n(3.3.1) become simply that \\mathbf{Q}^T\\mathbf{Q} is a diagonal matrix, since\\mathbf{Q}^T \\mathbf{Q} =\n\\begin{bmatrix}\n\\mathbf{q}_1^T \\\\[1mm] \\mathbf{q}_2^T \\\\ \\vdots \\\\ \\mathbf{q}_k^T\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{q}_1 & \\mathbf{q}_2 &  \\cdots & \\mathbf{q}_k\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{q}_1^T\\mathbf{q}_1 & \\mathbf{q}_1^T\\mathbf{q}_2 & \\cdots & \\mathbf{q}_1^T\\mathbf{q}_k \\\\[1mm]\n\\mathbf{q}_2^T\\mathbf{q}_1 & \\mathbf{q}_2^T\\mathbf{q}_2 & \\cdots & \\mathbf{q}_2^T\\mathbf{q}_k \\\\\n\\vdots & \\vdots & & \\vdots \\\\\n\\mathbf{q}_k^T\\mathbf{q}_1 & \\mathbf{q}_k^T\\mathbf{q}_2 & \\cdots & \\mathbf{q}_k^T\\mathbf{q}_k\n\\end{bmatrix}.\n\nIf the columns of \\mathbf{Q} are orthonormal, then \\mathbf{Q}^T\\mathbf{Q} is the k\\times k identity matrix. This is such an important property that we will break with common practice here and give this type of matrix a name.\n\nONC matrix\n\nAn ONC matrix is one whose columns are an orthonormal set of vectors.\n\nONC matrix\n\nSuppose \\mathbf{Q} is a real n\\times k ONC matrix (matrix with orthonormal columns). Then:\n\n\\mathbf{Q}^T\\mathbf{Q} = \\mathbf{I} (k\\times k identity).\n\n\\| \\mathbf{Q}\\mathbf{x} \\|_2 = \\| \\mathbf{x} \\|_2 for all k-vectors \\mathbf{x}.\n\n\\| \\mathbf{Q} \\|_2=1.\n\nThe first part is derived above. The second part follows a pattern that has become well established by now:\\| \\mathbf{Q}\\mathbf{x} \\|_2^2 = (\\mathbf{Q}\\mathbf{x})^T(\\mathbf{Q}\\mathbf{x}) = \\mathbf{x}^T \\mathbf{Q}^T \\mathbf{Q} \\mathbf{x} = \\mathbf{x}^T \\mathbf{I} \\mathbf{x} = \\| \\mathbf{x} \\|_2^2.\n\nThe last part of the theorem is left to the exercises.\n\nOf particular interest is a square ONC matrix.\n\nAn orthogonal matrix is a square matrix with orthonormal columns.\n\nOrthogonal matrices have properties beyond \n\nTheorem 3.3.1.\n\nOrthogonal matrix\n\nSuppose \\mathbf{Q} is an n\\times n real orthogonal matrix. Then:\n\n\\mathbf{Q}^T = \\mathbf{Q}^{-1}.\n\n\\mathbf{Q}^T is also an orthogonal matrix.\n\n\\kappa(\\mathbf{Q})=1 in the 2-norm.\n\nFor any other n\\times n matrix \\mathbf{A}, \\| \\mathbf{A}\\mathbf{Q} \\|_2=\\| \\mathbf{A} \\|_2.\n\nIf \\mathbf{U} is another n\\times n orthogonal matrix, then \\mathbf{Q}\\mathbf{U} is also orthogonal.\n\nSince \\mathbf{Q} is an ONC matrix, \\mathbf{Q}^T\\mathbf{Q}=\\mathbf{I}. All three matrices are n\\times n, so \\mathbf{Q}^{-1}=\\mathbf{Q}^T. The proofs of the other statements are left to the exercises.","type":"content","url":"/qr#orthogonal-and-onc-matrices","position":3},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal factorization"},"type":"lvl2","url":"/qr#orthogonal-factorization","position":4},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Orthogonal factorization"},"content":"Now we come to another important way to factor a matrix: the QR factorization. As we will show below, the QR factorization plays a role in linear least squares analogous to the role of LU factorization in linear systems.\n\nQR factorization\n\nEvery real m\\times n matrix \\mathbf{A} (m\\ge n) can be written as \\mathbf{A}=\\mathbf{Q}\\mathbf{R}, where \\mathbf{Q} is an m\\times m orthogonal matrix and \\mathbf{R} is an m\\times n upper triangular matrix.\n\nIn most introductory books on linear algebra, the QR factorization is derived through a process known as Gram–Schmidt orthogonalization. However, while it is an important tool for theoretical work, the Gram–Schmidt process is numerically unstable. We will consider an alternative construction in \n\nComputing QR factorizations.\n\nWhen m is much larger than n, which is often the case, there is a compressed form of the factorization that is more efficient. In the product\\mathbf{A} =\n\\begin{bmatrix}\n\\mathbf{q}_1 & \\mathbf{q}_2 & \\cdots & \\mathbf{q}_m\n\\end{bmatrix}\n\\begin{bmatrix}\nr_{11} & r_{12} & \\cdots & r_{1n} \\\\\n0 & r_{22} & \\cdots &  r_{2n} \\\\\n\\vdots & & \\ddots & \\vdots\\\\\n0 & 0 & \\cdots & r_{nn} \\\\\n0 & 0 & \\cdots & 0 \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\n0 & 0 & \\cdots & 0\n\\end{bmatrix},\n\nthe vectors \\mathbf{q}_{n+1},\\ldots,\\mathbf{q}_m always get multiplied by zero. Nothing about \\mathbf{A} is lost if we delete them and reduce the factorization to the equivalent form\\mathbf{A} =\n\\begin{bmatrix}\n\\mathbf{q}_1 & \\mathbf{q}_2 & \\cdots & \\mathbf{q}_n\n\\end{bmatrix}\n\\begin{bmatrix}\nr_{11} & r_{12} & \\cdots & r_{1n} \\\\\n0 & r_{22} & \\cdots &  r_{2n} \\\\\n\\vdots & & \\ddots & \\vdots\\\\\n0 & 0 & \\cdots & r_{nn}\n\\end{bmatrix} = \\hat{\\mathbf{Q}} \\hat{\\mathbf{R}}.\n\nThin QR factorization\n\nThe thin QR factorization is \\mathbf{A} = \\hat{\\mathbf{Q}} \\hat{\\mathbf{R}}, where \\hat{\\mathbf{Q}} is m\\times n and ONC, and \\hat{\\mathbf{R}} is n\\times n and upper triangular.\n\nQR factorization\n\nExample 3.3.1\n\nJulia provides access to both the thin and full forms of the QR factorization.\n\nA = rand(1.:9., 6, 4)\n@show m,n = size(A);\n\nHere is a standard call:\n\nQ,R = qr(A);\nQ\n\nR\n\nIf you look carefully, you see that we seemingly got a full \\mathbf{Q} but a thin \\mathbf{R}. However, the \\mathbf{Q} above is not a standard matrix type. If you convert it to a true matrix, then it reverts to the thin form.\n\nTip\n\nTo enter the accented character Q̂, type Q\\hat followed by Tab.\n\nQ̂ = Matrix(Q)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nopnorm(Q' * Q - I)\n\nThe thin \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC:\n\nQ̂' * Q̂ - I\n\nExample 3.3.1\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = magic(5);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nHere is the full form:\n\n[Q, R] = qr(A);\nszQ = size(Q), szR = size(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nQTQ = Q' * Q\nnorm(QTQ - eye(m))\n\nWith a second input argument given to qr, the thin form is returned. (This is usually the one we want in practice.)\n\n[Q_hat, R_hat] = qr(A, 0);\nszQ_hat = size(Q_hat), szR_hat = size(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nQ_hat' * Q_hat - eye(n)\n\nExample 3.3.1\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nA.shape\n\nHere is the full form:\n\nfrom numpy.linalg import qr\nQ, R = qr(A, \"complete\")\nprint(f\"size of Q is {Q.shape}\")\nprint(\"R:\")\nprint(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nprint(f\"norm of (Q^T Q - I) is {norm(Q.T @ Q - eye(6)):.3e}\")\n\nThe default for qr, and the one you usually want, is the thin form.\n\nQ_hat, R_hat = qr(A)\nprint(f\"size of Q_hat is {Q_hat.shape}\")\nprint(\"R_hat:\")\nprint(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nprint(f\"norm of (Q_hat^T Q_hat - I) is {norm(Q_hat.T @ Q_hat - eye(4)):.3e}\")","type":"content","url":"/qr#orthogonal-factorization","position":5},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Least squares and QR"},"type":"lvl2","url":"/qr#least-squares-and-qr","position":6},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Least squares and QR"},"content":"If we substitute the thin factorization \n\n(3.3.6) into the normal equations \n\n(3.2.3), we can simplify expressions a great deal.\\begin{split}\n  \\mathbf{A}^T\\mathbf{A} \\mathbf{x} &= \\mathbf{A}^T \\mathbf{b}, \\\\\n  \\hat{\\mathbf{R}}^T \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} \\hat{\\mathbf{R}} \\mathbf{x} &= \\hat{\\mathbf{R}}^T \\hat{\\mathbf{Q}}^T \\mathbf{b}, \\\\\n  \\hat{\\mathbf{R}}^T \\hat{\\mathbf{R}} \\mathbf{x}& = \\hat{\\mathbf{R}}^T \\hat{\\mathbf{Q}}^T \\mathbf{b}.\n\\end{split}\n\nIn order to have the normal equations be well posed, we require that \\mathbf{A} is not rank-deficient (as proved in \n\nTheorem 3.2.2). This is enough to guarantee that \\hat{\\mathbf{R}} is nonsingular (see \n\nExercise 4). Therefore, its transpose is nonsingular as well, and we arrive at\\hat{\\mathbf{R}} \\mathbf{x}=\\hat{\\mathbf{Q}}^T \\mathbf{b}.\n\nSolution of linear least squares by thin QR\n\nCompute the thin QR factorization \\hat{\\mathbf{Q}}\\hat{\\mathbf{R}}=\\mathbf{A}.\n\nCompute \\mathbf{z} = \\hat{\\mathbf{Q}}^T\\mathbf{b}.\n\nSolve the n\\times n linear system \\hat{\\mathbf{R}}\\mathbf{x} = \\mathbf{z} for \\mathbf{x}.\n\nThis algorithm is implemented in \n\nFunction 3.3.2. It is essentially the algorithm used internally by Julia when A\\b is called. The execution time is dominated by the factorization, the most common method for which is described in \n\nComputing QR factorizations.\n\nlsqrfact\n\nSolution of least squares by QR factorization\n\n\"\"\"\n    lsqrfact(A, b)\n\nSolve a linear least-squares problem by QR factorization. Returns\nthe minimizer of ||b-Ax||.\n\"\"\"\nfunction lsqrfact(A, b)\n    Q, R = qr(A)\n    c = Q' * b\n    x = backsub(R, c)\n    return x\nend\n\nSolution of least squares by QR factorization\n\nfunction x = lsqrfact(A,b)\r\n% LSQRFACT   Solve linear least squares by QR factorization.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\n[Q,R] = qr(A,0);                        % compressed factorization\r\nc = Q'*b;\r\nx = backsub(R,c);                       \n\nSolution of least squares by QR factorization\n\ndef lsqrfact(A, b):\n    \"\"\"\n    lsqrfact(A, b)\n    \n    Solve a linear least squares problem by QR factorization. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    Q, R = np.linalg.qr(A)\n    c = Q.T @ b\n    x = backsub(R, c)\n    return x\n\nThe solution of least-squares problems via QR factorization is more stable than when the normal equations are formulated and solved directly.\n\nStability of least-squares via QR\n\nExample 3.3.2\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = range(0, 3, 400)\nf = [ x -> sin(x)^2, x -> cos((1 + 1e-7) * x)^2, x -> 1. ]\nA = [ f(t) for t in t, f in f ]\nx = [1., 2, 1]\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(FNC.lsqrfact(A, b) - x) / norm(x);\n@show observed_error;\n@show error_bound = cond(A) * eps();\n\nExample 3.3.2\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nx = [1; 2; 1];\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(lsqrfact(A, b) - x) / norm(x)\nerror_bound = cond(A) * eps\n\nExample 3.3.2\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nx = array([1, 2, 1])\nb = A @ x\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nprint(f\"observed error: {norm(FNC.lsqrfact(A, b) - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {cond(A) * finfo(float).eps:.3e}\")","type":"content","url":"/qr#least-squares-and-qr","position":7},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Exercises"},"type":"lvl2","url":"/qr#exercises","position":8},{"hierarchy":{"lvl1":"The QR factorization","lvl2":"Exercises"},"content":"✍ Prove part 3 of \n\nTheorem 3.3.1.\n\n✍ Prove \n\nTheorem 3.3.2. For the third part, use the definition of the 2-norm as an induced matrix norm, then apply some of our other results as needed.\n\n⌨ Let t_0,\\ldots,t_m be m+1 equally spaced points in [-1,1]. Let \\mathbf{A} be the matrix in \n\n(3.1.2) for m=400 and fitting by polynomials of degree less than 5. Find the thin QR factorization of \\mathbf{A}, and, on a single graph, plot every column of \\hat{\\mathbf{Q}} as a function of the vector t.\n\n✍ Prove that if the m\\times n (m\\ge n) matrix \\mathbf{A} is not rank-deficient, then the factor \\hat{\\mathbf{R}} of the thin QR factorization is invertible. (Hint: Suppose on the contrary that \\hat{\\mathbf{R}} is singular. Show using the factored form of \\mathbf{A} that this would imply that \\mathbf{A} is rank-deficient.)\n\n✍ Let \\mathbf{A} be m\\times n with m>n. Show that if \\mathbf{A}=\\mathbf{Q}\\mathbf{R} is a QR factorization and \\mathbf{R} has rank n, then \\mathbf{A}^+=\\mathbf{R}^+\\mathbf{Q}^T.\n\n✍ Let \\mathbf{A} be m\\times n with m>n. Show that if \\mathbf{A}=\\hat{\\mathbf{Q}}\\hat{\\mathbf{R}} is a thin QR factorization and \\hat{\\mathbf{R}} is invertible, then \\mathbf{A}^+=\\hat{\\mathbf{R}}^{-1}\\hat{\\mathbf{Q}}^T.\n\n⌨ Repeat \n\nExercise 3.1.2, but use thin QR factorization rather than the backslash to solve the least-squares problem.\n\n✍ The matrix \\mathbf{P}=\\hat{\\mathbf{Q}} \\hat{\\mathbf{Q}}^T derived from the thin QR factorization has some interesting and important properties.\n\n(a) Prove that \\mathbf{P}=\\mathbf{A}\\mathbf{A}^+.\n\n(b) Prove that \\mathbf{P}^2=\\mathbf{P}. (This property defines a projection matrix.)\n\n(c) Any vector \\mathbf{x} may be written trivially as \\mathbf{x}=\\mathbf{u}+\\mathbf{v}, where \\mathbf{u}=\\mathbf{P}\\mathbf{x} and \\mathbf{v}=(\\mathbf{I}-\\mathbf{P})\\mathbf{x}. Prove that \\mathbf{u} and \\mathbf{v} are orthogonal. (Together with part (b), this means that \\mathbf{P} is an orthogonal projector.)\n\nConfusingly, a square matrix whose columns are orthogonal is not necessarily an orthogonal matrix; the columns must be orthonormal, which is a stricter condition.","type":"content","url":"/qr#exercises","position":9},{"hierarchy":{"lvl1":"Fixed-point iteration"},"type":"lvl1","url":"/fixed-point","position":0},{"hierarchy":{"lvl1":"Fixed-point iteration"},"content":"In this section, we consider the alternative form of the rootfinding problem known as the fixed-point problem.\n\nFixed-point problem\n\nGiven a function g, the fixed-point problem is to find a value p, called a fixed point, such that g(p)=p.\n\nGiven f for rootfinding, we could define g(x)=x-f(x), and then f(r)=0 implies g(r)=r and vice versa. There are infinitely many ways to make this transformation, such as g(x)=x+cf(x) for any constant c. The process can be reversed, too. Given g(x), we could define f(x)=x-g(x), and then g(p)=p implies f(p)=0.\n\nThere is an extraordinarily simple way to try to find a fixed point of any given g(x).\n\nFixed-point iteration\n\nGiven function g and initial value x_1, define  x_{k+1} = g(x_k), \\qquad k=1,2,\\ldots.\n\nThis is our first example of an iterative algorithm that never quite gets to the answer, even if we use exact numbers. The idea is to generate a sequence of values that one hopes will converge to the correct result, and stop when we are satisfied that we are close enough to the limit.\n\nFixed-point iteration\n\nExample 4.2.1\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nusing Polynomials\np = Polynomial([3.5, -4,1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nWe define g(x)=x-p(x).\n\ng(x) = x - p(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nusing Plots\nplt = plot([g x->x], 2, 3;\n    l=2, label=[L\"y=g(x)\" L\"y=x\"],\n    xlabel=L\"x\",  ylabel=L\"y\", \n    aspect_ratio=1,\n    title=\"Finding a fixed point\",  legend=:bottomright)\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot!([x, y], [y, y], arrow=true, color=3)\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y;  y = g(x)\nplot!([x, x], [x, y], arrow=true, color=4)\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot!([x, y], [y, y], color=3);  \n    x = y       # y becomes the new x\n    y = g(x)    # g(x) becomes the new y\n    plot!([x, x], [x, y], color=4)  \nend\nplt\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - rmax) / rmax\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nplt = plot([g x->x], 1, 2, l=2, label=[\"y=g(x)\" \"y=x\"], aspect_ratio=1, \n    xlabel=L\"x\", ylabel=L\"y\", title=\"Divergence\", legend=:bottomright)\n\nx = 1.3; y = g(x);\narrow = false\nfor k = 1:5\n    plot!([x, y], [y, y], arrow=arrow, color=3)  \n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    plot!([x, x], [x, y], arrow=arrow, color=4)\n    if k > 2; arrow = true; end\nend\nplt\n\nThis time, the iteration is pushing us away from the correct answer.\n\nExample 4.2.1\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5])\n\nWe define g(x)=x-p(x).\n\ng = @(x) x - f(x);\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nclf\nfplot(g, [2, 3])\nhold on,  plot([2, 3], [2, 3], 'k')\ntitle('Finding a fixed point'),  axis equal  \nxlabel('x'),  ylabel('y')\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot([x, y], [y, y], '-')\nx = y;\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\ny = g(x)\nplot([x, x],[x, y], '-')\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot([x, y], [y, y], '-')\n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-')  \nend\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - r(1)) / r(1)\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\ncla\nfplot(g, [1, 2])\nhold on, plot([1, 2], [1, 2], 'k')\nylim([1, 2])\nx = 1.3;  y = g(x);\nfor k = 1:5\n    plot([x, y], [y, y], '-'),  \n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-') \nend\ntitle('No convergence')\n\nThis time, the iteration is pushing us away from the correct answer.\n\nExample 4.2.1\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nWe define g(x)=x - f(x).\n\ng = lambda x: x - f(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nfig, ax = subplots()\ng = lambda x: x - f(x)\nxx = linspace(2, 3, 400)\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\naxis(\"equal\"), legend()\ntitle(\"Finding a fixed point\");\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1\ny = g(x)\nprint(y)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nax.plot([x, y], [y, y], \"r:\", label=\"\")\nfig\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y\ny = g(x)\nprint(\"y:\", y)\nax.plot([x, x], [x, y], \"k:\")\nfig\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    ax.plot([x, x], [x, y], \"k:\")  \nfig\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nprint(abs(y - max(r)) / max(r))\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nxx = linspace(1, 2, 400)\nfig, ax = subplots()\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\nax.set_aspect(1.0)\nax.legend()\n\nx = 1.3\ny = g(x)\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y\n    y = g(x)\n    ax.plot([x, x], [x, y], \"k:\")\nylim(1, 2.5)\ntitle(\"No convergence\");\n\nThis time, the iteration is pushing us away from the correct answer.","type":"content","url":"/fixed-point","position":1},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Series analysis"},"type":"lvl2","url":"/fixed-point#series-analysis","position":2},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Series analysis"},"content":"In \n\nDemo 4.2.1, the two computed iterations differ only in the choice of x_1. In the first case we evidently generated a sequence that converged to one of the fixed points. In the second case, however, the generated sequence diverged. The easiest way to uncover the essential difference between the two cases is to use a Taylor series expansion.\n\nSuppose a fixed point p is the desired limit of an iteration x_1,x_2,\\ldots. It’s often easier to express quantities in terms of the error sequence \\epsilon_1,\\epsilon_2,\\ldots, where \\epsilon_k=x_k-p. Starting from \n\n(4.2.1), we have\\begin{split}\n  \\epsilon_{k+1}+p = g( \\epsilon_{k}+p ) = g(p) + g'(p) \\epsilon_k + \\frac{1}{2}g''(p) \\epsilon_k^2 + \\cdots,\n\\end{split}\n\nassuming that g has at least two continuous derivatives. But by definition, g(p)=p, so  \\epsilon_{k+1} = g'(p) \\epsilon_k + O(\\epsilon_k^2).\n\nIf the iteration is to converge to p, the errors must approach zero. In this case we can neglect the second-order term and conclude that \\epsilon_{k+1} \\approx g'(p) \\epsilon_k. This is consistent with convergence if |g'(p)|<1. However, if |g'(p)| >1, we are led to the conclusion that the errors must grow, not vanish, even if they start quite small.\n\nfixed-point iteration for a differentiable g(x) converges to a fixed point p if the initial error is sufficiently small and |g'(p)|< 1. The iteration diverges for all initial values if |g'(p)| > 1.\n\nThe role of g'(p) is clear in \n\nDemo 4.2.1. We have g(x) = -x^2+5x-3.5 and g'(x)=-2x+5. For the first fixed point, near 2.71, we get g'(p)\\approx-0.42, indicating convergence. For the second fixed point, near 1.29, we get g'(p)\\approx 2.42, which is consistent with the observed divergence.","type":"content","url":"/fixed-point#series-analysis","position":3},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Linear convergence"},"type":"lvl2","url":"/fixed-point#linear-convergence","position":4},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Linear convergence"},"content":"In computation we usually want to know not just whether an iteration converges but also the rate at which convergence occurs, i.e., how quickly the errors approach zero. Other things being equal, faster convergence is preferred to slower convergence, as it usually implies that the computation will take less time to achieve a desired accuracy.\n\nThe prediction of the series analysis above is that if the fixed-point iteraion converges, the errors approximately satisfy |\\epsilon_{k+1}| = \\sigma|\\epsilon_k|, for \\sigma = |g'(p)| < 1. This is a well-known type of convergence.\n\nLinear convergence\n\nSuppose a sequence x_k approaches limit x^*. If the error sequence \\epsilon_k=x_k - x^* satisfies  \\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|} = \\sigma < 1,\n\nthen the sequence displays linear convergence. The number σ is called the convergence rate.\n\nIf we suppose that the ratios in \n\n(4.2.4) all equal σ (i.e., perfect linear convergence), then |\\epsilon_k| = C \\sigma^k. Taking logs, we get  \\log |\\epsilon_k| = k(\\log \\sigma) + (\\log C).\n\nThis is in the form \\log |\\epsilon_k| = \\alpha k + \\beta, which is a linear relationship.\n\nLinear convergence in practice\n\nLinear convergence is marked by an approximate reduction of the error at each iteration by a constant factor, the convergence rate σ. When graphed on a log-linear scale, the errors lie on a straight line whose slope is the log of the convergence rate. Both phenomena manifest most strongly at the latest iterations.\n\nConvergence of fixed-point iteration\n\nExample 4.2.3\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\np = Polynomial([3.5, -4, 1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nHere is the fixed-point iteration. This time we keep track of the whole sequence of approximations.\n\ng(x) = x - p(x)\nx = [2.1]\nfor k = 1:12\n    push!(x, g(x[k]))\nend\nx\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = @. abs(x - rmax)\nplot(0:12, err;\n    m=:o,\n    xaxis=(\"iteration number\"),  yaxis=(\"error\", :log10),\n    title=\"Convergence of fixed-point iteration\")\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log.(err[5:12])\np = Polynomials.fit(5:12, y, 1)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nσ = exp(p.coeffs[2])\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\n[err[i+1] / err[i] for i in 8:11]\n\nThe methods for finding σ agree well.\n\nExample 4.2.3\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5]);\n\nHere is the fixed-point iteration. This time we keep track of the whole sequence of approximations.\n\ng = @(x) x - f(x);\nx = 2.1; \nfor k = 1:12\n    x(k+1) = g(x(k));\nend\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - r(1));\nclf\nsemilogy(err, 'o-'), axis tight\nxlabel('iteration'),  ylabel('error')\ntitle('Convergence of fixed-point iteration')\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log(err(5:12));\np = polyfit(5:12, y, 1);\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nsigma = exp(p(1))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr(9:12) ./ err(8:11)\n\nThe methods for finding σ agree well.\n\nExample 4.2.3\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nHere is the fixed-point iteration. This time we keep track of the whole sequence of approximations.\n\ng = lambda x: x - f(x)\nx = zeros(12)\nx[0] = 2.1\nfor k in range(11):\n    x[k + 1] = g(x[k])\n\nprint(x)\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - max(r))\nsemilogy(err, \"-o\")\nxlabel(\"iteration number\"), ylabel(\"error\")\ntitle(\"Convergence of fixed-point iteration\");\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\np = polyfit(arange(5, 13), log(err[4:]), 1)\nprint(p)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nprint(\"sigma:\", exp(p[0]))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr[8:] / err[7:-1]\n\nThe methods for finding σ agree well.","type":"content","url":"/fixed-point#linear-convergence","position":5},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Contraction maps"},"type":"lvl2","url":"/fixed-point#contraction-maps","position":6},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Contraction maps"},"content":"The convergence condition \\sigma=|g'(p)|<1 derived by series expansion is a special case of a more general condition.\n\nA function g is said to satisfy a Lipschitz condition with constant L on the interval S\\subset\\mathbb{R} if, for all s,t\\in S,    \\bigl| g(s)-g(t) \\bigr| \\le L \\bigl| s-t \\bigr|.\n\nIt can be shown that a function satisfying \n\n(4.2.6) is continuous in S. If L<1, we call g a contraction mapping because distances between points all decrease after an application of g. This situation leads to a major result about fixed points.\n\nContraction mapping\n\nSuppose that g satisfies \n\n(4.2.6) with L<1 on an interval S. Then S contains exactly one fixed point p of g. If x_1,x_2,\\ldots are generated by the fixed-point iteraion \n\n(4.2.1), and x_1,x_2,\\ldots all lie in S, then |x_k-p|\\le L^{k-1} |x_1-p| for all k>1.\n\n(partial proof)  First we show there is at most one fixed point in S. Suppose g(t)=t and g(s)=s in S. Then by \n\n(4.2.6), |s-t|=|g(s)-g(t)|\\le L|s-t|, which for L<1 is possible only if |s-t|=0, so s=t.\n\nNow suppose that for some p\\in S, g(p)=p. By the definition of the fixed-point iteraion and the Lipschitz condition,|x_{k+1} - p | = |g(x_k) - g(p)| \\le L |x_k-p|,\n\nwhich shows that x_k\\to p as k\\to \\infty. To show that p must exist and complete the proof, one needs to apply the Cauchy theory of convergence of a sequence, which is beyond the scope of this text.\n\nFrom the Fundamental Theorem of Calculus, which asserts that g(s)-g(t)=\\int_s^t g'(x)\\, dx, it’s easy to conclude that an upper bound of |g'(x)|\\le L for all x results in \n\n(4.2.6). Hence:\n\nIf |g'(x)|\\le L < 1 for all x in an interval S, then the conclusions of \n\nTheorem 4.2.1 apply.\n\nThere are stronger and more general statements of \n\nTheorem 4.2.1. For instance, it’s possible to show that all initial x_1 that are sufficiently close to the fixed point will lead to convergence of the iteration. Algorithmically the main virtue of the fixed-point iteraion is that it is incredibly easy to apply. However, as we are about to discover, it’s far from the fastest option.","type":"content","url":"/fixed-point#contraction-maps","position":7},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Exercises"},"type":"lvl2","url":"/fixed-point#exercises","position":8},{"hierarchy":{"lvl1":"Fixed-point iteration","lvl2":"Exercises"},"content":"✍ In each case, show that the given g(x) has a fixed point at the given p and use \n\n(4.2.3) to show that fixed-point iteraion can converge to it.\n\n(a) g(x) = 1 + x - \\frac{1}{9}x^2, p=3\n\n(b) g(x) = \\pi + \\frac{1}{4}\\sin(x), p=\\pi\n\n(c) g(x) = x+1-\\tan(x/4), p=\\pi\n\n⌨ For each case in the preceding problem, apply 25 fixed-point iterations and use a log-linear graph of the error to verify linear convergence. Then use numerical values of the error to determine an approximate value for σ in \n\n(4.2.4).\n\n✍  In each case, show that the given g(x) has a fixed point at the given p. Then determine analytically whether the fixed-point iteration could converge to that point given a close enough starting value.\n\n(a) g(x) = 3+x-x^2, p=\\sqrt{3}\n\n(b) g(x) = \\sqrt{1+x}, p=(1+\\sqrt{5})/2\n\n(c) g(x) = -\\sqrt{1+x}, p=(1-\\sqrt{5})/2\n\n(d) g(x) = x+1-\\tan(\\pi x), p=1/4\n\nIn \n\nDemo 4.2.1 we defined g(x)=x-f(x) to find a fixed point of the polynomial f(x)=x^2 - 4x + 3.5.\n\n(a) ✍ Why does the iteration spiral in to the fixed point, instead of approaching it monotonically? (Refer to the series analysis.)\n\n(b) ✍ Show that if \\hat{g}(x) = (x^2+3.5)/4, then any fixed point of \\hat{g} is a root of f.\n\n(c) ⌨ Use fixed-point iteration on \\hat{g} to try to find both roots of f, and note which case(s), if either, converge.\n\n(d) ✍ Use \n\n(4.2.3) to explain the success/failure in part (c) for each fixed point.\n\n✍ The mth root of a positive real number a is a fixed point of the functiong(x) = \\frac{a}{x^{m-1}}.\n\nFor what integer values of m>1 will the fixed-point iteration for g converge (for close enough initial guesses)?\n\n(a) ✍ Show that p=1/3 is a fixed point of g(x) = 2x-3x^2.\n\n(b) ✍ Find g'(1/3). How does this affect \n\n(4.2.3)?\n\n(c) ⌨ Do an experiment with fixed-point iteration on g to converge to p=1/3. Is the convergence a straight line on a log-linear plot?\n\n✍  Consider the iterationx_{k+1} = x_k - \\frac{f(x_k)}{c}, \\qquad k=0,1,\\ldots.\n\nSuppose f(p)=0 and that f'(p)>0 exists. Find one or more conditions on c such that the iteration converges to p.\n\nWe can only ever generate a finite sample from an infinite sequence, which in principle does not guarantee anything whatsoever about the limit or divergence of that sequence. However, in practical computing one usually assumes that well-established trends in the sequence will continue, and we complement observed experience with rigorous theory where possible.","type":"content","url":"/fixed-point#exercises","position":9},{"hierarchy":{"lvl1":"Newton’s method"},"type":"lvl1","url":"/newton","position":0},{"hierarchy":{"lvl1":"Newton’s method"},"content":"Newton’s method is the cornerstone of rootfinding. We introduce the key idea with an example in \n\nDemo 4.3.1.\n\nGraphical interpretation of Newton’s method\n\nExample 4.3.1\n\nSuppose we want to find a root of the function\n\nf(x) = x * exp(x) - 2\nusing Plots\nplot(f, 0, 1.5; \n    label=\"function\",  legend=:topleft,\n    grid=:y,  ylim=[-2, 4],  xlabel=L\"x\",  ylabel=L\"y\")\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx₁ = 1\ny₁ = f(x₁)\nscatter!([x₁], [y₁], label=\"initial point\")\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx(x) = exp(x) * (x + 1)\nm₁ = df_dx(x₁)\ntangent = x -> y₁ + m₁ * (x - x₁)\n\nplot!(tangent, 0, 1.5, l=:dash, label=\"tangent line\",\n    title=\"Tangent line approximation\")\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\n@show x₂ = x₁ - y₁ / m₁\nscatter!([x₂], [0], label=\"tangent root\", title=\"First iteration\")\n\ny₂ = f(x₂)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nplot(f, 0.82, 0.87;\n    label=\"function\",  legend=:topleft,\n    xlabel=L\"x\",  ylabel=L\"y\",\n    title=\"Second iteration\")\n\nscatter!([x₂], [y₂], label=\"starting point\")\n\nm₂ = df_dx(x₂)\ntangent = x -> y₂ + m₂ * (x - x₂)\nplot!(tangent, 0.82, 0.87; l=:dash, label=\"tangent line\")\n\n@show x₃ = x₂ - y₂ / m₂\nscatter!([x₃], [0], label=\"tangent root\")\n\ny₃ = f(x₃)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nExample 4.3.1\n\nSuppose we want to find a root of the function\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0, 1.5])\nxlabel('x'), ylabel('y')    \nset(gca, 'ygrid', 'on')  \ntitle('Objective function')\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1;\ny1 = f(x1)\nhold on, scatter(x1, y1, 'k')\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx = @(x) exp(x) .* (x + 1);\nslope1 = df_dx(x1);\ntangent1 = @(x) y1 + slope1 * (x - x1);\naxis(axis)\nfplot(tangent1, [0, 1.5], 'k--')\ntitle('Function and tangent line')\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nscatter(x2, 0, 'r')\ntitle('Root of the tangent')\n\ny2 = f(x2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\ncla,  axis auto\nfplot(f, [0.83, 0.88])\nscatter(x2, y2, 'k')\nslope2 = df_dx(x2);\ntangent2 = @(x) y2 + slope2 * (x - x2);\naxis(axis)\nfplot(tangent2, [0.8, 0.9], 'k--')\nx3 = x2 - y2 / slope2;\nscatter(x3, 0, 'r')\ntitle('Next iteration')\n\ny3 = f(x3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nExample 4.3.1\n\nSuppose we want to find a root of this function:\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0, 1.5, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$y$\");\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1\ny1 = f(x1)\nax.plot(x1, y1, \"ko\", label=\"initial point\")\nax.legend()\nfig\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx = lambda x: exp(x) * (x + 1)\nslope1 = df_dx(x1)\ntangent1 = lambda x: y1 + slope1 * (x - x1)\n\nax.plot(xx, tangent1(xx), \"--\", label=\"tangent line\")\nax.set_ylim(-2, 4)\nax.legend()\nfig\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nax.plot(x2, 0, \"ko\", label=\"tangent root\")\nax.legend()\nfig\n\ny2 = f(x2)\nprint(y2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nxx = linspace(0.83, 0.88, 200)\n\nplot(xx, f(xx))\nplot(x2, y2, \"ko\")\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\n\nslope2 = df_dx(x2)\ntangent2 = lambda x: y2 + slope2 * (x - x2)\nplot(xx, tangent2(xx), \"--\")\nx3 = x2 - y2 / slope2\nplot(x3, 0, \"ko\")\ntitle(\"Second iteration\");\n\ny3 = f(x3)\nprint(y3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nUsing general notation, if we have a root approximation x_k, we can construct a linear model of f(x) using the classic formula for the tangent line of a differentiable function,  q(x) = f(x_k) + f'(x_k)(x-x_k).\n\nFinding the root of q(x)=0 is trivial. We define the next approximation by the condition q(x_{k+1})=0, which leads to the following.\n\nNewton’s method\n\nGiven a function f, its derivative, f', and an initial value x_1, iteratively define  x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}, \\qquad k=1,2,\\ldots.","type":"content","url":"/newton","position":1},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Convergence"},"type":"lvl2","url":"/newton#convergence","position":2},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Convergence"},"content":"The graphs of \n\nDemo 4.3.1 suggest why the Newton iteration may converge to a root: any differentiable function looks more and more like its tangent line as we zoom in to the point of tangency. Yet it is far from clear that it must converge, or at what rate it will do so. The matter of the convergence rate is fairly straightforward to resolve. Define the error sequence\\epsilon_k = x_k - r , \\quad k=1,2,\\ldots,\n\nwhere r is the limit of the sequence and f(r)=0. Exchanging x-values for ε-values in \n\n(4.3.2) gives  \\epsilon_{k+1}+r = \\epsilon_k + r - \\frac{f(r+\\epsilon_k)}{f'(r+\\epsilon_k)}.\n\nWe assume that |\\epsilon_k|\\to 0; eventually, the errors remain as small as we please forever. Then a Taylor expansion of f about x=r gives  \\epsilon_{k+1} = \\epsilon_k - \\frac{ f(r) + \\epsilon_kf'(r) + \\frac{1}{2}\\epsilon_k^2f''(r) +\n    O(\\epsilon_k^3)}{ f'(r) + \\epsilon_kf''(r) + O(\\epsilon_k^2)}.\n\nWe use the fact that f(r)=0 and additionally assume now that r is a simple root, i.e., f'(r)\\neq 0. Then\\epsilon_{k+1} = \\epsilon_k - \\epsilon_k \\left[ 1 + \\dfrac{1}{2}\\dfrac{f''(r)}{f'(r)} \\epsilon_k\n+ O(\\epsilon_k^2)\\right] \\, \\left[ 1 + \\dfrac{f''(r)}{f'(r)}\\epsilon_k + O(\\epsilon_k^2)\\right]^{-1}.\n\nThe series in the denominator is of the form 1/(1+z). Provided |z|<1, this is the limit of the geometric series 1-z+z^2-z^3 + \\cdots. Keeping only the lowest-order terms, we derive\\begin{align*}\n\n\\epsilon_{k+1} &= \\epsilon_k - \\epsilon_k \\left[ 1 + \\dfrac{1}{2}\\dfrac{f''(r)}{f'(r)} \\epsilon_k + O(\\epsilon_k^2) \\right] \\, \\left[ 1 - \\dfrac{f''(r)}{f'(r)}\n\\epsilon_k + O(\\epsilon_k^2) \\right]\\\\\n&= \\frac{1}{2}\\, \\frac{f''(r)}{f'(r)} \\epsilon_k^2 + O(\\epsilon_k^3).\n\\end{align*}\n\nAsymptotically, each iteration of Newton’s method roughly squares the error.\n\nQuadratic convergence\n\nSuppose a sequence x_k approaches limit x^*. If the error sequence \\epsilon_k=x_k - x^* satisfies  \\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|^2} = L\n\nfor a positive constant L, then the sequence has quadratic convergence to the limit.\n\nRecall that linear convergence is identifiable by trending toward a straight line on a log-linear plot of the error. When the convergence is quadratic, no such straight line exists—the convergence keeps getting steeper. As a numerical test, note that |\\epsilon_{k+1}|\\approx K |\\epsilon_{k}|^2 implies that as k\\to\\infty,\\begin{split}\n  \\log |\\epsilon_{k+1}| & \\approx 2 \\log |\\epsilon_{k}| + L,\\\\\n    \\frac{\\log |\\epsilon_{k+1}|}{\\log |\\epsilon_{k}|} &\\approx 2 + \\frac{L}{\\log |\\epsilon_{k}|} \\to 2. \n\\end{split}\n\nConvergence of Newton’s method\n\nExample 4.3.2\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf(x) = x * exp(x) - 2;\ndf_dx(x) = exp(x) * (x + 1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nusing NLsolve\nr = nlsolve(x -> f(x[1]), [1.0]).zero\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = [1; zeros(4)]\nfor k = 1:4\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nx\n\nHere is the sequence of errors.\n\nϵ = @. x - r\n\nBecause the error reaches machine epsilon so rapidly, we’re going to use extended precision to allow us to take a few more iterations. We’ll take the last iteration as the most accurate root estimate.\n\nTip\n\nA BigFloat uses 256 bits of precision, rather than 53 in Float64. But arithmetic is done by software emulation and is much slower.\n\nx = [BigFloat(1); zeros(7)]\nfor k = 1:7\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nr = x[end]\n\nϵ = @. Float64(x[1:end-1] - r)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = @. log10(abs(ϵ))\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"error\", \"log error\", \"ratio\"] [1:7 ϵ logerr ratios]\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nExample 4.3.2\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = @(x) x.*exp(x) - 2;\ndf_dx = @(x) exp(x).*(x+1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nformat long,  r = fzero(f,1)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = 1;\nfor k = 1:6\n    x(k+1) = x(k) - f(x(k)) / df_dx(x(k));\nend\nx\n\nHere is the sequence of errors.\n\nformat short e\nerr = x' - r\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nformat short\nlogerr = log(abs(err))\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nExample 4.3.2\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = lambda x: x * exp(x) - 2\ndf_dx = lambda x: exp(x) * (x + 1)\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nr = root_scalar(f, bracket=[0.8, 1.0]).root\nprint(r)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = ones(5)\nfor k in range(4):\n    x[k + 1] = x[k] - f(x[k]) / df_dx(x[k])\n\nprint(x)\n\nHere is the sequence of errors.\n\nerr = x - r\nprint(err)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nLet’s summarize the assumptions made to derive quadratic convergence as given by \n\n(4.3.7):\n\nThe residual function f has to have enough continuous derivatives to make the Taylor series expansion valid. Often this is stated as f having sufficient smoothness. This is usually not a problem, but see \n\nExercise 6.\n\nWe required f'(r)\\neq 0, meaning that r must be a simple root. See \n\nExercise 7 to investigate what happens at a multiple root.\n\nWe assumed that the sequence converged, which is not easy to guarantee in any particular case. In fact,\nfinding a starting value from which the Newton iteration converges is often the most challenging part of a rootfinding problem. We will try to deal with this issue in \n\nQuasi-Newton methods.","type":"content","url":"/newton#convergence","position":3},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Implementation"},"type":"lvl2","url":"/newton#implementation","position":4},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Implementation"},"content":"Our implementation of Newton’s iteration is given in \n\nFunction 4.3.2. It accepts functions that evaluate f and f' and the starting value x_1 as input arguments. Beginning programmers are tempted to embed f and f' directly into the code, but there are two good reasons not to do so. First, each new rootfinding problem would require its own copy of the code, creating a lot of duplication. Second, you may want to try more than one rootfinding algorithm for a particular problem, and keeping the definition of the problem separate from the algorithm for its solution makes this task much easier.\n\nnewton\n\nNewton’s method\n\n\"\"\"\n    newton(f, df_dx, x₁ [;maxiter,f tol, xtol])\n\nUse Newton's method to find a root of `f` starting from `x₁`, where\n`df_dx` is the derivative of `f`. Returns a vector of root estimates.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\"\"\"\nfunction newton(f, df_dx, x₁; maxiter = 40, ftol = 1e-13, xtol = 1e-13)\n    x = [float(x₁)]\n    y = f(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (abs(Δx) > xtol) && (abs(y) > ftol)\n        dy_dx = df_dx(x[k])\n        Δx = -y / dy_dx            # Newton step\n        push!(x, x[k] + Δx)        # append new estimate\n\n        k += 1\n        y = f(x[k])\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nNewton’s method\n\nfunction x = newton(f,dfdx,x1)\r\n% NEWTON   Newton's method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   dfdx     derivative function\r\n%   x1       initial root approximation\r\n% Output       \r\n%   x        vector of root approximations (last one is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = x1;  \r\ny = f(x1);\r\ndx = Inf;   % for initial pass below\r\nk = 1;\r\n\r\nwhile (abs(dx) > xtol) && (abs(y) > funtol) && (k < maxiter)\r\n    dydx = dfdx(x(k));\r\n    dx = -y/dydx;           % Newton step\r\n    x(k+1) = x(k) + dx;\r\n\r\n    k = k+1;\r\n    y = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n  warning('Maximum number of iterations reached.')\r\nend\n\nNewton’s method\n\ndef newton(f, dfdx, x1):\n    \"\"\"\n    newton(f, dfdx, x1)\n\n    Use Newton's method to find a root of f starting from x1, where dfdx is the\n    derivative of f. Returns a vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[0] = x1\n    y = f(x1)\n    dx = np.inf  # for initial pass below\n    k = 0\n\n    while (abs(dx) > xtol) and (abs(y) > funtol) and (k < maxiter):\n        dydx = dfdx(x[k])\n        dx = -y / dydx  # Newton step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y = f(x[k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n\n    return x[:k+1]\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nFunction 4.3.2 also deals with a thorny practical issue: how to stop the iteration. It adopts a three-part criterion. First, it monitors the difference between successive root estimates, |x_k-x_{k-1}|, which is used as a stand-in for the unknown error |x_k-r|. In addition, it monitors the residual |f(x_k)|, which is equivalent to the backward error and more realistic to control in badly conditioned problems (see \n\nThe rootfinding problem). If either of these quantities is considered to be sufficiently small, the iteration ends. Finally, we need to protect against the possibility of a nonconvergent iteration, so the procedure terminates with a warning if a maximum number of iterations is exceeded.\n\nUsing Newton’s method\n\nExample 4.3.3\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nTip\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\ng(x) = exp(x) - x\ndg_dx(x) = exp(x) - 1\ny = range(g(0), g(2), 200)\nx = zeros(length(y))\nfor (i, y) in enumerate(y)\n    f(x) = g(x) - y\n    df_dx(x) = dg_dx(x)\n    r = FNC.newton(f, df_dx, y)\n    x[i] = r[end]\nend\n\nplot(g, 0, 2, aspect_ratio=1, label=L\"g(x)\")\nplot!(y, x, label=L\"g^{-1}(y)\", title=\"Function and its inverse\")\nplot!(x -> x, 0, maximum(y), label=\"\", l=(:dash, 1), color=:black)\n\nExample 4.3.3\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nTip\n\nWhen a function is created, it can refer to any variables in scope at that moment. Those values are locked in to the definition, which is called a closure. If the enclosed variables change values later, the function still uses the values it was created with.\n\nh = @(x) exp(x) - x;\ndh_dx = @(x) exp(x) - 1;\ny_ = linspace(h(0), h(2), 200);\nx_ = zeros(size(y_));\nfor i = 1:length(y_)\n    f = @(x) h(x) - y_(i);\n    df_dx = @(x) dh_dx(x);\n    x = newton(f, df_dx, 1);  x_(i) = x(end);\nend\n\nclf, fplot(h, [0, 2])\nhold on, axis equal\nplot(y_, x_)\nplot([0, max(y_)], [0, max(y_)], 'k--')\nxlabel('x'), ylabel('y')\nlegend('h(x)', 'inverse', 'y=x');\n\nExample 4.3.3\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=h(x), or h(x)-y=0, for x when y is given. That equation has no solution in terms of elementary functions. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nTip\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\nh = lambda x: exp(x) - x\ndh_dx = lambda x: exp(x) - 1\ny_ = linspace(h(0), h(2), 200)\nx_ = zeros(y_.shape)\nfor (i, y) in enumerate(y_):\n    f = lambda x: h(x) - y\n    df_dx = lambda x: dh_dx(x)\n    x = FNC.newton(f, df_dx, y)\n    x_[i] = x[-1]\n\nplot(x_, y_, label=\"$y=h(x)$\")\nplot(y_, x_, label=\"$y=h^{-1}(x)$\")\nplot([0, max(y_)], [0, max(y_)], 'k--', label=\"\")\ntitle(\"Function and its inverse\")\nxlabel(\"x\"), ylabel(\"y\"), axis(\"equal\")\nax.grid()\nlegend();","type":"content","url":"/newton#implementation","position":5},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Exercises"},"type":"lvl2","url":"/newton#exercises","position":6},{"hierarchy":{"lvl1":"Newton’s method","lvl2":"Exercises"},"content":"For each of Exercises 1–3, do the following steps.\n\n(a) ✍ Rewrite the equation into the standard form for rootfinding, f(x) = 0, and compute f'(x).\n\n(b) ⌨  Make a plot of f over the given interval and determine how many roots lie in the interval.\n\n(c) ⌨ Use nlsolve with ftol=1e-15 to find a reference value for each root.\n\n(d) ⌨ Use \n\nFunction 4.3.2 to find each root.\n\n(e) ⌨ For one of the roots, use the errors in the Newton sequence to determine numerically whether the convergence is roughly quadratic.\n\nx^2=e^{-x}, over [-2,2]\n\n2x = \\tan x, over [-0.2,1.4]\n\ne^{x+1}=2+x, over [-2,2]\n\n⌨  Plot the function f(x)=x^{-2} - \\sin x on the interval x \\in [0.5,10].  For each initial value x_1=1,\\, x_1=2,\\,\\ldots,\\, x_1=7, apply \n\nFunction 4.3.2 to f, and make a table showing x_1 and the resulting root found by the method. In which case does the iteration converge to a root other than the one closest to it? Use the plot to explain why that happened.\n\n✍ Show that if f(x)=x^{-1}-b for nonzero b, then Newton’s iteration converging to the root r=1/b can be implemented without performing any divisions.\n\n✍ Discuss what happens when Newton’s method is applied to find a root of f(x) = \\operatorname{sign}(x) \\sqrt{|x|}, starting at x_1\\ne 0. (Hint: Write out both f(x) and f'(x) as piecewise functions.)\n\n✍ In the case of a multiple root, where f(r)=f'(r)=0, the derivation of the quadratic error convergence in \n\n(4.3.7) is invalid. Redo the derivation to show that in this circumstance and with f''(r)\\neq 0, the error converges only linearly.\n\n✍ In \n\nFunction 4.3.2 and elsewhere, the actual error is not available, so we use |x_k-x_{k-1}| as an approximate indicator of error to determine when to stop the iteration. Find an example that foils this indicator; that is, a sequence \\{x_k\\} such that\\lim_{k\\rightarrow \\infty} (x_k-x_{k-1}) = 0,\n\nbut \\{x_k\\} diverges. (Hint: You have seen such sequences in calculus.) Hence the need for residual tolerances and safety valves in the code!","type":"content","url":"/newton#exercises","position":7},{"hierarchy":{"lvl1":"Newton for nonlinear systems"},"type":"lvl1","url":"/newtonsys","position":0},{"hierarchy":{"lvl1":"Newton for nonlinear systems"},"content":"The rootfinding problem becomes much more difficult when multiple variables and equations are involved.\n\nMultidimensional rootfinding problem\n\nGiven a continuous vector-valued function \\mathbf{f} mapping from \\mathbb{R}^n into \\mathbb{R}^n, find a vector \\mathbf{r} such that\\begin{split}\n  f_1(r_1,\\dots,r_n) &= 0,\\\\\n  f_2(r_1,\\dots,r_n) &= 0,\\\\\n  &\\vdots\\\\\n  f_n(r_1,\\dots,r_n) &= 0.\n\\end{split}\n\nParticular problems are often posed using scalar variables and equations.\n\nThe steady state of interactions between the population w(t) of a predator species and the population h(t) of a prey species might be modeled as\\begin{split}\nah - b h w &= 0, \\\\ \n-cw + d w h &= 0,\n\\end{split}\n\nfor positive parameters a,b,c,d. To cast this in the form of \n\n(4.5.1), we could define \\mathbf{x}=[h,w], f_1(x_1,x_2) = ax_1 - bx_1x_2, and f_2(x_1,x_2)= -c x_2 + d x_1 x_2.\n\nWhile the equations of \n\nExample 4.5.1 are easy to solve by hand, in practice even establishing the existence and uniqueness of solutions for any particular system is typically quite difficult.","type":"content","url":"/newtonsys","position":1},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Linear model"},"type":"lvl2","url":"/newtonsys#linear-model","position":2},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Linear model"},"content":"To extend rootfinding methods to systems, we will keep to the basic philosophy of constructing easily managed models of the exact function. As usual, the starting point is a linear model. We base it on the multidimensional Taylor series,\\mathbf{f}(\\mathbf{x}+\\mathbf{h}) = \\mathbf{f}(\\mathbf{x}) + \\mathbf{J}(\\mathbf{x})\\mathbf{h} + O(\\| \\mathbf{h} \\|^2),\n\nwhere \\mathbf{J} is called the Jacobian matrix of \\mathbf{f} and is defined by\\mathbf{J}(\\mathbf{x}) =\n  \\begin{bmatrix}\n    \\rule[2mm]{0pt}{1em}\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\cdots & \\frac{\\partial f_1}{\\partial x_n}\\\\[2mm]\n    \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\cdots & \\frac{\\partial f_2}{\\partial x_n}\\\\[1mm]\n    \\vdots & \\vdots & & \\vdots\\\\[1mm]\n    \\rule[-3mm]{0pt}{1em} \\frac{\\partial f_n}{\\partial x_1} & \\frac{\\partial f_n}{\\partial x_2} & \\cdots & \\frac{\\partial f_n}{\\partial x_n}\n  \\end{bmatrix} = \\left[ \\frac{\\partial f_i}{\\partial x_j} \\right]_{\\,i,j=1,\\ldots,n}.\n\nBecause of the Jacobian’s role in \n\n(4.5.3), we may write \\mathbf{J}(\\mathbf{x}) as \\mathbf{f}{\\,}'(\\mathbf{x}). Like any derivative, it is a function of the independent variable \\mathbf{x}.\n\nLet\\begin{split}\n    f_1(x_1,x_2,x_3) &= -x_1\\cos(x_2) - 1\\\\\n    f_2(x_1,x_2,x_3) &= x_1x_2 + x_3\\\\\n    f_3(x_1,x_2,x_3) &= e^{-x_3}\\sin(x_1+x_2) + x_1^2 - x_2^2.\n\\end{split}\n\nThen    \\mathbf{J}(x) =\n    \\begin{bmatrix}\n       -\\cos(x_2) & x_1 \\sin(x_2) & 0\\\\\n      x_2 & x_1 & 1\\\\\n       e^{-x_3}\\cos(x_1+x_2)+2x_1 & e^{-x_3}\\cos(x_1+x_2)-2x_2 &\n       -e^{-x_3}\\sin(x_1+x_2)\n    \\end{bmatrix}.\n\nIf we were to start writing out the terms in \n\n(4.5.3), we would begin with\\begin{split}\n    f_1(x_1+h_1,x_2+h_2,x_3+h_3) &= -x_1\\cos(x_2)-1 -\\cos(x_2)h_1 +\n    x_1\\sin(x_2)h_2 + O\\bigl(\\| \\mathbf{h} \\|^2\\bigr) \\\\\n    f_2(x_1+h_1,x_2+h_2,x_3+h_3) &= x_1x_2 + x_3 + x_2h_1 +x_1h_2 +\n    h_3 + O\\bigl(\\| \\mathbf{h} \\|^2\\bigr),\n  \\end{split}\n\nand so on.\n\nThe terms \\mathbf{f}(\\mathbf{x})+\\mathbf{J}(\\mathbf{x})\\mathbf{h} in \n\n(4.5.3) represent the linear part of \\mathbf{f} near \\mathbf{x}. If \\mathbf{f} is actually linear, i.e., \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x}-\\mathbf{b}, then the Jacobian matrix is the constant matrix \\mathbf{A} and the higher-order terms in \n\n(4.5.3) disappear.","type":"content","url":"/newtonsys#linear-model","position":3},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"The multidimensional Newton iteration"},"type":"lvl2","url":"/newtonsys#the-multidimensional-newton-iteration","position":4},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"The multidimensional Newton iteration"},"content":"With a method in hand for constructing a linear model for the vector system \\mathbf{f}(\\mathbf{x}), we can generalize Newton’s method. Specifically, at a root estimate \\mathbf{x}_k, we set \\mathbf{h} = \\mathbf{x}-\\mathbf{x}_k in \n\n(4.5.3) and get\\mathbf{f}(\\mathbf{x}) \\approx \\mathbf{q}(\\mathbf{x})  = \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{J}(\\mathbf{x}_k)(\\mathbf{x}-\\mathbf{x}_k).\n\nWe define the next iteration value \\mathbf{x}_{k+1} by requiring \\mathbf{q}(\\mathbf{x}_{k+1})=\\boldsymbol{0},\\begin{split}\n  \\boldsymbol{0} &=  \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{J}(\\mathbf{x}_k)(\\mathbf{x}_{k+1}-\\mathbf{x}_k),\\\\\n\\end{split}\n\nwhich can be rearranged into\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\bigl[\\mathbf{J}(\\mathbf{x}_k)\\bigr]^{-1} \\mathbf{f}(\\mathbf{x}_k).\n\nNote that \\mathbf{J}^{-1}\\mathbf{f} now plays the role that f/f' had in the scalar case; in fact, the two are the same in one dimension. In computational practice, however, we don’t compute matrix inverses.\n\nMultidimensional Newton’s method\n\nGiven \\mathbf{f} and a starting value \\mathbf{x}_1, for each k=1,2,3,\\ldots\n\nCompute \\mathbf{y}_k = \\mathbf{f}(\\mathbf{x}_k) and \\mathbf{A}_k=\\mathbf{f\\,}'(\\mathbf{x}_k).\n\nSolve the linear system \\mathbf{A}_k\\mathbf{s}_k = -\\mathbf{y}_k for the Newton step \\mathbf{s}_k.\n\nLet \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\mathbf{s}_k.\n\nAn extension of our series analysis of the scalar Newton’s method shows that the vector version is also quadratically convergent in any vector norm, under suitable circumstances and when the iteration converges at all.","type":"content","url":"/newtonsys#the-multidimensional-newton-iteration","position":5},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Implementation"},"type":"lvl2","url":"/newtonsys#implementation","position":6},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Implementation"},"content":"An implementation of Newton’s method for systems is given in \n\nFunction 4.5.2. Other than computing the Newton step using backslash and taking vector magnitudes with norm, \n\nFunction 4.5.2 is virtually identical to the scalar version \n\nFunction 4.3.2 presented earlier.\n\nnewtonsys\n\nNewton’s method for systems\n\n\"\"\"\n    newtonsys(f, jac, x₁ [;maxiter, ftol, xtol])\n\nUse Newton's method to find a root of a system of equations,\nstarting from `x₁`. The functions `f` and `jac` should return the\nresidual vector and the Jacobian matrix, respectively. Returns the\nhistory of root estimates as a vector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction newtonsys(f, jac, x₁; maxiter = 40, ftol = 1e-13, xtol = 1e-13)\n    x = [float(x₁)]\n    y, J = f(x₁), jac(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (norm(Δx) > xtol) && (norm(y) > ftol)\n        Δx = -(J \\ y)             # Newton step\n        push!(x, x[k] + Δx)    # append to history\n        k += 1\n        y, J = f(x[k]), jac(x[k])\n\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n    end\n    return x\nend\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nNewton’s method for systems\n\nfunction x = newtonsys(f,x1)\r\n% NEWTONSYS   Newton's method for a system of equations.\r\n% Input:\r\n%   f        function that computes residual and Jacobian matrix\r\n%   x1       initial root approximation (n-vector)\r\n% Output       \r\n%   x        array of approximations (one per column, last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 1000*eps;  xtol = 1000*eps;  maxiter = 40;\r\n\r\nx = x1(:);  \r\n[y,J] = f(x1);\r\ndx = Inf;\r\nk = 1;\r\n\r\nwhile (norm(dx) > xtol) && (norm(y) > funtol) && (k < maxiter)\r\n    dx = -(J\\y);   % Newton step\r\n    x(:,k+1) = x(:,k) + dx;\r\n\r\n    k = k+1;\r\n    [y,J] = f(x(:,k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nNewton’s method for systems\n\ndef newtonsys(f, jac, x1):\n    \"\"\"\n        newtonsys(f, jac, x1)\n\n    Use Newton's method to find a root of a system of equations, starting from x1. The\n    function f should return the residual vector, and the function jac should return \n    the Jacobian matrix. Returns root estimates as a matrix, one estimate per column.\n    \"\"\"\n    # Operating parameters.\n    funtol = 1000 * np.finfo(float).eps\n    xtol = 1000 * np.finfo(float).eps\n    maxiter = 40\n\n    x = np.zeros((maxiter, len(x1)))\n    x[0] = x1\n    y, J = f(x1), jac(x1)\n    dx = 10.0  # for initial pass below\n    k = 0\n\n    while (norm(dx) > xtol) and (norm(y) > funtol) and (k < maxiter):\n        dx = -lstsq(J, y)[0]  # Newton step\n        x[k+1] = x[k] + dx\n\n        k = k + 1\n        y, J = f(x[k]), jac(x[k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:k+1]\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nConvergence of Newton’s method for systems\n\nExample 4.5.3\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nTip\n\nBe careful when coding a Jacobian all in one statement. Spaces separate columns, so x[3]-1 is not the same as x[3] - 1.\n\nfunction func(x)\n    [exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\nend;\n\nfunction jac(x)\n    [\n        -exp(x[2] - x[1]) exp(x[2] - x[1]) 0\n        x[2] x[1] 1\n        2*x[1] x[3]-1 x[2]\n    ]\nend;\n\nWe will use a BigFloat starting value, and commensurately small stopping tolerances, in order to get a sequence long enough to measure convergence.\n\nx₁ = BigFloat.([0, 0, 0])\nϵ = eps(BigFloat)\nx = FNC.newtonsys(func, jac, x₁, xtol=ϵ, ftol=ϵ);\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x[end]\n@show residual = norm(func(r));\n\nWe take the sequence of norms of errors, applying the log so that we can look at the exponents.\n\nlogerr = [Float64(log(norm(r - x[k]))) for k in 1:length(x)-1]\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"log error\", \"ratio\"] [eachindex(logerr) logerr ratios]\n\nThe ratio is neatly converging toward 2, which is expected for quadratic convergence.\n\nExample 4.5.3\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nTip\n\nThis function needs to be defined within a script file or in a file of its own with the .m extension.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nSince our system function is defined in an external file here, we need to use @ in order to reference it as a function argument.\n\nnlsystem = @f45_nlsystem;\nx1 = [0; 0; 0];    % column vector!\nx = newtonsys(nlsystem, x1);\nnum_iter = size(x, 2)\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x(:, end)\nback_err = norm(nlsystem(r))\n\nWe take the sequence errors in the first component of the solution, applying the log so that we can look at the exponents.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'\n\nThis sequence looks to be nearly doubling at each iteration, which is a good sign of quadratic convergence.\n\nExample 4.5.3\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\ndef jac(x):\n    return array([\n            [-exp(x[1] - x[0]), exp(x[1] - x[0]), 0],\n            [x[1], x[0], 1],\n            [2 * x[0], x[2] - 1, x[1]],\n    ])\n\nOur initial guess at a root is the origin.\n\nx1 = zeros(3)\nx = FNC.newtonsys(func, jac, x1)\nprint(x)\n\nThe output has one row per iteration, so the last row contains the final Newton estimate. Let’s compute its residual.\n\nr = x[-1]\nf = func(r)\nprint(\"final residual:\", f)\n\nLet’s check the convergence rate:\n\nlogerr = [log(norm(x[k] - r)) for k in range(x.shape[0] - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])\n\nThe ratio is apparently converging toward 2, as expected for quadratic convergence.","type":"content","url":"/newtonsys#implementation","position":7},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Exercises"},"type":"lvl2","url":"/newtonsys#exercises","position":8},{"hierarchy":{"lvl1":"Newton for nonlinear systems","lvl2":"Exercises"},"content":"✍ Suppose that\\mathbf{f}(\\mathbf{x}) =\n\\begin{bmatrix}\n  x_1x_2+x_2^2-1 \\\\[1mm] x_1x_2^3 + x_1^2x_2^2 + 1\n\\end{bmatrix}.\n\nLet \\mathbf{x}_1=[-2,1]^T. Use Newton’s method to find \\mathbf{x}_2.\n\n✍ Suppose that \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b} for a constant n\\times n matrix \\mathbf{A} and constant n\\times 1 vector \\mathbf{b}. Show that Newton’s method converges to the exact root in one iteration.\n\nTwo curves in the (u,v) plane are defined implicitly by the equations u\\log u + v \\log v = -0.3 and u^4 + v^2 = 1.\n\n(a) ✍ Write the intersection of these curves in the form \\mathbf{f}(\\mathbf{x}) = \\boldsymbol{0} for two-dimensional \\mathbf{f} and \\mathbf{x}.\n\n(b) ✍ Find the Jacobian matrix of \\mathbf{f}.\n\n(c) ⌨ Use \n\nFunction 4.5.2 to find an intersection point starting from u=1, v=0.1.\n\n(d) ⌨ Use \n\nFunction 4.5.2 to find an intersection point starting from u=0.1, v=1.\n\nTwo elliptical orbits (x_1(t),y_1(t)) and (x_2(t),y_2(t)) are described by the equations\\begin{bmatrix}\n  x_1(t) \\\\ y_1(t)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  -5+10\\cos(t) \\\\ 6\\sin(t)\n\\end{bmatrix}, \\qquad\n\\begin{bmatrix}\n  x_2(t)\\\\y_2(t)\n\\end{bmatrix} =\n\\begin{bmatrix}\n  8\\cos(t) \\\\ 3+12\\sin(t)\n\\end{bmatrix},\n\nwhere t represents time.\n\n(a) ⌨ Make a plot of the two orbits with the following code:x1(t) = -5+10*cos(t);   y1(t) = 6*sin(t);\nplot(x1,y1,0,2pi,aspect_ratio=1,legend=false)\nx2(t) = 8*cos(t);   y2(t) = 3 + 12*sin(t);\nplot!(x2,y2,0,2pi)\n\n(b) ✍ Write out a 2\\times 2 nonlinear system of equations that describes an intersection of these orbits. (Note: An intersection is not the same as a collision—they don’t have to occupy the same point at the same time.)\n\n(c) ✍ Write out the Jacobian matrix of this nonlinear system.\n\n(d) ⌨ Use \n\nFunction 4.5.2 to find all of the unique intersections.\n\n⌨  Suppose one wants to find the points on the ellipsoid x^2/25 + y^2/16 + z^2/9 = 1 that are closest to and farthest from the point (5,4,3). The method of Lagrange multipliers implies that any such point satisfies\\begin{split}\n    x-5 &= \\frac{\\lambda x}{25}, \\\\[1mm]\n    y-4 &= \\frac{\\lambda y}{16}, \\\\[1mm]\n    z-3 &= \\frac{\\lambda z}{9}, \\\\[1mm]\n    1 &=  \\frac{1}{25}x^2 + \\frac{1}{16}y^2 + \\frac{1}{9}z^2\n\\end{split}\n\nfor an unknown value of λ.\n\n(a) Write out this system in the form \\mathbf{f}(\\mathbf{u}) = \\boldsymbol{0}. (Note that the system has four variables to go with the four equations.)\n\n(b) Write out the Jacobian matrix of this system.\n\n(c) Use \n\nFunction 4.5.2 with different initial guesses to find the two roots of this system. Which is the closest point to (5,4,3), and which is the farthest?\n\n⌨  Any three noncollinear points in the plane determine a unique circle. Suppose the points are given as (x_i,y_i) for i=1,2,3. We can define the circle in terms of its center (a,b) and radius r. Thenf_i(a,b,r) = (a-x_i)^2 + (b-y_i)^2 - r^2\n\nshould be made zero for all i=1,2,3. This defines a nonlinear system \\mathbf{f}(\\mathbf{v})=\\boldsymbol{0} for \\mathbf{v}=[a,b,r].\n\nUse \n\nFunction 4.5.2 on this system to find the circle passing through (-5,0), (1,-3), and (4,2). Make a plot that shows you found the correct circle.","type":"content","url":"/newtonsys#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-3","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The fixed-point iteration has been used to prove results about convergence; see Quarteroni et al. \n\nQuarteroni et al. (2007) for more details.\n\nSolving nonlinear systems is a complex task.  Some classic texts on the subject include Ortega and Rheinbolt \n\nOrtega & Rheinboldt (2014), Kelley \n\nKelley (1995), and many others.\n\nTurning to nonlinear least squares, the widely used Levenberg–Marquardt algorithm has a connection to the authors’ home institution.  Donald Marquardt completed an MS in mathematics and statistics at the University of Delaware in 1956 entitled “Application of Digital Computers to Statistics.” He developed the method while working at DuPont Corporation’s laboratories; he worked there from 1953 to 1991.  He needed a better fitting method for experimental data generated at DuPont, and did just that.  The method was published in 1963 in the Journal of the Society for Industrial and Applied Mathematics \n\nMarquardt (1963). In a note at the end, he thanks a referee for pointing out that Levenberg had published related ideas elsewhere \n\nLevenberg (1944), and then cites that work.  He also made a FORTRAN program available that contained an implementation of the program.  There’s a lesson there for budding mathematical software designers:  If you want people to use your algorithm or method, give away software to do it!  An interesting discussion of the evolution of computing during his career at DuPont can be found in an interview \n\nHahn (1995).\n\nOptimization is closely linked to solving nonlinear equations as well.  More info can be found, among many other places, in Strang \n\nStrang (2007), Quarteroni et al. \n\nQuarteroni et al. (2007), and Conn et al. \n\nConn et al. (2009).\n\nFinally, we close with a remark about polynomials.  Polynomials are common, and finding their roots is a frequently occurring task. As we saw in \n\nChapter 1, however, the condition number of polynomial rootfinding can be large, and the possibility of complex roots is another challenge. It turns out that while general-purpose rootfinding can work for polynomials, it’s faster and more robust to use something tailored to the task. One of the best known ways is by converting the problem to one of finding the eigenvalues of a related matrix. A recent paper on the subject won an outstanding paper award from the Society for Industrial and Applied Mathematics \n\nAurentz et al. (2015); it used a clever combination of the companion matrix together with a specialized QR factorization to develop a fast and backward stable method. That paper also contains a very good comparison among modern methods for polynomial rootfinding.","type":"content","url":"/next-3","position":1},{"hierarchy":{"lvl1":"Nonlinear least squares"},"type":"lvl1","url":"/nlsq","position":0},{"hierarchy":{"lvl1":"Nonlinear least squares"},"content":"After the solution of square linear systems, we generalized to the case of having more constraints to satisfy than available variables. Our next step is to do the same for nonlinear equations, thus filling out this table:\n\n\n\nlinear\n\nnonlinear\n\nsquare\n\n\\mathbf{A}\\mathbf{x}=\\mathbf{b}\n\n\\mathbf{f}(\\mathbf{x})=\\boldsymbol{0}\n\noverdetermined\n\n\\min\\, \\bigl|\\mathbf{A}\\mathbf{x} - \\mathbf{b}\\bigr|_2\n\n\\min\\, \\bigl|\\mathbf{f}(\\mathbf{x}) \\bigr|_2\n\nNonlinear least-squares problem\n\nGiven a function \\mathbf{f}(\\mathbf{x}) mapping from \\real^n to \\real^m, the nonlinear least-squares problem is to find \\mathbf{x}\\in\\real^n such that \\bigl\\|\\mathbf{f}(\\mathbf{x})\\bigr\\|_2 is minimized.\n\nAs in the linear case, we consider only overdetermined problems, where m>n. Minimizing a positive quantity is equivalent to minimizing its square, so we could also define the result as minimizing \\phi(\\mathbf{x})=\\mathbf{f}(\\mathbf{x})^T\\mathbf{f}(\\mathbf{x}).","type":"content","url":"/nlsq","position":1},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Gauss–Newton method"},"type":"lvl2","url":"/nlsq#gauss-newton-method","position":2},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Gauss–Newton method"},"content":"You should not be surprised to learn that we can formulate an algorithm by substituting a linear model function for \\mathbf{f}. At a current estimate \\mathbf{x}_k we define  \\mathbf{q}(\\mathbf{x})  = \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{A}_k(\\mathbf{x}-\\mathbf{x}_k),\n\nwhere \\mathbf{A}_k is the exact m\\times n Jacobian matrix, \\mathbf{J}(\\mathbf{x}_k), or an approximation of it as described in \n\nQuasi-Newton methods.\n\nIn the square case, we solved \\mathbf{q}=\\boldsymbol{0} to define the new value for \\mathbf{x}, leading to the condition \\mathbf{A}_k\\mathbf{s}_k=-\\mathbf{f}_k, where  \\mathbf{s}_k=\\mathbf{x}_{k+1}-\\mathbf{x}_k. Now, with m>n, we cannot expect to solve \\mathbf{q}=\\boldsymbol{0}, so instead we define \\mathbf{x}_{k+1} as the value that minimizes \\| \\mathbf{q} \\|_2.\n\nGauss–Newton method\n\nGiven \\mathbf{f} and a starting value \\mathbf{x}_1, for each k=1,2,3,\\ldots\n\nCompute \\mathbf{y}_k = \\mathbf{f}(\\mathbf{x}_k) and \\mathbf{A}_k, the exact or approximate Jacobian matrix at \\mathbf{x}_k.\n\nSolve the linear least squares problem \\argmin \\| \\mathbf{A}_k\\mathbf{s}_k  + \\mathbf{y}_k\\|_2 for \\mathbf{s}_k.\n\nLet \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\mathbf{s}_k.\n\nIn brief, Gauss–Newton solves a series of linear least-squares problems in order to solve a nonlinear least-squares problem.\n\nSurprisingly, \n\nFunction 4.5.2 and \n\nFunction 4.6.3, which were introduced for the case of m=n nonlinear equations, work without modification as the Gauss–Newton method for the overdetermined case! The reason is that the backslash operator applies equally well to the linear system and linear least-squares problems, and nothing else in those functions was written with explicit reference to n.","type":"content","url":"/nlsq#gauss-newton-method","position":3},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Convergence"},"type":"lvl2","url":"/nlsq#convergence","position":4},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Convergence"},"content":"In the multidimensional Newton method for a nonlinear system, we expect quadratic convergence to a solution in the typical case. For the Gauss–Newton method, the picture is more complicated.\n\nAs always in least-squares problems, the residual \\mathbf{f}(\\mathbf{x}) will not necessarily be zero when \\|\\mathbf{f}\\| is minimized. Suppose that the minimum value of \\|\\mathbf{f}\\| is R>0. In general, we might observe quadratic-like convergence until the iterate \\|\\mathbf{x}_k\\| is within distance R of a true minimizer, and linear convergence thereafter. When R is not sufficiently small, the convergence can be quite slow.\n\nConvergence of nonlinear least squares\n\nExample 4.7.1\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng(x) = [sin(x[1] + x[2]), cos(x[1] - x[2]), exp(x[1] - x[2])]\np = [1, 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nTip\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nusing Printf\nplt = plot(xlabel=\"iteration\", yaxis=(:log10, \"error\"),\n    title=\"Convergence of Gauss–Newton\")\nfor R in [1e-3, 1e-2, 1e-1]\n    # Define the perturbed function.\n    f(x) = g(x) - g(p) + R * normalize([-1, 1, -1])\n    x = FNC.levenberg(f, [0, 0])\n    r = x[end]\n    err = [norm(x - r) for x in x[1:end-1]]\n    normres = norm(f(r))\n    plot!(err, label=@sprintf(\"R=%.2g\", normres))\nend\nplt\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nExample 4.7.1\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = @(x) [sin(x(1) + x(2)); cos(x(1) - x(2)); exp(x(1) - x(2))];\np = [1; 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nTip\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nclf\nlabels = [];\nfor R = [1e-3, 1e-2, 1e-1]\n    % Define the perturbed function.\n    f = @(x) g(x) - g(p) + R * [-1; 1; -1] / sqrt(3)\n    x = levenberg(f, [0; 0]);\n    r = x(:, end);\n    err = abs(x(1, 1:end-1) - r(1));\n    normres = norm(f(r));\n    semilogy(err), hold on\n    labels = [labels; sprintf(\"R=%.2g\", normres)];\nend\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend(labels);\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nExample 4.7.1\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = lambda x: array([sin(x[0] + x[1]), cos(x[0] - x[1]), exp(x[0] - x[1])])\np = array([1, 1])\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nfor R in [1e-3, 1e-2, 1e-1]:\n    # Define the perturbed function.\n    f = lambda x: g(x) - g(p) + R * array([-1, 1, -1]) / sqrt(3)\n    x = FNC.levenberg(f, [0, 0])\n    r = x[-1]\n    err = [norm(x[j] - r) for j in range(len(x) - 1)]\n    normres = norm(f(r))\n    semilogy(err, label=f\"R={normres:.2g}\")\ntitle(\"Convergence of Gauss–Newton\")\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend();\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.","type":"content","url":"/nlsq#convergence","position":5},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Nonlinear data fitting"},"type":"lvl2","url":"/nlsq#nonlinear-data-fitting","position":6},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Nonlinear data fitting"},"content":"In \n\nFitting functions to data we saw how to fit functions to data values, provided that the set of candidate fitting functions depends linearly on the undetermined coefficients. We now have a tool to generalize that process to fitting functions that depend nonlinearly on unknown parameters.\n\nSuppose that (t_i,y_i) for i=1,\\ldots,m are given points. We wish to model the data by a function g(t,\\mathbf{x}) that depends on unknown parameters x_1,\\ldots,x_n in an arbitrary way. A standard approach is to minimize the discrepancy between the model and the observations, in a least-squares sense. Define\\mathbf{f}(\\mathbf{x}) = \\left[\\, g(t_i,\\mathbf{x})-y_i  \\, \\right]_{\\,i=1,\\ldots,m}.\n\nWe call \\mathbf{f} a misfit function. By minimizing \\bigl\\| \\mathbf{f}(\\mathbf{c}) \\bigr\\|^2, we get the best possible fit to the data. If an explicit Jacobian matrix is desired for the minimization, we can compute\\mathbf{f}{\\,}'(\\mathbf{x}) = \\left[ \\frac{\\partial}{\\partial x_j} g(t_i,\\mathbf{x}) \\right]_{\\,i=1,\\ldots,m;\\,j=1,\\ldots,n.}\n\nThe form of g is up to the modeler. There may be compelling theoretical choices, or you may just be looking for enough algebraic power to express the data well. Naturally, in the special case where the dependence on \\mathbf{c} is linear, i.e.,  g(t,\\mathbf{c}) = c_1 g_1(t) + c_2 g_2(t) + \\cdots + c_m g_m(t),\n\nthen the misfit function is also linear in \\mathbf{c} and the fitting problem reduces to linear least squares.\n\nNonlinear data fitting\n\nInhibited enzyme reactions often follow what are known as Michaelis–Menten kinetics, in which a reaction rate w follows a law of the formw(s) = \\frac{V s}{K_m + s},\n\nwhere s is the concentration of a substrate. The real values V and K_m are parameters that are free to fit to data. For this example, we cook up some artificial data with V=2 and K_m=1/2.\n\nExample 4.7.2\n\nm = 25;\ns = range(0.05, 6, length=m)\nŵ = @. 2 * s / (0.5 + s)                      # exactly on the curve\nw = @. ŵ + 0.15 * cos(2 * exp(s / 16) * s);     # smooth noise added\n\nscatter(s, w, label=\"noisy data\",\n    xlabel=\"s\", ylabel=\"v\", leg=:bottomright)\nplot!(s, ŵ, l=:dash, color=:black, label=\"perfect data\")\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nTip\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\nfunction misfit(x)\n    V, Km = x   # rename components for clarity\n    return @. V * s / (Km + s) - w\nend\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction misfitjac(x)\n    V, Km = x   # rename components for clarity\n    J = zeros(m, 2)\n    J[:, 1] = @. s / (Km + s)              # dw/dV\n    J[:, 2] = @. -V * s / (Km + s)^2         # dw/d_Km\n    return J\nend\n\nx₁ = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x₁)\n\n@show V, Km = x[end]  # final values\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\nmodel(s) = V * s / (Km + s)\nplot!(model, 0, 6, label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nA = [s .^ (-1) s .^ 0]\nu = 1 ./ w\nα, β = A \\ u\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel(x) = 1 / (β + α / x)\nplot!(linmodel, 0, 6, label=\"linearized fit\")\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.\n\nExample 4.7.2\n\nm = 25; V = 2; Km = 0.5;\ns = linspace(0.05, 6, m)';\nw = V * s ./ (Km + s);                      % exactly on the curve\nw = w + 0.15 * cos(2 * exp(s / 16) .* s);   % noise added\nclf, fplot(@(s) V * s ./ (Km + s), [0, 6], '--')\nhold on, scatter(s, w)\nxlabel('concentration'), ylabel('reaction rate')    \nlabels = [\"ideal\", \"noisy data\"];    \nlegend(labels, 'location', 'east');\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g. In the Jacobian, the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction [f, J] = misfit(c, s, w)\n    V = c(1);   Km = c(2);\n    f = V * s ./ (Km + s) - w;\n    J(:,1) = s ./ (Km + s);            % d/d(V)\n    J(:,2) = -V * s ./ (Km + s).^2;    % d/d(Km)\nend\n\n\nThe misfit function above has to know the parameters x that are being optimized as well as the data s and w that remain fixed. We use a closure to pass the data values along.\n\nf = @(x) f47_misfit(x, s, w);\n\nNow we have a function that accepts a single 2-vector input and returns a 25-vector output. We can pass this function to levenberg to find the best-fit parameters.\n\nx1 = [1; 0.75];\nx = newtonsys(f, x1);\nV = x(1, end),  Km = x(2, end)     % final values\nmodel = @(s) V * s ./ (Km + s);    % best-fit model\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data:\n\nfinal_misfit_norm = norm(model(s) - w) \nhold on, fplot(model, [0, 6])\ntitle('Michaelis-Menten fitting')    \nlabels = [labels, \"nonlinear fit\"];    \nlegend(labels, 'location', 'east');\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nu = 1 ./ w;\nA = [s.^(-1), s.^0];  \nz = A \\ u;\nalpha = z(1);  beta = z(2);\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel = @(s) 1 ./ (beta + alpha ./ s);\nfinal_misfit_linearized = norm(linmodel(s) - w)\nfplot(linmodel, [0, 6])\nlabels = [labels, \"linearized fit\"];    \nlegend(labels, 'location', 'east');\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.\n\nExample 4.7.2\n\nm = 25\nV, Km = 2, 0.5\ns = linspace(0.05, 6, m)\nmodel = lambda x: V * x / (Km + x)\nw = model(s) + 0.15 * cos(2 * exp(s / 16) * s)    # noise added\n\nfig, ax = subplots()\nax.scatter(s, w, label=\"data\")\nax.plot(s, model(s), 'k--', label=\"unperturbed model\")\nxlabel(\"s\"), ylabel(\"w\")\nlegend();\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nTip\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\ndef misfit(c):\n    V, Km = c  # rename components for clarity\n    f = V * s / (Km + s) - w\n    return f\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\ndef misfitjac(x):\n    V, Km = x   # rename components for clarity\n    J = zeros([m, 2])\n    J[:, 0] = s / (Km + s)          # d/d(V)\n    J[:, 1] = -V * s / (Km + s)**2  # d/d(Km)\n    return J\n\nx1 = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x1)\nV, Km = x[-1]  # final values\nprint(f\"estimates are V = {V:.3f}, Km = {Km:.3f}\")\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\n# since V and Km have been updated, model() is too\nax.plot(s, model(s), label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nfrom numpy.linalg import lstsq\nA = array( [[1 / s[i], 1.0] for i in range(len(s))] )\nz = lstsq(A, 1 / w, rcond=None)[0]\nalpha, beta = z\nprint(\"alpha:\", alpha, \"beta:\", beta)\n\nThe two fits are different; they do not optimize the same quantities.\n\nlinmodel = lambda x: 1 / (beta + alpha / x)\nax.plot(s, linmodel(s), label=\"linear fit\")\nax.legend()\nfig\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/nlsq#nonlinear-data-fitting","position":7},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Exercises"},"type":"lvl2","url":"/nlsq#exercises","position":8},{"hierarchy":{"lvl1":"Nonlinear least squares","lvl2":"Exercises"},"content":"✍ Define \\mathbf{f}(x)=[ x-8, \\; x^2-4 ].\n\n(a) Write out the linear model of \\mathbf{f} at x=2.\n\n(b) Find the estimate produced by one step of the Gauss–Newton method, starting at x=2.\n\n✍ (Continuation of Exercise 1.) The Gauss–Newton method replaces \\mathbf{f}(\\mathbf{x}) by a linear model and minimizes the norm of its residual. An alternative is to replace \\| \\mathbf{f}(\\mathbf{x}) \\|_2^2 by a scalar quadratic model q(\\mathbf{x}) and minimize that.\n\n(a) Using \\mathbf{f}(x) = [ x-8, \\; x^2-4 ], let q(x) be defined by the first three terms in the Taylor series for \\| \\mathbf{f}(x) \\|_2^2 at x=2.\n\n(b) Find the unique x that minimizes q(x). Is the result the same as the estimate produced by Gauss–Newton?\n\n⌨  A famous result by Kermack and McKendrick in 1927 \n\nKermack et al. (1927) suggests that in epidemics that kill only a small fraction of a susceptible population, the death rate as a function of time is well modeled byw'(t) = A \\operatorname{sech}^2[B(t-C)]\n\nfor constant values of the parameters A,B,C. Since the maximum of sech is \\operatorname{sech}(0)=1, A is the maximum death rate and C is the time of peak deaths. You will use this model to fit the deaths per week from plague recorded in Mumbai\nduring 1906:5, 10, 17, 22, 30, 50, 51, 90, 120, 180, 292, 395, 445, 775, 780,\n700, 698, 880, 925, 800, 578, 400, 350, 202, 105, 65, 55, 40, 30, 20\n\n(a) Use \n\nFunction 4.6.3 to find the best least-squares fit to the data using the \\operatorname{sech}^2 model. Make a plot of the model fit superimposed on the data.\n\n(b) Repeat part (a) using only the first 15 data values.\n\n⌨  (Variation on \n\nExercise 4.5.6.) Suppose the points (x_i,y_i) for i=1,\\ldots,m are given, and the goal is to find the circle with center (a,b) and radius r that best fits the points. Definef_i(a,b,r) = (a-x_i)^2 + (b-y_i)^2 - r^2, \\qquad i=1,\\ldots,m.\n\nThen we can define the best circle as the one that minimizes \\|\\mathbf{f}\\|.\n\nDefine data points as follows:m = 30; t = 2π*rand(m);\nx = @. -2 + 5*cos(t); y = @. 1 + 5*sin(t);\nx += 0.2*randn(m); y += 0.2*randn(m);\n\nUse \n\nFunction 4.6.3 to find the best-fit circle, and make a plot of the circle superimposed on the points.\n\n⌨ The position of the upper lid during an eye blink can be measured from high-speed video \n\nWu et al. (2014), and it may be possible to classify blinks based in part on fits to the lid position \n\nBrosch et al. (2017). The lid position functions proposed to fit blinks is a product of a monomial or polynomial multiplying a decaying exponential \n\nBerke & Mueller (1998).  In this problem, you will generate representative data, add a small amount of noise to it, and then perform nonlinear least-squares fits to the data.\n\n(a) Consider the function y(\\mathbf{a}) = a_1 t^2 \\exp \\left( -a_2 t^{a_3} \\right), using the vector of coefficients \\mathbf{a} = [a_1,a_2,a_3], and create synthetic eyelid position data as follows:N = 20;                            # number of time values\nt = (1:N)/N;                       # equally spaced to t=1\na = [10, 10, 2];                   # baseline values\ny = @. a(1)*t^2*exp(-a(2)*t^a(3)); # ideal data\nym = copy(y);                      # vector for data\nir = 1:N-1;                        # range to add noise\nnoise = 0.03;                      # amplitude of noise\nym[ir] += noise*rand(N-1);         # add noise\n\n(b) Using the data (t,ym), find the nonlinear least-squares fit using \n\nFunction 4.6.3.\n\n(c) Plot the fits using np = 100 points over t=(1:np)/np together with symbols for the N measured data points ym.\n\n(d) Increase the noise to 5% and 10%. You may have to increase the number of measured points N and/or the maximum number of iterations.  How close are the coefficients?  Plot the data and the resulting fit for each case.\n\n⌨ Repeat the previous problem using the fitting function y(\\mathbf{a}) = (a_1+a_2 t + a_3 t^2) t^2 \\exp \\left( -a_4 t^{a_5} \\right), using the vector of coefficients \\mathbf{a} = [a_1,\\ldots,a_5]. (This was the choice used in Brosch et al \n\nBrosch et al. (2017).)  Use a = [20, -10, -8, 7, 2] to create the data and as an initial guess for the coefficients for the fit to the noisy data.","type":"content","url":"/nlsq#exercises","position":9},{"hierarchy":{"lvl1":"4. Roots of nonlinear equations"},"type":"lvl1","url":"/overview-3","position":0},{"hierarchy":{"lvl1":"4. Roots of nonlinear equations"},"content":"He says “I found her,” and keeps repeating, “She’s here.”\n\nC3PO, Star Wars: A New Hope\n\nIn this chapter we extend from linear algebra to deal with nonlinear algebraic problems. This kind of problem arises when there is a parameter or variable that can be changed in order to satisfy a constraint or achieve some goal. We start with scalar functions of a single variable, then generalize to n variables and n nonlinear equations. Finally, we generalize the problem of linear least squares to situations with more nonlinear constraints to satisfy than there are variables. In every case the strategy used is one of the cornerstones of numerical computing: replace a problem you can’t solve with an approximate one that you can. In the context of nonlinear algebraic problems, the particular tactic is to set up and solve a sequence of linear problems of the types covered in the two previous chapters.","type":"content","url":"/overview-3","position":1},{"hierarchy":{"lvl1":"Quasi-Newton methods"},"type":"lvl1","url":"/quasinewton","position":0},{"hierarchy":{"lvl1":"Quasi-Newton methods"},"content":"Newton’s method is a foundation for algorithms to solve equations and minimize quantities. But it is not ideal in its straightforward or pure form. Specifically, its least appealing features are the programming nuisance and computational expense of evaluating the Jacobian matrix, and the tendency of the iteration to diverge from many starting points. There are different quasi-Newton methods that modify the basic idea in an attempt to overcome these issues.","type":"content","url":"/quasinewton","position":1},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Jacobian by finite differences"},"type":"lvl2","url":"/quasinewton#jacobian-by-finite-differences","position":2},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Jacobian by finite differences"},"content":"In the scalar case, we found an easy alternative to a direct evaluation of the derivative. In retrospect, we may interpret the secant formula \n\n(4.4.2) as the Newton formula \n\n(4.3.2) with f'(x_k) replaced by the difference quotient  \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}.\n\nIf the sequence of x_k values converges to a root r, then this quotient converges to f'(r).\n\nIn the system case, replacing the Jacobian evaluation is more complicated: derivatives are needed with respect to n variables, not just one. From \n\n(4.5.4), we note that the jth column of the Jacobian is  \\mathbf{J}(\\mathbf{x}) \\mathbf{e}_j =\n  \\begin{bmatrix}\n    \\frac{\\partial{f_1}}{\\partial x_j} \\\\[2mm] \\frac{\\partial{f_2}}{\\partial x_j}\n    \\\\ \\vdots \\\\ \\frac{\\partial{f_n}}{\\partial x_j}\n  \\end{bmatrix}.\n\n(As always, \\mathbf{e}_j represents the jth column of the identity matrix, here in n dimensions.) Inspired by \n\n(4.6.1), we can replace the differentiation with a quotient involving a change in only x_j while the other variables remain fixed:  \\mathbf{J}(\\mathbf{x}) \\mathbf{e}_j \\approx\n  \\frac{\\mathbf{f}(\\mathbf{x}+\\delta \\mathbf{e}_j) - \\mathbf{f}(\\mathbf{x})}{\\delta}, \\qquad j=1,\\ldots,n.\n\nFor reasons explained in Chapter 5, δ is usually chosen close to \\sqrt{\\epsilon}, where ε represents the expected noise or uncertainty level in evaluation of \\mathbf{f}. If the only source of noise is floating-point roundoff, then \\delta \\approx \\sqrt{\\epsilon_\\text{mach}}.\n\nThe finite-difference formula \n\n(4.6.3) is implemented by \n\nFunction 4.6.1.\n\nfdjac\n\nFinite differences for Jacobian\n\n\"\"\"\n    fdjac(f, x₀ [,y₀])\n\nCompute a finite-difference approximation of the Jacobian matrix for\n`f` at `x₀`, where `y₀`=`f(x₀)` may be given.\n\"\"\"\nfunction fdjac(f, x₀, y₀ = f(x₀))\n    δ = sqrt(eps()) * max(norm(x₀), 1)    # near-optimum FD step size\n    m, n = length(y₀), length(x₀)\n    if n == 1\n        # Vector result for univariate functions.\n        J = (f(x₀ + δ) - y₀) / δ\n    else\n        J = zeros(m, n)\n        x = copy(x₀)\n        for j in 1:n\n            # Difference in the jth direction.\n            x[j] += δ\n            J[:, j] = (f(x) - y₀) / δ\n            x[j] -= δ\n        end\n    end\n    return J\nend\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.\n\nFinite differences for Jacobian\n\nfunction J = fdjac(f,x0,y0)\n% FDJAC   Finite-difference approximation of a Jacobian.\n% Input:\n%   f        function to be differentiated\n%   x0       evaluation point (n-vector)\n%   y0       value of f at x0 (m-vector)\n% Output       \n%   J        approximate Jacobian (m-by-n)\n\ndelta = sqrt(eps);   % FD step size\nm = length(y0);  n = length(x0);\nJ = zeros(m,n);\nI = eye(n);\nfor j = 1:n\n    J(:,j) = ( f(x0+delta*I(:,j)) - y0) / delta;\nend\n\nFinite differences for Jacobian\n\ndef fdjac(f, x0, y0):\n    \"\"\"\n    fdjac(f,x0,y0)\n\n    Compute a finite-difference approximation of the Jacobian matrix for f at x0,\n    where y0=f(x0) is given.\n    \"\"\"\n\n    delta = np.sqrt(np.finfo(float).eps)  # FD step size\n    m, n = len(y0), len(x0)\n    J = np.zeros((m, n))\n    I = np.eye(n)\n    for j in range(n):\n        J[:, j] = (f(x0 + delta * I[:, j]) - y0) / delta\n    return J\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.","type":"content","url":"/quasinewton#jacobian-by-finite-differences","position":3},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Broyden’s update"},"type":"lvl2","url":"/quasinewton#broydens-update","position":4},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Broyden’s update"},"content":"The finite-difference Jacobian is easy to conceive and use. But, as you can see from \n\n(4.6.3), it requires n additional evaluations of the system function at each iteration, which can be unacceptably slow in some applications. Conceptually these function evaluations seem especially wasteful given that the root estimates, and thus presumably the Jacobian matrix, are supposed to change little as the iteration converges. This is a good time to step in with the principle of approximate approximation, which suggests looking for a shortcut in the form of a cheap-but-good-enough way to update the Jacobian from one iteration to the next.\n\nRecall that the Newton iteration is derived by solving the linear model implied by \n\n(4.5.3):  \\mathbf{f}(\\mathbf{x}_{k+1}) \\approx \\mathbf{f}(\\mathbf{x}_k) + \\mathbf{J}(\\mathbf{x}_k)\\,(\\mathbf{x}_{k+1}-\\mathbf{x}_k) = \\boldsymbol{0}.\n\nLet \\mathbf{s}_k=\\mathbf{x}_{k+1}-\\mathbf{x}_k  be the Newton step. Let \\mathbf{y}_k=\\mathbf{f}(\\mathbf{x}_k), and now we replace \\mathbf{J}(\\mathbf{x}_k) by a matrix \\mathbf{A}_{k} that is meant to approximate the Jacobian. Hence the Newton step is considered to be defined, as in \n\nAlgorithm 4.5.1, by  \\mathbf{A}_k \\mathbf{s}_k = -\\mathbf{y}_k.\n\nOnce \\mathbf{x}_{k+1} is obtained, we should update the approximate Jacobian to a new \\mathbf{A}_{k+1}. If we think one-dimensionally for a moment, the secant method would assume that A_{k+1}=(f_{k+1}-f_k)/(x_{k+1}-x_k). It’s not easy to generalize a fraction to vectors, but we can do it if we instead write it as  \\mathbf{y}_{k+1}-\\mathbf{y}_k = \\mathbf{A}_{k+1} (\\mathbf{x}_{k+1}-\\mathbf{x}_k) = \\mathbf{A}_{k+1} \\mathbf{s}_k.\n\nThis is used to justify the following requirement:  \\mathbf{A}_{k+1} \\mathbf{s}_k = \\mathbf{y}_{k+1}-\\mathbf{y}_k.\n\nThis isn’t enough to uniquely determine \\mathbf{A}_{k+1}. However, if we also require that \\mathbf{A}_{k+1}-\\mathbf{A}_k is a matrix of rank 1, then one arrives at the following.\n\nBroyden update formula\n\nUsing the definitions above,  \\mathbf{A}_{k+1} = \\mathbf{A}_k + \\frac{1}{\\mathbf{s}_k^T \\mathbf{s}_k}(\\mathbf{y}_{k+1} - \\mathbf{y}_k -\\mathbf{A}_k \\mathbf{s}_k)\\, \\mathbf{s}_k^T.\n\nObserve that \\mathbf{A}_{k+1}-\\mathbf{A}_k is proportional to the outer product of two vectors, and that computing it requires no extra evaluations of \\mathbf{f}. Remarkably, under reasonable assumptions, the sequence of \\mathbf{x}_k resulting when Broyden updates are used converges superlinearly, even though the matrices \\mathbf{A}_k do not necessarily converge to the Jacobian of \\mathbf{f}.\n\nIn practice, one typically uses finite differences to initialize the Jacobian at iteration k=1. If for some k the step computed by the update formula fails to make enough improvement in the residual, then \\mathbf{A}_k is reinitialized by finite differences and the step is recalculated.","type":"content","url":"/quasinewton#broydens-update","position":5},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Levenberg’s method"},"type":"lvl2","url":"/quasinewton#levenbergs-method","position":6},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Levenberg’s method"},"content":"The most difficult part of many rootfinding problems is finding a starting point that will lead to convergence. The linear model implicitly constructed during a Newton iteration—whether we use an exact, finite-difference, or iteratively updated Jacobian matrix—becomes increasingly inaccurate as one ventures farther from the most recent root estimate, eventually failing to resemble the exact function much at all.\n\nAlthough one could imagine trying to do a detailed accuracy analysis of each linear model as we go, in practice simple strategies are valuable here. Suppose, after computing the step suggested by the linear model, we ask a binary question: Would taking that step improve our situation? Since we are trying to find a root of \\mathbf{f}, we have a quantitative way to pose this question: Does the backward error \\|\\mathbf{f}\\| decrease? If not, we should reject the step and find an alternative.\n\nThere are several ways to find alternatives to the standard step, but we will consider just one of them, based on the parameterized equation  (\\mathbf{A}_k^T \\mathbf{A}_k + \\lambda \\mathbf{I})\\,\\mathbf{s}_k = -\\mathbf{A}_k^T \\mathbf{f}_k.\n\nLevenberg’s method\n\nGiven \\mathbf{f}, a starting value \\mathbf{x}_1, and a scalar λ, for each k=1,2,3,\\ldots\n\nCompute \\mathbf{y}_k = \\mathbf{f}(\\mathbf{x}_k), and let \\mathbf{A}_k be an exact or approximate Jacobian matrix.\n\nSolve the linear system \n\n(4.6.9) for \\mathbf{s}_k.\n\nLet \\hat{\\mathbf{x}} = \\mathbf{x}_k + \\mathbf{s}_k.\n\nIf the residual is reduced at \\hat{\\mathbf{x}}, then let \\mathbf{x}_{k+1}=\\hat{\\mathbf{x}}.\n\nUpdate λ and update \\mathbf{A}_k to \\mathbf{A}_{k+1}.\n\nSome justification of \n\n(4.6.9) comes from considering extreme cases for λ. If \\lambda=0, then  \\mathbf{A}_k^T \\mathbf{A}_k \\mathbf{s}_k = -\\mathbf{A}_k^T \\mathbf{f}_k,\n\nwhich is equivalent to the definition of the usual linear model (i.e., Newton or quasi-Newton) step \n\n(4.6.5). On the other hand, as \\lambda\\to\\infty, Equation \n\n(4.6.9) approaches  \\lambda \\mathbf{s}_k = - \\mathbf{A}_k^T \\mathbf{f}_k.\n\nTo interpret this equation, define the scalar residual function\\phi(\\mathbf{x})=\\mathbf{f}(\\mathbf{x})^T\\mathbf{f}(\\mathbf{x}) = \\|\\mathbf{f}(\\mathbf{x})\\|^2.\n\nFinding a root of \\mathbf{f} is equivalent to minimizing ϕ. A calculation shows that the gradient of ϕ is   \\nabla \\phi(\\mathbf{x}) = 2 \\mathbf{J}(\\mathbf{x})^T \\mathbf{f}(\\mathbf{x}).\n\nHence, if \\mathbf{A}_k=\\mathbf{J}(\\mathbf{x}_k), then \\mathbf{s}_k from \n\n(4.6.11) is in the opposite direction from the gradient vector. In vector calculus you learn that this direction is the one of most rapid decrease or steepest descent. A small enough step in this direction is guaranteed in all but pathological cases to decrease ϕ, which is exactly what we want from a backup plan.\n\nIn effect, the λ parameter in \n\n(4.6.9) allows a smooth transition between the pure Newton step, for which convergence is very rapid near a root, and a small step in the gradient descent direction, which guarantees progress for the iteration when we are far from a root.","type":"content","url":"/quasinewton#levenbergs-method","position":7},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Implementation"},"type":"lvl2","url":"/quasinewton#implementation","position":8},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Implementation"},"content":"To a large extent, the incorporation of finite differences, Jacobian updates, and Levenberg step are independent decisions. \n\nFunction 4.6.3 shows how they might be combined. This function is one of the most logically complex we have encountered so far.\n\nEach pass through the loop starts by using \n\n(4.6.9) to propose a step \\mathbf{s}_k. The function then asks whether using this step would decrease the value of \\|\\mathbf{f}\\| from its present value. If so, we accept the new root estimate, we decrease λ in order to get more Newton-like (since things have gone well), and we apply the Broyden formula to get a cheap update of the Jacobian. If the proposed step is not successful, we increase λ to get more gradient-like (since we just failed) and, if the current Jacobian was the result of a cheap update, use finite differences to reevaluate it.\n\nlevenberg\n\nLevenberg’s method\n\n\"\"\"\n    levenberg(f, x₁ [;maxiter, ftol, xtol])\n\nUse Levenberg's quasi-Newton iteration to find a root of the system\n`f` starting from `x₁` Returns the history of root estimates as a\nvector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction levenberg(f, x₁; maxiter = 40, ftol = 1e-12, xtol = 1e-12)\n    x = [float(x₁)]\n    yₖ = f(x₁)\n    k = 1\n    s = Inf\n    A = fdjac(f, x[k], yₖ)   # start with FD Jacobian\n    jac_is_new = true\n\n    λ = 10\n    while (norm(s) > xtol) && (norm(yₖ) > ftol)\n        # Compute the proposed step.\n        B = A' * A + λ * I\n        z = A' * yₖ\n        s = -(B \\ z)\n\n        x̂ = x[k] + s\n        ŷ = f(x̂)\n\n        # Do we accept the result?\n        if norm(ŷ) < norm(yₖ)    # accept\n            λ = λ / 10   # get closer to Newton\n            # Broyden update of the Jacobian.\n            A += (ŷ - yₖ - A * s) * (s' / (s' * s))\n            jac_is_new = false\n\n            push!(x, x̂)\n            yₖ = ŷ\n            k += 1\n        else    # don't accept\n            # Get closer to gradient descent.\n            λ = 4λ\n            # Re-initialize the Jacobian if it's out of date.\n            if !jac_is_new\n                A = fdjac(f, x[k], yₖ)\n                jac_is_new = true\n            end\n        end\n\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n    end\n    return x\nend\n\nLevenberg’s method\n\nfunction x = levenberg(f,x1,tol)\r\n% LEVENBERG   Quasi-Newton method for nonlinear systems.\r\n% Input:\r\n%   f         objective function \r\n%   x1        initial root approximation\r\n%   tol       stopping tolerance (default is 1e-12)\r\n% Output       \r\n%   x         array of approximations (one per column)\r\n\r\n% Operating parameters.\r\nif nargin < 3, tol = 1e-12; end\r\nftol = tol;  xtol = tol;  maxiter = 40;\r\n\r\nx = x1(:);     fk = f(x1);\r\nk = 1;  s = Inf;        \r\nAk = fdjac(f,x(:,1),fk);   % start with FD Jacobian\r\njac_is_new = true;\r\nI = eye(length(x));\r\n\r\nlambda = 10; \r\nwhile (norm(s) > xtol) && (norm(fk) > ftol) && (k < maxiter)\r\n    % Compute the proposed step.\r\n    B = Ak'*Ak + lambda*I;\r\n    z = Ak'*fk;\r\n    s = -(B\\z);\r\n\r\n    xnew = x(:,k) + s;   fnew = f(xnew);\r\n    \r\n    % Do we accept the result?\r\n    if norm(fnew) < norm(fk)    % accept\r\n        y = fnew - fk;\r\n        x(:,k+1) = xnew;  fk = fnew;  \r\n        k = k+1;\r\n        \r\n        lambda = lambda/10;  % get closer to Newton\r\n        % Broyden update of the Jacobian.\r\n        Ak = Ak + (y-Ak*s)*(s'/(s'*s));\r\n        jac_is_new = false;\r\n    else                       % don't accept\r\n        % Get closer to steepest descent.\r\n        lambda = lambda*4;\r\n        % Re-initialize the Jacobian if it's out of date.\r\n        if ~jac_is_new\r\n            Ak = fdjac(f,x(:,k),fk);\r\n            jac_is_new = true;\r\n        end\r\n    end\r\nend\r\n\r\nif (norm(fk) > 1e-3)\r\n    warning('Iteration did not find a root.')\r\nend\n\nLevenberg’s method\n\ndef levenberg(f, x1, tol=1e-12):\n    \"\"\"\n    levenberg(f,x1,tol)\n\n    Use Levenberg's quasi-Newton iteration to find a root of the system f, \n    starting from x1, with tol as the stopping tolerance in both step size and residual norm. Returns root estimates as a matrix, one estimate per column.\n    \"\"\"\n\n    # Operating parameters.\n    ftol = tol\n    xtol = tol\n    maxiter = 40\n\n    n = len(x1)\n    x = np.zeros((maxiter+1, n))\n    x[0] = x1\n    fk = f(x1)\n    k = 0\n    s = 10.0\n    Ak = fdjac(f, x[0], fk)  # start with FD Jacobian\n    jac_is_new = True\n\n    lam = 10\n    while (norm(s) > xtol) and (norm(fk) > ftol) and (k < maxiter):\n        # Compute the proposed step.\n        B = Ak.T @ Ak + lam * np.eye(n)\n        z = Ak.T @ fk\n        s = -lstsq(B, z)[0]\n\n        xnew = x[k] + s\n        fnew = f(xnew)\n\n        # Do we accept the result?\n        if norm(fnew) < norm(fk):  # accept\n            y = fnew - fk\n            x[k + 1] = xnew\n            fk = fnew\n            k = k + 1\n\n            lam = lam / 10  # get closer to Newton\n            # Broyden update of the Jacobian.\n            Ak = Ak + np.outer(y - Ak @ s, s / np.dot(s, s))\n            jac_is_new = False\n        else:  # don't accept\n            # Get closer to steepest descent.\n            lam = lam * 4\n            # Re-initialize the Jacobian if it's out of date.\n            if not jac_is_new:\n                Ak = fdjac(f, x[k], fk)\n                jac_is_new = True\n\n    if norm(fk) > 1e-3:\n        warnings.warn(\"Iteration did not find a root.\")\n    return x[:k+1]\n\n\nIn some cases our simple logic in \n\nFunction 4.6.3 can make λ oscillate between small and large values; several better but more complicated strategies for controlling λ are known. In addition, the linear system \n\n(4.6.9) is usually modified to get the well-known Levenberg–Marquardt algorithm, which does a superior job in some problems as \\lambda\\to \\infty.\n\nUsing Levenberg’s method\n\nExample 4.6.1\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nf(x) = \n    [\n        exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx₁ = [0.0, 0.0, 0.0]\nx = FNC.levenberg(f, x₁)\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[end]\nprintln(\"backward error = $(norm(f(r)))\")\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method.\n\nlogerr = [log(norm(r - x[k])) for k in 1:length(x)-1]\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"log error\", \"ratio\"] [eachindex(logerr) logerr ratios]\n\nExample 4.6.1\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nTip\n\nA rule of thumb is that if you use a function as an input argument for another function, there needs to be an @ involved once: either for an anonymous definition or to reference a function defined elsewhere.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nIn all other respects usage is the same as for the newtonsys function.\n\nf = @f46_nlsystem;\nx1 = [0; 0; 0];   \nx = levenberg(f, x1);\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x(:, end)\nbackward_err = norm(f(r))\n\nLooking at the convergence of the first component, we find a rate between linear and quadratic, like with the secant method.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'\n\nExample 4.6.1\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx1 = zeros(3)\nx = FNC.levenberg(func, x1)\nprint(f\"Took {len(x) - 1} iterations.\")\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[-1]\nprint(\"backward error:\", norm(func(r)))\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method:\n\nlogerr = [log(norm(x[k] - r)) for k in range(len(x) - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])","type":"content","url":"/quasinewton#implementation","position":9},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Exercises"},"type":"lvl2","url":"/quasinewton#exercises","position":10},{"hierarchy":{"lvl1":"Quasi-Newton methods","lvl2":"Exercises"},"content":"⌨ (Variation on \n\nExercise 4.5.2.) Two curves in the (u,v) plane are defined implicitly by the equations u\\log u + v \\log v = -0.3 and u^4 + v^2 = 1.\n\n(a) ✍ Write the intersection of these curves in the form \\mathbf{f}(\\mathbf{x}) = \\boldsymbol{0} for two-dimensional \\mathbf{f} and \\mathbf{x}.\n\n(b) ⌨ Use \n\nFunction 4.6.3 to find an intersection point starting from u=1, v=0.1.\n\n(d) ⌨ Use \n\nFunction 4.6.3 to find an intersection point starting from u=0.1, v=1.\n\n⌨ (Variation on \n\nExercise 4.5.4) Two elliptical orbits (x_1(s),y_1(s)) and (x_2(t),y_2(t)) are described by the equations\\begin{bmatrix}\n  x_1(t) \\\\ y_1(t)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n  -5+10\\cos(t) \\\\ 6\\sin(t)\n\\end{bmatrix}, \\qquad\n\\begin{bmatrix}\n  x_2(t)\\\\y_2(t)\n\\end{bmatrix} =\n\\begin{bmatrix}\n  8\\cos(t) \\\\ 1+12\\sin(t)\n\\end{bmatrix},\n\nwhere t represents time.\n\n(a) ✍ Write out a 2\\times 2 nonlinear system of equations that describes an intersection of these orbits. (Note: An intersection is not the same as a collision—they don’t have to occupy the same point at the same time.)\n\n(b) ⌨ Use \n\nFunction 4.6.3 to find all of the unique intersections.\n\n⌨  (Variation on \n\nExercise 4.5.5) Suppose one wants to find the points on the ellipsoid x^2/25 + y^2/16 + z^2/9 = 1 that are closest to and farthest from the point (5,4,3). The method of Lagrange multipliers implies that any such point satisfies\\begin{split}\n    x-5 &= \\frac{\\lambda x}{25}, \\\\[1mm]\n    y-4 &= \\frac{\\lambda y}{16}, \\\\[1mm]\n    z-3 &= \\frac{\\lambda z}{9}, \\\\[1mm]\n    1 &=  \\frac{1}{25}x^2 + \\frac{1}{16}y^2 + \\frac{1}{9}z^2\n\\end{split}\n\nfor an unknown value of λ.\n\n(a) Write out this system in the form \\mathbf{f}(\\mathbf{u}) = \\boldsymbol{0}. (Note that the system has four variables to go with the four equations.)\n\n(b) Use \n\nFunction 4.6.3 with different initial guesses to find the two roots of this system. Which is the closest point to (5,4,3), and which is the farthest?\n\n✍ The Broyden update formula \n\n(4.6.8) is just one instance of so-called rank-1 updating. Verify the  Sherman–Morrison formula,(\\mathbf{A}+\\mathbf{u}\\mathbf{v}^T)^{-1} = \\mathbf{A}^{-1} - \\mathbf{A}^{-1}\\frac{\\mathbf{u}\\mathbf{v}^T}{1+\\mathbf{v}^T\\mathbf{A}^{-1}\\mathbf{u}}\\mathbf{A}^{-1},\n\nwhich is valid whenever \\mathbf{A} is invertible and the denominator above is nonzero. (Hint: Show that \\mathbf{A}+\\mathbf{u}\\mathbf{v}^T times the matrix above simplifies to the identity matrix.)\n\n✍ Derive Equation \n\n(4.6.13).\n\n⌨ (See also \n\nExercise 4.5.11.) Suppose that\\mathbf{f}(\\mathbf{x}) =\n\\begin{bmatrix}\n  x_1x_2+x_2^2-1 \\\\[1mm] x_1x_2^3 + x_1^2x_2^2 + 1\n\\end{bmatrix}.\n\nLet \\mathbf{x}_1=[-2,1]^T and let \\mathbf{A}_1=\\mathbf{J}(\\mathbf{x}_1) be the exact Jacobian.\n\n(a) Solve \n\n(4.6.9) for \\mathbf{s}_1 with \\lambda=0; this is the “pure” Newton step. Show numerically that \\|\\mathbf{f}(\\mathbf{x}_1+\\mathbf{s}_1)\\| > \\|\\mathbf{f}(\\mathbf{x}_1)\\|. (Thus, the Newton step made us go to a point seemingly farther from a root than where we started.)\n\n(b) Now repeat part (a) with \\lambda=0.01j for j=1,2,3,\\ldots. What is the smallest value of j such that \\|\\mathbf{f}(\\mathbf{x}_1+\\mathbf{s}_1)\\| < \\|\\mathbf{f}(\\mathbf{x}_1)\\|?\n\n✍ Show that Equation \n\n(4.6.9) is equivalent to the linear least-squares problem\\min_{\\mathbf{v}} \\Bigl(  \\bigl\\|\\mathbf{A}_k\\mathbf{v} + \\mathbf{f}_k\\bigr\\|_2^2 +\n\\lambda^2 \\bigl\\| \\mathbf{v} \\bigr\\|_2^2 \\Bigr).\n\n(Hint: Express the minimized quantity using block matrix notation, such that \n\n(4.6.9) becomes the normal equations for it.)\n\nThus, another interpretation of Levenberg’s method is that it is the Newton step plus a penalty, weighted by λ, for taking large steps.","type":"content","url":"/quasinewton#exercises","position":11},{"hierarchy":{"lvl1":"The rootfinding problem"},"type":"lvl1","url":"/rootproblem","position":0},{"hierarchy":{"lvl1":"The rootfinding problem"},"content":"For the time being we will focus on the rootfinding problem for single functions of one variable.\n\nRootfinding problem\n\nGiven a continuous scalar function f of a scalar variable, find a real number r, called a root, such that f(r)=0.\n\nThe formulation f(x)=0 is general enough to solve any equation. If we are trying to solve an equation g(x)=h(x), we can define f=g-h and find a root of f.\n\nUnlike the linear problems of the earlier chapters, the usual situation here is that the root cannot be produced in a finite number of operations, even in exact arithmetic. Instead, we seek a sequence of approximations that formally converge to the root, stopping when some member of the sequence seems to be good enough, in a sense we will clarify later.\n\nThe rootfinding problem for Bessel functions\n\nIn the theory of vibrations of a circular drum, the displacement of the drumhead can be expressed in terms of pure harmonic modes,J_m(\\omega_{k,m} r) \\cos(m\\theta) \\cos(c \\omega_{k,m} t),\n\nwhere (r,\\theta) are polar coordinates, 0\\le r\\le 1, t is time, m is a positive integer, c is a material parameter, and J_m is a Bessel function of the first kind. The quantity \\omega_{k,m} is a resonant frequency and is a positive root of the equationJ_m(\\omega_{k,m}) = 0,\n\nwhich states that the drumhead is clamped around the rim. Bessel functions often appear in physical problems featuring radial symmetry, and tabulating approximations to the zeros of Bessel functions occupied numerous mathematician-hours before computers were on the scene.\n\nExample 4.1.1\n\nusing Plots, SpecialFunctions\nJ₃(x) = besselj(3, x)\nplot(J₃, 0, 20;\n    title=\"Bessel function\",\n    xaxis=(L\"x\"),  yaxis=(L\"J_3(x)\"),  grid=:xy)\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nTip\n\nType \\omega followed by Tab to get the character ω.\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nusing NLsolve\nω = []\nfor guess = [6., 10. ,13., 16., 19.]\n    s = nlsolve(x -> J₃(x[1]), [guess], ftol=1e-14)\n    append!(ω, s.zero)\nend\n\ny = J₃.(ω)\n@pt :header=[\"root estimate\", \"function value\"] [ω y]\n\nscatter!(ω, y, title=\"Bessel function with roots\")\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nr = []\nfor guess = [3., 6., 10., 13.]\n    f(x) = J₃(x[1]) - 0.2\n    s = nlsolve(f, [guess], ftol=1e-14)\n    append!(r, s.zero)\nend\nscatter!(r, J₃.(r), title=\"Roots and other Bessel values\")\n\nExample 4.1.1\n\nJ3 = @(x) besselj(3,x);\nfplot(J3, [0, 20])\ngrid on\nxlabel('x'), ylabel('J_3(x)')  \ntitle('Bessel function')\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nTip\n\nType \\omega followed by Tab to get the character ω.\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nomega = [];\nfor guess = [6, 10, 13, 16, 19]\n    omega = [omega; fzero(J3, guess)];\nend\nomega\n\ntable(omega, J3(omega), 'VariableNames', {'root estimate', 'function value'})\n\nhold on\nscatter(omega, J3(omega))\ntitle('Bessel roots')\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = [];\nfor guess = [3, 6, 10, 13]\n    f = @(x) J3(x) - 0.2;\n    omega = [omega; fzero(f, guess)];\nend\nscatter(omega, J3(omega), '<')\n\nExample 4.1.1\n\nimport scipy.special as special\ndef J3(x):\n    return special.jv(3.0, x)\n\nxx = linspace(0, 20, 500)\nfig, ax = subplots()\nax.plot(xx, J3(xx))\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$J_3(x)$\")\ntitle(\"Bessel function\");\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use root_scalar from the scipy.optimize package to find these roots accurately.\n\nfrom scipy.optimize import root_scalar\n\nomega = []\nfor guess in [6.0, 10.0, 13.0, 16.0, 19.0]:\n    s = root_scalar(J3, bracket=[guess - 0.5, guess + 0.5]).root\n    omega.append(s)\n\nresults = PrettyTable()\nresults.add_column(\"root estimate\", omega)\nresults.add_column(\"function value\", [J3(ω) for ω in omega])\nprint(results)\n\nax.scatter(omega, J3(omega))\nax.set_title(\"Bessel function roots\")\nfig\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = []\nfor guess in [3., 6., 10., 13.]:\n    f = lambda x: J3(x) - 0.2\n    s = root_scalar(f, x0=guess).root\n    omega.append(s)\n\nax.scatter(omega, J3(omega))\nfig","type":"content","url":"/rootproblem","position":1},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Conditioning, error, and residual"},"type":"lvl2","url":"/rootproblem#conditioning-error-and-residual","position":2},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Conditioning, error, and residual"},"content":"In the rootfinding problem, the data is a continuous function f and the result is a root. (This overrides our Chapter 1 notation of f as the map from data to result.) How does the result change in response to perturbations in f? We will compute an absolute condition number rather than a relative one.\n\nYou might wonder about the relevance of perturbing a function as data to a problem. If nothing else, the values of f will be represented in floating point and thus subject to rounding error. Furthermore, in many applications, f might not be a simple formula but the result of a computation that uses an inexact algorithm. While there are infinitely many possible perturbations to a function, a constant perturbation is enough to get the main idea.\n\nWe assume f has at least one continuous derivative near a particular root r. Suppose that f is perturbed to \\tilde{f}(x) = f(x) + \\epsilon. As a result, the root (if it still exists) will be perturbed to \\tilde{r} = r + \\delta such that \\tilde{f}(\\tilde{r})=0. We now compute an absolute condition number \\kappa_r, which is the ratio \\left | \\frac{\\delta}{\\epsilon} \\right| as \\epsilon\\to 0.\n\nUsing Taylor’s theorem,  0 = f(r+\\delta) + \\epsilon \\approx f(r) + f'(r) \\delta + \\epsilon.\n\nSince r is a root, we have f(r)=0. This lets us relate δ to ε, and their ratio is the condition number.\n\nCondition number of rootfinding\n\nIf f is differentiable at a root r, then the absolute condition number of r with respect to constant changes in f is  \\kappa_r = \\bigl| f'(r) \\bigr|^{-1}.\n\nWe say \\kappa_r = \\infty if f'(r)=0.\n\nEquivalently, \n\n(4.1.4) is just the magnitude of the derivative of the inverse function f^{-1} at zero.\n\nCondition number of a rootfinding problem\n\nExample 4.1.2\n\nConsider first the function\n\nf(x) = (x - 1) * (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nTip\n\nThe syntax interval... is called splatting and means to insert all the individual elements of interval as a sequence.\n\ninterval = [0.8, 1.2]\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Well-conditioned root\")\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf(x) = (x - 1) * (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Poorly-conditioned root\")\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!\n\nExample 4.1.2\n\nConsider first the function\n\nf  = @(x) (x - 1) .* (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nclf\ninterval = [0.8, 1.2];\nfplot(f, interval)\ngrid on, hold on\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\naxis equal,  yticks([0])\nylim([-0.1, 0.1])\nxlabel('x'), ylabel('f(x)')\ntitle('Well-conditioned root')\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = @(x) (x - 1) .* (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\naxis(axis), cla\nfplot(f, interval)\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\nylim([-0.1, 0.1]), yticks([0])\ntitle('Poorly conditioned root')\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!\n\nExample 4.1.2\n\nConsider first the function\n\nf = lambda x: (x - 1) * (x - 2)\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Well-conditioned root\");\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = lambda x: (x - 1) * (x - 1.01)\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Poorly-conditioned root\");\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!\n\nWe must accept that when |f'| is small at the root, it may not be possible to get a small error in a computed root estimate. As always, the error is not a quantity we can compute without knowing the exact answer. There is something else we can measure, though.\n\nRootfinding residual\n\nIf \\tilde{r} approximates a root r of function f, then the residual at \\tilde{r} is f(\\tilde{r}).\n\nIt stands to reason that a small residual might be associated with a small error. To quantify the relationship, let \\tilde{r} approximate root r, and define the new function g(x)=f(x)-f(\\tilde{r}). Trivially, g(\\tilde{r})=0, meaning that \\tilde{r} is a true root of g. Since the difference g(x)-f(x) is the residual value f(\\tilde{r}), the residual is the distance to an exactly solved rootfinding problem.\n\nThe backward error in a root estimate is equal to the residual.\n\nIn general, it is not realistic to expect a small error in a root approximation if the condition number \n\n(4.1.4) is large. However, we can gauge the backward error from the residual.","type":"content","url":"/rootproblem#conditioning-error-and-residual","position":3},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Multiple roots"},"type":"lvl2","url":"/rootproblem#multiple-roots","position":4},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Multiple roots"},"content":"The condition number \n\n(4.1.4) naturally leads to the question of what happens if f'(r)=0 at a root r. The following definition agrees with and extends the notion of algebraic multiplicity in a polynomial to roots of more general differentiable functions.\n\nMultiplicity of a root\n\nIf f(r)=f'(r)=\\cdots=f^{(m-1)}(r)=0, but f^{(m)}(r)\\neq 0, then we say f has a root of multiplicity m at r. In particular, if f(r)=0 and f'(r)\\neq 0, then m=1 and we call r a simple root.\n\nAnother useful characterization of multiplicity m is that f(x)=(x-r)^m q(x) for a differentiable q with q(r)\\neq 0.\n\nWhen r is a nonsimple root, the condition number \n\n(4.1.4) is effectively infinite. However, even if r is simple, we should expect difficulty in rootfinding if the condition number is very large. This occurs when |f'(r)| is very small, which means that the quotient q satisfies q(r)\\approx 0 and another root of f is very close to r. We made the same observation about polynomial roots all the way back in \n\nDemo 1.4.3.","type":"content","url":"/rootproblem#multiple-roots","position":5},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Exercises"},"type":"lvl2","url":"/rootproblem#exercises","position":6},{"hierarchy":{"lvl1":"The rootfinding problem","lvl2":"Exercises"},"content":"⌨  For each equation and given interval, do the following steps.\n\n(a) Rewrite the equation into the standard form for rootfinding, f(x) = 0. Make a plot of f over the given interval and determine how many roots lie in the interval.\n\n(b)  Use nlsolve to find each root, as shown in \n\nDemo 4.1.1.\n\n(c) Compute the condition number of each root found in part (b).\n\nx^2=e^{-x}, over [-2,2]\n\n2x = \\tan x, over [-0.2,1.4]\n\ne^{x+1}=2+x, over [-2,2]\n\n⌨ A basic safe type of investment is an annuity: one makes monthly deposits of size P for n months at a fixed annual interest rate r, and at maturity collects the amount\\frac{12 P}{r} \\left( \\Bigl(1+\\frac{r}{12}\\Bigr)^n - 1\\right).\n\nSay you want to create an annuity for a term of 300 months and final value of $1,000,000. Using nlsolve, make a table of the interest rate you will need to get for each of the different contribution values P=500,550,\\ldots,1000.\n\n⌨ The most easily observed properties of the orbit of a celestial body around the sun are the period τ and the elliptical eccentricity ε. (A circle has \\epsilon=0.) From these, it is possible to find at any time t the angle \\theta(t) made between the body’s position and the major axis of the ellipse. This is done through\\tan \\frac{\\theta}{2} = \\sqrt{\\frac{1+\\epsilon}{1-\\epsilon}}\\,\n\\tan \\frac{\\psi}{2},\n\nwhere the eccentric anomaly \\psi(t) satisfies Kepler’s equation:\\psi - \\epsilon \\sin \\psi - \\frac{2\\pi t}{\\tau} = 0.\n\nEquation \n\n(4.1.7) must be solved numerically to find \\psi(t), and then \n\n(4.1.6) can be solved analytically to find \\theta(t).\n\nThe asteroid Eros has \\tau=1.7610 years and \\epsilon=0.2230. Using nlsolve for \n\n(4.1.7), make a plot of \\theta(t) for 100 values of t between 0 and τ, which is one full orbit. (Note: Use mod(θ,2π) to put the angle between 0 and 2\\pi if you want the result to be a continuous function.)\n\n⌨  Lambert’s W function is defined as the inverse of x e^x. That is, y=W(x) if and only if x=ye^y. Write a function lambertW that computes W using nlsolve. Make a plot of W(x) for 0\\le x \\le 4.\n\n✍ For each function, find the multiplicity of the given root. If it is a simple root, find its absolute condition number.\n\n(a) f(x) = x^3-2x^2+x-2, root r=2\n\n(b) f(x) = (\\cos x  + 1)^2, root r=\\pi\n\n(c) f(x) = \\frac{\\sin^2 x}{x}, root r=0 (define f(0) =0)\n\n(d) f(x) =(x-1)\\log(x), root r=1\n\nBased on our definitions, this means that the relative change to the root when f is changed by a perturbation of size ε is not O(\\epsilon) as \\epsilon\\to 0.","type":"content","url":"/rootproblem#exercises","position":7},{"hierarchy":{"lvl1":"Interpolation-based methods"},"type":"lvl1","url":"/secant","position":0},{"hierarchy":{"lvl1":"Interpolation-based methods"},"content":"From a practical standpoint, one of the biggest drawbacks of Newton’s method is the requirement to supply f' in \n\nFunction 4.3.2. It is both a programming inconvenience and a step that requires computational time. We can avoid using f', however, by making a simple but easily overlooked observation:\n\nWhen a step produces an approximate result, you are free to carry it out approximately.\n\nLet’s call this the principle of approximate approximation.\n\nIn the Newton context, the principle of approximate approximation begins with the observation that the use of f' is linked to the construction of a linear approximation q(x) equivalent to a tangent line. The root of q(x) is used to define the next iterate in the sequence. We can avoid calculating the value of f' by choosing a different linear approximation.\n\nGraphical interpretation of the secant method\n\nExample 4.4.1\n\nWe return to finding a root of the equation x e^x=2.\n\nusing Plots\nf(x) = x * exp(x) - 2;\nplot(f, 0.25, 1.25;\n    label=\"function\",  legend=:topleft,\n    xlabel=L\"x\",  ylabel=L\"y\")\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx₁ = 1;\ny₁ = f(x₁);\nx₂ = 0.5;\ny₂ = f(x₂);\nscatter!([x₁, x₂], [y₁, y₂];\n    label=\"initial points\",\n    title=\"Two initial values\")\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nm₂ = (y₂ - y₁) / (x₂ - x₁)\nsecant = x -> y₂ + m₂ * (x - x₂)\nplot!(secant, 0.25, 1.25, label=\"secant line\", l=:dash, color=:black,\n    title=\"Secant line\")\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx₃ = x₂ - y₂ / m₂\n@show y₃ = f(x₃)\nscatter!([x₃], [0], label=\"root of secant\", title=\"First iteration\")\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nm₃ = (y₃ - y₂) / (x₃ - x₂)\nx₄ = x₃ - y₃ / m₃\n\nExample 4.4.1\n\nWe return to finding a root of the equation x e^x=2.\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0.25, 1.25])\nset(gca, 'ygrid', 'on')  \nxlabel('x'), ylabel('y')    \ntitle('Objective function')\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1;    y1 = f(x1);\nx2 = 0.5;  y2 = f(x2);\nhold on, scatter([x1, x2], [y1, y2])\ntitle('Two initial values')\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1);\nsecant2 = @(x) y2 + slope2 * (x - x2);\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nfplot(secant2,[0.25, 1.25],'k--')\nx3 = x2 - y2 / slope2;\ny3 = f(x3)\nscatter(x3, 0)\ntitle('Next value')\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope2 = (y3 - y2) / (x3 - x2);\nx4 = x3 - y3 / slope2;\ny4 = f(x4)\n\nExample 4.4.1\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0.25, 1.25, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$f(x)$\")\nax.grid();\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1\ny1 = f(x1)\nx2 = 0.5\ny2 = f(x2)\nax.plot([x1, x2], [y1, y2], \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1)\nsecant2 = lambda x: y2 + slope2 * (x - x2)\nax.plot(xx, secant2(xx), \"--\", label=\"secant line\")\nax.legend()\nfig\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx3 = x2 - y2 / slope2\nax.plot(x3, 0, \"o\", label=\"root of secant\")\ny3 = f(x3)\nprint(y3)\nax.legend()\nfig\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope3 = (y3 - y2) / (x3 - x2)\nx4 = x3 - y3 / slope3\nprint(f(x4))\n\nThe example in \n\nDemo 4.4.1 demonstrates the secant method. In the secant method, one finds the root of the linear approximation through the two most recent root estimates. That is, given previous approximations x_1,\\ldots,x_k, define the linear model function as the line through \\bigl(x_{k-1},f(x_{k-1})\\bigr) and \\bigl(x_k,f(x_k)\\bigr):q(x) = f(x_k) + \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}(x-x_k).\n\nSolving q(x_{k+1})=0 for x_{k+1} gives the iteration formula.\n\nSecant iteration\n\nGiven function f and two initial values x_1 and x_2, definex_{k+1} = x_k - \\frac{f(x_k)(x_k-x_{k-1})}{f(x_k)-f(x_{k-1})}, \\quad k=2,3,\\ldots.\n\nOur implementation of the secant method is given in \n\nFunction 4.4.2.\n\nsecant\n\nSecant method\n\n\"\"\"\n    secant(f, x₁, x₂ [;maxiter, ftol, xtol])\n\nUse the secant method to find a root of `f` starting from `x₁` and\n`x₂`. Returns a vector of root estimates.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\"\"\"\nfunction secant(f, x₁, x₂; maxiter = 40, ftol = 1e-13, xtol = 1e-13)\n    x = [float(x₁), float(x₂)]\n    y₁ = f(x₁)\n    Δx, y₂ = Inf, Inf   # for initial pass in the loop below\n    k = 2\n\n    while (abs(Δx) > xtol) && (abs(y₂) > ftol)\n        y₂ = f(x[k])\n        Δx = -y₂ * (x[k] - x[k-1]) / (y₂ - y₁)   # secant step\n        push!(x, x[k] + Δx)        # append new estimate\n\n        k += 1\n        y₁ = y₂    # current f-value becomes the old one next time\n\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.\n\nSecant method\n\nfunction x = secant(f,x1,x2)\r\n% SECANT   Secant method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   x1,x2    initial root approximations\r\n% Output       \r\n%   x        vector of root approximations (last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = [x1 x2];\r\ndx = Inf;  y1 = f(x1);\r\nk = 2;  y2 = f(x2);\r\n\r\nwhile (abs(dx) > xtol) && (abs(y2) > funtol) && (k < maxiter)\r\n    dx = -y2 * (x(k)-x(k-1)) / (y2-y1);   % secant step\r\n    x(k+1) = x(k) + dx;\r\n    \r\n    k = k+1;\r\n    y1 = y2;    % current f-value becomes the old one next time\r\n    y2 = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nSecant method\n\ndef secant(f, x1, x2):\n    \"\"\"\n    secant(f, x1, x2)\n\n    Use the secant method to find a root of f starting from x1 and x2. Returns a\n    vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[:2] = [x1, x2]\n    y1 = f(x1)\n    y2 = 100\n    dx = np.inf  # for initial pass below\n    k = 1\n\n    while (abs(dx) > xtol) and (abs(y2) > funtol) and (k < maxiter):\n        y2 = f(x[k])\n        dx = -y2 * (x[k] - x[k - 1]) / (y2 - y1)  # secant step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y1 = y2  # current f-value becomes the old one next time\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:k+1]\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.","type":"content","url":"/secant","position":1},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Convergence"},"type":"lvl2","url":"/secant#convergence","position":2},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Convergence"},"content":"Graphically, a secant line usually looks like a less accurate model of f than the tangent line. How will that affect the convergence?\n\nAs before, let \\epsilon_k = x_k-r be the errors in the successive root approximations, and assume that r is a simple root. If the initial errors are small, then a tedious but straightforward Taylor expansion shows that, to lowest order,\\epsilon_{k+1} \\approx \\frac{1}{2}\\frac{f''(r)}{f'(r)} \\epsilon_k \\epsilon_{k-1}.\n\nIf we make an educated guess that\\epsilon_{k+1} = c (\\epsilon_k)^\\alpha, \\quad \\epsilon_k = c (\\epsilon_{k-1})^\\alpha, \\ldots, \\qquad \\alpha>0,\n\nthen \n\n(4.4.3) becomes\\left[ \\epsilon_{k-1}^{\\alpha} \\right]^{\\,\\alpha} \\approx C \\epsilon_{k-1}^{\\alpha+1}\n\nfor an unknown constant C. Treating the approximation as an equality, this becomes solvable if and only if the exponents match, i.e., \\alpha^2 = \\alpha+1. The only positive root of this equation is the golden ratio,  \\alpha = \\frac{1+\\sqrt{5}}{2} \\approx 1.618.\n\nHence the errors in the secant method converge like \\epsilon_{k+1} = c (\\epsilon_k)^\\alpha  for 1<\\alpha<2.\n\nSuperlinear convergence\n\nSuppose a sequence x_k approaches limit x^*. If the error sequence \\epsilon_k=x_k - x^* satisfies  \\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|^\\alpha} = L\n\nfor constants \\alpha >1 and L>0, then the sequence has superlinear convergence with rate α.\n\nQuadratic convergence is a particular case of superlinear convergence. Roughly speaking, we expect\\begin{align*}\n\n\\log |\\epsilon_{k+1}| & \\approx \\alpha (\\log |\\epsilon_k|) + \\log L, \\\\ \n\\frac{\\log |\\epsilon_{k+1}|}{\\log |\\epsilon_k|} & \\approx \\alpha + \\frac{\\log L}{\\log |\\epsilon_k|} \\to \\alpha,\n\\end{align*}\n\nas k\\to\\infty.\n\nConvergence of the secant method\n\nExample 4.4.2\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1. Again we will use extended precision to get a longer sequence than double precision allows.\n\nf(x) = x * exp(x) - 2\nx = FNC.secant(f, BigFloat(1), BigFloat(0.5), xtol=1e-80, ftol=1e-80);\n\nWe don’t know the exact root, so we use the last value as a proxy.\n\nr = x[end]\n\nHere is the sequence of errors.\n\nϵ = @. Float64(r - x[1:end-2])\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = @. log10(abs(ϵ))\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"error\", \"log error\", \"ratio\"] [eachindex(ϵ) ϵ logerr ratios]\n\nAs expected, this settles in at around 1.618.\n\nExample 4.4.2\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = @(x) x .* exp(x) - 2;\nx = secant(f, 1, 0.5);\n\nWe don’t know the exact root, so we use fzero to get a good proxy.\n\nr = fzero(f, 1);\n\nHere is the sequence of errors.\n\nformat short e\nerr = r - x(1:end-1)'\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)\n\nAs expected, this settles in at around 1.618.\n\nExample 4.4.2\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = lambda x: x * exp(x) - 2\nx = FNC.secant(f, 1, 0.5)\nprint(x)\n\nWe don’t know the exact root, so we use root_scalar to get a substitute.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.5, 1]).root\nprint(r)\n\nHere is the sequence of errors.\n\nerr = r - x\nprint(err)\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 2):\n    print(logerr[i+1] / logerr[i])\n\nAs expected, this settles in at around 1.618.\n\nIn terms of the error as a function of the iteration number k, the secant method converges at a rate strictly between linear and quadratic, which is slower than Newton’s method. But error versus iteration count may not be the best means of comparison.\n\nOften we analyze rootfinding methods by assuming that the bulk of computing time is spent evaluating the user-defined functions f and f'. (Our simple examples and exercises mostly don’t support this assumption, but many practical applications do.) In this light, we see that Newton’s method requires two evaluations, f(x_k) and f'(x_k), for each iteration. The secant method, on the other hand, while it uses the two function values f(x_k) and f(x_{k-1}) at each iteration, only needs to compute a single new one. Note that \n\nFunction 4.4.2 keeps track of one previous function value rather than recomputing it.\n\nNow suppose that |\\epsilon_k|=\\delta. Roughly speaking, two units of work (i.e., function evaluations) in Newton’s method brings us to an error of \\delta^2. If one spreads out the improvement in the error evenly across the two steps, using\\delta^2 = \\bigl( \\delta^{\\sqrt{2}} \\bigr)^{\\!\\sqrt{2}},\n\nit seems reasonable to say that the rate of convergence in Newton per function evaluation is \\sqrt{2}\\approx 1.41. This is actually less than the comparable rate of about 1.62 for the secant method.\n\nIf function evaluations are used to measure computational work, the secant iteration converges more rapidly than Newton’s method.\n\nNot only is the secant method easier to apply than Newton’s method in practice, it’s also more efficient—a rare win-win!","type":"content","url":"/secant#convergence","position":3},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Inverse interpolation"},"type":"lvl2","url":"/secant#inverse-interpolation","position":4},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Inverse interpolation"},"content":"At each iteration, the secant method constructs a linear model function that interpolates the two most recently found points on the graph of f. Two points determine a straight line, so this seems like a sensible choice. But as the iteration progresses, why use only the two most recent points? What would it mean to use more of them?\n\nIf we interpolate through three points by a polynomial, we get a unique quadratic function. Unfortunately, a parabola may have zero, one, or two crossings of the x-axis, potentially leaving some doubt as to how to define the next root estimate. On the other hand, if we turn a parabola on its side, we get a graph that intersects the x-axis exactly once, which is ideal for defining the next root estimate.\n\nThis leads to the idea of defining q(y) as the quadratic interpolant to the points (y_{k-2},x_{k-2}), (y_{k-1},x_{k-1}), and (y_k,x_k), where y_i=f(x_i) for all i, and setting x_{k+1}=q(0). The process defined in this way (given three initial estimates) is called inverse quadratic interpolation. Rather than deriving lengthy formulas for it here, we demonstrate how to perform inverse quadratic interpolation using fit to perform the interpolation step.\n\nInverse quadratic interpolation\n\nExample 4.4.3\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf(x) = x + cos(10 * x)\ninterval = [0.5, 1.5]\n\nplot(f, interval..., label=\"Function\", legend=:bottomright,\n    grid=:y, ylim=[-0.1, 3], xlabel=L\"x\", ylabel=L\"y\")\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]\ny = @. f(x)\nscatter!(x, y, label=\"initial points\")\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nusing Polynomials\nq = Polynomials.fit(x, y, 2)      # interpolating polynomial\nplot!(x -> q(x), interval..., l=:dash, label=\"interpolant\")\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nTip\n\nBy giving two functions in the plot call, we get the parametric plot (q(y),y) as a function of y.\n\nplot(f, interval..., label=\"Function\",\n    legend=:bottomright, grid=:y, xlabel=L\"x\", ylabel=L\"y\")\nscatter!(x, y, label=\"initial points\")\n\nq = Polynomials.fit(y, x, 2)       # interpolating polynomial\nplot!(y -> q(y), y -> y, -0.1, 2.6, l=:dash, label=\"inverse interpolant\")\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nq(0)\n\nLet’s restart the process with BigFloat numbers to get a convergent sequence.\n\nx = BigFloat.([8, 12, 10]) / 10\ny = @. f(x)\n\nfor k = 3:12\n    q = Polynomials.fit(y[k-2:k], x[k-2:k], 2)\n    push!(x, q(0))\n    push!(y, f(x[k+1]))\nend\n\nprintln(\"residual = $(f(x[end]))\")\n\nAs far as our current precision is concerned, we have an exact root.\n\nr = x[end]\nϵ = @. Float64(abs(r - x[1:end-1]))\nlogerr = @. log10(abs(ϵ))\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"error\", \"log error\", \"ratio\"] [eachindex(ϵ) ϵ logerr ratios]\n\nThe convergence is probably superlinear at a rate of \\alpha=1.8 or so.\n\nExample 4.4.3\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = @(x) x + cos(10 * x);\ninterval = [0.5, 1.5];\nclf, fplot(f, interval)\nset(gca, 'ygrid', 'on'), axis(axis)   \ntitle('Objective function')    \nxlabel('x'), ylabel('y')    \nr = fzero(f, 1)\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]';\ny = f(x);\nhold on, scatter(x, y)\ntitle('Three initial points')\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nc = polyfit(x, y, 2);    % coefficients of interpolant\nq = @(x) polyval(c, x);\nfplot(q, interval, '--')\ntitle('Parabola model')\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nTip\n\nBy giving two functions in the fplot call, we get the parametric plot (q(y),y) as a function of y.\n\ncla, fplot(f, interval)\nscatter(x, y)     \nc = polyfit(y, x, 2);    % coefficients of interpolating polynomial\nq = @(y) polyval(c, y);\nfplot(q, @(y) y, ylim,'--')    % plot x=q(y), y=y\ntitle('Sideways parabola')\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = [x; q(0)];\ny = [y; f(x(end))]\n\nWe repeat the process a few more times.\n\nfor k = 4:8\n    c = polyfit(y(k-2:k), x(k-2:k), 2);\n    x(k+1) = polyval(c, 0);\n    y(k+1) = f(x(k+1));\nend\ndisp('final residual:')\ny(end)\n\nHere is the sequence of errors.\n\nformat short e\nerr = x - r\n\nThe convergence is probably superlinear:\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)\n\nExample 4.4.3\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = lambda x: x + cos(10 * x)\nxx = linspace(0.5, 1.5, 400)\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$y$\")\nfig\n\nWe choose three values to get the iteration started.\n\nx = array([0.8, 1.2, 1])\ny = f(x)\nax.plot(x, y, \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nq = poly1d(polyfit(x, y, 2))  # interpolating polynomial\nax.plot(xx, q(xx), \"--\", label=\"interpolant\")\nax.set_ylim(-0.1, 3), ax.legend()\nfig\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nplot(xx, f(xx), label=\"function\")\nplot(x, y, \"ko\", label=\"initial points\")\n\nq = poly1d(polyfit(y, x, 2))  # inverse interpolating polynomial\nyy = linspace(-0.1, 2.6, 400)\nplot(q(yy), yy, \"--\", label=\"inverse interpolant\")\n\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\nlegend();\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = hstack([x, q(0)])\ny = hstack([y, f(x[-1])])\nprint(\"x:\", x, \"\\ny:\", y)\n\nWe repeat the process a few more times.\n\nfor k in range(6):\n    q = poly1d(polyfit(y[-3:], x[-3:], 2))\n    x = hstack([x, q(0)])\n    y = hstack([y, f(x[-1])])\nprint(f\"final residual is {y[-1]:.2e}\")\n\nHere is the sequence of errors.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.9, 1]).root\nerr = x - r\nprint(err)\n\nThe error seems to be superlinear, but subquadratic:\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])","type":"content","url":"/secant#inverse-interpolation","position":5},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Bracketing"},"type":"lvl2","url":"/secant#bracketing","position":6},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Bracketing"},"content":"Like Newton’s method, the secant and inverse quadratic interpolation methods cannot guarantee convergence. One final new idea is needed to make a (nearly) foolproof algorithm.\n\nIf f is continuous on the interval [a,b] and f(a)f(b)<0—that is, f changes sign on the interval—then f must have at least one root in the interval, due to the Intermediate Value Theorem from calculus. If we come up with a new root estimate c\\in(a,b), then whatever sign f(c) is, it is different from the sign at one of the endpoints. (Of course, if f(c) is zero, we are done!) So either [a,c] or [c,b] is guaranteed to have a root too, and in this way we can maintain not just individual estimates but an interval that always contains a root.\n\nThe best algorithms blend the use of fast-converging methods with the guarantee provided by a bracket. For example, say that an iteration begins with a bracketing interval. Make a list of the inverse quadratic estimate, the secant estimate, and the midpoint of the current interval, and pick the first member of the list that lies within the current interval. Replace the interval with the bracketing subinterval, and start a new iteration. This is the idea behind Brent’s method, which is a very successful rootfinding algorithm.","type":"content","url":"/secant#bracketing","position":7},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Exercises"},"type":"lvl2","url":"/secant#exercises","position":8},{"hierarchy":{"lvl1":"Interpolation-based methods","lvl2":"Exercises"},"content":"For each of Exercises 1–3, do the following steps.\n\n(a) ✍ Rewrite the equation into the standard form for rootfinding, f(x) = 0.\n\n(b) ⌨ Make a plot of f over the given interval and determine how many roots lie in the interval.\n\n(c) ⌨ Use nlsolve with ftol=1e-15 to find a reference value for each root.\n\n(d) ⌨ Determine a bracketing interval for each root. Then use \n\nFunction 4.4.2, starting with the endpoints of the bracketing interval, to find each root.\n\n(e) ⌨ For one of the roots, use the errors in the Newton sequence to determine numerically whether the convergence is apparently between linear and quadratic.\n\nx^2=e^{-x}, over [-2,2]\n\n2x = \\tan x, over [-0.2,1.4]\n\ne^{x+1}=2+x, over [-2,2]\n\n⌨ Use a plot to approximately locate all the roots of f(x)=x^{-2}-\\sin(x) in the interval [0.5,10]. Then find a pair of initial points for each root such that \n\nFunction 4.4.2 converges to that root.\n\n✍ Show analytically that the secant method converges in one step for a linear function, regardless of the initialization.\n\n✍ In general, the secant method formula \n\n(4.4.2) cannot be applied if x_{k}=x_{k-1}. However, suppose that f(x)=ax^2+bx+c for constants a, b, and c. Show that in this case the formula can be simplified to one that is well defined when x_{k}=x_{k-1}. Then show that the resulting x_{k+1} is the same as the result of one step of Newton’s method applied to f at x_k.\n\n✍ Let f(x)=x^2. Show that if (1/x_1) and (1/x_2) are positive integers, and the secant iteration is applied, then the sequence 1/x_1,1/x_2,1/x_3,\\ldots is a Fibonacci sequence, i.e., satisfying x_{k+1}=x_k+x_{k-1}.\n\n✍ Provide the details that show how to derive \n\n(4.4.3) from \n\n(4.4.2).\n\n⌨ Write a function iqi(f,x₁,x₂,x₃) that performs inverse quadratic interpolation for finding a root of f, given three initial estimates. To find the quadratic polynomial q(y) passing through the three most recent points, use fit. Test your function on the function in Exercise 1 from this section.","type":"content","url":"/secant#exercises","position":9},{"hierarchy":{"lvl1":"Adaptive integration"},"type":"lvl1","url":"/adaptive","position":0},{"hierarchy":{"lvl1":"Adaptive integration"},"content":"To this point, we have used only equally spaced nodes to compute integrals. Yet there are problems in which non-uniformly distributed nodes would clearly be more appropriate, as demonstrated in \n\nDemo 5.7.1.\n\nMotivation for adaptive integration\n\nExample 5.7.1\n\nThis function gets increasingly oscillatory as x increases.\n\nusing Plots\nf = x -> (x + 1)^2 * cos((2x + 1) / (x - 4.3))\nplot(f, 0, 4, xlabel=L\"x\", ylabel=L\"f(x)\")\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nusing QuadGK\nleft_val, _ = quadgk(f, 0, 2, atol=1e-14, rtol=1e-14)\nright_val, _ = quadgk(f, 2, 4, atol=1e-14, rtol=1e-14)\n\nn = [50 * 2^k for k in 0:3]\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n    T, _ = FNC.trapezoid(f, 0, 2, n)\n    err[k, 1] = T - left_val\n\n    T, _ = FNC.trapezoid(f, 2, 4, n)\n    err[k, 2] = T - right_val\nend\n\n@pt :header=[\"n\", \"left error\", \"right error\"] [n err]\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nExample 5.7.1\n\nThis function gets increasingly oscillatory as x increases.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\nclf\nfplot(f, [0, 4], 2000)\nxlabel('x'), ylabel(('f(x)'));\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nleft_val = integral(f, 0, 2, abstol=1e-14, reltol=1e-14);\nright_val = integral(f, 2, 4, abstol=1e-14, reltol=1e-14);\n\nn = round(50 * 2 .^ (0:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    T = trapezoid(f, 0, 2, n(i));\n    err(i, 1) = T - left_val;\n    T = trapezoid(f, 2, 4, n(i));\n    err(i, 2) = T - right_val;\nend\ntable(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"left error\", \"right error\"])\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nExample 5.7.1\n\nThis function gets increasingly oscillatory as x increases.\n\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nx = linspace(0, 4, 600)\nplot(x, f(x))\nxlabel(\"$x$\")\nylabel(\"$f(x)$\");\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nn_ = 50 * 2 ** arange(4)\nTleft = zeros(4)\nTright = zeros(4)\nfor i, n in enumerate(n_):\n    Tleft[i] = FNC.trapezoid(f, 0, 2, n)[0]\n    Tright[i] = FNC.trapezoid(f, 2, 4, n)[0]\nprint(\"left half:\", Tleft)\nprint(\"right half:\", Tright)\n\nfrom scipy.integrate import quad\nleft_val, err = quad(f, 0, 2, epsabs=1e-13, epsrel=1e-13)\nright_val, err = quad(f, 2, 4, epsabs=1e-13, epsrel=1e-13)\n\nprint(\"    n     left error   right error\")\nfor k in range(n_.size):\n    print(f\"  {n_[k]:4}    {Tleft[k]-left_val:8.3e}    {Tright[k]-right_val:8.3e}\")\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nWe would like an algorithm that automatically detects and reacts to a situation like that in \n\nDemo 5.7.1, a trait known as adaptivity.","type":"content","url":"/adaptive","position":1},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Error estimation"},"type":"lvl2","url":"/adaptive#error-estimation","position":2},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Error estimation"},"content":"Ideally, we would like to make adaptation decisions based on the error of the integration result. Knowing the error exactly would be equivalent to knowing the exact answer, but we can estimate it using the extrapolation technique of \n\nNumerical integration. Consider the Simpson formula \n\n(5.6.15) resulting from one level of extrapolation from trapezoid estimates:  S_f(2n) = \\frac{1}{3} \\Bigl[ 4 T_f(2n) - T_f(n) \\Bigr].\n\nWe expect this method to be fourth-order accurate, i.e.,  \\int_a^b f(x)\\, dx = S_f(2n) + O(n^{-4}),\n\nWe can further extrapolate to sixth-order accuracy using \n\n(5.6.17):  R_f(4n) = \\frac{1}{15} \\Bigl[ 16 S_f(4n) - S_f(2n) \\Bigr].\n\nBy virtue of higher order of accuracy, R_f(4n) should be more accurate than S_f(4n). Hence, a decent estimate of the error in the better of the two Simpson values is  E = R_f(4n) - S_f(4n) = \\frac{S_f(4n) - S_f(2n)}{15}.","type":"content","url":"/adaptive#error-estimation","position":3},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Divide and conquer"},"type":"lvl2","url":"/adaptive#divide-and-conquer","position":4},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Divide and conquer"},"content":"If |E| is judged to be acceptably small, we are done. This judgment takes some care. For instance, suppose the exact integral is \n\n1020.  Requiring |E| < \\delta\\ll 1 would be fruitless in double precision, since it would require more than 20 accurate digits. Hence checking the absolute size of the error alone is not appropriate. Conversely, consider the integral  \\int_{10^{-6}}^{2\\pi} 2 \\sin x\\, dx \\approx -10^{-12}.\n\nWe are likely to sample values of the integrand that are larger than, say, 1/2 in absolute value, so obtaining this very small result has to rely on subtractive cancellation. We cannot hope for more than 4-5 accurate digits, so a strict test of the relative error is also not recommended. In other words, we can seek an error that is small relative to the data (the integrand), which is O(1), but not relative to the answer itself.\n\nTypically, we use both relative and absolute error, stopping when either one is considered small enough. Algebraically, the test is  |E| < \\delta_a + \\delta_r |S_f(n)|,\n\nwhere \\delta_a and \\delta_r are given absolute and relative error tolerances, respectively.\n\nWhen |E| fails to meet \n\n(5.7.6), we bisect the interval [a,b] to exploit the identity  \\int_a^b f(x)\\, dx = \\int_a^{(a+b)/2} f(x)\\, dx + \\int_{(a+b)/2}^b f(x)\\, dx,\n\nand independently compute estimates to each of the half-length integrals. Each of these half-sized computations recursively applies Simpson’s formula and the error estimation criterion, making further bisections as necessary. Such an approach is called divide and conquer in computer science: recursively split the problem into easier pieces and glue the results together.","type":"content","url":"/adaptive#divide-and-conquer","position":5},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Implementation"},"type":"lvl2","url":"/adaptive#implementation","position":6},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Implementation"},"content":"It is typical to use just the minimal formula S_f(4) and its error estimate E to make decisions about adaptivity. A computation of S_f(4) requires three trapezoid estimates T_f(1), T_f(2), and T_f(4). As observed in \n\n(5.6.18) and \n\nDemo 5.6.3, the five integrand evaluations in T_f(4) are sufficient to compute all of these values.\n\nFunction 5.7.1 shows an implementation. It uses five function values to compute three trapezoid estimates with n=1, n=2, and n=4, applying the updating formula \n\n(5.6.18) twice. It goes on to find the two Simpson approximations and to estimate the error by \n\n(5.7.4).\n\nIf the error estimate passes the test \n\n(5.7.6), the better Simpson value is returned as the integral over the given interval. Otherwise, the interval is bisected, integrals over the two pieces are computed using recursive calls, and those results are added to give the complete integral.\n\nintadapt\n\nAdaptive integration\n\n\"\"\"\n    intadapt(f, a, b, tol)\n\nAdaptively integrate `f` over [`a`,`b`] to within target error\ntolerance `tol`. Returns the estimate and a vector of evaluation\nnodes.\n\"\"\"\nfunction intadapt(f, a, b, tol, fa = f(a), fb = f(b), m = (a + b) / 2, fm = f(m))\n    # Use error estimation and recursive bisection.\n    # These are the two new nodes and their f-values.\n    xl = (a + m) / 2\n    fl = f(xl)\n    xr = (m + b) / 2\n    fr = f(xr)\n\n    # Compute the trapezoid values iteratively.\n    h = (b - a)\n    T = [0.0, 0.0, 0.0]\n    T[1] = h * (fa + fb) / 2\n    T[2] = T[1] / 2 + (h / 2) * fm\n    T[3] = T[2] / 2 + (h / 4) * (fl + fr)\n\n    S = (4T[2:3] - T[1:2]) / 3      # Simpson values\n    E = (S[2] - S[1]) / 15           # error estimate\n\n    if abs(E) < tol * (1 + abs(S[2]))  # acceptable error?\n        Q = S[2]                   # yes--done\n        nodes = [a, xl, m, xr, b]      # all nodes at this level\n    else\n        # Error is too large--bisect and recurse.\n        QL, tL = intadapt(f, a, m, tol, fa, fm, xl, fl)\n        QR, tR = intadapt(f, m, b, tol, fm, fb, xr, fr)\n        Q = QL + QR\n        nodes = [tL; tR[2:end]]   # merge the nodes w/o duplicate\n    end\n    return Q, nodes\nend\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.\n\nAdaptive integration\n\nfunction [Q,t] = intadapt(f,a,b,tol)\n%INTADAPT   Adaptive integration with error estimation.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   tol   acceptable error\n% Output:\n%   Q     approximation to integral(f,a,b)\n%   t     vector of nodes used\n\nm = (b+a)/2;\n[Q,t] = do_integral(a,f(a),b,f(b),m,f(m),tol);\n\n    % Use error estimation and recursive bisection. \n    function [Q,t] = do_integral(a,fa,b,fb,m,fm,tol)\n        \n        % These are the two new nodes and their f-values.\n        xl = (a+m)/2;  fl = f(xl);\n        xr = (m+b)/2;  fr = f(xr);\n        t = [a;xl;m;xr;b];              % all 5 nodes at this level\n\n        % Compute the trapezoid values iteratively. \n        h = (b-a);\n        T(1) = h*(fa+fb)/2;\n        T(2) = T(1)/2 + (h/2)*fm;\n        T(3) = T(2)/2 + (h/4)*(fl+fr);\n        \n        S = (4*T(2:3)-T(1:2)) / 3;      % Simpson values\n        E = (S(2)-S(1)) / 15;           % error estimate\n                \n        if abs(E) < tol*(1+abs(S(2)))   % acceptable error?\n            Q = S(2);                   % yes--done\n        else\n            % Error is too large--bisect and recurse. \n            [QL,tL] = do_integral(a,fa,m,fm,xl,fl,tol);\n            [QR,tR] = do_integral(m,fm,b,fb,xr,fr,tol);\n            Q = QL + QR;\n            t = [tL;tR(2:end)];         % merge the nodes w/o duplicate\n        end        \n    end\n\nend  % main function\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.\n\nAdaptive integration\n\ndef intadapt(f, a, b, tol):\n    \"\"\"\n    intadapt(f, a, b, tol)\n\n    Do adaptive integration to estimate the integral of f over [a,b] to desired\n    error tolerance tol. Returns estimate and a vector of evaluation nodes used.\n    \"\"\"\n\n    # Use error estimation and recursive bisection.\n    def do_integral(a, fa, b, fb, m, fm, tol):\n        # These are the two new nodes and their f-values.\n        xl = (a + m) / 2\n        fl = f(xl)\n        xr = (m + b) / 2\n        fr = f(xr)\n        t = np.array([a, xl, m, xr, b])  # all 5 nodes at this level\n\n        # Compute the trapezoid values iteratively.\n        h = b - a\n        T = np.zeros(3)\n        T[0] = h * (fa + fb) / 2\n        T[1] = T[0] / 2 + (h / 2) * fm\n        T[2] = T[1] / 2 + (h / 4) * (fl + fr)\n\n        S = (4 * T[1:] - T[:-1]) / 3  # Simpson values\n        E = (S[1] - S[0]) / 15  # error estimate\n\n        if abs(E) < tol * (1 + abs(S[1])):  # acceptable error?\n            Q = S[1]  # yes--done\n        else:\n            # Error is too large--bisect and recurse.\n            QL, tL = do_integral(a, fa, m, fm, xl, fl, tol)\n            QR, tR = do_integral(m, fm, b, fb, xr, fr, tol)\n            Q = QL + QR\n            t = np.hstack([tL, tR[1:]])  # merge the nodes w/o duplicate\n        return Q, t\n\n    m = (b + a) / 2\n    Q, t = do_integral(a, f(a), b, f(b), m, f(m), tol)\n    return Q, t\n\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.\n\nUsing adaptive integration\n\nExample 5.7.2\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = x -> (x + 1)^2 * cos((2x + 1) / (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nA, t = FNC.intadapt(f, 0, 4, 0.001)\n@show num_nodes = length(t);\n\nplot(f, 0, 4;\n    color=:black, legend=:none,\n    xlabel=L\"x\",  ylabel=L\"f(x)\", \n    title=\"Adaptive node selection\")\nplot!(t, f.(t), seriestype=:sticks, m=(:o, 2))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nQ, _ = quadgk(f, 0, 4, atol=1e-14, rtol=1e-14);    # 'exact' value\nprintln(\"error: $(Q-A)\");\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = [1 / 10^k for k in 4:14]\nerr, n = [], []\nfor tol in 10.0 .^ (-4:-1:-14)\n    A, t = FNC.intadapt(f, 0, 4, tol)\n    push!(err, Q - A)\n    push!(n, length(t))\nend\n@pt :header=[\"tolerance\", \"error\", \"number of nodes\"] [tol err n][1:2:end, :]\n\nAs you can see, even though the errors are not smaller than the tolerances, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nplot(n, abs.(err);\n    m=:o, label=\"results\",\n    xaxis=(:log10, \"number of nodes\"),  yaxis=(:log10, \"error\"),\n    title=\"Convergence of adaptive integration\")\n\norder4 = @. 0.01 * (n / n[1])^(-4)\nplot!(n, order4, l=:dash, label=L\"O(n^{-4})\")\n\nExample 5.7.2\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\n[Q, t] = intadapt(f, 0, 4, 0.001);\nclf, fplot(f, [0, 4], 2000)\nhold on\nstem(t, f(t), '.-')\ntitle('Adaptive node selection')\nxlabel('x'), ylabel('f(x)')\nfprintf(\"number of nodes = %d\", length(t))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nI = integral(f, 0, 4, abstol=1e-14, reltol=1e-14);    % 'exact' value\nfprintf(\"error = %.2e\", abs(Q - I))\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = 1 ./ 10.^(4:14)';\nerr = zeros(size(tol));\nn = zeros(size(tol));\nfor k = 1:length(tol)\n    [A, t] = intadapt(f, 0, 4, tol(k));\n    err(k) =  I - A;\n    n(k) = length(t);\nend\ntable(tol, err, n, variableNames=[\"tolerance\", \"error\", \"number of nodes\"])\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"results\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\ntitle(\"Convergence of adaptive integration\")\norder4 = 0.1 * abs(err(end)) * (n / n(end)).^(-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nlegend();\n\nExample 5.7.2\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nfrom scipy.integrate import quad\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nI, errest = quad(f, 0, 4, epsabs=1e-12, epsrel=1e-12)\nprint(\"integral:\", I)    # 'exact' value\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nQ, t = FNC.intadapt(f, 0, 4, 0.001)\nprint(\"number of nodes:\", t.size)\n\nx = linspace(0, 4, 600)\nplot(x, f(x), \"k\")\nstem(t, f(t))\nxlabel(\"$x$\"); ylabel(\"$f(x)$\");\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nprint(\"error:\", I - Q)\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol_ = 10.0 ** arange(-4, -12, -1)\nerr_ = zeros(tol_.size)\nnum_ = zeros(tol_.size, dtype=int)\nprint(\"    tol         error     # f-evals\")\nfor i, tol in enumerate(tol_):\n    Q, t = FNC.intadapt(f, 0, 4, tol)\n    err_[i] = I - Q\n    num_[i] = t.size\n    print(f\"  {tol:6.1e}    {err_[i]:10.3e}    {num_[i]:6d}\")\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nloglog(num_, abs(err_), \"-o\", label=\"results\")\norder4 = 0.01 * (num_ / num_[0]) ** (-4)\nloglog(num_, order4, \"--\", label=\"$O(n^{-4})$\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\nlegend()\ntitle(\"Convergence of adaptive quadrature\");\n\nAlthough adaptivity and the error estimation that goes with it can be very powerful, they come at some cost. The error estimation cannot be universally perfect, so sometimes the answer will not be as accurate as requested, and sometimes the function will be evaluated more times than necessary. Subtle problems may arise when the integral is a step within a larger computation (see \n\nExercise 6).","type":"content","url":"/adaptive#implementation","position":7},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Exercises"},"type":"lvl2","url":"/adaptive#exercises","position":8},{"hierarchy":{"lvl1":"Adaptive integration","lvl2":"Exercises"},"content":"must be kept as #1\n\n⌨ For each integral below, use \n\nFunction 5.7.1 with error tolerance 10^{-2},10^{-3},\\ldots,10^{-12}. Make a table of errors and the number of integrand evaluation nodes used, and use a convergence plot as in \n\nDemo 5.7.2 to compare to fourth-order accuracy. (These integrals were taken from \n\nBailey et al. (2005).)\n\n(a) \\displaystyle \\int_0^1 x\\log(1+x)\\, dx = \\frac{1}{4}\n\n(b) \\displaystyle \\int_0^1 x^2 \\tan^{-1}x\\, dx = \\frac{\\pi-2+2\\log 2}{12}\n\n(c) \\displaystyle \\int_0^{\\pi/2}e^x \\cos x\\, dx = \\frac{e^{\\pi/2}-1}{2}\n\n(d) \\displaystyle \\int_{0}^1 \\sqrt{x} \\log(x) \\, dx = -\\frac{4}{9} (Note: Although the integrand has the limiting value zero as x\\to 0, you have to implement the function carefully to return zero as the value of f(0), or start the integral at x=\\macheps.)\n\n(e) \\displaystyle \\int_0^1 \\sqrt{1-x^2}\\, dx = \\frac{\\pi}{4}\n\n⌨ For each integral below: (i) use quadgk to find the value to at least 12 digits; (ii) use \n\nFunction 5.7.1 to evaluate the integral to a tolerance of \n\n10-8; (iii) compute the absolute error and the number of nodes used; (iv) use the O(h^2) term in the Euler–Maclaurin formula \n\n(5.6.9) to estimate how many nodes are required by the fixed-stepsize trapezoidal formula to reach an absolute error of \n\n10-8.\n\n(a) \\displaystyle \\int_{0.1}^3 \\operatorname{sech}(\\sin(1/x))\\, d x\n\n(b) \\rule[2em]{0pt}{0pt} \\displaystyle\\int_{-0.9}^9 \\ln((x+1)^3))\\, d x\n\n(c) \\rule[2em]{0pt}{0pt} \\displaystyle\\int_{-\\pi}^\\pi \\cos(x^3)\\, d x\n\n⌨ An integral such as \\displaystyle \\int_0^1 x^{-\\gamma}\\, dx for \\gamma>0, in which the integrand blows up at one or both ends, is known as an improper integral. It has a finite value if \\gamma<1, despite the singularity. One way to deal with the problem of the infinite value for f(t_0) is to replace the lower limit with a small number ε. (A more robust way to handle improper integrals is discussed in Chapter 9.)\n\nUsing \n\nFunction 5.7.1 with a small tolerance, make a log-log plot of the error as a function of ε when \\gamma=2/3, for \\epsilon=10^{-15},10^{-16},\\ldots,10^{-45}.\n\n⌨ A curious consequence of our logic in \n\nFunction 5.7.1 is that the algorithm uses what we believe to be a more accurate, sixth-order answer only for estimating error; the returned value is the supposedly less accurate S_f(2n). The practice of returning the extrapolated R_f(4n) instead is called local extrapolation.\n\nModify \n\nFunction 5.7.1 to use local extrapolation and repeat parts (a) and (e) of Exercise 1 above, comparing the observed convergence to both fourth order and sixth order.\n\n⌨ The sine integral function is defined by\\operatorname{Si}(x) = \\int_0^x \\frac{\\sin z}{z}\\, dz.\n\nUse \n\nFunction 5.7.1 to plot Si over the interval [1,10]. Note: You will need to replace the lower bound of integration by \\macheps.\n\n⌨  Adaptive integration can have subtle drawbacks. This exercise is based on the error function, a smooth function defined as\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-s^2}\\,ds.\n\n(a) Define a function g that approximates erf by applying \n\nFunction 5.6.1 with n=300. Make a plot of the error g(x)-\\operatorname{erf}(x) at 500 points in the interval [0,3].\n\n(b) Define another approximation h that applies \n\nFunction 5.7.1 with error tolerance \n\n10-7. Plot the error in h as in part (a). Why does it look so different from the previous case?\n\n(c) Suppose you wished to find x such that \\operatorname{erf}(x) = .95 by using rootfinding on one of your two approximations. Why is the version from part (a) preferable?","type":"content","url":"/adaptive#exercises","position":9},{"hierarchy":{"lvl1":"Convergence of finite differences"},"type":"lvl1","url":"/fd-converge","position":0},{"hierarchy":{"lvl1":"Convergence of finite differences"},"content":"All of the finite-difference formulas in the previous section based on equally spaced nodes converge as the node spacing h decreases to zero. However, note that to discretize a function over an interval [a,b], we use h=(b-a)/n, which implies n=(b-a)/h=O(h^{-1}). As h\\to 0, the total number of nodes needed grows without bound. So we would like to make h as large as possible while still achieving some acceptable accuracy.\n\nTruncation error of a finite-difference formula\n\nFor the finite-difference method \n\n(5.4.1) with weights a_{-p},\\ldots,a_{q}, the truncation error is\\tau_f(h) = f'(0) - \\frac{1}{h} \\sum_{k=-p}^{q} a_k f(kh).\n\nThe method is said to be convergent if \\tau_f(h)\\to 0 as h\\to 0.\n\nAlthough we are measuring the truncation error only at x=0, it could be defined for other x as well. The definition adjusts naturally to use f''(0) for difference formulas targeting the second derivative.\n\nAll of the finite-difference formulas given in \n\nFinite differences are convergent.\n\nThe forward difference formula \n\n(5.4.2) given by (f(h)-f(0))/h yields\\begin{split}\n\\tau_f(h) &= f'(0) - \\frac{ f(h)-f(0)}{h} \\\\\n&=f'(0) - h^{-1} \\left[ \\bigl( f(0) + h f'(0) + \\tfrac{1}{2}h^2f''(0)+ \\cdots \\bigr) - f(0) \\right] \\\\\n& = -\\frac{1}{2}h f''(0) + O(h^2).\n\\end{split}\n\nThe primary conclusion is that the truncation error is O(h) as h\\to 0.","type":"content","url":"/fd-converge","position":1},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Order of accuracy"},"type":"lvl2","url":"/fd-converge#order-of-accuracy","position":2},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Order of accuracy"},"content":"Of major interest is the rate at which \\tau_f\\to 0 in a convergent formula.\n\nOrder of accuracy of a finite-difference formula\n\nIf the truncation error of a finite-difference formula satisfies \\tau_f(h)=O(h^m) for a positive integer m, then m is the order of accuracy of the formula.\n\nHence the forward-difference formula in \n\nExample 5.5.1 has order of accuracy equal to 1; i.e., it is first-order accurate. All else being equal, a higher order of accuracy is preferred, since O(h^m) vanishes more quickly for larger values of m. As a rule, including more function values in a finite-difference formula (i.e., increasing the number of weights in \n\n(5.4.1)) increases the order of accuracy, as can be seen in \n\nTable 5.4.1 and \n\nTable 5.4.2.\n\nOrder of accuracy is calculated by expanding \\tau_f in a Taylor series about h=0 and ignoring all but the leading term.\n\nWe compute the truncation error of the centered difference formula \n\n(5.4.8):\\begin{split}\n  \\tau_f(h) &= f'(0) - \\frac{ f(h)-f(-h)}{2h}\\\\\n  &= f'(0) - (2h)^{-1} \\left[ \\bigl( f(0) + h f'(0) + \\tfrac{1}{2}h^2f''(0)+ \\tfrac{1}{6}h^3f'''(0)+ O(h^4) \\bigr) \\right.\\\\\n  &\\qquad - \\left.  \\bigl( f(0) - h f'(0) + \\tfrac{1}{2}h^2f''(0) - \\tfrac{1}{6}h^3f'''(0)+O(h^4) \\bigr) \\right] \\\\\n  &= -(2h)^{-1} \\left[ \\tfrac{1}{3}h^3f'''(0) + O(h^4) \\right] = O(h^2).\n\\end{split}\n\nThus, this method has order of accuracy equal to 2.\n\nConvergence of finite differences\n\nExample 5.5.3\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = x -> sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = [5 / 10^n for n in 1:6]\nFD = zeros(length(h), 2)\nfor (k, h) in enumerate(h)\n    FD[k, 1] = (f(h) - f(0)) / h\n    FD[k, 2] = (f(h) - f(-h)) / 2h\nend\n@pt :header=[\"h\", \"FD1\", \"FD2\"] [h FD]\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerror_FD = @. exact_value - FD\n@pt :header=[\"h\", \"error in FD1\", \"error in FD2\"] [h error_FD]\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nusing Plots\nplot(h, abs.(error_FD); \n    m=:o,  label=[\"FD1\" \"FD2\"], leg=:bottomleft,\n    xflip=true,  xaxis=(:log10, L\"h\"),  yaxis=(:log10, \"error\"),\n    title=\"Convergence of finite differences\")\n\n# Add lines for perfect 1st and 2nd order.\nplot!(h, [h h .^ 2], l=:dash, label=[L\"O(h)\" L\"O(h^2)\"])\n\nExample 5.5.3\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = @(x) sin(exp(x + 1));\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = 5 ./ 10.^(1:6)';\nFD1 = zeros(size(h));\nFD2 = zeros(size(h));\nfor i = 1:length(h)\n    h_i = h(i);\n    FD1(i) = (f(h_i) - f(0)    ) / h_i;\n    FD2(i) = (f(h_i) - f(-h_i)) / (2*h_i);\nend\ntable(h, FD1, FD2)\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerr1 = abs(exact_value - FD1);\nerr2 = abs(exact_value - FD2);\ntable(h, err1, err2, variableNames=[\"h\", \"error in FD1\", \"error in FD2\"])\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nclf\nloglog(h, abs([err1 err2]), \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err1(end) * (h / h(end)) .^ 1;\norder2 = 0.1 * err2(end) * (h / h(end)) .^ 2;\nhold on\nloglog(h, order1, \"--\", h, order2, \"--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"Convergence of finite differences\")\nlegend(\"FD1\", \"FD2\", \"O(h)\", \"O(h^2)\");\n\nExample 5.5.3\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = lambda x: sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh_ = array([5 / 10**(n+1) for n in range(6)])\nFD = zeros((len(h_), 2))\nfor (i, h) in enumerate(h_):\n    FD[i, 0] = (f(h) - f(0)) / h \n    FD[i, 1] = (f(h) - f(-h)) / (2*h)\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nprint(results)\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerrors = FD - exact_value\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"error in FD1\", errors[:, 0])\nresults.add_column(\"error in FD2\", errors[:, 1])\nprint(results)\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nplot(h_, abs(errors), \"o-\", label=[\"FD1\", \"FD2\"])\ngca().invert_xaxis()\n# Add lines for perfect 1st and 2nd order.\nloglog(h_, h_, \"--\", label=\"$O(h)$\")\nloglog(h_, h_**2, \"--\", label=\"$O(h^2)$\")\nxlabel(\"$h$\")\nylabel(\"error\")\nlegend();","type":"content","url":"/fd-converge#order-of-accuracy","position":3},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Stability"},"type":"lvl2","url":"/fd-converge#stability","position":4},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Stability"},"content":"The truncation error \\tau_f(h) of a finite-difference formula is dominated by a leading term O(h^m) for an integer m. This error decreases as h\\to 0. However, we have not yet accounted for the effects of roundoff error. To keep matters as simple as possible, let’s consider the forward difference\\delta(h) = \\frac{f(x+h)-f(x)}{h}.\n\nAs h\\to 0, the numerator approaches zero even though the values f(x+h) and f(x) are not necessarily near zero. This is the recipe for subtractive cancellation error! In fact, finite-difference formulas are inherently ill-conditioned as h\\to 0. To be precise, recall that the condition number for the problem of computing f(x+h)-f(x) is\\kappa(h) = \\frac{ \\max\\{\\,|f(x+h)|,|f(x)|\\,\\} }{ |f(x+h)-f(x) | },\n\nimplying a relative error of size \\kappa(h) \\epsilon_\\text{mach} in its computation. Hence the numerical value we actually compute for δ is\\begin{split}\n\\tilde{\\delta}(h) &= \\frac{f(x+h)-f(x)}{h}\\, (1+\\kappa(h)\\epsilon_\\text{mach}) \\\\\n&= \\delta(h) + \\frac{ \\max\\{\\,|f(x+h)|,|f(x)|\\,\\} }{ |f(x+h)-f(x) | }\\cdot \\frac{f(x+h)-f(x)}{h} \\cdot \\epsilon_\\text{mach}.\n\\end{split}\n\nHence as h\\to 0,\\bigl| \\tilde{\\delta}(h) - \\delta(h) \\bigr| = \\frac{ \\max\\{\\,|f(x+h)|,|f(x)|\\,\\} }{ h}\\,\\epsilon_\\text{mach} \\sim  |f(x)|\\, \\epsilon_\\text{mach}\\cdot h^{-1}.\n\nCombining the truncation error and the roundoff error leads to\\bigl|  f'(x) - \\tilde{\\delta}(h) \\bigr| \\le \\bigl| \\tau_f(h) \\bigr| + \\bigl|f(x) \\bigr|\\, \\epsilon_\\text{mach} \\, h^{-1}.\n\nEquation \n\n(5.5.8) indicates that while the truncation error τ vanishes as h decreases, the roundoff error actually increases thanks to the subtractive cancellation. At some value of h the two error contributions will be of roughly equal size. This occurs when\\bigl|f(x)\\bigr|\\, \\epsilon_\\text{mach}\\, h^{-1} \\approx C h, \\quad \\text{or} \\quad h \\approx K \\sqrt{\\rule[0.05em]{0mm}{0.4em}\\epsilon_\\text{mach}},\n\nfor a constant K that depends on x and f, but not h. In summary, for a first-order finite-difference method, the optimum spacing between nodes is proportional to \\epsilon_\\text{mach}^{\\,\\,1/2}. (This observation explains the choice of δ in \n\nFunction 4.6.1.)\n\nFor a method of truncation order m, the details of the subtractive cancellation are a bit different, but the conclusion generalizes.\n\nFor computing with a finite-difference method of order m in the presence of roundoff, the optimal spacing of nodes satisfiesh_\\text{opt} \\approx \\epsilon_\\text{mach}^{\\,\\,1/(m+1)},\n\nand the optimum total error is roughly \\epsilon_\\text{mach}^{\\,\\, m/(m+1)}.\n\nA different statement of the conclusion is that for a first-order formula, at most we can expect accuracy in only about half of the available machine digits. As m increases, we get ever closer to using the full accuracy available. Higher-order finite-difference methods are both more efficient and less vulnerable to roundoff than low-order methods.\n\nRoundoff error in finite differences\n\nExample 5.5.4\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = x -> exp(-1.3 * x);\nexact = -1.3\n\nh = [1 / 10^n for n in 1:12]\nFD = zeros(length(h), 3)\nfor (k, h) in enumerate(h)\n    nodes = h * (-2:2)\n    vals = @. f(nodes)\n    FD[k, 1] = dot([0 0 -1 1 0] / h, vals)\n    FD[k, 2] = dot([0 -1 / 2 0 1 / 2 0] / h, vals)\n    FD[k, 3] = dot([1 / 12 -2 / 3 0 2 / 3 -1 / 12] / h, vals)\nend\n@pt :header=[\"h\", \"FD1\", \"FD2\", \"FD4\"] [h FD]\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = @. abs(FD - exact)\n\nplot(h, err;\n    m=:o, label=[\"FD1\" \"FD2\" \"FD4\"],  legend=:bottomright,\n    xaxis=(:log10, L\"h\"),  xflip=true,  yaxis=(:log10, \"error\"),\n    title=\"FD error with roundoff\")\n\n# Add line for perfect 1st order.\nplot!(h, 0.1 * eps() ./ h, l=:dash, color=:black, label=L\"O(h^{-1})\")\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).\n\nExample 5.5.4\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = @(x) exp(-1.3 * x);\nexact = -1.3;\n\nh = 10 .^ (-(1:12))';\nFD = zeros(length(h), 3);\nfor i = 1:length(h)\n    h_i = h(i);\n    nodes = h_i * (-2:2);\n    vals = f(nodes);\n    FD(i, 1) = dot([0      0 -1   1    0] / h_i, vals);\n    FD(i, 2) = dot([0    -1/2 0 1/2    0] / h_i, vals);\n    FD(i, 3) = dot([1/12 -2/3 0 2/3 -1/12] / h_i, vals);\nend\nformat long\ntable(h, FD(:, 1), FD(:, 2), FD(:, 3), variableNames=[\"h\", \"FD1\", \"FD2\", \"FD4\"])\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = abs(FD - exact);\nclf\nloglog(h, err, \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err(end, 1) * (h / h(end)) .^ (-1);\nhold on\nloglog(h, order1, \"k--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"FD error with roundoff\")\nlegend(\"FD1\", \"FD2\", \"FD4\", \"O(1/h)\", \"location\", \"northeast\");\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).\n\nExample 5.5.4\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = lambda x: exp(-1.3 * x)\nexact = -1.3\n\nh_ = array([1 / 10**(n+1) for n in range(12)])\nFD = zeros((len(h_), 3))\nfor (i, h) in enumerate(h_):\n    nodes = h * linspace(-2, 2, 5)\n    vals = f(nodes)\n    FD[i, 0] = dot(array([0, 0, -1, 1, 0]) / h, vals)\n    FD[i, 1] = dot(array([0, -1/2, 0, 1/2, 0]) / h, vals)\n    FD[i, 2] = dot(array([1/12, -2/3, 0, 2/3, -1/12]) / h, vals)\n\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nresults.add_column(\"FD4\", FD[:, 2])\nprint(results)\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nloglog(h_, abs(FD[:, 0] + 1.3), \"-o\", label=\"FD1\")\nloglog(h_, abs(FD[:, 1] + 1.3), \"-o\", label=\"FD2\")\nloglog(h_, abs(FD[:, 2] + 1.3), \"-o\", label=\"FD4\")\ngca().invert_xaxis()\nplot(h_, 0.1 * 2 ** (-52) / h_, \"--\", color=\"k\", label=\"$O(h^{-1})$\")\nxlabel(\"$h$\")\nylabel(\"total error\")\ntitle(\"FD error with roundoff\")\nlegend();\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/fd-converge#stability","position":5},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Exercises"},"type":"lvl2","url":"/fd-converge#exercises","position":6},{"hierarchy":{"lvl1":"Convergence of finite differences","lvl2":"Exercises"},"content":"⌨ Evaluate the centered second-order finite-difference approximation to f'(4\\pi/5) for f(x)=\\cos(x^3) and h=2^{-1},2^{-2},\\ldots,2^{-8}. On a log-log graph, plot the error as a function of h and compare it graphically to second-order convergence.\n\n✍ Derive the first two nonzero terms of the Taylor series at h=0 of the truncation error \\tau_{f}(h) for the formula \n\n(5.4.3).\n\n✍ Calculate the first nonzero term in the Taylor series of the truncation error \\tau_{f}(h) for the finite-difference formula defined by the second row of \n\nTable 5.4.2.\n\n✍ Calculate the first nonzero term in the Taylor series of the truncation error \\tau_{f}(h) for the finite-difference formula defined by the third row of \n\nTable 5.4.2.\n\n✍ Show that the formula \n\n(5.4.12) is second-order accurate.\n\n✍  A different way to derive finite-difference formulas is the method of undetermined coefficients. Starting from \n\n(5.4.1),f'(x) \\approx \\frac{1}{h}\\sum_{k=-p}^q a_k f(x+kh),\n\nlet each f(x+k h) be expanded in a series around h=0. When the coefficients of powers of h are collected, one obtains\\frac{1}{h} \\sum_{k=-p}^q a_k f(x+kh) = \\frac{b_0}{h} + b_1 f'(x) + b_2 f''(x)h + \\cdots,\n\nwhereb_i = \\sum_{k=-p}^q k^i a_k.\n\nIn order to make the result as close as possible to f'(x), we impose the conditionsb_0 = 0,\\, b_1=1,\\, b_2=0,\\, b_3=0,\\,\\ldots,\\,b_{p+q}=0.\n\nThis provides a system of linear equations for the weights.\n\n(a) For p=q=2, write out the system of equations for a_{-2}, a_{-1}, a_0, a_1, a_2.\n\n(b) Verify that the coefficients from the appropriate row of \n\nTable 5.4.1 satisfy the equations you wrote down in part (a).\n\n(c) Derive the finite-difference formula for p=1, q=2 using the method of undetermined coefficients.\n\nThe term truncation error is derived from the idea that the finite-difference formula, being finite, has to truncate the series representation and thus cannot be exactly correct for all functions.","type":"content","url":"/fd-converge#exercises","position":7},{"hierarchy":{"lvl1":"Finite differences"},"type":"lvl1","url":"/finitediffs","position":0},{"hierarchy":{"lvl1":"Finite differences"},"content":"Now we turn to one of the most common and important applications of interpolants: finding derivatives of functions. Because differentiation is a linear operation, we will constrain ourselves to formulas that are linear in the nodal values.\n\nFinite-difference formula\n\nA finite-difference formula is a list of values a_{-p},\\ldots,a_q, called weights, such that for all f in some class of functions,  f'(x) \\approx \\frac{1}{h} \\sum_{k=-p}^{q} a_k f(x + kh).\n\nThe weights are independent of f and h. The formula is said to be convergent if the approximation becomes equality in the limit h\\to 0 for a suitable class of functions.\n\nNote that while \n\n(5.4.1) is about finding the derivative at a single point x, the same formula can be applied for different x. The usual situation is a regularly spaced grid of nodes, a,a+h,a+2h,\\ldots,b, and then the value of f at each node takes part in multiple applications of the formula. This will be demonstrated in \n\nExample 5.4.1 below.","type":"content","url":"/finitediffs","position":1},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Common examples"},"type":"lvl2","url":"/finitediffs#common-examples","position":2},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Common examples"},"content":"There are three appealing special cases of \n\n(5.4.1) that get special attention.\n\nForward, backward, and centered FD formulas\n\nA forward difference formula is characterized by \n\n(5.4.1) with p=0, a backward difference formula has q=0, and a centered difference formula has p=q.\n\nThe simplest example of a forward difference formula is inspired by the familiar limit definition of a derivative:  f'(x) \\approx \\frac{f(x+h)-f(x)}{h},\n\nwhich is \n\n(5.4.1) with p=0, q=1, a_0=-1, and a_1=1. Analogously, we have the backward difference  f'(x) \\approx \\frac{f(x)-f(x-h)}{h},\n\nin which p=1, q=0.\n\nSuppose f(x)=x^2, and we take h=\\frac{1}{4} over the interval [0,1]. This results in the nodes 0,\\frac{1}{4},\\frac{1}{2},\\frac{3}{4},1. We evaluate f at the nodes to getf(0) = 0, \\; f\\left(\\tfrac{1}{4}\\right) = \\frac{1}{16},\\; f\\left(\\tfrac{1}{2}\\right)=\\frac{1}{4},\\; f\\left(\\tfrac{3}{4}\\right)=\\frac{9}{16}, \\; f(1)=1.\n\nThis gives four forward difference estimates,\\begin{align*}\nf'(0) & \\approx 4\\left(\\frac{1}{16}-0\\right), &\\quad \nf'\\left(\\tfrac{1}{4}\\right)& \\approx 4\\left(\\frac{1}{4}-\\frac{1}{16}\\right), \\\\\nf'\\left(\\tfrac{1}{2}\\right)& \\approx 4\\left(\\frac{9}{16}-\\frac{1}{4}\\right), &\\quad \nf'\\left(\\tfrac{3}{4}\\right) &\\approx 4\\left(1-\\frac{9}{16}\\right).\n\\end{align*}\n\nWe also get four backward difference estimates,\\begin{align*}\nf'\\left(\\tfrac{1}{4}\\right) &\\approx 4\\left(\\frac{1}{16}-0\\right), &\\quad \nf'\\left(\\tfrac{1}{2}\\right) &\\approx 4\\left(\\frac{1}{4}-\\frac{1}{16}\\right), \\\\ \nf'\\left(\\tfrac{3}{4}\\right) &\\approx 4\\left(\\frac{9}{16}-\\frac{1}{4}\\right), &\\quad \nf'\\left(1\\right) &\\approx 4\\left(1-\\frac{9}{16}\\right).\n\\end{align*}\n\nNotice that it’s the same four differences each time, but we’re interpreting them as derivative estimates at different nodes.\n\nAs pointed out in \n\nExample 5.4.1, the only real distinction between \n\n(5.4.2) and \n\n(5.4.3) is whether we think that f' is being evaluated at the left node or the right one. Symmetry would suggest that we should evaluate it halfway between. That is the motivation behind centered difference formulas.\n\nLet’s derive the shortest centered formula using p=q=1. For simplicity, we will set x=0 without affecting the result. This means that f(-h), f(0), and f(h) are all available in \n\n(5.4.1).\n\nNote that \n\n(5.4.2) is simply the slope of the line through the points \\bigl(0,f(0)\\bigr) and \\bigl(h,f(h)\\bigr). One route to using all three function values is to differentiate the quadratic polynomial that interpolates \\bigl(-h,f(-h)\\bigr) as well (see \n\nExercise 1):Q(x) = \\frac{x(x-h)}{2h^2} f(-h) - \\frac{x^2-h^2}{h^2} f(0) + \\frac{x(x+h)}{2h^2} f(h).\n\nThis leads tof'(0) \\approx Q'(0) = \\frac{f(h)-f(-h)}{2h}.\n\nThis result is equivalent to \n\n(5.4.1) with p=q=1 and weights a_{-1}=-\\frac{1}{2}, a_0=0, and a_1=\\frac{1}{2}. Observe that while the value of f(0) was available during the derivation, its weight ends up being zero.\n\nBesides the aesthetic appeal of symmetry, in \n\nConvergence of finite differences we will see another important advantage of \n\n(5.4.8) compared to the one-sided formulas.\n\nWe can in principle derive any finite-difference formula from the same process: Interpolate the given function values, then differentiate the interpolant exactly. Some results of the process are given in \n\nTable 5.4.1 for centered differences, and in \n\nTable 5.4.2 for forward differences. Both show the weights for estimating the derivative at x=0. To get backward differences, you change the signs and reverse the order of the coefficients in any row of \n\nTable 5.4.2; see \n\nExercise 2.\n\nTable 5.4.1:Weights for centered finite-difference formulas.\n\norder\n\n-4h\n\n-3h\n\n-2h\n\n-h\n\n0\n\nh\n\n2h\n\n3h\n\n4h\n\n2\n\n\n\n\n\n\n\n-\\frac{1}{2}\n\n0\n\n\\frac{1}{2}\n\n\n\n\n\n\n\n4\n\n\n\n\n\n\\frac{1}{12}\n\n-\\frac{2}{3}\n\n0\n\n\\frac{2}{3}\n\n-\\frac{1}{12}\n\n\n\n\n\n6\n\n\n\n-\\frac{1}{60}\n\n\\frac{3}{20}\n\n-\\frac{3}{4}\n\n0\n\n\\frac{3}{4}\n\n-\\frac{3}{20}\n\n\\frac{1}{60}\n\n\n\n8\n\n\\frac{1}{280}\n\n-\\frac{4}{105}\n\n\\frac{1}{5}\n\n-\\frac{4}{5}\n\n0\n\n\\frac{4}{5}\n\n-\\frac{1}{5}\n\n\\frac{4}{105}\n\n-\\frac{1}{280}\n\nTable 5.4.2:Weights for forward finite-difference formulas. To get backward differences, change the signs and reverse the order of the coefficients.\n\norder\n\n0\n\nh\n\n2h\n\n3h\n\n4h\n\n1\n\n-1\n\n1\n\n\n\n\n\n\n\n2\n\n-\\frac{3}{2}\n\n2\n\n-\\frac{1}{2}\n\n\n\n\n\n3\n\n-\\frac{11}{6}\n\n3\n\n-\\frac{3}{2}\n\n\\frac{1}{3}\n\n\n\n4\n\n-\\frac{25}{12}\n\n4\n\n-3\n\n\\frac{4}{3}\n\n-\\frac{1}{4}\n\nThe main motivation for using more function values in a formula is to improve the accuracy. This is measured by order of accuracy, which is shown in the tables and explored in \n\nSection 5.5.\n\nAccording to the tables, here are three specific finite-difference formulas:\\begin{split}\nf'(0) &\\approx \\tfrac{1}{h} \\left[ \\tfrac{1}{12} f(-2h)\n- \\tfrac{2}{3} f(-h) + \\tfrac{2}{3} f(h) - \\tfrac{1}{12} f(2h) \\right], \\\\[1mm]\nf'(0) &\\approx \\tfrac{1}{h} \\left[ -\\tfrac{3}{2} f(0) + 2 f(h) -\\tfrac{1}{2} f(2h) \\right], \\\\[1mm]\nf'(0) &\\approx \\tfrac{1}{h} \\left[ \\tfrac{1}{2} f(-2h) - 2 f(-h) + \\tfrac{3}{2} f(0) \\right].\n\\end{split}\n\nFinite differences\n\nExample 5.4.3\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = x -> exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / 2h\nCD4 = (f(-2h) - 8f(-h) + 8f(h) - f(2h)) / 12h\n@show (CD2, CD4);\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3f(0) + 4f(h) - f(2h)) / 2h\n@show (FD1, FD2);\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2h) - 4f(-h) + 3f(0)) / 2h\n@show (BD1, BD2);\n\nExample 5.4.3\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05;\nformat long\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\n\nExample 5.4.3\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\nprint(f\"CD2 is {CD2:.9f} and CD4 is {CD4:.9f}\")\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")","type":"content","url":"/finitediffs#common-examples","position":3},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Higher derivatives"},"type":"lvl2","url":"/finitediffs#higher-derivatives","position":4},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Higher derivatives"},"content":"Many applications require the second derivative of a function. It’s tempting to use the finite difference of a finite difference. For example, applying \n\n(5.4.8) to f' givesf''(0) \\approx  \\frac{ f'(h) - f'(h) }{2h}.\n\nThen applying \n\n(5.4.8) to approximate the appearances of f' leads tof''(0) \\approx  \\frac{ f(-2h) - 2 f(0) + f(2h) }{4h^2}.\n\nThis is a valid formula, but it uses values at \\pm 2h rather than the closer values at \\pm h. A better and more generalizable tactic is to return to the quadratic Q(x) in \n\n(5.4.7) and use Q''(0) to approximate f''(0). Doing so yields  f''(0) \\approx  \\frac{ f(-h) - 2 f(0) + f(h) }{h^2},\n\nwhich is the simplest centered second-difference formula. As with the first derivative, we can choose larger values of p and q in \n\n(5.4.1) to get new formulas, such asf''(0) \\approx \\frac{ f(0) - 2 f(h) + f(2h) }{h^2},\n\nandf''(0) \\approx \\frac{ 2f(0) - 5 f(h) + 4 f(2h) -f(3h) }{h^2}.\n\nFor the second derivative, converting a forward difference to a backward difference requires reversing the order of the weights, while not changing their signs.\n\nFinite differences for f''\n\nExample 5.4.4\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = x -> exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2f(0) + f(h)) / h^2\n@show CD2;\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2f(h) + f(2h)) / h^2\nFD2 = (2f(0) - 5f(h) + 4f(2h) - f(3h)) / h^2\n@show (FD1, FD2);\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2h) - 2f(-h) + f(0)) / h^2\nBD2 = (-f(-3h) + 4f(-2h) - 5f(-h) + 2f(0)) / h^2\n@show (BD1, BD2);\n\nExample 5.4.4\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05;\nformat long\nCD2 = (f(-h) - 2*f(0) + f(h)) / h^2\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h^2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h^2\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h^2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h^2\n\nExample 5.4.4\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2*f(0) + f(h)) / h**2\nprint(f\"CD2 is {CD2:.9f}\")\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h**2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h**2\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h**2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h**2\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")","type":"content","url":"/finitediffs#higher-derivatives","position":5},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Arbitrary nodes"},"type":"lvl2","url":"/finitediffs#arbitrary-nodes","position":6},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Arbitrary nodes"},"content":"Although function values at equally spaced nodes are a common and convenient situation, the node locations may be arbitrary. The general form of a finite-difference formula is  f^{(m)}(0) \\approx \\sum_{k=0}^{r} c_{k,m} \\,f(t_k).\n\nWe no longer assume equally spaced nodes, so there is no “h” to be used in the formula. As before, the weights may be applied after any translation of the independent variable. The weights again follow from the interpolate/differentiate recipe, but the algebra becomes complicated. Fortunately there is an elegant recursion known as Fornberg’s algorithm that can calculate these weights for any desired formula. We present it without derivation as \n\nFunction 5.4.1.\n\nfdweights\n\nFornberg’s algorithm for finite difference weights\n\n\"\"\"\n    fdweights(t, m)\n\nCompute weights for the `m`th derivative of a function at zero using\nvalues at the nodes in vector `t`.\n\"\"\"\nfunction fdweights(t, m)\n    # This is a compact implementation, not an efficient one.\n    # Recursion for one weight.\n    function weight(t, m, r, k)\n        # Inputs\n        #   t: vector of nodes\n        #   m: order of derivative sought\n        #   r: number of nodes to use from t\n        #   k: index of node whose weight is found\n\n        if (m < 0) || (m > r)        # undefined coeffs must be zero\n            c = 0\n        elseif (m == 0) && (r == 0)  # base case of one-point interpolation\n            c = 1\n        else                     # generic recursion\n            if k < r\n                c =\n                    (t[r+1] * weight(t, m, r-1, k) - m * weight(t, m-1, r-1, k)) /\n                    (t[r+1] - t[k+1])\n            else\n                numer = r > 1 ? prod(t[r] - x for x in t[1:r-1]) : 1\n                denom = r > 0 ? prod(t[r+1] - x for x in t[1:r]) : 1\n                β = numer / denom\n                c =\n                    β *\n                    (m * weight(t, m - 1, r-1, r-1) - t[r] * weight(t, m, r-1, r-1))\n            end\n        end\n        return c\n    end\n    r = length(t) - 1\n    w = zeros(size(t))\n    return [weight(t, m, r, k) for k in 0:r]\nend\n\nFornberg’s algorithm for finite difference weights\n\nfunction w = fdweights(t,m)\r\n%FDWEIGHTS   Fornberg's algorithm for finite difference weights.\r\n% Input:\r\n%   t    nodes (vector, length r+1)\r\n%   m    order of derivative sought at x=0 (integer scalar)\r\n% Output:\r\n%   w    weights for the approximation to the jth derivative (vector)\r\n\r\n% This is a compact implementation, not an efficient one. \r\n\r\nr = length(t)-1;\r\nw = zeros(size(t));\r\nfor k = 0:r\r\n  w(k+1) = weight(t,m,r,k);\r\nend\r\n\r\n\r\nfunction c = weight(t,m,r,k)\r\n% Implement a recursion for the weights.\r\n% Input:\r\n%   t   nodes (vector)\r\n%   m   order of derivative sought \r\n%   r   number of nodes to use from t (<= length(t))\r\n%   k   index of node whose weight is found \r\n% Output:\r\n%   c   finite difference weight \r\n\r\nif (m<0) || (m>r)        % undefined coeffs must be zero\r\n  c = 0;    \r\nelseif (m==0) && (r==0)  % base case of one-point interpolation\r\n  c = 1;   \r\nelse                     % generic recursion \r\n  if k<r\r\n    c = (t(r+1)*weight(t,m,r-1,k) - ...\r\n        m*weight(t,m-1,r-1,k))/(t(r+1)-t(k+1));\r\n  else\r\n    beta = prod(t(r)-t(1:r-1)) / prod(t(r+1)-t(1:r));\r\n    c = beta*(m*weight(t,m-1,r-1,r-1) - t(r)*weight(t,m,r-1,r-1));\r\n  end\r\nend\n\nFornberg’s algorithm for finite difference weights\n\ndef fdweights(t, m):\n    \"\"\"\n    fdweights(t, m)\n\n    Return weights for the mth derivative of a function at zero using values at the\n    nodes in vector t.\n    \"\"\"\n    # This is a compact implementation, not an efficient one.\n\n    def weight(t, m, r, k):\n        # Recursion for one weight.\n        # Input:\n        #   t   nodes (vector)\n        #   m   order of derivative sought\n        #   r   number of nodes to use from t (<= length(t))\n        #   k   index of node whose weight is found\n\n        if (m < 0) or (m > r):  # undefined coeffs must be zero\n            c = 0\n        elif (m == 0) and (r == 0):  # base case of one-point interpolation\n            c = 1\n        else:  # generic recursion\n            if k < r:\n                denom = t[r] - t[k]\n                c = (t[r] * weight(t, m, r-1, k) - m * weight(t, m-1, r-1, k)) / denom\n            else:\n                beta = np.prod(t[r-1] - t[:r-1]) / np.prod(t[r] - t[:r])\n                c = beta * (m * weight(t, m-1, r-1, r-1) - t[r-1] * weight(t, m, r-1, r-1))\n        return c\n\n    r = len(t) - 1\n    w = np.zeros(t.shape)\n    return np.array([ weight(t, m, r, k) for k in range(r+1) ])\n\nFinite differences at arbitrary nodes\n\nExample 5.4.5\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75]   # nodes\nf = x -> cos(x^2)\ndf_dx = x -> -2 * x * sin(x^2)\nexact_value = df_dx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t .- 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f.(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nFNC.fdweights(0:3, 1)\n\nBy giving nodes of type Rational, we can get exact values instead.\n\nFNC.fdweights(Rational.(0:3), 1)\n\nExample 5.4.5\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75];    % nodes\nf = @(x) cos(x.^2);\ndfdx = @(x) -2 * x * sin(x^2);\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nformat short\nw = fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = w * f(t)'\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nfdweights(0:3, 1)\n\nExample 5.4.5\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = array([0.35, 0.5, 0.57, 0.6, 0.75])   # nodes\nf = lambda x: cos(x**2)\ndfdx = lambda x: -2 * x * sin(x**2)\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nprint(FNC.fdweights(linspace(0, 3, 4), 1))","type":"content","url":"/finitediffs#arbitrary-nodes","position":7},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Exercises"},"type":"lvl2","url":"/finitediffs#exercises","position":8},{"hierarchy":{"lvl1":"Finite differences","lvl2":"Exercises"},"content":"✍ This problem refers to Q(x) defined by \n\n(5.4.7).\n\n(a) Show that Q(x) interpolates the three values of f at x=-h, x=0, and x=h.\n\n(b) Show that Q'(0) gives the finite-difference formula defined by \n\n(5.4.8).\n\n(a) ✍ \n\nTable 5.4.2 lists forward difference formulas in which p=0 in \n\n(5.4.1). Show that the change of variable g(x) = f(-x) transforms these formulas into backward difference formulas with q=0, and write out the table analogous to \n\nTable 5.4.2 for backward differences.\n\n(b) ⌨ Suppose you are given the nodes t_0=0.9, t_1=1, and t_2=1.1, and f(x) = \\sin(2x). Using formulas from \n\nTable 5.4.1 and \n\nTable 5.4.2, compute second-order accurate approximations to f' at each of the three nodes.\n\n⌨ Let f(x)=e^{-x}, x=0.5, and h=0.2. Using \n\nFunction 5.4.1 to get the necessary weights on five nodes centered at x, find finite-difference approximations to the first, second, third, and fourth derivatives of f. Make a table showing the derivative values and the errors in each case.\n\n⌨ In the manner of \n\nDemo 5.4.5, use \n\nFunction 5.4.1 on centered node vectors of length  3, 5, 7, and 9 to produce a table analogous to \n\nTable 5.4.1 for the second derivative f''(0). (You do not need to show the orders of accuracy, just the weights.)\n\n⌨ For this problem, let f(x)=\\tan(2x).\n\n(a) ⌨ Apply \n\nFunction 5.4.1 to find a finite-difference approximation to f''(0.3) using the five nodes t_j=0.3+jh for j=-2,\\ldots,2 and h=0.05. Compare to the exact value of f''(0.3).\n\n(b) ⌨  Repeat part (a) for f''(0.75) on the nodes t_j=0.75+jh. Why is the finite-difference result so inaccurate? (Hint: A plot of f might be informative.)\n\n✍ Find the finite-difference formula for f''(0) that results from applying \n\n(5.4.2) on f' and then \n\n(5.4.3) on f' within that result.\n\n(a) ✍ Show using L’Hôpital’s Rule that the centered formula approximation \n\n(5.4.8) converges to an equality as h\\to 0.\n\n(b) ✍ Derive two conditions on the finite-difference weights in \n\n(5.4.1) that arise from requiring convergence as h\\to 0. (Hint: Consider what is required in order to apply L’Hôpital’s Rule, as well as the result of applying it.)","type":"content","url":"/finitediffs#exercises","position":9},{"hierarchy":{"lvl1":"Numerical integration"},"type":"lvl1","url":"/integration","position":0},{"hierarchy":{"lvl1":"Numerical integration"},"content":"In calculus you learn that the elegant way to evaluate a definite integral is to apply the Fundamental Theorem of Calculus and find an antiderivative. The connection is so profound and pervasive that it’s easy to overlook that a definite integral is a numerical quantity existing independently of antidifferentiation.  However, most conceivable integrands have no antiderivative in terms of familiar functions.\n\nNumerical integration\n\nExample 5.6.1\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe Julia package QuadGK has an all-purpose numerical integrator that estimates the value without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nusing QuadGK\nQ, errest = quadgk(x -> exp(x), 0, 1)\n@show Q;\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quadgk(x -> exp(sin(x)), 0, 1)\n@show Q;\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nusing Plots\nplot([exp, x -> exp(sin(x))], 0, 1, fill=0, layout=(2, 1),\n    xlabel=L\"x\", ylabel=[L\"e^x\" L\"e^{\\sin(x)}\"], ylim=[0, 2.7])\n\nExample 5.6.1\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nformat long\nexact = exp(1) - 1\n\nMATLAB has numerical integrator integral that estimates the value without finding the antiderivative first. As you can see here, it can be as accurate as floating-point precision allows.\n\nintegral(@(x) exp(x), 0, 1)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nintegral(@(x) exp(sin(x)), 0, 1)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 201)';\nsubplot(2,1,1), fill([x; 1; 0], [exp(x); 0;0 ], [1, 0.9, 0.9])\ntitle('exp(x)')\nylabel('f(x)')\nsubplot(2, 1, 2), fill([x; 1; 0], [exp(sin(x)); 0; 0], [1, 0.9, 0.9])\ntitle('exp(sin(x))')\nxlabel('x'), ylabel(('f(x)'));\n\nExample 5.6.1\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe module scipy.integrate has multiple functions that estimate the value of an integral numerically without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nfrom scipy.integrate import quad\nQ, errest = quad(exp, 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quad(lambda x: exp(sin(x)), 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 300)\nsubplot(1, 2, 1)\nplot(x, exp(x))\nylim([0, 2.7]), title(\"exp(x)\")\nsubplot(1, 2, 2)\nplot(x, exp(sin(x)))\nylim([0, 2.7]), title(\"exp(sin(x))\");\n\nNumerical integration, which also goes by the older name quadrature, is performed by combining values of the integrand sampled at nodes. In this section we will assume equally spaced nodes using the definitions  t_i = a +i h, \\quad h=\\frac{b-a}{n}, \\qquad i=0,\\ldots,n.\n\nNumerical integration formula\n\nA numerical integration formula is a list of weights w_0,\\ldots,w_n chosen so that for all f in some class of functions,  \\begin{split}\n    \\int_a^b f(x)\\, dx \\approx h \\sum_{i=0}^n w_if(t_i) =  h \\bigl[ w_0f(t_0)+w_1f(t_1)+\\cdots w_nf(t_n) \\bigr],\n  \\end{split}\n\nwith the t_i defined in \n\n(5.6.1). The weights are independent of f and h.\n\nNumerical integration formulas can be applied to sequences of data values even if no function is explicitly known to generate them. For our presentation and implementations, however, we assume that f is known and can be evaluated anywhere.\n\nA straightforward way to derive integration formulas is to mimic the approach taken for finite differences: find an interpolant and operate exactly on it.","type":"content","url":"/integration","position":1},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Trapezoid formula"},"type":"lvl2","url":"/integration#trapezoid-formula","position":2},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Trapezoid formula"},"content":"One of the most important integration formulas results from integration of the piecewise linear interpolant (see \n\nPiecewise linear interpolation). Using the cardinal basis form of the interpolant in \n\n(5.2.3), we have\\int_a^b f(x) \\, dx \\approx \\int_a^b \\sum_{i=0}^n f(t_i) H_i(x)\\, dx = \\sum_{i=0}^n f(t_i) \\left[ \\int_a^b H_i(x)\\right]\\, dx.\n\nThus we can identify the weights as w_i = h^{-1} \\int_a^b H_i(x)\\, dx. Using areas of triangles, it’s trivial to derive thatw_i = \\begin{cases}\n1, & i=1,\\ldots,n-1,\\\\\n\\frac{1}{2}, & i=0,n.\n\\end{cases}\n\nPutting everything together, the resulting formula is\\begin{split}\n  \\int_a^b f(x)\\, dx \\approx T_f(n) &= h\\left[\n    \\frac{1}{2}f(t_0) + f(t_1) + f(t_2) + \\cdots + f(t_{n-1}) +\n    \\frac{1}{2}f(t_n) \\right].\n\\end{split}\n\nTrapezoid formula\n\nThe trapezoid formula is a numerical integration formula in the form \n\n(5.6.2), withw_i = \\begin{cases}\n  \\frac{1}{2},& i=0 \\text{ or } i=n, \\\\ \n  1, & 0 < i < n.\n  \\end{cases}\n\nGeometrically, as illustrated in \n\nFigure 5.6.1, the trapezoid formula sums of the areas of trapezoids approximating the region under the curve y=f(x).\n\nThe trapezoid formula is the Swiss Army knife of integration formulas. A short implementation is given as \n\nFunction 5.6.1.\n\n\n\nFigure 5.6.1:Trapezoid formula for integration. The piecewise linear interpolant defines trapezoids that approximate the region under the curve.\n\ntrapezoid\n\nTrapezoid formula for numerical integration\n\n\"\"\"\n    trapezoid(f, a, b, n)\n\nApply the trapezoid integration formula for integrand `f` over\ninterval [`a`,`b`], broken up into `n` equal pieces. Returns\nthe estimate, a vector of nodes, and a vector of integrand values at the\nnodes.\n\"\"\"\nfunction trapezoid(f, a, b, n)\n    h = (b - a) / n\n    t = range(a, b, length = n + 1)\n    y = f.(t)\n    T = h * (sum(y[2:n]) + 0.5 * (y[1] + y[n+1]))\n    return T, t, y\nend\n\nTrapezoid formula for numerical integration\n\nfunction [T,t,y] = trapezoid(f,a,b,n)\n%TRAPEZOID   Trapezoid formula for numerical integration.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   n     number of interval divisions\n% Output:\n%   T     approximation to the integral of f over (a,b)\n%   t     vector of nodes used\n%   y     vector of function values at nodes\n\nh = (b-a)/n;\nt = a + h*(0:n)';\ny = f(t);\nT = h * ( sum(y(2:n)) + 0.5*(y(1) + y(n+1)) );\n\nTrapezoid formula for numerical integration\n\ndef trapezoid(f, a, b, n):\n    \"\"\"\n    trapezoid(f, a, b, n)\n\n    Apply the trapezoid integration formula for integrand f over interval [a,b], broken up into n equal pieces. Returns estimate, vector of nodes, and vector of integrand values at the nodes.\n    \"\"\"\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n    y = f(t)\n    T = h * (np.sum(y[1:-1]) + 0.5 * (y[0] + y[-1]))\n    return T, t, y\n\nLike finite-difference formulas, numerical integration formulas have a truncation error.\n\nTruncation error of a numerical integration formula\n\nFor the numerical integration formula \n\n(5.6.2), the truncation error is\\tau_f(h) = \\int_a^b f(x) \\, dx - h \\sum_{i=0}^{n} w_i f(t_i).\n\nThe order of accuracy is as defined in \n\nDefinition 5.5.2.\n\nIn \n\nTheorem 5.2.2 we stated that the pointwise error in a piecewise linear interpolant with equal node spacing h is bounded by O(h^2) as h\\rightarrow 0. Using I to stand for the exact integral of f and p to stand for the piecewise linear interpolant, we obtain\\begin{split}\n  I - T_f(n) = I - \\int_a^b p(x)\\, dx &= \\int_a^b \\bigl[f(x)-p(x)\\bigr] \\, dx \\\\\n  &\\le (b-a) \\max_{x\\in[a,b]} |f(x)-p(x)| = O(h^2).\n\\end{split}\n\nA more thorough statement of the truncation error is known as the Euler–Maclaurin formula,\\begin{split}\n\\int_a^b f(x)\\, dx &= T_f(n) - \\frac{h^2}{12} \\left[ f'(b)-f'(a) \\right] + \\frac{h^4}{740} \\left[ f'''(b)-f'''(a) \\right] + O(h^6) \\\\\n    &= T_f(n) - \\sum_{k=1}^\\infty \\frac{B_{2k}h^{2k}}{(2k)!}  \\left[ f^{(2k-1)}(b)-f^{(2k-1)}(a) \\right],\n\\end{split}\n\nwhere the B_{2k} are constants known as Bernoulli numbers. Unless we happen to be fortunate enough to have a function with f'(b)=f'(a), we should expect truncation error at second order and no better.\n\nThe trapezoid integration formula is second-order accurate.\n\nTrapezoid integration\n\nExample 5.6.2\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = x -> exp(sin(7 * x));\na = 0;\nb = 2;\n\nIn lieu of the exact value, we use the QuadGK package to find an accurate result.\n\nTip\n\nIf a function has multiple return values, you can use an underscore _ to indicate a  return value you want to ignore.\n\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14);\nprintln(\"Integral = $Q\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\n@show (T, Q - T);\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = [10^n for n in 1:5]\nerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    err[k] = Q - T\nend\n@pt :header=[\"n\", \"error\"] [n err]\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nplot(n, abs.(err);\n    m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"),  yaxis=(:log10, \"error\"),\n    title=\"Convergence of trapezoidal integration\")\n\n# Add line for perfect 2nd order.\nplot!(n, 3e-3 * (n / n[1]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\n\nExample 5.6.2\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = @(x) exp(sin(7 * x));\na = 0;  b = 2;\n\nIn lieu of the exact value, we use the integral function to find an accurate result.\n\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14);\nfprintf(\"Integral = %.15f\", I)\n\nHere is the trapezoid result at n=40, and its error.\n\nT = trapezoid(f, a, b, 40);\nfprintf(\"Trapezoid error = %.2e\", I - T)\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = 10 .^ (1:5)';\nerr = zeros(size(n));\nfor i = 1:length(n)\n    T = trapezoid(f, a, b, n(i));\n    err(i) = I - T;\nend\ntable(n, err, variableNames=[\"n\", \"Trapezoid error\"])\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"trapezoid\")\nhold on\nloglog(n, 0.1 * abs(err(end)) * (n / n(end)).^(-2), \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"error\")\ntitle(\"Convergence of trapezoidal integration\")\nlegend();\n\nExample 5.6.2\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = lambda x: exp(sin(7 * x))\na, b = 0, 2\n\nIn lieu of the exact value, we will use the quad function to find an accurate result.\n\nfrom scipy.integrate import quad\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\nprint(f\"Trapezoid estimate is {T:.14f} with error {I - T:.2e}\")\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn_ = 40 * 2 ** arange(6)\nerr = zeros(size(n_))\nprint(\"     n     error\")\nfor k, n in enumerate(n_):\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    err[k] = I - T\n    print(f\"{n:6d}   {err[k]:8.3e} \")\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nloglog(n_, abs(err), \"-o\", label=\"results\")\nloglog(n_, 3e-3 * (n_ / n_[0]) ** (-2), \"--\", label=\"2nd order\")\ngca().invert_xaxis()\nxlabel(\"$n$\")\nylabel(\"error\")\nlegend()\ntitle(\"Convergence of trapezoidal integration\");","type":"content","url":"/integration#trapezoid-formula","position":3},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Extrapolation"},"type":"lvl2","url":"/integration#extrapolation","position":4},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Extrapolation"},"content":"If evaluations of f are computationally expensive, we want to get as much accuracy as possible from them by using a higher-order formula. There are many routes for doing so; for example, we could integrate a not-a-knot cubic spline interpolant. However, splines are difficult to compute by hand, and as a result different methods were developed before computers came on the scene.\n\nKnowing the structure of the error allows the use of extrapolation to improve accuracy. Suppose a quantity A_0 is approximated by an algorithm A(h) with an\nerror expansion  A_0 = A(h) + c_1 h + c_2 h^2 + c_3 h^3 + \\cdots.\n\nCrucially, it is not necessary to know the values of the error constants c_k, merely that they exist and are independent of h.\n\nUsing I for the exact integral of f, the trapezoid formula has  I = T_f(n) + c_2 h^2 + c_4 h^{4} + \\cdots,\n\nas proved by the Euler–Maclaurin formula \n\n(5.6.9). The error constants depend on f and can’t be evaluated in general, but we know that this expansion holds. For convenience we recast the error expansion in terms of n=O(h^{-1}):  I = T_f(n) + c_2 n^{-2} + c_4 n^{-4} + \\cdots.\n\nWe now make the simple observation that  I = T_f(2n) + \\tfrac{1}{4} c_2 n^{-2} + \\tfrac{1}{16} c_4 n^{-4} + \\cdots.\n\nIt follows that if we combine \n\n(5.6.12) and \n\n(5.6.13) correctly, we can cancel out the second-order term in the error. Specifically, define  S_f(2n) = \\frac{1}{3} \\Bigl[ 4 T_f(2n) - T_f(n) \\Bigr].\n\n(We associate 2n rather than n with the extrapolated result because of the total number of nodes needed.) Then  I = S_f(2n) + O(n^{-4}) =  b_4 n^{-4} + b_6 n^{-6} + \\cdots.\n\nThe formula \n\n(5.6.14) is called Simpson’s formula, or Simpson’s rule. A different presentation and derivation are considered in \n\nExercise 4.\n\nEquation \n\n(5.6.15) is another particular error expansion in the form \n\n(5.6.10), so we can extrapolate again! The details change only a little. Considering that  I = S_f(4n) = \\tfrac{1}{16} b_4 n^{-4} + \\tfrac{1}{64} b_6 n^{-6} + \\cdots,\n\nthe proper combination this time is  R_f(4n) = \\frac{1}{15} \\Bigl[ 16 S_f(4n) - S_f(2n) \\Bigr],\n\nwhich is sixth-order accurate. Clearly the process can be repeated to get eighth-order accuracy and beyond. Doing so goes by the name of Romberg integration, which we will not present in full generality.","type":"content","url":"/integration#extrapolation","position":5},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Node doubling"},"type":"lvl2","url":"/integration#node-doubling","position":6},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Node doubling"},"content":"Note in \n\n(5.6.17) that R_f(4n) depends on S_f(2n) and S_f(4n), which in turn depend on T_f(n), T_f(2n), and T_f(4n).  There is a useful benefit realized by doubling of the nodes in each application of the trapezoid formula. As shown in \n\nFigure 5.6.2, when doubling n, only about half of the nodes are new ones, and previously computed function values at the other nodes can be reused.\n\n\n\nFigure 5.6.2:Dividing the node spacing by half introduces new nodes only at midpoints, allowing the function values at existing nodes to be reused for extrapolation.\n\nSpecifically, we have\\begin{split}\n  T_f(2m) & = \\frac{1}{2m} \\left[  \\frac{1}{2} f(a) + \\frac{1}{2} f(b) + \\sum_{i=1}^{2m-1}  f\\Bigl( a + \\frac{i}{2m} \\Bigr) \\right]\\\\[1mm]\n  & = \\frac{1}{2m} \\left[  \\frac{1}{2} f(a) + \\frac{1}{2} f(b)\\right] + \\frac{1}{2m} \\sum_{k=1}^{m-1}  f\\Bigl( a+\\frac{2k}{2m} \\Bigr)  + \\frac{1}{2m} \\sum_{k=1}^{m} f\\Bigl( a+\\frac{2k-1}{2m} \\Bigr) \\\\[1mm]\n  &=  \\frac{1}{2m} \\left[  \\frac{1}{2} f(a) + \\frac{1}{2} f(b) + \\sum_{k=1}^{m-1} f\\Bigl( a+\\frac{k}{m} \\Bigr) \\right] + \\frac{1}{2m} \\sum_{k=1}^{m}  f\\Bigl( a+\\frac{2k-1}{2m} \\Bigr)  \\\\[1mm]\n  &= \\frac{1}{2} T_f(m) + \\frac{1}{2m} \\sum_{k=1}^{m-1}  f\\left(t_{2k-1} \\right),\n\\end{split}\n\nwhere the nodes referenced in the last line are relative to n=2m. Hence in passing from n=m to n=2m, new integrand evaluations are needed only at the odd-numbered nodes of the finer grid.\n\nIntegration by extrapolation\n\nExample 5.6.3\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = x -> x^2 * exp(-2x);\na = 0;\nb = 2;\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14)\n@show Q;\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       # the coarsest formula\nn = N;\nh = (b - a) / n;\nt = h * (0:n);\ny = f.(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = [h * (sum(y[2:n]) + y[1] / 2 + y[n+1] / 2)]\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nWe can repeat the same code to double n again.\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = [(4T[i+1] - T[i]) / 3 for i in 1:2]\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16S[2] - S[1]) / 15\n\nWe can make a triangular table of the errors:\n\nTip\n\nThe value nothing equals nothing except nothing.\n\nerr = [T .- Q [nothing; S .- Q] [nothing; nothing; R - Q]]\n@pt :header=[\"order 2\", \"order 4\", \"order 6\"] err\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.\n\nExample 5.6.3\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = @(x) x.^2 .* exp(-2 * x);\na = 0;  b = 2;\nformat long\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14)\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       % the coarsest formula\nn = N;  h = (b - a) / n;\nt = h * (0:n)';\ny = f(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = h * ( sum(y(2:n)) + y(1) / 2 + y(n+1) / 2 )\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(2) = T(1) / 2 + h * sum( f(t(2:2:n)) )\n\nWe can repeat the same code to double n again.\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(3) = T(2) / 2 + h * sum( f(t(2:2:n)) )\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = (4 * T(2:3) - T(1:2)) / 3\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16*S(2) - S(1)) / 15\n\nWe can make a triangular table of the errors:\n\nerr2 = T(:) - I;\nerr4 = [NaN; S(:) - I];\nerr6 = [NaN; NaN; R - I];\nformat short e\ntable(err2, err4, err6, variablenames=[\"order 2\", \"order 4\", \"order 6\"])\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.\n\nExample 5.6.3\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nfrom scipy.integrate import quad\nf = lambda x: x**2 * exp(-2 * x)\na = 0\nb = 2\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20    # the coarsest formula\nn = N\nh = (b - a) / n\nt = h * arange(n + 1)\ny = f(t)\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = zeros(3)\nT[0] = h * (sum(y[1:-1]) + y[0] / 2 + y[-1] / 2)\nprint(f\"error (2nd order): {I - T[0]:.2e}\")\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[1] = T[0] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:2])\n\nAs expected for a second-order estimate, the error went down by a factor of about 4. We can repeat the same code to double n again.\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[2] = T[1] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:3])\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = array([(4 * T[i + 1] - T[i]) / 3 for i in range(2)])\nprint(\"error (4th order):\", I - S)\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16 * S[1] - S[0]) / 15\nprint(\"error (6th order):\", I - R)\n\nWe can make a triangular table of the errors:\n\nerr = nan * ones((3, 3))\nerr[0, :] = I - T\nerr[1, 1:] = I - S\nerr[2, 2] = I - R\nresults = PrettyTable([\"2nd order\", \"4th order\", \"6th order\"])\nresults.add_rows(err.T)\nprint(results)\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/integration#node-doubling","position":7},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Exercises"},"type":"lvl2","url":"/integration#exercises","position":8},{"hierarchy":{"lvl1":"Numerical integration","lvl2":"Exercises"},"content":"must be kept as #1\n\n⌨ For each integral below, use \n\nFunction 5.6.1 to estimate the integral for n=10\\cdot 2^k nodes for k=1,2,\\ldots,10. Make a log-log plot of the errors and confirm or refute second-order accuracy. (These integrals were taken from \n\nBailey et al. (2005).)\n\n(a) \\displaystyle \\int_0^1 x\\log(1+x)\\, dx = \\frac{1}{4}\n\n(b) \\displaystyle \\int_0^1 x^2 \\tan^{-1}x\\, dx = \\frac{\\pi-2+2\\log 2}{12}\n\n(c) \\displaystyle \\int_0^{\\pi/2}e^x \\cos x\\, dx = \\frac{e^{\\pi/2}-1}{2}\n\n(d) \\displaystyle \\int_0^1 \\sqrt{x} \\log(x) \\, dx = -\\frac{4}{9} (Note: Although the integrand has the limiting value zero as x\\to 0, it cannot be evaluated naively at x=0. You can start the integral at x=\\macheps instead.)\n\n(e) \\displaystyle \\int_0^1 \\sqrt{1-x^2}\\,\\, dx = \\frac{\\pi}{4}\n\n✍ The Euler–Maclaurin error expansion \n\n(5.6.9) for the trapezoid formula implies that if we could cancel out the term due to f'(b)-f'(a), we would obtain fourth-order accuracy. We should not assume that f' is available, but approximating it with finite differences can achieve the same goal. Suppose the forward difference formula \n\n(5.4.13) is used for f'(a), and its reflected backward difference is used for f'(b). Show that the resulting modified trapezoid formula is    G_f(h) = T_f(h) - \\frac{h}{24} \\left[ 3\\Bigl( f(t_n)+f(t_0) \\Bigr) -4\\Bigr( f(t_{n-1}) + f(t_1) \\Bigr) + \\Bigl( f(t_{n-2})+f(t_2)   \\Bigr) \\right],\n\nwhich is known as a Gregory integration formula.\n\n⌨ Repeat each integral in Exercise 1 above using Gregory integration \n\n(5.6.19) instead of the trapezoid formula. Compare the observed errors to fourth-order convergence.\n\n✍  Simpson’s formula can be derived without appealing to extrapolation.\n\n(a) Show thatp(x) = \\beta + \\frac{\\gamma-\\alpha}{2h}\\, x + \\frac{\\alpha-2\\beta+\\gamma}{2h^2}\\, x^2\n\ninterpolates the three points (-h,\\alpha), (0,\\beta), and (h,\\gamma).\n\n(b) Find  \\int_{-h}^h p(s)\\, ds,\n\nwhere p is the quadratic polynomial from part (a), in terms of h, α, β, and γ.\n\n(c) Assume equally spaced nodes in the form t_i=a+ih, for h=(b-a)/n and i=0,\\ldots,n. Suppose f is approximated by p(x) over the subinterval [t_{i-1},t_{i+1}]. Apply the result from part (b) to find  \\int_{t_{i-1}}^{t_{i+1}} f(x)\\, dx \\approx \\frac{h}{3} \\bigl[ f(t_{i-1}) + 4f(t_i) + f(t_{i+1}) \\bigr].\n\n(Use the change of variable s=x-t_i.)\n\n(d) Now also assume that n=2m for an integer m. Derive Simpson’s formula,  \\begin{split}\n    \\int_a^b f(x)\\, dx \\approx  \\frac{h}{3}\\bigl[ &f(t_0) + 4f(t_1) + 2f(t_2) + 4f(t_3) + 2f(t_4) + \\cdots\\\\\n    &+ 2f(t_{n-2}) + 4f(t_{n-1}) + f(t_n) \\bigr].\n  \\end{split}\n\n✍ Show that the Simpson formula \n\n(5.6.23) is equivalent to S_f(n/2), given the definition of S_f in \n\n(5.6.14).\n\n⌨ For each integral in Exercise 1 above, apply the Simpson formula \n\n(5.6.23) and compare the errors to fourth-order convergence.\n\n⌨ For n=10,20,30,\\ldots,200, compute the trapezoidal approximation to\\int_{0}^1 \\frac{1}{2.01+\\sin (6\\pi x)-\\cos(2\\pi x)} \\,d x \\approx 0.9300357672424684.\n\nMake two separate plots of the absolute error as a function of n, one using a log-log scale and the other using log-linear. The graphs suggest that the error asymptotically behaves as C \\alpha^n for some C>0 and some 0<\\alpha<1. How does this result relate to \n\n(5.6.9)?\n\n⌨ For each integral in Exercise 1 above, extrapolate the trapezoidal results two levels to get sixth-order accurate results, and compute the errors for each value.\n\n✍ Find a formula like \n\n(5.6.17) that extrapolates two values of R_f to obtain an eighth-order accurate one.\n\nSome texts distinguish between a formula for a single subinterval [t_{k-1},t_k] and a composite formula that adds them up over the whole interval to get \n\n(5.6.5).","type":"content","url":"/integration#exercises","position":9},{"hierarchy":{"lvl1":"The interpolation problem"},"type":"lvl1","url":"/interpolation","position":0},{"hierarchy":{"lvl1":"The interpolation problem"},"content":"Interpolation problem\n\nGiven n+1 distinct points (t_0,y_0), (t_1,y_1),\\ldots,(t_n,y_n), with t_0<t_1<\\ldots <t_n called nodes, the interpolation problem is to find a function p(x), called the interpolant, such that p(t_k)=y_k for k=0,\\dots,n.\n\nIn this chapter, we use t_k for the nodes and x to denote the continuous independent variable.\n\nAttention\n\nThe interpolation nodes are numbered from 0 to n. This is convenient for our mathematical statements, but less so in a language such as Julia in which vector indices start with 1. Our approach is that indices in a computer code have the same meaning as those identically named in the mathematical formulas, and therefore must be incremented by one whenever used in an indexing context.","type":"content","url":"/interpolation","position":1},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Polynomials"},"type":"lvl2","url":"/interpolation#polynomials","position":2},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Polynomials"},"content":"Polynomials are the obvious first candidate to serve as interpolating functions. They are easy to work with, and in \n\nPolynomial interpolation we saw that a linear system of equations can be used to determine the coefficients of a polynomial that passes through every member of a set of given points in the plane. However, it’s not hard to find examples for which polynomial interpolation leads to unusable results.\n\nTrouble in polynomial interpolation\n\nExample 5.1.1\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nusing Plots\nn = 5\nt = range(-1, 1, n+1)\ny = @. t^2 + t + 0.05 * sin(20t)\nscatter(t, y, label=\"data\", legend=:top)\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\nusing Polynomials\np = Polynomials.fit(t, y, n)     # interpolating polynomial\nplot!(p, -1, 1, label=\"interpolant\")\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = range(-1, 1, n+1)\ny = @. t^2 + t + 0.05 * sin(20t)\nscatter(t, y, label=\"data\", leg=:top)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = Polynomials.fit(t, y, n)\nx = range(-1, 1, 1000)    # use a lot of points\nplot!(x, p.(x), label=\"interpolant\")\n\nSurely there must be functions that are more intuitively representative of those points!\n\nExample 5.1.1\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5;\nt = linspace(-1,1,n+1)';  \ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t,y)\n\nThe polynomial interpolant, as computed using polyfit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on\nfplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north');\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on, fplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north');\n\nSurely there must be functions that are more intuitively representative of those points!\n\nExample 5.1.1\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\np = poly1d(polyfit(t, y, n))  # interpolating polynomial\ntt = linspace(-1, 1, 400)\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = poly1d(polyfit(t, y, n))\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nSurely there must be functions that are more intuitively representative of those points!\n\nInterpolation by a polynomial at equally spaced nodes is ill-conditioned as the degree of the polynomial grows.\n\nIn Chapter 9 we explore the large oscillations in the last figure of \n\nDemo 5.1.1; it turns out that one must abandon either equally spaced nodes or n\\to\\infty for polynomials. In the rest of this chapter we will keep n fairly small and let the nodes be unrestricted.","type":"content","url":"/interpolation#polynomials","position":3},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Piecewise polynomials"},"type":"lvl2","url":"/interpolation#piecewise-polynomials","position":4},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Piecewise polynomials"},"content":"In order to keep polynomial degrees small while interpolating large data sets, we will choose interpolants from the piecewise polynomials. Specifically, the interpolant p must be a polynomial on each subinterval [t_{k-1},t_k] for k=1,\\ldots,n.\n\nSome examples of piecewise polynomials for the nodes  t_0=-2, t_1=0, t_2=1, and t_3=4 are p_1(x)=x+1, p_2(x)=\\operatorname{sign}(x), p_3(x)=|x-1|^{3}, and p_4(x)=(\\max\\{0,x\\})^{4}. Note that p_{1}, p_{2}, and p_4 would also be piecewise polynomial on the node set \\{t_0,t_1,t_3\\}, but p_3 would not.\n\nUsually we designate in advance a maximum degree d for each polynomial piece of p(x). An important property of the piecewise polynomials of degree d is that they form a vector space: that is, any linear combination of piecewise polynomials of degree d is another piecewise polynomial of degree d. If p and q share the same node set, then the combination is piecewise polynomial on that node set.\n\nPiecewise polynomial interpolation\n\nExample 5.1.3\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 12\nt = range(-1, 1, n+1)\ny = @. t^2 + t + 0.5 * sin(20t)\nscatter(t, y, label=\"data\", leg=:top)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\np = FNC.plinterp(t, y)\nplot!(p, -1, 1, label=\"piecewise linear\")\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\nusing Dierckx\np = Spline1D(t, y)\nplot!(x -> p(x), -1, 1, label=\"piecewise cubic\")\n\nExample 5.1.3\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using interp1 from MATLAB.\n\nx = linspace(-1, 1, 400)';\nhold on, plot(x, interp1(t, y, x))\ntitle('Piecewise linear interpolant')\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\ncla\nscatter(t, y)\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic interpolant')\n\nExample 5.1.3\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nclf\nn = 12\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.5 * sin(20 * t)\nfig, ax = subplots()\nscatter(t, y, label=\"data\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\nfrom scipy.interpolate import interp1d\ntt = linspace(-1, 1, 400)\np = interp1d(t, y, kind=\"linear\")\nax.plot(tt, p(tt), label=\"piecewise linear\")\nax.legend()\nfig\n\nWe may prefer a smoother interpolant that is piecewise cubic:\n\nscatter(t, y, label=\"data\")\np = interp1d(t, y, kind=\"cubic\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cubic spline\")\nxlabel(\"$x$\"),  ylabel(\"$y$\")\nlegend();\n\nWe will consider piecewise linear interpolation in more detail in \n\nPiecewise linear interpolation, and we look at piecewise cubic interpolation in \n\nCubic splines.","type":"content","url":"/interpolation#piecewise-polynomials","position":5},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Conditioning of interpolation"},"type":"lvl2","url":"/interpolation#conditioning-of-interpolation","position":6},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Conditioning of interpolation"},"content":"In the interpolation problem we are given the values (t_k,y_k) for k=0,\\ldots,n. Let us consider the nodes t_k of the problem to be fixed, and let a=t_0, b=t_n. Then the data for the interpolation problem consists of a vector \\mathbf{y}, and the result of the problem is a function on [a,b].\n\nLet \\mathcal{I} be a prescription for producing the interpolant from a data vector.  That is, \\mathcal{I}(\\mathbf{y})=p, where p(t_k)=y_k for all k. The interpolation methods we will consider are all linear, in the sense that\\cI(\\alpha\\mathbf{y} + \\beta\\mathbf{z}) = \\alpha \\cI(\\mathbf{y}) + \\beta \\cI(\\mathbf{z})\n\nfor all vectors \\mathbf{y},\\mathbf{z} and scalars \\alpha,\\beta.\n\nLinearity greatly simplifies the analysis of interpolation. To begin with, for any data vector \\mathbf{y} we have the standard expression \\mathbf{y}=\\sum y_k \\mathbf{e}_k, where as always \\mathbf{e}_k is a column of an identity matrix. Hence by linearity,\\cI( \\mathbf{y} ) = \\cI \\left( \\sum_{k=0}^n y_k \\mathbf{e}_k  \\right) = \\sum_{k=0}^n y_k \\cI( \\mathbf{e}_k ).\n\nThe functions appearing within the sum above have particular significance.\n\nCardinal function\n\nA cardinal function \\phi_k for a node set t_0,\\ldots,t_n is the function that interpolates the value (t_k,1) and (t_j,0) for all j\\neq k.\n\nFor any set of n+1 nodes, there are n+1 cardinal functions \\phi_0,\\ldots,\\phi_n, each singling out a different interpolation node in the set. We finish \n\n(5.1.2) by writing\\cI( \\mathbf{y} ) = \\sum_{k=0}^n y_k \\phi_k.\n\nIn the following result we use the function infinity-norm or max-norm defined by\\| f\\|_{\\infty} = \\max_{x \\in [a,b]} |f(x)|.\n\nConditioning of interpolation\n\nSuppose that \\cI is a linear interpolation method on nodes t_0,\\ldots,t_n. Then with respect to the infinity norm, the absolute condition number of \\cI satisfies\\max_{0\\le k \\le n}\\, \\bigl\\| \\phi_k \\bigr\\|_\\infty \\le \\kappa(\\mathbf{y}) \\le  \\sum_{k=0}^n  \\, \\bigl\\| \\phi_k \\bigr\\|_\\infty,\n\nwhere the \\phi_k are cardinal interpolating functions.\n\nSuppose the data vector is perturbed from \\mathbf{y} to \\mathbf{y}+ \\mathbf{d}. Then  \\cI(\\mathbf{y} + \\mathbf{d}) - \\cI(\\mathbf{y}) = \\cI(\\mathbf{d}) = \\sum_{k=0}^n d_k \\phi_k.\n\nHence\\frac{\\bigl\\|\\cI(\\mathbf{y} + \\mathbf{d}) - \\cI(\\mathbf{y}) \\bigr\\|_{\\infty}}{\\| \\mathbf{d} \\|_{\\infty}} =\n\\left\\|\\, \\sum_{k=0}^{n} \\frac{d_k}{\\|\\mathbf{d} \\|_{\\infty}} \\phi_k \\,  \\right\\|_{\\infty}.\n\nThe absolute condition number maximizes this quantity over all \\mathbf{d}. Suppose j is such that \\|\\phi_j\\|_\\infty is maximal. Then let \\mathbf{d}=\\mathbf{e}_j and the first inequality in \n\n(5.1.5) follows. The other inequality follows from the triangle inequality:\\left\\| \\, \\sum_{k=0}^{n} \\frac{d_k}{\\|\\mathbf{d} \\|_{\\infty}} \\phi_k \\,  \\right\\|_{\\infty} \\le \\sum_{k=0}^{n} \\frac{|d_k|}{\\|\\mathbf{d} \\|_{\\infty}} \\| \\phi_k \\|_\\infty.\n\nSince |d_k|\\le \\|\\mathbf{d}\\|_\\infty for all k, this finishes \n\n(5.1.5).\n\nConditioning of interpolation\n\nExample 5.1.4\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18\nt = range(-1, 1, n+1)\ny = [zeros(9); 1; zeros(n - 9)];  # data for 10th cardinal function\n\nscatter(t, y, label=\"data\")\n\nϕ = Spline1D(t, y)\nplot!(x -> ϕ(x), -1, 1;\n    label=\"spline\",\n    xlabel=L\"x\",  ylabel=L\"\\phi(x)\",\n    title=\"Piecewise cubic cardinal function\")\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nscatter(t, y, label=\"data\")\n\nϕ = Polynomials.fit(t, y, n)\nplot!(x -> ϕ(x), -1, 1;\n    label=\"polynomial\",  legend=:top,\n    xlabel=L\"x\",  ylabel=L\"\\phi(x)\", \n    title=\"Polynomial cardinal function\")\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.\n\nExample 5.1.4\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18;\nt = linspace(-1, 1, n+1)';\ny = [zeros(9, 1); 1; zeros(n - 9, 1)];    % 10th cardinal function\nclf, scatter(t, y)\nhold on\nx = linspace(-1, 1, 400)';\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic cardinal function') \nxlabel('x'), ylabel('p(x)')\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nclf, scatter(t, y)\nc = polyfit(t, y, n);\nhold on, plot(x, polyval(c, x))\ntitle('Polynomial cardinal function')\nxlabel('x'), ylabel(('p(x)'));\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.\n\nExample 5.1.4\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nclf\nn = 18\nt = linspace(-1, 1, n + 1)\ny = zeros(n + 1)\ny[9] = 1.0\np = interp1d(t, y, kind=\"cubic\")\n\nscatter(t, y, label=\"data\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cardinal function\")\ntitle(\"Cubic spline cardinal function\")\nlegend();\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\np = poly1d(polyfit(t, y, n))\nscatter(t, y, label=\"data\")\nplot(tt, p(tt), label=\"cardinal function\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\ntitle(\"Polynomial cardinal function\")\nlegend();\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/interpolation#conditioning-of-interpolation","position":7},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Exercises"},"type":"lvl2","url":"/interpolation#exercises","position":8},{"hierarchy":{"lvl1":"The interpolation problem","lvl2":"Exercises"},"content":"⌨ Create data by enteringt = -2:4;  y = tanh.(t);\n\n(a) Use fit to construct and plot the polynomial interpolant of the data, superimposed on a scatter plot of the data.\n\n(b) Use Spline1D to construct and plot a piecewise cubic interpolant of the data, superimposed on a scatter plot of the data.\n\n⌨ The following table gives the life expectancy in the U.S. by year of birth.\n\n1980\n\n1985\n\n1990\n\n1995\n\n2000\n\n2005\n\n2010\n\n73.7\n\n74.7\n\n75.4\n\n75.8\n\n77.0\n\n77.8\n\n78.7\n\n(a) Defining “year since 1980” as the independent variable, use fit to construct and plot the polynomial interpolant of the data.\n\n(b) Use Spline1D to construct and plot a piecewise cubic interpolant of the data.\n\n(c) Use both methods to estimate the life expectancy for a person born in 2007. Which value is more believable?\n\n⌨ The following two vectors define a flying saucer shape.x = [ 0,0.51,0.96,1.06,1.29,1.55,1.73,2.13,2.61,\n      2.19,1.76,1.56,1.25,1.04,0.58,0 ]\ny = [ 0,0.16,0.16,0.43,0.62,0.48,0.19,0.18,0,\n      -0.12,-0.12,-0.29,-0.30,-0.15,-0.16,0 ]\n\nWe can regard both x and y as functions of a parameter s, with the points being values given at s=0,1,\\ldots,15.\n\n(a) Use Spline1D once on each coordinate as functions of s, and make a picture of the flying saucer.\n\n(b) One drawback of the result in part (a) is the noticeable corner at the left side, which corresponds to s=0 from above and s=15 from below. There is a periodic variation on cubic spline interpolation that you can invoke by adding the keyword periodic=true to the Spline1D call. Use this to re-plot the flying saucer.\n\n✍ Defineq(s) = a\\frac{s(s-1)}{2} - b (s-1)(s+1) + c \\frac{s(s+1)}{2}.\n\n(a) Show that q is a polynomial interpolant of the points (-1,a), (0,b), (1,c).\n\n(b) Find a change of variable s=Ax+B so that the values s=-1,0,1 correspond to x=x_0-h,x_0,x_0+h.\n\n(c) Find a quadratic polynomial interpolant \\tilde{q}(x) for the points (x_0-h,a), (x_0,b), (x_0+h,c).\n\n✍ (continuation) Use the result of the previous exercise and \n\nTheorem 5.1.1 to derive bounds on the condition number of quadratic polynomial interpolation at the nodes x_0-h, x_0, x_0+h.\n\nTo be precise, we are using \\mathbf{e}_k to mean column number k+1 from an (n+1)\\times (n+1) identity matrix, since in linear algebra we start indexing at 1.","type":"content","url":"/interpolation#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-4","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The algorithmic possibilities for piecewise linear and cubic spline approximation are explored in a different way in Van Loan \n\nVan Loan (2000).  In that source, a binary search is used to find the interval for evaluating the piecewise polynomial interpolant.\n\nFurther details regarding the derivation of the cubic spline equations, with an emphasis on minimizing memory usage, may be found in a number of sources, e.g., Burden and Faires \n\nBurden & Faires (2001), Cheney and Kincaid \n\nCheney & Kincaid (2012), and Atkinson and Han \n\nAtkinson & Han (2004). Comprehensive theoretical results can be found in de Boor \n\nde Boor (1978).\n\nOn a historical note, Carl de Boor was elected to several National Academies of Science (USA, Poland, and Germany, e.g.) and was awarded the (USA) National Medal of Science in 2003 for his work on splines.  Splines continue to be important for computer-aided design and computer graphics, among other applications.\n\nAn excellent and pragmatic introduction to finite-difference methods is by Fornberg \n\nFornberg (1998). Numerical integration is a large topic unto itself; one longer introduction to it is by Davis and Rabinowitz \n\nDavis & Rabinowitz (2014).","type":"content","url":"/next-4","position":1},{"hierarchy":{"lvl1":"5. Piecewise interpolation"},"type":"lvl1","url":"/overview-4","position":0},{"hierarchy":{"lvl1":"5. Piecewise interpolation"},"content":"You must feel the Force around you. Here, between you...me...the tree...the rock...everywhere!\n\nYoda, The Empire Strikes Back\n\nIn many scientific problems the solution is a function. Accordingly, our next task is to represent functions numerically. This task is more difficult and complicated than the one we faced in representing real numbers. With numbers it’s intuitively clear how one real value can stand for a small interval around it. But designating representatives for sets of functions is less straightforward—in fact, it’s one of the core topics in computing. The process of converting functions into numerical representations of finite length is known as discretization.\n\nOnce we have selected a method of discretization, we can define numerical analogs of our two favorite operations on functions, differentiation and integration. These are linear operations, so the most natural numerical analogs are linear operations too. As we will see in many of the chapters following this one, a lot of numerical computing boils down to converting calculus to algebra, with discretization as the link between them.","type":"content","url":"/overview-4","position":1},{"hierarchy":{"lvl1":"Piecewise linear interpolation"},"type":"lvl1","url":"/pwlin","position":0},{"hierarchy":{"lvl1":"Piecewise linear interpolation"},"content":"Piecewise linear interpolation is simply a game of connect-the-dots. That is, the data points are joined pairwise by line segments.\n\nPiecewise linear interpolant\n\nGiven nodes t_0 < t_1 < \\cdots < t_n, the piecewise linear interpolant p(x) is given byp(x) = y_k + \\frac{y_{k+1}-y_k}{t_{k+1}-t_k}(x-t_k) \\quad \\text{ for } x\\in[t_k,t_{k+1}].\n\nIt should be clear from \n\n(5.2.1) that on each interval [t_k,t_{k+1}], p(x) is a linear function passing through both (t_k,y_k) and (t_{k+1},y_{k+1}).","type":"content","url":"/pwlin","position":1},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Hat functions"},"type":"lvl2","url":"/pwlin#hat-functions","position":2},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Hat functions"},"content":"Rather than basing an implementation on \n\n(5.2.1), we return to the idea used in \n\nDemo 2.1.1 of choosing the interpolant from among the linear combinations of a preselected finite set of functions. In the present context we use, for k=0,\\ldots,n,  H_k(x) =\n  \\begin{cases}\n    \\dfrac{x-t_{k-1}}{t_k-t_{k-1}} & \\text{if $x\\in[t_{k-1},t_k]$},\\\\[2.5ex]\n    \\dfrac{t_{k+1}-x}{t_{k+1}-t_{k}} & \\text{if $x\\in[t_{k},t_{k+1}]$},\\\\[2.5ex]\n    0 & \\text{otherwise}.\n  \\end{cases} \\qquad\n\nThe functions H_0,\\ldots,H_n are called hat functions. They depend on the node vector \\mathbf{t}, but this dependence is not usually indicated explicitly.\n\nEach hat function is globally continuous and is linear inside every interval [t_k,t_{k+1}].  Consequently, any linear combination of them will have the same property. Furthermore, any such function is expressible as a unique linear combination of hat functions, i.e.,  \\sum_{k=0}^n c_k H_k(x)\n\nfor some choice of the coefficients c_0,\\ldots,c_n. No smaller set of functions can have the same properties. We summarize these facts by calling the hat functions a basis of the set of functions that are continuous and piecewise linear relative to \\mathbf{t}.  Another point of view, familiar from abstract linear algebra, is that a basis sets up a one-to-one correspondence between the spanned function space and the more familiar space \\mathbb{R}^{n+1}, with each function being represented by its coefficients c_0,\\ldots,c_n.\n\nAn appealing characteristic of the hat function basis is that it depends only on the node locations, while the expansion coefficients in \n\n(5.2.3) depend only on the data values. This clean separation would be useful if we wanted to construct many interpolants on the same node set, and it has deeper theoretical uses as well.\n\nFunction 5.2.1 presents a simple implementation of hat functions. The inputs are a presorted vector of nodes and a value of k between 0 and n, which represent the indices of the endpoints. The return value is a function of x that can be evaluated as needed. Note that we have not formally defined values for a hat function outside of the node interval; our choice in \n\nFunction 5.2.1 is to make it zero there.\n\nhatfun\n\nHat function\n\n\"\"\"\n    hatfun(t, k)\n\nCreate a piecewise linear hat function, where `t` is a\nvector of n+1 interpolation nodes and `k` is an integer in 0:n\ngiving the index of the node where the hat function equals one.\n\"\"\"\nfunction hatfun(t, k)\n    n = length(t) - 1\n    return function (x)\n        if k > 0 && t[k] ≤ x ≤ t[k+1]\n            return (x - t[k]) / (t[k+1] - t[k])\n        elseif k < n && t[k+1] ≤ x ≤ t[k+2]\n            return (t[k+2] - x) / (t[k+2] - t[k+1])\n        else\n            return 0\n        end\n    end\nend\n\nHat function\n\nfunction H = hatfun(t, k)\r\n% HATFUN   Hat function/piecewise linear basis function.\r\n% Input: \r\n%   t      interpolation nodes (vector, length n+1)\r\n%   k      node index (integer, in 0,...,n)\r\n% Output:\r\n%   H      kth hat function (function)\r\n\r\nn = length(t) - 1;\r\n\r\nfunction y = evaluate(x)\r\n    y = zeros(size(x));\r\n    for i = 1:numel(x)\r\n        if (k > 0) && (t(k) <= x(i)) && (x(i) <= t(k+1))\r\n            y(i) = (x(i) - t(k)) / (t(k+1) - t(k));\r\n        elseif (k < n) && (t(k+1) <= x(i)) && (x(i) <= t(k+2))\r\n            y(i) = (t(k+2) - x(i)) / (t(k+2) - t(k+1));\r\n        end\r\n    end\r\nend\r\n\r\nH = @evaluate;\r\nend\n\nHat function\n\ndef hatfun(t, k):\n    \"\"\"\n    hatfun(t, k)\n\n    Returns a piecewise linear \"hat\" function,  where t is a vector of\n    n+1 interpolation nodes and k is an integer in 0:n giving the index of the node\n    where the hat function equals one.\n    \"\"\"\n    n = len(t) - 1\n\n    def evaluate(x):\n        H = np.zeros(np.array(x).shape)\n        for (j, xj) in enumerate(x):\n            if (k > 0) and (t[k-1] <= xj) and (xj <= t[k]):\n                H[j] = (xj - t[k-1]) / (t[k] - t[k-1])\n            elif (k < n) and (t[k] <= xj) and (xj <= t[k+1]):\n                H[j] = (t[k+1] - xj) / (t[k+1] - t[k])\n        return H\n    return evaluate\n\nA look at hat functions\n\nExample 5.2.1\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1]\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nTip\n\nUse annotate! to add text to a plot.\n\nusing Plots\nplt = plot(layout=(4, 1),  legend=:top,\n    xlabel=L\"x\",  ylims=[-0.1, 1.1],  ytick=[])\nfor k in 0:3\n    Hₖ = FNC.hatfun(t, k)\n    plot!(Hₖ, 0, 1, subplot=k + 1)\n    scatter!(t, Hₖ.(t), m=3, subplot=k + 1)\n    annotate!(t[k+1], 0.25, text(latexstring(\"H_$k\"), 10), subplot=k+1)\nend\nplt\n\nExample 5.2.1\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1];\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nclf\nfor k = 0:3\n    subplot(4, 1, k+1)\n    Hk = hatfun(t, k);\n    fplot(Hk, [0, 1])\n    hold on\n    scatter(t, Hk(t))\n    text(t(k+1), 0.6, sprintf(\"H_%d\", k))\nend\n\nExample 5.2.1\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nx = linspace(0, 1, 300)\nfor k in range(6):\n    plot(x, FNC.hatfun(t, k)(x))\nxlabel(\"$x$\"),  ylabel(\"$H_k(x)$\")\ntitle(\"Hat functions\");","type":"content","url":"/pwlin#hat-functions","position":3},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Cardinality conditions"},"type":"lvl2","url":"/pwlin#cardinality-conditions","position":4},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Cardinality conditions"},"content":"A handy property of the hat functions is that they are cardinal functions for piecewise linear interpolation, since they satisfy the cardinality conditionsH_k(t_i) =\n\\begin{cases}\n  1 &\\text{if $i=k$,}\\\\\n  0 & \\text{otherwise.}\n\\end{cases}\n\nAll candidate piecewise linear (PL) functions can be expressed as a linear combination such as \n\n(5.2.3) for some coefficients c_0,\\ldots,c_n. But because of the cardinality conditions and the necessity for p(x) to interpolate the data values in \\mathbf{y}, expressing the interpolant using the hat functions is trivial:  p(x) = \\sum_{k=0}^n y_k H_k(x).\n\nThe resulting algorithmic simplicity is reflected in \n\nFunction 5.2.2. Take note that the output of \n\nFunction 5.2.2 is itself a function, meant to be called with a single argument representing a value of x. Our mathematical viewpoint is that the result of an interpolation process is a function, and our codes reflect this.\n\nplinterp\n\nPiecewise linear interpolation\n\n\"\"\"\n    plinterp(t, y)\n\nConstruct a piecewise linear interpolating function for data values in\n`y` given at nodes in `t`.\n\"\"\"\nfunction plinterp(t, y)\n    n = length(t) - 1\n    H = [hatfun(t, k) for k in 0:n]\n    return x -> sum(y[k+1] * H[k+1](x) for k in 0:n)\nend\n\nPiecewise linear interpolation\n\nfunction p = plinterp(t,y)\r\n% PLINTERP   Piecewise linear interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   p     piecewise linear interpolant (function)\r\n\r\nn = length(t) - 1;\r\nH = {};\r\nfor k = 0:n\r\n    H{k+1} = hatfun(t, k);\r\nend\r\np = @evaluate;\r\n\r\n    % This function evaluates p when called.\r\n    function f = evaluate(x)\r\n        f = 0;\r\n        for k = 0:n\r\n            f = f + y(k+1) * H{k+1}(x);\r\n        end\r\n    end\r\n\r\nend\n\nPiecewise linear interpolation\n\ndef plinterp(t, y):\n    \"\"\"\n    plinterp(t, y)\n\n    Create a piecewise linear interpolating function for data values in y given at nodes\n    in t.\n    \"\"\"\n    n = len(t) - 1\n    H = [hatfun(t, k) for k in range(n+1)]\n    def evaluate(x):\n        f = 0\n        for k in range(n+1):\n            f += y[k] * H[k](x)\n        return f\n    return evaluate\n\nUsing piecewise linear interpolation\n\nExample 5.2.2\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = x -> exp(sin(7x))\n\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]    # nodes\ny = f.(t)                             # function values\nscatter!(t, y, label=\"values at nodes\")\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"PL interpolation\")\n\nExample 5.2.2\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = @(x) exp(sin(7 * x));\nclf\nfplot(f, [0, 1], displayname=\"function\")\nxlabel(\"x\");  ylabel((\"y\"));\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % function values\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = plinterp(t, y);\nhold on\nfplot(p, [0, 1], displayname=\"interpolant\")\nscatter(t, y, displayname=\"values at nodes\")\ntitle(\"PL interpolation\")\nlegend();\n\nExample 5.2.2\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 400)\nfig, ax = subplots()\nplot(x, f(x), label=\"function\")\nxlabel(\"$x$\")\nylabel(\"$f(x)$\");\n\nFirst we sample the function to create the data.\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # function values\n\nax.plot(t, y, \"o\", label=\"nodes\")\nax.legend()\nfig\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nax.plot(x, p(x), label=\"interpolant\")\nax.legend()\nfig","type":"content","url":"/pwlin#cardinality-conditions","position":5},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Conditioning and convergence"},"type":"lvl2","url":"/pwlin#conditioning-and-convergence","position":6},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Conditioning and convergence"},"content":"The condition number bounds from \n\nTheorem 5.1.1 are very simple for piecewise linear interpolation because the interpolant of the data \\mathbf{e}_k is just the hat function H_k. Hence 1\\le \\kappa \\le n+1. However, there is an even simpler result.\n\nConditioning of PL interpolation\n\nThe absolute condition number of piecewise linear interpolation in the infinity norm equals 1. More specifically, if \\mathcal{I} is the piecewise linear interpolation operator, then\\| \\mathcal{I}(\\mathbf{y}+\\mathbf{z}) - \\mathcal{I}(\\mathbf{y}) \\|_\\infty = \\|\\mathbf{z}\\|_\\infty.\n\n(The norm on the left side is on functions, while the norm on the right side is on vectors.)\n\nBy linearity,\\mathcal{I}(\\mathbf{y}+\\mathbf{z}) - \\mathcal{I}(\\mathbf{y}) = \\mathcal{I}(\\mathbf{z}) = \\sum_{k=0}^n z_k H_k(x).\n\nCall this piecewise linear function p(x). Consider a maximum element of \\mathbf{z}, i.e., choose i such that |z_i|=\\|\\mathbf{z}\\|_\\infty. Then |p(t_i)|=\\|\\mathbf{z}\\|_\\infty. Hence \\|p\\|_\\infty\\ge \\|\\mathbf{z}\\|_\\infty. Now consider|p(x)| = \\left|\\sum_{k=0}^n z_k H_k(x)\\right| \\le \\sum_{k=0}^n |z_k| H_k(x) \\le \\|\\mathbf{z}\\|_\\infty \\sum_{k=0}^n H_k(x) = \\|\\mathbf{z}\\|_\\infty.\n\nYou are asked to prove the final step above in \n\nExercise 4. We conclude that  \\|p\\|_\\infty\\le \\|\\mathbf{z}\\|_\\infty, so that \\|p\\|_\\infty = \\|\\mathbf{z}\\|_\\infty, which completes the proof.\n\nNow suppose that f is a “nice” function on an interval [a,b] containing all of the nodes. We can sample values of f to get data, i.e., y_k=f(t_k) for all k, then perform piecewise linear interpolation of the data to get a different function, the interpolant p. How close is p to the original f?\n\nTo make a simple statement, we will consider only the case of equally spaced nodes covering the interval. It turns out that piecewise linear interpolation converges at second order in the spacing of the nodes.\n\nConvergence of PL interpolation\n\nSuppose that f(x) has a continuous second derivative in [a,b] (often expressed as f\\in C^2([a,b])). Let p_n(x) be the piecewise linear interpolant of \\bigl(t_i,f(t_i)\\bigr) for i=0,\\ldots,n, where t_i=a+i h and h=(b-a)/n. Then\\bigl\\| f - p_n \\bigr\\|_\\infty = \\max_{x \\in [a,b]}\n|f(x)-p(x)| \\le M h^2,\n\nwhere M = \\bigl\\| f'' \\bigr\\|_\\infty.\n\nFor an outline of a proof, see \n\nExercise 5.\n\nWe normally don’t have access to f'', so the importance of \n\nTheorem 5.2.2 is that the error in the interpolant is O(h^2) as h\\to 0.\n\nAlgebraic convergence\n\nIf an approximation has error that is O(h^m) as h\\to 0 for an integer m and a discretization size parameter h, then we say the approximation has algebraic convergence. If the error is not also O(h^{m+1}), then m is the order of accuracy.\n\nThus, \n\nTheorem 5.2.2 states that piecewise linear interpolation is second-order accurate. For instance, if we increase the number of equally spaced nodes by a factor of 10, the piecewise linear interpolant becomes about 100 times more accurate. Note also that if y \\approx C h^m, then\\log y \\approx m (\\log h) + \\log C.\n\nHence a log-log graph of error versus h should be approximately a straight line of slope m.\n\nConvergence of piecewise linear interpolation\n\nExample 5.2.3\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = x -> exp(sin(7x))\nx = range(0, 1, 10001)  # sample the difference at many points\nn = @. round(Int, 10^(1:0.25:3.5))\nmaxerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    t = (0:n) / n    # interpolation nodes\n    p = FNC.plinterp(t, f.(t))\n    err = @. f(x) - p(x)\n    maxerr[k] = norm(err, Inf)\nend\n\ndata = (n=n[1:4:end], err=maxerr[1:4:end])\n@pt :header=[\"n\", \"max-norm error\"] data\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nh = @. 1 / n\norder2 = @. 10 * (h / h[1])^2\n\nplot(h, maxerr, m=:o, label=\"error\", xflip=true)\nplot!(h, order2;\n    l=:dash,  label=L\"O(h^2)\",\n    xaxis=(:log10, L\"h\"),  yaxis=(:log10, L\"|| f-p\\, ||_\\infty\"),\n    title=\"Convergence of PL interpolation\")\n\nExample 5.2.3\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = @(x) exp(sin(7 * x));\nx = linspace(0, 1, 10001)';    % sample the difference at many points\nn = round(10.^(1:0.25:3.5))';\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i)) / n(i);       % interpolation nodes\n    p = plinterp(t, f(t));\n    maxerr(i) = norm(f(x) - p(x), Inf);\nend\ntable(n(1:4:end), maxerr(1:4:end), variableNames=[\"n\", \"inf-norm error\"])\n\nAs predicted, a factor of 10 in n produces a factor of 100 reduction in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder2 = 0.5 * maxerr(end) * (n / n(end)) .^ (-2);\nhold on\nloglog(n, order2, \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"|| f-p ||_{\\infty}\")\ntitle(\"Convergence of PL interpolation\")\nlegend();\n\nExample 5.2.3\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 10000)  # sample the difference at many points\nN = 2 ** arange(3, 11)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.plinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\norder2 = 0.1 * (N / N[0]) ** (-2)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order2, \"--\", label=\"2nd order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-p\\|_\\infty$\")\nlegend();","type":"content","url":"/pwlin#conditioning-and-convergence","position":7},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/pwlin#exercises","position":8},{"hierarchy":{"lvl1":"Piecewise linear interpolation","lvl2":"Exercises"},"content":"⌨ For each given function and interval, perform piecewise linear interpolation using \n\nFunction 5.2.2 for n+1 equispaced nodes with n=10,20,40,80,160,320. For each n, estimate the errorE(n) = \\| f-p \\|_\\infty = \\max_x | f(x) - p(x) |\n\nby evaluating the function and interpolant at 1600 points in the interval. Make a log-log plot of E as a function of n and add the line E=Cn^{-2} for a constant C of your choosing.\n\n(a) \\cos(\\pi x^2) on [0,4]\n\n(b) \\log(x) on [1,20]\n\n(c) \\sin\\left(\\frac{1}{x}\\right) on \\left[\\frac{1}{2},7\\right]\n\n✍ For this problem, let H(x) be the hat function that passes through the three points (-1,0), (0,1), and (1,0).\n\n(a) Write out a piecewise definition of H in the style of \n\n(5.2.2).\n\n(b) Define the function Q by Q(x) = \\int_{x-1}^x H(t)\\, dt. Find a piecewise formula for Q(x). (Hint: Perform the integration separately for the cases -1\\le x \\le 0, 0\\le x \\le 1, etc.)\n\n(c) Make a sketch of Q(x) for -2\\le x \\le 2.\n\n(d) Show that Q is continuous. Are Q' and Q''?\n\n✍ Before electronic calculators, the function \\ln(x) was often computed using piecewise linear interpolation with a table of values. If you were using such a table at the nodes 3.1,3.2,\\ldots,3.9,4, what is an upper bound on the error in the result?\n\n✍ Show that for any node distribution and any x\\in[t_0,t_n],\\sum_{k=0}^n H_k(x) = 1.\n\n(Hint: The simplest way is to apply \n\n(5.2.5).) This is called the partition of unity property.\n\n✍ Here we consider a proof of \n\nTheorem 5.2.2 using the mean value theorems from elementary calculus: If f is continuously differentiable in (a,b), then there exist points s and t in (a,b) such that\\int_a^b f(z) \\, dz = (b-a)f(s) \\qquad \\text{and} \\qquad f'(t) = \\frac{f(b)-f(a)}{b-a}.\n\nFor the following, suppose x \\in (t_k,t_{k+1}).\n\n(a) Show that for some s \\in (t_k,t_{k+1}),f(x) = y_k + (x-t_k)f'(s).\n\n(b) Show that for some other values u and v in (t_k,t_{k+1}),f'(s) -  \\frac{y_{k+1}-y_k}{t_{k+1}-t_k} = (s-u) f''(v).\n\n(c) Use \n\n(5.2.1) to finish the proof of the theorem.","type":"content","url":"/pwlin#exercises","position":9},{"hierarchy":{"lvl1":"Cubic splines"},"type":"lvl1","url":"/splines","position":0},{"hierarchy":{"lvl1":"Cubic splines"},"content":"A piecewise linear interpolant is continuous but has discontinuities in its derivative. We often desire a smoother interpolant, i.e., one that has some continuous derivatives. By far the most popular choice is piecewise cubic.\n\nCubic spline\n\nA cubic spline is a piecewise cubic function that has two continuous derivatives everywhere.\n\nWe use S(x) to denote the cubic spline interpolant. As before, suppose that distinct nodes t_0 < t_1 < \\cdots < t_n (not necessarily equally spaced) and data y_0,\\ldots,y_n are given. For any k=1,\\ldots,n, the spline S(x) on the interval [t_{k-1},t_k] is by definition a cubic polynomial S_k(x), which we express as S_k(x) = a_k + b_k(x-t_{k-1}) + c_k(x-t_{k-1})^2 + d_k(x-t_{k-1})^3, \\qquad k=1,\\ldots,n,\n\nwhere a_k,b_k,c_k,d_k are values to be determined. Overall there are 4n such undetermined coefficients.","type":"content","url":"/splines","position":1},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Smoothness conditions"},"type":"lvl2","url":"/splines#smoothness-conditions","position":2},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Smoothness conditions"},"content":"We are able to ensure that S has at least two continuous derivatives everywhere by means of the following constraints.\n\n1. Interpolation by S_k at both of its endpoints.\n\nAlgebraically we require S_k(t_{k-1})=y_{k-1} and S_k(t_k)=y_k for every k=1,\\dots,n. In terms of \n\n(5.3.1), these conditions area_k = y_{k-1},    a_k + b_k  h_k + c_k h_k^2 + d_k h_k^3 = y_{k}, \\qquad k=1,\\ldots,n,\n\nwhere we have used the definitionh_k = t_{k}-t_{k-1}, \\qquad k=1,\\ldots,n.\n\nThe values of h_k are derived from the nodes. Crucially, the unknown coefficients appear only linearly in the constraint equations. So we will express the constraints using linear algebra. The left endpoint interpolation constraints \n\n(5.3.2) are, in matrix form,\\begin{bmatrix}\n  \\mathbf{I} & \\boldsymbol{0} & \\boldsymbol{0} & \\boldsymbol{0}\n\\end{bmatrix}\n\\begin{bmatrix}\n    \\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n\\end{bmatrix}\n=\n  \\begin{bmatrix}\n  y_0 \\\\ \\vdots \\\\ y_{n-1}\n\\end{bmatrix},\n\nwith \\mathbf{I} being an n\\times n identity. The right endpoint interpolation constraints, given by \n\n(5.3.3), become\\begin{bmatrix}\n  \\mathbf{I} & \\mathbf{H} & \\mathbf{H}^2 & \\mathbf{H}^3\n\\end{bmatrix}\n\\begin{bmatrix}\n  \\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n\\end{bmatrix}\n  =\n\\begin{bmatrix}\n  y_1 \\\\ \\vdots \\\\ y_{n}\n\\end{bmatrix},\n\nwhere we have defined the diagonal matrix\\mathbf{H}  =\n\\begin{bmatrix}\n  h_1 & & & \\\\ & h_2 & & \\\\ & & \\ddots & \\\\ & & & h_n\n\\end{bmatrix}.\n\nCollectively, \n\n(5.3.5) and \n\n(5.3.6) express 2n scalar constraints on the unknowns.\n\n2. Continuity of S'(x) at interior nodes.\n\nWe do not know what the slope of the interpolant should be at the nodes, but we do want the same slope whether a node is approached from the left or the right. Thus we obtain constraints at the nodes that sit between two neighboring piecewise definitions, so that S_1'(t_1)=S_2'(t_1), and so on. Altogether these areb_k + 2 c_k h_k + 3 d_k h_k^2 = b_{k+1}, \\qquad k=1,\\dots,n-1.\n\nMoving the unknowns to the left side, as a system these become\\mathbf{E}\n\\begin{bmatrix}\n  \\boldsymbol{0} & \\mathbf{J} & 2\\mathbf{H} & 3\\mathbf{H}^2\n\\end{bmatrix}\n\\begin{bmatrix}\n  \\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n  \\end{bmatrix}\n= \\boldsymbol{0},\n\nwhere now we have defined\\mathbf{J} =\n\\begin{bmatrix}\n  1  & -1 & & & \\\\ & 1 & -1 & & \\\\ & & \\ddots & \\ddots & \\\\ & & &1 & -1 \\\\ & & & & 1\n\\end{bmatrix},\n\nand \\mathbf{E} is the (n-1)\\times n matrix resulting from deleting the last row of the identity:\\mathbf{E} =\n\\begin{bmatrix}\n  1  & 0 & & & \\\\ & 1 & 0 & & \\\\ & & \\ddots & \\ddots & \\\\ & & & 1&  0\n\\end{bmatrix}.\n\nLeft-multiplying by \\mathbf{E} deletes the last row of any matrix or vector. Hence \n\n(5.3.9) represents n-1 constraints on the unknowns. (Remember, there are only n-1 interior nodes.)\n\n3. Continuity of S''(x) at interior nodes.\n\nThese again apply only at the interior nodes t_1,\\dots,t_{n-1}, in the form S_1''(t_1)=S_2''(t_1) and so on. Using \n\n(5.3.1) once more, we obtain  2 c_k + 6 d_k h_k = 2c_{k+1}, \\qquad k=1,\\dots,n-1.\n\nIn system form (after canceling a factor of 2 from each side) we get\\mathbf{E}\n\\begin{bmatrix}\n\\boldsymbol{0} & \\boldsymbol{0} & \\mathbf{J} & 3\\mathbf{H}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{a} \\\\ \\mathbf{b} \\\\ \\mathbf{c} \\\\ \\mathbf{d}\n\\end{bmatrix}\n= \\boldsymbol{0}.","type":"content","url":"/splines#smoothness-conditions","position":3},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"End conditions"},"type":"lvl2","url":"/splines#end-conditions","position":4},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"End conditions"},"content":"So far the equations \n\n(5.3.5),  \n\n(5.3.6),  \n\n(5.3.9), and \n\n(5.3.13) form 2n+(n-1)+(n-1)=4n-2 linear conditions on the 4n unknowns in the piecewise definition \n\n(5.3.1). In order to obtain a square system, we must add two more constraints. If the application prescribes values for S' or S'' at the endpoints, those may be applied. Otherwise there are two major alternatives:\n\nNatural spline: \\quad S_1''(t_0)=S_n''(t_n)=0\n\nNot-a-knot spline: \\quad S_1'''(t_1)=S_2'''(t_1), \\;  S_{n-1}'''(t_{n-1})=S_n'''(t_{n-1})\n\nWhile natural splines have important theoretical properties, not-a-knot splines give better pointwise accuracy, and they are the only type we consider further.\n\nIn the not-a-knot spline, the values and first three derivatives of the cubic polynomials S_1 and S_2 agree at the node t_1. Hence they must be the same cubic polynomial! The same is true of S_{n-1} and S_n. We could use these facts to eliminate some of the undetermined coefficients from our linear system of constraints. However, rather than rework the algebra we just append two more rows to the system, expressing the conditionsd_1=d_2, \\quad  d_{n-1}=d_n.\n\nCollectively, \n\n(5.3.5),  \n\n(5.3.6),  \n\n(5.3.9),  \n\n(5.3.13), and \n\n(5.3.14) comprise a square linear system of size 4n which can be solved for the coefficients defining the piecewise cubics in \n\n(5.3.1). This is a major difference from the piecewise linear interpolant, for which there is no linear system to solve. Indeed, while it is possible to find a basis for the cubic spline interpolant analogous to the hat functions, it is not possible in closed form to construct a cardinal basis, so the solution of a linear system cannot be avoided.","type":"content","url":"/splines#end-conditions","position":5},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Implementation"},"type":"lvl2","url":"/splines#implementation","position":6},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Implementation"},"content":"spinterp\n\nCubic spline interpolation\n\n\"\"\"\n    spinterp(t, y)\n\nConstruct a cubic not-a-knot spline interpolating function for data\nvalues in `y` given at nodes in `t`.\n\"\"\"\nfunction spinterp(t, y)\n    n = length(t) - 1\n    h = [t[k+1] - t[k] for k in 1:n]\n\n    # Preliminary definitions.\n    Z = zeros(n, n)\n    In = I(n)\n    E = In[1:n-1, :]\n    J = diagm(0 => ones(n), 1 => -ones(n - 1))\n    H = diagm(0 => h)\n\n    # Left endpoint interpolation:\n    AL = [In Z Z Z]\n    vL = y[1:n]\n\n    # Right endpoint interpolation:\n    AR = [In H H^2 H^3]\n    vR = y[2:n+1]\n\n    # Continuity of first derivative:\n    A1 = E * [Z J 2 * H 3 * H^2]\n    v1 = zeros(n - 1)\n\n    # Continuity of second derivative:\n    A2 = E * [Z Z J 3 * H]\n    v2 = zeros(n - 1)\n\n    # Not-a-knot conditions:\n    nakL = [zeros(1, 3 * n) [1 -1 zeros(1, n - 2)]]\n    nakR = [zeros(1, 3 * n) [zeros(1, n - 2) 1 -1]]\n\n    # Assemble and solve the full system.\n    A = [AL; AR; A1; A2; nakL; nakR]\n    v = [vL; vR; v1; v2; 0; 0]\n    z = A \\ v\n\n    # Break the coefficients into separate vectors.\n    rows = 1:n\n    a = z[rows]\n    b = z[n.+rows]\n    c = z[2*n.+rows]\n    d = z[3*n.+rows]\n    S = [Polynomial([a[k], b[k], c[k], d[k]]) for k in 1:n]\n\n    # This function evaluates the spline when called with a value\n    # for x.\n    return function (x)\n        if x < t[1] || x > t[n+1]    # outside the interval\n            return NaN\n        elseif x == t[1]\n            return y[1]\n        else\n            k = findlast(x .> t)    # last node to the left of x\n            return S[k](x - t[k])\n        end\n    end\nend\n\nCubic spline interpolation\n\nfunction S = spinterp(t,y)\r\n% SPINTERP   Cubic not-a-knot spline interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   S     not-a-knot cubic spline (function)\r\n\r\nt = t(:);  y = y(:);  % ensure column vectors\r\nn = length(t)-1;\r\nh = diff(t);          % differences of all adjacent pairs\r\n\r\n% Preliminary definitions.\r\nZ = zeros(n);\r\nI = eye(n);  E = I(1:n-1,:);\r\nJ = I - diag(ones(n-1,1),1);\r\nH = diag(h);\r\n\r\n% Left endpoint interpolation:\r\nAL = [ I, Z, Z, Z ];\r\nvL = y(1:n);\r\n\r\n% Right endpoint interpolation:\r\nAR = [ I, H, H^2, H^3 ];\r\nvR = y(2:n+1);\r\n\r\n% Continuity of first derivative:\r\nA1 = E*[ Z, J, 2*H, 3*H^2 ];\r\nv1 = zeros(n-1,1);\r\n\r\n% Continuity of second derivative:\r\nA2 = E*[ Z, Z, J, 3*H ];\r\nv2 = zeros(n-1,1);\r\n\r\n% Not-a-knot conditions:\r\nnakL = [ zeros(1,3*n), [1,-1, zeros(1,n-2)] ];\r\nnakR = [ zeros(1,3*n), [zeros(1,n-2), 1,-1] ];\r\n\r\n% Assemble and solve the full system.\r\nA = [ AL; AR; A1; A2; nakL; nakR ];\r\nv = [ vL; vR; v1; v2; 0 ;0 ];\r\nz = A\\v;\r\n\r\n% Break the coefficients into separate vectors.\r\nrows = 1:n;\r\na = z(rows);\r\nb = z(n+rows);  c = z(2*n+rows);  d = z(3*n+rows);\r\nS = @evaulate;\r\n\r\n    % This function evaluates the spline when called with a value for x.\r\n    function f = evaulate(x)\r\n        f = zeros(size(x));\r\n        for k = 1:n       % iterate over the pieces\r\n            % Evalaute this piece's cubic at the points inside it.\r\n            index = (x>=t(k)) & (x<=t(k+1));   \r\n            f(index) = polyval( [d(k),c(k),b(k),a(k)], x(index)-t(k) );\r\n        end\r\n    end\r\n\r\nend\n\nCubic spline interpolation\n\ndef spinterp(t, y):\n    \"\"\"\n    spinterp(t, y)\n\n    Create a cubic not-a-knot spline interpolating function for data values in y given at nodes in t.\n    \"\"\"\n    n = len(t) - 1\n    h = [t[i + 1] - t[i] for i in range(n)]\n\n    # Preliminary definitions.\n    Z = np.zeros([n, n])\n    I = np.eye(n)\n    E = I[: n - 1, :]\n    J = np.eye(n) + np.diag(-np.ones(n - 1), 1)\n    H = np.diag(h)\n\n    # Left endpoint interpolation:\n    AL = np.hstack([I, Z, Z, Z])\n    vL = y[:-1]\n\n    # Right endpoint interpolation:\n    AR = np.hstack([I, H, H**2, H**3])\n    vR = y[1:]\n\n    # Continuity of first derivative:\n    A1 = E @ np.hstack([Z, J, 2 * H, 3 * H**2])\n    v1 = np.zeros(n - 1)\n\n    # Continuity of second derivative:\n    A2 = E @ np.hstack([Z, Z, J, 3 * H])\n    v2 = np.zeros(n - 1)\n\n    # Not-a-knot conditions:\n    nakL = np.hstack([np.zeros(3 * n), np.hstack([1, -1, np.zeros(n - 2)])])\n    nakR = np.hstack([np.zeros(3 * n), np.hstack([np.zeros(n - 2), 1, -1])])\n\n    # Assemble and solve the full system.\n    A = np.vstack([AL, AR, A1, A2, nakL, nakR])\n    v = np.hstack([vL, vR, v1, v2, 0, 0])\n    z = solve(A, v)\n\n    # Break the coefficients into separate vectors.\n    rows = np.arange(n)\n    a = z[rows]\n    b = z[n + rows]\n    c = z[2 * n + rows]\n    d = z[3 * n + rows]\n    S = [np.poly1d([d[k], c[k], b[k], a[k]]) for k in range(n)]\n\n    # This function evaluates the spline when called with a value for x.\n    def evaluate(x):\n        f = np.zeros(x.shape)\n        for k in range(n):\n            # Evaluate this piece's cubic at the points inside it.\n            index = (x >= t[k]) & (x <= t[k + 1])\n            f[index] = S[k](x[index] - t[k])\n        return f\n\n    return evaluate\n\nFunction 5.3.1 gives an implementation of cubic not-a-knot spline interpolation. For clarity it stays very close to the description given above. There are some possible shortcuts—for example, one could avoid using \\mathbf{E} and instead directly delete the last row of any matrix it left-multiplies. Observe that the linear system is assembled and solved just once, and the returned evaluation function simply uses the resulting coefficients. This allows us to make multiple calls to evaluate S without unnecessarily repeating the linear algebra.","type":"content","url":"/splines#implementation","position":7},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Conditioning and convergence"},"type":"lvl2","url":"/splines#conditioning-and-convergence","position":8},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Conditioning and convergence"},"content":"Cubic splines\n\nExample 5.3.1\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nusing Plots\nf = x -> exp(sin(7x))\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]  # nodes\ny = f.(t)                           # values at nodes\nscatter!(t, y, label=\"values at nodes\")\n\nS = FNC.spinterp(t, y)\nplot!(S, 0, 1, label=\"spline\")\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000) / 1e4              # sample the difference at many points\nn = @. round(Int, 2^(3:0.5:7))  # numbers of nodes\nerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    t = (0:n) / n\n    S = FNC.spinterp(t, f.(t))\n    dif = @. f(x) - S(x)\n    err[k] = norm(dif, Inf)\nend\n@pt :header=[\"n\", \"max-norm error\"] [n[1:2:end] err[1:2:end]]\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = @. (n / n[1])^(-4)\n\nplot(n, [err order4];\n    m=[:o :none], l=[:solid :dash],\n    label=[\"error\" \"4th order\"],\n    xaxis=(:log10, \"n\"),  yaxis=(:log10, L\"|| f-S\\,||_\\infty\"),\n    title=\"Convergence of spline interpolation\")\n\nExample 5.3.1\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nclf\nf = @(x) exp(sin(7 * x));\nfplot(f, [0, 1], displayname=\"function\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % values at nodes\nhold on, scatter(t, y, displayname=\"values at nodes\")\n\nS = spinterp(t, y);\nfplot(S, [0, 1], displayname=\"spline\")\n\nxlabel(\"x\");  ylabel(\"y\")\nlegend();\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000)' / 1e4;              % sample the difference at many points\nn = round(2 .^ (3:0.5:7))';        % numbers of nodes\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i))' / n(i);\n    S = spinterp(t, f(t));\n    err = f(x) - S(x);\n    maxerr(i) = norm(err, Inf);\nend\ntable(n(1:2:end), maxerr(1:2:end), variableNames=[\"n\", \"inf-norm error\"])\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder4 = 0.5 * maxerr(end) * (n / n(end)) .^ (-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nxlabel(\"n\");  ylabel(\"|| f-S ||_{\\infty}\")\ntitle((\"Convergence of spline interpolation\"));\n\nExample 5.3.1\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nf = lambda x: exp(sin(7 * x))\n\nx = linspace(0, 1, 500)\nfig, ax = subplots()\nax.plot(x, f(x), label=\"function\")\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # values at nodes\n\nxlabel(\"$x$\")\nylabel(\"$y$\")\nax.scatter(t, y, label=\"nodes\")\n\nS = FNC.spinterp(t, y)\nax.plot(x, S(x), label=\"spline\")\nax.legend()\nfig\n\nNow we look at the convergence rate as the number of nodes increases.\n\nN = floor(2 ** linspace(3, 8, 17)).astype(int)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.spinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = (N / N[0]) ** (-4)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order4, \"--\", label=\"4th order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-S\\|_\\infty$\")\nlegend();\n\nBesides having more smoothness than a piecewise linear interpolant, the not-a-knot cubic spline improves the order of accuracy to 4.\n\nSuppose that f(x) has four continuous derivatives in [a,b] (i.e., f\\in C^4[a,b]). Let S_n(x) be the not-a-knot cubic spline interpolant of \\bigl(t_i,f(t_i)\\bigr) for i=0,\\ldots,n, where t_i=a+i h and h=(b-a)/n. Then for all sufficiently small h, there is a constant C>0 such that\\bigl\\| f - S_n \\bigr\\|_\\infty \\le Ch^4.\n\nThe conditioning of spline interpolation is much more complicated than for the piecewise linear case. First, the fact that the coefficients of all the cubics must be solved for simultaneously implies that each data value in \\mathbf{y} has an influence on S over the entire interval. Second, S can take on values larger in magnitude than all of the values in \\mathbf{y} (see \n\nExercise 5). The details may be found in more advanced texts.","type":"content","url":"/splines#conditioning-and-convergence","position":9},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Exercises"},"type":"lvl2","url":"/splines#exercises","position":10},{"hierarchy":{"lvl1":"Cubic splines","lvl2":"Exercises"},"content":"✍ In each case, write out the entries of the matrix and right-hand side of the linear system that determines the coefficients for the cubic not-a-knot spline interpolant of the given function and node vector.\n\n(a) \\cos  (\\pi^2 x^2 ), \\: \\mathbf{t} = [-1,1,4]\n\n(b) \\cos (\\pi^2 x^2), \\: \\mathbf{t} = [0,\\tfrac{1}{2},\\tfrac{3}{4},1]\n\n(c) \\ln(x), \\:  \\mathbf{t} = [1,2,3]\n\n(d) \\sin(x^2),\\:  \\mathbf{t} = [-1,0,1]\n\n⌨ (continuation) For each case in the preceding problem, use Julia to solve the linear system you wrote down. Then plot the resulting cubic spline over the interval between the second and third nodes.\n\n⌨ For each given function, interval, and value of n, define n+1 evenly spaced nodes. Then use \n\nFunction 5.3.1 to plot the cubic spline interpolant using those nodes, together with the original function over the given interval.\n\n(a) \\cos(\\pi x^2) on [0,4], n=18\n\n(b) \\ln(x) on [1,20], n=4\n\n(c) \\sin\\left(\\frac{1}{x}\\right) on \\left[\\frac{1}{2},7\\right], n=9\n\n⌨ For each given function and interval, perform piecewise linear interpolation using \n\nFunction 5.3.1 for n+1 equispaced nodes with n=10,20,40,80,160,320. For each n, estimate the errorE(n) = \\| f-p \\|_\\infty = \\max_x | f(x) - p(x) |\n\nby evaluating the function and interpolant at 1600 points in the interval. Make a log-log plot of E as a function of n and add the line E=Cn^{-4} for a constant C of your choosing.\n\n(a) \\cos(\\pi x^2) on [0,4]\n\n(b) \\ln(x) on [1,20]\n\n(c) \\sin\\left(\\frac{1}{x}\\right) on \\left[\\frac{1}{2},7\\right]\n\n⌨  Although the cardinal cubic splines are intractable in closed form, they can be found numerically. Each cardinal spline interpolates the data from one column of an identity matrix. Define the nodes \\mathbf{t} = \\bigl[0,\\, 0.075,\\, 0.25,\\, 0.55,\\, 1]. Plot over [0,1] the five cardinal functions for this node set over the interval [0,1].\n\n✍ Suppose you were to define a piecewise quadratic spline that interpolates n+1 given values and has a continuous first derivative. Follow the derivation of this section to express all of the interpolation and continuity conditions. How many additional conditions are required to make a square system for the coefficients?\n\n(a) ✍ If y_0=y_n, another possibility for cubic spline end conditions is to make S(x) a periodic function. This implies that S' and S'' are also periodic. Write out the two new algebraic equations for these constraints in terms of the piecewise coefficients.\n\n(b) ⌨ Modify \n\nFunction 5.3.1 to compute a periodic spline interpolant. Test by making a plot of the interpolant for f(x) =\\exp(\\sin(3x)) over the interval [0,2\\pi/3] with equally spaced nodes and n=8.\n\nThis explains the name of the not-a-knot spline—for splines, “knots” are the points at which  different piecewise definitions meet.","type":"content","url":"/splines#exercises","position":11},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta"},"type":"lvl1","url":"/adaptive-rk","position":0},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta"},"content":"The derivation and analysis of methods for initial-value problems usually assumes a fixed step size h. While the error behavior O(h^p) is guaranteed by \n\nTheorem 6.2.1 as h\\rightarrow 0, this bound comes with an unknowable constant, and it is not very useful as a guide to the numerical value of the error at any particular value of h. Furthermore, as we saw in \n\nAdaptive integration for numerical integration, in many problems a fixed step size is far from the most efficient strategy.\n\nIn response we will employ the basic strategy of \n\nAdaptive integration: estimate the error and adapt the step size in order to reach an accuracy goal. Unlike the integration problem, though, the “integrand” of an IVP is dependent on the solution itself, so the details differ greatly.","type":"content","url":"/adaptive-rk","position":1},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Step size prediction"},"type":"lvl2","url":"/adaptive-rk#step-size-prediction","position":2},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Step size prediction"},"content":"Suppose that, starting from a given value u_i and using a step size h, we run one step of two different RK methods simultaneously: one method with order p, producing u_{i+1}, and the other method with order p+1, producing \\tilde{u}_{i+1}. In most circumstances, we can expect that \\tilde{\\mathbf{u}}_{i+1} is a much better approximation to the solution than \\mathbf{u}_{i+1} is. So it seems reasonable to useE_i(h)=|\\tilde{\\mathbf{u}}_{i+1} - \\mathbf{u}_{i+1}|\n\nas an estimate of the actual local error made by the pth-order method. For a vector IVP, we would use a norm rather than an absolute value. If the goal is to keep global error less than some predetermined value, we could decide to accept the new solution value if $E_i$ small enough, and otherwise reject it.[^extrap]\n\n[^extrap]: Even though the estimate $E_i$ is meant to go with the *less* accurate proposed value $\\mathbf{u}_{i+1}$, it's hard to resist the temptation to keep the more accurate value instead, and this is common in practice. \n\nNow we ask: looking back, what step size should we have taken to meet an error target of size ε? Let’s speculate, given the behavior of local truncation error as h\\rightarrow 0, that E_i(h)\\approx C h^{p+1} for an unknown constant C. If we had used a step size q h for some q>0, then trivially, we would expectE_i(qh)\\approx C q^{p+1}h^{p+1}.\n\nOur best guess for q would therefore be to set E_i(qh)\\approx \\epsilon, or  q \\approx \\left(\\frac{\\epsilon}{E_i}\\right)^{1/(p+1)}.\n\nPerhaps, though, we should aim to control the contribution to global error, which is closer to E_i(qh)/(q h). Then we end up with  q \\le \\left(\\frac{\\epsilon}{E_i}\\right)^{1/p}.\n\nExperts have different recommendations about whether to use \n\n(6.5.3) or \n\n(6.5.4). Even though \n\n(6.5.4) appears to be more in keeping with our assumptions about global errors, modern practice seems to favor \n\n(6.5.3).\n\nWe now have an outline of an algorithm.\n\nAdaptive step size for an IVP\n\nGiven a solution estimate u_i at t=t_i, and a step size h, do the following:\n\nProduce estimates {u}_{i+1} and \\tilde{u}_{i+1}, and estimate the error.\n\nIf the error is small enough, adopt \\tilde{u}_{i+1} as the solution value at t=t_i+h, then increment i.\n\nReplace h by q h, with q given by \n\n(6.5.3) or \n\n(6.5.4).\n\nRepeat until t=b.\n\nMany details remain unspecified at this point, but we first address step 1.","type":"content","url":"/adaptive-rk#step-size-prediction","position":3},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Embedded formulas"},"type":"lvl2","url":"/adaptive-rk#embedded-formulas","position":4},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Embedded formulas"},"content":"Suppose, for example, we choose to use a  pair of second- and third-order RK methods to get the \\mathbf{u}_{i+1} and \\tilde{\\mathbf{u}}_{i+1} needed in \n\nAlgorithm 6.5.1. Then we seem to need at least 2+3=5 evaluations of f(t,y) for each attempted time step. This is more than double the computational work needed by the second-order method without adaptivity.\n\nFortunately, the marginal cost of adaptivity can be substantially reduced by using embedded Runge–Kutta formulas. Embedded RK formulas are a pair of RK methods whose stages share the same internal f evaluations, combining them differently in order to get estimates of two different orders of accuracy.\n\nA good example of an embedded method is the Bogacki–Shampine (BS23) formula, given by the table\\begin{array}{r|cccc}\n0                  & \\rule{0pt}{2.75ex} &                    &                    &                    \\\\\n\\frac{1}{2}        & \\frac{1}{2}        & \\rule{0pt}{2.75ex} &                    &                    \\\\\n\\frac{3}{4}        & 0                  & \\frac{3}{4}        & \\rule{0pt}{2.75ex} &                    \\\\\n1                 & \\frac{2}{9}        & \\frac{1}{3}        & \\frac{4}{9}        & \\rule{0pt}{2.75ex} \\\\[2pt] \\hline\n\\rule{0pt}{2.75ex} & \\frac{2}{9}        & \\frac{1}{3}        & \\frac{4}{9}        & 0                  \\\\[2pt] \\hline\n\\rule{0pt}{2.75ex} & \\frac{7}{24}       & \\frac{1}{4}        & \\frac{1}{3}        & \\frac{1}{8}\n\\end{array}\n\nThe top part of the table describes four stages in the usual RK fashion. The last two rows describe how to construct a third-order estimate \\tilde{\\mathbf{u}}_{i+1} and a second-order estimate \\mathbf{u}_{i+1} by taking different combinations of those stages.","type":"content","url":"/adaptive-rk#embedded-formulas","position":5},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Implementation"},"type":"lvl2","url":"/adaptive-rk#implementation","position":6},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Implementation"},"content":"Our implementation of an embedded second/third-order (RK23) code is given in \n\nFunction 6.5.2.\n\nrk23\n\nAdaptive IVP solver based on embedded RK formulas\n\n\"\"\"\n    rk23(ivp, tol)\n\nApply an adaptive embedded RK formula pair to solve given IVP with\nestimated error `tol`. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk23(ivp, tol)\n    # Initialize for the first time step.\n    a, b = ivp.tspan\n    t = [a]\n    u = [float(ivp.u0)]\n    i = 1\n    h = 0.5 * tol^(1 / 3)\n    s₁ = ivp.f(ivp.u0, ivp.p, a)\n\n    # Time stepping.\n    while t[i] < b\n        # Detect underflow of the step size.\n        if t[i] + h == t[i]\n            @warn \"Stepsize too small near t=$(t[i])\"\n            break  # quit time stepping loop\n        end\n\n        # New RK stages.\n        s₂ = ivp.f(u[i] + (h / 2) * s₁, ivp.p, t[i] + h / 2)\n        s₃ = ivp.f(u[i] + (3h / 4) * s₂, ivp.p, t[i] + 3h / 4)\n        u_new3 = u[i] + h * (2s₁ + 3s₂ + 4s₃) / 9   # 3rd order solution\n        s₄ = ivp.f(u_new3, ivp.p, t[i] + h)\n        err = h * (-5s₁ / 72 + s₂ / 12 + s₃ / 9 - s₄ / 8)  # 2nd/3rd difference\n        E = norm(err, Inf)                         # error estimate\n        maxerr = tol * (1 + norm(u[i], Inf))     # relative/absolute blend\n\n        # Accept the proposed step?\n        if E < maxerr     # yes\n            push!(t, t[i] + h)\n            push!(u, u_new3)\n            i += 1\n            s₁ = s₄       # use FSAL property\n        end\n\n        # Adjust step size.\n        q = 0.8 * (maxerr / E)^(1 / 3)   # conservative optimal step factor\n        q = min(q, 4)               # limit stepsize growth\n        h = min(q * h, b - t[i])        # don't step past the end\n    end\n    return t, u\nend\n\nAbout the code\n\nThe check t[i]+h == t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\nAdaptive IVP solver based on embedded RK formulas\n\nfunction [t, u] = rk23(ivp, a, b, tol)\r\n% RK23   Adaptive IVP solver based on embedded RK formulas.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   tol     global error target (positive scalar)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Initialize for the first time step.\r\nt = a;\r\nu(:, 1) = u0(:);  i = 1;\r\nh = 0.5 * tol^(1/3);\r\ns1 = du_dt(t(1), u(:, 1) ,p);\r\n\r\n% Time stepping.\r\nwhile t(i) < b\r\n    % Detect underflow of the step size.\r\n    if t(i) + h == t(i)\r\n        warning('Stepsize too small near t=%.6g.',t(i))\r\n        break  % quit time stepping loop\r\n    end\r\n    \r\n    % New RK stages.\r\n    s2 = du_dt(t(i) + h/2,   u(:, i) + (h/2)   * s1, p);\r\n    s3 = du_dt(t(i) + 3*h/4, u(:, i) + (3*h/4) * s2, p);\r\n    unew2 = u(:, i) + h * (2*s1 + 3*s2 + 4*s3) / 9;    % 2rd order solution\r\n    s4 = du_dt(t(i) + h, unew2, p );\r\n    err = h * (-5*s1/72 + s2/12 + s3/9 - s4/8);        % 2nd/3rd order difference\r\n    E = norm(err, Inf);                                % error estimate\r\n    maxerr = tol * (1 + norm(u(:, i), Inf));           % relative/absolute blend\r\n    \r\n    % Accept the proposed step? \r\n    if E < maxerr     % yes \r\n        t(i+1) = t(i) + h;\r\n        u(:, i+1) = unew2;\r\n        i = i+1;\r\n        s1 = s4;      % use FSAL property\r\n    end\r\n    \r\n    % Adjust step size. \r\n    q = 0.8 * (maxerr/E)^(1/3);       % conservative optimal step factor\r\n    q = min(q, 4);                    % limit stepsize growth\r\n    h = min(q*h, b - t(i));           % don't step past the end\r\nend\n\nAbout the code\n\nThe check t(i) + h == t(i)on line 24 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 36, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 47--49 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 43 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s4 as s1 for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\nAdaptive IVP solver based on embedded RK formulas\n\ndef euler(du_dt, tspan, u0, n):\n    \"\"\"\n    euler(du_dt, tspan, u0, n)\n\n    Apply Euler's method to solve the IVP u'=du_dt(u,t) over the interval tspan with\n    u(tspan[1])=u0, using n subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * du_dt(t[i], u[i])\n\n    return t, u.T\n\nAbout the code\n\nThe check t[i]+h==t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\nAdaptive step size\n\nExample 6.5.1\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nusing OrdinaryDiffEq, Plots\nf(u, p, t) = exp(t - u * sin(u))\nivp = ODEProblem(f, 0, (0.0, 5.0))\nt, u = FNC.rk23(ivp, 1e-5)\nplot(t, u, m=2,\n    xlabel=L\"t\",  ylabel=L\"u(t)\", \n    title=\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nΔt = diff(t)\nplot(t[1:end-1], Δt;\n    xaxis=(L\"t\", (0, 5)), yaxis=(:log10, \"step size\"),\n    title=\"Adaptive step sizes\")\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprintln(\"minimum step size = $(minimum(Δt))\")\n\nOn the other hand, the average step size that was actually taken was\n\nprintln(\"average step size = $(sum(Δt)/(length(t)-1))\")\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nExample 6.5.1\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) exp(t - u * sin(u));\nivp.InitialValue = 0;\na = 0;  b = 5;\n\n[t, u] = rk23(ivp, a, b, 1e-5);\nclf, plot(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle((\"Adaptive IVP solution\"));\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nDelta_t = diff(t);\nsemilogy(t(1:end-1), Delta_t) \nxlabel(\"t\");  ylabel(\"step size\")\ntitle((\"Adaptive step sizes\"));\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nfprintf(\"minimum step size = %.2e\", min(Delta_t))\n\nOn the other hand, the average step size that was actually taken was\n\nfprintf(\"average step size = %.2e\", mean(Delta_t))\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nExample 6.5.1\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nf = lambda t, u: exp(t - u * sin(u))\nt, u = FNC.rk23(f, [0.0, 5.0], [0.0], 1e-5)\nscatter(t, u[0, :])\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle((\"Adaptive IVP solution\"));\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\ndt = [t[i + 1] - t[i] for i in range(t.size - 1)]\nsemilogy(t[:-1], dt)\nxlabel(\"$t$\"), ylabel(\"time step\")\ntitle((\"Adaptive step sizes\"));\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprint(f\"min step size was {min(dt):.2e}\")\n\nOn the other hand, the average step size that was actually taken was\n\nprint(f\"mean step size was {mean(dt):.2e}\")\n\nWe took fewer steps by a factor of 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nAdaptive step size near a singularity\n\nExample 6.5.2\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\nf(u, p, t) = (t + u)^2\nivp = ODEProblem(f, 1, (0.0, 1.0))\nt, u = FNC.rk23(ivp, 1e-5);\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nplot(t, u;\n    legend=:none,\n    xlabel=L\"t\",  yaxis=(:log10, L\"u(t)\"), \n    title=\"Finite-time blowup\")\n\ntf = t[end]\nvline!([tf], l=:dash)\nannotate!(tf, 1e5, latexstring(@sprintf(\"t = %.6f \", tf)), :right)\n\nExample 6.5.2\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialValue = 1;\n[t, u] = rk23(ivp, 0, 1, 1e-5);\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nclf, semilogy(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle(\"Adaptive solution near a singularity\")\n\ntf = t(end);\nxline(tf, \"linestyle\", \"--\")\ntext(tf, 1e5, sprintf(\" t = %.6f \", tf))\n\nExample 6.5.2\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\ndu_dt = lambda t, u: (t + u)**2\ntspan = (0.0, 2.0)\nu0 = [1.0]\nt, u = FNC.rk23(du_dt, tspan, u0, 1e-5)\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nsemilogy(t, u[0, :])\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\ntitle(\"Finite-time blowup\")\n\ntf = t[-1]\naxvline(x=tf, color='k', linestyle='--', label=f\"t = {tf:.6f}\")\nlegend();\n\nOften the adaptively chosen steps clearly correspond to identifiable features of the solution. However, there are so-called stiff problems in which the time steps seem unreasonably small in relation to the observable behavior of the solution. These problems benefit from a particular type of solver that is considered in \n\nImplementation of multistep methods.","type":"content","url":"/adaptive-rk#implementation","position":7},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Exercises"},"type":"lvl2","url":"/adaptive-rk#exercises","position":8},{"hierarchy":{"lvl1":"Adaptive Runge–Kutta","lvl2":"Exercises"},"content":"⌨ Using \n\nFunction 6.5.2 with an error tolerance of \n\n10-8, solve y'' +(1+y')^3 y = 0 over  0 \\le t \\le 4 \\pi with the indicated initial conditions. Plot y(t) and y'(t) as functions of t and separately plot the time step size as a function of t.\n\n(a) y(0) = 0.1, \\quad y'(0) = 0\n\n(b) y(0) = 0.5, \\quad y'(0) = 0\n\n(c) y(0) = 0.75, \\quad y'(0) = 0\n\n(d) y(0) = 0.95, \\quad y'(0) = 0\n\n⌨ Solve the FitzHugh–Nagumo system from \n\nExercise 4.3.6 for I=0.05740 using \n\nFunction 6.5.2 with error tolerance \n\n10-2, \n\n10-3, and \n\n10-4. (This illustrates that the error tolerance is a target, not a guarantee!)\n\n✍ Derive Equation \n\n(6.5.4) using the stated assumption about controlling global rather than local error.\n\n⌨ Solve the problem u'=100u^2-u^3, u(0)=0.0002, 0\\le t \\le 100, and make plots that show both the solution and the time steps taken. The solution makes a quick transition between two nearly constant states. Does the step size selection behave the same in both states?","type":"content","url":"/adaptive-rk#exercises","position":9},{"hierarchy":{"lvl1":"Basics of IVPs"},"type":"lvl1","url":"/basics","position":0},{"hierarchy":{"lvl1":"Basics of IVPs"},"content":"Initial-value problem (scalar)\n\nA scalar first-order initial-value problem (IVP) is\\begin{split}\n   u'(t) &= f(t,u(t)), \\qquad a \\le t \\le b,  \\\\\n  u(a) &=u_0.\n\\end{split}\n\nWe call t the independent variable and u the dependent variable. If u'=f(t,u)=g(t)+u h(t), the differential equation is linear; otherwise, it is nonlinear.\n\nA solution of an initial-value problem is a function u(t) that makes both u'(t)=f\\bigl(t,u(t)\\bigr) and u(a)=u_0 true equations.\n\nWhen t is meant to be time, sometimes we write \\dot{u} (read “u-dot”) instead of u'.\n\nSuppose u(t) is the size of a population at time t. We idealize by allowing u to take any real (not just integer) value. If we assume a constant per capita birth rate (births per unit population per unit time), then\\frac{d u}{d t} = k u, \\qquad u(0)=u_0\n\nfor some k>0. The solution of this linear equation is u(t)=e^{kt}u_0, which is exponential growth.\n\nA more realistic model would cap the growth due to finite resources. Suppose the death rate is proportional to the size of the population, indicating competition. Then  \\frac{d u}{d t} = ku - ru^2, \\qquad u(0)=u_0.\n\nThis is the logistic equation. Although crude, it is still useful in population models.  The solution relevant for population models has the form  u(t) = \\frac{k/r}{ 1 + \\left( \\frac{k}{r u_0} - 1 \\right) e^{-k t} }.\n\nFor k,r,u_0>0, the solution smoothly varies from the initial population u_0 to a finite population, equal to k/r, that has been limited by competition.\n\nLinear problems can be solved in terms of integrals. Defining the integrating factor \\rho(t) = \\exp\\bigl[\\int -h(t)\\, dt \\bigr], the solution is derived from  \\rho(t) u(t) = u_0 + \\int_a^t \\rho(s) g(s) \\, ds.\n\nIn many cases, however, the necessary integrals cannot be done in closed form. Some nonlinear ODEs, such as separable equations, may also be solvable with a short formula, perhaps with difficult integrations. Most often, though, there is no analytic formula available for the solution.\n\nAn ODE may have higher derivatives of the unknown solution present. For example, a second-order ordinary differential equation is often given in the form u''(t)=f\\bigl(t,u,u'\\bigr). A second-order IVP requires two conditions at the initial time in order to specify a solution completely. As we will see in \n\nIVP systems, we are always able to reformulate higher-order IVPs in a first-order form, so we will deal with first-order problems exclusively.","type":"content","url":"/basics","position":1},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Numerical solutions"},"type":"lvl2","url":"/basics#numerical-solutions","position":2},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Numerical solutions"},"content":"Solving an IVP\n\nExample 6.1.2\n\nThe OrdinaryDiffEq package offers solvers for IVPs. Let’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nBecause many practical problems come with parameters that are fixed within an instance but varied from one instance to another, the syntax for IVPs includes a input argument p that stays fixed throughout the solution. Here we don’t want to use that argument, but it must be in the definition for the solver to work.\n\nTip\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf(u, p, t) = sin((t + u)^2)     # defines du/dt, must include p argument\nu₀ = -1.0                       # initial value\ntspan = (0.0, 4.0)               # t interval\n\nWith the data above we define an IVP problem object and then solve it. Here we tell the solver to use the Tsit5 method, which is a good first choice for most problems.\n\nusing OrdinaryDiffEq\nivp = ODEProblem(f, u₀, tspan)\nsol = solve(ivp, Tsit5());\n\nThe resulting solution object can be shown using plot.\n\nusing Plots\nplot(sol;\n    label=\"solution\", legend=:bottom,\n    xlabel=\"t\",  ylabel=L\"u(t)\",\n    title=L\"u'=\\sin((t+u)^2)\")\n\nThe solution also acts like any callable function that can be evaluated at different values of t.\n\n@show sol(1.0);\n\nUnder the hood, the solution object holds some information about how the values and plot are produced:\n\n[sol.t sol.u]\n\nThe solver initially finds approximate values of the solution (second column above) at some automatically chosen times (first column above). To compute the solution at other times, the object performs an interpolation on those values. This chapter is about how the discrete t and u values are computed. For now, just note how we can extract them from the solution object.\n\nscatter!(sol.t, sol.u, label=\"discrete values\")\n\nExample 6.1.2\n\nLet’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1. To create an initial-value problem for u(t), you must create an ode with a function that computes u' and an initial condition for u. Then you create a solution by calling solve with a time interval.\n\nTip\n\nMost real ODE problems contain parameters that are constant during the solution but that can change from one problem instance to the next. Accordingly, we define the ODE function below to accept a third argument, p, which is a vector of parameters. We always include this argument for consistency, even when there are no parameters.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialTime = 0;\nivp.InitialValue = -1;\nsol = solve(ivp, 0, 4);\n\nThe resulting solution object has fields Time and Solution that contain the approximate values of the solution at automatically chosen times in the interval you provided.\n\nclf\nplot(sol.Time, sol.Solution, '-o')\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle((\"Solution of an IVP\"));\n\nYou might want to know the solution at particular times other than the ones selected by the solver. That requires an interpolation, which is done by solutionFcn.\n\nu = solutionFcn(ivp, 0, 10);\nu(0:5)\n\nExample 6.1.2\n\nLet’s use solve_ivp from scipy.integrate to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = [-1.0]\n\nNote above that even though this is a problem for a scalar function u(t), we had to set the initial condition as a “one-dimensional vector.”\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, u0)\n\nThe resulting solution object has fields t and y that contain the values of the independent and dependent variables, respectively; those field names are the same regardless of what we use in our own codes.\n\nprint(\"t shape:\", sol.t.shape)\nprint(\"u shape:\", sol.y.shape)\nplot(sol.t, sol.y[0, :], \"-o\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle((\"Solution of $u' = sin((t+u)^2)$\"));\n\nYou can see above that the solution was not computed at enough points to make a smooth graph. There is a way to request output at times of your choosing.\n\nsol = solve_ivp(f, tspan, u0, t_eval=linspace(0, 4, 200))\nplot(sol.t, sol.y[0, :], \"-\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle((\"Solution of $u' = sin((t+u)^2)$\"));\n\nAnother option is to enable interpolation to evaluate the solution anywhere after the fact:\n\nsol = solve_ivp(f, tspan, u0, dense_output=True)\nfor t in linspace(0, 4, 6):\n    print(f\"u({t:.2f}) = {sol.sol(t)[0]:.4f}\")","type":"content","url":"/basics#numerical-solutions","position":3},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Existence and uniqueness"},"type":"lvl2","url":"/basics#existence-and-uniqueness","position":4},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Existence and uniqueness"},"content":"There are simple IVPs that do not have solutions at all possible times.\n\nFinite-time singularity\n\nExample 6.1.3\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nf(u, p, t) = (t + u)^2\nivp = ODEProblem(f, 1.0, (0.0, 1.0))\nsol = solve(ivp, Tsit5());\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nplot(sol, label=\"\";\n    xlabel=L\"t\",  yaxis=(:log10, L\"u(t)\"),\n    title=\"Finite-time blowup\")\n\nExample 6.1.3\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialTime = 0;\nivp.InitialValue = 1;\nsol = solve(ivp, 0, 1);\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nclf\nsemilogy(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle((\"Finite-time blowup\"));\n\nExample 6.1.3\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nTip\n\nIt’s a good idea to check sol.success after calling solve_ivp. If it’s False, the solution may not be reliable.\n\nf = lambda t, u: (t + u) ** 2\nsol = solve_ivp(f, [0.0, 1.0], [1.0])\nif not sol.success:\n    print(sol.message)\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nsemilogy(sol.t, sol.y[0, :])\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle((\"Blowup in finite time\"));\n\nWe can also produce an IVP that has more than one solution.\n\nThe functions u(t)=u^2 and u(t)\\equiv 0 both satisfy the differential equation u'=2\\sqrt{u} and the initial condition u(0)=0. Thus the corresponding IVP has more than one solution.\n\nThe following standard theorem gives us a condition that is easy to check and guarantees that a unique solution exists. But it is not the most general possible such condition, so there are problems with a unique solution that it cannot detect. We state the theorem without proof.\n\nExistence and uniqueness\n\nIf the derivative \\frac{\\partial f}{\\partial u} exists and \\left|\\frac{\\partial f}{\\partial u}\\right| is bounded by a constant L for all a\\le t \\le b and all u, then the initial-value problem \n\n(6.1.1) has a unique solution for t\\in [a,b].","type":"content","url":"/basics#existence-and-uniqueness","position":5},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Conditioning of first-order IVPs"},"type":"lvl2","url":"/basics#conditioning-of-first-order-ivps","position":6},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Conditioning of first-order IVPs"},"content":"In a numerical context we have to be concerned about the conditioning of the IVP. There are two key items in \n\n(6.1.1) that we might consider to be the data of the initial-value ODE problem: the function f(t,u), and the initial value u_0. It’s easier to discuss perturbations to numbers than to functions, so we will focus on the effect of u_0 on the solution, using the following theorem that we give without proof. Happily, its conditions are identical to those in \n\nTheorem 6.1.1.\n\nDependence on initial value\n\nIf the derivative \\frac{\\partial f}{\\partial u} exists and \\left|\\frac{\\partial f}{\\partial u}\\right| is bounded by a constant L for all a\\le t \\le b and all u, then the solution u(t;u_0+\\delta) of u'=f(t,u) with initial condition u(0)=u_0+\\delta satisfies\\left\\|u(t;u_0+\\delta)-u(t;u_0)\\right\\|_\\infty \\le |\\delta| e^{L(b-a)}\n\nfor all sufficiently small |\\delta|.\n\nNumerical solutions of IVPs have errors, and those errors can be seen as perturbations to the solution. \n\nTheorem 6.1.2 gives an upper bound of e^{L(b-a)} on the infinity norm (i.e., pointwise) absolute condition number of the solution with respect to perturbations at an initial time. However, the upper bound may be a terrible overestimate of the actual sensitivity for a particular problem.\n\nConditioning of an IVP\n\nExample 6.1.5\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = range(0, 3, length=800)\nu = @. exp(t) * 1\nlower, upper = @. exp(t) * 0.7, @. exp(t) * 1.3\nplot(t, u;\n    l=:black, ribbon=(lower, upper),\n    leg=:none,  xlabel=L\"t\",  ylabel=L\"u(t)\",\n    title=\"Exponential divergence of solutions\")\n\nBut with u'=-u, solutions actually get closer together with time.\n\nu = @. exp(-t) * 1\nlower, upper = @. exp(-t) * 0.7, @. exp(-t) * 1.3\nplot(t, u;\n    l=:black,  ribbon=(lower, upper),\n    leg=:none,  xlabel=L\"t\",  ylabel=L\"u(t)\",\n    title=\"Exponential convergence of solutions\")\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.\n\nExample 6.1.5\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')\ntitle(('Exponential divergence of solutions'));\n\nBut with u'=-u, solutions actually get closer together with time.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(-t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')\ntitle(('Exponential convergence of solutions'));\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.\n\nExample 6.1.5\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = linspace(0, 3, 200)\nu = array([exp(t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle((\"Exponential divergence of solutions\"));\n\nBut with u'=-u, solutions actually get closer together with time.\n\nt = linspace(0, 3, 200)\nu = array([exp(-t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle((\"Exponential convergence of solutions\"));\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence, the exponentially growing upper bound e^{b-a} is a gross overestimate.\n\nIn general, solutions can diverge from, converge to, or oscillate around the original trajectory in response to perturbations. We won’t fully consider these behaviors and their implications for numerical methods again until a later chapter.","type":"content","url":"/basics#conditioning-of-first-order-ivps","position":7},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Exercises"},"type":"lvl2","url":"/basics#exercises","position":8},{"hierarchy":{"lvl1":"Basics of IVPs","lvl2":"Exercises"},"content":"✍ For each IVP, determine whether the problem satisfies the conditions of \n\nTheorem 6.1.2). If so, determine the smallest possible value for L.\n\n(a) f(t,u) = 3 u,\\; 0 \\le t \\le 1\n\n(b) f(t,u) = -t \\sin(u),\\; 0 \\le t \\le 5\n\n(c) f(t,u) = -(1+t^2) u^2,\\; 1 \\le t \\le 3\n\n(d) f(t,u) = \\sqrt{u},\\; 0 \\le t \\le 1\n\n⌨ For each ODE in the preceding problem, assume that u is initially equal to 1 on the given interval. Solve the resulting IVP with solve and make a plot of the solution.\n\n✍ Use an integrating factor to find the solution of each problem in analytic form.\n\n(a) u' = -t u,\\ 0 \\le t \\le 5,\\ u(0) = 2\n\n(b) u' - 3 u = e^{-2t},\\ 0 \\le t \\le 1,\\  u(0) = 5\n\n✍ Consider the IVP u'=u^2, u(0)=\\alpha.\n\n(a) Does \n\nTheorem 6.1.1 apply to this problem?\n\n(b) Show that u(t) = \\alpha/(1-\\alpha t) is a solution of the IVP.\n\n(c) Does this solution necessarily exist for all t\\in[0,1]?\n\n⌨ Using solve, compute solutions x(t) to the logistic equation with harvesting,x' = k (S-x)(x-M), \\qquad 0\\le t \\le 10,\n\nwith k=S=1 and M=0.25, for the initial conditions x(0)=0.9M, 1.1M, 1.5M, 0.9S, 1.1S, 3S. Show all the solutions together on one plot with 0\\le x \\le 3. (Note: One of the solutions will throw a warning and fail to reach t=10, but you can plot it anyway.)\n\n⌨ (a) Using solve, solve the IVP u'=u\\cos(u) + \\cos(4t), 0\\le t \\le 10, u(0) = u_0 for u_0 = -2,-1.5,-1,\\ldots,1.5,2. Plot all the solutions on a single graph.\n\n(b) All of the solutions in part (a) eventually settle into one of two periodic oscillations. To two digits of accuracy, find the value of u_0 in (-1,1) at which the selected long-term solution changes. (This will take repeated trials, narrowing down the range for u_0 each time.)\n\n⌨ Experimental evidence (see \n\nNewton et al. (1981)) shows that a 300-mg oral dose of caffeine, such as might be found in a large mug of drip-brewed coffee, creates a concentration of about 8 \\mu{\\rm g}/mL in blood plasma. This boost is followed by first-order kinetics with a half-life of about 6 hours (although this rate can vary a great deal from person to person). We can model the caffeine concentration due to one drink taken over half an hour via  x'(t) = -kx + C(t),\\quad x(0)=0,\n\nwhere k=\\log(2)/6 and  C(t) =\n  \\begin{cases}\n    16, & 0\\le t \\le 0.5, \\\\\n    0, & t > 0.5.\n  \\end{cases}\n\nUse solve to make a plot of the caffeine concentration for 12 hours. Then change k=\\log(2)/8 (half-life of 8 hours) and plot the solution again.\n\n⌨ A reasonable model of the velocity v(t) of a skydiver is\\frac{dv}{dt} = -g + \\frac{k}{m}v^2,  \\qquad v(0)=0,\n\nwhere g=9.8 \\text{ m/sec}^2 is gravitational acceleration, m is the mass of the skydiver with parachute, and k quantifies the effect of air resistance. At the US Air Force Academy, a training jump starts at about 1200 m and has k=0.4875 for t<13 and k=29.16 or t\\ge 13. (This is an oversimplification; see \n\nMeade & Struthers (1999).)\n\n(a) Solve the IVP for v for an 80-kg cadet for t\\in [0,200], and plot the solution.\n\n(b) The total distance fallen up to time t is \\displaystyle\\int_0^t v(s)\\, ds. Use \n\nFunction 5.7.1 to calculate and plot the altitude of the cadet as a function of time.\n\n(c) In part (b), you should have found that the altitude becomes negative. Use \n\nFunction 4.4.2 to determine accurately when the cadet reaches the ground.","type":"content","url":"/basics#exercises","position":9},{"hierarchy":{"lvl1":"Euler’s method"},"type":"lvl1","url":"/euler","position":0},{"hierarchy":{"lvl1":"Euler’s method"},"content":"Let a first-order initial-value problem be given in the form\\begin{split}\n  u'(t) &= f\\bigl(t,u(t)\\bigr), \\qquad a \\le t \\le b,\\\\\n  u(a)& =u_0.\n\\end{split}\n\nWe represent a numerical solution of an IVP by its values at a finite collection of nodes, which for now we require to be equally spaced:t_i = a + ih, \\qquad h=\\frac{b-a}{n}, \\qquad i=0,\\ldots,n.\n\nThe number h is called the step size.\n\nBecause we don’t get exactly correct values of the solution at the nodes, we need to take some care with the notation. From now on we let \\hat{u}(t) denote the exact solution of the IVP. The approximate value at t_i computed at the nodes by our numerical methods will be denoted by u_i\\approx \\hat{u}(t_i). Because we are given the initial value u(a)=u_0 exactly, there is no need to distinguish whether we mean u_0 as the exact or the numerical solution.\n\nConsider a piecewise linear interpolant to the (as yet unknown) values u_0,u_1,\\ldots, u_n. For t_i < t < t_{i+1}, its slope is\\frac{u_{i+1} - u_{i}}{t_{i+1}-t_i} = \\frac{u_{i+1}-u_i}{h}.\n\nWe can connect this derivative to the differential equation by following the model of u'=f(t,u):\\frac{u_{i+1}-u_i}{h} = f(t_i,u_i), \\qquad i=0,\\ldots,n-1.\n\nWe could view the left-hand side as a forward-difference approximation to u'(t) at t=t_i. We can rearrange the equation to get Euler’s method, our first method for IVPs.\n\nEuler’s method for an IVP\n\nGiven the IVP u'=f(t,u), u(a)=u_0, and the nodes \n\n(6.2.2), iteratively compute the sequence  u_{i+1}=u_i + h f(t_i,u_i), \\qquad i=0,\\ldots,n-1.\n\nThen u_i is approximately the value of the solution at t=t_i.\n\nEuler’s method marches ahead in t, obtaining the solution at a new time level explicitly in terms of the latest value.\n\nA basic implementation of Euler’s method is shown in \n\nFunction 6.2.2.\n\neuler\n\nEuler’s method for an initial-value problem\n\n\"\"\"\n    euler(ivp, n)\n\nApply Euler's method to solve the given IVP using `n` time steps.\nReturns a vector of times and a vector of solution values.\n\"\"\"\nfunction euler(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initial condition and output setup.\n    u = fill(float(ivp.u0), n+1)\n\n    # The time stepping iteration.\n    for i in 1:n\n        u[i+1] = u[i] + h * ivp.f(u[i], ivp.p, t[i])\n    end\n    return t, u\nend\n\nAbout the code\n\nThe ivp input argument is an ODEProblem, like in \n\nDemo 6.1.2. It has fields ivp.f, ivp.tspan, ivp.u0, and ivp.p that fully define the problem. The outputs are vectors of the nodes and approximate solution values at those nodes.\n\nEuler’s method for an initial-value problem\n\nfunction [t, u] = eulerivp(ivp, a, b, n)\r\n% EULERIVP   Euler's method for a scalar initial-value problem.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;\r\nt = a + (0:n) * h;\r\n\r\n% Initialize solution array.\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0;\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  u(:, i+1) = u(:, i) + h * du_dt(t(i), u(:, i), p);\r\nend\n\nAbout the code\n\nThe ivp input argument is the same structure that is used with the built-in solve solvers. The outputs t and u are row vectors of the same length, like the fields in a solution object output by solve. While the entries of u could be simplified to u(1), u(i), etc., we chose a column-access syntax like u(:, i) that will prove useful for what’s coming next in the chapter.\n\nEuler’s method for an initial-value problem\n\ndef euler(du_dt, tspan, u0, n):\n    \"\"\"\n    euler(du_dt, tspan, u0, n)\n\n    Apply Euler's method to solve the IVP u'=du_dt(u,t) over the interval tspan with\n    u(tspan[1])=u0, using n subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * du_dt(t[i], u[i])\n\n    return t, u.T","type":"content","url":"/euler","position":1},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Local truncation error"},"type":"lvl2","url":"/euler#local-truncation-error","position":2},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Local truncation error"},"content":"Let \\hat{u}(t) be the exact solution of the IVP \n\n(6.2.1), and suppose that somehow we have access to it at t=t_i, so that u_i=\\hat{u}(t_i). How good is u_{i+1} as an approximation to \\hat{u}(t_{i+1})? The answer is revealed through a Taylor series:\\begin{split}\n  \\hat{u}(t_{i+1}) - \\bigl[ u_i + hf(t_i,u_i) \\bigr]\n &=  \\hat{u}(t_{i+1}) - \\bigl[ \\hat{u}(t_i) + hf\\bigl(t_i,\\hat{u}(t_i)\\bigr) \\bigr] \\\\\n &= \\bigl[ \\hat{u}(t_i) + h \\hat{u}'(t_i) + \\tfrac{1}{2}h^2 \\hat{u}''(t_i) + O(h^3) \\bigr] - \\bigl[ \\hat{u}(t_i) + h\\hat{u}'(t_i) \\bigr] \\notag \\\\\n  &= \\tfrac{1}{2}h^2 \\hat{u}''(t_i) + O(h^3),\n\\end{split}\n\nwhere we used the fact that \\hat{u} satisfies the differential equation.\n\nWe now introduce some formalities.\n\nOne-step IVP method\n\nA one-step method for the IVP \n\n(6.2.1) is a formula of the form{u}_{i+1} = u_i + h\\phi(t_i,u_i,h), \\qquad i=0,\\ldots,n-1.\n\nEuler’s method is the particular case of \n\n(6.2.7) with \\phi(t,u,h) = f(t,u), but we will see other one-step methods in later sections.\n\nIn close analogy with \n\nConvergence of finite differences, we define truncation error as the residual of \n\n(6.2.7) when the exact solution is inserted.\n\nTruncation error of a one-step IVP method\n\nThe local truncation error (LTE) of the one-step method \n\n(6.2.7) is  \\tau_{i+1}(h) := \\frac{\\hat{u}(t_{i+1})-\\hat{u}(t_i)}{h} - \\phi\\bigl(t_i,\\hat{u}(t_i),h\\bigr).\n\nThe method is called consistent if \\tau_{i+1}(h)\\to 0 as h\\to 0.\n\nThe following follows immediately from the definitions.\n\nIf \\phi(t,u,0)=f(t,u) for any function u, then the method \n\n(6.2.7) is consistent.","type":"content","url":"/euler#local-truncation-error","position":3},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Convergence"},"type":"lvl2","url":"/euler#convergence","position":4},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Convergence"},"content":"While the local truncation error is straightforward to calculate from its definition, it is not the quantity we want to know about and control.\n\nGlobal error of an IVP solution\n\nGiven an IVP whose exact solution is \\hat{u}(t), the global error of approximate solution values u_0,u_1,\\ldots,u_n at times t_i in \n\n(6.2.2) is the vector [ \\hat{u}(t_i) - u_i ]_{\\,i=0,\\ldots,n}.\n\nAt times the term global error may be interpreted as the max-norm of the global error vector, or as its final value.\n\nBy our definitions, the local error in stepping from t_i to t_{i+1} is h\\tau_{i+1}(h). To reach the time t=b from t=a with step size h, we need to take n=(b-a)/h steps. If we want to reach, say, t=(a+b)/2, then we would have to take n/2 steps, and so on. In fact, to reach any fixed time in the interval, we need to take O(n)=O(h^{-1}) steps. By expressing the local error with a factor of h taken out, the LTE τ itself is accounting for the simple accumulation of error caused by taking O(n) steps.\n\nHowever, global error is not as simple as a sum of local errors. As explained in \n\nTheorem 6.1.2 and illustrated in \n\nDemo 6.1.5, each step causes a perturbation of the solution that can grow as t advances. Thus, we have to account for the flow evolution of individual step truncation errors as well as their mere accumulation. That is the subject of the following theorem.\n\nSuppose that the unit local truncation error of the one-step method \n\n(6.2.7) satisfies  |\\tau_{i+1}(h)| \\le C h^p,\n\nand that\\left| \\frac{\\partial \\phi}{\\partial u} \\right| \\le L\n\nfor all t\\in[a,b], all u, and all h>0. Then the global error satisfies|\\hat{u}(t_i) - u_i| \\le \\frac{Ch^p}{L} \\left[ e^{L(t_i-a)} - 1\n\\right] = O(h^p),\n\nas h\\rightarrow 0.\n\nDefine the global error sequence ϵ_i=\\hat{u}(t_i)-u_i. Using \n\n(6.2.7), we obtain  ϵ_{i+1} - ϵ_i = \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - ( {u}_{i+1} - u_i ) =\n  \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - h\\phi(t_i,u_i,h),\n\nor  ϵ_{i+1} = ϵ_i + [\\hat{u}(t_{i+1}) - \\hat{u}(t_i) - h\\phi(t_i,\\hat{u}(t_i),h)] +\n  h[\\phi(t_i,\\hat{u}(t_i),h)- \\phi(t_i,u_i,h)].\n\nWe apply the triangle inequality,  \n\n(6.2.8), and \n\n(6.2.9) to find  |ϵ_{i+1}| \\le |ϵ_i| + Ch^{p+1} + h \\left| \\phi(t_i,\\hat{u}(t_i),h)- \\phi(t_i,u_i,h)\\right|.\n\nThe Fundamental Theorem of Calculus implies that\\begin{split}\n  \\left| \\phi(t_i,\\hat{u}(t_i),h)- \\phi(t_i,u_i,h)\\right|\n      & = \\left|  \\int_{u_i}^{\\hat{u}(t_i)} \\frac{\\partial \\phi}{\\partial u} \\,du  \\right|\\\\\n    & \\le  \\int_{u_i}^{\\hat{u}(t_i)} \\left|\\frac{\\partial \\phi}{\\partial u}\\right| \\,du \\\\[1mm]\n    & \\le L | \\hat{u}(t_i)-u_i| = L\\, |ϵ_i|.\n\\end{split}\n\nThus\\begin{split}\n  |ϵ_{i+1}| &\\le Ch^{p+1} + (1 + hL) |ϵ_i| \\\\\n  &\\le Ch^{p+1} + (1 + hL) \\bigl[ Ch^{p+1} + (1 + hL) |ϵ_{i-1}|\n  \\bigr]\\\\\n  &\\;\\vdots \\\\\n  &\\le Ch^{p+1} \\left[ 1 + (1+hL) + (1+hL)^2 + \\cdots + (1+hL)^i\n  \\right].\n\\end{split}\n\nTo get the last line we applied the inequality recursively until reaching ϵ_0, which is zero. Replacing i+1 by i and simplifying the geometric sum, we get  |ϵ_i| \\le Ch^{p+1}\\frac{(1+hL)^i - 1}{(1+hL)-1} = \\frac{Ch^p}{L}\n  \\left[ (1+hL)^i - 1 \\right].\n\nWe observe that 1+x \\le e^x for x\\ge 0 (see \n\nExercise 5). Hence (1+hL)^i \\le e^{i h L}, which completes the proof.\n\nThe theorem justifies one more general definition.\n\nOrder of accuracy of a one-step IVP method\n\nIf the local truncation error of the one-step method \n\n(6.2.7) satisfies \\tau_{i+1}(h)=O(h^p) for a positive integer p, then p is the order of accuracy of the formula.\n\nWe could restate \n\nTheorem 6.2.1 as saying that the global error has the same order of accuracy as the LTE. Note, however, that the O(h^p) convergence hides a leading constant that grows exponentially in time. When the time interval is bounded as h\\to 0, this does not interfere with the conclusion, but the behavior as t\\to\\infty contains no such guarantee.\n\nConvergence of Euler’s method\n\nExample 6.2.1\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nusing OrdinaryDiffEq\nf(u, p, t) = sin((t + u)^2);\ntspan = (0.0, 4.0);\nu0 = -1.0;\nivp = ODEProblem(f, u0, tspan)\n\nHere is the call to \n\nFunction 6.2.2.\n\nusing Plots\nt, u = FNC.euler(ivp, 20)\nplot(t, u;\n    m=2,  label=\"n=20\", \n    xlabel=L\"t\",  ylabel=L\"u(t)\",\n    title=\"Solution by Euler's method\")\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(ivp, 50)\nplot!(t, u, m=2, label=\"n=50\")\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a DifferentialEquations solver to construct an accurate reference solution.\n\nu_exact = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14)\nplot!(u_exact, l=(2, :black), label=\"reference\")\n\nNow we can perform a convergence study.\n\nn = [round(Int, 5 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.euler(ivp, n)\n    push!(err, norm(u_exact.(t) - u, Inf))\nend\n@pt :header=[\"n\", \"inf-norm error\"] [n err]\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nplot(n, err;\n    m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"),  yaxis=(:log10, \"inf-norm global error\"),\n    title=\"Convergence of Euler's method\")\n\n# Add line for perfect 1st order.\nplot!(n, 0.5 * err[end] * (n / n[end]) .^ (-1), l=:dash, label=L\"O(n^{-1})\")\n\nExample 6.2.1\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We need to define the function for the right-hand side of the ODE, the interval for the independent variable, and the initial value.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nHere is the call to \n\nFunction 6.2.2.\n\n[t, u] = eulerivp(ivp, a, b, 20);\nclf, plot(t, u, '.-')\nxlabel('t')\nylabel('u(t)')\ntitle(('Solution by Euler''s method'));\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\n[t, u] = eulerivp(ivp, a, b, 50);\nhold on, plot(t, u, '.-')\nlegend('20 steps', '50 steps');\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a built-in solver to construct an accurate reference solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_exact = solutionFcn(ivp, a, b);\n\nNow we can perform a convergence study.\n\nn = round(5 * 10.^(0:0.5:3));\nerr = [];\nfor k = 1:length(n)\n    [t, u] = eulerivp(ivp, a, b, n(k));\n    err(k) = norm(u_exact(t) - u, Inf);\nend\ntable(n', err', VariableNames=[\"n\", \"inf-norm error\"])\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nclf\nloglog(n, err, 'o-')\nhold on, loglog(n, 0.5 * err(end) * (n / n(end)).^(-1), '--')\nxlabel('n')\nylabel('inf-norm error')\ntitle('Convergence of Euler''s method')\nlegend('error', 'O(n^{-1})', 'location', 'southwest');\n\nExample 6.2.1\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = -1.0\nt, u = FNC.euler(f, tspan, u0, 20)\n\nfig, ax = subplots()\nax.plot(t, u[0, :], \"-o\", label=\"$n=20$\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution by Euler's method\")\nlegend();\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(f, tspan, u0, 200)\nax.plot(t, u[0, :], label=\"$n=200$\")\nax.legend()\nfig\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use solve_ivp to construct an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, [u0], dense_output=True, atol=1e-8, rtol=1e-8)\nax.plot(t, sol.sol(t)[0, :], \"--\", label=\"accurate\")\nax.legend()\nfig\n\nNow we can perform a convergence study.\n\nn_ = array([int(5 * 10**k) for k in arange(0, 3, 0.5)])\nerr_ = zeros(6)\nresults = PrettyTable([\"n\", \"error\"])\nfor j, n in enumerate(n_):\n    t, u = FNC.euler(f, tspan, u0, n)\n    err_[j] = norm(sol.sol(t)[0, :] - u[0, :], inf)\n    results.add_row((n, err_[j]))\nprint(results)\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nloglog(n_, err_, \"-o\", label=\"results\")\nplot(n_, 0.5 * (n_ / n_[0])**(-1), \"--\", label=\"1st order\")\nxlabel(\"$n$\"), ylabel(\"inf-norm error\")\ntitle(\"Convergence of Euler's method\")\nlegend();\n\nEuler’s method is the ancestor of the two major families of IVP methods presented in this chapter. Before we describe them, though, we generalize the initial-value problem itself in a crucial way.","type":"content","url":"/euler#convergence","position":5},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Exercises"},"type":"lvl2","url":"/euler#exercises","position":6},{"hierarchy":{"lvl1":"Euler’s method","lvl2":"Exercises"},"content":"✍ Do two steps of Euler’s method for the following problems using the given step size h. Then, compute the error using the given exact solution.\n\n(a) u' = -2t u, \\ u(0) = 2;\\ h=0.1;\\ \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ u(0) = 2;\\ h=0.2;\\ \\hat{u}(t) = -1-t+3e^t\n\n(c) t u' + u = 1, \\ u(1) = 6, \\ h = 0.25;\\ \\hat{u}(t) = 1+5/t\n\n(d) u' - 2u(1-u) = 0, \\ u(0) = 1/2, \\ h = 0.25; \\ \\hat{u}(t) = 1/(1 + e^{-2t})\n\n⌨ For each IVP, solve the problem using \n\nFunction 6.2.2. (i) Plot the solution for n=320. (ii) For n=10\\cdot2^k, k=2,3,\\ldots,10, compute the error at the final time and make a log-log convergence plot, including a reference line for first-order convergence.\n\n(a) u' = -2t u, \\ 0 \\le t \\le 2, \\ u(0) = 2;\\  \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ 0 \\le t \\le 1, \\ u(0) = 2;\\  \\hat{u}(t) = -1-t+3e^t\n\n(c) (1+t^3)uu' = t^2,\\ 0 \\le xt \\le 3, \\ u(0) =1;\\ \\hat{u}(t) = [1+(2/3)\\ln (1+xt^3)]^{1/2}\n\n(d) u' - 2u(1-u) = 0, \\ 0 \\le t \\le 2, \\ u(0) = 1/2; \\ \\hat{u}(t) = 1/(1 + e^{-2t})\n\n(e) v' - (1+x^2) v = 0, \\ 1 \\le x \\le 3, \\ v(1) = 1, \\ \\hat{v}(x) = e^{(x^3+3x-4)/3}\n\n(f) v' + (1+x^2) v^2 = 0, \\ 0 \\le x \\le 2, \\ v(0) = 2, \\ \\hat{v}(x) = 6/(2x^3+6x+3)\n\n(g) u' = 2(1+t)(1+u^2), \\ 0 \\le t \\le 0.5, \\ u(0) = 0,  \\ \\hat{u}(t) = \\tan(2t + t^2)\n\n✍ Here is an alternative to Euler’s method:\\begin{split}\n  v_{i+1} &= u_i + h f(t_i,u_i),\\\\\n  u_{i+1} &= u_i + hf(t_{i}+h,v_{i+1}).\n\\end{split}\n\n(a) Write out the method explicitly in the general one-step form \n\n(6.2.7) (i.e., clarify what ϕ is for this method).\n\n(b) Show that the method is consistent.\n\n✍ Consider the problem u'=ku, u(0)=1 for constant k and t>0.\n\n(a) Find an explicit formula in terms of h, k, and i for the Euler solution u_i at t=ih.\n\n(b) Find values of k and h such that |u_i|\\to\\infty as i\\to\\infty while the exact solution \\hat{u}(t) is bounded as t\\to\\infty.\n\n✍ Prove the fact, used in the proof of \n\nTheorem 6.2.1, that 1+x\\le e^x for all x\\ge 0.\n\n✍ Suppose that the error in making a step is also subject to roundoff error \\epsilon_{i+1}, so that the total local error per unit step is Ch^p+\\epsilon_{i+1} h^{-1}; assume that |\\epsilon_{i+1}| \\le \\epsilon for all i and that the initial condition is known exactly. Generalize \n\nTheorem 6.2.1 for this case.\n\nAnother point of view is that we can of course make local errors smaller by chopping h in half, but then we have to take twice as many steps. The important quantity, then, is local error per unit step length, which is how τ is defined.","type":"content","url":"/euler#exercises","position":7},{"hierarchy":{"lvl1":"Implementation of multistep methods"},"type":"lvl1","url":"/implicit","position":0},{"hierarchy":{"lvl1":"Implementation of multistep methods"},"content":"We now consider some of the practical issues that arise when multistep formulas are used to solve IVPs. In this section we emphasize the vector IVP, \\mathbf{u}'=\\mathbf{f}(t,\\mathbf{u}), and use boldface in the difference formula \n\n(6.6.2) as well.","type":"content","url":"/implicit","position":1},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Explicit methods"},"type":"lvl2","url":"/implicit#explicit-methods","position":2},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Explicit methods"},"content":"As a concrete example, the AB4 method is defined by the formula\\mathbf{u}_{i+1} = \\mathbf{u}_i + h\\, ( \\tfrac{55}{24}\\mathbf{f}_i - \\tfrac{59}{24} \\mathbf{f}_{i-1} + \\tfrac{37}{24}\\mathbf{f}_{i-2} - \\tfrac{9}{24}\\mathbf{f}_{i-3}), \\quad i=3,\\ldots,n-1.\n\nFunction 6.7.1 shows a basic implementation of AB4.\n\nObserve that \n\nFunction 6.4.2 is used to find the starting values \\mathbf{u}_1,\\mathbf{u}_2,\\mathbf{u}_3 that are needed before the iteration formula takes over. As far as RK4 is concerned, it needs to solve  (the same step size as in the AB4 iteration). These results are then used to find \\mathbf{f}_0,\\ldots,\\mathbf{f}_3 and get the main iteration started.\n\nab4\n\n4th-order Adams–Bashforth formula for an IVP\n\n\"\"\"\n    ab4(ivp, n)\n\nApply the Adams-Bashforth 4th order method to solve the given IVP\nusing `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction ab4(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Constants in the AB4 method.\n    k = 4\n    σ = [55, -59, 37, -9] / 24\n\n    # Find starting values by RK4.\n    u = fill(float(ivp.u0), n+1)\n    rkivp = ODEProblem(ivp.f, ivp.u0, (a, a + (k - 1) * h), ivp.p)\n    ts, us = rk4(rkivp, k - 1)\n    u[1:k] .= us\n\n    # Compute history of u' values, from newest to oldest.\n    f = [ivp.f(u[k-i], ivp.p, t[k-i]) for i in 1:k-1]\n\n    # Time stepping.\n    for i in k:n\n        f = [ivp.f(u[i], ivp.p, t[i]), f[1:k-1]...]   # new value of du/dt\n        u[i+1] = u[i] + h * sum(f[j] * σ[j] for j in 1:k)  # advance a step\n    end\n    return t, u\nend\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n4th-order Adams–Bashforth formula for an IVP\n\nfunction [t, u] = ab4(ivp, a, b, n)\r\n%AB4     4th-order Adams-Bashforth formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Constants in the AB4 method.\r\nk = 4;  \r\nsigma = [55; -59; 37; -9] / 24;  \r\n\r\n% Find starting values by RK4.\r\n[ts, us] = rk4(ivp, a, a + (k-1)*h, k-1);\r\nu = zeros(length(u0), n+1);\r\nu(:, 1:k) = us(:, 1:k);\r\n\r\n% Compute history of u' values, from oldest to newest.\r\nf = zeros(length(u0), k);\r\nfor i = 1:k-1\r\n  f(:, k-i) = du_dt(t(i), u(:, i), p);\r\nend\r\n\r\n% Time stepping.\r\nfor i = k:n\r\n  f = [du_dt(t(i), u(:, i), p), f(:, 1:k-1)];   % new value of du/dt\r\n  u(:, i+1) = u(:, i) + h * (f * sigma);        % advance one step\r\nend\n\nAbout the code\n\nLine 21 sets sigma to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 24--26 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then lines 29--32 compute the vector [f_2,f_1,f_0].\n\nLine 36 computes f_i, based on the most recent solution value and time. That goes into the first column of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n4th-order Adams–Bashforth formula for an IVP\n\ndef ab4(du_dt, tspan, u0, n):\n    \"\"\"\n    ab4(du_dt, tspan, u0, n)\n\n    Apply the Adams-Bashforth 4th order method to solve the vector-valued IVP u'=du_dt(u,p,t)\n    over the interval tspan with u(tspan[1])=u0, using n subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Constants in the AB4 method.\n    k = 4\n    sigma = np.array([55, -59, 37, -9]) / 24\n\n    # Find starting values by RK4.\n    ts, us = rk4(du_dt, [a, a + (k - 1) * h], u0, k - 1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[:k] = us[:k].T\n\n    # Compute history of u' values, from newest to oldest.\n    f = np.array([du_dt(t[k-j-2], u[k-j-2]) for j in range(k)])\n\n    # Time stepping.\n    for i in range(k-1, n):\n        f = np.vstack([du_dt(t[i], u[i]), f[:-1]])  # new value of du/dt\n        u[i+1] = u[i] + h * np.dot(sigma, f)  # advance one step\n\n    return t, u.T\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\nConvergence of Adams–Bashforth\n\nExample 6.7.1\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve is called to give an accurate reference solution.\n\nusing OrdinaryDiffEq\nivp = ODEProblem((u, p, t) -> sin((t + u)^2), -1.0, (0.0, 4.0))\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of the AB4 code.\n\nn = @. [round(Int, 4 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.ab4(ivp, n)\n    push!(err, norm(u_ref.(t) - u, Inf))\nend\n@pt :header=[\"n\", \"inf-norm error\"] [n err]\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nusing Plots\nplot(n, err, m=3, \n    label=\"AB4\",  legend=:bottomleft,\n    xaxis=(:log10, L\"n\"),  yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of AB4\")\n\nplot!(n, 0.1 * err[end] * (n / n[end]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nExample 6.7.1\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, a built-in solver is called to give an accurate reference solution.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of the AB4 code.\n\nn = round(4 * 10.^(0:0.5:3)');\nerr = zeros(size(n));\nfor i = 1:length(n)\n    [t, u] = ab4(ivp, a, b, n(i));\n    err(i) = norm(u_ref(t) - u, Inf);\nend\ntable(n, err, variableNames=[\"n\", \"inf-norm error\"])\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nclf, loglog(n, err, '-o')\nhold on\nloglog(n, 0.5 * err(end) * (n / n(end)) .^ (-4), '--')\nxlabel(\"n\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of AB4\")\nlegend(\"AB4\", \"O(n^{-4})\", location=\"southwest\");\n\nExample 6.7.1\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve_ivp is called to give an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = [-1.0]\nu_ref = solve_ivp(du_dt, tspan, u0, dense_output=True, rtol=1e-13, atol=1e-13).sol\n\nNow we perform a convergence study of the AB4 code.\n\nn = array([int(4 * 10**k) for k in linspace(0, 3, 7)])\nerr = []\nresults = PrettyTable([\"n\", \"AB4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ab4(du_dt, tspan, u0, n[i])\n    err.append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[-1]])\n\nprint(results)\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nloglog(n, err, \"-o\", label=\"AB4\")\nloglog(n, 0.5 * err[-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"$n$\"),  ylabel(\"final error\")\nlegend(), title(\"Convergence of AB4\");","type":"content","url":"/implicit#explicit-methods","position":3},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Implicit methods"},"type":"lvl2","url":"/implicit#implicit-methods","position":4},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Implicit methods"},"content":"The implementation of an implicit multistep method is more difficult. Consider the second-order implicit formula AM2, also known as the trapezoid method. To advance from step i to i+1, we need to solve  \\mathbf{z} - \\tfrac{1}{2} h f(t_{i+1},\\mathbf{z})  = \\mathbf{u}_i + \\tfrac{1}{2} h \\mathbf{f}(t_i,\\mathbf{u}_i)\n\nfor \\mathbf{z}. This equation can be written as \\mathbf{g}(\\mathbf{z})=\\boldsymbol{0}, so the rootfinding methods of Chapter 4 can be used. The new value \\mathbf{u}_{i+1} is equal to the root of this equation.\n\nAn implementation of AM2 using \n\nFunction 4.6.3 from \n\nQuasi-Newton methods is shown in \n\nFunction 6.7.2.\n\nam2\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\n\"\"\"\n    am2(ivp, n)\n\nApply the Adams-Moulton 2nd order method to solve given IVP using\n`n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction am2(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initialize output.\n    u = fill(float(ivp.u0), n+1)\n\n    # Time stepping.\n    for i in 1:n\n        # Data that does not depend on the new value.\n        known = u[i] + h / 2 * ivp.f(u[i], ivp.p, t[i])\n        # Find a root for the new value.\n        g = z -> z - h / 2 * ivp.f(z, ivp.p, t[i+1]) - known\n        u_new = levenberg(g, known)\n        u[i+1] = u_new[end]\n    end\n    return t, u\nend\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\nfunction [t, u] = am2(ivp, a, b, n)\r\n% AM2    2nd-order Adams-Moulton (trapezoid) formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  % Data that does not depend on the new value.\r\n  known = u(:,i) + h/2 * du_dt(t(i), u(:, i), p);\r\n  % Find a root for the new value. \r\n  unew = levenberg(@trapzero, known);\r\n  u(:, i+1) = unew(:, end);\r\nend\r\n\r\n% This function defines the rootfinding problem at each step.\r\nfunction F = trapzero(z)\r\n    F = z - h/2 * du_dt(t(i+1), z, p) - known;\r\nend\r\n\r\nend  % main function\n\nAbout the code\n\nLines 32--34 define the function \\mathbf{g}. This is sent to levenberg in line~27 to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\ndef am2(du_dt, tspan, u0, n):\n    \"\"\"\n    am2(du_dt, tspan, u0, n)\n\n    Apply the Adams-Moulton 2nd order method to solve the vector-valued IVP u'=du_dt(u,p,t)\n    over the interval tspan with u(tspan[1])=u0, using n subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        # Data that does not depend on the new value.\n        known = u[i] + h / 2 * du_dt(t[i], u[i])\n        # Find a root for the new value.\n        F = lambda z: z - h / 2 * du_dt(t[i+1], z) - known\n        unew = levenberg(F, known)\n        u[i+1] = unew[-1]\n\n    return t, u.T\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/implicit#implicit-methods","position":5},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Stiff problems"},"type":"lvl2","url":"/implicit#stiff-problems","position":6},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Stiff problems"},"content":"At each time step in \n\nFunction 6.7.2, or any implicit IVP solver, a rootfinding iteration of uncertain expense is needed, requiring multiple calls to evaluate the function \\mathbf{f}. This fact makes the cost of an implicit method much greater on a per-step basis than for an explicit one. Given this drawback, you are justified to wonder whether implicit methods are ever competitive! The answer is emphatically yes, as \n\nDemo 6.7.2 demonstrates.\n\nStiffness\n\nExample 6.7.2\n\nThe following simple ODE uncovers a surprise.\n\nivp = ODEProblem((u, p, t) -> u^2 - u^3, 0.005, (0, 400.0))\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(ivp, 200)\n\nplot(tI, uI;\n    label=\"AM2\", legend=:bottomright,\n    xlabel=L\"t\",  ylabel=L\"u(t)\")\n\nNow we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(ivp, 200)\nscatter!(tE, uE, m=3, label=\"AB4\", ylim=[-4, 2])\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[105:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplt = scatter(tI, uI;\n    m=3,  label=\"AM2, n=200\",  legend=:bottomright,\n    xlabel=L\"t\",  ylabel=L\"u(t)\")\n\nfor n in [1000, 1600]\n    tE, uE = FNC.ab4(ivp, n)\n    plot!(tE, uE, label=\"AM4, n=$n\")\nend\nplt\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!\n\nExample 6.7.2\n\nThe following simple ODE uncovers a surprise.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) u^2 - u^3;\nivp.InitialValue = 0.005;\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\n[tI, uI] = am2(ivp, 0, 400, 200);\nclf\nplot(tI, uI)\nxlabel(\"t\");  ylabel((\"u(t)\"));\n\nNow we repeat the process using the explicit AB4 method.\n\n[tE, uE] = ab4(ivp, 0, 400, 200);\nhold on\nplot(tE, uE, '.', 'markersize', 8)\nylim([-5, 3])\nlegend(\"AM2\", \"AB4\");\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nformat short e\nuE(105:111)\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nclf,  plot(tI, uI, '.', 'markersize', 10)\nhold on\n[tE, uE] = ab4(ivp, 0, 400, 1000);\nplot(tE, uE)\n[tE, uE] = ab4(ivp, 0, 400, 1600);\nplot(tE, uE)\nlegend(\"AM2, n=200\", \"AB4, n=1000\", \"AB4, n=1600\", location=\"northwest\");\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!\n\nExample 6.7.2\n\nThe following simple ODE uncovers a surprise.\n\nf = lambda t, u: u**2 - u**3\nu0 = array([0.005])\ntspan = [0, 400]\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(f, [0.0, 400.0], u0, 200)\nfig, ax = subplots()\nax.plot(tI, uI[0], label=\"AM2\")\nxlabel(\"$t$\"), ylabel(\"$y(t)$\");\n\nSo far, so good. Now we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(f, [0.0, 400.0], u0, 200)\nax.scatter(tE, uE[0], label=\"AB4\")\nax.set_ylim([-4, 2]), ax.legend()\nfig\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[0, 104:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplot(tI, uI[0], color=\"k\", label=\"AM2\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1000)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1000\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1600)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1600\")\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\nlegend();\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!\n\nAlthough the result of \n\nDemo 6.7.2 may seem counter-intuitive, there is no contradiction. A fourth-order explicit formula is more accurate than a second-order implicit one, in the limit h\\to 0. But there is another limit to consider, t\\to \\infty with h fixed, and in this one the implicit method wins.\n\nProblems for which implicit methods are much more efficient than explicit counterparts are called stiff. A complete mathematical description will wait for Chapter 11, but a sure sign of stiffness is the presence of phenomena on widely different time scales. In \n\nDemo 6.7.2, for instance, there are two slow periods during which the solution changes very little, interrupted by a very fast transition in the state. An explicit method “thinks” that the step size must always be dictated by the time scale of the fast transition, whereas an implicit method can take large steps during the slow periods.","type":"content","url":"/implicit#stiff-problems","position":7},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Adaptivity"},"type":"lvl2","url":"/implicit#adaptivity","position":8},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Adaptivity"},"content":"As with RK methods, we can run two time stepping methods simultaneously in order to estimate the error and adjust the step size. For example, we could pair AB3 with AB4 as practically no cost because the methods differ only in how they include known information from the recent past. The more accurate AB4 value should allow an accurate estimate of the local error in the AB3 value, and so on.\n\nBecause multistep methods rely on the solution history, though, changing the step size is more algebraically complicated than for RK methods. If h is changed, then the historical values \\mathbf{u}_{i-1},\\mathbf{u}_{i-2}\\ldots and \\mathbf{f}_{i-1},\\mathbf{f}_{i-2}\\ldots are no longer given at the right moments in time to apply the iteration formula. A typical remedy is to use interpolation to re-evaluate the historical values at the appropriate times. The details are important but not especially illuminating, and we do not give them here.","type":"content","url":"/implicit#adaptivity","position":9},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Exercises"},"type":"lvl2","url":"/implicit#exercises","position":10},{"hierarchy":{"lvl1":"Implementation of multistep methods","lvl2":"Exercises"},"content":"Must stay as #1\n\n⌨ For each IVP, solve the problem using \n\nFunction 6.7.1 with n=100, and plot the solution and the error u-\\hat{u} on separate plots.\n\n(a) u' = -2t u, \\ 0 \\le t \\le 2, \\ u(0) = 2;\\  \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ 0 \\le t \\le 1, \\ u(0) = 2;\\  \\hat{u}(t) = 1-t+e^t\n\n(c) u' = x^2/[u(1+x^3)],\\ 0 \\le x \\le 3, \\ u(0) =1;\\ \\hat{u}(x) =[1+(2/3)\\ln (1+x^3)]^{1/2}\n\n(d) u''+ 9u = 9t, \\: 0< t< 2\\pi, \\: u(0) =1,\\: u'(0) = 1; \\: \\hat{u}(t) = t+\\cos (3t)\n\n(e) u''+ 9u = \\sin(2t), \\: 0< t< 2\\pi, \\: u(0) =2,\\: u'(0) = 1;\n\\quad \\hat{u}(t) = (1/5) \\sin(3t) + 2 \\cos (3t)+ (1/5) \\sin (2t)\n\n(f) u''- 9u = 9t \\: 0< t< 1, \\: u(0) =2,\\: u'(0) = -1; \\: \\hat{u}(t) = e^{3t} + e^{-3t}-t\n\n(g) u''+ 4u'+ 4u = t, \\: 0< t< 4, \\: u(0) =1,\\: u'(0) = 3/4; \\: \\hat{u}(t) = (3t+5/4)e^{-2t} + (t-1)/4\n\n(h) x^2 u'' +5xu' + 4u = 0,\\: 1<x<e^2, \\: u(1) =1, \\: u'(1) = -1; \\: \\hat{u}(x) = x^{-2}( 1 + \\ln x)\n\n(i) 2 x^2 u'' +3xu' - u = 0,\\: 1<x<16, \\: u(1) =4, \\: u'(1) = -1;\n\\quad \\hat{u}(x) = 2(x^{1/2} + x^{-1})\n\n(j) x^2 u'' -xu' + 2u = 0,\\: 1<x<e^{\\pi}, \\: u(1) =3, \\: u'(1) = 4;\n\\quad \\hat{u}(x) = x \\left[ 3 \\cos \\left( \\ln x \\right)+\\sin \\left( \\ln x \\right) \\right]\n\n⌨ For each IVP in Exercise 1, use \n\nFunction 6.7.1 for n=10\\cdot2^d and d=1,\\ldots,10. Make a log-log convergence plot for the final time error |u_n-\\hat{u}(t_n)| versus n, and add a straight line indicating fourth-order convergence.\n\n⌨ Repeat Exercise 1 above  using \n\nFunction 6.7.2.\n\n⌨  Repeat Exercise 2 above using \n\nFunction 6.7.2 and comparing to second-order rather than fourth-order convergence.\n\n⌨ Using \n\nFunction 6.7.2 as a model, write a function bd2 that applies the BD2 method to solve an IVP. Test the convergence of your function on one of the IVPs in \n\nExercise 1 above.\n\n⌨ For double-precision purposes, the exact solution of the IVP in \n\nDemo 6.7.2 satisfies \\hat{u}(400)=1.\n\n(a) Use \n\nFunction 6.7.1 with n=600,800,1000,\\ldots,2000 and make a log-log convergence plot of the error |u_n-1| as a function of n.\n\n(b) Repeat part (a) using \n\nFunction 6.7.2.\n\nConsider the IVP\\mathbf{u}'(t) = \\mathbf{A} \\mathbf{u}(t), \\quad \\mathbf{A}=\n\\begin{bmatrix}\n  0&-4\\\\4&0\n\\end{bmatrix}, \\quad \\mathbf{u}(0) =\n\\begin{bmatrix}\n  1\\\\0\n\\end{bmatrix}.\n\n(a) ✍ Define E(t) = \\bigl\\|\\mathbf{u}(t)\\bigr\\|_2^2. Show that E(t) is constant. (Hint: differentiate \\mathbf{u}^T\\mathbf{u} with respect to time and simplify it.)\n\n(b) ⌨ Use \n\nFunction 6.7.1 to solve the IVP for t\\in[0,20] with n=100 and n=150. Plot |E(t)-E(0)| versus time for both solutions on a single log-linear graph. You should see exponential growth in time. (In this regime, AB4 is acting unstably in a sense discussed in \n\nAbsolute stability.)\n\n(c) ⌨ Repeat part (b) with n=400 and n=600, but on a linear-linear plot. Now you should see only linear growth of |E(t)-E(0)|. (In this regime, AB4 is fully stable.)\n\n(d) ⌨ Repeat part (b) with AM2 instead of AB4, on a linear-linear plot. You will find that AM2 conserves energy, just like the exact solution.\n\n⌨ (a) Modify \n\nFunction 6.7.1 to implement the AB2 method.\n\n(b) Repeat part (b) of the preceding exercise, using AB2 in place of AB4.\n\n(c) Repeat part (c) of the preceding exercise, using AB2 in place of AB4.\n\n⌨ (a) Modify \n\nFunction 6.7.2 to implement the backward Euler (AM1) method.\n\n(b) Repeat part (d) of Exercise 7 above, using AM1 in place of AM2 and n=400,800. Does the AM1 method conserve energy?","type":"content","url":"/implicit#exercises","position":11},{"hierarchy":{"lvl1":"Multistep methods"},"type":"lvl1","url":"/multistep","position":0},{"hierarchy":{"lvl1":"Multistep methods"},"content":"In Runge–Kutta methods we start at u_i to find {u}_{i+1}, taking multiple f-evaluations (stages) to achieve high accuracy. In contrast, multistep methods boost accuracy by employing more of the history of the solution, taking information from the recent past. For the discussion in this and following sections, we introduce the shorthand notationf_i = f(t_i,u_i).\n\nMultistep method for IVPs\n\nA k-step multistep (or linear multistep) method is given by the difference equation\\begin{split}\nu_{i+1} &= a_{k-1}u_i + \\cdots + a_0 u_{i-k+1} \\qquad \\\\ \n& \\qquad + h ( b_kf_{i+1} + \\cdots + b_0 f_{i-k+1}),\n\\end{split}\n\nwhere the a_j and the b_j are constants. If b_k=0, the method is explicit; otherwise, it is implicit.\n\nThe quantities u and f in \n\n(6.6.2) are shown as scalars, but in general they can be vectors.\n\nIn order to use \n\n(6.6.2) as a numerical method, we iterate through i=k-1,\\ldots,n-1. The value u_0 is determined by the initial condition, but we also need some way of generating the starting valuesu_1=\\alpha_1, \\quad \\ldots \\quad u_{k-1}=\\alpha_{k-1}.\n\nIn practice the starting values are often found using an RK formula.\n\nThe difference formula \n\n(6.6.2) defines {u}_{i+1} in terms of known values of the solution and its derivative from the past. In the explicit case with b_k=0, Equation \n\n(6.6.2) immediately gives a formula for the unknown quantity {u}_{i+1} in terms of values at time level t_i and earlier. Thus only one new evaluation of f is needed to make a time step, provided that we store the recent history.\n\nFor an implicit method, however, b_k\\neq 0 and \n\n(6.6.2) has the form  {u}_{i+1} - hb_kf(t_{i+1},{u}_{i+1}) = F(u_i,u_{i-1},\\ldots,u_{i-k+1}).\n\nNow the unknown {u}_{i+1} that we seek appears inside the function f. In general this equation is a nonlinear rootfinding problem for {u}_{i+1} and is not solvable in a finite number of steps by a formula. The implementation of both explicit and implicit multistep formulas is discussed in detail in \n\nImplementation of multistep methods.\n\nAs with RK formulas, a multistep method is entirely specified by the values of a few constants. \n\nTable 6.6.1 and \n\nTable 6.6.2 present some of the most well-known and important formulas. The Adams–Bashforth (AB) methods are explicit, while Adams–Moulton (AM) and backward differentiation formulas (BD) are implicit. The tables also list the methods’ order of accuracy, to be defined shortly. We adopt the convention of referring to a multistep method by appending its order of accuracy to a two-letter name abbreviation, e.g., the AB3 method.\n\nTable 6.6.1:Coefficients of Adams multistep formulas. All have a_{k-1}=1 and a_{k-2} = \\cdots = a_0 = 0.\n\nname/order\n\nsteps k\n\nb_k\n\nb_{k-1}\n\nb_{k-2}\n\nb_{k-3}\n\nb_{k-4}\n\nAB1\n\n1\n\n0\n\n1\n\n(Euler)\n\n\n\n\n\nAB2\n\n2\n\n0\n\n\\frac{3}{2}\n\n-\\frac{1}{2}\n\n\n\n\n\nAB3\n\n3\n\n0\n\n\\frac{23}{12}\n\n-\\frac{16}{12}\n\n\\frac{5}{12}\n\n\n\nAB4\n\n4\n\n0\n\n\\frac{55}{24}\n\n-\\frac{59}{24}\n\n\\frac{37}{24}\n\n-\\frac{9}{24}\n\nAM1\n\n1\n\n1\n\n(Backward Euler)\n\n\n\n\n\n\n\nAM2\n\n1\n\n\\frac{1}{2}\n\n\\frac{1}{2}\n\n(Trapezoid)\n\n\n\n\n\nAM3\n\n2\n\n\\frac{5}{12}\n\n\\frac{8}{12}\n\n-\\frac{1}{12}\n\n\n\n\n\nAM4\n\n3\n\n\\frac{9}{24}\n\n\\frac{19}{24}\n\n-\\frac{5}{24}\n\n\\frac{1}{24}\n\n\n\nAM5\n\n4\n\n\\frac{251}{720}\n\n\\frac{646}{720}\n\n-\\frac{264}{720}\n\n\\frac{106}{720}\n\n-\\frac{19}{720}\n\nTable 6.6.2:Coefficients of backward differentiation formulas. All  have b_k\\neq 0 and b_{k-1} = \\cdots = b_0 = 0.\n\nname/order\n\nsteps k\n\na_{k-1}\n\na_{k-2}\n\na_{k-3}\n\na_{k-4}\n\nb_k\n\nBD1\n\n1\n\n1\n\n(Backward Euler)\n\n\n\n\n\n1\n\nBD2\n\n2\n\n\\frac{4}{3}\n\n-\\frac{1}{3}\n\n\n\n\n\n\\frac{2}{3}\n\nBD3\n\n3\n\n\\frac{18}{11}\n\n-\\frac{9}{11}\n\n\\frac{2}{11}\n\n\n\n\\frac{6}{11}\n\nBD4\n\n4\n\n\\frac{48}{25}\n\n-\\frac{36}{25}\n\n\\frac{16}{25}\n\n-\\frac{3}{25}\n\n\\frac{12}{25}","type":"content","url":"/multistep","position":1},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Generating polynomials"},"type":"lvl2","url":"/multistep#generating-polynomials","position":2},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Generating polynomials"},"content":"An alternative description of a multistep method is the generating polynomials\\begin{split}\n  \\rho(z) &= z^k - a_{k-1} z^{k-1} - \\cdots - a_0,\\\\\n  \\sigma(z) &= b_k z^k + b_{k-1}z^{k-1} + \\cdots + b_0.\n\\end{split}\n\nFor example, the AB3 method is completely specified by  \\rho(z) = z^3-z^2, \\qquad \\sigma(z) = \\tfrac{1}{12}(23z^2-16z+5).\n\nLet ρ and σ be the generating polynomials of a multistep method. Then:\n\nThe polynomial \\rho(z) is monic (i.e., its leading term has a unit coefficient).\n\nThe degree of ρ is the number of steps k.\n\nThe degree of \\sigma(z) is k for an implicit method and less than k for an explicit method.\n\nThe connection between the generating polynomials and the numerical method requires a little abstraction. Let \\mathcal{Z} be a forward-shift operator, so that, for example, \\mathcal{Z} t_i = t_{i+1}, \\mathcal{Z}^3 u_{i-1} = u_{i+2}, and so on. With this, the difference formula \n\n(6.6.2) can be written concisely as  \\rho(\\mathcal{Z}) u_{i-k+1} = h \\sigma(\\mathcal{Z}) f_{i-k+1}.","type":"content","url":"/multistep#generating-polynomials","position":3},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Truncation and global error"},"type":"lvl2","url":"/multistep#truncation-and-global-error","position":4},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Truncation and global error"},"content":"The definition of local truncation error is easily extended to multistep methods.\n\nLTE and order of accuracy for a multistep IVP method\n\nFor the multistep formula defined by \n\n(6.6.2), the local truncation error is  \\tau_{i+1}(h) = \\frac{\\hat{u}(t_{i+1}) - a_{k-1}\\hat{u}(t_i) - \\cdots - a_0\n    \\hat{u}(t_{i-k+1})}{h} - \\bigl[ b_kf(t_{i+1},\\hat{u}(t_{i+1})) + \\cdots +\n  b_0f(t_{i-k+1},\\hat{u}(t_{i-k+1})) \\bigr].\n\nIf the local truncation error satisfies \\tau_{i+1}(h)=O(h^p), then p is the order of accuracy of the formula. If p>0, the method is consistent.\n\nThe first-order Adams–Moulton method is also known as backward Euler, because its difference equation is  {u}_{i+1} = u_i + hf_{i+1},\n\nwhich is equivalent to a backward-difference approximation to u'(t_{i+1}). AM1 is characterized by \\rho(z) = z-1 and \\sigma(z) = z.\n\nTo derive the LTE, we use the definition:\\begin{split}\n    h\\tau_{i+1}(h) &= \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - hf\\bigl(t_{i+1},\\hat{u}(t_{i+1})\\bigr) \\\\\n    &= \\hat{u}(t_i) + h\\hat{u}'(t_i) + \\frac{h^2}{2}\\hat{u}''(t_i) + O(h^3)\n    - \\hat{u}(t_i) -h \\hat{u}'(t_{i+1}) \\\\\n    &= h\\hat{u}'(t_i) + \\frac{h^2}{2}\\hat{u}''(t_i) + O(h^3)\n    - h[\\hat{u}'(t_i) + h\\hat{u}''(t_i) + O(h^2)]\\\\\n    &= - \\frac{h^2}{2}\\hat{u}''(t_i) + O(h^3).\n\\end{split}\n\nThus \\tau_{i+1}(h)=O(h) and AM1 (backward Euler) is a first-order method.\n\nThe AB2 method has the formula  {u}_{i+1} = u_i + h\\left(\\frac{3}{2} f_i - \\frac{1}{2} f_{i-1} \\right).\n\nThe generating polynomials are \\rho(z)=z^2-z and \\sigma(z) = (3z-1)/2. We find that the method is second order from the LTE:\\begin{split}\n  h\\tau_{i+1}(h)\n  & = \\hat{u}(t_{i+1}) - \\hat{u}(t_i) - h\\left[\n    \\frac{3}{2}f(t_i,\\hat{u}(t_i)) - \\frac{1}{2}f(t_{i-1},\\hat{u}(t_{i-1}))\n    \\right]                                                                                   \\\\\n  & = \\hat{u}(t_i) + h\\hat{u}'(t_i) + \\frac{h^2}{2}\\hat{u}''(t_i) + \\frac{h^3}{6}\\hat{u}'''(t_i) + O(h^4) \\\\\n  & \\qquad - \\hat{u}(t_i) - \\frac{3h}{2}\\hat{u}'(t_i)  \\\\\n  &\\qquad  + \\frac{h}{2} \\bigl[\\hat{u}'(t_i) - h\\hat{u}''(t_i) + \\frac{h^2}{2}\\hat{u}'''(t_i) + O(h^3)\\bigr]        \\\\\n  & = \\frac{5h^3}{12}\\hat{u}'''(t_i) + O(h^4),\n\\end{split}\n\nso that \\tau_{i+1}(h)=O(h^2).\n\nAlthough we will not present the analysis, the main conclusion for the multistep methods in this section is the same as for one-step methods.\n\nThe global error of each method in \n\nTable 6.6.1 and \n\nTable 6.6.2 converges at the same order as the local truncation error.","type":"content","url":"/multistep#truncation-and-global-error","position":5},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Derivation of the formulas"},"type":"lvl2","url":"/multistep#derivation-of-the-formulas","position":6},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Derivation of the formulas"},"content":"Where do coefficients like those in \n\nTable 6.6.1 come from? There are different ways to answer that question, but Adams and BD methods have distinctive stories to tell. The derivation of Adams methods begins with the observation that  \\hat{u}(t_{i+1}) = \\hat{u}(t_i) + \\int_{t_i}^{t_{i+1}} \\hat{u}'(t) \\, dt =\n  \\hat{u}(t_i) + \\int_{t_i}^{t_{i+1}} f\\bigl(t,\\hat{u}(t)\\bigr) \\, dt.\n\nAs a result, a k-step Adams method always has \\rho(z)=z^k-z^{k-1}. While the integrand above is unknown over the interval of integration, we can approximate it by a polynomial interpolant of the historical values of f. That polynomial can be integrated analytically, leading to a derivation of the coefficients b_0,\\ldots,b_k.\n\nLet’s derive a one-step AM method using the two values (t_i,f_i) and (t_{i+1},f_{i+1}). The interpolating polynomial is the linear functionp(t) = f_i\\frac{t_{i+1}-t}{t_{i+1}-t_i} + f_{i+1}\\frac{t-t_i}{t_{i+1}-t_i}.\n\nThings become a little easier with the change of variable s=t-t_i and applying h=t_{i+1}-t_i:\\int_{t_i}^{t_{i+1}} p(t)  \\, d t = \\int_0^h p(t_i+s) \\, d s\n= h^{-1} \\int_0^h [ (h-s)f_i + s f_{i+1} ]\\, d s = \\frac{h}{2}(f_i + f_{i+1}).\n\nHence \\sigma(z)=\\tfrac{1}{2}z + \\tfrac{1}{2}. Like the trapezoid formula for a definite integral, AM2 computes the exact integral of a piecewise linear interpolant, and it often goes by the trapezoid name as well.\n\nIn AB methods, the interpolating polynomial has degree k-1, which means that its interpolation error is O(h^k). Upon integrating we get a local error of O(h^{k+1}), which reduces to a global error of O(h^k). The AM interpolating polynomial is one degree larger, so its order of accuracy is one higher for the same number of steps.\n\nThe idea behind backward differentiation formulas is complementary to that for Adams: Interpolate solution values {u}_{i+1},\\ldots,u_{i-k+1} by a polynomial q, and then, motivated by f(t,\\hat{u})=\\hat{u}'(t), set  f_{i+1} =q'(t_{i+1}).\n\nThe quantity q'(t_{i+1}) can be approximated by a finite difference of the past solution values, leading to the coefficients of \\rho(z) and \\sigma(z)=b_k z^k.\n\nConsulting \n\nTable 5.4.2, we find the finite-difference approximationq'(t_{i+1}) \\approx \\frac{1}{h} \\left( \\frac{3}{2} u_{i+1} - 2 u_i + \\frac{1}{2} u_{i-1} \\right),\n\nfrom which we geth f_{i+1} = \\frac{3}{2} u_{i+1} - 2 u_i + \\frac{1}{2} u_{i-1}.\n\nRearranging and Normalizing by the coefficient of u_{i+1} gives \\rho(z)=z^2 + \\tfrac{4}{3}z - \\tfrac{1}{3} and \\sigma(z) = \\tfrac{2}{3}z^2, which is the BD2 method.","type":"content","url":"/multistep#derivation-of-the-formulas","position":7},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Exercises"},"type":"lvl2","url":"/multistep#exercises","position":8},{"hierarchy":{"lvl1":"Multistep methods","lvl2":"Exercises"},"content":"✍ For each method, write out the generating polynomials \\rho(z) and \\sigma(z).\n\n(a) AM2,\n(b) AB2,\n(c) BD2,\n(d) AM3,\n(e) AB3.\n\n✍ Write out by hand an equation that defines the first solution value u_1 produced by AM1 (backward Euler) for each IVP. (Reminder: This is an implicit formula.)\n\n(a) u' = -2t u, \\quad 0 \\le t \\le 2, \\quad u_0 = 2, \\quad h = 0.2\n\n(b) u' = u + t, \\quad 0 \\le t \\le 1, \\quad u_0 = 2, \\quad h = 0.1\n\n(c) (1+x^3)uu' = x^2,\\quad 0 \\le x \\le 3, \\quad u_0=1, , \\quad h = 0.5\n\n✍ Do the preceding exercise for AM2 (trapezoid) instead of backward Euler.\n\n✍ For each method, find the leading term in the local truncation error using \n\n(6.6.8).\n\n(a) AM2,\n(b) AB2,\n(c) BD2.\n\n✍/ ⌨ For each method, find the leading term in the local truncation error using \n\n(6.6.8). (Computer algebra is recommended.)\n\n(a) AM3,\n(b) AB3,\n(c) BD4.\n\n✍ A formula for the quadratic polynomial interpolant through the points (s_1,y_1), (s_2,y_2), and (s_3,y_3) isp(x) = \\frac{(x-s_2)(x-s_3)}{(s_1-s_2)(s_1-s_3)}\\,y_1 +\n        \\frac{(x-s_1)(x-s_3)}{(s_2-s_1)(s_2-s_3)}\\,y_2 +\n        \\frac{(x-s_1)(x-s_2)}{(s_3-s_1)(s_3-s_2)}\\,y_3.\n\n(a) Use \n\n(6.6.13) and a polynomial interpolant through three points to derive the coefficients of the AM3 method.\n\n(b) Use \n\n(6.6.16) and a polynomial interpolant through three points to derive the coefficients of the BD2 method.\n\n✍ By doing series expansion about the point z=1, show for BD2 that\\frac{\\rho(z)}{\\sigma(z)} - \\log(z-1) = O\\bigl( (z-1)^3 \\bigr).\n\n✍/ ⌨  By doing series expansion about the point z=1, show for AB3 and AM3 that\\frac{\\rho(z)}{\\sigma(z)} - \\log(z-1) = O\\bigl( (z-1)^4 \\bigr).\n\n(Computer algebra is recommended.)\n\nIf we must use an RK method to start anyway, why bother with multistep formulas at all? The answer is that multistep methods can be more efficient in some problems, even at the same order of accuracy.","type":"content","url":"/multistep#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-5","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"We use Runge-Kutta methods as a class to represent what are also called single-step or one-step methods. A gentle introduction to these and other kinds of IVP methods can be found in Atkinson and Han \n\nAtkinson (1989). More advanced introductions are given in Corless and Fillon \n\nCorless & Fillion (2013) and Iserles \n\nIserles (1996). The most definitive reference is by Hairer et al. \n\nHairer et al. (2008).\n\nA dated but still interesting article about the built-in functions for solving initial value problems in MATLAB is by Shampine \n\nShampine & Reichelt (1997). Methods for a more general type of problem known as differential–algebraic equations are covered in Brenan et al. \n\nBrenan et al. (1996).\n\nInteresting history of IVP methods can be found at\n\n\nthe SIAM website, where C. W. Gear gives both an \n\noral history and an \n\narticle reprinted from \n\nNash (1990).","type":"content","url":"/next-5","position":1},{"hierarchy":{"lvl1":"6. Initial-value problems for ODEs"},"type":"lvl1","url":"/overview-5","position":0},{"hierarchy":{"lvl1":"6. Initial-value problems for ODEs"},"content":"Without precise calculations we could fly right through a star or bounce too close to a supernova and that’d end your trip real quick, wouldn’t it?\n\nHan Solo, Star Wars: A New Hope\n\nQuantities that change continuously in time or space are often modeled by differential equations. When everything depends on just one independent variable, we call the model an ordinary differential equation (ODE).  Differential equations need supplemental conditions to define both the modeling situation and the theoretical solutions uniquely. The initial-value problem (IVP), in which all of the conditions are given at a single value of the independent variable, is the simplest situation. Often the independent variable in this case represents time.\n\nMethods for IVPs usually start from the known initial value and iterate or “march” forward from there. There is a large number of them, owing in part to differences in accuracy, stability, and convenience. The most broadly important methods fall into one of two camps: Runge–Kutta and linear multistep formulas. Each type introduces its own complications, and we will consider them separately.","type":"content","url":"/overview-5","position":1},{"hierarchy":{"lvl1":"Runge–Kutta methods"},"type":"lvl1","url":"/rk","position":0},{"hierarchy":{"lvl1":"Runge–Kutta methods"},"content":"We come now to one of the major and most-used types of methods for initial-value problems: Runge–Kutta (RK) methods. They are one-step methods in the sense of \n\n(6.2.7), though they are not often written in that form. RK methods boost the accuracy past first order by evaluating the ODE function f(t,u) more than once per time step.","type":"content","url":"/rk","position":1},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"A second-order method"},"type":"lvl2","url":"/rk#a-second-order-method","position":2},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"A second-order method"},"content":"Consider a series expansion of the exact solution to u'=f(t,u),\\hat{u}(t_{i+1}) = \\hat{u}(t_i) + h \\hat{u}'(t_i) + \\frac{1}{2}h^2 \\hat{u}''(t_i) + O(h^3) .\n\nIf we replace \\hat{u}' by f and keep only the first two terms on the right-hand side, we would obtain the Euler method. To get more accuracy we will need to compute or estimate the third term as well. Note that\\hat{u}'' = f' = \\frac{d f}{d t} = \\frac{\\partial f}{\\partial t} + \\frac{\\partial f}{\\partial u} \\frac{d u}{d t} = f_t + f_u f,\n\nwhere we have applied the multidimensional chain rule to the derivative, because both of the arguments of f depend on t. Using this expression in \n\n(6.4.1), we obtain\\begin{split}\n  \\hat{u}(t_{i+1}) &= \\hat{u}(t_i) \\\\ \n  & + h\\left[f\\bigl(t_i,\\hat{u}(t_i)\\bigr) +\n    \\frac{h}{2}f_t\\bigl(t_i,\\hat{u}(t_i)\\bigr) +\n    \\frac{h}{2}f\\bigl(t_i,\\hat{u}(t_i)\\bigr)\\,f_u\\bigl(t_i,\\hat{u}(t_i)\\bigr)\\right] \\\\\n  &+ O(h^3).\n\\end{split}\n\nWe have no desire to calculate and then code those partial derivatives of f directly; an approximate approximation is called for. Observe that\\begin{split}\n  f\\bigl(t_i+\\alpha,\\hat{u}(t_i)+\\beta\\bigr) & = f\\bigl(t_i,\\hat{u}(t_i)\\bigr) \\\\ \n  & +\n  \\alpha f_t\\bigl(t_i,\\hat{u}(t_i)\\bigr) + \\beta f_u\\bigl(t_i,\\hat{u}(t_i)\\bigr) \\\\ \n  & + O\\bigl(\\alpha^2 + |\\alpha\\beta| + \\beta^2\\bigr).\n\\end{split}\n\nMatching this expression to the term in brackets in \n\n(6.4.3), it seems natural to select \\alpha = h/2 and \\beta = \\frac{1}{2}h f\\bigl(t_i,\\hat{u}(t_i)\\bigr). Doing so, we find  \\hat{u}(t_{i+1}) = \\hat{u}(t_i) + h\\left[f\\bigl(t_i+\\alpha,\\hat{u}(t_i)+\\beta\\bigr)\\right] +\n  O(h\\alpha^2 + h|\\alpha \\beta| + h\\beta^2 + h^3).\n\nTruncation of the series here results in a new one-step method.\n\nImproved Euler method (IE2)\n\nThe improved Euler method is the one-step formula{u}_{i+1} = u_i +  hf\\left(t_i+\\tfrac{1}{2}h,u_i+\\tfrac{1}{2}h f(t_i,u_i)\\right).\n\nThanks to the definitions above of α and β, the omitted terms are of size  O(h\\alpha^2 + h|\\alpha \\beta| + h\\beta^2 + h^3) = O(h^3).\n\nTherefore h\\tau_{i+1}=O(h^3), and the order of accuracy of improved Euler is two.","type":"content","url":"/rk#a-second-order-method","position":3},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Implementation"},"type":"lvl2","url":"/rk#implementation","position":4},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Implementation"},"content":"Runge–Kutta methods are called multistage methods. We can see why if we interpret \n\n(6.4.6) from the inside out. In the first stage, the method takes an Euler half-step to time t_i+\\frac{1}{2}h:\\begin{split}\n  k_1 &= h f(t_i,u_i), \\\\\n  v &= u_i + \\tfrac{1}{2}k_1.\n\\end{split}\n\nThe second stage employs an Euler-style strategy over the whole time step, but using the value from the first stage to get the slope:\\begin{split}\n  k_2 &= h f\\left(t_i+\\tfrac{1}{2}h,v\\right),\\\\\n  {u}_{i+1} &= u_i + k_2.\n\\end{split}\n\nOur implementation of IE2 is shown in \n\nFunction 6.4.1.\n\nie2\n\nImproved Euler method for an IVP\n\n\"\"\"\n    ie2(ivp, n)\n\nApply the Improved Euler method to solve the given IVP using `n`\ntime steps. Returns a vector of times and a vector of solution\nvalues.\n\"\"\"\nfunction ie2(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initialize output.\n    u = fill(float(ivp.u0), n+1)\n\n    # Time stepping.\n    for i in 1:n\n        uhalf = u[i] + h / 2 * ivp.f(u[i], ivp.p, t[i])\n        u[i+1] = u[i] + h * ivp.f(uhalf, ivp.p, t[i] + h / 2)\n    end\n    return t, u\nend\n\nImproved Euler method for an IVP\n\nfunction [t, u] = ie2(ivp, a, b, n)\r\n% IE2    Improved Euler method for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping. \r\nfor i = 1:n \r\n    uhalf = u(:, i) + h/2 * du_dt(t(i), u(:, i), p);\r\n    u(:, i+1) = u(:, i) + h * du_dt(t(i) + h/2, uhalf, p);\r\nend\n\nImproved Euler method for an IVP\n\ndef ie2(du_dt, tspan, u0, n):\n    \"\"\"\n    ie2(du_dt, tspan, u0, n)\n\n    Apply the Improved Euler method to solve the vector-valued IVP u'=du_dt(u,p,t) over the\n    interval tspan with u(tspan[1])=u0, using n subintervals/steps. Returns a vector\n    of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        uhalf = u[i] + h / 2 * du_dt(t[i], u[i])\n        u[i+1] = u[i] + h * du_dt(t[i] + h / 2, uhalf)\n\n    return t, u.T","type":"content","url":"/rk#implementation","position":5},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"More Runge–Kutta methods"},"type":"lvl2","url":"/rk#more-runge-kutta-methods","position":6},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"More Runge–Kutta methods"},"content":"While it is interesting to interpret IE2 as a pair of Euler-like steps, the Taylor series derivation is the only way to see that it will be more accurate than Euler, and it is also the path to deriving other methods. Moving to higher orders of accuracy requires introducing additional stages, each having free parameters so that more terms in the series may be matched. The amount of algebra grows rapidly in size and complexity, though there is a sophisticated theory for keeping track of it. We do not give the derivation details.\n\nA generic s-stage RK method takes the form  \\begin{split}\n    k_1 &= h f(t_i,u_i),\\\\\n    k_2 &= h f(t_i+c_1h,u_i + a_{11}k_1),\\\\\n    k_3 &= h f(t_i+c_2h, u_i + a_{21}k_1 + a_{22}k_2),\\\\\n    &\\vdots\\\\\n    k_s &= h f(t_i + c_{s-1}h, u_i + a_{s-1,1}k_1 + \\cdots +\n    a_{s-1,s-1}k_{s-1}),\\\\\n    \\mathbf{u}_{i+1} &= u_i + b_1k_1 + \\cdots + b_s k_s.\n  \\end{split}\n\nThis recipe is completely determined by the number of stages s and the constants a_{ij}, b_j, and c_i.  Often an RK method is presented as just a table of these numbers, as in  \\begin{array}{r|ccccc}\n    0 &  &  & & & \\\\\n    c_1 & a_{11} & & &\\\\\n    c_2 & a_{21} & a_{22} & & &\\\\\n    \\vdots & \\vdots & & \\ddots & &\\\\\n    c_{s-1} & a_{s-1,1} & \\cdots & & a_{s-1,s-1}&\\\\[1mm] \\hline\n    \\rule{0pt}{2.25ex}    & b_1 & b_2 & \\cdots & b_{s-1} & b_s\n  \\end{array}\n\nFor example, IE2 is given by  \\begin{array}{r|cc}\n    \\rule{0pt}{2.75ex}0 &  &  \\\\\n    \\rule{0pt}{2.75ex}\\frac{1}{2} & \\frac{1}{2} &\\\\[1mm] \\hline\n    \\rule{0pt}{2.75ex}& 0 & 1\n  \\end{array}\n\nHere are two more two-stage, second-order methods, modified Euler and Heun’s method, respectively:  \\begin{array}{r|cc}\n    \\rule{0pt}{2.75ex}0 &  &  \\\\\n    \\rule{0pt}{2.75ex}1 & 1 &\\\\[1mm] \\hline\n    \\rule{0pt}{2.75ex}& \\frac{1}{2} & \\frac{1}{2}\n  \\end{array}\n  \\qquad \\qquad\n  \\begin{array}{r|cc}\n   \\rule{0pt}{2.75ex} 0 &  &  \\\\\n   \\rule{0pt}{2.75ex} \\frac{2}{3} & \\frac{2}{3} &\\\\[1mm] \\hline\n   \\rule{0pt}{2.75ex} & \\frac{1}{4} & \\frac{3}{4}\n  \\end{array}\n\nAttention\n\nEuler, improved Euler (IE2), and modified Euler (ME2) are all distinct numerical methods.\n\nThe most commonly used RK method, and perhaps the most popular IVP method of all, is the fourth-order one given by  \\begin{array}{r|cccc}\n    \\rule{0pt}{2.75ex}0 &  & & & \\\\\n    \\rule{0pt}{2.75ex}\\frac{1}{2} & \\frac{1}{2} & & &\\\\\n    \\rule{0pt}{2.75ex}\\frac{1}{2} & 0 & \\frac{1}{2} & &\\\\\n    \\rule{0pt}{2.75ex}1 & 0 & 0 & 1\\\\[1mm] \\hline\n    \\rule{0pt}{2.75ex}& \\frac{1}{6} & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{6}\n  \\end{array}\n\nThis formula is often referred to as the fourth-order RK method, even though there are many others, and we refer to it as RK4.  Written out, the recipe is as follows.\n\nFourth-order Runge–Kutta method (RK4)  \\begin{split}\n    k_1 &= hf(t_i,u_i), \\\\\n    k_2 &= hf(t_i+h/2,u_i+k_1/2),\\\\\n    k_3 &= hf(t_i+h/2,u_i+k_2/2),\\\\\n    k_4 &= hf(t_i+h,u_i+k_3),\\\\\n    u_{i+1} &= u_i + \\frac{1}{6} k_1 + \\frac{1}{3} k_2 + \\frac{1}{3} k_3 + \\frac{1}{6} k_4.\n  \\end{split}\n\nOur implementation is given in \n\nFunction 6.4.2.\n\nrk4\n\nFourth-order Runge-Kutta for an IVP\n\n\"\"\"\n    rk4(ivp, n)\n\nApply the common Runge-Kutta 4th order method to solve the given\nIVP using `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk4(ivp, n)\n\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initialize output.\n    u = fill(float(ivp.u0), n+1)\n\n    # Time stepping.\n    for i in 1:n\n        k₁ = h * ivp.f(u[i], ivp.p, t[i])\n        k₂ = h * ivp.f(u[i] + k₁ / 2, ivp.p, t[i] + h / 2)\n        k₃ = h * ivp.f(u[i] + k₂ / 2, ivp.p, t[i] + h / 2)\n        k₄ = h * ivp.f(u[i] + k₃, ivp.p, t[i] + h)\n        u[i+1] = u[i] + (k₁ + 2(k₂ + k₃) + k₄) / 6\n    end\n    return t, u\nend\n\nFourth-order Runge-Kutta for an IVP\n\nfunction [t, u] = rk4(ivp, a, b, n)\r\n% RK4    Fourth-order Runge-Kutta for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  k1 = h * du_dt( t(i),       u(:, i)       , p);\r\n  k2 = h * du_dt( t(i) + h/2, u(:, i) + k1/2, p );\r\n  k3 = h * du_dt( t(i) + h/2, u(:, i) + k2/2, p );\r\n  k4 = h * du_dt( t(i) + h,   u(:, i) + k3  , p);\r\n  u(:, i+1) = u(:, i) + (k1 + 2*(k2 + k3) + k4) / 6;\r\nend\n\nFourth-order Runge-Kutta for an IVP\n\ndef rk4(du_dt, tspan, u0, n):\n    \"\"\"\n    rk4(du_dt, tspan, u0, n)\n\n    Apply \"the\" Runge-Kutta 4th order method to solve the vector-valued IVP u'=du_dt(u,p,t)\n    over the interval tspan with u(tspan[1])=u0, using n subintervals/steps.\n    Return a vector of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        k1 = h * du_dt(t[i], u[i])\n        k2 = h * du_dt(t[i] + h / 2, u[i] + k1 / 2)\n        k3 = h * du_dt(t[i] + h / 2, u[i] + k2 / 2)\n        k4 = h * du_dt(t[i] + h, u[i] + k3)\n        u[i+1] = u[i] + (k1 + 2 * (k2 + k3) + k4) / 6\n\n    return t, u.T\n\nConvergence of Runge–Kutta methods\n\nExample 6.4.1\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nusing OrdinaryDiffEq\nf(u, p, t) = sin((t + u)^2)\ntspan = (0.0, 4.0)\nu₀ = -1.0\nivp = ODEProblem(f, u₀, tspan)\n\nWe use a DifferentialEquations solver to construct an accurate approximation to the exact solution.\n\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = [round(Int, 2 * 10^k) for k in 0:0.5:3]\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n    t, u = FNC.ie2(ivp, n)\n    err[k, 1] = norm(u_ref.(t) - u, Inf)\n    t, u = FNC.rk4(ivp, n)\n    err[k, 2] = norm(u_ref.(t) - u, Inf)\nend\n@pt :header=[\"n\", \"IE2 error\", \"RK4 error\"] [n err]\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nusing Plots\nplot([2n 4n], err;\n    m=3, label=[\"IE2\" \"RK4\"], legend=:bottomleft,\n    xaxis=(:log10, \"f-evaluations\"),  yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of RK methods\")\n\nplot!(2n, 0.1 * err[end,1] * (n / n[end]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\nplot!(4n, 0.1 * err[end,2] * (n / n[end]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.\n\nExample 6.4.1\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nWe use a built-in solver to construct an accurate approximation to the exact solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = round(2 * 10.^(0:0.5:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    [t, u] = ie2(ivp, a, b, n(i));\n    err(i, 1) = norm(u_ref(t) - u, Inf);\n    [t, u] = rk4(ivp, a, b, n(i));\n    err(i, 2) = norm(u_ref(t) - u, Inf);\nend\n\ntable(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"IE2 error\", \"RK4 error\"])\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nclf, loglog([2*n 4*n], err, '-o')\nhold on\nloglog(2*n, 1e-5 * (n / n(end)) .^ (-2), '--')\nloglog(4*n, 1e-10 * (n / n(end)) .^ (-4), '--')\nxlabel(\"f-evaluations\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of RK methods\")\nlegend(\"IE2\", \"RK4\", \"O(n^{-2})\", \"O(n^{-4})\", \"location\", \"southwest\");\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.\n\nExample 6.4.1\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We start by getting a reference solution to validate against.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = -1.0\nsol = solve_ivp(du_dt, tspan, [u0], dense_output=True, atol=1e-13, rtol=1e-13)\nu_ref = sol.sol\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = array([int(2 * 10**k) for k in linspace(0, 3, 7)])\nerr = {\"IE2\" : [], \"RK4\" : []}\nresults = PrettyTable([\"n\", \"IE2 error\", \"RK4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ie2(du_dt, tspan, u0, n[i])\n    err[\"IE2\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    t, u = FNC.rk4(du_dt, tspan, u0, n[i])\n    err[\"RK4\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[\"IE2\"][-1], err[\"RK4\"][-1]])\n\nprint(results)\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nloglog(2 * n, err[\"IE2\"], \"-o\", label=\"IE2\")\nloglog(4 * n, err[\"RK4\"], \"-o\", label=\"RK4\")\nplot(2 * n, 0.5 * err[\"IE2\"][-1] * (n / n[-1])**(-2), \"--\", label=\"2nd order\")\nplot(4 * n, 0.5 * err[\"RK4\"][-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"f-evaluations\"),  ylabel(\"inf-norm error\")\nlegend()\ntitle(\"Convergence of RK methods\");\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/rk#more-runge-kutta-methods","position":7},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Efficiency"},"type":"lvl2","url":"/rk#efficiency","position":8},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Efficiency"},"content":"As with rootfinding and integration, the usual point of view is that evaluations of f are the only significant computations and are therefore to be minimized in number. One of the most important characteristics of a multistage method is that each stage requires an evaluation of f; that is, a single time step of an s-stage method requires s evaluations of f.\n\nThe error decreases geometrically as s is incremented, so trading a stage for an increase in order is a good deal. But s=5, 6, or 7 gives a maximal order of accuracy of s-1; this decreases to s-2 for s=8 and s=9, etc. Fourth order is considered adequate and the sweet spot for many applications.","type":"content","url":"/rk#efficiency","position":9},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Exercises"},"type":"lvl2","url":"/rk#exercises","position":10},{"hierarchy":{"lvl1":"Runge–Kutta methods","lvl2":"Exercises"},"content":"must stay as #1\n\n✍ For each IVP, write out (possibly using a calculator) the first time step of the improved Euler method with h=0.2.\n\n(a) u' = -2t u, \\ 0 \\le t \\le 2, \\ u(0) = 2;\\  \\hat{u}(t) = 2e^{-t^2}\n\n(b) u' = u + t, \\ 0 \\le t \\le 1, \\ u(0) = 2;\\  \\hat{u}(t) = -1-t+3e^t\n\n(c) (1+x^3)uu' = x^2,\\ 0 \\le x \\le 3, \\ u(0) = 1;\\ \\hat{u}(x) = [1+(2/3)\\ln (1+x^3)]^{1/2}\n\n✍ Use the modified Euler method to solve the problems in the preceding exercise.\n\n⌨ Modify \n\nFunction 6.4.2 to implement the modified Euler method. Test your function on the IVP in part (a) of Exercise 1 by solving with n=30,60,90,\\ldots,300 and plotting the convergence of the error at the final time together with a line showing O(n^{-2}).\n\n✍ Use Heun’s method to solve the problems in \n\nExercise 1 above.\n\n⌨ Modify \n\nFunction 6.4.2 to implement Heun’s method. Test your function on the IVP in part (a) of Exercise 1 by solving with n=30,60,90,\\ldots,300 and plotting the convergence of the error at the final time together with a line showing O(n^{-2}).\n\n✍ Use RK4 to solve the problems in \n\nExercise 1 above.\n\n✍ Using \n\n(6.4.3) and \n\n(6.4.4), show that the modified Euler method has order of accuracy at least 2.\n\n✍ Using \n\n(6.4.3) and \n\n(6.4.4), show that Heun’s method has order of accuracy at least 2.\n\n⌨ For each IVP, compute the solution using \n\nFunction 6.4.2. (i) Plot the solution for n=300. (ii) For n=100,200,300,\\ldots,1000, compute the error at the final time and make a log-log convergence plot, including a reference line for fourth-order convergence.\n\n(a) u''+ 9u = 9t, \\: 0< t< 2\\pi, \\: u(0) = 1,\\: u'(0) = 1; \\: \\hat{u}(t) = t+\\cos (3t)\n\n(b) u''+ 9u = \\sin(2t), \\: 0< t< 2\\pi, \\: u(0) = 2,\\: u'(0) = 1;\n\n\\quad \\hat{u}(t) = (1/5) \\sin(3t) + 2 \\cos (3t)+  (1/5) \\sin (2t)\n\n(c) u''- 9u = 9t, \\: 0< t< 1, \\: u(0) = 2,\\: u'(0) = -1; \\: \\hat{u}(t) = e^{3t} + e^{-3t}-t\n\n(d) u''+ 4u'+ 4u = t, \\: 0< t< 4, \\: u(0) = 1,\\: u'(0) = 3/4; \\: \\hat{u}(t) = (3t+5/4)e^{-2t} + (t-1)/4\n\n(e) x^2 y'' +5xy' + 4y = 0,\\: 1<x<e^2, \\: y(1) = 1, \\: y'(1) = -1, \\: \\hat{y}(x) = x^{-2}( 1 + \\ln x)\n\n(f) 2 x^2 y'' +3xy' - y = 0,\\: 1<x<16, \\: y(1) = 4, \\: y'(1) = -1, \\: \\hat{y}(x) = 2(x^{1/2} + x^{-1})\n\n(g) x^2 y'' -xy' + 2y = 0,\\: 1<x<e^{\\pi}, \\: y(1) = 3, \\: y'(1) = 4;\n\n\\quad \\hat{y}(x) = x \\left[ 3 \\cos \\left( \\ln x \\right)+\\sin \\left( \\ln x \\right) \\right]\n\n(h) x^2 y'' + 3xy' + 4y = 0,\\: e^{\\pi/12} < x < e^{\\pi}, \\: y(e^{\\pi/12}) = 0,  \\: y'(e^{\\pi/12}) = -6;\n\n\\quad \\hat{y}(x) = x^{-1} \\left[ 3 \\cos \\left( 3 \\ln x \\right)+\\sin \\left( 3 \\ln x \\right) \\right]\n\n⌨ Do \n\nExercise 6.3.4, but using \n\nFunction 6.4.2 instead of solve.\n\n✍ Consider the problem u'=c u, u(0) = 1 for constant c and t>0.\n\n(a) Find an explicit formula in terms of h and c for u_{i+1}/u_i in the modified Euler method.\n\n(b) Show that if ch=-3, then |u_i|\\to\\infty as i\\to\\infty while the exact solution \\hat{u}(t) approaches zero as t\\to\\infty.\n\nAmericans tend to pronounce these German names as “run-ghuh kut-tah.”","type":"content","url":"/rk#exercises","position":11},{"hierarchy":{"lvl1":"IVP systems"},"type":"lvl1","url":"/systems","position":0},{"hierarchy":{"lvl1":"IVP systems"},"content":"Few applications involve an initial-value problem with just a single dependent variable. Usually there are multiple unknowns and a system of equations to define them.\n\nVariations of the following model are commonly seen in ecology:  \\begin{split}\n    \\frac{d y}{d t} &= y(1-\\alpha y) - \\frac{yz}{1+\\beta y}, \\\\\n    \\frac{d z}{d t} &= -z + \\frac{yz}{1+\\beta y},\n  \\end{split}\n\nwhere α and β are positive constants. This model is a system of two differential equations for the unknown functions y(t), which could represent a prey species or susceptible host, and z(t), which could represent a predator species or infected population.  We refer to this as a predator–prey model. Both of the equations involve both of the unknowns, with no clear way to separate them.\n\nWe can pack the two dependent variables y and z into a vector-valued function of time, \\mathbf{u}(t), writing\\begin{split}\n  u_1'(t) &= f_1(t,\\mathbf{u}) =  u_1(1-au_1) - \\frac{u_1 u_2}{1+bu_1},\\\\\n  u_2'(t) &= f_2(t,\\mathbf{u}) = -u_2 + \\frac{u_1 u_2}{1+bu_1},\n\\end{split}\n\nand identifying u_1=y, u_2=z.\n\nWe now upgrade our IVP definition, \n\nDefinition 6.1.1.\n\nVector-valued IVP / IVP system\n\nA vector-valued first-order initial-value problem (IVP) is  \\mathbf{u}'(t) = \\mathbf{f}\\bigl(t,\\mathbf{u}(t)\\bigr), \\qquad a \\le t \\le b, \\qquad\n  \\mathbf{u}(a)=\\mathbf{u}_0,\n\nwhere \\mathbf{u}(t) is m-dimensional. If \\mathbf{f}(t,\\mathbf{u})=\\mathbf{A}(t)\\mathbf{u}(t)+ \\mathbf{g}(t), the differential equation is linear; otherwise, it is nonlinear.\n\nWe use the terms IVP system and vector-valued IVP interchangeably; a system of scalar IVPs can be put into the form of \n\n(6.3.3) by appropriate definitions of \\mathbf{u} and \\mathbf{f}, as shown in \n\nExample 6.3.1.","type":"content","url":"/systems","position":1},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Numerical solutions"},"type":"lvl2","url":"/systems#numerical-solutions","position":2},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Numerical solutions"},"content":"The generalization of any scalar IVP solver to handle systems is straightforward. Consider Euler’s method, which in system form becomes  \\begin{split}\n    \\mathbf{u}_{i+1} &= \\mathbf{u}_i + h\\,\\mathbf{f}(t_i,\\mathbf{u}_i), \\qquad i=0,\\ldots,n-1.\n  \\end{split}\n\nThe vector difference equation \n\n(6.3.4) is just Euler’s formula applied simultaneously to each component of the ODE system. Because operations such as addition and multiplication translate easily from scalars to vectors, \n\nFunction 6.2.2 that we wrote for scalar IVPs works for systems as well. Practically speaking, the only changes that must be made are that the initial condition and the ODE function have to be coded to use vectors.\n\nPredator-prey model\n\nExample 6.3.2\n\nWe encode the predator–prey equations via a function.\n\nfunction predprey(u, p, t)\n    α, β = p      # rename parameters for convenience\n    y, z = u      # rename solution components\n    s = (y * z) / (1 + β * y)     # appears in both equations\n    return [y * (1 - α * y) - s, -z + s]\nend;\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable.\n\nusing OrdinaryDiffEq\nu₀ = [1, 0.01]\ntspan = (0.0, 60.0)\nα, β = 0.1, 0.25\nivp = ODEProblem(predprey, u₀, tspan, [α, β])\n\nYou can use any DifferentialEquations solver on the IVP system.\n\nusing Plots\nsol = solve(ivp, Tsit5());\nplot(sol, label=[\"prey\" \"predator\"],\n    title=\"Predator-prey solution\")\n\nWe can find the discrete values used to compute the interpolated solution. The sol.u value is a vector of vectors.\n\nt, u = sol.t, sol.u    # extract times and solution values\n@show size(u);\n@show t[20];\n@show u[20];\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt, u = FNC.euler(ivp, 1200);\n\nThe solution u is a vector of [prey,predator] 2-vectors for each of the discrete times in t. Manipulating the vector-of-vectors output can be a little tricky. Here, we convert it to an n\\times 2 matrix. Each column is one component, while each row is a single value of t.\n\nu = [u[j] for u in u, j in 1:2]\nplot!(t[1:3:end], u[1:3:end, :];\n    l=(1, :black),  m=2,\n    label=[\"Euler prey\" \"Euler predator\"])\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nTip\n\nYou can use idxs in the plot of a solution produced by solve to specify the components of the solution that appear on each axis.\n\nplot(sol, idxs=(1, 2),\n    title=\"Predator-prey in the phase plane\",\n    xlabel=L\"y\",  ylabel=L\"z\")\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nExample 6.3.2\n\nWe encode the predator–prey equations via a function, defined here externally.\n\nfunction du_dt = predprey(t, u, p)\n    alpha = p(1);  beta = p(2);\n    y = u(1);      z = u(2);\n    s = (y * z) / (1 + beta * y);  % appears in both equations\n    du_dt = [ y * (1 - alpha * y) - s;  -z + s ];\nend\n\n\nThe values of alpha and beta are parameters that influence the solution of the IVP. We use the Parameters field of the IVP object to define them for the solver, which in turn passes them as the third argument into our ODE function.\n\nu0 = [1; 0.01];    % column vector\np = [0.1, 0.25];\nivp = ode;\nivp.ODEFcn = @f63_predprey;\nivp.InitialValue = u0;\nivp.Parameters = p;\nsol = solve(ivp, 0, 60);\nsize(sol.Solution)\n\nEach column of the Solution field is the solution vector \\mathbf{u} at a particular time; each row is a component of \\mathbf{u} over all time.\n\nclf\nplot(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle('Predator-prey solution')\nlegend('prey', 'predator');\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\n[t, u] = eulerivp(ivp, 0, 60, 1200);\n\nhold on\nplot(t, u, '.')\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nclf\nplot(u(1, :), u(2, :))\ntitle(\"Predator-prey in the phase plane\")\nxlabel(\"y\")\nylabel((\"z\"));\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nExample 6.3.2\n\nWe encode the predator–prey equations via a function.\n\ndef predprey(t, u):\n    y, z = u                        # rename for convenience\n    s = (y * z) / (1 + beta * y)    # appears in both equations\n    return array([y * (1 - alpha * y) - s, -z + s])\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable. These are given in the call to solve_ivp.\n\nfrom scipy.integrate import solve_ivp\nu0 = array([1, 0.01])\ntspan = [0.0, 80.0]\nalpha, beta = 0.1, 0.25\nsol = solve_ivp(predprey, tspan, u0, dense_output=True)\nprint(f\"solved with {sol.y.shape[1]} time steps\")\n\nAs in scalar problems, the solution object has fields t and y that contain the values of the independent and dependent variables, respectively. Each row of y represents one component of the solution at every time step, and each column of y is the entire solution vector at one time step. Since we used dense_output=True, there is also a method sol that can be used to evaluate the solution at any time.\n\nt = linspace(0, 80, 1200)\nu = vstack([sol.sol(t[i]) for i in range(t.size)]).T    # same shape as sol.y\nfig, ax = subplots()\nax.plot(t, u[0, :], label=\"prey\")\nax.plot(t, u[1, :], label=\"predator\")\nxlabel(\"$t$\"), ylabel(\"population\")\ntitle((\"Predator-prey solution\"));\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt_E, u_E = FNC.euler(predprey, tspan, u0, 800)\nax.scatter(t_E, u_E[0, :], label=\"prey (Euler)\", s=1)\nax.scatter(t_E, u_E[1, :], label=\"predator (Euler)\", s=2)\nax.legend()\nfig\n\nYou can see above that the Euler solution is not very accurate. When the solution has two components, it’s common to plot the it in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nplot(u[0, :], u[1, :])\nxlabel(\"prey\"), ylabel(\"predator\")\ntitle((\"Predator-prey phase plane\"));\n\nFrom this plot we can see that the solution approaches a periodic one, which in the phase plane is represented by a closed path.\n\nIn the rest of this chapter we present methods as though they are for scalar equations, but their application to systems is taken for granted. The generalization of error analysis can be more complicated, but our statements about order of accuracy and other properties are true for systems as well as scalars. The codes are all written to accept systems.","type":"content","url":"/systems#numerical-solutions","position":3},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Transformation of high-order systems"},"type":"lvl2","url":"/systems#transformation-of-high-order-systems","position":4},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Transformation of high-order systems"},"content":"Fortunately, the ability to solve first-order ODE systems implies the ability to solve systems of higher differential order, too. The reason is that there is a systematic way to turn a higher-order problem into a first-order one of higher dimension.\n\nConsider the nonlinear initial-value problem  y''+(1+y')^3 y = 0, \\qquad y(0)= y_0, \\quad y'(0) = 0.\n\nIn order to write this problem as a first-order system we define two scalar unknown functions, u_1 = y and u_2 = y'. With these definitions, we have the two differential equations\\begin{split}\n  u_1' &= u_2, \\\\\n  u_2' &= -(1+u_2)^3 u_1,\n\\end{split}\n\nwhich is a first-order system in two dimensions. The initial\ncondition of the system is  u_1(0) = y_0, \\quad u_2(0) = 0.\n\nTwo identical pendulums suspended from the same rod and swinging in parallel planes can be modeled as the second-order system\\begin{split}\n  \\theta_1''(t) +\\gamma \\theta_1' + \\frac{g}{L} \\sin \\theta_1 +\n  k(\\theta_1-\\theta_2) &= 0,\\\\\n  \\theta_2''(t) +\\gamma \\theta_2' + \\frac{g}{L} \\sin \\theta_2 +\n  k(\\theta_2-\\theta_1) &= 0,\n\\end{split}\n\nwhere \\theta_1 and \\theta_2 are angles made by the two pendulums, L is the length of each pendulum, γ is a frictional parameter, and k is a parameter describing a torque produced by the rod when it is twisted. We can convert this problem into a first-order system using the substitutions  u_1 = \\theta_1, \\quad u_2 = \\theta_2, \\quad u_3 = \\theta_1', \\quad\n  u_4 = \\theta_2'.\n\nWith these definitions the system becomes\\begin{split}\n  u_1' &= u_3, \\\\\n  u_2' &= u_4, \\\\\n  u_3' &= -\\gamma u_3 - \\frac{g}{L}\\sin u_1 + k(u_2-u_1), \\\\\n  u_4' &= -\\gamma u_4 - \\frac{g}{L}\\sin u_2 + k(u_1-u_2),\n\\end{split}\n\nwhich is a first-order system in four dimensions. To complete the description of the problem, you need to specify values for \\theta_1(0), \\theta_1'(0), \\theta_2(0), and \\theta_2'(0).\n\nThe trick illustrated in the preceding examples is always available. Suppose y is a scalar dependent variable in the system. You should introduce a component of \\mathbf{u} for y, y', etc., up to but not including the highest derivative appearing anywhere for y. This is done for each scalar variable in the original system. There should be one component of \\mathbf{u} for each scalar initial condition given. Many equations for the first-order system then come from the trivial relationships among all the lower derivatives. The remaining equations for the system come from the original, high-order equations. In the end, there must be as many scalar component equations as unknown first-order variables.\n\nCoupled pendulums\n\nExample 6.3.5\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nTip\n\nThe similar function creates an array of the same size and type as a given value, without initializing the contents.\n\nfunction couple(u, p, t)\n    γ, L, k = p\n    g = 9.8\n    udot = similar(u)\n    udot[1:2] .= u[3:4]\n    udot[3] = -γ * u[3] - (g / L) * sin(u[1]) + k * (u[2] - u[1])\n    udot[4] = -γ * u[4] - (g / L) * sin(u[2]) + k * (u[1] - u[2])\n    return udot\nend\n\nu₀ = [1.25, -0.5, 0, 0]\ntspan = (0.0, 50.0);\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nTip\n\nHere idxs is used to plot two components as functions of time.\n\nγ, L, k = 0, 0.5, 0\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], \n    label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], \n    title=\"Uncoupled pendulums\")\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 1\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], \n    label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], \n    title=\"Coupled pendulums\")\n\nThe coupling makes the pendulums swap energy back and forth.\n\nExample 6.3.5\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nfunction udot = pendulums(t, u, p)\n    gamma = p(1);  L = p(2);  k = p(3);\n    g = 9.8;\n    udot = zeros(4, 1);\n    udot(1:2) = u(3:4);\n    udot(3) = -gamma * u(3) - (g / L) * sin(u(1)) + k * (u(2) - u(1));\n    udot(4) = -gamma * u(4) - (g / L) * sin(u(2)) + k * (u(1) - u(2));\nend\n\n\nu0 = [1.25; -0.5; 0; 0];\na = 0; b = 50;\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nTip\n\nHere OutputVariables is used to restrict output to just u_1 and u_2.\n\nparams =[0.01, 0.5, 0];    % gamma, L, k\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nt = linspace(a, b, 1001);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\");\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nparams(3) = 1;\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Coupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\");\n\nThe coupling makes the pendulums swap energy back and forth.\n\nExample 6.3.5\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\ndef couple(t, u, params):\n    gamma, L, k = params\n    g = 9.8\n    udot = copy(u)\n    udot[:2] = u[2:4]\n    udot[2] = -gamma * u[2] - (g / L) * sin(u[0]) + k * (u[1] - u[0])\n    udot[3] = -gamma * u[3] - (g / L) * sin(u[1]) + k * (u[0] - u[1])\n    return udot\n\nu0 = array([1.25, -0.5, 0, 0])\ntspan = [0.0, 50.0]\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nTip\n\nWe use a closure here to pass the fixed parameter values into couple.\n\ngamma, L, k = 0.01, 0.5, 0.0\ndu_dt = lambda t, u: couple(t, u, (gamma, L, k))\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)    # first two components of solution\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\");\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 0.75    # changes the value in the du_dt closure\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Coupled pendulums\");\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/systems#transformation-of-high-order-systems","position":5},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Exercises"},"type":"lvl2","url":"/systems#exercises","position":6},{"hierarchy":{"lvl1":"IVP systems","lvl2":"Exercises"},"content":"✍ Rewrite the given higher order problems as first-order systems.\n\n(a) y'''-3y''+3 y' -y = t, \\: y(0) = 1, \\: y'(0) = 2, \\: y''(0) = 3\n\n(b) y'' + 4 (x^2-1)y' + y = 0, \\: y(0) = 2, \\: y'(0) = -1\n\n(c) For a given constant a,\\begin{split}\n  x'' + \\frac{a x}{(x^2+y^2)^{3/2}} &= 0,\\\\\n  y'' + \\frac{a y}{(x^2+y^2)^{3/2}} &= 0,\n  \\end{split}\n\nwith initial values x(0) = 1, x'(0)=y(0) = 0, y'(0)=3\n\n(d) y^{(4)} -y = e^{-t}, \\: y(0) = 0, \\: y'(0) = 0, \\: y''(0) = 1,\\: y'''(0) = 0\n\n(e) y'''-y''+y'-y = t, \\: y(0) = 1, \\: y'(0) = 2, \\: y''(0) = 3\n\n✍ Write the given IVP as a system. Then do two steps of Euler’s method by hand (perhaps with a calculator) with the indicated step size h. Using the given exact solution, compute the error after the second step.\n\n(a) y''+ 4y = 4t, \\: y(0) = 1,\\: y'(0) = 1; \\: \\hat{y}(t) = t+\\cos (2t),\\: h=0.1\n\n(b) y''- 4y = 4t, \\: y(0) = 2,\\: y'(0) = -1; \\: \\hat{y}(t) = e^{2t} + e^{-2t}-t,\\: h=0.1\n\n(c) 2 x^2 y'' +3xy' - y = 0, \\: y(2) = 1, \\: y'(2) = -1/2,  \\: \\hat{y}(x) = 2/x, h = 1/8\n\n(d) 2 x^2 y'' +3xy' - y = 0,\\: y(1) = 4, \\: y'(1) = -1, \\: \\hat{y}(x) = 2(x^{1/2} + x^{-1}), h=1/4\n\n⌨ Solve the following IVPs using \n\nFunction 6.2.2 using n=1000 steps. Plot the solution and its first derivative together on one plot, and plot the error in each component as functions of time on another.\n\n(a) y''+ 4y = 4t, \\: 0< t< 2\\pi, \\: y(0) = 1,\\: y'(0) = 1; \\: \\hat{y}(t) = t+\\cos (2t)\n\n(b) y''+ 9y = \\sin(2t), \\: 0< t< 2\\pi, \\: y(0) = 2,\\: y'(0) = 1; \\quad \\hat{y}(t) = (1/5) \\sin(3t) + 2 \\cos (3t)+  (1/5) \\sin (2t)\n\n(c) y''- 4y = 4t \\: 0< t< 1.5, \\: y(0) = 2,\\: y'(0) = -1; \\: \\hat{y}(t) = e^{2t} + e^{-2t}-t\n\n(d) y''+ 4y'+ 4y = t, \\: 0< t< 4, \\: y(0) = 1,\\: y'(0) = 3/4; \\: \\hat{y}(t) = (3t+5/4)e^{-2t} + (t-1)/4\n\n(e) x^2 y'' +5xy' + 4y = 0,\\: 1<x<e^2, \\: y(1) = 0, \\: y'(1) = 2, \\: \\hat{y}(x) = (2/x^2) \\ln x\n\n(f) x^2 y'' +5xy' + 4y = 0,\\: 1<x<e^2, \\: y(1) = 1, \\: y'(1) = -1, \\: \\hat{y}(x) = x^{-2}( 1 + \\ln x)\n\n(g) 2 x^2 y'' +3xy' - y = 0,\\: 2<x<20, \\: y(2) = 1, \\: y'(2) = -1/2, \\: \\hat{y}(x) = 2/x\n\n(h) 2 x^2 y'' +3xy' - y = 0,\\: 1<x<16, \\: y(1) = 4, \\: y'(1) = -1, \\: \\hat{y}(x) = 2(x^{1/2} + x^{-1})\n\n(i) x^2 y'' -xy' + 2y = 0,\\: 1<x<e^{\\pi}, \\: y(1) = 3, \\: y'(1) = 4; \\quad \\hat{y}(x) = x \\left[ 3 \\cos \\left( \\ln x \\right)+\\sin \\left( \\ln x \\right) \\right]\n\n(j) x^2 y'' + 3xy' + 4y = 0,\\: e^{\\pi/12} < x < e^{\\pi}, \\: y(e^{\\pi/12}) = 0,  \\: y'(e^{\\pi/12}) = -6; \\quad \\hat{y}(x) = x^{-1} \\left[ 3 \\cos \\left( 3 \\ln x \\right)+\\sin \\left( 3 \\ln x \\right) \\right]\n\n⌨ A disease that is endemic to a population can be modeled by tracking the fraction of the population that is susceptible to infection, v(t), and the fraction that is infectious, w(t). (The rest of the population is considered to be recovered and immune.) A typical model is the SIR model (see \n\nBritton (2003))\\frac{dv}{dt} = 0.2(1-v) - 3vw, \\qquad \\frac{dw}{dt} = (3v-1)w.\n\nStarting with v(0) = 0.95 and w(0) = 0.05, use solve to find the long-term steady values of v(t) and w(t). Plot both components of the solution as functions of time.\n\n⌨ In each case below, use solve to solve the given ODE for 0\\le t \\le 10 with the given initial conditions. Plot the results together as curves in the phase plane (that is, with x and y as the axes of the plot), using aspect_ratio=1 in the plot command.\n\n(a)\\begin{split}\n  x'(t) & = - 4y + x(1-x^2-y^2),\\\\\n  y'(t) & = 4x + y(1-x^2-y^2),\n\\end{split}\n\nwith [x(0),y(0)]=[0.1,0] and [x(0),y(0)]=[0,1.9].\n\n(b)\\begin{split}\n  x'(t) & = - 4y - \\tfrac{1}{4}x(1-x^2-y^2)(4-x^2-y^2),\\\\\n  y'(t) & = 4x - \\tfrac{1}{4}y(1-x^2-y^2)(4-x^2-y^2),\n\\end{split}\n\nwith [x(0),y(0)]=[0.95,0], [0,1.05], and [-2.5,0].\n\n⌨ The FitzHugh–Nagumo equations are a simple model of the repeated firing of a neuron. They are given by\\begin{split}\n\\frac{d v_1}{dt} &= - v_1(v_1-1)(v_1-a) - v_2 + I, \\\\\n\\frac{d v_2}{dt} &= \\epsilon ( v_1 - \\gamma v_2).\n\\end{split}\n\nAssume v_1(0) = 0.5, v_2(0) = 0.1, a = 0.1, \\epsilon = 0.008, \\gamma = 1. For each value of I below, find and plot the solution using solve for 0\\le t \\le 600. The solutions are highly sensitive to I, and you need to change the requested absolute and relative error tolerances to \n\n10-9. In each case the solution quickly approaches a periodic oscillation.\n\n(a) I = 0.05527,\\quad\n(b) I = 0.05683,\\quad\n(c) I = 0.0568385,\\quad\n(d) I = 0.05740.\n\nThis exploration was carried out by Baer and Erneux \n\nBaer & Erneux (1986).","type":"content","url":"/systems#exercises","position":7},{"hierarchy":{"lvl1":"Zero-stability of multistep methods"},"type":"lvl1","url":"/zerostability","position":0},{"hierarchy":{"lvl1":"Zero-stability of multistep methods"},"content":"For one-step methods such as Runge–Kutta, \n\nTheorem 6.2.1 guarantees that the method converges and that the global error is of the same order as the local truncation error. For multistep methods, however, a new wrinkle is introduced.\n\nInstability\n\nIt is straightforward to check that the two-step method LIAF, defined by  \\mathbf{u}_{i+1} = -4u_i + 5u_{i-1} + h(4f_i + 2f_{i-1}),\n\nis third-order accurate. Let’s apply it to the ridiculously simple IVP u'=u, u(0)=1, whose solution is e^t.\n\nExample 6.8.1\n\nWe’ll measure the error at the time t=1.\n\ndu_dt(u, t) = u\nû = exp\na, b = 0.0, 1.0;\nn = [5, 10, 20, 40, 60]\nerr = []\nt, u = [], []\nfor n in n\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n    u = [1; û(h); zeros(n - 1)]\n    f_val = [du_dt(u[1], t[1]); zeros(n)]\n    for i in 2:n\n        f_val[i] = du_dt(u[i], t[i])\n        u[i+1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f_val[i] + 2 * f_val[i-1])\n    end\n    push!(err, abs(û(b) - u[end]))\nend\n@pt :header=[\"n\", \"h\", \"error\"] [n (b - a) ./ n err]\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nusing Plots\nplot(t, abs.(u);\n    m=3,  label=\"\",\n    xlabel=L\"t\",  yaxis=(:log10, L\"|u(t)|\"), \n    title=\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.\n\nExample 6.8.1\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = @(t, u) u;\nu_exact = @exp;\na = 0;  b = 1;\nn = [5, 10, 20, 40, 60]';\nerr = zeros(size(n));\nfor j = 1:length(n)\n    h = (b - a) / n(j);\n    t = a + h *(0:n(j));\n    u = [1, u_exact(h), zeros(1, n(j) - 1)];\n    f = [du_dt(t(1), u(1)), zeros(1, n(j) - 2)];\n    for i = 2:n(j)\n        f(i) = du_dt(t(i), u(i));\n        u(i+1) = -4*u(i) + 5*u(i-1) + h * (4*f(i) + 2*f(i-1));\n    end\n    err(j) = abs(u_exact(b) - u(end));\nend\n\nh = (b-a) ./ n;\ntable(n, h, err)\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nclf\nsemilogy(t, abs(u))\nxlabel(\"t\");  ylabel(\"|u(t)|\")\ntitle((\"LIAF solution\"));\n\nIt’s clear that the solution is growing exponentially in time.\n\nExample 6.8.1\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = lambda t, u: u\nu_exact = exp\na, b = (0.0, 1.0)\n\ndef LIAF(du_dt, tspan, u0, n):\n    a, b = tspan\n    h = (b - a) / n\n    t = linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[1] = u_exact(t[1])    # use an exact starting value\n    f = copy(u)\n    f[0] = du_dt(t[0], u[0])\n    for i in range(n):\n        f[i] = du_dt(t[i], u[i])\n        u[i + 1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f[i] + 2 * f[i-1])\n\n    return t, u.T\n\nn = [5, 10, 20, 40, 60]\nresults = PrettyTable([\"n\", \"error\"])\nfor j in range(5):\n    t, u = LIAF(du_dt, [a, b], [1.0], n[j])\n    err = abs(u_exact(b) - u[0, -1])\n    results.add_row([n[j], err])\nprint(results)\n\nThere is no convergence in sight! A graph of the last numerical attempt yields a clue:\n\nsemilogy(t, abs(u[0]), \"-o\")\nxlabel(\"$t$\"), ylabel(\"$|u|$\")\ntitle((\"LIAF solution\"));\n\nIt’s clear that the solution is growing exponentially in time.\n\nThe source of the exponential growth in \n\nDemo 6.8.1 is not hard to identify. Recall that we can rewrite \n\n(6.8.1) as \\rho(\\mathcal{Z})u_{i-1}=h \\sigma(\\mathcal{Z})u_{i-1} using the forward shift operator \\mathcal{Z}:  (\\mathcal{Z}^2 + 4\\mathcal{Z} - 5) u_{i-1} = h(4\\mathcal{Z} + 2)f_{i-1}.\n\n(See \n\n(6.6.7), using k=2 here.) Next, suppose that h is negligible in \n\n(6.8.2). Then the numerical solution of LIAF is roughly defined by  (\\mathcal{Z}^2 + 4\\mathcal{Z} - 5) u_{i-1} = 0.\n\nThe graph in \n\nDemo 6.8.1 strongly suggests that for small h, |u_i|\\approx c \\alpha^i for some \\alpha>1 as m gets large. So we are motivated to try definingu_i = c z^i\n\nfor all i and see if we can prove that it is an exact solution. The beauty of this choice is that for all i,\\mathcal{Z} u_i = u_{i+1} = z u_i.\n\nHence \n\n(6.8.3) becomes  z^2 + 4z - 5 = 0.\n\nTherefore, as h\\to 0, the two roots of z^2+4z+5 will each correspond to an approximate solution in the form \n\n(6.8.4) of the LIAF method. These roots are z=1 and z=-5, and the growth curve at the end of \n\nDemo 6.8.1 is approximately |(-5)^i|.","type":"content","url":"/zerostability","position":1},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Zero-stability"},"type":"lvl2","url":"/zerostability#zero-stability","position":2},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Zero-stability"},"content":"Here is the crucial property that LIAF lacks.\n\nZero-stability of a multistep IVP method\n\nA multistep method is zero-stable if, as h\\to 0, every numerical solution produced by the method remains bounded throughout a\\le t_i \\le b.\n\nWithout zero-stability, any truncation or roundoff error will get exponentially amplified and eventually overwhelm convergence to the exact solution.\n\nThe following theorem concisely summarizes when we can expect zero-stability.\n\nRoot condition\n\nA linear multistep method is zero-stable if and only if every root r of the generating polynomial \\rho(z) satisfies |r|\\le 1, and any root r with |r|=1 is simple.\n\n(Partial proof, when all roots of ρ are simple.) As explained above, the values produced by the numerical method approach solutions of the difference equation \\rho(\\mathcal{Z})u_{i-k+1}=0. We consider only the case where the roots r_1,\\ldots,r_k of \\rho(z). Then u_i=(r_j)^i is a solution of \\rho(\\mathcal{Z})u_i=0 for each j=1,\\ldots,k. By linearity,  u_i = c_1 (r_1)^i + c_2 (r_2)^i + \\cdots + c_k (r_k)^i\n\nis a solution for any values of c_1,\\ldots,c_k. These constants are determined uniquely by the starting values u_0,\\ldots,u_{k-1} (we omit the proof). Now, if all the roots satisfy |r_j|\\le 1, then  |u_i| \\le \\sum_{j=1}^k |c_j| |r_j|^i \\le \\sum_{j=1}^k |c_j|,\n\nindependently of h and i. This proves zero-stability. Conversely, if some |r_j|>1, then |u_i| cannot be bounded above by a constant independent of i. Since b=t_i, i\\to\\infty at t=b as h\\to 0, so zero-stability cannot hold.\n\nA nonsimple root of ρ introduces a modification of \n\n(6.8.4) that is considered in \n\nExercise 4.\n\nA k-step Adams method has \\rho(z) = z^k - z^{k-1} = z^{k-1}(z-1). Hence 1 is a simple root and 0 is a root of multiplicity k-1. So the Adams methods are all stable.\n\nThe method u_{i+1} = 2u_i - u_{i-1} + h(f_i-f_{i-1}) is first-order accurate. But \\rho(z)=(z-1)^2, which has a double root at z=1, so it is not zero-stable.","type":"content","url":"/zerostability#zero-stability","position":3},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Dahlquist theorems"},"type":"lvl2","url":"/zerostability#dahlquist-theorems","position":4},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Dahlquist theorems"},"content":"It turns out that lacking zero-stability is the only thing that can go wrong for a consistent multistep method.\n\nDahlquist equivalence\n\nA linear multistep method converges as h\\to 0 if and only if it is consistent and zero-stable.\n\nThe Dahlquist equivalence theorem is one of the most important and celebrated in the history of numerical analysis. It can be proved more precisely that a zero-stable, consistent method is convergent in the same sense as \n\nTheorem 6.2.1, with the error between numerical and exact solutions being of the same order as the local truncation error, for a wide class of problems.\n\nYou may have noticed that the Adams and BD formulas use only about half of the available data from the past k steps, i.e., they have many possible coefficients set to zero. For instance, a k-step AB method uses only the f_j-values and has order k. The order could be made higher by also using u_j-values, like the LIAF method does for k=2. Also like the LIAF method, however, such attempts are doomed by instability.\n\nFirst Dahlquist stability barrier\n\nThe order of accuracy p of a stable k-step linear multistep method satisfiesp \\le\n\\begin{cases}\n  k+2 & \\text{if $k$ is even},\\\\\n  k+1 & \\text{if $k$ is odd},\\\\\n  k & \\text{if the method is explicit.}\n\\end{cases}\n\nThe lesson of \n\nTheorem 6.8.3 is that accuracy is not the only important feature, and trying to optimize for it leads to failure. New lessons on the same theme appear in \n\nAbsolute stability.","type":"content","url":"/zerostability#dahlquist-theorems","position":5},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Exercises"},"type":"lvl2","url":"/zerostability#exercises","position":6},{"hierarchy":{"lvl1":"Zero-stability of multistep methods","lvl2":"Exercises"},"content":"✍ Show that the LIAF method \n\n(6.8.1) has order of accuracy equal to 3.\n\n✍ / ⌨  Verify that the order of accuracy of the given multistep method is at least 1. Then apply \n\nTheorem 6.8.1 to determine whether it is zero-stable.\n\n(a) BD2\n\n(b) BD3\n\n(c) u_{i+1}=u_{i-1}+2hf_i\n\n(d) u_{i+1} = -u_i +u_{i-1} + u_{i-2} + \\frac{2h}{3}(4f_i+f_{i-1}+f_{i-2})\n\n(e) u_{i+1} = u_{i-3} + \\frac{4h}{3} ( 2f_i - f_{i-1} + 2f_{i-2})\n\n(f) u_{i+1} = -2u_i + 3u_{i-1} + h (f_{i+1}+2f_i+f_{i-1})\n\n✍  A Fibonacci sequence is defined by u_{i+1}=u_i+u_{i-1}, where u_0 and u_1 are seed values. Using the proof of \n\nTheorem 6.8.1, find r_1 and r_2 such that u_i=c_1(r_1)^i+c_2(r_2)^i for all i.\n\n✍ (a) Suppose that \\rho(r) = \\rho'(r) = 0. Show that u_i = i r^i is a solution of the difference equation \\rho(\\mathcal{Z})u_i=0.\n\n(b) Explain why the result of part (a) implies that a non-simple root r with |r|=1 makes it impossible for a multistep method to be zero-stable.","type":"content","url":"/zerostability#exercises","position":7},{"hierarchy":{"lvl1":"Dimension reduction"},"type":"lvl1","url":"/dimreduce","position":0},{"hierarchy":{"lvl1":"Dimension reduction"},"content":"The SVD has another important property that proves very useful in a variety of applications. Let \\mathbf{A} be a real m\\times n matrix with SVD \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T and (momentarily) m\\ge n. Another way of writing the thin form of the SVD is\\begin{split}\n  \\mathbf{A} = \\hat{\\mathbf{U}}\\hat{\\mathbf{S}}\\mathbf{V}^T &=\n  \\begin{bmatrix}\n    \\rule[-0.3em]{0pt}{1em} \\mathbf{u}_1 & \\mathbf{u}_2 & \\cdots & \\mathbf{u}_n\n  \\end{bmatrix} \\:\n  \\begin{bmatrix}\n    \\sigma_1 & & \\\\\n    & \\ddots & \\\\\n    & & \\sigma_n\n  \\end{bmatrix} \\: \n        \\begin{bmatrix}\n          \\mathbf{v}_1^T \\\\ \\vdots \\\\ \\mathbf{v}_n^T\n        \\end{bmatrix}\\ \\\\\n  &=\n  \\begin{bmatrix}\n    \\rule[-0.3em]{0pt}{1em} \\sigma_1\\mathbf{u}_1  & \\cdots & \\sigma_n\\mathbf{u}_n\n  \\end{bmatrix}\\:\n  \\begin{bmatrix}\n    \\mathbf{v}_1^T \\\\ \\vdots \\\\ \\mathbf{v}_n^T\n  \\end{bmatrix} \\\\\n  &= \\sigma_1 \\mathbf{u}_{1}\\mathbf{v}_{1}^T + \\cdots + \\sigma_r \\mathbf{u}_{r}\\mathbf{v}_{r}^T = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_{i}\\mathbf{v}_{i}^T,\n\\end{split}\n\nwhere r is the rank of \\mathbf{A}. The final formula also holds for the case m<n.\n\nEach outer product \\mathbf{u}_{i}\\mathbf{v}_{i}^T is a rank-1 matrix of unit 2-norm. Thanks to the ordering of singular values, then, Equation \n\n(7.5.1) expresses \\mathbf{A} as a sum of decreasingly important contributions. This motivates the definition, for 1\\le k \\le r,\\mathbf{A}_k = \\sum_{i=1}^k \\sigma_i \\mathbf{u}_{i}\\mathbf{v}_{i}^T = \\mathbf{U}_k \\mathbf{S}_k \\mathbf{V}_k^T,\n\nwhere \\mathbf{U}_k and \\mathbf{V}_k are the first k columns of \\mathbf{U} and \\mathbf{V}, respectively, and \\mathbf{S}_k is the upper-left k\\times k submatrix of \\mathbf{S}.\n\nThe rank of a sum of matrices is always less than or equal to the sum of the ranks, so \\mathbf{A}_k is a rank-k approximation to \\mathbf{A}. It turns out that \\mathbf{A}_k is the best rank-k approximation of \\mathbf{A}, as measured in the matrix 2-norm.\n\nSuppose \\mathbf{A} has rank r and let \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T be an SVD. Let \\mathbf{A}_k be as in \n\n(7.5.2) for 1\\le k < r. Then\n\n\\| \\mathbf{A} - \\mathbf{A}_k \\|_2 = \\sigma_{k+1}, \\quad k=1,\\ldots,r-1, and\n\nIf the rank of \\mathbf{B} is k or less, then \\| \\mathbf{A}-\\mathbf{B} \\|_2\\ge \\sigma_{k+1}.\n\n(part 1 only) Note that \n\n(7.5.2) is identical to \n\n(7.5.1) with \\sigma_{k+1},\\ldots,\\sigma_r all set to zero. This implies that\\mathbf{A} - \\mathbf{A}_k = \\mathbf{U}(\\mathbf{S}-\\hat{\\mathbf{S}})\\mathbf{V}^T,\n\nwhere \\hat{\\mathbf{S}} has those same values of \\sigma_i replaced by zero. But that makes the above an SVD of \\mathbf{A} - \\mathbf{A}_k, with singular values 0,\\ldots,0,\\sigma_{k+1},\\ldots,\\sigma_r, the largest of which is \\sigma_{k+1}. That proves the first claim.","type":"content","url":"/dimreduce","position":1},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Compression"},"type":"lvl2","url":"/dimreduce#compression","position":2},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Compression"},"content":"If the singular values of \\mathbf{A} decrease sufficiently rapidly, then \\mathbf{A}_{k} may capture the most significant behavior of the matrix for a reasonably small value of k.\n\nImage compression\n\nExample 7.5.1\n\nWe make an image from some text, then reload it as a matrix.\n\nusing Plots, Images\nplot(annotations=(0.5, 0.5, text(\"Hello world\", 44, :center, :center)),\n    grid=:none, frame=:none, size=(400, 150))\nsavefig(\"hello.png\")\nimg = load(\"hello.png\")\nA = @. Float64(Gray(img))\nGray.(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=45.\n\nU, σ, V = svd(A)\nscatter(σ;\n    xaxis=(L\"i\"),  yaxis=(:log10, L\"\\sigma_i\"),\n    title=\"Singular values\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nplt = plot(layout=(2, 2), frame=:none, aspect_ratio=1, titlefontsize=10)\nfor i in 1:4\n    k = 3i\n    Ak = U[:, 1:k] * diagm(σ[1:k]) * V[:, 1:k]'\n    plot!(Gray.(Ak), subplot=i, title=\"rank = $k\")\nend\nplt\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\nm, n = size(A)\ncompression = m * n / (9 * (m + n + 1))\n\nExample 7.5.1\n\nWe make an image from some text, then reload it as a matrix.\n\nclf\ntobj = text(0, 0,'Hello world','fontsize',44);\nex = get(tobj, 'extent');\naxis([ex(1) ex(1) + ex(3) ex(2) ex(2) + ex(4)]), axis off\nexportgraphics(gca, 'hello.png', resolution=300)\nA = imread('hello.png');\nA = double(im2gray(A));\nsize_A = size(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=100.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\nsemilogy(sigma, '.')\ntitle('singular values'), axis tight \nxlabel('i'), ylabel('\\sigma_i') \nr = find(sigma / sigma(1) > 10*eps, 1, 'last')\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor i = 1:4\n    subplot(2, 2, i)\n    k = 2*i;\n    Ak = U(:, 1:k) * S(1:k, 1:k) * V(:, 1:k)';\n    imshow(Ak, [0, 255])\n    title(sprintf('rank = %d', k))\nend\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\n[m, n] = size(A);\nfull_size = m * n;\ncompressed_size = 8 * (m + n + 1);\nfprintf(\"compression ratio: %.1f\", full_size / compressed_size)\n\nExample 7.5.1\n\nWe make an image from some text, then reload it as a matrix.\n\ntext(\n    0.5,\n    0.5,\n    \"Hello world\",\n    dict(fontsize=44),\n    horizontalalignment=\"center\",\n    verticalalignment=\"center\",\n)\naxis(\"off\")\nsavefig(\"hello.png\")\n\nimg = imread(\"hello.png\")[:, :, :3]\nA = rgb2gray(img)\nprint(f\"image of size {A.shape}\")\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around index 38.\n\nfrom numpy.linalg import svd\nU, sigma, Vt = svd(A)\nsemilogy(sigma, \"o\")\ntitle(\"Singular values\")\nxlabel(\"$i$\"), ylabel(\"$\\\\sigma_i$\");\n\nsignificant = sigma / sigma[0] > 10 * 2**-52\nprint(f\"last significant singular value at index {max(where(significant)[0])}\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor k in range(4):\n    r = 2 + 2 * k\n    Ak = U[:, :r] @ diag(sigma[:r]) @ Vt[:r, :]\n    subplot(2, 2, k + 1)\n    imshow(Ak, cmap=\"gray\", clim=(0.0, 1.0))\n    title(f\"rank = {r}\")\n    xticks([]), yticks([])\n\nConsider how little data is needed to reconstruct these images. For rank-8, for instance, we have 8 left and right singular vectors plus 8 singular values.\n\nm, n = A.shape\nfull_size = m * n\ncompressed_size = 8 * (m + n + 1)\nprint(f\"compression ratio: {full_size / compressed_size:.1f}\")","type":"content","url":"/dimreduce#compression","position":3},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Capturing major trends"},"type":"lvl2","url":"/dimreduce#capturing-major-trends","position":4},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Capturing major trends"},"content":"The use of dimension reduction offered by low-rank SVD approximation goes well beyond simply reducing computation time. By isolating the most important contributions to the matrix, dimension reduction can uncover deep connections and trends that are otherwise obscured by weaker effects and noise.\n\nOne useful way to quantify the decay in the singular values is to computes_k = \\sum_{i=1}^k \\sigma_i^2, \\quad \\tau_k = \\frac{s_k}{s_r}, \\quad k=1,\\ldots,r.\n\nClearly 0\\le \\tau_k \\le 1 and \\tau_k is non-decreasing as a function of k. We can think of \\tau_k as the fraction of energy (or in statistical terms, variance) contained in the singular values up to and including the kth.\n\nDimension reduction in voting records\n\nExample 7.5.2\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nusing JLD2\n@load \"voting.jld2\" A;\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nheatmap(A;\n    color=:viridis,  xlabel=\"bill\",  ylabel=\"senator\",\n    title=\"Votes in 111th U.S. Senate\")\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, σ, V = svd(A)\nτ = cumsum(σ .^ 2) / sum(σ .^ 2)\nscatter(τ[1:16];\n    xaxis=(\"k\"),  yaxis=(L\"\\tau_k\"),\n    title=\"Fraction of singular value energy\")\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nscatter(U[:, 1], label=\"\", layout=(1, 2),\n    xlabel=\"senator\",  title=\"left singular vector\")\nscatter!(V[:, 1], label=\"\", subplot=2,\n    xlabel=\"bill\",  title=\"right singular vector\")\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = A * V[:, 1];\nx2 = A * V[:, 2];\n\n@load \"voting.jld2\" Rep Dem Ind\nRep = vec(Rep);\nDem = vec(Dem);\nInd = vec(Ind);\nscatter(x1[Dem], x2[Dem];\n    color=:blue,  label=\"D\",\n    xaxis=(\"partisanship\"),  yaxis=(\"bipartisanship\"), \n    title=\"111th US Senate by voting record\")\nscatter!(x1[Rep], x2[Rep], color=:red, label=\"R\")\nscatter!(x1[Ind], x2[Ind], color=:yellow, label=\"I\")\n\nExample 7.5.2\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nload voting\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nclf\nimagesc(A)\ncolormap parula\ntitle('Votes in 111th U.S. Senate')\nylabel(('senator'),  xlabel('bill'));\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\ntau = cumsum(sigma.^2) / sum(sigma.^2);\nplot(tau(1:16), 'o')\nxlabel('k'),  ylabel('\\tau_k')\ntitle(('Fraction of singular value energy'));\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(211), plot(U(:, 1), '.')\nxlabel('senator number'), title('left singular vector')\nsubplot(212), plot(V(:, 1), '.')\nxlabel('bill number'), title(('right singular vector'));\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nclf\nx1 = V(:, 1)'*A';   x2 = V(:, 2)'*A'; \nscatter(x1(Dem), x2(Dem), 20, 'b'),  hold on\nscatter(x1(Rep), x2(Rep), 20, 'r')\nscatter(x1(Ind), x2(Ind), 20, 'm')\nxlabel('partisanship'),  ylabel('bipartisanship')\nlegend('Democrat', 'Republican', 'Independent')\ntitle(('111th US Senate in 2D'));\n\nExample 7.5.2\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nfrom scipy.io import loadmat\nvars = loadmat(\"voting.mat\")\nA = vars[\"A\"]\nm, n = A.shape\nprint(\"size:\", (m, n))\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nimshow(A, cmap=\"viridis\")\nxlabel(\"bill\")\nylabel(\"senator\")\ntitle(\"Votes in 111th U.S. Senate\");\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, sigma, Vt = svd(A)\ntau = cumsum(sigma**2) / sum(sigma**2)\nplot(range(1, 17), tau[:16], \"o\")\nxlabel(\"$k$\")\nylabel(\"$\\tau_k$\")\ntitle(\"Fraction of singular value energy\");\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(1, 2, 1)\nplot(U[:, 0], \"o\")\nxlabel(\"senator\"),title(\"left singular vector\")\nsubplot(1, 2, 2)\nplot(Vt[0, :], \"o\")\nxlabel(\"bill\"), title(\"right singular vector\");\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = sigma[0] * U[:, 0]\nx2 = sigma[1] * U[:, 1]\n\nRep = vars[\"Rep\"] - 1\nDem = vars[\"Dem\"] - 1\nInd = vars[\"Ind\"] - 1\n\nscatter(x1[Dem], x2[Dem], color=\"blue\", label=\"D\")\nscatter(x1[Rep], x2[Rep], color=\"red\", label=\"R\")\nscatter(x1[Ind], x2[Ind], color=\"darkorange\", label=\"I\")\n\nxlabel(\"partisanship\"),  ylabel(\"bipartisanship\")\nlegend(),  title(\"111th US Senate in 2D\");\n\nNot all data sets can be reduced effectively to a small number of dimensions, but as \n\nDemo 7.5.2 illustrates, in some cases reduction reveals information that corresponds to real-world understanding.","type":"content","url":"/dimreduce#capturing-major-trends","position":5},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Exercises"},"type":"lvl2","url":"/dimreduce#exercises","position":6},{"hierarchy":{"lvl1":"Dimension reduction","lvl2":"Exercises"},"content":"✍  Suppose that \\mathbf{A} is an n\\times n matrix. Explain why \\sigma_n is the distance (in 2-norm) from \\mathbf{A} to the set of all singular matrices.\n\n✍ Suppose \\mathbf{A} is a 7\\times 4 matrix and the eigenvalues of \\mathbf{A}^*\\mathbf{A} are 3, 4, 7, and 10. How close is \\mathbf{A} in the 2-norm to (a) a rank-3 matrix? (b) a rank-2 matrix?\n\n(a) ⌨ Find the rank-1 matrix closest to\\mathbf{A}=\\displaystyle \\begin{bmatrix}\n    1 & 5 \\\\ 5 & 1\n    \\end{bmatrix},\n\nas measured in the 2-norm.\n\n(b) ⌨ Repeat part (a) for\\mathbf{A}=\\displaystyle \\begin{bmatrix}\n    1 & 5 \\\\ 0 & 1\n    \\end{bmatrix}.\n\n✍ Find the rank-1 matrix closest to\\mathbf{A}=\\displaystyle \\begin{bmatrix}\n    1 & b \\\\ b & 1\n    \\end{bmatrix},\n\nas measured in the 2-norm, where b>0.\n\n⌨ Following \n\nDemo 7.5.1 as a guide, load the “mandrill” test image and convert it to a matrix of floating-point pixel grayscale intensities. Using the SVD, display as images the best approximations of rank 5, 10, 15, and 20.\n\nIn statistics this quantity may be interpreted as the fraction of explained variance.","type":"content","url":"/dimreduce#exercises","position":7},{"hierarchy":{"lvl1":"Eigenvalue decomposition"},"type":"lvl1","url":"/evd","position":0},{"hierarchy":{"lvl1":"Eigenvalue decomposition"},"content":"To this point we have dealt frequently with the solution of the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Alongside this problem in its importance to linear algebra is the eigenvalue problem.\n\nEigenvalue and eigenvector\n\nGiven a square matrix \\mathbf{A}, if\\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x}\n\nfor a scalar λ and a nonzero vector \\mathbf{x}, then λ is an \n\neigenvalue and \\mathbf{x} is an associated \n\neigenvector.","type":"content","url":"/evd","position":1},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Complex matrices"},"type":"lvl2","url":"/evd#complex-matrices","position":2},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Complex matrices"},"content":"A matrix with real entries can have complex eigenvalues. Therefore we assume all matrices, vectors, and scalars may be complex in what follows. Recall that a complex number can be represented as a+i b for real a and b and where i^2=-1. The complex conjugate of x=a+i b is denoted \\bar{x} and is given by \\bar{x}=a-i b. The magnitude or modulus of a complex number z is|z| = \\sqrt{z\\cdot \\bar{z}}.\n\nTerms for complex matrices\n\nThe \n\nadjoint or hermitian of a matrix \\mathbf{A} is denoted \\mathbf{A}^* and is given by \\mathbf{A}^*=(\\overline{\\mathbf{A}})^T=\\overline{\\mathbf{A}^T}. The matrix is self-adjoint or \n\nhermitian if \\mathbf{A}^*=\\mathbf{A}.\n\nThe 2-norm of a complex vector \\mathbf{u} is \\sqrt{\\mathbf{u}^*\\mathbf{u}}. Other vector norms, and all matrix norms, are as defined in \n\nVector and matrix norms.\n\nComplex vectors \\mathbf{u} and \\mathbf{v} of the same dimension are \n\northogonal vectors if \\mathbf{u}^*\\mathbf{v}=0 and are \n\northonormal vectors if both also have unit 2-norm. A \n\nunitary matrix  is a square matrix with orthonormal columns, or, equivalently, a matrix satisfying \\mathbf{A}^* = \\mathbf{A}^{-1}.\n\nFor the most part, “adjoint” replaces “transpose,” “hermitian” replaces “symmetric,” and “unitary matrix” replaces “orthogonal matrix” when applying our previous results to complex matrices.","type":"content","url":"/evd#complex-matrices","position":3},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Eigenvalue decomposition"},"type":"lvl2","url":"/evd#eigenvalue-decomposition","position":4},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Eigenvalue decomposition"},"content":"An easy rewrite of the eigenvalue definition \n\n(7.2.1) is that (\\mathbf{A} - \\lambda\\mathbf{I}) \\mathbf{x} = \\boldsymbol{0}. Hence (\\mathbf{A} - \\lambda\\mathbf{I}) is singular, and it therefore must have a zero determinant. This is the property most often used to compute eigenvalues by hand.\n\nGiven\\mathbf{A} = \\begin{bmatrix} 1 & 1 \\\\ 4 & 1 \\end{bmatrix},\n\nwe compute\\begin{vmatrix}\n1-\\lambda & 1\\\\ \n4 & 1-\\lambda\n\\end{vmatrix}\n= (1-\\lambda)^2 - 4 = \\lambda^2-2\\lambda-3.\n\nThe eigenvalues are the roots of this quadratic, \\lambda_1=3 and \\lambda_2=-1.\n\nThe determinant \\det(\\mathbf{A} - \\lambda \\mathbf{I}) is called the characteristic polynomial. Its roots are the eigenvalues, so we know that an n\\times n matrix has n eigenvalues, counting algebraic multiplicity.\n\nSuppose that \\mathbf{A}\\mathbf{v}_k=\\lambda_k\\mathbf{v}_k for k=1,\\ldots,n. We can summarize these as\\begin{split}\n   \\begin{bmatrix}\n    \\mathbf{A}\\mathbf{v}_1 & \\mathbf{A}\\mathbf{v}_2 & \\cdots & \\mathbf{A}\\mathbf{v}_n\n  \\end{bmatrix}\n  &=\n    \\begin{bmatrix}\n      \\lambda_1 \\mathbf{v}_1 & \\lambda_2\\mathbf{v}_2 & \\cdots & \\lambda_n \\mathbf{v}_n\n    \\end{bmatrix}, \\\\[1mm]\n  \\mathbf{A} \\begin{bmatrix}\n    \\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n\n  \\end{bmatrix}\n  &=\n\\begin{bmatrix}\n    \\mathbf{v}_1 & \\mathbf{v}_2 & \\cdots & \\mathbf{v}_n\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\lambda_1 & &  &  \\\\\n    & \\lambda_2 & & \\\\\n    & & \\ddots & \\\\\n    & & & \\lambda_n\n  \\end{bmatrix},\n\\end{split}\n\nwhich we write as  \\mathbf{A} \\mathbf{V} = \\mathbf{V} \\mathbf{D}.\n\nIf we find that \\mathbf{V} is a nonsingular matrix, then we arrive at a key factorization.\n\nEigenvalue decomposition (EVD)\n\nAn eigenvalue decomposition (EVD) of a square matrix \\mathbf{A} is\\mathbf{A} = \\mathbf{V} \\mathbf{D} \\mathbf{V}^{-1}.\n\nIf \\mathbf{A} has an EVD, we say that \\mathbf{A} is a \n\ndiagonalizable matrix; otherwise \\mathbf{A} is nondiagonalizable (or defective).\n\nObserve that if \\mathbf{A}\\mathbf{v} = \\lambda \\mathbf{v} for nonzero \\mathbf{v}, then the equation remains true for any nonzero multiple of \\mathbf{v}. Therefore, eigenvectors are not unique, and thus neither is an EVD.\n\nWe stress that while \n\n(7.2.6) is possible for all square matrices, \n\n(7.2.7) is not.  One simple example of a nondiagonalizable matrix is  \\mathbf{B} = \\begin{bmatrix}\n    1 & 1\\\\0 & 1\n  \\end{bmatrix}.\n\nThere is a common circumstance in which we can guarantee an EVD exists. The proof of the following theorem can be found in many elementary texts on linear algebra.\n\nIf the n\\times n matrix \\mathbf{A} has n distinct eigenvalues, then \\mathbf{A} is diagonalizable.\n\nEigenvalues and eigenvectors\n\nExample 7.2.2\n\nThe eigvals function returns a vector of the eigenvalues of a matrix.\n\nA = π * ones(2, 2)\n\nλ = eigvals(A)\n\nIf you want the eigenvectors as well, use eigen.\n\nλ, V = eigen(A)\n\nnorm(A * V[:, 2] - λ[2] * V[:, 2])\n\nBoth functions allow you to sort the eigenvalues by specified criteria.\n\nA = diagm(-2.3:1.7)\n@show eigvals(A, sortby=real);\n@show eigvals(A, sortby=abs);\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1]\nλ, V = eigen(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nopnorm(A * V - V * diagm(λ))\n\nExample 7.2.2\n\nThe eig function with one output argument returns a vector of the eigenvalues of a matrix.\n\nA = pi * ones(2, 2);\nlambda = eig(A)\n\nWith two output arguments given, eig returns a matrix eigenvectors and a diagonal matrix with the eigenvalues.\n\n[V, D] = eig(A)\n\nWe can check the fact that this is an EVD.\n\nnorm( A - V*D/V )   % / V is like * inv(V)\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1];\n[V, D] = eig(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nnorm(A * V - V * D)\n\nExample 7.2.2\n\nThe eig function from scipy.linalg will return a vector of eigenvalues and a matrix of associated eigenvectors.\n\nfrom numpy.linalg import eig\nA = pi * ones([2, 2])\nd, V = eig(A)\nprint(\"eigenvalues:\", d)\n\nWe can check the fact that this is an EVD (although in practice we never invert a matrix).\n\nfrom numpy.linalg import inv\nD = diag(d)\nprint(f\"should be near zero: {norm(A - V @ D @ inv(V), 2):.2e}\")\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nfrom numpy.linalg import cond\nA = array([[1, 1], [0, 1]])\nd, V = eig(A)\nprint(f\"cond(V) is {cond(V):.2e}\")\n\nBut even in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds up to roundoff error.\n\nprint(f\"should be near zero: {norm(A @ V - V @ diag(d), 2):.2e}\")","type":"content","url":"/evd#eigenvalue-decomposition","position":5},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Similarity and matrix powers"},"type":"lvl2","url":"/evd#similarity-and-matrix-powers","position":6},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Similarity and matrix powers"},"content":"The particular relationship between matrices \\mathbf{A} and \\mathbf{D} in \n\n(7.2.7) is important.\n\nSimilar matrices\n\nIf \\mathbf{S} is any nonsingular matrix, we say that \\mathbf{B}=\\mathbf{S}\\mathbf{A}\\mathbf{S}^{-1} is a \n\nsimilarity transformation of \\mathbf{A}, and we say that \\mathbf{A} and \\mathbf{B} are \n\nsimilar matrices.\n\nHence, an EVD transforms \\mathbf{A} to a similar matrix that happens to be diagonal, which is as simple as a matrix gets.\n\nOne way to interpret similarity is via change of basis (see \n\nObservation A.5):\\mathbf{B}\\mathbf{x} = \\mathbf{S}\\mathbf{A}\\mathbf{S}^{-1} \\mathbf{x} \n= \\underbrace{\\mathbf{S} \\underbrace{ \\Bigl(\\mathbf{A} \\underbrace{\\left( \\mathbf{S}^{-1} \\mathbf{x}\\right)}_{\\text{into $S$-basis}}\\Bigr)}_{\\text{apply $\\mathbf{A}$}}}_{\\text{out of $S$-basis}} .\n\nThat is, \\mathbf{A} and \\mathbf{B} represent the same linear transformation in different bases.\n\nA similarity transformation does not change eigenvalues, a fact that is typically proved in elementary linear algebra texts:\n\nIf \\mathbf{S} is a nonsingular matrix, then \\mathbf{S}\\mathbf{A}\\mathbf{S}^{-1} has the same eigenvalues as \\mathbf{A}.\n\nThe EVD is especially useful for matrix powers. To begin,\\mathbf{A}^2=(\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1})(\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1})=\\mathbf{V}\\mathbf{D}(\\mathbf{V}^{-1}\\mathbf{V})\\mathbf{D}\\mathbf{V}^{-1}=\\mathbf{V}\\mathbf{D}^2\\mathbf{V}^{-1}.\n\nMultiplying this result by \\mathbf{A} repeatedly, we find that\\mathbf{A}^k = \\mathbf{V}\\mathbf{D}^k\\mathbf{V}^{-1}.\n\nBecause \\mathbf{D} is diagonal, its power \\mathbf{D}^k is just the diagonal matrix of the kth powers of the eigenvalues.\n\nFurthermore, given a polynomial p(z)=c_0+c_1 z + \\cdots + c_m z^m, we can apply the polynomial to the matrix in a straightforward way,p(\\mathbf{A}) = c_0\\mathbf{I}  +c_1 \\mathbf{A} + \\cdots + c_m \\mathbf{A}^m.\n\nApplying \n\n(7.2.11) leads to\\begin{split}\np(\\mathbf{A}) & = c_0\\mathbf{V}\\mathbf{V}^{-1}  +c_1 \\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1} + \\cdots + c_m \\mathbf{V}\\mathbf{D}^m\\mathbf{V}^{-1} \\\\ \n&= \\mathbf{V} \\cdot [ c_0\\mathbf{I}  +c_1 \\mathbf{D} + \\cdots + c_m \\mathbf{D}^m] \\cdot \\mathbf{V}^{-1} \\\\[1mm] \n&= \\mathbf{V} \\cdot \\begin{bmatrix}\n  p(\\lambda_1) & & & \\\\ & p(\\lambda_2) & &  \\\\ & & \\ddots & \\\\ & & & p(\\lambda_n)  \n\\end{bmatrix} \\cdot \\mathbf{V}^{-1}.\n\\end{split}\n\nFinally, given the convergence of Taylor polynomials to common functions, we are able to apply a function f to a square matrix by replacing p with f in \n\n(7.2.13).","type":"content","url":"/evd#similarity-and-matrix-powers","position":7},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Conditioning of eigenvalues"},"type":"lvl2","url":"/evd#conditioning-of-eigenvalues","position":8},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Conditioning of eigenvalues"},"content":"Just as linear systems have condition numbers that quantify the effect of finite precision, eigenvalue problems may be poorly conditioned too. While many possible results can be derived, we will use just one, the Bauer–Fike theorem.\n\nBauer–Fike\n\nLet \\mathbf{A}\\in\\mathbb{C}^{n\\times n} be diagonalizable, \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1}, with eigenvalues \\lambda_1,\\ldots,\\lambda_n. If μ is an eigenvalue of \\mathbf{A}+\\mathbf{E} for a complex matrix \\mathbf{E}, then\\min_{j=1,\\ldots,n} |\\mu - \\lambda_j| \\le \\kappa(\\mathbf{V}) \\, \\| \\mathbf{E} \\|\\,,\n\nwhere \\|\\cdot\\| and κ are in the 2-norm.\n\nThe Bauer–Fike theorem tells us that eigenvalues can be perturbed by an amount that is \\kappa(\\mathbf{V}) times larger than perturbations to the matrix. This result is a bit less straightforward than it might seem—eigenvectors are not unique, so there are multiple possible values for \\kappa(\\mathbf{V}). Even so, the theorem indicates caution when a matrix has eigenvectors that form an ill-conditioned matrix. The limiting case of \\kappa(\\mathbf{V})=\\infty might be interpreted as indicating a nondiagonalizable matrix \\mathbf{A}. The other extreme is also of interest: \\kappa(\\mathbf{V})=1, which implies that \\mathbf{V} is unitary.\n\nNormal matrix\n\nIf \\mathbf{A} has an EVD \n\n(7.2.7) with a unitary eigenvector matrix \\mathbf{V}, then \\mathbf{A} is a \n\nnormal matrix.\n\nAs we will see in \n\nSymmetry and definiteness, hermitian and real symmetric matrices are normal. Since the condition number of a unitary matrix is equal to 1, \n\n(7.2.14) guarantees that a perturbation of a normal matrix changes the eigenvalues by the same amount or less.\n\nEigenvalue conditioning\n\nExample 7.2.3\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7\nA = randn(n, n) + 1im * randn(n, n)\nA = (A + A') / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nλ, V = eigen(A)\n@show cond(V);\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones.\n\nTip\n\nSince the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = 1:n\nA = triu(x * ones(n)')\nA[1:5, 1:5]\n\nThis matrix is not especially close to normal.\n\nλ, V = eigen(A)\n@show cond(V);\n\nAs a result, the eigenvalues can change by a good deal more.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\nBF_bound = cond(V) * norm(ΔA)\n@show maximum(dist), BF_bound;\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nusing Plots\nplt = scatter(λ, zeros(n), aspect_ratio=1)\nfor _ in 1:200\n    ΔA = eps(Float32) * normalize(randn(n, n) + 1im * randn(n, n))\n    λ̃ = eigvals(A + ΔA)\n    scatter!(real(λ̃), imag(λ̃), m=1, color=:black)\nend\nplt\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nExample 7.2.3\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7;\nA = randn(n, n) + 1i * randn(n, n);\nA = (A + A') / 2;\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones. Note: since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = [];\nfor j = 1:n\n    dist = [dist; min(abs(dd - lambda(j)))];\nend\ndist\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20;\nx = (1:n)';\nA = triu(x * ones(1, n));\nA(1:5, 1:5)\n\nThis matrix is not at all close to normal.\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = -Inf;\nfor j = 1:n\n    dist = max(dist, min(abs(dd - lambda(j))));\nend\nfprintf(\"max change in eigenvalues: %.2e\", dist)\nfprintf(\"Bauer-Fike upper bound: %.2e\", cond(V) * norm(E))\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nscatter(lambda, 0*lambda)\naxis equal; hold on\nfor k = 1:60\n    E = randn(n, n) + 1i * randn(n, n);\n    E = eps(single(1)) * E / norm(E);\n    dd = eig(A + E);\n    plot(real(dd), imag(dd), 'k.', markersize=2)\nend\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nExample 7.2.3\n\nWe first define a hermitian matrix. Note that we add the conjugate transpose of a matrix to itself.\n\nn = 7\nA = random.randn(n, n) + 1j * random.randn(n, n)\nA = (A + conj(A.T)) / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nfrom numpy.linalg import eig\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.5f}\")\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. Note that the Bauer–Fike theorem uses absolute differences, not relative ones. Since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(dist)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = arange(n) + 1\nA = triu(outer(x, ones(n)))\nprint(A[:5, :5])\n\nThis matrix is not at all close to normal.\n\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.2e}\")\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(f\"Maximum eigenvalue change is {max(dist):.2e}\")\nprint(f\"The Bauer-Fike upper bound is {cond(V) * norm(E, 2):.2e}\")\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nscatter(d, zeros(n), 18)\naxis(\"equal\") \nfor _ in range(100):\n    E = random.randn(n, n) + 1j * random.randn(n, n)\n    E = finfo(np.float32).eps * E / norm(E, 2)\n    dd, _ = eig(A + E)\n    scatter(real(dd), imag(dd), 2, 'k')\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.","type":"content","url":"/evd#conditioning-of-eigenvalues","position":9},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Computing the EVD"},"type":"lvl2","url":"/evd#computing-the-evd","position":10},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Computing the EVD"},"content":"Roots of the characteristic polynomial are not used in numerical methods for finding eigenvalues. Practical algorithms for computing the EVD go beyond the scope of this book. The essence of the matter is the connection to matrix powers indicated in \n\n(7.2.11). (We will see much more about the importance of matrix powers in Chapter 8.)\n\nIf the eigenvalues have different complex magnitudes, then as k\\to\\infty the entries on the diagonal of \\mathbf{D}^k become increasingly well separated and easy to pick out. It turns out that there is an astonishingly easy and elegant way to accomplish this separation without explicitly computing the matrix powers.\n\nFrancis QR iteration\n\nExample 7.2.4\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diagm([-6, -1, 2, 4, 5])\nV, R = qr(randn(5, 5))    # V is unitary\nA = V * D * V'\n\neigvals(A)\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\neigvals(A)\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in 1:40\n    Q, R = qr(A)\n    A = R * Q\nend\nA\n\nExample 7.2.4\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diag([-6, -1, 2, 4, 5]);\n[V, R]= qr(randn(5, 5));    % V is unitary\nA = V * D * V';\n\nsort(eig(A))\n\nNow we will take the QR factorization and just reverse the factors.\n\n[Q, R] = qr(A);\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nsort(eig(A))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k = 1:40\n    [Q, R] = qr(A);\n    A = R * Q;\nend\nformat short e\nA\n\nExample 7.2.4\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nfrom numpy.linalg import qr\nD = diag([-6, -1, 2, 4, 5])\nV, R = qr(random.randn(5, 5))\nA = V @ D @ V.T    # note that V.T = inv(V) here\n\nprint(sort(eig(A)[0]))\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R @ Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nprint(sort(eig(A)[0]))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in range(40):\n    Q, R = qr(A)\n    A = R @ Q\nset_printoptions(precision=4)\nprint(A)\n\nThe process demonstrated in \n\nDemo 7.2.4 is known as the Francis QR iteration, and it can be formulated as an O(n^3) algorithm for finding the EVD. It forms the basis of most practical eigenvalue computations, at least until the matrix size approaches \n\n104 or so.","type":"content","url":"/evd#computing-the-evd","position":11},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Exercises"},"type":"lvl2","url":"/evd#exercises","position":12},{"hierarchy":{"lvl1":"Eigenvalue decomposition","lvl2":"Exercises"},"content":"(a) ✍ Suppose that matrix \\mathbf{A} has an eigenvalue λ. Show that for any induced matrix norm, \\| \\mathbf{A} \\|\\ge |\\lambda|.\n\n(b) ✍ Find a matrix \\mathbf{A} such that \\| \\mathbf{A} \\|_2 is strictly larger than |\\lambda| for all eigenvalues λ. (Proof-by-computer isn’t allowed here. You don’t need to compute \\| \\mathbf{A} \\|_2 exactly, just a lower bound for it.)\n\n✍ Prove that the matrix \\mathbf{B} in \n\n(7.2.8) does not have two independent eigenvectors. TODO: Get rid of rank. \n\n⌨ In each part, find all the eigenvalues of \\mathbf{A}. Then, choose one eigenvalue λ and associated eigenvector \\mathbf{v} and compute \\twonorm{\\mathbf{A} \\mathbf{v} - \\lambda \\mathbf{v}}, which should be comparable to machine epsilon.\n\n(a) \\mathbf{A} = \\begin{bmatrix}\n 2  & -1 & 0 \\\\\n -1 &  2 & -1 \\\\\n 0  & -1 & 2\n \\end{bmatrix}\n\n(b) \\mathbf{A} = \\begin{bmatrix}\n      2 & -1 & -1 \\\\\n     -2 &  2 & -1 \\\\\n     -1 & -2 & 2\n   \\end{bmatrix}\n\n(c)  \\mathbf{A} = \\begin{bmatrix}\n      2 & -1 & -1 \\\\\n     -1 &  2 & -1 \\\\\n     -1 & -1 & 2\n   \\end{bmatrix} \n\n(d) \\mathbf{A} = \\begin{bmatrix}\n   3 & 1 & 0 & 0 \\\\\n   1 & 3 & 1 & 0 \\\\\n   0 & 1 & 3 & 1 \\\\\n   0 & 0 & 1 & 3\n \\end{bmatrix}\\qquad \n\n(e) \\mathbf{A} = \\begin{bmatrix}\n      4 & -3 & -2 & -1\\\\\n     -2 &  4 & -2 & -1 \\\\\n     -1 & -2 & 4  & -1 \\\\\n     -1 & -2 & -1 & 4 \\\\\n   \\end{bmatrix} \n\n(a) ✍ Show that the eigenvalues of a diagonal n\\times n matrix \\mathbf{D} are the diagonal entries of \\mathbf{D}. (That is, produce the associated eigenvectors.)\n\n(b) ✍ The eigenvalues of a triangular matrix are its diagonal entries. Prove this in the 3\\times 3 case,  \\mathbf{T} =\n  \\begin{bmatrix}\n    t_{11} & t_{12}&  t_{13}\\\\ 0 & t_{22} & t_{23} \\\\ 0 & 0 & t_{33}\n  \\end{bmatrix},\n\nby finding the eigenvectors. (Start by showing that [1,0,0]^T is an eigenvector. Then show how to make [a,1,0]^T an eigenvector, except for one case that does not change the outcome. Continue the same logic for [a,b,1]^T.)\n\n✍ Let \\mathbf{A}=\\displaystyle\\frac{\\pi}{6}\\begin{bmatrix} 4 & 1 \\\\ 4 & 4 \\end{bmatrix}.\n\n(a) Show that\\lambda_1=\\pi,\\, \\mathbf{v}_1=\\begin{bmatrix}1 \\\\ 2 \\end{bmatrix}, \\quad \\lambda_2=\\frac{\\pi}{3},\\, \\mathbf{v}_2=\\begin{bmatrix}1 \\\\ -2 \\end{bmatrix}\n\nyield an EVD of \\mathbf{A}.\n\n(b) Use \n\n(7.2.13) to evaluate p(\\mathbf{A}), where p(x) = (x-\\pi)^4.\n\n(c) Use the function analog of \n\n(7.2.13) to evaluate \\cos(\\mathbf{A}).\n\n⌨ In \n\nExercise 2.3.5, you showed that the\ndisplacements of point masses placed along a string satisfy a linear system \\mathbf{A}\\mathbf{q}=\\mathbf{f} for an (n-1)\\times(n-1) matrix \\mathbf{A}. The eigenvalues and eigenvectors of \\mathbf{A} correspond to resonant frequencies and modes of vibration of the string. For n=40 and the physical parameters given in part (b) of that exercise, find the eigenvalue decomposition of \\mathbf{A}. Report the three eigenvalues with smallest absolute value, and plot all three associated eigenvectors on a single graph (as functions of the vector row index).\n\n⌨ \n\nDemo 7.2.4 suggests that the result of the Francis QR iteration as k\\to\\infty sorts the eigenvalues on the diagonal according to a particular ordering. Following the code there as a model, create a random matrix with eigenvalues equal to -9.6,-8.6,\\ldots,10.4, perform the iteration 200 times, and check whether the sorting criterion holds in your experiment as well.\n\n⌨ Eigenvalues of random matrices and their perturbations can be very interesting.\n\n(a) Let A=randn(60,60). Scatter plot its eigenvalues in the complex plane, using a plot aspect ratio of 1 and red diamonds as markers.\n\n(b) Let \\mathbf{E} be another random 60\\times 60 matrix, and on top of the previous graph, plot the eigenvalues of \\mathbf{A}+0.05\\mathbf{E} as blue dots. Repeat this for 100 different values of \\mathbf{E}.\n\n(c) Let T=triu(A). On a new graph, scatter plot the eigenvalues of \\mathbf{T} in the complex plane. (They all lie on the real axis.)\n\n(d) Repeat part (b) with \\mathbf{T} in place of \\mathbf{A}.\n\n(e) Compute some condition numbers and apply \n\nTheorem 7.2.3 to explain the dramatic difference between your plots with respect to the dot distributions.\n\nSuppose that \\mathbf{A} is diagonalizable and that \n\n(7.2.13) is used to define \\cos(\\mathbf{A}) and \\sin(\\mathbf{A}), with those functions substituted in for p in the equation. Is it necessarily true that \\cos(\\mathbf{A})^2+\\sin(\\mathbf{A})^2 is an identity matrix? Explain why or why not.\n\nThe terms “factorization” and “decomposition” are equivalent; they coexist mainly for historical reasons.\n\nIn fact, the situation is reversed: eigenvalue methods are among the best ways to compute the roots of a given polynomial.\n\nThe randn function generates random numbers from a standard normal distribution. In Python, it is found in the numpy.random module.","type":"content","url":"/evd#exercises","position":13},{"hierarchy":{"lvl1":"From matrix to insight"},"type":"lvl1","url":"/insight","position":0},{"hierarchy":{"lvl1":"From matrix to insight"},"content":"Any two-dimensional array of numbers may be interpreted as a matrix. Whether or not this is the only point of view that matters to a particular application, it does lead to certain types of analysis. The related mathematical and computational tools are universally applicable and find diverse uses.","type":"content","url":"/insight","position":1},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Tables as matrices"},"type":"lvl2","url":"/insight#tables-as-matrices","position":2},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Tables as matrices"},"content":"Tables are used to represent variation of a quantity with respect to two variables. These variables may be encoded as the rows and columns of a matrix.\n\nA corpus is a collection of text documents. A term-document matrix has one column for each document and one row for each unique term appearing in the corpus. The (i,j) entry of the matrix is the number of times term i appears in document j. That is, column j of the matrix is a term-frequency vector quantifying all occurrences of the indexed terms. A new document could be represented by its term-frequency vector, which is then comparable to the columns of the matrix. Or, a new term could be represented by counting its appearances in all of the documents and be compared to the rows of the matrix.\n\nIt turns out that by finding the \n\nsingular value decomposition of the term-document matrix, the strongest patterns within the corpus can be isolated, frequently corresponding to what we interpret as textual meaning. This is known as latent semantic analysis.\n\nEach vote cast in the U. S. Congress is \n\navailable for download. We can put members of Congress along the columns of a matrix and bills along the rows, recording a number that codes for “yea,”  “nay,” “none,” etc. The \n\nsingular value decomposition can reveal an objective, reproducible analysis of the partisanship and cooperation of individual members.\n\nIn 2006 the online video service Netflix started an open competition for a $1 million prize. They provided a data set of 100,480,507 ratings (one to five stars) made by 480,189 users for 17,770 movies. Each rating is implicitly an entry in a 17,770-by-480,189 matrix. The object of the prize was to predict a user’s ratings for movies they had not rated. This is known as a matrix completion problem. (It took 6 days for a contestant to improve on Netflix’s private algorithm, and in 2009 the million-dollar prize was awarded to a team that had improved the performance by over 10%.)","type":"content","url":"/insight#tables-as-matrices","position":3},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Graphs as matrices"},"type":"lvl2","url":"/insight#graphs-as-matrices","position":4},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Graphs as matrices"},"content":"Graphs and adjacency matrices\n\nA \n\ngraph or network consists of a set V of nodes and a set E of edges, each of which is an ordered pair of nodes. If there is an edge (v_i,v_j), then we say that node i is adjacent to node j. The graph is undirected if for every edge (v_i,v_j), the pair (v_j,v_i) is also an edge; otherwise the graph is directed.\n\nThe \n\nadjacency matrix of a graph with n nodes V and edge set E is the n\\times n matrix whose elements areA_{ij} =\n\\begin{cases}\n1 & \\text{if $(v_i,v_j)\\in E$ (i.e., node $i$ is adjacent to node $j$)},\\\\\n0 & \\text{otherwise}.\n\\end{cases}\n\nNote\n\nIn an undirected graph, the edges (v_i,v_j) and (v_j,v_i) are equivalent and may be identified as a single edge, depending on the context.\n\nGraphs are a useful way to represent the link structure of social networks, airline routes, power grids, sports teams, and web pages, to name a few examples. The natural interpretation is that the edge (v_i,v_j) denotes a link from node i to node j, in which case we say that node i is adjacent to node j. One usually visualizes small graphs by drawing points for nodes and arrows or lines for the edges.\n\nHere are some elementary results about adjacency matrices.\n\nFor any \n\ngraph with \n\nadjacency matrix \\mathbf{A},\n\nThe graph is undirected if and only if \\mathbf{A} is symmetric, and\n\nFor any positive integer k, the (i,j) element of \\mathbf{A}^k is the number of ways to walk from node i to node j by following along exactly k edges.\n\nPart 1 follows immediately from the definitions. Part 2 is clearly true for k=1. Assume inductively that it is true for k-1. Each walk of length k from node i to node j must be a walk of length k-1 from i to node p, then a walk of length 1 from node p to node j. The total number of such walks is therefore\\sum_{p=1}^n [\\mathbf{A}^{k-1}]_{ip} \\cdot A_{pj},\n\nwhich is the (i,j) element of \\mathbf{A}^k.\n\nAdjacency matrix\n\nExample 7.1.4\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nThe graphplot function makes a visual representation of this graph.\n\nusing Plots, GraphRecipes\ngraphplot(A, names=1:4, markersize=0.2, arrow=6)\n\nSince this adjacency matrix is not symmetric, the edges are all directed, as indicated by the arrows. Here are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0]\ngraphplot(A, names=1:4, markersize=0.2)\n\nExample 7.1.4\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nSince this adjacency matrix is not symmetric, the edges are all directed. We use digraph to create a directed graph.\n\nG = digraph(A);\nplot(G)\n\nHere are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0];\nplot(graph(A))\n\nA “buckyball” is an allotrope of carbon atoms with the same connection structure as a soccer ball.\n\nplot(graph(bucky))\n\nExample 7.1.4\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = array([[0, 1, 0, 0], [1, 0, 0, 0], [1, 1, 0, 1], [0, 1, 1, 0]])\nprint(A)\n\nThe networkx package has many functions for working with graphs. Here, we instruct it to create a directed graph from the adjacency matrix, then make a drawing of it.\n\nimport networkx as nx\nG = nx.from_numpy_array(A, create_using=nx.DiGraph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nHere are the counts of all walks of length 3 in the graph:\n\nprint(linalg.matrix_power(A, 3))\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = array([[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [0, 1, 0, 0]])\nG = nx.from_numpy_array(A, create_using=nx.Graph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nThe representation of a graph by its adjacency matrix opens up the possibility of many kinds of analysis of the graph. One might ask whether the nodes admit a natural partition into clusters, for example. Or one might ask to rank the nodes in order of importance to the network as determined by some objective criteria—an application made famous by Google’s PageRank algorithm, and one which is mathematically stated as an \n\neigenvalue problem.","type":"content","url":"/insight#graphs-as-matrices","position":5},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Images as matrices"},"type":"lvl2","url":"/insight#images-as-matrices","position":6},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Images as matrices"},"content":"Computers typically represent images as rectangular arrays of pixels, each of which is colored according to numerical values for red (R), green (G), and blue (B) components of white light. Most often, these are given as integers in the range from zero (no color) to 255 (full color). Thus, an image that is m-by-n pixels can be stored as an m-by-n-by-3 array of integer values. In Julia, we can work with an m\\times n matrix of 3-vectors representing entire colors.\n\nImages as matrices\n\nExample 7.1.5\n\nThe Images package has many functions for image manipulation, and TestImages has some standard images to play with.\n\nusing Images, TestImages\nimg = testimage(\"mandrill\")\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nimg[100, 10]\n\nYou can use eltype to find out the type of the elements of any array.\n\neltype(img)\n\nIt’s possible to extract matrices of red, green, and blue intensities, scaled from 0 to 1.\n\nR, G, B = red.(img), green.(img), blue.(img);\n@show minB, maxB = extrema(B);\n\nOr we can convert the pixels to gray, each pixel again scaled from 0 to 1.\n\nGray.(img)\n\nIn order to do our usual operations, we need to tell Julia that we want to interpret the elements of the image matrix as floating-point values.\n\nA = Float64.(Gray.(img))\nA[1:4, 1:5]\n\nWe can use Gray to reinterpret a matrix of floating-point values as grayscale pixels.\n\nGray.(reverse(A, dims=1))\n\nExample 7.1.5\n\nMATLAB ships with a few test images to play with.\n\nA = imread('peppers.png');\ncolor_size = size(A)\n\nUse imshow to display the image.\n\nimshow(A)\n\nThe image has three layers or channels for red, green, and blue. We can deal with each layer as a matrix, or (as below) convert it to a single matrix indicating shades of gray from black (0) to white (255). Either way, we have to explicitly convert the entries to floating-point values rather than integers.\n\nA = im2gray(A);   % collapse from 3 dimensions to 2\ngray_size = size(A)\nimshow(A)\n\nBefore we can do any numerical computation, we need to convert the image to a matrix of floating-point numbers.\n\nA = double(A);\n\nExample 7.1.5\n\nWe will use a test image from the well-known scikit-image package.\n\nfrom skimage import data as testimages\nimg = getattr(testimages, \"coffee\")()\nimshow(img)\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nprint(f\"image has shape {img.shape}\")\nprint(f\"first pixel has value {img[0, 0]}\")\n\nThe three values at each pixel are for intensities of red, green, and blue. We can convert each of those layers into an ordinary matrix of values between 0 and 255, which is maximum intensity.\n\nR = img[:, :, 0]\nprint(\"upper left corner of the red plane is:\")\nprint(R[:5, :5])\nprint(f\"red channel values range from {R.min()} to {R.max()}\")\n\nIt may also be convenient to convert the image to grayscale, which has just one layer of values from zero (black) to one (white).\n\nfrom skimage.color import rgb2gray\nA = rgb2gray(img)\nA[:5, :5]\nprint(\"upper left corner of grayscale:\")\nprint(A[:5, :5])\nprint(f\"gray values range from {A.min()} to {A.max()}\")\n\nimshow(A, cmap='gray')\naxis('off');\n\nSome changes we make to the grayscale matrix are easy to interpret visually.\n\nimshow(flipud(A), cmap='gray')\naxis('off');\n\nRepresentation of an image as a matrix allows us to describe some common image operations in terms of linear algebra. For example, in \n\nSingular value decomposition we will use the singular value decomposition to compress the information, and in \n\nMatrix-free iterations we will see how to apply and remove blurring effects.","type":"content","url":"/insight#images-as-matrices","position":7},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Exercises"},"type":"lvl2","url":"/insight#exercises","position":8},{"hierarchy":{"lvl1":"From matrix to insight","lvl2":"Exercises"},"content":"✍ Consider the terms numerical, analysis, and fun. Write out the term-document matrix for the following statements:\n\n(a) Numerical analysis is the most fun type of analysis.\n\n(b) It’s fun to produce numerical values for the digits of pi.\n\n(c) Complex analysis is a beautiful branch of mathematics.\n\n✍ Write out the adjacency matrix for the following graph on six nodes.\n\n✍ Here is a graph adjacency matrix.\\begin{bmatrix}\n0 & 1 & 0 & 1 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 & 1 \\\\\n1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 1 & 0 \\\\\n1 & 1 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0   \n\\end{bmatrix}\n\n(a) How many vertices are adjacent to vertex 5? (Assume node numbering starts at 1.)\n\n(b) Is the graph directed or undirected?\n\n(c) How many edges are in the graph?\n\n(d) Draw the graph.\n\n⌨ Refer to \n\nDemo 7.1.5 on loading and displaying images. Choose a test image of your liking.\n\n(a) Display the test image upside-down.\n\n(b) Display it mirror-reversed from left to right.\n\n(c) Display the image so that it is cropped to isolate a part of the subject.\n\n⌨ For this problem you need to download and import data:\n\nDownload \n\nactors.mat by clicking the link and saving (you may need to fix the file name).using MAT\nA = matread(\"actors.mat\")[\"A\"]\n\nDownload \n\nactors.mat by clicking the link and saving (you may need to fix the file name).load actors\n\nDownload \n\nactors.mtx by clicking the link and saving (you may need to fix the file name).import scipy.io as spio\nA = spio.mmread(\"actors.mtx\")\n\nBased on data provided by the Self-Organized Networks Database at the University of Notre Dame, the matrix A contains information about the appearances of 392,400 actors in 127,823 movies, as given by the Internet Movie Database. It has A_{ij}=1 if actor j appeared in movie i and zero elements elsewhere.\n\n(a) What is the maximum number of actors appearing in any one movie?\n\n(b) How many actors appeared in exactly three movies?\n\n(c) Define \\mathbf{C}=\\mathbf{A}^T\\mathbf{A}. How many nonzero entries does \\mathbf{C} have? What is the interpretation of C_{ij}?","type":"content","url":"/insight#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-6","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"Details on the computation of the eigenvalue and singular value decompositions are presented at length in \n\nStewart (2001) and more briefly in Chapters 7 and 8 of \n\nGolub & Van Loan (1996). A classic reference on the particulars of the symmetric case is \n\nParlett (1980), while \n\nTrefethen & Embree (2005) focuses on the non-normal case. Dimension reduction via the SVD often goes by the name principal component analysis, which is the subject of \n\nJolliffe (2002).","type":"content","url":"/next-6","position":1},{"hierarchy":{"lvl1":"7. Matrix analysis"},"type":"lvl1","url":"/overview-6","position":0},{"hierarchy":{"lvl1":"7. Matrix analysis"},"content":"Judge me by my size, do you?\n\nYoda, The Empire Strikes Back\n\nIn previous chapters, we have seen how matrices that represent square or overdetermined linear systems of equations can be manipulated into LU and QR factorizations. But matrices have other factorizations that are more intrinsic to their nature as mathematical linear transformations. The most fundamental of these are the eigenvalue and singular value decompositions.\n\nThese decompositions can be used to solve linear and least-squares systems, but they have greater value in how they represent the matrix itself. They lead to critical and quantitative insights about the structure of the underlying transformation and suggest ways to approximate it efficiently. In this chapter, we will look at both of these fundamental decompositions and hint at just a few of their computational applications.","type":"content","url":"/overview-6","position":1},{"hierarchy":{"lvl1":"Singular value decomposition"},"type":"lvl1","url":"/svd","position":0},{"hierarchy":{"lvl1":"Singular value decomposition"},"content":"We now introduce another factorization that is as fundamental as the EVD.\n\nSingular value decomposition (SVD)\n\nThe \n\nsingular value decomposition of an m\\times n matrix \\mathbf{A} is\\mathbf{A} = \\mathbf{U} \\mathbf{S} \\mathbf{V}^*,\n\nwhere \\mathbf{U}\\in\\mathbb{C}^{m\\times m} and \\mathbf{V}\\in\\mathbb{C}^{n\\times n} are unitary and \\mathbf{S}\\in\\mathbb{R}^{m\\times n} is real and diagonal with nonnegative elements.\n\nThe columns of \\mathbf{U} and \\mathbf{V} are called left and right singular vectors, respectively. The diagonal elements of \\mathbf{S}, written \\sigma_1,\\ldots,\\sigma_r, for r=\\min\\{m,n\\}, are called the singular values of \\mathbf{A} and are ordered so that\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_r\\ge 0, \\qquad r=\\min\\{m,n\\}.\n\nWe call \\sigma_1 the principal singular value and \\mathbf{u}_{1} and \\mathbf{v}_{1} the principal singular vectors.\n\nEvery m\\times n matrix has an SVD. The singular values of a matrix are unique, but the singular vectors are not. If the matrix is real, then \\mathbf{U} and \\mathbf{V} in \n\n(7.3.1) can be chosen to be real, orthogonal matrices.\n\nThe nonuniqueness is easy: for instance, we can replace \\mathbf{U} and \\mathbf{V} by their negatives without affecting \n\n(7.3.1). Proof of the other statements usually relies on induction in the size of \\mathbf{A} and can be found in advanced linear algebra texts.\n\nIt is easy to check that\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}\n= \\underbrace{\\left(\\frac{1}{5} \\begin{bmatrix}\n  3 & -4 \\\\ 4 & 3\n\\end{bmatrix}\\,\\right)}_{\\mathbf{U}} \\cdot \n\\underbrace{\\begin{bmatrix}\n  5 \\\\ 0\n\\end{bmatrix}}_{\\mathbf{S}} \\cdot \n\\underbrace{\\begin{bmatrix}\n  1\n\\end{bmatrix}}_{\\mathbf{V}^T}\n\nmeets all the requirements of an SVD. Hence, interpreted as a 2\\times 1 matrix, the vector [3,4] has the lone singular value 5.\n\nSuppose \\mathbf{A} is a real matrix and that \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T is an SVD. Then \\mathbf{A}^T=\\mathbf{V}\\mathbf{S}^T\\mathbf{U}^T meets all the requirements of an SVD for \\mathbf{A}^T: the first and last matrices are orthogonal, and the middle matrix is diagonal with nonnegative elements. Hence \\mathbf{A} and \\mathbf{A}^T have the same singular values.","type":"content","url":"/svd","position":1},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Connections to the EVD"},"type":"lvl2","url":"/svd#connections-to-the-evd","position":2},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Connections to the EVD"},"content":"The eigenvalues of \\mathbf{A}^*\\mathbf{A} are real and nonnegative, and the \\min\\{m,n\\} largest of them are the squares of the singular values of \\mathbf{A}.\n\nLet \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* be m\\times n, and compute the square hermitian matrix \\mathbf{B}=\\mathbf{A}^*\\mathbf{A}:\\mathbf{B} = (\\mathbf{V}\\mathbf{S}^*\\mathbf{U}^*) (\\mathbf{U}\\mathbf{S}\\mathbf{V}^*) = \\mathbf{V}\\mathbf{S}^*\\mathbf{S}\\mathbf{V}^* = \\mathbf{V}(\\mathbf{S}^T\\mathbf{S})\\mathbf{V}^{-1}.\n\nNote that \\mathbf{S}^T\\mathbf{S} is a diagonal n \\times n matrix. There are two cases to consider. If m \\ge n, then\\mathbf{S}^T\\mathbf{S} = \n\\begin{bmatrix}\n  \\sigma_1^2 & & \\\\\n  & \\ddots & \\\\\n  & & \\sigma_n^2\n\\end{bmatrix}.\n\nOn the other hand, if m<n, then\\mathbf{S}^T\\mathbf{S} =\n\\begin{bmatrix}\n  \\sigma_1^2 & & & \\\\\n  & \\ddots & & \\\\\n  & & \\sigma_m^2 & \\\\\n  & & & \\boldsymbol{0}\n\\end{bmatrix}.\n\nExcept for some unimportant technicalities, the eigenvectors of \\mathbf{A}^*\\mathbf{A}, when appropriately ordered and normalized, are right singular vectors of \\mathbf{A}. The left singular vectors could then be deduced from the identity \\mathbf{A}\\mathbf{V} = \\mathbf{U}\\mathbf{S}.\n\nAnother close connection between EVD and SVD comes via the (m+n)\\times (m+n) matrix\\mathbf{C} =\n\\begin{bmatrix}\n0 & \\mathbf{A}^* \\\\ \\mathbf{A} & 0\n\\end{bmatrix}.\n\nIf σ is a singular value of \\mathbf{B}, then σ and -\\sigma are eigenvalues of \\mathbf{C}, and the associated eigenvector immediately reveals a left and a right singular vector (see \n\nExercise 11). This connection is implicitly exploited by software to compute the SVD.","type":"content","url":"/svd#connections-to-the-evd","position":3},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Interpreting the SVD"},"type":"lvl2","url":"/svd#interpreting-the-svd","position":4},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Interpreting the SVD"},"content":"Another way to write \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* is\\mathbf{A}\\mathbf{V}=\\mathbf{U}\\mathbf{S}.\n\nTaken columnwise, this equation means\\mathbf{A} \\mathbf{v}_{k} = \\sigma_k \\mathbf{u}_{k}, \\qquad k=1,\\ldots,r=\\min\\{m,n\\}.\n\nIn words, each right singular vector is mapped by \\mathbf{A} to a scaled version of its corresponding left singular vector; the magnitude of scaling is its singular value.\n\nBoth the SVD and the EVD describe a matrix in terms of some special vectors and a small number of scalars. \n\nTable 7.3.1 summarizes the key differences. The SVD sacrifices having the same basis in both source and image spaces—after all, they may not even have the same dimension—but as a result gains orthogonality in both spaces.\n\nTable 7.3.1:Comparison of the EVD and SVD\n\nEVD\n\nSVD\n\nexists for most square matrices\n\nexists for all rectangular and square matrices\n\n\\mathbf{A}\\mathbf{x}_k = \\lambda_k \\mathbf{x}_k\n\n\\mathbf{A} \\mathbf{v}_k = \\sigma_k \\mathbf{u}_k\n\nsame basis for domain and range of \\mathbf{A}\n\ntwo orthonormal bases\n\nmay have poor conditioning\n\nperfectly conditioned","type":"content","url":"/svd#interpreting-the-svd","position":5},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Thin form"},"type":"lvl2","url":"/svd#thin-form","position":6},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Thin form"},"content":"In \n\nThe QR factorization we saw that a matrix has both full and thin forms of the QR factorization. A similar situation holds with the SVD.\n\nSuppose \\mathbf{A} is m\\times n with m > n and let \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* be an SVD. The last m-n rows of \\mathbf{S} are all zero due to the fact that \\mathbf{S} is diagonal. Hence\\begin{align*}\n  \\mathbf{U} \\mathbf{S} & =\n  \\begin{bmatrix}\n    \\mathbf{u}_1 & \\cdots & \\mathbf{u}_n & \\mathbf{u}_{n+1} & \\cdots & \\mathbf{u}_m\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\sigma_1 & &  \\\\\n    & \\ddots &  \\\\\n    & & \\sigma_n \\\\\n    & & \\\\\n    & \\boldsymbol{0} & \\\\\n    & &\n  \\end{bmatrix} \\\\\n  &=\n  \\begin{bmatrix}\n    \\mathbf{u}_1 & \\cdots & \\mathbf{u}_n\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\sigma_1 & &  \\\\\n    & \\ddots &  \\\\\n    & & \\sigma_n\n  \\end{bmatrix} = \\hat{\\mathbf{U}} \\hat{\\mathbf{S}},\n\\end{align*}\n\nin which \\hat{\\mathbf{U}} is m\\times n and \\hat{\\mathbf{S}} is n\\times n. This allows us to define the thin SVD\\mathbf{A}=\\hat{\\mathbf{U}}\\hat{\\mathbf{S}}\\mathbf{V}^*,\n\nin which \\hat{\\mathbf{S}} is square and diagonal and \\hat{\\mathbf{U}} is ONC but not square.\n\nSo, in sketch form, a full SVD of a matrix that is taller than it is wide looks like\\rule{1cm}{2.4cm} \\; \\raisebox{11mm}{=} \\; \\rule{2.4cm}{2.4cm} \\; \\raisebox{11mm}{$\\centerdot$} \\; \\rule{1cm}{2.4cm}\\; \\raisebox{11mm}{$\\centerdot$} \\; \\rule[6mm]{1cm}{1cm}\\quad\n\nwhile a thin SVD looks like\\rule{1cm}{2.4cm} \\; \\raisebox{11mm}{=} \\; \\rule{1cm}{2.4cm} \\; \\raisebox{11mm}{$\\centerdot$} \\; \\rule[6mm]{1cm}{1cm} \\; \\raisebox{11mm}{$\\centerdot$} \\; \\rule[6mm]{1cm}{1cm}\n\nGiven the full SVD of \n\nExample 7.3.1, the corresponding thin SVD is\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}\n= \\left(\\frac{1}{5} \\begin{bmatrix}\n  3 \\\\ 4 \n\\end{bmatrix}\\, \\right) \\cdot \\begin{bmatrix}\n  5 \n\\end{bmatrix}\\cdot \\begin{bmatrix}\n  1\n\\end{bmatrix}.\n\nThe thin form retains all the information about \\mathbf{A} from the SVD; the factorization is still an equality, not an approximation. It is computationally preferable when m \\gg n, since it requires far less storage than a full SVD. For a matrix with more columns than rows, one can derive a thin form by taking the adjoint of the thin SVD of \\mathbf{A}^*.","type":"content","url":"/svd#thin-form","position":7},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"SVD and the 2-norm"},"type":"lvl2","url":"/svd#svd-and-the-2-norm","position":8},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"SVD and the 2-norm"},"content":"The SVD is intimately connected to the 2-norm, as the following theorem describes.\n\nSVD properties\n\nLet \\mathbf{A}\\in\\mathbb{C}^{m\\times n} have an SVD \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* in which \n\n(7.3.2) holds. Then:\n\nThe 2-norm satisfies\\| \\mathbf{A} \\|_2 = \\sigma_1.\n\nThe rank of \\mathbf{A} is the number of nonzero singular values.\n\nLet r=\\min\\{m,n\\}. Then\\kappa_2(\\mathbf{A}) = \\|\\mathbf{A}\\|_2\\|\\mathbf{A}^+\\|_2 = \\frac{\\sigma_1}{\\sigma_r},\n\nwhere a division by zero implies that \\mathbf{A} does not have full rank.\n\nThe conclusion \n\n(7.3.15) can be proved by vector calculus. In the square case m=n, \\mathbf{A} having full rank is identical to being invertible. The SVD is the usual means for computing the 2-norm and condition number of a matrix.\n\nSVD properties\n\nExample 7.3.4\n\nWe verify some of the fundamental SVD properties using standard Julia functions from LinearAlgebra.\n\nA = [i^j for i = 1:5, j = 0:3]\n\nTo get only the singular values, use svdvals.\n\nσ = svdvals(A)\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\n@show opnorm(A, 2);\n@show σ[1];\n\n@show cond(A, 2);\n@show σ[1] / σ[end];\n\nTo get singular vectors as well, use svd. The thin form of the factorization is the default.\n\nU, σ, V = svd(A);\n@show size(U);\n@show size(V);\n\nWe verify the orthogonality of the singular vectors as follows:\n\n@show opnorm(U' * U - I);\n@show opnorm(V' * V - I);\n\nExample 7.3.4\n\nWe verify some of the fundamental SVD properties using the built-in svd function.\n\nA = vander(1:5);\nA = A(:, 1:4)\n\n[U, S, V] = svd(A);\ndisp(sprintf(\"U is %d by %d. S is %d by %d. V is %d by %d.\\n\", size(U), size(S), size(V)))\n\nWe verify the orthogonality of the singular vectors as follows:\n\nnorm(U' * U - eye(5))\nnorm(V' * V - eye(4))\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\ns = diag(S);\nnorm_A = norm(A)\nsigma_max = s(1)\n\ncond_A = cond(A)\nsigma_ratio = s(1) / s(end)\n\nExample 7.3.4\n\nWe verify some of the fundamental SVD properties using standard functions from numpy.linalg.\n\nA = array([[(i + 1.0) ** j for j in range(4)] for i in range(5)])\nset_printoptions(precision=4)\nprint(A)\n\nThe factorization is obtained using svd from numpy.linalg.\n\nfrom numpy.linalg import svd\nU, sigma, Vh = svd(A)\nprint(\"singular values:\")\nprint(sigma)\n\nBy default, the full factorization type is returned. This can be a memory hog if one of the dimensions of \\mathbf{A} is very large.\n\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.T.shape)\n\nBoth \\mathbf{U} and \\mathbf{V} are orthogonal (in the complex case, unitary). Note that it’s \\mathbf{V}^* that is returned, not \\mathbf{V}.\n\nprint(f\"should be near zero: {norm(U.T @ U - eye(5), 2):.2e}\")\nprint(f\"should be near zero: {norm(Vh @ Vh.T - eye(4), 2):.2e}\")\n\nNext we test that we have the factorization promised by the SVD, using diagsvd to construct a rectangular diagonal matrix.\n\nfrom scipy.linalg import diagsvd\nS = diagsvd(sigma, 5, 4)\nprint(f\"should be near zero: {norm(A - U @ S @ Vh, 2):.2e}\")\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\nfrom numpy.linalg import cond\nprint(\"largest singular value:\", sigma[0])\nprint(\"2-norm of the matrix:  \", norm(A, 2))\nprint(\"singular value ratio:\", sigma[0] / sigma[-1])\nprint(\"2-norm condition no.:\", cond(A, 2))\n\nFor matrices that are much taller than they are wide, the thin SVD form is more memory-efficient, because \\mathbf{U} takes the same shape.\n\nA = random.randn(1000, 10)\nU, sigma, Vh = svd(A, full_matrices=False)\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.shape)","type":"content","url":"/svd#svd-and-the-2-norm","position":9},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Exercises"},"type":"lvl2","url":"/svd#exercises","position":10},{"hierarchy":{"lvl1":"Singular value decomposition","lvl2":"Exercises"},"content":"✍ Each factorization below is algebraically correct. The notation \\mathbf{I}_n means an n\\times n identity. In each case, determine whether it is an SVD. If it is, write down \\sigma_1, \\mathbf{u}_1, and \\mathbf{v}_1. If it is not, state all of the ways in which it fails the required properties.\n\n(a) \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix} = \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0 \n \\end{bmatrix} \\begin{bmatrix}\n   1 & 0 \\\\ 0 & 0\n \\end{bmatrix} \\begin{bmatrix}\n   0 & 1 \\\\ -1 & 0 \n \\end{bmatrix}\\qquad \n(b) \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix} =\n \\mathbf{I}_2 \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix}\n \\mathbf{I}_2\n\n\n(c)\n\\begin{bmatrix}\n   1 & 0\\\\ 0 & \\sqrt{2}\\\\ 1 & 0\n \\end{bmatrix} = \\begin{bmatrix}\n   \\alpha & 0 & -\\alpha \\\\ 0 & 1 & 0 \\\\ \\alpha & 0 & -\\alpha \n \\end{bmatrix}  \\begin{bmatrix}\n   \\sqrt{2} & 0 \\\\ 0 & \\sqrt{2} \\\\ 0 & 0 \n \\end{bmatrix}  \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0 \n \\end{bmatrix}, \\quad \\alpha=1/\\sqrt{2}\n\n\n(d)\n\\begin{bmatrix}\n   \\sqrt{2} & \\sqrt{2}\\\\ -1 & 1\\\\ 0 & 0\n \\end{bmatrix} =\n \\mathbf{I}_3  \\begin{bmatrix}\n   2 & 0 \\\\ 0 & \\sqrt{2} \\\\ 0 & 0 \n \\end{bmatrix}  \\begin{bmatrix}\n  \\alpha & \\alpha \\\\ -\\alpha & \\alpha \n \\end{bmatrix}, \\quad \\alpha=1/\\sqrt{2}\n\n✍ Apply \n\nTheorem 7.3.2 to find an SVD of \\mathbf{A}=\\displaystyle \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\\\ -1 & -1 \\end{bmatrix}.\n\n⌨ Let x be a vector of 1000 equally spaced points between 0 and 1. Suppose \\mathbf{A}_n is the 1000\\times n matrix whose (i,j) entry is x_i^{j-1} for j=1,\\ldots,n.\n\n(a) Print out the singular values of \\mathbf{A}_1, \\mathbf{A}_2, and \\mathbf{A}_3.\n\n(b) Make a log-linear plot of the singular values of \\mathbf{A}_{40}.\n\n(c) Repeat part (b) after converting the elements of x to single precision.\n\n(d) Having seen the plot for part (c), which singular values in part (b) do you suspect may be incorrect?\n\n⌨ See \n\nDemo 7.1.5 for how to get the “mandrill” test image. Make a log-linear scatter plot of the singular values of the matrix of grayscale intensity values. (The shape of this graph is surprisingly similar across a wide range of images.)\n\n✍ Prove that for a square real matrix \\mathbf{A}, \\| \\mathbf{A} \\|_2=\\| \\mathbf{A}^T \\|_2.\n\n✍ Prove \n\n(7.3.16) of \n\nTheorem 7.3.3, given that \n\n(7.3.15) is true. (Hint: If the SVD of \\mathbf{A} is known, what is the SVD of \\mathbf{A}^{+}?)\n\n✍ Let \\mathbf{A}\\in\\mathbb{R}^{m\\times n} with m>n have the thin SVD \\mathbf{A}=\\hat{\\mathbf{U}}\\hat{\\mathbf{S}}\\mathbf{V}^T, and suppose all the singular values are nonzero. Show that the matrix \\mathbf{A}\\mathbf{A}^{+} is equal to \\hat{\\mathbf{U}}\\hat{\\mathbf{U}}^T, where \\mathbf{A}^{+} is the \n\npseudoinverse of \\mathbf{A}, as given in \n\n(3.2.4). (You must be careful with matrix sizes in this derivation.)\n\n✍ In  \n\n(3.2.6) we defined the 2-norm condition number of a rectangular matrix as \\kappa(\\mathbf{A})=\\|\\mathbf{A}\\|\\cdot \\|\\mathbf{A}^{+}\\|, and then claimed (in the real case) that \\kappa(\\mathbf{A}^*\\mathbf{A})=\\kappa(\\mathbf{A})^2. Prove this assertion using the SVD.\n\n✍ Show that the square of each singular value of \\mathbf{A} is an eigenvalue of the matrix \\mathbf{A}\\mathbf{A}^* for any m\\times n matrix \\mathbf{A}. (You should consider the cases m>n and m\\le n separately.)\n\n✍ In this problem you will see how \n\n(7.3.15) is proved in the real case.\n\n(a) Use the technique of Lagrange multipliers to show that among vectors that satisfy \\|\\mathbf{x}\\|_2^2=1, any vector that maximizes \\|\\mathbf{A}\\mathbf{x}\\|_2^2 must be an eigenvector of \\mathbf{A}^T\\mathbf{A}. It will help to know that if \\mathbf{B} is any symmetric matrix, the gradient of the scalar function \\mathbf{x}^T\\mathbf{B}\\mathbf{x} with respect to \\mathbf{x} is 2\\mathbf{B}\\mathbf{x}.\n\n(b) Use the result of part (a) to prove \n\n(7.3.15) for real matrices.\n\n✍ Suppose \\mathbf{A}\\in\\mathbb{R}^{n \\times n}, and define \\mathbf{C} as in \n\n(7.3.7).\n\n(a) Suppose that \\mathbf{v}=\\begin{bmatrix} \\mathbf{x} \\\\ \\mathbf{y} \\end{bmatrix}, and write the block equation \\mathbf{C}\\mathbf{v} = \\lambda \\mathbf{v} as two individual equations involving both \\mathbf{x} and \\mathbf{y}.\n\n(b) By applying some substitutions, rewrite the equations from part (a) as one in which \\mathbf{x} was eliminated, and another in which \\mathbf{y} was eliminated.\n\n(c) Substitute the SVD \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T and explain why \\lambda^2=\\sigma_k^2 for some singular value \\sigma_k.\n\n(d) As a more advanced variation, modify the argument to show that \\lambda=0 is another possibility if \\mathbf{A} is not square.","type":"content","url":"/svd#exercises","position":11},{"hierarchy":{"lvl1":"Symmetry and definiteness"},"type":"lvl1","url":"/symm-eig","position":0},{"hierarchy":{"lvl1":"Symmetry and definiteness"},"content":"As we saw in \n\nExploiting matrix structure, symmetry can simplify the LU factorization into the symmetric form \\mathbf{A}=\\mathbf{L}\\mathbf{D}\\mathbf{L}^T. Important specializations occur as well for the eigenvalue and singular value factorizations. In this section we stay with complex-valued matrices, so we are interested in the case when \\mathbf{A}^*=\\mathbf{A}, i.e., \\mathbf{A} is hermitian. However, we often loosely speak of symmetry to mean this property even in the complex case. All of the statements in this section easily specialize to the real case.","type":"content","url":"/symm-eig","position":1},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Normality"},"type":"lvl2","url":"/symm-eig#normality","position":2},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Normality"},"content":"Suppose now that \\mathbf{A}^*=\\mathbf{A} and that \\mathbf{A}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^* is an SVD. Since \\mathbf{S} is real and square, we have\\mathbf{A}^* = \\mathbf{V} \\mathbf{S}^* \\mathbf{U}^* = \\mathbf{V} \\mathbf{S} \\mathbf{U}^*,\n\nand it’s tempting to conclude that \\mathbf{U}=\\mathbf{V}. Happily, this is nearly true. The following theorem is typically proved in an advanced linear algebra course.\n\nSpectral decomposition\n\nIf \\mathbf{A}=\\mathbf{A}^*, then \\mathbf{A} has a diagonalization \\mathbf{A}=\\mathbf{V} \\mathbf{D} \\mathbf{V}^{-1} in which \\mathbf{V} is unitary and \\mathbf{D} is diagonal and real.\n\nAnother way to state the result of this theorem is that a hermitian matrix has real eigenvalues and a complete set of orthonormal eigenvectors—that is, the matrix is normal. Because hermitian matrices are normal, their eigenvalue condition number is guaranteed to be 1 by \n\nTheorem 7.2.3.\n\nNote\n\nThe converse of \n\nTheorem 7.4.1 is also true: every normal matrix with real eigenvalues is hermitian. This was illustrated in \n\nDemo 7.2.3.\n\nFor a hermitian matrix, the EVD\\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1}=\\mathbf{V} \\mathbf{D} \\mathbf{V}^*\n\nis almost an SVD.\n\nIf \\mathbf{A}^*=\\mathbf{A} and \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^{-1} is a unitary diagonalization, then\\mathbf{A} = (\\mathbf{V}\\mathbf{T})\\cdot |\\mathbf{D}|\\cdot \\mathbf{V}^*\n\nis an SVD, where |\\mathbf{D}| is the elementwise absolute value and \\mathbf{T} is diagonal with |T_{ii}|=1 for all i. In particular, the absolute values of the eigenvalues of \\mathbf{A} are the singular values of \\mathbf{A}.\n\nLet T_{ii}=\\operatorname{sign}(D_{ii}) for all i. Then \\mathbf{T}^2=\\mathbf{I}, |\\mathbf{D}|=\\mathbf{T}\\mathbf{D}, and\\mathbf{A}=\\mathbf{V} \\mathbf{D} \\mathbf{V}^*=\\mathbf{V} \\mathbf{T}^2 \\mathbf{D} \\mathbf{V}^*=(\\mathbf{V} \\mathbf{T}) (\\mathbf{T} \\mathbf{D}) \\mathbf{V}^*.","type":"content","url":"/symm-eig#normality","position":3},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Rayleigh quotient"},"type":"lvl2","url":"/symm-eig#rayleigh-quotient","position":4},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Rayleigh quotient"},"content":"Recall that for a matrix \\mathbf{A} and compatible vector \\mathbf{x}, the quadratic form \\mathbf{x}^* \\mathbf{A} \\mathbf{x} is a scalar.\n\nGiven hermitian \\mathbf{A} and nonzero vector \\mathbf{x}, the \n\nRayleigh quotient is the functionR_{\\mathbf{A}}(\\mathbf{x}) = \\frac{ \\mathbf{x}^* \\mathbf{A} \\mathbf{x}}{\\mathbf{x}^* \\mathbf{x}}.\n\nIf \\mathbf{v} is an eigenvector such that \\mathbf{A} \\mathbf{v}=\\lambda \\mathbf{v}, then one easily calculates that R_{\\mathbf{A}}(\\mathbf{v})=\\lambda. That is, the Rayleigh quotient maps an eigenvector into its associated eigenvalue.\n\nIf \\mathbf{A}^*=\\mathbf{A}, then the Rayleigh quotient has another interesting property: \\nabla R_{\\mathbf{A}}(\\mathbf{v})=\\boldsymbol{0} if \\mathbf{v} is an eigenvector. By a multidimensional Taylor series, then,R_{\\mathbf{A}}(\\mathbf{v}+\\epsilon\\mathbf{z}) = R_{\\mathbf{A}}(\\mathbf{v}) + 0 + O( \\epsilon^2) =  \\lambda + O( \\epsilon^2),\n\nas \\epsilon\\to 0. The conclusion is that a good estimate of an eigenvector becomes an even better estimate of an eigenvalue.\n\nRayleigh quotient\n\nExample 7.4.1\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nλ = 1:n\nD = diagm(λ)\nV, _ = qr(randn(n, n))   # get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = x -> (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nR(V[:, 7])\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nδ = @. 1 ./ 10^(1:5)\neval_diff = zeros(size(δ))\nfor (k, delta) in enumerate(δ)\n    e = randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 7] + e\n    eval_diff[k] = R(x) - 7\nend\nlabels = [\"perturbation δ\", \"δ²\", \"R(x) - λ\"]\n@pt :header=labels [δ δ .^ 2 eval_diff]\n\nExample 7.4.1\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nlambda = 1:n;\nD = diag(lambda);\n[V, ~] = qr(randn(n, n));    % get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = @(x) (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nformat long\nR(V(:, 7))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\ndelta = 1 ./ 10 .^ (1:5)';\ndif = zeros(size(delta));\nfor k = 1:length(delta)\n    e = randn(n, 1);\n    e = delta(k) * e / norm(e);\n    x = V(:, 6) + e;\n    dif(k) = R(x) - lambda(6);\nend\ntable(delta, dif, variablenames=[\"perturbation size\", \"R(x) - lambda\"])\n\nExample 7.4.1\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nfrom numpy.linalg import qr\nn = 20\nd = arange(n) + 1\nD = diag(d)\nV, _ = qr(random.randn(n, n))    # get a random orthogonal V\nA = V @ D @ V.T\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = lambda x: dot(x, A @ x) / dot(x, x)\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nprint(R(V[:, 6]))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nresults = PrettyTable([\"perturbation size\", \"R.Q. - λ\"])\nfor delta in 1 / 10 ** arange(1, 6):\n    e = random.randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 5] + e\n    quotient = R(x)\n    results.add_row([delta, quotient - d[5]])\n\nprint(results)","type":"content","url":"/symm-eig#rayleigh-quotient","position":5},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Definite, semidefinite, and indefinite matrices"},"type":"lvl2","url":"/symm-eig#definite-semidefinite-and-indefinite-matrices","position":6},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Definite, semidefinite, and indefinite matrices"},"content":"In the real case, we called a symmetric matrix \\mathbf{A} symmetric positive definite (SPD) if \\mathbf{x}^T \\mathbf{A}\\mathbf{x} > 0  for all nonzero vectors \\mathbf{x}. In the complex case the analog is a \n\nhermitian positive definite matrix (HPD matrix), meaning that \\mathbf{A}^*=\\mathbf{A} and \\mathbf{x}^* \\mathbf{A}\\mathbf{x} > 0 for all complex vectors \\mathbf{x}. Putting this property together with the Rayleigh quotient leads to the following.\n\nIf \\mathbf{A}^*=\\mathbf{A}, then the following statements are equivalent.\n\n\\mathbf{A} is HPD.\n\nThe eigenvalues of \\mathbf{A} are positive numbers.\n\nSuppose item 1 is true. If \\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x} is an eigenpair, then a Rayleigh quotient implies that\\lambda = \\frac{ \\mathbf{x}^*\\mathbf{A}\\mathbf{x} }{\\mathbf{x}^*\\mathbf{x}} > 0.\n\nHence item 2 is true. Conversely, suppose item 2 is known. Then we can write the EVD as \\mathbf{A}=\\mathbf{V}\\mathbf{S}^2\\mathbf{V}^*, where the S_{ii} are positive square roots of the eigenvalues. Hence\\mathbf{x}^*\\mathbf{A}\\mathbf{x} = \\mathbf{x}^*\\mathbf{V}\\mathbf{S}^2\\mathbf{V}^*\\mathbf{x} = \\|\\mathbf{S}\\mathbf{V}^*\\mathbf{x}\\|^2 > 0,\n\nas both \\mathbf{S} and \\mathbf{V} are invertible. Thus, item 1 is true.\n\nAccording to \n\nTheorem 7.4.3, for an HPD matrix, the EVD \\mathbf{A}=\\mathbf{V}\\mathbf{D}\\mathbf{V}^* meets all the requirements of the SVD, provided the ordering of eigenvalues is chosen appropriately.\n\nA hermitian matrix with all negative eigenvalues is called negative definite, and one with eigenvalues of different signs is indefinite. Finally, if one or more eigenvalues is zero and the rest have one sign, it is positive or negative semidefinite.","type":"content","url":"/symm-eig#definite-semidefinite-and-indefinite-matrices","position":7},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Exercises"},"type":"lvl2","url":"/symm-eig#exercises","position":8},{"hierarchy":{"lvl1":"Symmetry and definiteness","lvl2":"Exercises"},"content":"✍ Each line below is an EVD for a hermitian matrix. State whether the matrix is definite, indefinite, or semidefinite. Then state whether the given factorization is also an SVD, and if it is not, modify it to find an SVD.\n\n(a) \\begin{bmatrix}\n   0 & 0 \\\\ 0 & -1\n \\end{bmatrix} =   \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0\n \\end{bmatrix}  \\begin{bmatrix}\n   -1 & 0 \\\\ 0 & 0\n \\end{bmatrix}  \\begin{bmatrix}\n   0 & 1 \\\\ 1 & 0\n \\end{bmatrix}\n\n\n(b) \\begin{bmatrix}\n   4 & -2 \\\\ -2 & 1\n \\end{bmatrix} = \\begin{bmatrix}\n   1 & -0.5 \\\\ -0.5 & -1\n \\end{bmatrix}  \\begin{bmatrix}\n   5 & 0 \\\\ 0 & 0\n \\end{bmatrix}  \\begin{bmatrix}\n   0.8 & -0.4 \\\\ -0.4 & -0.8\n \\end{bmatrix}\n\n\n(c)\n\\begin{bmatrix}\n   -5 & 3\\\\ 3 & -5\n \\end{bmatrix} =  \\begin{bmatrix}\n   \\alpha & \\alpha \\\\ \\alpha & -\\alpha\n \\end{bmatrix}  \\begin{bmatrix}\n   -2 & 0 \\\\ 0 & -8\n \\end{bmatrix}  \\begin{bmatrix}\n   \\alpha & \\alpha \\\\ \\alpha & -\\alpha\n \\end{bmatrix}, \\quad\\alpha=1/\\sqrt{2}\n\n⌨ The matrix names below are found in MatrixDepot for Julia, gallery for MATLAB, and rogues for Python. You will have to adjust the syntax accordingly. For each matrix, determine whether it is positive definite, negative definite, positive or negative semidefinite, or indefinite.\n\n(a) pei(5)  - 6 \\mathbf{I}\n\n(b) hilb(8)  - 2 \\mathbf{I}\n\n(c) dingdong(20)\n\n(d) lehmer(100)\n\n(e) fiedler(200)\n\n✍ Prove true, or give a counterexample: If \\mathbf{A} and \\mathbf{B} are hermitian matrices of the same size, thenR_{\\mathbf{A}+\\mathbf{B}}(\\mathbf{x}) = R_{\\mathbf{A}}(\\mathbf{x})+R_{\\mathbf{B}}(\\mathbf{x}).\n\n⌨ The range of the function R_{\\mathbf{A}}(\\mathbf{x}) is a subset of the complex plane known as the field of values of the matrix \\mathbf{A}. Use 500 random vectors to plot points in the field of values of \\mathbf{A} = \\displaystyle  \\begin{bmatrix}\n  1  &   0   & -2\\\\\n  0  &   2  &   0\\\\\n -2   &  0 &    1\n \\end{bmatrix}. Then compute its eigenvalues and guess what the exact field of values is.\n\n✍ Let \\mathbf{A}=\\displaystyle \\begin{bmatrix} 3 & -2 \\\\ -2 & 0 \\end{bmatrix}.\n\n(a) Write out R_{\\mathbf{A}}(\\mathbf{x}) explicitly as a function of x_1 and x_2.\n\n(b) Find R_{\\mathbf{A}}(\\mathbf{x}) for x_1=1, x_2=2.\n\n(c) Find the gradient vector \\nabla R_{\\mathbf{A}}(\\mathbf{x}).\n\n(d) Show that the gradient vector is zero when x_1=1, x_2=2.\n\n✍ A skew-Hermitian matrix is one that satisfies \\mathbf{A}^*=-\\mathbf{A}. Show that if \\mathbf{A} is skew-Hermitian, then R_{\\mathbf{A}} is imaginary-valued.\n\n⌨ Thanks largely to \n\nTheorem 7.4.1, the eigenvalue problem for symmetric/hermitian matrices is easier than for general matrices.\n\n(a) Let \\mathbf{A} be a 1000\\times 1000 random real matrix, and let \\mathbf{S}=\\mathbf{A}+\\mathbf{A}^T. Time finding the eigenvalues of \\mathbf{A} and then of \\mathbf{S}. You should find that the computation for \\mathbf{S} is around an order of magnitude faster.\n\n(b) Perform the experiment from part (a) on n\\times n matrices for n=200,300,\\ldots,1600. Plot running time as a function of n for both matrices on a single log-log plot. Is the ratio of running times roughly constant, or does it grow with n?","type":"content","url":"/symm-eig#exercises","position":9},{"hierarchy":{"lvl1":"GMRES"},"type":"lvl1","url":"/gmres","position":0},{"hierarchy":{"lvl1":"GMRES"},"content":"The most important use of the Arnoldi iteration is to solve the square linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nIn \n\nDemo 8.4.1, we attempted to replace the linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b} by the lower-dimensional approximation\\min_{\\mathbf{x}\\in \\mathcal{K}_m} \\|  \\mathbf{A}\\mathbf{x}-\\mathbf{b}  \\| = \\min_{\\mathbf{z}\\in\\mathbb{C}^m} \\|   \\mathbf{A}\\mathbf{K}_m\\mathbf{z}-\\mathbf{b}  \\|,\n\nwhere \\mathbf{K}_m is the Krylov matrix generated using \\mathbf{A} and the seed vector \\mathbf{b}. This method was unstable due to the poor conditioning of \\mathbf{K}_m, which is a numerically poor basis for \\mathcal{K}_m.\n\nThe Arnoldi algorithm yields an orthonormal basis of the same space and fixes the stability problem. Set \\mathbf{x}=\\mathbf{Q}_m\\mathbf{z} and obtain\\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{A} \\mathbf{Q}_m \\mathbf{z}-\\mathbf{b}  \\bigr\\|.\n\nFrom the fundamental Arnoldi identity \n\n(8.4.10), this is equivalent to\\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{Q}_{m+1} \\mathbf{H}_m\\mathbf{z}-\\mathbf{b} \\bigr\\|.\n\nNote that \\mathbf{q}_1 is a unit multiple of \\mathbf{b}, so \\mathbf{b} = \\|\\mathbf{b}\\| \\mathbf{Q}_{m+1}\\mathbf{e}_1. Thus \n\n(8.5.3) becomes\\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{Q}_{m+1} (\\mathbf{H}_m\\mathbf{z}-\\|\\mathbf{b}\\|\\mathbf{e}_1) \\bigr\\|.\n\nThe least-squares problems \n\n(8.5.2),  \n\n(8.5.3), and \n\n(8.5.4) are all n\\times m. But observe that for any \\mathbf{w}\\in\\mathbb{C}^{m+1},  \\|\\mathbf{Q}_{m+1}\\mathbf{w}\\|^2 = \\mathbf{w}^*\\mathbf{Q}_{m+1}^*\\mathbf{Q}_{m+1}\\mathbf{w} = \\mathbf{w}^*\\mathbf{w} = \\|\\mathbf{w}\\|^2.\n\nThe first norm in that equation is on \\mathbb{C}^n, while the last is on the much smaller space \\mathbb{C}^{m+1}. Hence the least-squares problem \n\n(8.5.4) is equivalent to  \\min_{\\mathbf{z}\\in\\mathbb{C}^m}\\, \\bigl\\| \\mathbf{H}_m\\mathbf{z}-\\|\\mathbf{b}\\|\\,\\mathbf{e}_1 \\bigr\\|,\n\nwhich is of size (m+1)\\times m. We call the solution of this minimization \\mathbf{z}_m, and then \\mathbf{x}_m=\\mathbf{Q}_m \\mathbf{z}_m is the mth approximation to the solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nGMRES\n\nGiven n\\times n matrix \\mathbf{A} and n-vector \\mathbf{b}:\n\nFor m=1,2,\\ldots, let \\mathbf{x}_m=\\mathbf{Q}_m \\mathbf{z}_m, where \\mathbf{z}_m solves the linear least-squares problem \n\n(8.5.6), and \\mathbf{Q}_m,\\mathbf{H}_m arise from the Arnoldi iteration.\n\nGMRES uses the Arnoldi iteration to minimize the residual \\mathbf{b} - \\mathbf{A}\\mathbf{x} over successive Krylov subspaces. In exact arithmetic, GMRES should get the exact solution when m=n, but the goal is to reduce the residual enough to stop at some m \\ll n.\n\nGMRES\n\nExample 8.5.1\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = [norm(b); zeros(60)]\nfor m in 1:60\n    s = [norm(b); zeros(m)]\n    z = H[1:m+1, 1:m] \\ s\n    x = Q[:, 1:m] * z\n    resid[m+1] = norm(b - A * x)\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nusing Plots\nplot(0:60, resid, m=:o,\n    xaxis=(L\"m\"),  yaxis=(:log10, \"norm of mth residual\"),\n    title=\"Residual for GMRES\",  legend=:none)\n\nExample 8.5.1\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nlambda = 10 + (1:100);\nA = diag(lambda) + triu(rand(100), 1); \nb = rand(100, 1);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\n[Q, H] = arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = norm(b);\nfor m = 1:60\n    s = [norm(b); zeros(m, 1)];\n    z = H(1:m+1, 1:m) \\ s;\n    x = Q(:, 1:m) * z;\n    resid = [resid, norm(b - A * x)];\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nclf\nsemilogy(resid,'.-')\nxlabel('m'),  ylabel('|| b - Ax_m ||')\naxis tight, title(('Residual for GMRES'));\n\nExample 8.5.1\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100)\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60)\nprint(H[:5, :5])\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nfrom numpy.linalg import lstsq\nresid = zeros(61)\nresid[0] = norm(b)\nfor m in range(1, 61):\n    s = hstack([norm(b), zeros(m)])\n    z = lstsq(H[: m + 1, :m], s, rcond=None)[0]\n    x = Q[:, :m] @ z\n    resid[m] = norm(b - A @ x)\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nsemilogy(range(61), resid, \"-o\")\nxlabel(\"$m$\"),  ylabel(\"$\\| b-Ax_m \\|$\")\ntitle(\"Residual for GMRES\");\n\nCompare the graph in \n\nDemo 8.5.1  to the one in \n\nDemo 8.4.1. Both start with the same linear convergence, but only the version using Arnoldi avoids the instability created by the poor Krylov basis.\n\nA basic implementation of GMRES is given in \n\nFunction 8.5.2.\n\ngmres\n\nGMRES\n\n\"\"\"\n    gmres(A, b, m)\n\nDo `m` iterations of GMRES for the linear system `A`*x=`b`. Returns\nthe final solution estimate x and a vector with the history of\nresidual norms. (This function is for demo only, not practical use.)\n\"\"\"\nfunction gmres(A, b, m)\n    n = length(b)\n    Q = zeros(n, m+1)\n    Q[:, 1] = b / norm(b)\n    H = zeros(m+1, m)\n\n    # Initial solution is zero.\n    x = 0\n    residual = [norm(b); zeros(m)]\n\n    for j in 1:m\n        # Next step of Arnoldi iteration.\n        v = A * Q[:, j]\n        for i in 1:j\n            H[i, j] = dot(Q[:, i], v)\n            v -= H[i, j] * Q[:, i]\n        end\n        H[j+1, j] = norm(v)\n        Q[:, j+1] = v / H[j+1, j]\n\n        # Solve the minimum residual problem.\n        r = [norm(b); zeros(j)]\n        z = H[1:j+1, 1:j] \\ r\n        x = Q[:, 1:j] * z\n        residual[j+1] = norm(A * x - b)\n    end\n    return x, residual\nend\n\nGMRES\n\nfunction [x, residual] = arngmres(A, b, m)\r\n% ARNGMRES   GMRES for a linear system (demo only).\r\n% Input:\r\n%   A       square matrix (n by n)\r\n%   b       right-hand side (n by 1)\r\n%   M       number of iterations\r\n% Output: \r\n%   x       approximate solution (n by 1)\r\n%   r       history of norms of the residuals\r\n\r\nn = length(A);\r\nQ = zeros(n, m+1);  \r\nQ(:, 1) = b / norm(b);\r\nH = zeros(m+1 ,m);\r\n\r\n% Initial \"solution\" is zero.\r\nresidual(1) = norm(b);\r\n\r\nfor j = 1:m\r\n  % Next step of Arnoldi iteration.\r\n  v = A * Q(:, j);\r\n  for i = 1:j\r\n      H(i, j) = Q(:, i)' * v;\r\n      v = v - H(i, j) * Q(:,i);\r\n  end\r\n  H(j+1, j) = norm(v);\r\n  Q(:, j+1) = v / H(j+1, j);\r\n  \r\n  % Solve the minimum residual problem.\r\n  r = norm(b) * eye(j+1, 1);\r\n  z = H(1:j+1, 1:j) \\ r;\r\n  x = Q(:, 1:j) * z;\r\n  residual(j+1) = norm( A*x - b );\r\nend\n\nGMRES\n\ndef gmres(A, b, m):\n    \"\"\"\n    gmres(A, b, m)\n\n    Do m iterations of GMRES for the linear system A*x=b. Return the final solution\n    estimate x and a vector with the history of residual norms. (This function is for\n    demo only, not practical use.)\n    \"\"\"\n    n = len(b)\n    Q = np.zeros([n, m + 1])\n    Q[:, 0] = b / np.linalg.norm(b)\n    H = np.zeros([m + 1, m])\n\n    # Initial \"solution\" is zero.\n    residual = np.hstack([np.linalg.norm(b), np.zeros(m)])\n\n    for j in range(m):\n        # Next step of Arnoldi iteration.\n        v = A @ Q[:, j]\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n        # Solve the minimum residual problem.\n        r = np.hstack([np.linalg.norm(b), np.zeros(j + 1)])\n        z = np.linalg.lstsq(H[:j + 2, :j + 1], r)[0]\n        x = Q[:, :j + 1] @ z\n        residual[j + 1] = np.linalg.norm(A @ x - b)\n\n    return x, residual","type":"content","url":"/gmres","position":1},{"hierarchy":{"lvl1":"GMRES","lvl2":"Convergence and restarting"},"type":"lvl2","url":"/gmres#convergence-and-restarting","position":2},{"hierarchy":{"lvl1":"GMRES","lvl2":"Convergence and restarting"},"content":"Thanks to \n\nTheorem 8.4.1, minimization of \\|\\mathbf{b}-\\mathbf{A}\\mathbf{x}\\| over \\mathcal{K}_{m+1} includes minimization over \\mathcal{K}_m. Hence the norm of the residual \\mathbf{r}_m = \\mathbf{b} - \\mathbf{A}\\mathbf{x}_m (being the minimized quantity) cannot increase as the iteration unfolds.\n\nUnfortunately, making other conclusive statements about the convergence of GMRES is neither easy nor simple. \n\nDemo 8.5.1 shows the cleanest behavior: essentially linear convergence down to the range of machine epsilon. But it is possible for the convergence to go through phases of sublinear and superlinear convergence as well. There is a strong dependence on the eigenvalues of the matrix, a fact we state with more precision and detail in the next section.\n\nOne of the practical challenges in GMRES is that as the dimension of the Krylov subspace grows, the number of new entries to be found in \\mathbf{H}_m and the total number of columns in \\mathbf{Q} also grow. Thus both the work and the storage requirements are quadratic in m, which can become intolerable in some applications. For this reason, GMRES is often used with restarting.\n\nSuppose \\hat{\\mathbf{x}} is an approximate solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Then if we set \\mathbf{x}=\\mathbf{u}+\\hat{\\mathbf{x}}, we have \\mathbf{A}(\\mathbf{u}+\\hat{\\mathbf{x}}) = \\mathbf{b}, or \\mathbf{A}\\mathbf{u} = \\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}}. The conclusion is that if we get an approximate solution and compute its residual \\mathbf{r}=\\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}}, then we need only to solve \\mathbf{A}\\mathbf{u} = \\mathbf{r} in order to get a correction to \\hat{\\mathbf{x}}.\n\nRestarting guarantees a fixed upper bound on the per-iteration cost of GMRES. However, this benefit comes at a price. Even though restarting preserves progress made in previous iterations, the Krylov space information is discarded and the residual minimization process starts again over low-dimensional spaces. That can significantly retard or even stagnate the convergence.\n\nRestarting GMRES\n\nExample 8.5.2\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nA = FNC.poisson(50)\nn = size(A, 1)\nb = ones(n);\nspy(A, color=:blues)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from the IterativeSolvers package, since our simple implementation does not offer restarting.\n\nTip\n\nThe syntax f(x;foo) is shorthand for f(x,foo=foo).\n\nusing IterativeSolvers\nreltol = 1e-12;\nplt = plot(title=\"Convergence of restarted GMRES\", legend=:bottomleft,\n    xaxis=(L\"m\"),  yaxis=(:log10, \"residual norm\", [1e-8, 100]))\n\nfor restart in [n, 20, 40, 60]\n    x, hist = IterativeSolvers.gmres(A, b; restart, reltol,\n        maxiter=100, log=true)\n    plot!(hist[:resnorm], label=\"restart = $restart\")\nend\n\nplt\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.\n\nExample 8.5.2\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nd = 50;\nA = d^2 * gallery('poisson', d);\nn = size(A, 1)\nb = ones(n, 1);\nclf,  spy(A)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using the built-in gmres, since our simple implementation does not offer restarting.\n\nclf\nrestart = [120, 20, 40, 60];\nfor j = 1:4\n    [~,~,~,~,rv] = gmres(A, b, restart(j), 1e-9,120 / restart(j));\n    semilogy(0:length(rv) - 1, rv),  hold on\nend\ntitle('Convergence of restarted GMRES')\nxlabel('m'),  ylabel('residual norm')\nlegend('no restart','every 20','every 40','every 60','location','southwest');\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.\n\nExample 8.5.2\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nd = 50;  n = d**2\nA = FNC.poisson2d(d)\nb = ones(n)\nspy(A);\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from scipy.sparse.linalg, since our simple implementation does not offer restarting. We’re also using a trick to accumulate the vector of residual norms as it runs.\n\nfrom scipy.sparse.linalg import gmres\nctr = lambda rvec: resid.append(norm(rvec))\nresid = [1.]\nx, flag = gmres(A, b, restart=None, rtol=1e-8, atol=1e-14, maxiter=120, callback=ctr)\nsemilogy(resid); \nxlabel(\"$m$\"), ylabel(\"residual norm\")\ntitle((\"Convergence of unrestarted GMRES\"));\n\nmaxit = 120\nrtol = 1e-8\nrestarts = [maxit, 20, 40, 60]\nhist = lambda rvec: resid.append(norm(rvec))\nfor r in restarts:\n    resid = [1.]\n    x, flag = gmres(A, b, restart=r, rtol=rtol, atol=1e-14, maxiter=maxit, callback=hist)\n    semilogy(resid)\n\nylim(1e-8, 2)\nlegend([\"none\", \"20\", \"40\", \"60\"])\ntitle((\"Convergence of restarted GMRES\"));\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.\n\nRestarting creates a tradeoff between the number of iterations and the speed per iteration. It’s essentially impossible in general to predict the ideal restart location in any given problem, so one goes by experience and hopes for the best.\n\nThere are other ways to avoid the growth in computational effort as the GMRES/Arnoldi iteration proceeds. Three of the more popular variations are abbreviated CGS, BiCGSTAB, and QMR. We do not describe them in this book.","type":"content","url":"/gmres#convergence-and-restarting","position":3},{"hierarchy":{"lvl1":"GMRES","lvl2":"Exercises"},"type":"lvl2","url":"/gmres#exercises","position":4},{"hierarchy":{"lvl1":"GMRES","lvl2":"Exercises"},"content":"✍ (See also \n\nExercise 8.4.1.) Consider the linear system with\\mathbf{A}=\\displaystyle \n    \\begin{bmatrix}\n      0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0\n    \\end{bmatrix}, \\qquad \\mathbf{b}=\\mathbf{e}_1.\n\n(a) Find the exact solution by inspection.\n\n(b) Find the GMRES approximate solutions \\mathbf{x}_m for m=1,2,3,4.\n\n✍ (Continuation of \n\nExercise 8.4.3.) Show that if \\mathbf{x}_m\\in\\mathcal{K}_m, then the residual \\mathbf{b}-\\mathbf{A}\\mathbf{x}_m is equal to q(\\mathbf{A})\\mathbf{b}, where q is a polynomial of degree at most m and q(0)=1. (This fact is a key one for many convergence results.)\n\n✍ Explain why GMRES, in exact arithmetic, converges to the true solution in n iterations for an n\\times n matrix if \\operatorname{rank}(\\mathbf{K}_n)=n. (Hint: Consider how the algorithm is defined from first principles.)\n\n⌨ Let \\mathbf{A} be the n\\times n tridiagonal matrix\\begin{bmatrix}\n      -4 & 1      &        &        &   \\\\\n      1  & -4     & 1      &        &   \\\\\n         & \\ddots & \\ddots & \\ddots &   \\\\\n         &        & 1      & -4     & 1 \\\\\n         &        &        & 1      & -4 \n    \\end{bmatrix}\n\nand let the n-vector \\mathbf{b} have elements b_i=i/n. For n=8,16,32,64, run \n\nFunction 8.5.2 for m=n/2 iterations. On one semi-log graph, plot \\|\\mathbf{r}_k\\|/\\|\\mathbf{b}\\| for all the cases. How does the convergence rate of GMRES seem to depend on n?must stay as #5\n\n⌨  In this exercise you will see the strong effect the eigenvalues of the matrix may have on GMRES convergence. Let\\mathbf{B}=\n    \\begin{bmatrix}\n      1 & & & \\\\\n      & 2 & & \\\\\n      & & \\ddots & \\\\\n      & & & 100\n    \\end{bmatrix},\n\nlet \\mathbf{I} be a 100\\times 100 identity, and let \\mathbf{Z} be a 100\\times 100 matrix of zeros. Also let \\mathbf{b} be a 200\\times 1 vector of ones. You will use GMRES with restarts, as in \n\nDemo 8.5.2 (i.e., not the book’s version of gmres).\n\n(a) Let \\mathbf{A} = \\begin{bmatrix} \\mathbf{B} & \\mathbf{I} \\\\ \\mathbf{Z} & \\mathbf{B} \\end{bmatrix}. What are its eigenvalues (no computer required here)? Apply gmres with tolerance \n\n10-10 for 100 iterations without restarts, and plot the residual convergence.\n\n(b) Repeat part (a) with restarts every 20 iterations.\n\n(c) Now let \\mathbf{A} = \\begin{bmatrix} \\mathbf{B} & \\mathbf{I} \\\\ \\mathbf{Z} & -\\mathbf{B} \\end{bmatrix}. What are its eigenvalues? Repeat part (a). Which matrix is more difficult for GMRES? (Note: Even though this matrix is triangular, GMRES has no way of exploiting that fact.)\n\n⌨ (Continuation of \n\nExercise 8.3.5.) We again consider the n^2\\times n^2 sparse matrix defined by FNC.poisson(n). The solution of \\mathbf{A}\\mathbf{x}=\\mathbf{b} may be interpreted as the deflection of a lumped membrane in response to a load represented by \\mathbf{b}.\n\n(a) For n=10,15,20,25, let \\mathbf{b} be the vector of n^2 ones and apply \n\nFunction 8.5.2 for 50 iterations. On one semi-log graph, plot the four convergence curves \\|\\mathbf{r}_m\\|/\\|\\mathbf{b}\\|.\n\n(b) For the case n=25 make a surface plot of x after reshaping it to a 25×25 matrix. It should look physically plausible (though upside-down for a weighted membrane).\n\nGMRES stands for Generalized Minimum RESidual. We will encounter its precursor MINRES in \n\nMINRES and conjugate gradients.\n\nThis statement is not strictly correct for rare special cases of breakdown where the rank of \\mathcal{K}_n is less than n. In that situation, some additional steps must be taken that we do not discuss here.\n\nThe new problem needs to be solved for accuracy relative to \\|\\mathbf{b}\\|, not relative to \\|\\mathbf{r}\\|.","type":"content","url":"/gmres#exercises","position":5},{"hierarchy":{"lvl1":"Inverse iteration"},"type":"lvl1","url":"/inviter","position":0},{"hierarchy":{"lvl1":"Inverse iteration"},"content":"Power iteration finds only the dominant eigenvalue. We next show that it can be adapted to find any eigenvalue, provided you start with a reasonably good estimate of it. Some simple linear algebra is all that is needed.\n\nLet \\mathbf{A} be an n\\times n matrix with eigenvalues \\lambda_1,\\ldots,\\lambda_n (possibly with repeats), and let s be a complex scalar. Then:\n\nThe eigenvalues of the matrix \\mathbf{A}-s\\mathbf{I} are \\lambda_1-s,\\ldots,\\lambda_n-s.\n\nIf s is not an eigenvalue of \\mathbf{A}, the eigenvalues of the matrix (\\mathbf{A}-s\\mathbf{I})^{-1} are (\\lambda_1-s)^{-1},\\ldots,(\\lambda_n-s)^{-1}.\n\nThe eigenvectors associated with the eigenvalues in the first two parts are the same as those of \\mathbf{A}.\n\nThe equation \\mathbf{A}\\mathbf{v}=\\lambda \\mathbf{v} implies that (\\mathbf{A}-s\\mathbf{I})\\mathbf{v} = \\mathbf{A}\\mathbf{v} - s\\mathbf{I}\\mathbf{v} = \\lambda\\mathbf{v} - s\\mathbf{v} = (\\lambda-s)\\mathbf{v}. That proves the first part of the theorem. For the second part, we note that by assumption, (\\mathbf{A}-s\\mathbf{I}) is nonsingular, so (\\mathbf{A}-s\\mathbf{I})\\mathbf{v} = (\\lambda-s) \\mathbf{v} implies that \\mathbf{v} = (\\lambda-s) (\\mathbf{A}-s\\mathbf{I}) \\mathbf{v}, or  (\\lambda-s)^{-1} \\mathbf{v} =(\\mathbf{A}-s\\mathbf{I})^{-1} \\mathbf{v}. The discussion above also proves the third part of the theorem.\n\nConsider first part 2 of the theorem with s=0, and suppose that \\mathbf{A} has a smallest eigenvalue,|\\lambda_n| \\ge |\\lambda_{n-1}| \\ge \\cdots > |\\lambda_1|.\n\nThen clearly|\\lambda_1^{-1}| > |\\lambda_{2}^{-1}| \\ge \\cdots \\ge |\\lambda_n^{-1}|,\n\nand \\mathbf{A}^{-1} has a \n\ndominant eigenvalue. Hence power iteration on \\mathbf{A}^{-1} can be used to find the eigenvalue of \\mathbf{A} closest to zero. For nonzero values of s, then we suppose there is an ordering|\\lambda_n-s| \\ge \\cdots \\ge |\\lambda_2-s|  > |\\lambda_1-s|.\n\nThen it follows that|\\lambda_1-s|^{-1} > |\\lambda_{2}-s|^{-1} \\ge \\cdots \\ge |\\lambda_n-s|^{-1},\n\nand power iteration on the matrix (\\mathbf{A}-s\\mathbf{I})^{-1} converges to (\\lambda_1-s)^{-1}, which is easily solved for \\lambda_1 itself.","type":"content","url":"/inviter","position":1},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Algorithm"},"type":"lvl2","url":"/inviter#algorithm","position":2},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Algorithm"},"content":"A literal application of \n\nAlgorithm 8.2.1 would include the step\\mathbf{y}_k = (\\mathbf{A}-s\\mathbf{I})^{-1} \\mathbf{x}_k.\n\nAs always, we do not want to explicitly find the inverse of a matrix. Instead we should write this step as the solution of a linear system.\n\nInverse iteration\n\nGiven matrix \\mathbf{A} and shift s:\n\nChoose \\mathbf{x}_1.\n\nFor k=1,2,\\ldots,\n\na. Solve for \\mathbf{y}_k in(\\mathbf{A}-s\\mathbf{I}) \\mathbf{y}_k =\\mathbf{x}_k .\n\nb. Find m such that |y_{k,m}|=\\|{\\mathbf{y}_k} \\|_\\infty.\n\nc. Set \\alpha_k = \\dfrac{1}{y_{k,m}} and \\,\\beta_k = s + \\dfrac{x_{k,m}}{y_{k,m}}.\n\nd. Set \\mathbf{x}_{k+1} = \\alpha_k \\mathbf{y}_k.\n\nNote\n\nIn \n\nAlgorithm 8.2.1, we used y_{k,m}/x_{k,m} as an estimate of the dominant eigenvalue of \\mathbf{A}. Here, that ratio is an estimate of (\\lambda_1-s)^{-1}, and solving for \\lambda_1 gives the \\beta_k in \n\nAlgorithm 8.3.1.\n\nEach pass of inverse iteration requires the solution of a linear system of equations with the matrix \\mathbf{B}=\\mathbf{A}-s\\mathbf{I}. This solution might use methods we consider later in this chapter. Here, we use (sparse) PLU factorization and hope for the best. Since the matrix \\mathbf{B} is constant, the factorization needs to be done only once for all iterations. The details are in \n\nFunction 8.3.2.\n\ninviter\n\nInverse iteration\n\n\"\"\"\n    inviter(A, s, numiter)\n\nPerform `numiter` inverse iterations with the matrix `A` and shift\n`s`, starting from a random vector. Returns a vector of\neigenvalue estimates and the final eigenvector approximation.\n\"\"\"\nfunction inviter(A, s, numiter)\n    n = size(A, 1)\n    x = normalize(randn(n), Inf)\n    β = zeros(numiter)\n    fact = lu(A - s * I)\n    for k in 1:numiter\n        y = fact \\ x\n        normy, m = findmax(abs.(y))\n        β[k] = x[m] / y[m] + s\n        x = y / y[m]\n    end\n    return β, x\nend\n\nInverse iteration\n\nfunction [beta, x] = inviter(A, s, numiter)\r\n% INVITER   Shifted inverse iteration for the closest eigenvalue.\r\n% Input:\r\n%   A         square matrix\r\n%   s         value close to targeted eigenvalue (complex scalar)\r\n%   numiter   number of iterations\r\n% Output: \r\n%   beta      sequence of eigenvalue approximations (vector)\r\n%   x         final eigenvector approximation\r\n\r\nn = length(A);\r\nx = randn(n, 1);\r\nx = x / norm(x, inf);\r\nB = A - s*eye(n);\r\n[L,U] = lu(B);\r\nfor k = 1:numiter\r\n    y = U \\ (L\\x);\r\n    [normy, m] = max(abs(y));\r\n    beta(k) = (x(m) / y(m)) + s;\r\n    x = y / y(m);\r\nend \n\nInverse iteration\n\ndef inviter(A, s, numiter):\n    \"\"\"\n    inviter(A, s, numiter)\n\n    Perform numiter inverse iterations with the matrix A and shift s, starting\n    from a random vector, and return a vector of eigenvalue estimates and the final\n    eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    PL, U = lu(A - s * np.eye(n), permute_l=True)\n    for k in range(numiter):\n        y = np.linalg.solve(U, np.linalg.solve(PL, x))\n        m = np.argmax(abs(y))\n        gamma[k] = x[m] / y[m] + s\n        x = y / y[m]\n\n    return gamma, x","type":"content","url":"/inviter#algorithm","position":3},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Convergence"},"type":"lvl2","url":"/inviter#convergence","position":4},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Convergence"},"content":"The convergence is linear, at a rate found by reinterpreting \n\n(8.2.10) with (\\mathbf{A}-s\\mathbf{I})^{-1} in place of \\mathbf{A}:\\frac{\\beta_{k+1} - \\lambda_1}{\\beta_{k} - \\lambda_1} \\rightarrow\n\\frac{  \\lambda_1 - s } {\\lambda_2 - s}\\quad \\text{ as } \\quad k\\rightarrow \\infty,\n\nwith the eigenvalues ordered as in \n\n(8.3.3). Thus, the convergence is best when the shift s is close to the target eigenvalue \\lambda_1, specifically when it is much closer to that eigenvalue than to any other.\n\nConvergence of inverse iteration\n\nExample 8.3.1\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run inverse iteration with the shift s=0.7 and take the final estimate as our “exact” answer to observe the convergence.\n\ns = 0.7\nβ, x = FNC.inviter(A, s, 30)\neigval = β[end]\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nusing Plots\nerr = @. abs(eigval - β)\nplot(0:28, err[1:end-1];\n    m=:o,  xlabel=L\"k\", \n    yaxis=(L\"|\\lambda_3-\\beta_k|\", :log10, [1e-16, 1]),\n    title=\"Convergence of inverse iteration\")\n\nThe observed linear convergence rate is found from the data.\n\n@show observed_rate = err[22] / err[21];\n\nWe reorder the eigenvalues to enforce \n\n(8.3.3).\n\nTip\n\nThe sortperm function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nλ = λ[sortperm(abs.(λ .- s))]\n\nHence the theoretical convergence rate is\n\n@show theoretical_rate = (λ[1] - s) / (λ[2] - s);\n\nExample 8.3.1\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nev = [1, -0.75, 0.6, -0.4, 0];\nA = triu(ones(5, 5), 1) + diag(ev);\n\nWe run inverse iteration with the shift s=0.7. The result should converge to the eigenvalue closest to 0.7, which we know to be 0.6 here.\n\ns = 0.7;\n[beta, x] = inviter(A, s, 30);\nformat short\nbeta(1:10)\n\nThe convergence is again linear.\n\nerr = abs(0.6 - beta);\nsemilogy(abs(err),'.-')\ntitle('Convergence of inverse iteration')\nxlabel('k'), ylabel(('|\\lambda_j - \\beta_k|'));\n\nLet’s reorder the eigenvalues to enforce \n\n(8.3.3).\n\nTip\n\nThe second output of sort returns the index permutation needed to sort the given vector.\n\n[~, idx] = sort(abs(ev - s));\nev = ev(idx)\n\nNow it is easy to compare the theoretical and observed linear convergence rates.\n\ntheoretical_rate = (ev(1) - s) / (ev(2) - s)\nobserved_rate = err(26) / err(25)\n\nExample 8.3.1\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run inverse iteration with the shift s=0.7. Convergence should be to the eigenvalue closest to the shift, which we know to be 0.6 here.\n\nbeta, x = FNC.inviter(A, 0.7, 30)\nprint(beta)\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nerr = beta[-1] - beta    # last estimate is our best\nsemilogy(arange(30), abs(err), \"-o\")\nylim(1e-16, 1)\nxlabel(\"$k$\"),  ylabel(\"$|\\\\lambda_3 - \\\\beta_k|$\")\ntitle((\"Convergence of inverse iteration\"));\n\nLet’s reorder the eigenvalues to enforce \n\n(8.3.3).\n\nTip\n\nThe argsort function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nev = ev[argsort(abs(ev - 0.7))]\nprint(ev)\n\nNow it is easy to compare the theoretical and observed linear convergence rates.\n\nprint(f\"theory: {(ev[0] - 0.7) / (ev[1] - 0.7):.5f}\")\nprint(f\"observed: {err[21] / err[20]:.5f}\")","type":"content","url":"/inviter#convergence","position":5},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Dynamic shifting"},"type":"lvl2","url":"/inviter#dynamic-shifting","position":6},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Dynamic shifting"},"content":"There is a clear opportunity for positive feedback in \n\nAlgorithm 8.3.1. The convergence rate of inverse iteration improves as the shift gets closer to the true eigenvalue—and the algorithm computes improving eigenvalue estimates! If we update the shift to s=\\beta_k after each iteration, the convergence accelerates. You are asked to implement this algorithm in \n\nExercise 6.\n\nLet’s analyze the resulting convergence. If the eigenvalues are ordered by distance to s, then the convergence is linear with rate |\\lambda_1-s|/|\\lambda_2-s|. As s\\to\\lambda_1, the change in the denominator is negligible. So if the error (\\lambda_1-s) is ε, then the error in the next estimate is reduced by a factor O(\\epsilon). That is, ε becomes O(\\epsilon^2), which is quadratic convergence.\n\nDynamic shift strategy\n\nExample 8.3.2\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\ns = 0.7\nx = ones(5)\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = β\nx = y / y[1]\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in 1:4\n    s = β\n    x = y / y[1]\n    y = (A - s * I) \\ x\n    @show β = x[1] / y[1] + s\nend\n\nExample 8.3.2\n\nev = [1, -0.75, 0.6, -0.4, 0];\nA = triu(ones(5, 5), 1) + diag(ev);\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\ns = 0.7;\nx = ones(5, 1);\ny = (A - s * eye(5)) \\ x;\nbeta = x(1) / y(1) + s\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = beta;\nx = y / y(1);\ny = (A - s * eye(5)) \\ x;\nbeta = x(1) / y(1) + s\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nformat long\nfor k = 1:4\n    s = beta;\n    x = y / y(1);\n    y = (A - s * eye(5)) \\ x;\n    beta = x(1) / y(1) + s\nend\n\nExample 8.3.2\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\nfrom numpy.linalg import solve\ns = 0.7\nx = ones(5)\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = beta\nx = y / y[0]\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in range(4):\n    s = beta\n    x = y / y[0]\n    y = solve(A - s * eye(5), x)\n    beta = x[0] / y[0] + s\n    print(f\"latest estimate: {beta:.12f}\")\n\nThere is a price to pay for this improvement. The matrix of the linear system to be solved, (\\mathbf{A}-s\\mathbf{I}), now changes with each iteration. That means that we can no longer do just one LU factorization for the entire iteration. The speedup in convergence usually makes this tradeoff worthwhile, however.\n\nIn practice power and inverse iteration are not as effective as the algorithms used by eigs and based on the mathematics described in the rest of this chapter. However, inverse iteration can be useful for turning an eigenvalue estimate into an eigenvector estimate.","type":"content","url":"/inviter#dynamic-shifting","position":7},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Exercises"},"type":"lvl2","url":"/inviter#exercises","position":8},{"hierarchy":{"lvl1":"Inverse iteration","lvl2":"Exercises"},"content":"⌨  Use \n\nFunction 8.3.2 to perform 10 iterations for the given matrix and shift. Compare the results quantitatively to the convergence given by \n\n(8.3.7).\n\n(a)  \\mathbf{A} = \\begin{bmatrix}\n     1.1 & 1 \\\\\n     0 & 2.1\n   \\end{bmatrix}, \\; s = 1 \\qquad \n(b) \\mathbf{A} = \\begin{bmatrix}\n     1.1 & 1 \\\\\n     0 & 2.1\n   \\end{bmatrix}, \\; s = 2\\qquad \n\n(c) \\mathbf{A} = \\begin{bmatrix}\n     1.1 & 1 \\\\\n     0 & 2.1\n   \\end{bmatrix}, \\; s = 1.6\\qquad \n(d) \\mathbf{A} = \\begin{bmatrix}\n     2 & 1 \\\\\n     1 & 0\n   \\end{bmatrix}, \\; s = -0.33 \\qquad\n\n(e) \\mathbf{A} = \\begin{bmatrix}\n   6 & 5 & 4 \\\\\n   5 & 4 & 3 \\\\\n   4 & 3 & 2\n \\end{bmatrix}, \\;  s = 0.1 \n\n✍ Let \\mathbf{A} = \\displaystyle \\begin{bmatrix} 1.1 & 1 \\\\ 0 & 2.1 \\end{bmatrix}. Given the starting vector \\mathbf{x}_1=[1,1], find the vector \\mathbf{x}_2 for the following shifts.\n\n(a) s=1\\quad (b) s=2\\quad (c) s=1.6\n\n✍ Why is it a bad idea to use unshifted inverse iteration with the matrix \\displaystyle \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}? Does the shift s=-1 improve matters?\n\n✍ When the shift s is very close to an eigenvalue of \\mathbf{A}, the matrix \\mathbf{A}-s\\mathbf{I} is close to a singular matrix. But then \n\n(8.3.6) is a linear system with a badly conditioned matrix, which should create a lot of error in the numerical solution for \\mathbf{y}_k. However, it happens that the error is mostly in the direction of the eigenvector we are looking for, as the following toy example illustrates.\n\nProve that \\displaystyle \\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix} has an eigenvalue at zero with associated eigenvector \\mathbf{v}=[-1,1]^T. Suppose this matrix is perturbed slightly to \\displaystyle \\mathbf{A} = \\begin{bmatrix} 1 & 1 \\\\ 0 & \\epsilon \\end{bmatrix}, and that \\mathbf{x}_k=[1,1] in \n\n(8.3.6). Show that once \\mathbf{y}_k is normalized by its infinity norm, the result is within ε of a multiple of \\mathbf{v}.must stay as #5\n\n⌨ (Continuation of \n\nExercise 8.2.3.) This exercise concerns the n^2\\times n^2 sparse matrix defined by FNC.poisson(n) for integer n. It represents a lumped model of a vibrating square membrane held fixed around the edges.\n\n(a) The eigenvalues of \\mathbf{A} closest to zero are approximately squares of the frequencies of vibration for the membrane. Using eigs, find the eigenvalue \\lambda_m closest to zero for n=10,15,20,25.\n\n(b) For each n in part (a), apply 50 steps of \n\nFunction 8.3.2 with zero shift. On one graph, plot the four convergence curves |\\beta_k-\\lambda_m| using a semi-log scale.\n\n(c) Let v be the eigenvector (second output) found by \n\nFunction 8.3.2 for n=25. Make a surface plot of the vibration mode by reshaping v into an n\\times n matrix.must remain as number 6\n\n⌨ This problem explores the use of dynamic shifting to accelerate the inverse iteration.\n\n(a) Modify \n\nFunction 8.3.2 to change the value of the shift s to be the most recently computed value in the vector β. Note that the matrix B must also change with each iteration, and the LU factorization cannot be done just once.\n\n(b) Define a 100\\times 100 matrix with values k^2 for k=1,\\ldots,100 on the main diagonal and random values uniformly distributed between 0 and 1 on the first superdiagonal. (Since this matrix is triangular, the diagonal values are its eigenvalues.) Using an initial shift of s=920, apply the dynamic inverse iteration. Determine which eigenvalue was found and make a table of the log10 of the errors in the iteration as a function of iteration number. (These should approximately double, until machine precision is reached, due to quadratic convergence.)\n\n(c) Repeat part (b) using a different initial shift of your choice.","type":"content","url":"/inviter#exercises","position":9},{"hierarchy":{"lvl1":"Matrix-free iterations"},"type":"lvl1","url":"/matrixfree","position":0},{"hierarchy":{"lvl1":"Matrix-free iterations"},"content":"A primary reason for our interest in matrices is their relationship to linear transformations. If we define \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x}, then for all vectors \\mathbf{x}, \\mathbf{y}, and scalars α,\\begin{split}\n\\mathbf{f}(\\mathbf{x} + \\mathbf{y} ) &= \\mathbf{f}(\\mathbf{x}) + \\mathbf{f}(\\mathbf{y} ), \\\\\n\\mathbf{f}(\\alpha \\mathbf{x} ) & = \\alpha\\, \\mathbf{f}(\\mathbf{x}).\n\\end{split}\n\nThese properties define a linear transformation. Moreover, every linear transformation between finite-dimensional vector spaces can be represented as a matrix-vector multiplication.","type":"content","url":"/matrixfree","position":1},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Matrix-free iterations"},"type":"lvl2","url":"/matrixfree#matrix-free-iterations","position":2},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Matrix-free iterations"},"content":"In Chapter 4 we solved the nonlinear rootfinding problem \\mathbf{f}(\\mathbf{x})=\\boldsymbol{0} with methods that needed only the ability to evaluate \\mathbf{f} at any known value of \\mathbf{x}. By repeatedly evaluating \\mathbf{f} at cleverly chosen points, these algorithms were able to return an estimate for \\mathbf{f}^{-1}(\\boldsymbol{0}).\n\nA close examination reveals that the power method and Krylov subspace methods have the same structure because the only appearance of the matrix \\mathbf{A} in them is to multiply a known vector, i.e., to evaluate \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x}. This is used to evaluate the inverse, \\mathbf{A}^{-1}\\mathbf{b}.\n\nBringing these points of view together leads us to a cornerstone of modern scientific computation: matrix-free iterations. Krylov subspace methods can be used to invert a linear transformation if one provides code for the transformation, even if its associated matrix is not known explicitly.","type":"content","url":"/matrixfree#matrix-free-iterations","position":3},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Blurring images"},"type":"lvl2","url":"/matrixfree#blurring-images","position":4},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Blurring images"},"content":"In \n\nFrom matrix to insight we saw that a grayscale image can be represented as an m\\times n matrix \\mathbf{X} of pixel intensity values. Now consider a simple model for blurring the image. Define \\mathbf{B} as the m\\times m tridiagonal matrixB_{ij} =\n\\begin{cases}\n\\tfrac{1}{2} & \\text{if $i=j$},\\\\\n\\tfrac{1}{4} & \\text{if $|i-j|=1$},\\\\\n0 & \\text{otherwise.}\n\\end{cases}\n\nThe product \\mathbf{B}\\mathbf{X} applies \\mathbf{B} to each column of \\mathbf{X}. Within that column it does a weighted average of the values of each pixel and its two neighbors. That has the effect of blurring the image vertically. We can increase the amount of blur by applying \\mathbf{B} repeatedly.\n\nIn order to blur horizontally, we can transpose the image and apply blurring in the same way. We need a blurring matrix defined as in \n\n(8.7.2) but with size n\\times n. We call this matrix \\mathbf{C}. Altogether the horizontal blurring is done by transposing, applying \\mathbf{C}, and transposing back to the original orientation. That is,\\bigl(\\mathbf{C} \\mathbf{X}^T\\bigr)^T = \\mathbf{X}\\mathbf{C}^T = \\mathbf{X}\\mathbf{C},\n\nusing the symmetry of \\mathbf{C}. So we can describe blur in both directions as the function\\operatorname{blur}(\\mathbf{X}) = \\mathbf{B}^k \\mathbf{X} \\mathbf{C}^k\n\nfor a positive integer k.\n\nBlurring an image\n\nExample 8.7.1\n\nWe use a readily available test image.\n\nusing Images, TestImages\nimg = testimage(\"mandrill\")\nm, n = size(img)\nX = @. Float64(Gray(img))\nplot(Gray.(X), title=\"Original image\", aspect_ratio=1)\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nusing SparseArrays\nfunction blurmatrix(d)\n    v1 = fill(0.25, d - 1)\n    return spdiagm(0 => fill(0.5, d), 1 => v1, -1 => v1)\nend\nB, C = blurmatrix(m), blurmatrix(n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nusing Plots\nblur = X -> B^12 * X * C^12;\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nExample 8.7.1\n\nWe use a readily available test image.\n\nload mandrill\n[m, n] = size(X);\nclf\nimshow(X, [0, 255])\ntitle('Original image')    % ignore this\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nv = [1/4, 1/2, 1/4];\nB = spdiags(v, -1:1, m, m);\nC = spdiags(v, -1:1, n, n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nblur = @(X) B^12 * X * C^12;\nimshow(blur(X), [0, 255])\ntitle(('Blurred image'));\n\nExample 8.7.1\n\nWe use a readily available test image.\n\nfrom skimage import data as testimages\nfrom skimage.color import rgb2gray\nimg = getattr(testimages, \"coffee\")()\nX = rgb2gray(img)\nimshow(X, cmap=\"gray\");\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nimport scipy.sparse as sp\ndef blurmatrix(d):\n    data = [[0.25] * (d-1), [0.5] * d, [0.25] * (d-1)]\n    return sp.diags(data, [-1, 0, 1], shape=(d, d))\n\nm, n = X.shape\nB = blurmatrix(m)\nC = blurmatrix(n)\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nfrom scipy.sparse.linalg import matrix_power\nblur = lambda X: matrix_power(B, 12) @ X @ matrix_power(C, 12)\n\nimshow(blur(X), cmap=\"gray\")\ntitle(\"Blurred image\");","type":"content","url":"/matrixfree#blurring-images","position":5},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Deblurring"},"type":"lvl2","url":"/matrixfree#deblurring","position":6},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Deblurring"},"content":"A more interesting operation is deblurring: given an image blurred by poor focus, can we reconstruct the true image? Conceptually, we want to invert the function \\operatorname{blur}(\\mathbf{X}).\n\nIt’s easy to see from \n\n(8.7.4) that the blur operation is a linear transformation on image matrices. But an m\\times n image matrix is equivalent to a length-mn vector—it’s just a matter of interpreting the shape of the same data. Let \\operatorname{vec}(\\mathbf{X})=\\mathbf{x} and \\operatorname{unvec}(\\mathbf{x})=\\mathbf{X} be the mathematical statements of such reshaping operations. Now say \\mathbf{X} is the original image and \\mathbf{Z}=\\operatorname{blur}(\\mathbf{X}) is the blurred one. Then by linearity there is some matrix \\mathbf{A} such that\\mathbf{A} \\operatorname{vec}(\\mathbf{X}) = \\operatorname{vec}(\\mathbf{Z}),\n\nor \\mathbf{A}\\mathbf{x}=\\mathbf{z}.\n\nThe matrix \\mathbf{A} is mn\\times mn; for a 12-megapixel image, it would have 1.4\\times 10^{14} entries! Admittedly, it is extremely sparse, but the point is that we don’t need it at all.\n\nInstead, given any vector \\mathbf{u} we can compute \\mathbf{v}=\\mathbf{A}\\mathbf{u} through the steps\\begin{align*}\n  \\mathbf{U} &= \\operatorname{unvec}(\\mathbf{u}),\\\\\n  \\mathbf{V} &= \\operatorname{blur}(\\mathbf{U}),\\\\\n  \\mathbf{v} &= \\operatorname{vec}(\\mathbf{V}).\n\\end{align*}\n\nThe following example shows how to put these ideas into practice with MINRES.\n\nDeblurring an image\n\nExample 8.7.2\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = testimage(\"lighthouse\")\nm, n = size(img)\nX = @. Float64(Gray(img))\n\nB = spdiagm(0 => fill(0.5, m),\n    1 => fill(0.25, m - 1), -1 => fill(0.25, m - 1))\nC = spdiagm(0 => fill(0.5, n),\n    1 => fill(0.25, n - 1), -1 => fill(0.25, n - 1))\nblur = X -> B^12 * X * C^12\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\n# vec (built-in) converts matrix to vector\nunvec = z -> reshape(z, m, n);  # convert vector to matrix\n\nNow we declare the three-step blur transformation as a LinearMap, supplying also the size of the vector form of an image.\n\nusing LinearMaps\nT = LinearMap(x -> vec(blur(unvec(x))), m * n);\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nTip\n\nThe function clamp01 in Images restricts values to be in the interval [0,1].\n\nusing IterativeSolvers\ny = minres(T, vec(Z), maxiter=50, reltol=1e-5);\nY = unvec(clamp01.(y))\n\nplot(Gray.(X), layout=2, title=\"Original\")\nplot!(Gray.(Y), subplot=2, title=\"Deblurred\")\n\nExample 8.7.2\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nload mandrill\n[m, n] = size(X);\nv = [1/4, 1/2, 1/4];\nB = spdiags(v, -1:1, m, m);\nC = spdiags(v, -1:1, n, n);\nblur = @(X) B^12 * X * C^12;\n\nZ = blur(X);\nclf,  imshow(Z, [0, 255])\ntitle((\"Blurred image\"));\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\nvec = @(X) reshape(X,m*n,1);\nunvec = @(x) reshape(x,m,n);\nT = @(x) vec( blur(unvec(x)) );\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\ny = gmres(T, vec(Z), 50, 1e-5);\nY = unvec(y);\n\nsubplot(121)\nimshow(X, [0, 255])\ntitle(\"Original\")\nsubplot(122)\nimshow(Y, [0, 255])\ntitle((\"Deblurred\"));\n\nExample 8.7.2\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = getattr(testimages, \"coffee\")()\nX = rgb2gray(img)\nm, n = X.shape\n\nimport scipy.sparse as sp\ndef blurmatrix(d):\n    data = [[0.25] * (d-1), [0.5] * d, [0.25] * (d-1)]\n    return sp.diags(data, [-1, 0, 1], shape=(d, d))\nB = blurmatrix(m)\nC = blurmatrix(n)\n\nfrom scipy.sparse.linalg import matrix_power\nblur = lambda X: matrix_power(B, 12) @ X @ matrix_power(C, 12)\n\nZ = blur(X)\nimshow(Z, cmap=\"gray\")\ntitle(\"Blurred image\");\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\nfrom scipy.sparse.linalg import LinearOperator\nvec = lambda Z: Z.reshape(m * n)\nunvec = lambda z: z.reshape(m, n)\nxform = lambda x: vec(blur(unvec(x)))\n\nNow we declare the three-step blur transformation as a LinearOperator, supplying also the size of the vector form of an image.\n\nT = LinearOperator((m * n, m * n), matvec=xform)\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nfrom scipy.sparse.linalg import gmres\ny, flag = gmres(T, vec(Z), rtol=1e-5, maxiter=50)\nY = unvec(maximum(0, minimum(1, y)))\n\n\nsubplot(1, 2, 1),  imshow(X, cmap=\"gray\")\naxis(\"off\"),  title(\"Original\")\nsubplot(1, 2, 2),  imshow(Y, cmap=\"gray\")\naxis(\"off\"),  title(\"Deblurred\");","type":"content","url":"/matrixfree#deblurring","position":7},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Exercises"},"type":"lvl2","url":"/matrixfree#exercises","position":8},{"hierarchy":{"lvl1":"Matrix-free iterations","lvl2":"Exercises"},"content":"✍ Show using \n\n(8.7.1) and \n\n(8.7.4) that the blur operation is a linear transformation.\n\n✍ In each case, state with reasons whether the given transformation on n-vectors is linear.\n\n(a) \\,\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_2\\\\x_3 \\\\\\vdots\\\\ x_n \\\\ x_1 \\end{bmatrix}\\qquad\n(b) \\,\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_1\\\\x_1+x_2\\\\x_1+x_2+x_3\\\\\\vdots\\\\x_1+\\cdots+x_n \\end{bmatrix} \\qquad\n(c) \\,\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_1 + 1 \\\\x_2 + 2 \\\\ x_3 + 3 \\\\\\vdots \\\\ x_n+n \\end{bmatrix} \\qquad\n(d) \\,\\mathbf{f}(\\mathbf{x}) = \\|\\mathbf{x}\\|_\\infty\\, \\mathbf{e}_1\n\n✍ Suppose that code for the linear transformation \\mathbf{f}(\\mathbf{x})=\\mathbf{A}\\mathbf{x} is given for an unknown matrix \\mathbf{A}. Explain carefully how one could construct \\mathbf{A}.\n\n⌨ The matrix of the blur transformation happens to be symmetric and positive definite. Repeat \n\nDemo 8.7.2 using CG for the deblurring.\n\nThe condition number of the matrix of the blur transformation is related to the condition numbers of the single-dimension matrices \\mathbf{B}^k and \\mathbf{C}^k in \n\n(8.7.4).\n\n(a) ⌨  Let m=50. Show that \\mathbf{B} has a Cholesky factorization and thus is SPD. Find \\kappa(\\mathbf{B}). (Note: cond requires a regular dense matrix, not a sparse matrix.)\n\n(b) ✍ Explain why part (a) implies \\kappa( \\mathbf{B}^k ) = \\kappa(\\mathbf{B})^k.\n\n(c) ✍ Explain two important effects of the limit k\\to \\infty on deblurring by Krylov methods.\n\nThe cumulative summation function cumsum is defined as\\mathbf{f}(\\mathbf{x}) = \\begin{bmatrix} x_1 \\\\ x_1+x_2 \\\\ \\vdots \\\\ x_1 + x_2 + \\cdots + x_n \\end{bmatrix}.\n\n(a) ✍ Show that \\mathbf{f} is a linear transformation.\n\n(b) ⌨ Define vector \\mathbf{b} by b_i = (i/100)^2 for i=1,\\ldots,100. Then use gmres to find \\mathbf{x}=\\mathbf{f}^{-1}(\\mathbf{b}).\n\n(c) ⌨ Plot \\mathbf{x}, and explain why the result looks as it does.","type":"content","url":"/matrixfree#exercises","position":9},{"hierarchy":{"lvl1":"MINRES and conjugate gradients"},"type":"lvl1","url":"/minrescg","position":0},{"hierarchy":{"lvl1":"MINRES and conjugate gradients"},"content":"We have seen before that certain matrix properties enhance solutions to linear algebra problems. One of the most important of these is when \\mathbf{A}^*=\\mathbf{A}; i.e., \\mathbf{A} is hermitian. The Arnoldi iteration has a particularly useful specialization to this case. While in this section we describe the resulting algorithms, we do not present them in detail or show implementations.","type":"content","url":"/minrescg","position":1},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Lanczos iteration"},"type":"lvl2","url":"/minrescg#lanczos-iteration","position":2},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Lanczos iteration"},"content":"Starting from \n\n(8.4.10), we left-multiply by \\mathbf{Q}_m^* to get\\mathbf{Q}_m^* \\mathbf{A} \\mathbf{Q}_m = \\mathbf{Q}_m^* \\mathbf{Q}_{m+1} \\mathbf{H}_m = \\tilde{\\mathbf{H}}_m,\n\nwhere \\tilde{\\mathbf{H}}_m is rows 1 through m of \\mathbf{H}_m. If \\mathbf{A} is hermitian, then so is the left side of this equation, hence \\tilde{\\mathbf{H}}_m is hermitian too. But it is also upper Hessenberg, meaning that the (i,j) element is zero if i > j+1. By symmetry, this means that elements are zero when j > i+1 as well.\n\nFor a hermitian (or real symmetric) matrix, the upper Hessenberg matrix \\mathbf{H}_m produced by the Arnoldi iteration is tridiagonal.\n\nEquation \n\n(8.4.6) of the Arnoldi iteration now simplifies to a much shorter expression:\\mathbf{A} \\mathbf{q}_m = H_{m-1,m} \\,\\mathbf{q}_{m-1} + H_{mm} \\,\\mathbf{q}_m + H_{m+1,m}\\,\\mathbf{q}_{m+1}.\n\nAs before in deriving the Arnoldi iteration, when given the first m vectors we can solve for the entries in column m of \\mathbf{H} and then for \\mathbf{q}_{m+1}. The resulting process is known as the Lanczos iteration. Its most important practical advantage is that while Arnoldi needs O(m) steps to get \\mathbf{q}_{m+1} from the previous vectors, Lanczos needs only O(1) steps, so restarting isn’t required for symmetric matrices.","type":"content","url":"/minrescg#lanczos-iteration","position":3},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"MINRES"},"type":"lvl2","url":"/minrescg#minres","position":4},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"MINRES"},"content":"When \\mathbf{A} is hermitian and the Arnoldi iteration is reduced to Lanczos, the analog of GMRES is known as MINRES. Like GMRES, MINRES minimizes the residual \\|\\mathbf{b}-\\mathbf{A}\\mathbf{x}\\| over increasingly larger Krylov spaces.\n\nMINRES is also more theoretically tractable than GMRES. The following result relies on some advanced approximation theory. Recall that the eigenvalues of a hermitian matrix are real.\n\nConvergence of MINRES (indefinite case)\n\nSuppose \\mathbf{A} is hermitian, invertible, and indefinite. Divide its eigenvalues into positive and negative sets \\Lambda_+ and \\Lambda_-, and define\\kappa_+ = \\frac{ \\max_{\\lambda \\in \\Lambda_+}  |\\lambda| }{ \\min_{\\lambda \\in \\Lambda_+}  |\\lambda| }, \\qquad\n\\kappa_- = \\frac{ \\max_{\\lambda \\in \\Lambda_-}  |\\lambda| }{ \\min_{\\lambda \\in \\Lambda_-}  |\\lambda| }.\n\nThen \\mathbf{x}_m, the mth solution estimate of MINRES, satisfies\\frac{\\|\\mathbf{r}_m\\|_2}{\\|\\mathbf{b}\\|_2} \\le  \\left( \\frac{\\sqrt{\\kappa_+\\kappa_-} - 1}{\\sqrt{\\kappa_+\\kappa_-} + 1} \\right)^{\\lfloor m/2\\rfloor},\n\nwhere \\lfloor m/2\\rfloor means to round m/2 down to the nearest integer.\n\nThe bound for a definite matrix is better, as the next theorem shows. The upper bound \n\n(8.6.4) on the residual obeys a linear convergence rate. As the product \\kappa_+\\kappa_- grows, the rate of this convergence approaches 1. Hence the presence of eigenvalues close to the origin (relative to the max eigenvalues) is expected to force a slower convergence.\n\nSuppose \\mathbf{A} has \\kappa_+=60 and \\kappa_-=15. Then to achieve a guaranteed reduction in the relative residual of \n\n10-3, we require\\left( \\frac{\\sqrt{900} - 1}{\\sqrt{900} + 1} \\right)^{\\lfloor m/2\\rfloor} \\le 10^{-3},{\\lfloor m/2\\rfloor} \\log_{10} \\left( \\frac{29}{31} \\right) \\le -3,m  \\ge  2 \\lceil \\frac{3}{\\log_{10}(29/31)} \\rceil = 208.\n\nBecause the theorem gives an upper bound, MINRES may converge faster. All we can say is that 208 is certain to be enough iterations.\n\nMINRES\n\nExample 8.6.2\n\nThe following matrix is indefinite.\n\nA = FNC.poisson(10) - 20I\nλ = eigvals(Matrix(A))\nisneg = @. λ < 0\n@show sum(isneg), sum(.!isneg);\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nmn, mx = extrema(-λ[isneg])\nκ₋ = mx / mn\nmn, mx = extrema(λ[.!isneg])\nκ₊ = mx / mn\nρ = (sqrt(κ₋ * κ₊) - 1) / (sqrt(κ₋ * κ₊) + 1)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nusing IterativeSolvers, Plots\nb = rand(100)\nx, hist = minres(A, b, reltol=1e-10, maxiter=51, log=true);\nrelres = hist[:resnorm] / norm(b)\nm = 0:length(relres)-1\nplot(m, relres;\n    label=\"observed\", legend=:left,\n    xaxis=L\"m\",  yaxis=(:log10, \"relative residual\"),\n    title=(\"Convergence of MINRES\"))\nplot!(m, ρ .^ (m / 2), l=:dash, label=\"upper bound\")\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nExample 8.6.2\n\nThe following matrix is indefinite.\n\nA = (11 / pi)^2 * gallery('poisson', 10);\nA = A - 20 * eye(100);\nlambda = eig(full(A));\nisneg = lambda < 0;\ndisp(sprintf(\"%d negative and %d positive eigenvalues\", sum(isneg), sum(~isneg)))\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nm = min(-lambda(isneg));\nM = max(-lambda(isneg));\nkappa_minus = M / m;\nm = min(lambda(~isneg));\nM = max(lambda(~isneg));\nkappa_plus = M / m;\nS = sqrt(kappa_minus * kappa_plus);\nrho = sqrt((S - 1) / (S + 1));\nfprintf(\"convergence rate: %.3f\", rho)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nb = rand(100, 1);\n[xMR, ~,~ , ~, residMR] = minres(A, b, 1e-10, 100);\nrelres = residMR / norm(b);\nm = 0:length(relres) - 1;\nclf,  semilogy(m, relres, '.-')\nhold on\nsemilogy(m, rho .^ m, 'k--')\nxlabel('m'),  ylabel('relative residual') \ntitle('Convergence of MINRES') \nlegend('MINRES', 'upper bound', 'location', 'southwest');\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nExample 8.6.2\n\nThe following matrix is indefinite.\n\nfrom numpy.linalg import eig\nimport scipy.sparse as sp\nA = FNC.poisson2d(10) - 20*sp.eye(100)\nev, _ = eig(A.todense())\nnum_negative_ev = sum(ev < 0)\nprint(f\"There are {sum(ev < 0)} negative and {sum(ev > 0)} positive eigenvalues\")\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nm, M = min(-ev[ev < 0]), max(-ev[ev < 0])\nkappa_minus = M / m\nm, M = min(ev[ev > 0]), max(ev[ev > 0])\nkappa_plus = M / m\nS = sqrt(kappa_plus * kappa_minus)\nrho = sqrt((S - 1) / (S + 1))\nprint(f\"Condition numbers: {kappa_minus:.2e}, {kappa_plus:.2e}\")\nprint(f\"Convergence rate: {rho:.3f}\")\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nfrom scipy.sparse.linalg import minres\nb = random.rand(100)\nresid = [norm(b)]\nhist = lambda x: resid.append(norm(b - A @ x))\nx, flag = minres(A, b, rtol=1e-8, maxiter=1000, callback=hist)\n\nsemilogy(resid, \".-\");\nupper = norm(b) * rho**arange(len(resid))\nsemilogy(upper, \"k--\")\nxlabel(\"$m$\"),  ylabel(\"residual norm\")\nlegend([\"MINRES\", \"upper bound\"], loc=\"lower left\")\ntitle(\"Convergence of MINRES\");\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.","type":"content","url":"/minrescg#minres","position":5},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Conjugate gradients"},"type":"lvl2","url":"/minrescg#conjugate-gradients","position":6},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Conjugate gradients"},"content":"Given positive definiteness in addition to symmetry, we arrive at perhaps the most famous Krylov subspace method for \\mathbf{A}\\mathbf{x}=\\mathbf{b}, called conjugate gradients.\n\nSuppose now that \\mathbf{A} is hermitian and positive definite (HPD). Then \\mathbf{A} has a Cholesky factorization, which in the complex case is \\mathbf{A}=\\mathbf{R}^*\\mathbf{R}. Therefore, for any vector \\mathbf{u},\\mathbf{u}^*\\mathbf{A}\\mathbf{u} = (\\mathbf{R}\\mathbf{u})^*(\\mathbf{R}\\mathbf{u})=\\|\\mathbf{R} \\mathbf{u}\\|^2,\n\nwhich is nonnegative and zero only when \\mathbf{u}=\\boldsymbol{0}, provided \\mathbf{A} (and therefore \\mathbf{R}) is nonsingular. Hence we can define a special vector norm relative to \\mathbf{A}:\\| \\mathbf{u} \\|_{\\mathbf{A}} = \\left( \\mathbf{u}^*\\mathbf{A}\\mathbf{u} \\right)^{1/2}.\n\nMethod of conjugate gradients (CG)\n\nFor each m=1,2,3,\\ldots, minimize \\|\\mathbf{x}_m-\\mathbf{x}\\|_{\\mathbf{A}} for \\mathbf{x} in the Krylov subspace \\mathcal{K}_m.","type":"content","url":"/minrescg#conjugate-gradients","position":7},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Convergence"},"type":"lvl2","url":"/minrescg#convergence","position":8},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Convergence"},"content":"The convergence of CG and MINRES is dependent on the eigenvalues of \\mathbf{A}. In the HPD case the eigenvalues are real and positive, and they equal the singular values. Hence the condition number κ is equal to the ratio of the largest eigenvalue to the smallest one. The following theorem suggests that MINRES and CG are not so different in convergence.\n\nMINRES and CG convergence (definite case)\n\nLet \\mathbf{A} be real and SPD with 2-norm condition number κ. For MINRES define R(m)=\\|\\mathbf{r}_m\\|_2/\\|\\mathbf{b}\\|_2, and for CG define R(m)=\\|\\mathbf{x}_m-\\mathbf{x}\\|_{\\mathbf{A}}/\\|\\mathbf{x}\\|_{\\mathbf{A}},\nwhere \\mathbf{r}_m and \\mathbf{x}_m are the residual and solution approximation associated with the space \\mathcal{K}_m. ThenR(m) \\le  2\\, \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^m.\n\nTheorem 8.6.2 characterizes the convergence of MINRES and CG similarly, differing only in whether the measurement is of the residual or the \\mathbf{A}-norm of the error, respectively. While these are different quantities, in practice one may not find a consistent advantage for one method over the other.\n\nAs in the indefinite case with MINRES, a larger condition number is associated with slower convergence in the positive definite case. Specifically, to make the bound in \n\n(8.6.10) less than a number ε requires\\begin{gather*}\n  2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^m \\approx \\epsilon, \\\\\n  m \\log \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)\n  \\approx \\log\\Bigl( \\frac{\\epsilon}{2} \\Bigr).\n\\end{gather*}\n\nWe estimate\\begin{align*}\n   \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\n &=  (1 - \\kappa^{-1/2}\\,) (1 + \\kappa^{-1/2}\\,)^{-1}\\\\\n &= (1 - \\kappa^{-1/2}\\,)  (1 - \\kappa^{-1/2} + \\kappa^{-1} + \\cdots)\\\\\n &= 1 - 2\\kappa^{-1/2} + O(\\kappa^{-1}) \\quad \\text{ as $\\kappa\n   \\rightarrow \\infty$.}\n\\end{align*}\n\nWith the Taylor expansion \\log(1+x) = x - (x^2/2) + \\cdots, we finally conclude\\begin{gather*}\n  2 m \\kappa^{-1/2} \\approx \\log\\Bigl( \\frac{\\epsilon}{2} \\Bigr),\n  \\text{ or }\n  m = O(\\sqrt{\\kappa}),\n\\end{gather*}\n\nas an estimate of the number of iterations needed to achieve a fixed accuracy.\n\nAs a rule of thumb, the number of iterations required for MINRES or CG to converge is O(\\sqrt{\\kappa}), where κ is the condition number.\n\nThis estimate fails for very large κ, however.\n\nConvergence of MINRES and CG\n\nExample 8.6.3\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, 1 / 100)\nx = (1:n) / n\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from IterativeSolvers.\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"),  yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = FNC.sprandsym(n, density, 1 / 2500)\nb = A * x;\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.\n\nExample 8.6.3\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000;\ndensity = 0.001;\nA = sprandsym(n, density, 1e-2, 2);\n\nWe generate a system with a known solution.\n\nx = (1:n)' / n;\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals.\n\n[xMR, ~, ~, ~, residMR] = minres(A, b, 1e-7, 100);\n[xCG, ~, ~, ~, residCG] = pcg(A, b, 1e-7, 100);\nM = length(residMR) - 1;\nclf,  semilogy(0:M, residMR / norm(b), '.-')\nM = length(residCG) - 1;\nhold on,  semilogy(0:M, residCG / norm(b), '.-')\ntitle('Convergence of MINRES and CG')\nxlabel('Krylov dimension m')\nylabel('||r_m|| / ||b||')\nlegend('MINRES', 'CG');\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = sprandsym(n, density, 1e-2 / 25, 2);\nb = A * x;\n\n[xMR, ~, ~, ~, residMR] = minres(A, b, 1e-7, 400);\n[xCG, ~, ~, ~, residCG] = pcg(A, b, 1e-7, 400);\nM = length(residMR) - 1;\nclf,  semilogy(0:M, residMR / norm(b), '.-')\nM = length(residCG) - 1;\nhold on,  semilogy(0:M, residCG / norm(b), '.-')\ntitle('Convergence of MINRES and CG')\nxlabel('Krylov dimension m')\nylabel('||r_m|| / ||b||')\nlegend('MINRES', 'CG');\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.\n\nExample 8.6.3\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, rcond=1e-2)\nx = arange(1, n+1) / n\nb = A @ x\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from scipy.sparse.linalg.\n\nfrom scipy.sparse.linalg import cg, minres\nhist = lambda x: resid.append(norm(b - A @ x))\n\nresid = [norm(b)]\nxMR, flag = minres(A, b, rtol=1e-12, maxiter=100, callback=hist)\nsemilogy(resid / norm(b), label=\"MINRES\")\n\nresid = [norm(b)]\nxCG, flag = cg(A, b, rtol=1e-12, maxiter=100, callback=hist)\nsemilogy(resid / norm(b), label=\"CG\")\n\nxlabel(\"Krylov dimension $m$\"), ylabel(\"$\\\\|r_m\\\\| / \\\\|b\\\\|$\")\ngrid(),  legend(),  title(\"Convergence of MINRES and CG\");\n\nThere is little difference between the two methods here. Both achieve relative residual of \n\n10-6 in aout 60 iterations, for example. The final errors are similar, too.\n\nprint(f\"MINRES error: {norm(xMR - x) / norm(x):.2e}\")\nprint(f\"CG error: {norm(xCG - x) / norm(x):.2e}\")\n\nNext, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5; i.e., 300 iterations to reach \n\n10-6.\n\nA = FNC.sprandsym(n, density, rcond=1e-2 / 25)\nx = arange(1, n+1) / n\nb = A @ x\n\nfrom scipy.sparse.linalg import cg, minres\nhist = lambda x: resid.append(norm(b - A @ x))\n\nresid = [norm(b)]\nxMR, flag = minres(A, b, rtol=1e-12, maxiter=400, callback=hist)\nsemilogy(resid / norm(b), label=\"MINRES\")\n\nresid = [norm(b)]\nxCG, flag = cg(A, b, rtol=1e-12, maxiter=400, callback=hist)\nsemilogy(resid / norm(b), label=\"CG\")\n\nxlabel(\"Krylov dimension $m$\"), ylabel(\"$\\\\|r_m\\\\| / \\\\|b\\\\|$\")\ngrid(),  legend(),  title(\"Convergence of MINRES and CG\")\n\nprint(f\"MINRES error: {norm(xMR - x) / norm(x):.2e}\")\nprint(f\"CG error: {norm(xCG - x) / norm(x):.2e}\")\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation.","type":"content","url":"/minrescg#convergence","position":9},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Exercises"},"type":"lvl2","url":"/minrescg#exercises","position":10},{"hierarchy":{"lvl1":"MINRES and conjugate gradients","lvl2":"Exercises"},"content":"✍ For each part, the eigenvalues of \\mathbf{A} are given. Suppose MINRES is applied to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Use \n\n(8.6.4) or \n\n(8.6.10), whichever is most appropriate, to determine a lower bound on m to guarantee reduction of the residual norm by a factor \n\n10-4.\n\n(a) -100,-99,\\ldots,-1,1,2,\\ldots,100\n\n(b) -100,1,2,\\ldots,100\n\n(c) 1,2,\\ldots,100\n\n⌨ Let \\mathbf{b} be a random unit vector of length 202. Define a diagonal matrix with diagonal entries d_k given by\\begin{align*}\n    d_k &= -200 + 1.95k, \\quad k=0,1,\\ldots,100, \\\\\n    d_{k+101} &= 10 + 0.9k, \\quad k=0,1,\\ldots,100.\n    \\end{align*}\n\n(a)  Apply 120 iterations of MINRES to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Compute the relative error of the answer, and plot the norm of the residual as a function of m on a log-linear scale.\n\n(b) Add to your graph the line representing the upper bound \n\n(8.6.4). (Ignore the rounding in the exponent.) This line should stay strictly on or above the error curve.\n\n⌨ Let \\mathbf{b} be a random unit vector of length 501. Define a sparse diagonal matrix \\mathbf{A} with diagonal entries d_k given by\\begin{align*}\n    d_k &= 4 + k\\cdot\\frac{9996}{500}, \\quad k=0,1,\\ldots,500.\n    \\end{align*}\n\n(a) Apply 100 iterations of MINRES to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. Compute the relative norm of the answer. Plot the norm of the residual as a function of m.\n\n(b) Add to your graph the line representing the upper bound \n\n(8.6.10). This line should stay strictly on or above the convergence curve.\n\n(c) Add a convergence curve for 100 iterations of cg.\n\n✍ Suppose a family of SPD matrices \\mathbf{A} is parameterized by t, and that the condition numbers of the matrices scale like O(t^2) as t\\to\\infty. Given that CG takes 60 iterations to reach a certain reduction in the error of a linear system when t=200, estimate the number of iterations CG will need to reach the same accuracy at t=300.\n\n✍ Given real n\\times n symmetric \\mathbf{A} and vector \\mathbf{b}=\\mathbf{A}\\mathbf{x}, we can define the scalar-valued function\\varphi(\\mathbf{u}) = \\mathbf{u}^T \\mathbf{A} \\mathbf{u} - 2 \\mathbf{u}^T \\mathbf{b}, \\qquad \\mathbf{u}\\in\\mathbb{R}^n.\n\n(a) Expand and simplify the expression \\varphi(\\mathbf{x}+\\mathbf{v})-\\varphi(\\mathbf{x}), keeping in mind that \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\n(b) Using the result of part (a), prove that if \\mathbf{A} is an SPD matrix, φ has a global minimum at \\mathbf{x}.\n\n(c) Show that for any vector \\mathbf{u}, \\|\\mathbf{u}-\\mathbf{x}\\|_{\\mathbf{A}}^2-\\varphi(\\mathbf{u}) is constant.\n\n(d) Using the result of part (c), prove that CG minimizes \\varphi(\\mathbf{u}) over Krylov subspaces.\n\n⌨  Let n=50. Define the matrix \\mathbf{A}_k as FNC.poisson(n) minus k^2 times the n^2\\times n^2 identity matrix, and define vector \\mathbf{b} as n^2 copies of -1. The linear system \\mathbf{A}_k\\mathbf{x}=\\mathbf{b} arises from the Helmholtz equation for wave propagation at a single frequency k.\n\n(a) Apply both MINRES and CG to the Helmholtz system for k=1.3, solving to a relative residual tolerance of \n\n10-5. Plotting their convergence curves together.\n\n(b) Repeat part (a) for k=8.\n\n(c) Use eigs on the matrix from part (b) to show that it is indefinite. (Hint: Use additional arguments to get the eigenvalues with smallest and largest real parts.) This helps explain why the CG convergence curve for this matrix looks rather strange.\n\nIn principle, the implementation of Lanczos iteration is minor change from Arnoldi, but numerical stability requires some extra analysis and effort. We do not present the details.","type":"content","url":"/minrescg#exercises","position":11},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-7","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The iterative solution of large linear systems is a vast and difficult subject. A broad yet detailed introduction to the subject, including classical topics such as Jacobi and Gauss–Seidel methods not mentioned in this chapter, is \n\nSaad (2003). A more focused introduction to Krylov methods is given in \n\nvan der Vorst (2003).\n\nThe conjugate gradient method was originally intended to be a direct method.  Theoretically, the answer is found in n steps if there are n unknowns if the arithmetic is perfect.  However, for floating-point arithmetic this result no longer holds.  The trouble is that as the method progresses, the succeeding search directions become closer to being dependent, and this causes problems for conditioning and floating-point computation.  The method was not successful until it came to be viewed as an iterative method that could be stopped once a reasonable approximation was reached.  The method was discovered by Hestenes and Stiefel independently, but they joined forces to publish a widely cited paper \n\nHestenes & Stiefel (1952) as part of an early research program in computing run by what was then called the (US) National Bureau of Standards (now called the National Institute of Standards and Technology).  It took until the 1970s for the method to catch on as a computational method \n\nGolub & O'Leary (1989).  The interested reader can visit the SIAM History Project’s articles at \n\nhttp://​history​.siam​.org​/hestenes​.htm to find an article by Hestenes that recounts the discovery (reprinted from Nash \n\nNash (1990)).\n\nFor those not experienced with preconditioning, it can seem like something of an art.  The approach that works best very often depends on the application. Summaries of some approaches can be found in Quarteroni et al. \n\nQuarteroni et al. (2007) and Trefethen and Bau \n\nTrefethen & III (1997).","type":"content","url":"/next-7","position":1},{"hierarchy":{"lvl1":"8. Krylov methods in linear algebra"},"type":"lvl1","url":"/overview-7","position":0},{"hierarchy":{"lvl1":"8. Krylov methods in linear algebra"},"content":"I warn you not to underestimate my powers.\n\nLuke Skywalker, Return of the Jedi\n\nWhat are the implications of the O(n^3) work requirements for solving linear systems? Suppose tomorrow your computer became a thousand times faster. (Historically this has taken about 15 years in the real world.) Assuming you are willing to wait just as long today as you were yesterday, the size of the linear system you can solve has gone up only by a factor of 10. Nice, but not nearly the jump that you got in hardware power. In fact, there is an odd paradox: faster computers make faster algorithms more important, not less, because they demand that you work at larger values of n, where asymptotic differences are large.\n\nIn practice the only reasonable way to deal with large matrices (at this writing, n>10^4 or so) is if they are sparse, or can be approximated sparsely. But LU factorization of a sparse matrix does not necessarily lead to sparse factors, particularly when row pivoting is required. The algorithm can be improved to be more sparse-aware, but we will not go into the details.\n\nInstead, we will replace LU factorization with an iterative algorithm. Unlike the LU factorization, iteration gives useful intermediate and continually improving results before the exact solution is found, allowing us to stop well before the nominal exact termination. More importantly, though, these iterations, based on an idea called Krylov subspaces, allow us to fully exploit sparsity.\n\nKrylov subspace methods have two other advantages that are subtle but critically relevant to applications. One is that they allow us to do linear algebra even without having the relevant matrix. This may sound undesirable or even impossible, but it exploits the connection between matrix-vector multiplication and a linear transformation. The other major advantage of Krylov subspace iterations is that they can exploit approximate inverses when they are available. These two features are among the most powerful ideas behind scientific computation today.","type":"content","url":"/overview-7","position":1},{"hierarchy":{"lvl1":"Power iteration"},"type":"lvl1","url":"/power","position":0},{"hierarchy":{"lvl1":"Power iteration"},"content":"Given that matrix-vector multiplication is fast for sparse matrices, let’s see what we might accomplish with only that at our disposal.\n\nPower iteration\n\nExample 8.2.1\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = rand(1.0:9.0, 5, 5)\nA = A ./ sum(A, dims=1)\nx = randn(5)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A * x\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A * y\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nThis phenomenon seems to occur regardless of the starting vector.\n\nx = randn(5)\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nExample 8.2.1\n\nHere we choose a magic 5×5 matrix and a random 5-vector.\n\nA = magic(5) / 65;\nx = randn(5, 1);\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A * x\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A * y\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nfor j = 1:8\n    x = A * x;\nend\n[x, A * x]\n\nThis phenomenon seems to occur regardless of the starting vector.\n\nx = randn(5, 1);\nfor j = 1:8\n    x = A * x;\nend\n[x, A * x]\n\nExample 8.2.1\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = random.choice(range(10), (5, 5))\nA = A / sum(A, 0)\nx = random.randn(5)\nprint(x)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A @ x\nprint(y)\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A @ y\nprint(z)\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nx = random.randn(5)\nfor j in range(6):\n    x = A @ x\nprint(x)\nprint(A @ x)\n\nThis phenomenon is unlikely to be a coincidence!\n\nThere was a little cheating in \n\nDemo 8.2.1 to make the story come out neatly (specifically, the normalization step after creating a random matrix). But it illustrates an important general fact that we investigate now.","type":"content","url":"/power","position":1},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Dominant eigenvalue"},"type":"lvl2","url":"/power#dominant-eigenvalue","position":2},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Dominant eigenvalue"},"content":"Analysis of matrix powers is most straightforward in the diagonalizable case. Let \\mathbf{A} be any diagonalizable n\\times n matrix having eigenvalues \\lambda_1,\\ldots,\\lambda_n and corresponding linearly independent eigenvectors \\mathbf{v}_1,\\ldots,\\mathbf{v}_n. Furthermore, suppose the eigenvalues are such that|\\lambda_1| > |\\lambda_2| \\ge |\\lambda_3| \\ge \\cdots \\ge |\\lambda_n|.\n\nGiven \n\n(8.2.1) we say that \\lambda_1 is the \n\ndominant eigenvalue. This was the case with \\lambda_1=1 for \\mathbf{A} in \n\nDemo 8.2.1.\n\nNow let \\mathbf{x} be an n-vector, let k be a positive integer, and refer to \n\n(7.2.11):\\mathbf{A}^k \\mathbf{x} = \\mathbf{V}\\mathbf{D}^k\\mathbf{V}^{-1}\\mathbf{x}.\n\nLet \\mathbf{z}=\\mathbf{V}^{-1}\\mathbf{x}, and recall that \\mathbf{D} is a diagonal matrix of eigenvalues. Then\\begin{split}\n  \\mathbf{A}^k\\mathbf{x} &= \\mathbf{V}\\mathbf{D}^k \\mathbf{z} = \\mathbf{V}\\begin{bmatrix} \\lambda_1^kz_1 \\\\[0.5ex] \\lambda_2^kz_2 \\\\ \\vdots \\\\ \\lambda_n^kz_n \\end{bmatrix} \\\\\n\t&= \\lambda_1^k \\left[ z_1 \\mathbf{v}_{1} +\n\t\tz_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right) ^k \n\t\t\\mathbf{v}_{2} + \\cdots + z_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^k\n\t\t\\mathbf{v}_{n} \\right].\n\\end{split}\n\nSince \\lambda_1 is dominant, we conclude that if z_1\\neq 0,\\left\\| \\frac{ \\mathbf{A}^k\\mathbf{x}}{\\lambda_1^k}\n- z_1\\mathbf{v}_1\\right\\| \\le |z_2|\\cdot\\left|\\frac{\\lambda_2}{\\lambda_1}\\right| ^k\n\\| \\mathbf{v}_{2} \\| + \\cdots +  |z_n|\\cdot\\left|\\frac{\\lambda_n}{\\lambda_1}\\right|^k\n\\| \\mathbf{v}_{n} \\| \\rightarrow 0 \\text{ as $k\\rightarrow \\infty$}.\n\nThat is, \\mathbf{A}^k\\mathbf{x} eventually is close to close to a scalar multiple of the dominant eigenvector.\n\nAttention\n\nFor algorithmic purposes, it is important to interpret \\mathbf{A}^k\\mathbf{x} as \\mathbf{A}\\bigl( \\cdots\\bigl( \\mathbf{A} (\\mathbf{A}\\mathbf{x})\\bigl) \\cdots\\bigl), i.e., as repeated applications of \\mathbf{A} to a vector. Doing so allows us to fully exploit sparsity of \\mathbf{A}, something which is not preserved by taking a matrix power \\mathbf{A}^k explicitly before the multiplication with \\mathbf{x} (see \n\nDemo 8.1.2).","type":"content","url":"/power#dominant-eigenvalue","position":3},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Power iteration"},"type":"lvl2","url":"/power#power-iteration","position":4},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Power iteration"},"content":"An important technicality separates us from an algorithm: unless |\\lambda_1|=1, the factor \\lambda_1^k tends to make \\|\\mathbf{A}^k\\mathbf{x}\\| either very large or very small. Nor can we easily normalize by \\lambda_1^k, as in \n\n(8.2.4), unless we know \\lambda_1 in advance.\n\nTo make a practical algorithm, we alternate matrix-vector multiplication with a renormalization of the vector. In the following, we use x_{k,m} and y_{k,m} to mean the mth component of vectors \\mathbf{x}_k and \\mathbf{y}_k.\n\nPower iteration\n\nGiven matrix \\mathbf{A}:\n\nChoose \\mathbf{x}_1.\n\nFor k=1,2,\\ldots,\n\na. Set \\mathbf{y}_k = \\mathbf{A} \\mathbf{x}_k.\n\nb. Find m such that |y_{k,m}|=\\|{\\mathbf{y}_k} \\|_\\infty.\n\nc. Set \\alpha_k = \\dfrac{1}{y_{k,m}} and \\,\\beta_k = \\dfrac{y_{k,m}}{x_{k,m}}.\n\nd. Set \\mathbf{x}_{k+1} = \\alpha_k \\mathbf{y}_k.\n\nReturn \\beta_1,\\beta_2,\\ldots as dominant eigenvalue estimates, and \\mathbf{x}_1,\\mathbf{x}_2,\\ldots as associated eigenvector estimates.\n\nNote\n\nThe vectors and scalars in \n\nAlgorithm 8.2.1 are subscripted by iteration number to help make the discussion here more convenient. In practice, the algorithm can be implemented without keeping the history, and \\alpha_k need not be separately computed at all.\n\nBy construction, \\| \\mathbf{x}_{k}\\|_\\infty=1 for all k > 1. Also, we can write\\mathbf{x}_{k} = (\\alpha_1 \\alpha_2 \\cdots \\alpha_k ) \\mathbf{A}^k \\mathbf{x}_{1}.\n\nThus \n\nAlgorithm 8.2.1 modifies \n\n(8.2.3) and \n\n(8.2.4) only slightly.\n\nFinally, if \\mathbf{x}_k is nearly a dominant eigenvector of \\mathbf{A}, then \\mathbf{A}\\mathbf{x}_k is nearly \\lambda_1\\mathbf{x}_k, and we can take the ratio \\beta_k=y_{k,m}/x_{k,m} as an eigenvalue estimate. In fact, revisiting \n\n(8.2.3), the extra \\alpha_j normalization factors cancel in the ratio, and, after some simplification, we get\\beta_k = \\frac{y_{k,m}}{x_{k,m}} = \\lambda_1\n\\frac{1+r_2^{k+1} b_2 + \\cdots +  r_n^{k+1} b_n}{1+r_2^{k} b_2 +  \\cdots +  r_n^{k} b_n},\n\nwhere r_j=\\lambda_j/\\lambda_1 and the b_j are constants. By assumption \n\n(8.2.1), each r_j satisfies |r_j|<1, so we see that \\beta_k\\rightarrow \\lambda_1 as k\\rightarrow\\infty.\n\nFunction 8.2.2 is our implementation of power iteration.\n\npoweriter\n\nPower iteration\n\n\"\"\"\n    poweriter(A, numiter)\n\nPerform `numiter` power iterations with the matrix `A`, starting\nfrom a random vector. Returns a vector of eigenvalue estimates\nand the final eigenvector approximation.\n\"\"\"\nfunction poweriter(A, numiter)\n    n = size(A, 1)\n    x = normalize(randn(n), Inf)\n    β = zeros(numiter)\n    for k in 1:numiter\n        y = A * x\n        m = argmax(abs.(y))\n        β[k] = y[m] / x[m]\n        x = y / y[m]\n    end\n    return β, x\nend\n\nPower iteration\n\nfunction [beta, x] = poweriter(A, numiter)\r\n% POWERITER   Power iteration for the dominant eigenvalue.\r\n% Input:\r\n%   A         square matrix\r\n%   numiter   number of iterations\r\n% Output: \r\n%   beta      sequence of eigenvalue approximations (vector)\r\n%   x         final eigenvector approximation\r\n\r\nn = length(A);\r\nx = randn(n, 1);\r\nx = x / norm(x, inf);\r\nfor k = 1:numiter\r\n    y = A*x;\r\n    [normy, m] = max(abs(y));\r\n    beta(k) = y(m) / x(m);\r\n    x = y / y(m);\r\nend \n\nPower iteration\n\ndef poweriter(A, numiter):\n    \"\"\"\n    poweriter(A, numiter)\n\n    Perform numiter power iterations with the matrix A, starting from a random vector, \n    and return a vector of eigenvalue estimates and the final eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    for k in range(numiter):\n        y = A @ x\n        m = np.argmax(abs(y))\n        gamma[k] = y[m] / x[m]\n        x = y / y[m]\n\n    return gamma, x\n\nObserve that the only use of \\mathbf{A} is to find the matrix-vector product \\mathbf{A}\\mathbf{x}, which makes exploitation of the sparsity of \\mathbf{A} trivial.","type":"content","url":"/power#power-iteration","position":5},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Convergence"},"type":"lvl2","url":"/power#convergence","position":6},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Convergence"},"content":"Let’s examine the terms in the numerator and denominator of \n\n(8.2.6) more carefully:\\begin{split}\nr_2^{k} b_2 +  \\cdots +  r_n^{k} b_n &= r_2^k \\left[ b_2 + \\left( \\frac{r_3}{r_2} \\right)^kb_3 + \\cdots + \\left( \\frac{r_n}{r_2} \\right)^kb_n \\right] \\\\\n&= r_2^k \\left[ b_2 + \\left( \\frac{\\lambda_3}{\\lambda_2} \\right)^kb_3 + \\cdots + \\left( \\frac{\\lambda_n}{\\lambda_2} \\right)^kb_n \\right].\n\\end{split}\n\nAt this point we’ll introduce an additional assumption,|\\lambda_2| > |\\lambda_3| \\ge \\cdots \\ge |\\lambda_n|.\n\nThis condition isn’t strictly necessary, but it simplifies the following statements considerably because now it’s clear that the quantity in \n\n(8.2.7) approaches b_2 r_2^k as k\\rightarrow \\infty.\n\nNext we estimate \n\n(8.2.6) for large k, using a geometric series expansion for the denominator to get\\begin{split}\n\\beta_k & \\to \\lambda_1 \\left( 1+b_2 r_2^{k+1} \\right) \\left( 1 - b_2 r_2^{k} + O(r_2^{2k}) \\right), \\\\\n\\beta_k - \\lambda_1 &\\to \\lambda_1 b_2 (  r_2 - 1 ) r_2^{k}.\n\\end{split}\n\nThis is \n\nlinear convergence with factor r_2:\\frac{\\beta_{k+1} - \\lambda_1}{\\beta_{k}-\\lambda_1} \\rightarrow r_2 = \\frac{\\lambda_2}{\\lambda_1} \\quad \\text{as } k\\rightarrow \\infty.\n\nThe error in the power iteration eigenvalue estimates \\beta_k is reduced asymptotically by a constant factor \\lambda_2/\\lambda_1 at each iteration, where \\lambda_1 and \\lambda_2 are the dominant eigenvalues of \\mathbf{A}.\n\nConvergence of power iteration\n\nExample 8.2.2\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run the power iteration 60 times. The best estimate of the dominant eigenvalue is the last entry of the first output.\n\nβ, x = FNC.poweriter(A, 60)\neigval = β[end]\n\nWe check for linear convergence using a log-linear plot of the error.\n\nusing Plots\nerr = @. 1 - β\nplot(0:59, abs.(err); m=:o, \n    xlabel=L\"k\",  \n    yaxis=(L\"|\\lambda_1-\\beta_k|\", :log10, [1e-10, 1]),\n    title=\"Convergence of power iteration\")\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\n@show theory = λ[2] / λ[1];\n@show observed = err[40] / err[39];\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nβ[26:30]\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = @. β[end] - β[1:end-1]\nplot(0:58, abs.(err), m=:o, \n    xlabel=L\"k\", \n    yaxis=(L\"|\\beta_{60}-\\beta_k|\", :log10, [1e-10, 1]),\n    title=\"Convergence of power iteration\")\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.\n\nExample 8.2.2\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nev = [1, -0.75, 0.6, -0.4, 0];\n% Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diag(ev);\n\nWe run the power iteration 60 times. The best estimate of the dominant eigenvalue is the last entry of the first output.\n\n[beta, x] = poweriter(A, 60);\nformat long\nbeta(1:12)\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = 1 - beta;\nclf,  semilogy(abs(err), '.-')\ntitle('Convergence of power iteration')\nxlabel('k'),  ylabel(('|\\lambda_1 - \\beta_k|'));\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\ntheory = ev(2) / ev(1)\nobserved = err(40) / err(39)\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nbeta(26:29)\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = beta(end) - beta(1:end-1);\nsemilogy(abs(err), '.-')\ntitle('Convergence of power iteration')\nxlabel('k'),  ylabel(('|\\beta_{60} - \\beta_k|'));\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.\n\nExample 8.2.2\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nev = [1, -0.75, 0.6, -0.4, 0]\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run the power iteration 60 times. The first output should be a sequence of estimates converging to the dominant eigenvalue—which, in this case, we set up to be 1.\n\nbeta, x = FNC.poweriter(A, 60)\nprint(beta)\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = 1 - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1)\nxlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\nprint(f\"theory: {ev[1] / ev[0]:.5f}\")\nprint(f\"observed: {err[40] / err[39]:.5f}\")\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nprint(beta[26:30])\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = beta[-1] - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1), xlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.\n\nThe practical utility of \n\n(8.2.10) is limited: if we knew \\lambda_1 and \\lambda_2, we wouldn’t be running the power iteration in the first place! Sometimes it’s possible to find estimates of or bounds on the ratio. If nothing else, though, it is useful to know that linear convergence is expected at a rate based solely on the dominant eigenvalues.","type":"content","url":"/power#convergence","position":7},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Exercises"},"type":"lvl2","url":"/power#exercises","position":8},{"hierarchy":{"lvl1":"Power iteration","lvl2":"Exercises"},"content":"⌨ Use \n\nFunction 8.2.2 to perform 20 power iterations for the following matrices. Quantitatively compare the observed convergence to the prediction in \n\n(8.2.10).\n\n(a)\n\\mathbf{A} = \\begin{bmatrix}\n   1.1 & 1 \\\\\n   0.1 & 2.4\n \\end{bmatrix} \\quad\n(b) \\mathbf{A} = \\begin{bmatrix}\n   2 & 1 \\\\\n   1 & 0\n \\end{bmatrix} \\quad\n(c)  \\mathbf{A} = \\begin{bmatrix}\n   6 & 5 & 4 \\\\\n   5 & 4 & 3 \\\\\n   4 & 3 & 2\n \\end{bmatrix}\n\n(d) \\mathbf{A} = \\begin{bmatrix}\n 8 & -14 & 0 & -14 \\\\\n -8 & 1 & 1 & 1 \\\\\n -4 & -2 & 0 & 2 \\\\\n 8 & -7 & -1 & -7 \n \\end{bmatrix}\n\n✍ Describe what happens during power iteration using the matrix \\mathbf{A}= \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix} and initial vector \\mathbf{x}=\\begin{bmatrix} 0.4\\\\0.7 \\end{bmatrix}. Does the algorithm converge to an eigenvector? How does this relate to \n\n(8.2.3)?\n\n⌨  In  \n\nExercise 2.3.5 we considered a mass-lumped model of a hanging string that led to a tridiagonal system of linear equations. Then, in \n\nExercise 7.2.6, we found that eigenvectors of the same matrix correspond to vibrational modes of the string. The same setup can be applied to a membrane hanging from a square frame. Lumping the mass onto a Cartesian grid, each interacts with the four neighbors to the north, south, east, and west. If n masses are used in each coordinate direction, we get an n^2\\times n^2 sparse matrix \\mathbf{A} that can be constructed by FNC.poisson(n).\n\n(a) Let n=10 and make a spy plot of \\mathbf{A}. What is the density of \\mathbf{A}? Most rows all have the same number of nonzeros; find this number.\n\n(b) Find the dominant \\lambda_1 using eigs for n=10,15,20,25.\n\n(c) For each n in part (b), apply 100 steps of \n\nFunction 8.2.2. On one graph, plot the four convergence curves |\\beta_k-\\lambda_1| using a semi-log scale. (They will not be smooth curves because this matrix has many repeated eigenvalues that complicate the convergence analysis.)\n\n⌨ Copy the instructions from \n\nExercise 8.1.5 to obtain a large, sparse matrix \\mathbf{A}. Use \n\nFunction 8.2.2 to find the leading eigenvalue of \\mathbf{A}^T\\mathbf{A} to at least six significant digits.\n\n⌨ For symmetric matrices, the Rayleigh quotient \n\n(7.4.5) converts an O(\\epsilon) eigenvector estimate into an O(\\epsilon^2) eigenvalue estimate. Duplicate \n\nFunction 8.2.2 and rename it to powersym. Modify the new function to use the Rayleigh quotient to produce the entries of β or beta. Your function should not introduce any additional matrix-vector multiplications. Apply the original \n\nFunction 8.2.2 and the new powersym on the MatrixDepot/gallery/rogues matrix fiedler(100), plotting the convergence curves on one graph.\n\nIf \\mathbf{x} is chosen randomly, the probability that z_1=0 is mathematically zero.","type":"content","url":"/power#exercises","position":9},{"hierarchy":{"lvl1":"Preconditioning"},"type":"lvl1","url":"/precond","position":0},{"hierarchy":{"lvl1":"Preconditioning"},"content":"An important aspect of MINRES and CG (and, by extension, GMRES) is that the convergence of a Krylov method can be expected to deteriorate as the condition number of the matrix increases. Even moderately large condition numbers can make the convergence impractically slow. Therefore it’s common for these methods to be used with a technique to reduce the relevant condition number.\n\nPreconditioning\n\nGiven a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, a preconditioner is a matrix \\mathbf{M} or equivalent linear transformation that modifies the system to be(\\mathbf{M}^{-1} \\mathbf{A}) \\mathbf{x} = \\mathbf{M}^{-1}\\mathbf{b}.\n\nMore specifically, \n\n(8.8.1) is known as left preconditioning, but it is the simplest and most common type.\n\nAs usual, we do not want to actually compute \\mathbf{M}^{-1} for a given \\mathbf{M}. Instead, we have a linear system with the matrix \\mathbf{M}^{-1}\\mathbf{A}. In a Krylov method, the operation “let \\mathbf{v}=\\mathbf{A}\\mathbf{u}” becomes a two-step process:\n\nSet \\mathbf{y}=\\mathbf{A}\\mathbf{u}.\n\nSolve \\mathbf{M}\\mathbf{v}=\\mathbf{y} for \\mathbf{v}.\n\nAs an implementation detail, it is common to provide the Krylov solver with code that does step 2; if the matrix \\mathbf{M} is given, the default is to use sparse factorization.\n\nThere are competing objectives in the choice of \\mathbf{M}. On one hand, we want \\mathbf{M}^{-1}\\mathbf{A}\\approx \\mathbf{I} in some sense because that makes \n\n(8.8.1) easy to solve by Krylov iteration. Hence \\mathbf{M}\\approx \\mathbf{A}. On the other hand, we desire that solving the system \\mathbf{M}\\mathbf{v}=\\mathbf{y} be relatively fast.\n\nGood preconditioning is a matter of finding an easily inverted (i.e., quickly solvable) approximation of the original matrix.","type":"content","url":"/precond","position":1},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Diagonal preconditioning"},"type":"lvl2","url":"/precond#diagonal-preconditioning","position":2},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Diagonal preconditioning"},"content":"One of the simplest choices for the preconditioner \\mathbf{M} is a diagonal matrix. This definitely meets the requirement of being fast to invert: the solution of \\mathbf{M}\\mathbf{v}=\\mathbf{y} is just v_i=y_i/M_{ii}. The only question is whether it can be chosen in such a way that \\mathbf{M}^{-1}\\mathbf{A} is much more amenable to Krylov iterations than \\mathbf{A} is. This may be the case when the rows of \\mathbf{A} differ greatly in scale, or when \\mathbf{A} is diagonally dominant (see \n\n(2.9.1)).\n\nDiagonal preconditioning\n\nExample 8.8.1\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nusing MatrixDepot\nA = matrixdepot(\"wathen\", 60)\nn = size(A, 1)\n@show n, nnz(A);\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nusing Preconditioners\nb = ones(n)\nM = DiagonalPreconditioner(diag(A));\n\nWe now compare CG with and without the preconditioner.\n\nusing IterativeSolvers, Plots\nplain(b) = cg(A, b, maxiter=200, reltol=1e-4, log=true)\ntime_plain = @elapsed x, hist1 = plain(b)\nprec(b) = cg(A, b, Pl=M, maxiter=200, reltol=1e-4, log=true)\ntime_prec = @elapsed x, hist2 = prec(b)\n@show time_plain, time_prec\n\nrr = hist1[:resnorm]\nplot(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"plain\")\nrr = hist2[:resnorm]\nplot!(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"preconditioned\")\ntitle!(\"Diagonal preconditioning in CG\")\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\nExample 8.8.1\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nA = gallery(\"wathen\", 60, 60);\nn = size(A, 1);\nclf,  spy(A)\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nM = spdiags(diag(A), 0, n, n);\n\nWe now compare MINRES with and without the preconditioner.\n\nb = ones(n, 1);\n[x, ~, ~, ~, resid_plain] = minres(A, b, 1e-10, 400);\nclf,  semilogy(resid_plain)\nxlabel('iteration number'), ylabel('residual norm')\ntitle('Unpreconditioned MINRES')\n\n[x, ~, ~, ~, resid_prec] = minres(A, b, 1e-10, 400, M);\nhold on,  semilogy(resid_prec)\ntitle('Precondtioned MINRES')\nlegend('no prec.', 'with prec.');\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\nExample 8.8.1\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nfrom scipy.sparse import sparray\nimport rogues\nA = rogues.wathen(60, 60)\nn = A.shape[0]\nprint(f\"Matrix is {n} x {n} with {A.nnz} nonzeros\")\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nimport scipy.sparse as sp\nprec = sp.diags(1 / A.diagonal(), 0)\n\nWe now compare CG with and without the preconditioner.\n\nfrom scipy.sparse.linalg import cg\nb = ones(n)\nhist = lambda x: resid.append(norm(b - A @ x))\nresid = [norm(b)]\nstart = timer()\nx, _ = cg(A, b, rtol=1e-4, maxiter=200, callback=hist)\nprint(f\"No preconditioner: Finished in {timer() - start:.2f} sec\")\nresid_plain = resid.copy()\nresid = [norm(b)]\nstart = timer()\nx, _ = cg(A, b, rtol=1e-4, maxiter=200, M=prec, callback=hist)\nprint(f\"Diagonal preconditioner: Finished in {timer() - start:.2f} sec\")\nresid_prec = resid.copy()\n\nsemilogy(resid_plain, label=\"no preconditioner\")\nsemilogy(resid_prec, label=\"diagonal preconditioner\")\nxlabel(\"iteration\"), ylabel(\"residual norm\")\nlegend(),  title(\"Convergence of CG with and without preconditioning\");\n\nThe diagonal preconditioner cut down substantially on the number of iterations and the execution time.","type":"content","url":"/precond#diagonal-preconditioning","position":3},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Incomplete factorization"},"type":"lvl2","url":"/precond#incomplete-factorization","position":4},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Incomplete factorization"},"content":"Another general-purpose technique is the incomplete LU factorization. Since true factorization of a sparse matrix usually leads to an undesirable amount of fill-in, incomplete LU sacrifices exact factors by dropping elements smaller than an adjustable threshold.\n\nIncomplete LU preconditioning\n\nExample 8.8.2\n\nHere is a nonsymmetric matrix arising from a probabilistic model in computational chemistry.\n\nusing SparseArrays\nA = sparse(matrixdepot(\"Watson/chem_master1\"))\nn = size(A, 1)\n@show n, nnz(A), issymmetric(A)\n\nWithout a preconditioner, GMRES makes essentially no progress after 100 iterations.\n\nb = rand(40000)\nconst GMRES = IterativeSolvers.gmres\nx, history = GMRES(A, b, maxiter=100, reltol=1e-5, log=true)\nresnorm = history[:resnorm]\n@show resnorm[end] / resnorm[1];\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\nusing IncompleteLU\niLU = ilu(A, τ=0.25)\n@show nnz(iLU) / nnz(A);\n\nThe result is almost 10 times as dense as \\mathbf{A} and yet still not a true factorization of it. However, it’s close enough for an approximate inverse in a preconditioner. The actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}, but we just supply the factorization to gmres.\n\n_, history = GMRES(A, b, Pl=iLU, maxiter=100, reltol=1e-5, log=true)\nhistory\n\nThe τ parameter in ilu balances the accuracy of the iLU factorization with the time needed to compute it and invert it. As \\tau\\to 0, more of the elements are kept, making the preconditioner more effective but slower per iteration.\n\nplt = plot(0:40, resnorm[1:41] / resnorm[1];\n    label=\"no preconditioning\",  legend=:bottomright,\n    xaxis=(\"iteration number\"),\n    yaxis=(:log10, \"residual norm\"),\n    title=\"Incomplete LU preconditioning\")\nfor τ in [2, 1, 0.25, 0.1]\n    t = @elapsed iLU = ilu(A; τ)\n    t += @elapsed _, history = GMRES(A, b, Pl=iLU, maxiter=100,\n        reltol=1e-5, log=true)\n    resnorm = history[:resnorm]\n    label = \"τ = $τ, time = $(round(t,digits=3))\"\n    plot!(0:length(resnorm)-1, resnorm / resnorm[1]; label)\nend\nplt\n\nIn any given problem, it’s impossible to know in advance where the right balance lies between fidelity and speed for the preconditioner.\n\nExample 8.8.2\n\nHere is a random nonsymmetric matrix.\n\nn = 8000;\nA = speye(n) + sprand(n, n, 0.00035);\n\nWithout a preconditioner, restarted GMRES makes slow progress.\n\nb = rand(n, 1);\n[x, ~, ~, ~, resid_plain] = gmres(A, b, 50, 1e-10, 3);  % restart at 50\nformat short e\nresid_plain(1:30:end)\n\nThis version of incomplete LU factorization simply prohibits fill-in for the factors, freezing the sparsity pattern of the approximate factors to match the original matrix.\n\n[L, U] = ilu(A);\nclf\nsubplot(121), spy(L)\ntitle('L')\nsubplot(122), spy(U)\ntitle('U')\ndisp(sprintf(\"There are %d nonzeros in A\", nnz(A)))\n\nIt does not produce a true factorization of \\mathbf{A}.\n\nnorm( full(A - L * U) )\n\nThe actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}. However, the gmres function allows setting the preconditioner by giving the factors independently.\n\n[x, ~, ~, ~, resid_prec] = gmres(A, b, [], 1e-10, 300, L, U);\n\nThe preconditioner makes a significant difference in the number of iterations needed.\n\nclf, semilogy(resid_plain)\nhold on, semilogy(resid_prec)\nxlabel('iteration number'), ylabel('residual norm')\ntitle('Precondtioned GMRES ')\nlegend('no preconditioner', 'with preconditioner');\n\nExample 8.8.2\n\nHere is a random nonsymmetric matrix.\n\nimport scipy.sparse as sp\nn = 8000\nA = 2.8 * sp.eye(n) + sp.rand(n, n, 0.002)\n\nWithout a preconditioner, GMRES can solve a system with this matrix.\n\nfrom scipy.sparse.linalg import gmres\n\nb = random.rand(n)\nhist = lambda rvec: resid.append(norm(rvec))\nresid = [1.]\n\nstart = timer()\nx, flag = gmres(A, b, maxiter=300, rtol=1e-10, restart=50, callback=hist)\nprint(f\"time for plain GMRES: {timer() - start:.3f} sec\")\nresid_plain = resid.copy()\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\nfrom scipy.sparse.linalg import spilu\niLU = spilu(A, drop_tol=0.2)\nprint(f\"Factors have {iLU.nnz} nonzeros, while A has {A.nnz}\")\n\nThe result is not a true factorization of the original matrix. However, it’s close enough for an approximate inverse in a preconditioner.\n\nfrom scipy.sparse.linalg import LinearOperator\nprec = LinearOperator((n, n), matvec=lambda y: iLU.solve(y))\n\nresid = [1.];  start = timer()\nx, flag = gmres(A, b, M=prec, maxiter=300, rtol=1e-10, restart=50, callback=hist)\nprint(f\"time for preconditioned GMRES: {timer() - start:.3f} sec\")\nresid_prec = resid\n\nsemilogy(resid_plain, label=\"no prec.\")\nsemilogy(resid_prec, label=\"iLU prec.\")\nxlabel(\"iteration number\"),  ylabel(\"residual norm\")\nlegend()\ntitle(\"GMRES convergence compared\");\n\nIn practice, good preconditioning is often as important, if not more important, than the specific choice of Krylov method. Effective preconditioning may require deep understanding of the underlying application, however, which limits our ability to go into further details. For instance, the linear system may be some approximation of a continuous mathematical model, and then \\mathbf{M} can be derived by using a cruder form of the approximation. Krylov methods offer a natural way to exploit these and other approximate inverses.","type":"content","url":"/precond#incomplete-factorization","position":5},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Exercises"},"type":"lvl2","url":"/precond#exercises","position":6},{"hierarchy":{"lvl1":"Preconditioning","lvl2":"Exercises"},"content":"✍ Suppose \\mathbf{M}=\\mathbf{R}^T\\mathbf{R}. Show that the eigenvalues of \\mathbf{R}^{-T}\\mathbf{A}\\mathbf{R}^{-1} are the same as the eigenvalues of \\mathbf{M}^{-1}\\mathbf{A}. (This observation underlies preconditioning variants for SPD matrices.)\n\n⌨ The object returned by ilu stores the factors in a way that optimizes sparse triangular substitution. You can recover the factors themselves viaiLU = ilu(A,τ=0.1)   # for example\nL, U = I+iLU.L, iLU.U'\n\nIn this problem, use A = 1.5I + sprand(800,800,0.005).\n\n(a) Using \\tau=0.3 for the factorization, plot the eigenvalues of \\mathbf{A} and of \\mathbf{M}^{-1}\\mathbf{A} in the complex plane on side-by-side subplots. Do they support the notion that \\mathbf{M}^{-1}\\mathbf{A} is “more like” an identity matrix than \\mathbf{A} is? (Hint: the matrices are small enough to convert to standard dense form for the use of eigvals.)\n\n(b) Repeat part (a) for \\tau=0.03. Is \\mathbf{M} more accurate than in part (a), or less?\n\n⌨ (Continuation of \n\nExercise 8.5.5.) Let \\mathbf{B} be diagm(1:100),  let \\mathbf{I} be I(100), and let \\mathbf{Z} be a 100\\times 100 matrix of zeros. Define\\mathbf{A} = \\begin{bmatrix}\n      \\mathbf{B} & \\mathbf{I} \\\\ \\mathbf{Z} & -\\mathbf{B}\n    \\end{bmatrix}\n\nand let \\mathbf{b} be a 200-vector of ones. The matrix \\mathbf{A} is difficult for GMRES.\n\n(a) Design a diagonal preconditioner \\mathbf{M}, with all diagonal elements equal to 1 or -1, such that \\mathbf{M}^{-1}\\mathbf{A} has all positive eigenvalues. Apply gmres without restarts using this preconditioner and a tolerance of \n\n10-10 for 100 iterations. Plot the convergence curve.\n\n(b) Now design another diagonal preconditioner such that all the eigenvalues of \\mathbf{M}^{-1}\\mathbf{A} are 1, and apply preconditioned gmres again. How many iterations are apparently needed for convergence?\n\n⌨ Let A = matrixdepot(\"Bai/rdb2048\"), and let b be a vector of 2048 ones. In the steps below, use GMRES for up to 300 iterations without restarts and with a stopping tolerance of \n\n10-4.\n\n(a) Time the GMRES solution without preconditioning. Verify that convergence was achieved.\n\n(b) Show that diagonal preconditioning is not helpful for this problem.\n\n(c) To two digits, find a value of τ in iLU such that the preconditioned method transitions from effective and faster than part (a) to ineffective.","type":"content","url":"/precond#exercises","position":7},{"hierarchy":{"lvl1":"Sparsity and structure"},"type":"lvl1","url":"/structure-1","position":0},{"hierarchy":{"lvl1":"Sparsity and structure"},"content":"Very large matrices cannot be stored all within primary memory of a computer unless they are sparse. A sparse matrix has structural zeros, meaning entries that are known to be exactly zero.} For instance, the adjacency matrix of a graph has zeros where there are no links in the graph. To store and operate with a sparse matrix efficiently, it is not represented as an array of all of its values. There is a variety of sparse formats available; for the most part, you can imagine that the matrix is stored as triples (i,j,A_{ij}) for all the nonzero (i,j) locations.","type":"content","url":"/structure-1","position":1},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Computing with sparse matrices"},"type":"lvl2","url":"/structure-1#computing-with-sparse-matrices","position":2},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Computing with sparse matrices"},"content":"Most graphs with real applications have many fewer edges than the maximum possible n^2 for n nodes. Accordingly, their adjacency matrices have mostly zero elements and should be represented sparsely.\n\nSparsity\n\nExample 8.1.1\n\nTip\n\nJulia functions to deal with sparse matrices are found in the SparseArrays package in the standard library.\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nusing SparseArrays, JLD2\n@load \"roswell.jld2\" A;      # file is on the book's website\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nTip\n\nUse nnz to count the number of nonzeros in a sparse matrix.\n\nm, n = size(A)\n@show density = nnz(A) / (m * n);\n\nThe computer memory consumed by any variable can be discovered using summarysize. We can use it to compare the space needed for the sparse representation to its dense counterpart, that is, the space needed to store all the elements, whether zero or not.\n\nF = Matrix(A)\nBase.summarysize(F) / Base.summarysize(A)\n\nAs you can see, the storage savings are dramatic. Matrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nx = randn(n)\nA * x;   # make sure * is loaded and compiled\n@elapsed for i in 1:300\n    A * x\nend\n\nF * x;\n@elapsed for i in 1:300\n    F * x\nend\n\nExample 8.1.1\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nload roswelladj\na = whos('A')\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nTip\n\nUse nnz to count the number of nonzeros in a sparse matrix.\n\nsz = size(A);  n = sz(1);\ndensity = nnz(A) / prod(sz)\n\nThe computer memory consumed by any variable can be discovered using whos. We can use it to compare the space needed for the sparse representation to its dense counterpart, that is, the space needed to store all the elements, whether zero or not.\n\nF = full(A);\nf = whos('F');\nstorage_ratio = f.bytes / a.bytes\n\nMatrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nx = randn(n,1);\ntic, for i = 1:200, A*x; end\nsparse_time = toc\n\ntic, for i = 1:200, F*x; end\ndense_time = toc\n\nHowever, the sparse storage format in MATLAB is column-oriented.  Operations on rows may take a lot longer than similar ones on columns.\n\nv = A(:, 1000);\ntic, for i = 1:n, A(:, i) = v; end\ncolumn_time = toc\nr = v';\ntic, for i = 1:n, A(i, :) = r; end\nrow_time = toc\n\nExample 8.1.1\n\nTip\n\nFunctions to work with sparse matrices are found in the scipy.sparse module.\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nimport scipy.sparse as sp\nfrom scipy.io import loadmat\n\nvars = loadmat(\"roswelladj.mat\")    # get from the book's website\nA = sp.csr_matrix(vars[\"A\"])\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nm, n = A.shape\nprint(f\"density is {A.nnz / (m * n):.3%}\")\n\nWe can compare the storage space needed for the sparse \\mathbf{A} with the space needed for its dense / full counterpart.\n\nF = A.todense()\nprint(f\"{A.data.nbytes/1e6:.3f} MB for sparse form, {F.nbytes/1e6:.3f} MB for dense form\")\n\nMatrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nfrom timeit import default_timer as timer\nx = random.randn(n)\nstart = timer()\nfor i in range(1000):\n    A @ x\nprint(f\"sparse time: {timer() - start:.4g} sec\")\n\nstart = timer()\nfor i in range(1000):\n    F @ x\nprint(f\"dense time: {timer() - start:.4g} sec\")\n\nArithmetic operations such as +, -, *, and ^ respect and exploit sparsity if the matrix operands are sparse. However, matrix operations may substantially decrease the amount of sparsity, a phenomenon known as fill-in.\n\nFill-in of a sparse matrix\n\nExample 8.1.2\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nusing GraphRecipes\n@load \"smallworld.jld2\" A\ngraphplot(A, linealpha=0.5)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nspy(A, title=\"Nonzero locations\", m=2, color=:blues)\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nplt = plot(layout=(1, 3), legend=:none, size=(600, 240))\nfor k in 2:4\n    spy!(A^k;\n        subplot=k - 1, color=:blues,\n        title=latexstring(\"\\\\mathbf{A}^$k\"))\nend\nplt\n\nExample 8.1.2\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nload smallworld.mat\nG = graph(A);\nplot(G, nodecolor='r')\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nspy(A)\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nclf\ntiledlayout(2, 2)\nfor k = [2, 3, 4, 6]\n    nexttile\n    spy(A^k)\n    title(sprintf(\"A^{%d}\", k))\nend\n\nExample 8.1.2\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nimport networkx as nx\nwsg = nx.watts_strogatz_graph(200, 4, 0.02)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nA = nx.adjacency_matrix(wsg)\nspy(A)\ntitle(\"Adjacency matrix $A$\");\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nTip\n\nWhile A**6 is valid syntax here, it means elementwise power, not matrix power.\n\nfrom scipy.sparse.linalg import matrix_power\nspy(matrix_power(A, 6))\ntitle((\"$A^6$\"));","type":"content","url":"/structure-1#computing-with-sparse-matrices","position":3},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Banded matrices"},"type":"lvl2","url":"/structure-1#banded-matrices","position":4},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Banded matrices"},"content":"A particularly important type of sparse matrix is a banded matrix. Recall from \n\nExploiting matrix structure that \\mathbf{A} has upper bandwidth p if j-i > p implies A_{ij}=0, and lower bandwidth q if i-j > q implies A_{ij}=0. We say the total bandwidth is p+q+1. Banded matrices appear naturally in many applications where each element interacts directly with only a few neighbors.\n\nWithout pivoting, an LU factorization preserves bandwidth, but pivoting can change or destroy bandedness.\n\nBanded matrices\n\nExample 8.1.3\n\nThe spdiagm function creates a sparse matrix given its diagonal elements. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50;\nA = spdiagm(-3 => fill(n, n - 3),\n    0 => ones(n),\n    1 => -(1:n-1),\n    5 => fill(0.1, n - 5))\nMatrix(A[1:7, 1:7])\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nTip\n\nThe sparse function converts any matrix to sparse form. But it’s usually better to construct a sparse matrix directly, as the standard form might not fit in memory.\n\nL, U = FNC.lufact(A)\nplot(layout=2)\nspy!(sparse(L), m=2, subplot=1, title=L\"\\mathbf{L}\", color=:blues)\nspy!(sparse(U), m=2, subplot=2, title=L\"\\mathbf{U}\", color=:blues)\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\nfact = lu(A)\nplot(layout=2)\nspy!(sparse(fact.L), m=2, subplot=1, title=L\"\\mathbf{L}\", color=:blues)\nspy!(sparse(fact.U), m=2, subplot=2, title=L\"\\mathbf{U}\", color=:blues)\n\nExample 8.1.3\n\nThe spdiags function creates a sparse matrix given its diagonal elements. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50;\nn = 50;\n% Put constant values on 3 diagonals\nA = spdiags([n, 1, 0.1], [-3, 0, 5], n, n);\n% Put other values on 1st superdiagonal\nA = spdiags(-(0:n-1)', 1, A);\nfull(A(1:7, 1:7))\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nTip\n\nThe sparse function converts any matrix to sparse form. But it’s usually better to construct a sparse matrix directly, as the standard form might not fit in memory.\n\n[L, U] = lufact(A);\nclf\nsubplot(1, 2, 1), spy(L), title('L')\nsubplot(1, 2, 2), spy(U), title(('U'));\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\n[L, U, p] = plufact(A);\nsubplot(1, 2, 1), spy(L(p, :)), title('L')\nsubplot(1, 2, 2), spy(U), title(('U'));\n\nExample 8.1.3\n\nThe scipi.sparse.diags function creates a sparse matrix given its diagonal elements and the diagonal indexes to put them on. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50\ndata = [n * ones(n-3), ones(n), linspace(-1, 1-n, n-1)]\noffsets = [-3, 0, 1]    # 3rd below, main, 1st above\nA = sp.diags(data, offsets, format=\"lil\")\nprint(A[:7, :7].todense())\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nL, U = FNC.lufact(A.todense())\nsubplot(1, 2, 1), spy(L)\nsubplot(1, 2, 2), spy(U);\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\nL, U, p = FNC.plufact(A.todense())\nsubplot(1, 2, 1), spy(L[p, :])\nsubplot(1, 2, 2), spy(U)","type":"content","url":"/structure-1#banded-matrices","position":5},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Systems and eigenvalues"},"type":"lvl2","url":"/structure-1#systems-and-eigenvalues","position":6},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Systems and eigenvalues"},"content":"If given a sparse matrix, the backslash operator will automatically try a form of sparse-aware Cholesky or pivoted LU factorization. Depending on the sparsity pattern of the matrix, the time taken to solve the linear system may be well below the O(n^3) needed in the general case.\n\nFor very large matrices, it’s unlikely that you will want to find all of its eigenvalues and eigenvectors. In \n\nKrylov subspaces we describe some of the math behind an algorithm that can find a selected number of eigenvalues of largest magnitude, lying to the extreme left or right, or nearest a given complex number.\n\nEigenvalues of sparse matrices\n\nExample 8.1.4\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nλ = @. 1 + 1 / (1:n)   # exact eigenvalues\nA = FNC.sprandsym(n, density, λ);\n\nThe eigs function from Arpack finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=:LM.\n\nusing Arpack\nλmax, V = eigs(A, nev=5, which=:LM)    # Largest Magnitude\nfmt = ft_printf(\"%20.15f\")\npretty_table([λmax λ[1:5]], header=[\"found\", \"exact\"], formatters=fmt)\n\nNow we find the 5 closest to the value 1 in the complex plane, via sigma=1.\n\nλ1, V = eigs(A, nev=5, sigma=1)    # closest to sigma\ndata = [λ1 λ[end:-1:end-4]]\npretty_table(data, header=[\"found\", \"exact\"], formatters=fmt)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nx = @. 1 / (1:n);\nb = A * x;\n\nnorm(x - A \\ b);  # force compilation\nt = @elapsed sparse_err = norm(x - A \\ b)\nprintln(\"Time for sparse solve: $t\")\n\nD = Matrix(A)  # convert to regular matrix\nnorm(x - D \\ b);\nt = @elapsed dense_err = norm(x - D \\ b)\nprintln(\"Time for dense solve: $t\")\n\n@show sparse_err;\n@show dense_err;\n\nExample 8.1.4\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000;\ndensity = 4e-4;\nlambda = 1 ./ (1:n);\nA = sprandsym(n, density, lambda);\nclf,  spy(A)\ntitle('Sparse symmetric matrix')\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude.\n\n[V, D] = eigs(A, 5);    % largest magnitude\n1 ./ diag(D)            % should be 1, 2, 3, 4, 5\n\nNow we find the 4 closest to the value 0.03 in the complex plane.\n\n[V, D] = eigs(A, 4, 0.03);    % closest to 0.03\ndiag(D)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nx = 1 ./ (1:n)';  \nb = A * x;\ntic, sparse_err = norm(x - A\\b), sparse_time = toc\n\nF = full(A);\ntic, dense_err = norm(x - F\\b), dense_time = toc\n\nExample 8.1.4\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nev = 1 / arange(1, n + 1)\nA = FNC.sprandsym(n, density, eigvals=ev)\nprint(f\"density is {A.nnz / prod(A.shape):.3%}\")\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=\"LM\".\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=5, which=\"LM\")    # largest magnitude\nprint(1 / ev)\n\nNow we find the 4 closest to the value 1 in the complex plane, via sigma=1.\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=4, sigma=0.03)    # closest to sigma\nprint(ev)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nfrom scipy.sparse.linalg import spsolve\nx = 1 / arange(1, n + 1)\nb = A @ x\nstart = timer()\nxx = spsolve(A, b)\nprint(f\"sparse time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")\n\nfrom numpy.linalg import solve\nF = A.todense()\nstart = timer()\nxx = solve(F, b)\nprint(f\"dense time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")","type":"content","url":"/structure-1#systems-and-eigenvalues","position":7},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Exercises"},"type":"lvl2","url":"/structure-1#exercises","position":8},{"hierarchy":{"lvl1":"Sparsity and structure","lvl2":"Exercises"},"content":"⌨ Use spdiagm to build the 50\\times 50 matrices\\mathbf{A} =\n\\begin{bmatrix}\n-2 & 1 & & &  \\\\\n1 & -2 & 1 & &  \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & 1 & -2 & 1 \\\\\n& & & 1 & -2\n\\end{bmatrix}, \\qquad\n\\mathbf{B} =\n\\begin{bmatrix}\n-2 & 1 & & & 1 \\\\\n1 & -2 & 1 & &  \\\\\n& \\ddots & \\ddots & \\ddots & \\\\\n& & 1 & -2 & 1 \\\\\n1 & & & 1 & -2\n\\end{bmatrix}.\n\nFor each matrix, use spy and an inspection of the 5\\times 5 submatrices in the corners to verify the correctness of your matrices.\n\n⌨ This problem requires the matrix used in \n\nDemo 8.1.2.\n\nDownload \n\nsmallworld.mat by clicking the link and saving (you may need to fix the file name).using MAT\nA = matread(\"smallworld.mat\")[\"A\"]\n\nDownload \n\nsmallworld.mat by clicking the link and saving (you may need to fix the file name).load smallworld\n\nDownload \n\nsmallworld.mtx by clicking the link and saving (you may need to fix the file name).import scipy.io as spio\nA = spio.mmread(\"smallworld.mtx\")\n\n(a) Find the density of \\mathbf{A} (number of nonzeros divided by total number of elements), \\mathbf{A}^2, \\mathbf{A}^4, and \\mathbf{A}^8. (You should find that it increases with the power of \\mathbf{A}.)\n\n(b) The LU factors tend to at least partially retain sparsity. Find the density of the \\mathbf{L} and \\mathbf{U} factors of \\mathbf{A} using lufact (\n\nAlgorithm 2.4.1). (If you get an error, convert the matrix to dense form first.)\n\n(c) Repeat part (b) for the QR factorization using qrfact (\n\nAlgorithm 3.4.1). (If you get an error, convert the matrix to dense form first.)\n\n⌨ One use of adjacency matrices is to analyze the links between members of a collection. Obtain the adjacency matrix \\mathbf{A} from \n\nDemo 8.1.1 via the following:\n\nDownload \n\nroswell.mat by clicking the link and saving (you may need to fix the file name).using MAT\nA = matread(\"roswell.mat\")[\"A\"]\n\nDownload \n\nroswell.mat by clicking the link and saving (you may need to fix the file name).load roswell\n\nDownload \n\nroswell.mtx by clicking the link and saving (you may need to fix the file name).import scipy.io as spio\nA = spio.mmread(\"roswell.mtx\")\n\nThe matrix catalogs the links between web sites related to the town of Roswell, NM, with A_{ij}=1 if and only if site i links to site j.\n\n(a) Verify numerically that the matrix does not include any links from a site to itself.\n\n(b) Verify numerically that \\mathbf{A} is not symmetric. (Thus, its graph is a directed one.)\n\n(c) How many sites in the group are not pointed to by any other sites in the group?\n\n(d) Which site points to the most other sites?\n\n(e) Which site is pointed to the most by the other sites? This is a crude way to establish the most important site.\n\n(f) There are \n\n27902 possible ways to connect ordered pairs of sites. What fraction of these pairs is connected by a walk of links that is no greater than three in length?\n\n⌨ The graph Laplacian matrix is \\mathbf{L}=\\mathbf{D}-\\mathbf{A}, where \\mathbf{A} is the adjacency matrix and \\mathbf{D} is the degree matrix, a diagonal matrix with diagonal entries d_{jj}=\\sum_{i=1}^n a_{ij}.\n\nFollow the directions in Exercise 3 to obtain an adjacency matrix \\mathbf{A}. Then find the five eigenvalues of \\mathbf{L} having largest magnitude.\n\n⌨ See \n\nExercise 7.1.5 for instructions on loading a matrix \\mathbf{A} that contains information about the appearances of 392,400 actors in 127,823 movies, as given by the Internet Movie Database. Specifically, A_{ij}=1 if actor j appeared in movie i, and all other elements are zero.\n\n(a) What is the maximum number of actors appearing in any one movie?\n\n(b) How many actors appeared in exactly three movies?\n\n(c) Define \\mathbf{C}=\\mathbf{A}^T\\mathbf{A}. How many nonzero entries does \\mathbf{C} have? What is the interpretation of C_{ij}?\n\n⌨  A matrix that arises from the Helmholtz equation for wave propagation can be specified usingA = FNC.poisson(n) - k^2*I;\n\nwhere k is a real parameter. Let n=50.\n\n(a) Let k=1. What is the size of \\mathbf{A}? What is its density?\n\n(b) Still with k=1, use eigs to find the four largest and four smallest (in magnitude) eigenvalues of \\mathbf{A}. (See \n\nDemo 8.1.4 for examples.)\n\n(c) The eigenvalues are all real. Find a value of k so that \\mathbf{A} has exactly three negative eigenvalues.","type":"content","url":"/structure-1#exercises","position":9},{"hierarchy":{"lvl1":"Krylov subspaces"},"type":"lvl1","url":"/subspace","position":0},{"hierarchy":{"lvl1":"Krylov subspaces"},"content":"The power and inverse iterations have a flaw that seems obvious once it is pointed out. Given a seed vector \\mathbf{u}, they produce a sequence of vectors \\mathbf{u}_1,\\mathbf{u}_2,\\ldots that are scalar multiples of \\mathbf{u},\\mathbf{A}\\mathbf{u},\\mathbf{A}^{2}\\mathbf{u},\\ldots, but only the most recent vector is used to produce an eigenvector estimate.\n\nIt stands to reason that we could do no worse, and perhaps much better, if we searched among all linear combinations of the vectors seen in the past. In other words, we seek a solution in the range (column space) of the matrix\\mathbf{K}_m =\n\\begin{bmatrix}\n  \\mathbf{u} & \\mathbf{A}\\mathbf{u} & \\mathbf{A}^{2} \\mathbf{u} & \\cdots & \\mathbf{A}^{m-1} \\mathbf{u}\n\\end{bmatrix}.\n\nKrylov matrix and subspace\n\nGiven n\\times n matrix \\mathbf{A} and n-vector \\mathbf{u}, the mth Krylov matrix is the n\\times m matrix \n\n(8.4.1). The range (i.e., column space) of this matrix is the mth Krylov subspace \\mathcal{K}_m.\n\nIn general, we expect that the dimension of the Krylov subspace \\mathcal{K}_m, which is the rank of \\mathbf{K}_m, equals m, though it may be smaller.","type":"content","url":"/subspace","position":1},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Properties"},"type":"lvl2","url":"/subspace#properties","position":2},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Properties"},"content":"As we have seen with the power iteration, part of the appeal of the Krylov matrix is that it can be generated in a way that fully exploits the sparsity of \\mathbf{A}, simply through repeated matrix-vector multiplication. Furthermore, we have some important mathematical properties.\n\nSuppose \\mathbf{A} is n\\times n, 0<m<n, and a vector \\mathbf{u} is used to generate Krylov subspaces. If \\mathbf{x}\\in\\mathcal{K}_m, then the following hold:\n\n\\mathbf{x} = \\mathbf{K}_m \\mathbf{z} for some \\mathbf{z}\\in\\mathbb{C}^m.\n\n\\mathbf{x} \\in \\mathcal{K}_{m+1}.\n\n\\mathbf{A}\\mathbf{x} \\in \\mathcal{K}_{m+1}.\n\nIf \\mathbf{x}\\in\\mathcal{K}_m, then for some coefficients c_1,\\ldots,c_m,\\mathbf{x} = c_1 \\mathbf{u} + c_2 \\mathbf{A} \\mathbf{u} + \\cdots + c_m \\mathbf{A}^{m-1} \\mathbf{u}.\n\nThus let \\mathbf{z}= \\begin{bmatrix} c_1 & \\cdots & c_m \\end{bmatrix}^T. Also \\mathbf{x}\\in\\mathcal{K}_{m+1}, as we can add zero times \\mathbf{A}^{m}\\mathbf{u} to the sum. Finally,\\mathbf{A}\\mathbf{x} = c_1 \\mathbf{A} \\mathbf{u} + c_2 \\mathbf{A}^{2} \\mathbf{u} + \\cdots + c_m \\mathbf{A}^{m} \\mathbf{u} \\in \\mathcal{K}_{m+1}.","type":"content","url":"/subspace#properties","position":3},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Dimension reduction"},"type":"lvl2","url":"/subspace#dimension-reduction","position":4},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Dimension reduction"},"content":"The problems \\mathbf{A}\\mathbf{x}=\\mathbf{b} and \\mathbf{A}\\mathbf{x}=\\lambda\\mathbf{x} are posed in a very high-dimensional space \\mathbb{R}^n or \\mathbb{C}^n. One way to approximate them is to replace the full n-dimensional space with a much lower-dimensional \\mathcal{K}_m for m\\ll n. This is the essence of the Krylov subspace approach.\n\nFor instance, we can interpret \\mathbf{A}\\mathbf{x}_m\\approx \\mathbf{b} in the sense of linear least-squares—that is, using \n\nTheorem 8.4.1 to let \\mathbf{x}=\\mathbf{K}_m\\mathbf{z},\\min_{\\mathbf{x}\\in\\mathcal{K}_m} \\|  \\mathbf{A}\\mathbf{x}-\\mathbf{b} \\|\n= \\min_{\\mathbf{z}\\in\\mathbb{C}^m} \\| \\mathbf{A}(\\mathbf{K}_m\\mathbf{z})-\\mathbf{b} \\|\n= \\min_{\\mathbf{z}\\in\\mathbb{C}^m} \\| (\\mathbf{A}\\mathbf{K}_m)\\mathbf{z}-\\mathbf{b} \\|.\n\nThe natural seed vector for \\mathcal{K}_m in this case is the vector \\mathbf{b}. In the next example we try to implement \n\n(8.4.4). We do take one precaution: because the vectors \\mathbf{A}^{k}\\mathbf{b} may become very large or small in norm, we normalize after each multiplication by \\mathbf{A}, just as we did in the power iteration.\n\nConditioning of the Krylov matrix\n\nExample 8.4.1\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = [b zeros(100, 29)]\nfor m in 1:29\n    v = A * Km[:, m]\n    Km[:, m+1] = v / norm(v)\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nresid = zeros(30)\nfor m in 1:30\n    z = (A * Km[:, 1:m]) \\ b\n    x = Km[:, 1:m] * z\n    resid[m] = norm(b - A * x)\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nusing Plots\nplot(0:29, resid; m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, L\"\\| b-Ax_m \\|\"),\n    title=\"Residual for linear systems\", legend=:none)\n\nExample 8.4.1\n\nFirst we define a triangular matrix \\mathbf{A} with known eigenvalues and a random vector \\mathbf{b}.\n\nlambda = 10 + (1:100);\nA = diag(lambda) + triu(rand(100), 1); \nb = rand(100, 1);\n\nNext, we build up the first ten Krylov matrices iteratively. In order to keep the columns from growing exponentially in norm, we normalize them as we go. This doesn’t affect the column space of the Krylov matrix, in principle at least.\n\nKm = b;\nfor m = 1:29      \n    v = A * Km(:, m);\n    Km(:, m+1) = v / norm(v);\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nwarning off  \nresid = zeros(30, 1);\nfor m = 1:30  \n    z = (A * Km(:, 1:m)) \\ b;\n    x = Km(:, 1:m) * z;\n    resid(m) = norm(b - A * x);\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nclf\nsemilogy(resid, '.-')\nxlabel('m'),  ylabel('|| b-Ax_m ||')\nset(gca,'ytick',10.^(-6:2:0))\naxis tight, title('Residual for linear systems')\n\nExample 8.4.1\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100)\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = zeros([100, 30])\nKm[:, 0] = b\nfor m in range(29):\n    v = A @ Km[:, m]\n    Km[:, m + 1] = v / norm(v)\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nfrom numpy.linalg import lstsq\nresid = zeros(30)\nresid[0] = norm(b)\nfor m in range(1, 30):\n    z = lstsq(A @ Km[:, :m], b, rcond=None)[0]\n    x = Km[:, :m] @ z\n    resid[m] = norm(b - A @ x)\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nsemilogy(range(30), resid, \"-o\")\nxlabel(\"$m$\"),  ylabel(\"$\\\\| b-Ax_m \\\\|$\")\ntitle((\"Residual for linear systems\"));","type":"content","url":"/subspace#dimension-reduction","position":5},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"The Arnoldi iteration"},"type":"lvl2","url":"/subspace#the-arnoldi-iteration","position":6},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"The Arnoldi iteration"},"content":"The breakdown of convergence in \n\nDemo 8.4.1 is due to a critical numerical defect in our approach: the columns of the Krylov matrix \n\n(8.4.1) increasingly become parallel to the dominant eigenvector, as \n\n(8.2.4) predicts, and therefore to one another. As we saw in \n\nThe QR factorization, near-parallel vectors create the potential for numerical cancellation. This manifests as a large condition number for \\mathbf{K}_m as m grows, eventually creating excessive error when solving the least-squares system.\n\nThe polar opposite of an ill-conditioned basis for \\mathcal{K}_m is an orthonormal one. Suppose we had a thin QR factorization of \\mathbf{K}_m:\\begin{align*}\n  \\mathbf{K}_m  = \\mathbf{Q}_m \\mathbf{R}_m\n  & =\n  \\begin{bmatrix}\n    \\mathbf{q}_1& \\mathbf{q}_2 & \\cdots & \\mathbf{q}_m\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    R_{11} & R_{12} & \\cdots & R_{1m} \\\\\n    0 & R_{22} & \\cdots & R_{2m} \\\\\n    \\vdots & & \\ddots & \\\\\n    0 & 0 & \\cdots & R_{mm}\n  \\end{bmatrix}.\n\\end{align*}\n\nThen the vectors \\mathbf{q}_1,\\ldots,\\mathbf{q}_m are the orthonormal basis we seek for \\mathcal{K}_m. By \n\nTheorem 8.4.1, we know that \\mathbf{A}\\mathbf{q}_m \\in \\mathcal{K}_{m+1}, and therefore\\mathbf{A} \\mathbf{q}_m = H_{1m} \\, \\mathbf{q}_1 + H_{2m} \\, \\mathbf{q}_2 + \\cdots + H_{m+1,m}\\,\\mathbf{q}_{m+1}\n\nfor some choice of the H_{ij}. Note that by using orthonormality, we have\\mathbf{q}_i^* (\\mathbf{A}\\mathbf{q}_m) = H_{im},\\qquad i=1,\\ldots,m.\n\nSince we started by assuming that we know \\mathbf{q}_1,\\ldots,\\mathbf{q}_m, the only unknowns in \n\n(8.4.6) are H_{m+1,m} and \\mathbf{q}_{m+1}. But they appear only as a product, and we know that \\mathbf{q}_{m+1} is a unit vector, so they are uniquely defined (up to sign) by the other terms in the equation.\n\nWe can now proceed iteratively.\n\nArnoldi iteration\n\nGiven matrix \\mathbf{A} and vector \\mathbf{u}:\n\nLet \\mathbf{q}_1= \\mathbf{u} \\,/\\, \\| \\mathbf{u}\\|.\n\nFor m=1,2,\\ldots\n\na. Use \n\n(8.4.7) to find H_{im} for i=1,\\ldots,m.\n\nb. Let\\mathbf{v} = (\\mathbf{A} \\mathbf{q}_m) - H_{1m} \\,\\mathbf{q}_1 - H_{2m}\\, \\mathbf{q}_2 - \\cdots - H_{mm}\\, \\mathbf{q}_m.\n\nc. Let H_{m+1,m}=\\|\\mathbf{v}\\|.\n\nd. Let \\mathbf{q}_{m+1}=\\mathbf{v}\\,/\\,H_{m+1,m}.\n\nReturn the n\\times (m+1) matrix \\mathbf{Q}_{m+1} whose columns are \\mathbf{q}_1,\\dots, \\mathbf{q}_{m+1} and the (m+1)\\times m matrix \\mathbf{H}_m.\n\nThe vectors \\mathbf{q}_1,\\dots, \\mathbf{q}_m are an orthonormal basis for the space \\mathcal{K}_m, which makes them ideal for numerical computations in that space. The matrix \\mathbf{H}_m plays an important role, too, and has a particular “triangular plus” structure,\\mathbf{H}_m = \\begin{bmatrix}\n    H_{11} & H_{12} & \\cdots & H_{1m} \\\\\n    H_{21} & H_{22} & \\cdots & H_{2m} \\\\\n    & H_{32} & \\ddots & \\vdots \\\\\n    & & \\ddots & H_{mm} \\\\\n    & & & H_{m+1,m}\n\\end{bmatrix}\n\nUpper Hessenberg matrix\n\nA matrix \\mathbf{H} is an \n\nupper Hessenberg matrix if H_{ij}=0 whenever i>j+1.\n\nThe identity \n\n(8.4.6) used over all the iterations can be collected into a single matrix equation,\\mathbf{A}\\mathbf{Q}_m = \\mathbf{Q}_{m+1} \\mathbf{H}_m,\n\nwhich is a fundamental identity of Krylov subspace methods.","type":"content","url":"/subspace#the-arnoldi-iteration","position":7},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Implementation"},"type":"lvl2","url":"/subspace#implementation","position":8},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Implementation"},"content":"An implementation of the Arnoldi iteration is given in \n\nFunction 8.4.2. A careful inspection shows that inner nested loop does not exactly implement \n\n(8.4.7) and \n\n(8.4.8). The reason is numerical stability. Though the described and implemented versions are mathematically equivalent in exact arithmetic (see \n\nExercise 6), the approach in \n\nFunction 8.4.2 is more stable.\n\narnoldi\n\nArnoldi iteration\n\n\"\"\"\n    arnoldi(A, u, m)\n\nPerform the Arnoldi iteration for `A` starting with vector `u`, out\nto the Krylov subspace of degree `m`. Returns the orthonormal basis\n(`m`+1 columns) and the upper Hessenberg `H` of size `m`+1 by `m`.\n\"\"\"\nfunction arnoldi(A, u, m)\n    n = length(u)\n    Q = zeros(n, m+1)\n    H = zeros(m+1, m)\n    Q[:, 1] = u / norm(u)\n    for j in 1:m\n        # Find the new direction that extends the Krylov subspace.\n        v = A * Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in 1:j\n            H[i, j] = dot(Q[:, i], v)\n            v -= H[i, j] * Q[:, i]\n        end\n        # Normalize and store the new basis vector.\n        H[j+1, j] = norm(v)\n        Q[:, j+1] = v / H[j+1, j]\n    end\n    return Q, H\nend\n\nArnoldi iteration\n\nfunction [Q, H] = arnoldi(A, u, m)\r\n% ARNOLDI   Arnoldi iteration for Krylov subspaces.\r\n% Input:\r\n%   A    square matrix (n by n)\r\n%   u    initial vector\r\n%   m    number of iterations\r\n% Output: \r\n%   Q    orthonormal basis of Krylov space (n by m+1)\r\n%   H    upper Hessenberg matrix, A*Q(:,1:m)=Q*H (m+1 by m)\r\n\r\nn = length(A);\r\nQ = zeros(n, m+1);  \r\nH = zeros(m+1, m);\r\nQ(:, 1) = u / norm(u);\r\nfor j = 1:m\r\n  % Find the new direction that extends the Krylov subspace.\r\n  v = A * Q(:, j);\r\n  % Remove the projections onto the previous vectors.\r\n  for i = 1:j\r\n    H(i, j) = Q(:, i)' * v;\r\n    v = v - H(i,j) * Q(:,i);\r\n  end\r\n  % Normalize and store the new basis vector.\r\n  H(j+1, j) = norm(v);\r\n  Q(:, j+1) = v / H(j+1, j);\r\nend\n\nArnoldi iteration\n\ndef arnoldi(A, u, m):\n    \"\"\"\n    arnoldi(A, u, m)\n\n    Perform the Arnoldi iteration for A starting with vector u, out to the Krylov\n    subspace of degree m. Return the orthonormal basis (m+1 columns) and the upper\n    Hessenberg H of size m+1 by m.\n    \"\"\"\n    n = u.size\n    Q = np.zeros([n, m + 1])\n    H = np.zeros([m + 1, m])\n    Q[:, 0] = u / np.linalg.norm(u)\n    for j in range(m):\n        # Find the new direction that extends the Krylov subspace.\n        v = A @ Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        # Normalize and store the new basis vector.\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n    return Q, H\n\nArnoldi iteration\n\nExample 8.4.2\n\nHere again is the linear system from \n\nExample 8.4.1.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nWe can use \\mathbf{b} as the seed vector for the Arnoldi iteration.\n\nQ, H = FNC.arnoldi(A, b, 30)\nprintln(\"Q has size $(size(Q))\")\nprintln(\"H has size $(size(H))\")\n\nHere’s one validation of the key identity \n\n(8.4.10).\n\nshould_be_near_zero = opnorm(A * Q[:, 1:20] - Q[:, 1:21] * H[1:21, 1:20])\n\nUsing the Krylov matrix to project the linear system into a Kyrlov subspace in \n\nExample 8.4.1 was unable to get the residual much smaller than about \n\n10-4. But the Arnoldi basis gives us a stable way to work in that subspace and get better results.\n\nz = (A * Q) \\ b\nx = Q * z\n@show resid_norm = norm(b - A * x);\n\nExample 8.4.2\n\nHere again is the linear system from \n\nExample 8.4.1.\n\nlambda = 10 + (1:100);\nA = diag(lambda) + triu(rand(100), 1); \nb = rand(100, 1);\n\nWe can use \\mathbf{b} as the seed vector for the Arnoldi iteration.\n\n[Q, H] = arnoldi(A, b, 30);\ndisp(sprintf(\"Q is %d by %d\", size(Q)))\ndisp(sprintf(\"H is %d by %d\", size(H)))\n\nHere’s one validation of the key identity \n\n(8.4.10).\n\nshould_be_near_zero = norm(A * Q(:, 1:20) - Q(:, 1:21) * H(1:21, 1:20))\n\nUsing the Krylov matrix to project the linear system into a Kyrlov subspace in \n\nExample 8.4.1 was unable to get the residual much smaller than about \n\n10-4. But the Arnoldi basis gives us a stable way to work in that subspace and get better results.\n\nz = (A * Q) \\ b;\nx = Q * z;\nresid_norm = norm(b - A * x)\n\nExample 8.4.2\n\nHere again is the linear system from \n\nExample 8.4.1.\n\nev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100);\n\nWe can use \\mathbf{b} as the seed vector for the Arnoldi iteration.\n\nQ, H = FNC.arnoldi(A, b, 30)\nprint(\"Q has size\", Q.shape)\nprint(\"H has size\", H.shape)\n\nHere’s one validation of the key identity \n\n(8.4.10).\n\nfrom numpy.linalg import norm\nshould_be_near_zero = norm(A @ Q[:, :20] - Q[:, :21] @ H[:21, :20])\nprint(should_be_near_zero)\n\nUsing the Krylov matrix to project the linear system into a Kyrlov subspace in \n\nExample 8.4.1 was unable to get the residual much smaller than about \n\n10-4. But the Arnoldi basis gives us a stable way to work in that subspace and get better results.\n\nz, _, _, _ = linalg.lstsq(A @ Q, b)\nx = Q @ z\nresid_norm = norm(b - A @ x)\nprint(f\"residual norm: {resid_norm:.2e}\")\n\nIn the next section, we revisit the idea of approximately solving \\mathbf{A}\\mathbf{x}=\\mathbf{b} over a Krylov subspace as suggested in \n\nExample 8.4.2. A related idea explored in \n\nExercise 7 is used to approximate the eigenvalue problem for \\mathbf{A}, which is the approach that underlies eigs for sparse matrices.","type":"content","url":"/subspace#implementation","position":9},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Exercises"},"type":"lvl2","url":"/subspace#exercises","position":10},{"hierarchy":{"lvl1":"Krylov subspaces","lvl2":"Exercises"},"content":"✍ Let \\mathbf{A}=\\displaystyle \\begin{bmatrix}\n 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 0\n \\end{bmatrix}.\n\n(a) Find the Krylov matrix \\mathbf{K}_3 for the seed vector \\mathbf{u}=\\mathbf{e}_1.\n\n(b) Find \\mathbf{K}_3 for the seed vector \\mathbf{u}=\\begin{bmatrix}1; \\: 1;\\: 1; \\: 1\\end{bmatrix}.\n\n⌨ For each matrix, make a table of the 2-norm condition numbers \\kappa(\\mathbf{K}_m) for m=1,\\ldots,10. Use a vector of all ones as the Krylov seed.\n\n(a) Matrix from \n\nDemo 8.4.1\n\n(b) \\begin{bmatrix}\n   -2 & 1 & & &  \\\\\n   1 & -2 & 1 & &  \\\\\n   & \\ddots & \\ddots & \\ddots & \\\\\n   & & 1 & -2 & 1 \\\\\n    & & & 1 & -2\n  \\end{bmatrix} \\: (100\\times 100)\n\n(c) \\begin{bmatrix}\n   -2 & 1 & & & 1 \\\\\n   1 & -2 & 1 & &  \\\\\n   & \\ddots & \\ddots & \\ddots & \\\\\n   & & 1 & -2 & 1 \\\\\n   1 & & & 1 & -2\n \\end{bmatrix} \\:(200\\times 200) must stay as #3\n\n✍ Show that if \\mathbf{x}\\in\\mathcal{K}_m, then \\mathbf{x}=p(\\mathbf{A})\\mathbf{u} for a polynomial p of degree at most m-1. (See \n\n(7.2.12) for applying a polynomial to a matrix.)\n\n✍ Compute the asymptotic flop requirements for \n\nFunction 8.4.2. Assume that due to sparsity, a matrix-vector multiplication \\mathbf{A}\\mathbf{u} requires only c n flops for a constant c, rather than the usual O(n^2).\n\n⌨ When Arnoldi iteration is performed on the Krylov subspace generated using the matrix \\mathbf{A}=\\displaystyle \\begin{bmatrix}  2& 1& 1& 0\\\\ 1 &3 &1& 0\\\\ 0& 1& 3& 1\\\\ 0& 1& 1& 2 \\end{bmatrix}, the results can depend strongly on the initial vector \\mathbf{u}.\n\n(a) Apply \n\nFunction 8.4.2 and output Q and H when using the following seed vectors.\n\n(i) \\bigl[1,\\,0,\\,0,\\,0\\bigr] \\qquad (ii) \\bigl[1,\\,1,\\,1,\\,1\\bigr] \\qquad (iii) rand(4)\n\n(b) Can you explain why case (ii) in part (a) cannot finish successfully? (Hint: What line(s) of the function can possibly return NaN when applied to finite values?)must stay as #6\n\n✍ As mentioned in the text, \n\nFunction 8.4.2 does not compute H_{ij} as defined by \n\n(8.4.7), but ratherS_{ij} = \\mathbf{q}_i^* ( \\mathbf{A}\\mathbf{q}_j - S_{1j}\\,\\mathbf{q}_1 - \\cdots -\n    S_{i-1,j}\\,\\mathbf{q}_{i-1} )\n\nfor i=1,\\ldots,j. Show that S_{ij}=H_{ij}. (Hence the function is mathematically equivalent to our Arnoldi formulas.)must stay as #7\n\nOne way to approximate the eigenvalue problem \\mathbf{A}\\mathbf{x}=\\lambda\\mathbf{x} over \\mathcal{K}_m is to restrict \\mathbf{x} to the low-dimensional spaces \\mathcal{K}_m.\n\n(a) ✍ Show starting from \n\n(8.4.10) that\\mathbf{Q}_m^* \\mathbf{A} \\mathbf{Q}_m =  \\tilde{\\mathbf{H}}_m,\n\nwhere \\tilde{\\mathbf{H}}_m is the upper Hessenberg matrix resulting from deleting the last row of \\mathbf{H}_m. What is the size of this matrix?\n\n(b) ✍ Show the reasoning above leads to the approximate eigenvalue problem \\tilde{\\mathbf{H}}_m\\mathbf{z} \\approx \\lambda\\mathbf{z}. (Hint: Start with \\mathbf{A}\\mathbf{x} \\approx \\lambda\\mathbf{x}, and let \\mathbf{x}=\\mathbf{Q}_m\\mathbf{z} before applying part (a).)\n\n(c) ⌨ Apply \n\nFunction 8.4.2 to the matrix of \n\nDemo 8.4.1 using a random seed vector. Compute eigenvalues of \\tilde{\\mathbf{H}}_m for m=1,\\ldots,40, keeping track in each case of the error between the largest of those values (in magnitude) and the largest eigenvalue of \\mathbf{A}. Make a log-linear graph of the error as a function of m.\n\nThe proper pronunciation of “Krylov” is something like “kree-luv,” but American English speakers often say “kreye-lahv.”","type":"content","url":"/subspace#exercises","position":11},{"hierarchy":{"lvl1":"The barycentric formula"},"type":"lvl1","url":"/barycentric","position":0},{"hierarchy":{"lvl1":"The barycentric formula"},"content":"The Lagrange formula \n\n(9.1.4) is useful theoretically but not ideal for computation. For each new value of x, all of the cardinal functions \\ell_k must be evaluated at x, which requires a product of n terms. Thus the total work is O(n^2) for every value of x. Moreover, the formula is numerically unstable. An alternative version of the formula improves on both issues.","type":"content","url":"/barycentric","position":1},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Derivation"},"type":"lvl2","url":"/barycentric#derivation","position":2},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Derivation"},"content":"We again will use the error indicator function Φ from \n\nDefinition 9.1.2,  \\Phi(x) = \\prod_{j=0}^n (x-t_j),\n\nas well as a set of values derived from the nodes.\n\nBarycentric weights\n\nThe barycentric weights for nodes x_0,\\dots,x_n are defined asw_k = \\frac{1}{\\displaystyle \\prod_{\\substack{j=0\\\\j\\neq k}}^n (t_k - t_j)} = \\frac{1}{\\Phi'(x_k)}, \\qquad\nk = 0,\\ldots,n.\n\nThe following formula is the key to efficient and stable evaluation of a polynomial interpolant.\n\nBarycentric interpolation formula\n\nGiven points (t_k,y_k) for k=0,\\ldots,n with all the t_k distinct, the unique polynomial of degree n or less that interpolates the points is  p(x) = \\frac{\\displaystyle \\sum_{k=0}^n \\, \\dfrac{w_k y_k}{x-t_k}  }{\\displaystyle\\sum_{k=0}^n \\, \\dfrac{w_k}{x-t_k}}.\n\nThe Lagrange cardinal polynomial \n\n(9.1.3) can be written as  \\ell_k(x) = \\Phi(x) \\frac{w_k}{x-t_k},\n\nand thus the interpolating polynomial in \n\n(9.1.4) isp(x) = \\Phi(x) \\sum_{k=0}^n \\frac{w_k}{x-t_k} y_k.\n\nObviously, the constant function p(x)\\equiv 1 is its own polynomial interpolant on any set of nodes. The uniqueness of the interpolating polynomial, as proved in \n\nTheorem 9.1.1, allows us to plug y_k=1 for all k into \n\n(9.2.5) to obtain1 = \\Phi(x) \\sum_{k=0}^n \\frac{w_k}{x-t_k}.\n\nThis is solved for \\Phi(x) and put back into \n\n(9.2.5) to get \n\n(9.2.3).\n\nEquation \n\n(9.2.3) is certainly an odd-looking way to write a polynomial! Indeed, it is technically undefined when x equals one of the nodes, but in fact, \\lim_{x\\to t_k} p(x) = y_k, so a continuous extension to the nodes is justified. (See \n\nExercise 3.)\n\nLet us write out the barycentric formula for the interpolating polynomial for the quadratic case (n=2) for \n\nExample 9.1.2.  The weights are computed from \n\n(9.2.2):  w_0 = \\frac{1}{(t_0-t_1)(t_0-t_2)} = \\frac{1}{\\left(0-\\frac{\\pi}{6}\\right)\n\\left(0-\\frac{\\pi}{3}\\right)} = \\frac{18}{\\pi^2},\n\nand similarly, w_1 = -36/\\pi^2 and w_2=18/\\pi^2.\n\nNote that in \n\n(9.2.3), any common factor in the weights cancels out without affecting the results. Hence it’s a lot easier to use w_0=w_2=1 and w_1=-2. Then\\begin{align*}\n    p(x) & = \\frac{\\rule[-1.2em]{0pt}{1em} \\dfrac{w_0}{x-t_0} y_0  + \\dfrac{w_1}{x-t_1} y_1 + \\dfrac{w_2}{x-t_2} y_2 }{ \\rule{0pt}{1.5em} \\dfrac{w_0}{x-t_0} + \\dfrac{w_1}{x-t_1} + \\dfrac{w_2}{x-t_2}}\\\\[1.5ex]\n    & =\\frac{ \\rule[-1.2em]{0pt}{1em}\\left( \\dfrac{1}{x} \\right) 0 -  \\left( \\dfrac{2}{x-\\pi/6} \\right) \\dfrac{1}{\\sqrt{3}} + \\left( \\dfrac{1}{x-\\pi/3} \\right) \\sqrt{3} }{\n        \\rule{0pt}{1.6em} \\dfrac{1}{x} - \\dfrac{2}{x-\\pi/6} + \\dfrac{1}{x-\\pi/3}  }.\n\\end{align*}\n\nFurther algebraic manipulation could return this expression to the classical Lagrange form derived in \n\nExample 9.1.2.","type":"content","url":"/barycentric#derivation","position":3},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Implementation"},"type":"lvl2","url":"/barycentric#implementation","position":4},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Implementation"},"content":"For certain important node distributions, simple formulas for the weights w_k are known. Otherwise, the first task of an implementation is to compute the weights w_k, or more conveniently, w_k^{-1}.\n\nWe begin with the singleton node set \\{t_0\\}, for which one gets the single weight w_0=1. The idea is to grow this singleton into the set of all nodes through a recursive formula. Define \\omega_{k,m-1} (for k< m) as the inverse of the weight for node k using the set \\{t_0,\\ldots,t_{m-1}\\}. Then\\omega_{k,m} = \\displaystyle \\prod_{\\substack{j=0\\\\j\\neq k}}^{m} (t_k - t_j)\n     = \\omega_{k,m-1} \\cdot (t_k-t_{m}), \\qquad k=0,1,\\ldots,m-1.\n\nA direct application of \n\n(9.2.2) can be used to find \\omega_{m,m}. This process is iterated over m=1,\\ldots,n to find w_k=\\omega_{k,n}^{-1}.\n\nIn \n\nFunction 9.2.1 we give an implementation of the barycentric formula for polynomial interpolation.\n\npolyinterp\n\nBarycentric polynomial interpolation\n\n\"\"\"\n    polyinterp(t, y)\n\nConstruct a callable polynomial interpolant through the points in\nvectors `t`, `y` using the barycentric interpolation formula.\n\"\"\"\nfunction polyinterp(t, y)\n    n = length(t) - 1\n    C = (t[n+1] - t[1]) / 4           # scaling factor to ensure stability\n    tc = t / C\n\n    # Adding one node at a time, compute inverses of the weights.\n    ω = ones(n+1)\n    for m in 0:n-1\n        d = tc[1:m+1] .- tc[m+2]    # vector of node differences\n        @. ω[1:m+1] *= d            # update previous\n        ω[m+2] = prod(-d)         # compute the new one\n    end\n    w = 1 ./ ω                      # go from inverses to weights\n\n    # This function evaluates the interpolant at given x.\n    p = function (x)\n        Δ = x .- t\n        if any(iszero.(Δ))     # we're at a node exactly\n            # return the node's data value\n            idx = findfirst(iszero.(Δ))\n            f = y[idx]\n        else\n            terms = w ./ Δ\n            f = sum(y .* terms) / sum(terms)\n        end\n    end\n    return p\nend\n\nAbout the code\n\nAs noted in \n\nExample 9.2.1, a common scaling factor in the weights does not affect the barycentric formula \n\n(9.2.3). In lines 9--10 this fact is used to rescale the nodes in order to avoid eventual tiny or enormous numbers that could go outside the bounds of double precision.\n\nThe return value is a function that evaluates the polynomial interpolant. Within this function, isinf is used to detect either Inf or -Inf, which occurs when x exactly equals one of the nodes. In this event, the corresponding data value is returned.\n\nBarycentric polynomial interpolation\n\nfunction p = polyinterp(t, y)\r\n% POLYINTERP Polynomial interpolation by the barycentric formula.\r\n% Input:\r\n%   t   interpolation nodes (vector, length n+1)\r\n%   y   interpolation values (vector, length n+1)\r\n% Output:\r\n%   p   polynomial interpolant (function)\r\n\r\nt = t(:);                    % column vector\r\nn = length(t) - 1;\r\nC = (t(end) - t(1)) / 4;       % scaling factor to ensure stability\r\ntc = t / C;\r\n\r\n% Adding one node at a time, compute inverses of the weights.\r\nomega = ones(n+1, 1);\r\nfor m = 1:n\r\n    d = (tc(1:m) - tc(m+1));      % vector of node differences\r\n    omega(1:m) = omega(1:m) .* d; % update previous \r\n    omega(m+1) = prod(-d);        % compute the new one\r\nend\r\nw = 1./omega;                     % go from inverses to weights\r\np = @evaluate;\r\n\r\n    function f = evaluate(x)\r\n        % % Compute interpolant, one value of x at a time.\r\n        f = zeros(size(x));\r\n        for j = 1:numel(x)\r\n            terms = w ./ (x(j) - t );\r\n            f(j) = sum(y.*terms) / sum(terms);\r\n        end\r\n        \r\n        % Apply L'Hopital's Rule exactly.\r\n        for j = find( isnan(f(:)) )'           % where divided by zero\r\n            [~, idx] = min( abs(x(j) - t) );   % node closest to x(j)\r\n            f(j) = y(idx);                     % value at node\r\n        end        \r\n    end    % evaluate function\r\n\r\nend    % polyinterp function\n\nBarycentric polynomial interpolation\n\ndef polyinterp(t, y):\n    \"\"\"\n    polyinterp(t, y)\n\n    Return a callable polynomial interpolant through the points in vectors t, y. Uses\n    the barycentric interpolation formula.\n    \"\"\"\n    n = len(t) - 1\n    C = (t[-1] - t[0]) / 4  # scaling factor to ensure stability\n    tc = t / C\n\n    # Adding one node at a time, compute inverses of the weights.\n    omega = np.ones(n + 1)\n    for m in range(n):\n        d = tc[: m + 1] - tc[m + 1]  # vector of node differences\n        omega[: m + 1] = omega[: m + 1] * d  # update previous\n        omega[m + 1] = np.prod(-d)  # compute the new one\n    w = 1 / omega  # go from inverses to weights\n\n    def p(x):\n        # Compute interpolant.\n        z = np.where(x == t)[0]\n        if len(z) > 0:  # avoid dividing by zero\n            # Apply L'Hopital's Rule exactly.\n            f = y[z[0]]\n        else:\n            terms = w / (x - t)\n            f = np.sum(y * terms) / np.sum(terms)\n        return f\n\n    return np.vectorize(p)\n\nAbout the code\n\nAs noted in \n\nExample 9.2.1, a common scaling factor in the weights does not affect the barycentric formula \n\n(9.2.3). In lines 9--10 this fact is used to rescale the nodes in order to avoid eventual tiny or enormous numbers that could go outside the bounds of double precision.\n\nThe return value is a function that evaluates the polynomial interpolant. Within this function, isinf is used to detect either Inf or -Inf, which occurs when x exactly equals one of the nodes. In this event, the corresponding data value is returned.\n\nComputing all n+1 weights in \n\nFunction 9.2.1 takes O(n^2) operations. Fortunately, the weights depend only on the nodes, not the data, and once they are known, computing p(x) at a particular value of x takes just O(n) operations.\n\nBarycentric interpolation\n\nWe show the barycentric formula in action for values from the function \\sin(e^{2x}) at equally spaced nodes in [0,1] with n=3 and n=6.\n\nExample 9.2.2\n\nusing Plots\nf(x) = sin(exp(2x))\nplot(f, 0, 1, label=\"function\", legend=:bottomleft)\n\nt = (0:3) / 3\ny = f.(t)\nscatter!(t, y, color=:black, label=\"nodes\")\n\np = FNC.polyinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"Interpolation on 4 nodes\")\n\nThe curves must intersect at the interpolation nodes. For n=6 the interpolant is noticeably better.\n\nplot(f, 0, 1, label=\"function\", legend=:bottomleft)\nt = (0:6) / 6\ny = f.(t)\np = FNC.polyinterp(t, y)\nscatter!(t, y, color=:black, label=\"nodes\")\nplot!(p, 0, 1, label=\"interpolant\", title=\"Interpolation on 7 nodes\")\n\nExample 9.2.2\n\nf = @(x) sin( exp(2 * x) );\nclf,  fplot(f, [0, 1], displayname=\"function\")\nxlabel('x'),  ylabel('f(x)')   \nlegend(location=\"southwest\");\n\nWe start with 4 equally spaced nodes (n=3).\n\nt = linspace(0, 1, 4)'; \ny = f(t);\np = polyinterp(t, y);\nhold on,  fplot(p, [0, 1], displayname=\"interpolant on 4 nodes\")\nscatter(t, y, 'k', displayname=\"nodes\")\n\nThe curves always intersect at the interpolation nodes. For n=6, the interpolant is noticeably better.\n\ncla,  fplot(f, [0, 1], displayname=\"function\")\nt = linspace(0, 1, 7)'; \ny = f(t);\np = polyinterp(t, y);\nhold on,  fplot(p, [0, 1], displayname=\"interpolant on 7 nodes\")\nscatter(t, y, 'k', displayname=\"nodes\")\n\nExample 9.2.2\n\nf = lambda x: sin(exp(2 * x))\nx = linspace(0, 1, 500)\nfig, ax = subplots()\nax.plot(x, f(x), label=\"function\")\n\nt = linspace(0, 1, 4)\ny = f(t)\np = FNC.polyinterp(t, y)\n\nax.plot(x, p(x), label=\"interpolant\")\nax.plot(t, y, \"ko\", label=\"nodes\")\nax.legend()\nax.set_title(\"Interpolation on 4 nodes\")\nfig\n\nThe curves must intersect at the interpolation nodes. For n=6 the interpolant is noticeably better.\n\nplot(x, f(x), label=\"function\")\nt = linspace(0, 1, 7)\ny = f(t)\np = FNC.polyinterp(t, y)\nplot(x, p(x), label=\"interpolant\")\nplot(t, y, \"ko\", label=\"nodes\")\nlegend(),  title(\"Interpolation on 7 nodes\");","type":"content","url":"/barycentric#implementation","position":5},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Stability"},"type":"lvl2","url":"/barycentric#stability","position":6},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Stability"},"content":"You might suspect that as the evaluation point x approaches a node t_k, subtractive cancellation error will creep into the barycentric formula because of the term 1/(x-t_k). While such errors do occur, they turn out not to cause trouble, because the same cancellation happens in the numerator and denominator. In fact, the stability of the barycentric formula has been proved, though we do not give the details.","type":"content","url":"/barycentric#stability","position":7},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Exercises"},"type":"lvl2","url":"/barycentric#exercises","position":8},{"hierarchy":{"lvl1":"The barycentric formula","lvl2":"Exercises"},"content":"✍ (a) Find the barycentric weights for the nodes t_0=0, t_1=1, t_2=3.\n\n(b) Compute the interpolant at x=2 for the nodes in part (a) and the data y_0=-2, y_1=2, y_2=1.\n\n✍ For each case of \n\nExercise 9.1.1, write out the barycentric form of the interpolating polynomial.\n\n✍  Show using L’Hôpital’s rule on \n\n(9.2.3) that p(t_i)=y_i for all i=0,\\ldots,n.\n\n⌨ In each case, use \n\nFunction 9.2.1 to interpolate the given function using n+1 evenly spaced nodes in the given interval. Plot each interpolant together with the exact function.\n\n(a) f(x) = \\ln (x), \\quad n = 2,3,4, \\quad x\\in [1,10]\n\n(b) f(x) = \\tanh (x), \\quad n = 2,3,4, \\quad x \\in [0-3,2]\n\n(c) f(x) = \\cosh (x), \\quad n = 2,3,4, \\quad x \\in [-1,3]\n\n(d) f(x) = |x|, \\quad n = 3,5,7, \\quad x \\in [-2,1]\n\n⌨ Using code from \n\nFunction 9.2.1, compute the barycentric weights numerically using n+1 equally spaced nodes in [-1,1] for n=30, n=60, and n=90. On a single graph, plot |w_i| as a function of t_i on a log-linear scale. (The resulting graphs are an indication of the trouble with equally spaced nodes that is explored in \n\nStability of polynomial interpolation.)\n\n✍ Derive this fact stated implicitly in \n\n(9.2.2):\\Phi'(x_k) = \\prod_{\\substack{j=0\\\\j\\neq k}}^n (t_k - t_j).\n\n✍ Use \n\n(9.2.4) to show that if j\\neq k,\\ell_k'(x_j) = \\frac{w_k}{w_j(x_j-x_k)}.","type":"content","url":"/barycentric#exercises","position":9},{"hierarchy":{"lvl1":"Improper integrals"},"type":"lvl1","url":"/improper","position":0},{"hierarchy":{"lvl1":"Improper integrals"},"content":"When the interval of integration or the integrand itself is unbounded, we say an integral is improper. Improper integrals present particular challenges to numerical computation.","type":"content","url":"/improper","position":1},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Infinite interval"},"type":"lvl2","url":"/improper#infinite-interval","position":2},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Infinite interval"},"content":"When the integration domain is (-\\infty,\\infty), the integrand has to decay as x \\to \\pm \\infty in order for the improper integral to be finite. This fact brings up the possibility of truncating the domain:\\int_{-\\infty}^{\\infty} f(x)\\, dx \\approx  \\int_{-M}^{M} f(x)\\, dx.\n\nThis integral can be discretized finitely by, say, the trapezoid formula, or an adaptive integrator. However, this approach can be inefficient.\n\nConsider the integral of f(x)=1/(1+x^2),\\int_{-\\infty}^\\infty \\frac{1}{1+x^{2}}\\, dx = \\pi.\n\nIn this case we can easily estimate the effect of truncation on the result. For large M,\\int_M^\\infty f\\,dx \\approx \\int_M^\\infty x^{-2}\\,dx =  M^{-1}.\n\nThe same estimate applies to the integral over (-\\infty,-M). To get eight digits of accuracy, for instance, we need to truncate with M > 2 \\times 10^8.","type":"content","url":"/improper#infinite-interval","position":3},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Double exponential transformation"},"type":"lvl2","url":"/improper#double-exponential-transformation","position":4},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Double exponential transformation"},"content":"In order to do better than direct truncation, we want to encourage the function to decay faster. In practice this means a change of variable, x(t). If |x(t)| grows rapidly as |t| \\to \\infty, then f(x(t)) will decay more rapidly in t than in x.\n\nOne way to accomplish this feat is to use  x(t) = \\sinh\\left(  \\sinh t \\right).\n\nNoting the asymptotic behavior as t \\rightarrow \\pm\\infty that  \\left| \\sinh(t) \\right| \\sim \\frac{1}{2} e^{ |t| },\n\nwe find that in the same limits,x(t) \\approx \\pm \\frac{1}{2} \\exp\\left( \\frac{1}{2} e^{ |t| } \\right).\n\nThus, \n\n(9.7.4) is often referred to as a double exponential transformation.\n\nBy the chain rule,\\begin{split}\n\\int_{-\\infty}^\\infty f(x)\\, dx &= \\int_{-\\infty}^\\infty f(x(t))\\frac{dx}{dt}\\, dt \\\\\n  &= \\int_{-\\infty}^\\infty f(x(t))\\, \\cosh\\left( \\sinh t \\right)  \\cosh t  \\, dt.\n\\end{split}\n\nThe exponential terms introduced by the chain rule grow double exponentially, but the more rapid decay of f in the new variable more than makes up for this.\n\nDecay by transformation\n\nConsider again f(x)=1/(1+x^2) from \n\nExample 9.7.1, with x(t) given by \n\n(9.7.4). As t\\to\\infty,f(x(t)) \\approx x^{-2} \\approx 4 \\exp\\left( -e^{t} \\right).\n\nThe chain rule terms in \n\n(9.7.7) become\\cosh\\left( \\sinh t \\right)  \\cosh t \n\\approx \\frac{1}{2} \\exp\\left( \\frac{1}{2} e^t  \\right)  \\cdot \\frac{1}{2} e^t,\n\nyielding a product that is roughly2 \\exp\\left( -\\frac{1}{2} e^t  \\right).\n\nThe total integrand in \n\n(9.7.7) therefore has double exponential decay in t, essentially because of the squaring of x in the denominator of f. The same result holds as t\\to-\\infty.\n\nExample 9.7.2\n\nusing Plots\nf(x) = 1 / (1 + x^2)\nplot(f, -4, 4, layout=(2, 1),\n    xlabel=L\"x\", \n    yaxis=(:log10, L\"f(x)\", (1e-16, 2)),\n    title=\"Original integrand\")\n\nξ(t) = sinh( π * sinh(t) / 2 )\ndξ_dt(t) = π/2 * cosh(t) * cosh(π * sinh(t) / 2)\ng(t) = f(ξ(t)) * dξ_dt(t)\n\nplot!(g,-4, 4, subplot=2,\n    xlabel=L\"t\",\n    yaxis=(:log10, L\"f(x(t))\\cdot x'(t)\", (1e-16, 2)),\n    title=\"Transformed integrand\")\n\nThis graph suggests that we capture all of the integrand values that are larger than machine epsilon by integrating in t from -4 to 4.\n\nExample 9.7.2\n\nf = @(x) 1 ./ (1 + x.^2);\nclf,  subplot(2, 1, 1)\nfplot(f, [-4, 4]);  set(gca, 'yscale', 'log') \nxlabel('x'),  ylabel('f(x)'),  ylim([1e-20, 1])  \ntitle('Original integrand')   \n\nx = @(t) sinh( pi * sinh(t) / 2 );\nchain = @(t) pi/2 * cosh(t) .* cosh( pi * sinh(t) / 2 );\nintegrand = @(t) f(x(t)) .* chain(t);\nsubplot(2, 1, 2)\nfplot(integrand, [-4, 4]);  set(gca, 'yscale', 'log') \nxlabel('t'), ylabel('f(x(t))'),  ylim([1e-20, 1])  \ntitle('Transformed integrand')\n\nThis graph suggests that we capture all of the integrand values that are larger than machine epsilon by integrating in t from -4 to 4.\n\nExample 9.7.2\n\nf = lambda x: 1 / (1 + x**2)\nx = linspace(-4, 4, 500)\nsubplot(2, 1, 1)\nplot(x, f(x)),  yscale('log')\nxlabel('x'),  ylabel('f(x)'),  ylim([1e-16, 1])  \ntitle('Original integrand')   \n\nxi = lambda t: sinh( pi * sinh(t) / 2 )\ndxi_dt = lambda t: pi/2 * cosh(t) * cosh( pi * sinh(t) / 2 )\nintegrand = lambda t: f(xi(t)) * dxi_dt(t)\nsubplot(2, 1, 2)\nplot(x, integrand(x)),  yscale('log')\nxlabel('t'),  ylabel('f(x(t))'),  ylim([1e-16, 1])  \ntitle('Transformed integrand')\n\nThis graph suggests that we capture all of the integrand values that are larger than machine epsilon by integrating in t from -4 to 4.\n\nFunction 9.7.1 implements double exponential integration by applying the adaptive integrator \n\nFunction 5.7.1 to \n\n(9.7.7). It truncates the interval to -M\\le t \\le M by increasing M until the integrand is too small to matter relative to the error tolerance.\n\nintinf\n\nIntegration over (-\\infty,\\infty)\n\n\"\"\"\n    intinf(f, tol)\n\nPerform adaptive doubly-exponential integration of function `f`\nover (-Inf,Inf), with error tolerance `tol`. Returns the integral\nestimate and a vector of the nodes used.\n\"\"\"\nfunction intinf(f, tol)\n    x = t -> sinh(sinh(t))\n    dx_dt = t -> cosh(t) * cosh(sinh(t))\n    g = t -> f(x(t)) * dx_dt(t)\n\n    # Find where to truncate the integration interval.\n    M = 3\n    while (abs(g(-M)) > tol / 100) || (abs(g(M)) > tol / 100)\n        M += 0.5\n        if isinf(x(M))\n            @warn \"Function may not decay fast enough.\"\n            M -= 0.5\n            break\n        end\n    end\n\n    I, t = intadapt(g, -M, M, tol)\n    return I, x.(t)\nend\n\nAbout the code\n\nThe test isinf(x(M)) in line 17 checks whether x(M) is larger than the maximum double-precision value, causing it to overflow to Inf.\n\nIntegration over (-\\infty,\\infty)\n\nfunction [I, x] = intinf(f, tol)\r\n% INTINF   Adaptive doubly exponential integration over (-inf,inf).\r\n% Input:\r\n%   f   integrand (function)\r\n%   tol error tolerance (positive scalar)\r\n% Output:\r\n%   I   approximation to intergal(f) over (-inf,inf)\r\n%   x   evaluation nodes (vector) \r\n\r\nxi = @(t) sinh(sinh(t));\r\ndxi_dt = @(t) cosh(t) .* cosh(sinh(t));\r\ng = @(t) f(xi(t)) .* dxi_dt(t);\r\n\r\n% Find where to truncate the integration interval.\r\nM = 3;\r\nwhile (abs(g(-M)) > tol/100) || (abs(g(M)) > tol/100)\r\n    M = M + 0.5;\r\n    if isinf(xi(M)) \r\n        warning(\"Function may not decay fast enough.\")\r\n        M = M - 0.5;\r\n        break\r\n    end\r\nend\r\n\r\n[I, t] = intadapt(g, -M, M, tol);\r\nx = xi(t);\r\nend\n\nIntegration over (-\\infty,\\infty)\n\ndef intinf(f, tol):\n    \"\"\"\n    intinf(f, tol)\n\n    Perform doubly-exponential integration of function f over (-Inf,Inf), using\n    error tolerance tol. Return integral and a vector of the nodes used.\n    \"\"\"\n    xi = lambda t: np.sinh(np.sinh(t))\n    dxi_dt = lambda t: np.cosh(t) * np.cosh(np.sinh(t))\n    g = lambda t: f(xi(t)) * dxi_dt(t)\n    M = 3\n    while (abs(g(-M)) > tol/100) or (abs(g(M)) > tol/100):\n        M += 0.5\n        if np.isinf(xi(M)):\n            warnings.warn(\"Function may not decay fast enough.\")\n            M -= 0.5\n            break\n\n    I, t = intadapt(g,-M,M,tol)\n    x = xi(t)\n    return I, x\n\nAbout the code\n\nThe test isinf(x(M)) in line 17 checks whether x(M) is larger than the maximum double-precision value, causing it to overflow to Inf.\n\nInfinite interval\n\nWe compare direct truncation in x to the double exponential method of \n\nFunction 9.7.1 for f(x)=1/(1+x^2).\n\nExample 9.7.3\n\nf(x) = 1 / (1 + x^2)\ntol = [1 / 10^d for d in 5:0.5:14]\nerr = zeros(length(tol), 2)\nlen = zeros(Int, length(tol), 2)\nfor (i, tol) in enumerate(tol)\n    I1, x1 = FNC.intadapt(f, -2/tol, 2/tol, tol)\n    I2, x2 = FNC.intinf(f, tol)\n    @. err[i,:] = abs(π - [I1, I2])\n    @. len[i,:] = length([x1, x2])\nend\nplot(len, err, m=:o, label=[\"direct\" \"double exponential\"])\nn = [100, 10000]\nplot!(n, 1000n.^(-4), \n    color=:black,  l=:dash,\n    label=\"fourth-order\",  legend=:bottomleft,\n    xaxis=(:log10, \"number of nodes\"), \n    yaxis=(:log10, \"error\"),\n    title=\"Comparison of integration methods\")\n\nBoth methods are roughly fourth-order due to Simpson’s formula in the underlying adaptive integration method. At equal numbers of evaluation nodes, however, the double exponential method is consistently 2--3 orders of magnitude more accurate.\n\nExample 9.7.3\n\nf = @(x) 1 ./ (1 + x.^2);\ntol = 1 ./ 10.^(5:0.5:14);\nerr = zeros(length(tol), 2);\nlen = zeros(length(tol), 2);\nfor k = 1:length(tol)\n    [I1, x1] = intadapt(f, -2/tol(k), 2/tol(k), tol(k));\n    [I2, x2] = intinf(f, tol(k));\n    err(k, :) = abs(pi - [I1, I2]);\n    len(k, :) = [length(x1), length(x2)];\nend\nclf,  loglog(len, err, 'o-')   \nn = [100, 10000];\nhold on,  loglog(n, 1000 * n.^(-4), 'k--')  % 4th order error\nlegend(\"direct\", \"double exponential\", \"4th order\", location=\"southwest\")\ntitle((\"Comparison of integration methods\"));\n\nBoth methods are roughly fourth-order due to Simpson’s formula in the underlying adaptive integration method. At equal numbers of evaluation nodes, however, the double exponential method is consistently 2–3 orders of magnitude more accurate.\n\nExample 9.7.3\n\nf = lambda x: 1 / (1 + x**2)\nexact = pi\ntol = array([1 / 10**d for d in arange(5, 14, 0.5)])\nerr = zeros((tol.size, 2))\nlength = zeros((tol.size, 2))\nfor k in range(tol.size):\n    I1, x1 = FNC.intadapt(f, -2/tol[k], 2/tol[k], tol[k])\n    I2, x2 = FNC.intinf(f, tol[k])\n    err[k] = abs(exact - array([I1, I2]))\n    length[k] = [x1.size, x2.size]\nloglog(length, err, \"-o\")\n# plot(len,err,m=:o,label=[\"direct\" \"double exponential\"])\nn = array([100, 10000])\nloglog(n, 1000 / n**4, 'k--')\nxlabel(\"number of nodes\"),  ylabel(\"error\")\ntitle(\"Comparison of integration methods\")\nlegend([\"direct\", \"double exponential\", \"4th-order\"], loc=\"lower left\");\n\nBoth methods are roughly fourth-order due to Simpson’s formula in the underlying adaptive integration method. At equal numbers of evaluation nodes, however, the double exponential method is consistently 2--3 orders of magnitude more accurate.","type":"content","url":"/improper#double-exponential-transformation","position":5},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Integrand singularity"},"type":"lvl2","url":"/improper#integrand-singularity","position":6},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Integrand singularity"},"content":"If f asymptotically approaches infinity as x approaches an integration endpoint, its exact integral may or may not be finite. If f is integrable, then the part of the integration interval near the singularity needs to be more finely resolved than the rest of it.\n\nLet’s consider\\int_0^1 f(x)\\,dx,\n\nwhere f and/or a derivative of f is unbounded at the left endpoint, zero. The change of variable  x(t) = \\frac{2}{1+\\exp(2 \\sinh t)}\n\nsatisfies x(0)=1 and x\\to 0^+ as t\\to \\infty, thereby transforming the integration interval to t\\in(0,\\infty) and placing the singularity at infinity. The chain rule implies\\begin{split}\n  \\int_{0}^1 f(x)\\, dx &= \\int_{0}^\\infty f(x(t)) \\frac{dx}{dt}\\, dt \\\\\n  &= \\int_{0}^\\infty f(x(t)) \\frac{\\cosh t}{\\cosh(\\sinh t)^2}  \\,  dt.\n\\end{split}\n\nNow the growth of f and \\cosh t together are counteracted by the double exponential denominator, allowing easy truncation of \n\n(9.7.13). This variable transformation is paired with adaptive integration in \n\nFunction 9.7.2.\n\nintsing\n\nIntegration with endpoint singularities\n\n\"\"\"\n    intsing(f, tol)\n\nAdaptively integrate function `f` over (0,1), where `f` may be\nsingular at zero, with error tolerance `tol`. Returns the\nintegral estimate and a vector of the nodes used.\n\"\"\"\nfunction intsing(f, tol)\n    x = t -> 2 / (1 + exp(2sinh(t)))\n    dx_dt = t -> cosh(t) / cosh(sinh(t))^2\n    g = t -> f(x(t)) * dx_dt(t)\n\n    # Find where to truncate the integration interval.\n    M = 3\n    while abs(g(M)) > tol / 100\n        M += 0.5\n        if iszero(x(M))\n            @warn \"Function may grow too rapidly.\"\n            M -= 0.5\n            break\n        end\n    end\n\n    I, t = intadapt(g, 0, M, tol)\n    return I, x.(t)\nend\n\nAbout the code\n\nThe test iszero(x(M)) in line 17 checks whether x(M) is less than the smallest positive double-precision value, causing it to underflow to zero.\n\nIntegration with endpoint singularities\n\nfunction [I, x] = intsing(f, tol)\r\n% INTSING   Adaptively integrate a function with a singularity at the left endpoint.\r\n% Input:\r\n%   f   integrand  (function)\r\n%   tol error tolerance (positive scalar)\r\n% Output:\r\n%   I   approximation to integral(f) over (0,1)\r\n%   x   evaluation nodes (vector)\r\n\r\nxi = @(t) 2 ./ (1 + exp( 2*sinh(t) ));\r\ndxi_dt = @(t) cosh(t) ./ cosh( sinh(t) ).^2;\r\ng = @(t) f(xi(t)) .* dxi_dt(t);\r\n\r\n% Find where to truncate the integration interval.\r\nM = 3;\r\nwhile abs(g(M)) > tol/100\r\n    M = M + 0.5;\r\n    if xi(M) == 0\r\n        warning(\"Function may grow too rapidly.\")\r\n        M = M - 0.5;\r\n        break\r\n    end\r\nend\r\n\r\n[I, t] = intadapt(g, 0, M, tol);\r\nx = xi(t);\r\nend\n\nIntegration with endpoint singularities\n\ndef intsing(f, tol):\n    \"\"\"\n    intsing(f, tol)\n\n    Adaptively integrate function f over (0,1), where f may be \n    singular at zero, with error tolerance tol. Returns the\n    integral estimate and a vector of the nodes used.\n    \"\"\"\n    xi = lambda t: 2 / (1 + np.exp( 2*np.sinh(t) ))\n    dxi_dt = lambda t: np.cosh(t) / np.cosh(np.sinh(t))**2\n    g = lambda t: f(xi(t)) * dxi_dt(t)\n    # Find where to truncate the integration interval.\n    M = 3\n    while abs(g(M)) > tol/100:\n        M += 0.5\n        if xi(M) == 0:\n            warnings.warn(\"Function may grow too rapidly.\")\n            M -= 0.5\n            break\n\n    I, t = intadapt(g, 0, M, tol)\n    x = xi(t)\n    return I, x\n\nAbout the code\n\nThe test iszero(x(M)) in line 17 checks whether x(M) is less than the smallest positive double-precision value, causing it to underflow to zero.\n\nSingularity at an endpoint\n\nLet’s use \n\nFunction 9.7.2 to compute\\int_0^{0.01} \\frac{1}{\\sqrt{x}}\\, dx.\n\nSince the integration interval is not [0,1], we must first use the change of variable s=100t, yielding\\int_0^{1} \\frac{1}{10\\sqrt{s}}\\, ds = 0.2.\n\nIn order to use \n\nFunction 5.7.1, we must truncate on the left to avoid evaluation at zero, where f is infinite. Since the integral from 0 to δ is 20\\sqrt{\\delta}, we use \\delta=(\\epsilon/20)^2 to achieve error tolerance ε.\n\nExample 9.7.4\n\nf(x) = 1 / (10 * sqrt(x))\ntol = [1 / 10^d for d in 5:0.5:14]\nerr = zeros(length(tol), 2)\nlen = zeros(Int, length(tol), 2)\nfor (i, tol) in enumerate(tol)\n    I1, x1 = FNC.intadapt(f, (tol/20)^2, 1, tol)\n    I2, x2 = FNC.intsing(f, tol)\n    @. err[i, :] = abs(0.2 - [I1, I2])\n    @. len[i, :] = length([x1, x2])\nend\nplot(len, err, m=:o, label=[\"direct\" \"double exponential\"])\nn = [30, 3000]\nplot!(n, 30n.^(-4);\n    color=:black,  l=:dash,\n    label=\"fourth-order\",  legend=:bottomleft,\n    xaxis=(:log10, \"number of nodes\"),\n    yaxis=(:log10, \"error\"),\n    title=\"Comparison of integration methods\")\n\nAs in \n\nDemo 9.7.3, the double exponential method is more accurate than direct integration by a few orders of magnitude. Equivalently, the same accuracy can be reached with many fewer nodes.\n\nExample 9.7.4\n\nf = @(x) 1 ./ (10 * sqrt(x));\ntol = 1 ./ 10.^(5:0.5:14);\nerr = zeros(length(tol), 2);\nlen = zeros(length(tol), 2);\nfor k = 1:length(tol)\n    [I1, x1] = intadapt(f, (tol(k)/20)^2, 1, tol(k));\n    [I2, x2] = intsing(f, tol(k));\n    err(k, :) = abs(0.2 - [I1, I2]);\n    len(k, :) = [length(x1), length(x2)];\nend\nclf,  loglog(len, err, 'o-')   \nn = [30, 3000];\nhold on,  loglog(n, 30 * n.^(-4), 'k--')  % 4th order error\nlegend(\"direct\", \"double exponential\", \"4th order\", location=\"southwest\")\ntitle((\"Comparison of integration methods\"));\n\nAs in \n\nDemo 9.7.3, the double exponential method is more accurate than direct integration by a few orders of magnitude. Equivalently, the same accuracy can be reached with many fewer nodes.\n\nExample 9.7.4\n\nf = lambda x: 1 / (10 * sqrt(x))\nexact = 0.2\ntol = array([1 / 10**d for d in arange(5, 14, 0.5)])\nerr = zeros((tol.size, 2))\nlength = zeros((tol.size, 2))\nfor k in range(tol.size):\n    I1, x1 = FNC.intadapt(f, (tol[k]/20)**2, 1, tol[k])\n    I2, x2 = FNC.intsing(f, tol[k])\n    err[k] = abs(exact - array([I1, I2]))\n    length[k] = [x1.size, x2.size]\nloglog(length, err, \"-o\")\n# plot(len,err,m=:o,label=[\"direct\" \"double exponential\"])\nn = array([100, 10000])\nloglog(n, 30 / n**4, 'k--')\nxlabel(\"number of nodes\"),  ylabel(\"error\")\ntitle(\"Comparison of integration methods\")\nlegend([\"direct\", \"double exponential\", \"4th-order\"], loc=\"lower left\");\n\nAs in \n\nDemo 9.7.3, the double exponential method is more accurate than direct integration by a few orders of magnitude. Equivalently, the same accuracy can be reached with many fewer nodes.\n\nDouble exponential integration is an effective general-purpose technique for improper integrals that usually outperforms interval truncation in the original variable. There are specialized methods tailored to specific singularity types that can best it, but those require more analytical work to use properly.","type":"content","url":"/improper#integrand-singularity","position":7},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Exercises"},"type":"lvl2","url":"/improper#exercises","position":8},{"hierarchy":{"lvl1":"Improper integrals","lvl2":"Exercises"},"content":"⌨ Use \n\nFunction 9.7.1 to estimate the given integral with error tolerances 10^{-3},10^{-6},10^{-9},10^{-12}. For each result, show the actual error and the number of nodes used.\n\n(a) \\displaystyle\\int_{-\\infty}^\\infty \\dfrac{1}{1+x^2+x^4}\\, dx = \\dfrac{\\pi}{\\sqrt{3}}\n\n(b) \\displaystyle\\int_{-\\infty}^\\infty e^{-x^2}\\cos(x)\\, dx = e^{-1/4}\\sqrt{\\pi}\n\n(c) \\displaystyle\\int_{-\\infty}^\\infty (1+x^2)^{-2/3}\\, dx = \\dfrac{\\sqrt{\\pi}\\,\\Gamma(1/6)}{\\Gamma(2/3)}  (use gamma() for \\Gamma())\n\n⌨ Use \n\nFunction 9.7.2 to estimate the given integral, possibly after rewriting the integral into the form \n\n(9.7.11) with a left-endpoint singularity. Use error tolerances 10^{-3},10^{-6},10^{-9},10^{-12}, and for each result, show the actual error and the number of nodes used.\n\n(a) \\displaystyle\\int_{0}^1 (\\log x)^2\\, dx = 2\n\n(b) \\displaystyle\\int_{0}^{\\pi/4} \\sqrt{\\tan(x)}\\, dx = \\dfrac{\\pi}{\\sqrt{2}}\n\n(c) \\displaystyle\\int_{0}^1 \\frac{1}{\\sqrt{1-x^2}}\\, dx = \\dfrac{\\pi}{2}\n\nFor integration on a semi-infinite interval such as x\\in [0,\\infty), another double exponential transformation is useful: x(t)=\\exp\\left( \\sinh t \\right).\n\n(a) ✍ Show that t\\in(-\\infty,\\infty) is mapped to x\\in (0,\\infty).\n\n(b) ✍ Derive an analog of \n\n(9.7.7) for the chain rule on \\int_0^\\infty f(x)\\,dx.\n\n(c) ✍ Show that truncation of t to [-M,M] will truncate x to [1/\\mu,\\mu] for some positive μ.\n\n(d) ⌨ Write a function intsemi(f,tol) for the semi-infinite integration problem. Test it on the integral\\displaystyle\\int_0^\\infty \\frac{e^{-x}}{\\sqrt{x}}\\,dx = \\sqrt{\\pi}.","type":"content","url":"/improper#exercises","position":9},{"hierarchy":{"lvl1":"Next steps"},"type":"lvl1","url":"/next-8","position":0},{"hierarchy":{"lvl1":"Next steps"},"content":"The topics in this chapter come mainly under the heading of approximation theory, on which there are many good references. A thorough introduction to polynomial interpolation and approximation, emphasizing the complex plane and going well beyond the basics given here, is \n\nTrefethen (2013). A more thorough treatment of the least-squares case is given in \n\nDavis (1963).\n\nA thorough comparison of Clenshaw–Curtis and Gauss–Legendre integration is given in \n\nTrefethen (2008).\n\nThe literature on the FFT is vast; a good place to start is with the brief and clear original paper by Cooley and Tukey \n\nCooley & Tukey (1965). A historical perspective by Cooley on the acceptance and spread of the method can be found at the SIAM History Project at \n\nhttp://​history​.siam​.org​/cooley​.htm (reprinted from Nash \n\nNash (1990)).  The FFT has a long and interesting history.\n\nDoubly exponential integration, by contrast, is not often included in books. The original idea is presented in the readable paper \n\nTakahasi & Mori (1973), and the method is compared to Gaussian quadrature in \n\nBailey et al. (2005), which is the source of some of the integration exercises in \n\nImproper integrals.","type":"content","url":"/next-8","position":1},{"hierarchy":{"lvl1":"Orthogonal polynomials"},"type":"lvl1","url":"/orthogonal","position":0},{"hierarchy":{"lvl1":"Orthogonal polynomials"},"content":"Interpolation is not the only way to use polynomials for global approximation of functions. In \n\nFitting functions to data we saw how to find least-squares polynomial fits to data by solving linear least-squares matrix problems. This idea can be extended to fitting functions.\n\nContinuous least-squares fitting\n\nExample 9.4.1\n\nLet’s approximate e^x over the interval [−1,1]. We can sample it at, say, 15 points, and find the best-fitting straight line to that data.\n\nusing Plots\nplot(exp, -1, 1, label=\"function\")\nt = range(-1, 1, 15)\ny = exp.(t)\nV = [ti^j for ti in t, j in 0:1]  # Vandermonde-ish\nc = V \\ y\nplot!(t -> c[1] + c[2] * t, -1, 1;\n    label=\"linear fit for 15 points\", legend=:bottomright,\n    xaxis=(\"x\"),  yaxis=(\"value\"),\n    title=\"Least-squares fit of exp(x)\")\n\nThere’s nothing special about 20 points. Choosing more doesn’t change the result much.\n\nt = range(-1, 1, 150)\ny = exp.(t)\nV = [ ti^j for ti in t, j=0:1 ]\nc = V \\ y\nplot!(t -> c[1] + c[2]*t, -1, 1,\n    label=\"linear fit for 150 points\",  legend=:bottomright,\n    xaxis=(\"x\"),  yaxis=(\"value\"),\n    title=\"Least-squares fit of exp(x)\")\n\nThis situation is unlike interpolation, where the degree of the interpolant increases with the number of nodes. Here, the linear fit is apparently approaching a limit that we may think of as a continuous least-squares fit.\n\nn = 40:60:400\nslope = zeros(size(n))\nintercept = zeros(size(n))\n\nfor (k, n) in enumerate(n)\n    t = range(-1, 1, n)\n    y = exp.(t)\n    V = [ ti^j for ti in t, j in 0:1 ]\n    c = V \\ y\n    intercept[k], slope[k] = c\nend\n\nlabels = [\"n\", \"intercept\", \"slope\"]\n@pt :header=labels, [n intercept slope]\n\nExample 9.4.1\n\nLet’s approximate e^x over the interval [−1,1]. We can sample it at, say, 15 points, and find the best-fitting straight line to that data.\n\nclf;  fplot(@exp, [-1, 1], displayname=\"function\")\nt = linspace(-1, 1, 15)';\ny = exp(t);\nV = [t.^0, t];\nc = V \\ y;\np = @(t) c(1) + c(2)*t;\n\nhold on,  fplot(p, [-1, 1], displayname=\"LS fit at 15 points\")\ntitle('Least-squares fit to samples of exp(x)')    \nxlabel('x'),  ylabel('f(x)')    \nlegend(location=\"northwest\")\n\nThere’s nothing special about 15 points. Choosing more doesn’t change the result much.\n\nt = linspace(-1, 1, 150)';\ny = exp(t);\nV = [t.^0, t];\nc = V \\ y;\np = @(t) c(1) + c(2)*t;\nfplot(p, [-1, 1], displayname=\"LS fit at 150 points\")\n\nThis situation is unlike interpolation, where the degree of the interpolant increases with the number of nodes. Here, the linear fit is apparently approaching a limit that we may think of as a continuous least-squares fit.\n\nn = (40:60:400)';\nslope = zeros(size(n));\nintercept = zeros(size(n));\n\nfor k = 1:length(n)\n    t = linspace(-1, 1, n(k))';\n    V = [t.^0, t];\n    c = V \\ exp(t);\n    intercept(k) = c(1);\n    slope(k) = c(2);\nend\ntable(n, intercept, slope)\n\nExample 9.4.1\n\nLet’s approximate e^x over the interval [−1,1]. We can sample it at, say, 15 points, and find the best-fitting straight line to that data.\n\nfrom numpy.linalg import lstsq\nt = linspace(-1, 1, 15)\ny = exp(t)\nplot(t, y, label=\"function\")\n\nV = [[ti**j for j in range(2)] for ti in t]\nc = lstsq(V, y, rcond=None)[0]\nprint(\"fit coeffs:\", c)\n\nx = linspace(-1, 1, 600)\nplot(x, c[1] + c[0] * x, label=\"fit\")\nxlabel(\"x\"),  ylabel(\"value\")\nlegend(),  title(\"Least squares fit of exp(x)\");\n\nThere’s nothing special about 15 points. Choosing more doesn’t change the result much.\n\nt = linspace(-1, 1, 150)\ny = exp(t)\nplot(t, y, label=\"function\")\n\nV = [[ti**j for j in range(2)] for ti in t]\nc = lstsq(V, y, rcond=None)[0]\nprint(\"fit coeffs:\", c)\n\nx = linspace(-1, 1, 600)\nplot(x, c[1] + c[0] * x, label=\"fit\")\nxlabel(\"x\"),  ylabel(\"value\")\nlegend(),  title(\"Least squares fit of exp(x)\");\n\nThis situation is unlike interpolation, where the degree of the interpolant increases with the number of nodes. Here, the linear fit is apparently approaching a limit that we may think of as a continuous least-squares fit.\n\nn = arange(40, 420, 60)\nresults = PrettyTable([\"n\", \"intercept\", \"slope\"])\nslope = zeros(n.size)\nintercept = zeros(n.size)\n\nfor k in range(n.size):\n    t = linspace(-1, 1, n[k])\n    y = exp(t)\n    V = [[ti**j for j in range(2)] for ti in t]\n    c = lstsq(V, y, rcond=None)[0]\n    results.add_row([n[k], c[1], c[0]])\n\nprint(results)\n\nWe can extend least-squares fitting from data to functions by extending several familiar finite-dimensional definitions. The continuous extension of a sum is an integral, which leads to the following.\n\nInner product of functions\n\nLet S be the set of continuous real-valued functions on the interval [-1,1]. The inner product of any functions f and g in S is the real scalar\\langle f,g \\rangle  = \\int_{-1}^1 f(x)g(x)\\,dx.\n\nWith this inner product, S is an inner product space. The 2-norm of a function f\\in S is\\|f\\|_2 = \\sqrt{\\rule[1mm]{0pt}{0.75em}\\langle f,f \\rangle}.\n\nFunctions f and g in S are orthogonal if\\langle f,g \\rangle = 0.","type":"content","url":"/orthogonal","position":1},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Quasimatrices"},"type":"lvl2","url":"/orthogonal#quasimatrices","position":2},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Quasimatrices"},"content":"If we are extending our notion of vectors to include continuous functions, what should serve as an extension of a matrix? One of our most important interpretations of a matrix is the connection to linear combinations. For instance, the Vandermonde-like system \\mathbf{V} \\mathbf{c} \\approx \\mathbf{y} from \n\n(3.1.2) is the statement\\mathbf{y} \\approx \\mathbf{V} \\mathbf{c} = c_0 \\mathbf{v}_0 + c_1 \\mathbf{v}_1 + \\cdots + c_n \\mathbf{v}_n,\n\nin which the ith row of \\mathbf{v}_j is t_i^j. This was derived as a discrete approximation for j=0,\\ldots,n.\\mathbf{y} \\approx c_0 + c_1 x + \\cdots + c_n x^n,\n\nwhich we want to abbreviate in “matrix”-vector form.\n\nQuasimatrix and Gram matrix\n\nGiven functions f_1,\\ldots,f_n in inner product space S, define the quasimatrix\\mathbf{F} =\n\\begin{bmatrix}\n    \\underline{f_1(x)} & \\underline{f_2(x)} & \\cdots &  \\underline{f_n(x)}\n\\end{bmatrix}.\n\nFor a vector \\mathbf{z} \\in \\real^n, define the quasimatrix-vector product\\mathbf{F}\\mathbf{z} = z_1f_1(x) + z_2f_2(x) + \\cdots + z_n f_n(x).\n\nFor another function g\\in S, define the adjoint product  \\mathbf{F}^T g =\n  \\begin{bmatrix}\n    \\langle f_1,g \\rangle \\\\ \\vdots  \\\\  \\langle f_n,g \\rangle\n  \\end{bmatrix}.\n\nFinally, define the Gram matrix  \\mathbf{F}^T \\mathbf{F} = \\bigl[ \\langle f_i,f_j \\rangle \\bigr]_{\\,i,j=1,\\ldots,n}.\n\nWe consider any other expressions involving a quasimatrix to be undefined. It might help to think of \\mathbf{F} as an \\infty\\times n matrix, which is consistent with the definitions that \\mathbf{F}\\mathbf{z} is a function (\\infty\\times 1), \\mathbf{F}^T g is a vector (n\\times 1), and \\mathbf{F}^T\\mathbf{F} is a matrix (n \\times n). When infinite dimensions combine in a product, we use integrals rather than sums.\n\nLet \\mathbf{F} = \\bigl[ \\,\\underline{\\cos(\\pi x)} \\quad \\underline{\\sin(\\pi x)}\\, \\bigr]. Then\\begin{split}\n\\mathbf{F} \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} &= -2\\cos(x) + \\sin(x), \\\\\n\\mathbf{F}^T x & = \\begin{bmatrix} \\int_{-1}^1 x\\cos(\\pi x)\\, dx \\\\  \\int_{-1}^1 x\\sin(\\pi x)\\, dx\\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 2/\\pi \\end{bmatrix}, \\\\\n\\mathbf{F}^T\\mathbf{F} &= \\begin{bmatrix} \\int_{-1}^1 \\cos^2(\\pi x)\\, dx & \\int_{-1}^1 \\cos(\\pi x)\\sin(\\pi x)\\, dx \\\\ \n\\int_{-1}^1 \\cos(\\pi x)\\sin(\\pi x)\\, dx & \\int_{-1}^1 \\sin^2(\\pi x)\\, dx \\end{bmatrix} = \\mathbf{I}.\n\\end{split}","type":"content","url":"/orthogonal#quasimatrices","position":3},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Normal equations"},"type":"lvl2","url":"/orthogonal#normal-equations","position":4},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Normal equations"},"content":"The discrete linear least-squares problem of minimizing  \\| \\mathbf{y} - \\mathbf{V} \\mathbf{c} \\|_2 over all possible \\mathbf{c}, given matrix \\mathbf{V} and data vector \\mathbf{y}, has a solution via the normal equations \n\n(3.2.3),\\mathbf{c} = \\left(\\mathbf{V}^T\\mathbf{V}\\right)^{-1} \\mathbf{V}^T \\mathbf{y}.\n\nWe can now reinterpret \n\n(9.4.11) in terms of quasimatrices.\n\nGiven functions f_1,\\ldots,f_n and y in an inner product space S, the least-squares problem\\operatorname{argmin}_{\\mathbf{c}\\in \\real^n} \\| c_1f_1(x) + \\cdots + c_n f_n(x) - y(x) \\|_2\n\nhas the solution\\mathbf{c} = \\left(\\mathbf{F}^T\\mathbf{F}\\right)^{-1} \\mathbf{F}^T y,\n\nwhere \\mathbf{F} is the quasimatrix \n\n(9.4.6).\n\nThere is no need to supply a proof of \n\nTheorem 9.4.1 because it will read exactly the same as for the discrete normal equations. All the effort has gone into making definitions that set up a perfect analogy. In retrospect, all we needed in the original discrete case were linear combinations and inner products.\n\nWe revisit approximation of e^x as suggested in \n\nDemo 9.4.1. With the Vandermonde quasimatrix \\mathbf{V}= \\begin{bmatrix} \\underline{1} & \\underline{x} \\end{bmatrix}, we get\\mathbf{V}^Te^x =\n  \\begin{bmatrix}\n    \\langle 1,e^x \\rangle \\\\[1mm] \\langle x,e^x \\rangle\n  \\end{bmatrix} =\n  \\begin{bmatrix}\n    \\int_{-1}^1 e^x\\, dx \\\\[1mm] \\int_{-1}^1 x e^x\\, dx\n  \\end{bmatrix} =\n  \\begin{bmatrix}\n    e-e^{-1} \\\\ 2 e^{-1}\n  \\end{bmatrix}\n\nand\\mathbf{V}^T \\mathbf{V} =\n  \\begin{bmatrix}\n    \\langle 1,1 \\rangle & \\langle 1,x \\rangle \\\\[1mm] \\langle x,1 \\rangle & \\langle x,x \\rangle\n  \\end{bmatrix} =\n  \\begin{bmatrix}\n    2 & 0 \\\\ 0 & 2/3\n  \\end{bmatrix}.\n\nThe normal equations \n\n(9.4.13) therefore have solution\\mathbf{c} = \\begin{bmatrix}\n    2 & 0 \\\\ 0 & 2/3\n  \\end{bmatrix}^{-1}\n  \\begin{bmatrix}\n    e-e^{-1} \\\\ 2 e^{-1}\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    \\sinh(1) \\\\ 3e^{-1}\n  \\end{bmatrix} \\approx\n  \\begin{bmatrix}\n    1.175201\\\\ 1.103638\n  \\end{bmatrix},\n\nwhich is well in line with the values found in \n\nDemo 9.4.1.\n\nIf we extend \\mathbf{V} by an additional column for x^2, then we need to calculate \\int_{-1}^1 x^2 e^x \\, dx = e - 5e^{-1} and \\int_{-1}^1 x^4\\, dx = 2/5 to get\\mathbf{c} = \\begin{bmatrix}\n    2 & 0 & 2/3\\\\ 0 & 2/3 & 0 \\\\ 2/3 & 0 & 2/5\n  \\end{bmatrix}^{-1}    \n  \\begin{bmatrix}\n    e-e^{-1} \\\\ 2 e^{-1} \\\\ e - 5e^{-1}\n  \\end{bmatrix}\n  \\approx\n  \\begin{bmatrix}\n    0.9962940 \\\\ 1.103638 \\\\ 0.5367215\n  \\end{bmatrix}.","type":"content","url":"/orthogonal#normal-equations","position":5},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Legendre polynomials"},"type":"lvl2","url":"/orthogonal#legendre-polynomials","position":6},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Legendre polynomials"},"content":"Equation \n\n(9.4.13) becomes much simpler if \\mathbf{V}^T\\mathbf{V} is diagonal. By our definitions, this would imply that the columns of \\mathbf{V} are mutually orthogonal in the sense of the function inner product. This is not the case for the monomial functions x^j. But there are orthogonal polynomials which do satisfy this property.\n\nFor what follows, let \\mathcal{P}_n \\subset S be the set of polynomials of degree n or less.\n\nLegendre polynomials\n\nThe Legendre polynomials are \\begin{split}\n     P_0(x) &= 1, \\\\\n     P_1(x) &= x, \\\\\n     P_{k}(x) &= \\frac{2k-1}{k}xP_{k-1}(x) - \\frac{k-1}{k}P_{k-2}(x), \\qquad k = 2,3,\\ldots.\n \\end{split}\n\nHere are some key facts that are straightforward to prove.\n\nProperties of Legendre polynomials\n\nThe degree of P_k is k.\n\nP_0,\\ldots,P_n form a basis for \\mathcal{P}_n.\n\nThe Legendre polynomials are mutually orthogonal. More specifically, the Gram matrix is given by \\langle P_i,P_j \\rangle =\n \\begin{cases}\n   0, & i \\neq j, \\\\\n   \\alpha_i^2 = \\bigl(i+\\tfrac{1}{2}\\bigr)^{-1}, & i=j.\n \\end{cases}\n\nNow let us define the quasimatrix  \\mathbf{L}_n(x) =\n  \\begin{bmatrix}\n    \\alpha_0^{-1} \\underline{P_0} & \\alpha_1^{-1} \\underline{P_1} & \\cdots\n    & \\alpha_{n}^{-1} \\underline{P_{n}}\n  \\end{bmatrix}.\n\nThen \\mathbf{L}_n^T\\mathbf{L}_n=\\mathbf{I}. The normal equations \n\n(9.4.13) thus simplify accordingly. Unraveling the definitions, we find the least-squares solution  \\mathbf{L}_n \\bigl( \\mathbf{L}_n^T f \\bigr) = \\sum_{k=0}^n c_k P_k(x), \\quad \\text{where }\n  c_k = \\frac{1}{\\alpha_k^2} \\langle P_k,f \\rangle.","type":"content","url":"/orthogonal#legendre-polynomials","position":7},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Chebyshev polynomials"},"type":"lvl2","url":"/orthogonal#chebyshev-polynomials","position":8},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Chebyshev polynomials"},"content":"Equation \n\n(9.4.1) is not the only useful way to define an inner product on a function space. It can be generalized to  \\langle f,g \\rangle = \\int_{-1}^1 f(x)g(x)w(x)\\,dx\n\nfor a positive function w(x) called the weight function of the inner product. An important special case is  \\langle f,g \\rangle  = \\int_{-1}^1 \\frac{f(x)g(x)}{\\sqrt{1-x^2}}\\,dx.\n\nChebyshev polynomials\n\nThe Chebyshev polynomials are defined by \\begin{split}\n     T_0(x) &= 1, \\\\\n     T_1(x) &= x, \\\\\n     T_{k}(x) &= 2xT_{k-1}(x) - T_{k-2}(x) ,\\qquad k = 2,3,\\ldots.\n \\end{split}\n\nChebyshev polynomials also have a startling alternative form,T_k(x) = \\cos\\left( k \\theta \\right), \\quad \\theta = \\arccos(x).\n\nThe results from \n\nTheorem 9.4.2 apply to Chebyshev polynomials as well, with orthogonality being in the sense of \n\n(9.4.23). Their Gram matrix is given by\\langle T_i,T_j \\rangle \n  = \\begin{cases} 0, &  i\\neq j, \\\\ \n      \\gamma_0^2 = \\pi, & i=j=0, \\\\ \n      \\gamma_i^2=\\pi/2, & i=j>0. \n    \\end{cases}\n\nThe least-squares solution is not the same in the Legendre and Chebyshev cases: both find the nearest approximation to a given f(x), but the norm used to measure distances is not the same.","type":"content","url":"/orthogonal#chebyshev-polynomials","position":9},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Roots of orthogonal polynomials"},"type":"lvl2","url":"/orthogonal#roots-of-orthogonal-polynomials","position":10},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Roots of orthogonal polynomials"},"content":"Interesting properties can be deduced entirely from the orthogonality conditions. The following result will be relevant in \n\nSpectrally accurate integration. The same result holds for orthogonal polynomial families with different weight functions, such as the Chebyshev polynomials.\n\nAll n roots of the Legendre polynomial P_n(x) are simple and real, and they lie in the open interval (-1,1).\n\nLet x_1,\\ldots,x_m be all of the distinct roots of P_n(x) between -1 and 1 at which P_n(x) changes sign (in other words, all roots of odd multiplicity). Definer(x) = \\prod_{i=1}^m (x-x_i).\n\nBy definition, r(x)P_n(x) does not change sign over (-1,1). Therefore  \\int_{-1}^1 r(x)P_n(x) \\, dx \\neq 0.\n\nBecause r is a degree-m polynomial, we can express it as a combination of P_0,\\ldots,P_m. If m<n, the integral \n\n(9.4.28) would be zero, by the orthogonality property of Legendre polynomials. So m\\ge n. Since P_n(x) has at most n real roots, m=n. All of the roots must therefore be simple, and this completes the proof.\n\nThe result of \n\nTheorem 9.4.3 holds for orthogonal families of polynomials for other weight functions. The Chebyshev case is unusual in that thanks to \n\n(9.4.25), the roots of T_n are known explicitly:  t_k = \\cos\\left(\\frac{2k-1}{2n}\\pi\\right), \\qquad k=1,\\ldots,n.\n\nThese are known as the Chebyshev points of the first kind. The chief difference between first-kind and second-kind points is that the latter type include the endpoints \\pm 1. Both work well for polynomial interpolation and give spectral convergence.","type":"content","url":"/orthogonal#roots-of-orthogonal-polynomials","position":11},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Least squares versus interpolation"},"type":"lvl2","url":"/orthogonal#least-squares-versus-interpolation","position":12},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Least squares versus interpolation"},"content":"Both interpolation and the solution of a linear least-squares problem produce a projection of a function into the space of polynomials \\mathcal{P}_n. In the least-squares case, the close connection with inner products and orthogonality makes the 2-norm, perhaps with a weight function, a natural setting for analysis. Because a constant weight function is the simplest choice, Legendre polynomials are commonly used for least squares.\n\nInterpolation has no easy connection to inner products or the 2-norm. With interpolants a different kind of approximation analysis is more fruitful, often involving the complex plane, in which the max-norm is the natural choice. For reasons beyond the scope of this text, Chebyshev polynomials are typically the most convenient to work with in this context.","type":"content","url":"/orthogonal#least-squares-versus-interpolation","position":13},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Exercises"},"type":"lvl2","url":"/orthogonal#exercises","position":14},{"hierarchy":{"lvl1":"Orthogonal polynomials","lvl2":"Exercises"},"content":"✍ Let \\mathbf{F} be the quasimatrix \\bigl[\\, \\underline{1} \\quad\\! \\underline{\\cos(\\pi x)}\\quad\\! \\underline{\\sin(\\pi x)}\\,\\bigr] for x\\in[-1,1].\n\n(a) Find \\mathbf{F}^T e^x.\n\n(b) Find \\mathbf{F}^T \\mathbf{F}.\n\n✍ (a) Find the best linear approximation in the least-squares sense to the function \\sin(x) on [-1,1].\n\n(b) Using \n\nTheorem 9.4.1, explain why the best fitting quadratic polynomial will be the linear function you found in part (a). (Note: You do not need to carry out the complete calculation.)\n\n(a) ✍ ⌨ Use \n\n(9.4.18) to write out P_2(x) and P_3(x). Plot P_0,P_1,P_2,P_3 on one graph for -1\\le x \\le 1. (You may find it interesting to compare to the graph in \n\nExercise 3.3.3.)\n\n(b) ✍ ⌨  Use \n\n(9.4.24) to write out T_2(x) and T_3(x). Plot T_0,T_1,T_2,T_3 on one graph for -1\\le x \\le 1.\n\n✍ Use \n\n(9.4.18) to show that P_n(x) is an odd function if n is odd and an even function if n is even.\n\n⌨ Using \n\n(9.4.18), write a function legpoly(x,n) that returns a matrix whose columns are the Legendre polynomials P_0,P_1,\\ldots,P_n evaluated at all the points in the vector x. Then use your function to plot P_0,P_1,P_2,P_3 on one graph.\n\n⌨ (Continuation of previous problem.) Choose 1600 evenly spaced points in [-1,1]. For n=1,2,\\ldots,16, use this vector of points and the function legpoly to construct a 1600\\times (n+1) matrix that discretizes the quasimatrix\\mathbf{A}_n = \n    \\begin{bmatrix}\n     \\underline{P_0} &  \\underline{P_1} & \\cdots \n    &  \\underline{P_{n}}\n    \\end{bmatrix}.\n\nMake a table of the matrix condition number \\kappa(\\mathbf{A}_n) as a function of n. (These will not be much larger than 1, showing that the Legendre polynomials are a good basis set.)\n\n⌨ Using \n\n(9.4.25), write a function chebpoly that returns a matrix whose columns are the Chebyshev polynomials T_0,T_1,\\ldots,T_n evaluated at all the points in the vector x. Then use your function to plot T_0,T_1,T_2,T_3 on one graph.\n\n(a) ✍ Use \n\n(9.4.25) to show that the first-kind points \n\n(9.4.29) are roots of T_n.\n\n(b) ✍ Use \n\n(9.4.25) to show that the second-kind points \n\n(9.3.2) are local extreme points of T_n.\n\n✍ Show that the definition \n\n(9.4.25) satisfies the recursion relation in \n\n(9.4.24).\n\n✍ Use \n\n(9.4.25) to show that \\langle T_0,T_0 \\rangle=\\pi and \\langle T_k,T_k \\rangle=\\pi/2 for k>0 in the Chebyshev-weighted inner product. (Hint: Change to the variable θ.)","type":"content","url":"/orthogonal#exercises","position":15},{"hierarchy":{"lvl1":"9. Global function approximation"},"type":"lvl1","url":"/overview-8","position":0},{"hierarchy":{"lvl1":"9. Global function approximation"},"content":"Not entirely stable? I’m glad you’re here to tell us these things.\n\nHan Solo, The Empire Strikes Back\n\nIn \n\nChapter 5 we considered a few ways to map data values to functions via interpolation. The methods we deemed successful were piecewise low-degree polynomials. In this chapter we deal with approximations that are globally defined over the entire interval, not piecewise.\n\nThe conditioning of a global polynomial is unacceptable for high degree interpolants of equally spaced data. We’ll remedy that issue by changing how the interpolation nodes are distributed. With that change, polynomial interpolation becomes extremely accurate and fast. Then we will look beyond interpolation and beyond polynomials a bit, and consider the application of these global methods to numerical integration.","type":"content","url":"/overview-8","position":1},{"hierarchy":{"lvl1":"Polynomial interpolation"},"type":"lvl1","url":"/polynomial","position":0},{"hierarchy":{"lvl1":"Polynomial interpolation"},"content":"In \n\nPolynomial interpolation and \n\nThe interpolation problem we encountered polynomial interpolation for the n+1 data points (t_0,y_0),\\ldots, (t_n,y_n). As before, we use t_i to denote interpolation or data nodes, and x to denote the independent variable. Remember that while our mathematical notation starts indexing the points at zero, in our codes we have to shift the indices up by 1.\n\nTheoretically, we can always construct an interpolating polynomial, and the result is unique among polynomials whose degree is less than n+1.\n\nIf the nodes t_0,\\dots,t_n are all distinct, there exists a unique polynomial p of degree at most n that satisfies p(t_k)=y_k for all k=0,\\dots,n.\n\nWe defer the existence part to Equation \n\n(9.1.4).  As for uniqueness, if p and q are two interpolating polynomials, then p-q is a  polynomial of degree at most n that is zero at the n+1 points  t_0,\\dots,t_n. By the Fundamental Theorem of Algebra, which states that a kth degree polynomial has no more than k roots, we conclude that p-q\\equiv 0, so p=q.","type":"content","url":"/polynomial","position":1},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Lagrange formula"},"type":"lvl2","url":"/polynomial#lagrange-formula","position":2},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Lagrange formula"},"content":"In our earlier encounters with polynomial interpolation, we found the interpolant by solving a linear system of equations with a Vandermonde matrix. The first step was to express the polynomial in the natural monomial basis 1,x,x^2,\\ldots. However, as we saw in \n\nPiecewise linear interpolation, no basis is more convenient than a cardinal basis, in which each member is one at a single node and zero at all of the other nodes.\n\nIt is surprisingly straightforward to construct a cardinal basis for global polynomial interpolation. By definition, each member \\ell_{k} of the basis, for k=0,\\ldots,n, is an nth degree polynomial satisfying the cardinality conditions  \\ell_{k}(t_j) = \\begin{cases}\n  1 &\\text{if $j=k$,}\\\\\n  0 & \\text{otherwise.}\n  \\end{cases}\n\nRecall that any polynomial of degree n can be expressed asc(x-r_1)(x-r_2)\\dots(x-r_n) = c\\prod_{k=1}^n(x-r_k),\n\nwhere r_1,\\dots,r_n are the roots of the polynomial and c is a constant. The conditions \n\n(9.1.1) give all n roots of \\ell_{k}, and the normalization \\ell_{k}(t_k)=1 tells us how to find c.\n\nLagrange cardinal polynomial\n\nGiven distinct nodes t_0,\\ldots,t_n, the polynomial\\begin{split}\n\\ell_{k}(x) & = \\frac{(x-t_0)\\dots(x-t_{k-1})(x-t_{k+1})\\dots(x-t_n)}{(t_k-t_0)\\dots(t_k-t_{k-1})(t_k-t_{k+1})\\dots(t_k-t_n)} \\\\[1mm]\n&= \\prod_{\\substack{i=0\\\\i\\ne k}}^n \\frac{(x-t_i)}{(t_k-t_i)}\n\\end{split}\n\nis of degree at most n and satisfies the cardinality conditions \n\n(9.1.1).\n\nLagrange cardinal polynomials\n\nExample 9.1.1\n\nHere is a vector of nodes.\n\nt = [ 1, 1.5, 2, 2.25, 2.75, 3 ]\nn = length(t) - 1;\n\nLet’s apply the definition of the cardinal Lagrange polynomial for k=2. First we define a polynomial q that is zero at all the nodes except i=k. Then \\ell_2 is found by normalizing q by q(t_k).\n\nTip\n\nCharacter ℓ is typed as \\ellTab.\n\nk = 2\nq(x) = prod(x - t[i] for i in [0:k-1; k+1:n] .+ 1)\nℓₖ(x) = q(x) / q(t[k+1]);\n\nA plot confirms the cardinal property of the result.\n\nusing Plots\nplot(ℓₖ, 1, 3)\ny = zeros(n+1);  y[k+1] = 1\nscatter!(t, y, color=:black,\n    xaxis=(L\"x\"),  yaxis=(L\"\\ell_2(x)\"),\n    title=\"Lagrange cardinal function\")\n\nObserve that \\ell_k is not between zero and one everywhere, unlike a hat function.\n\nExample 9.1.1\n\nHere is a vector of nodes.\n\nt = [ 1, 1.5, 2, 2.25, 2.75, 3 ];\nn = 5;  k = 2;\nnot_k = [0:k-1 k+1:n];   % all except the kth node\n\nLet’s apply the definition of the cardinal Lagrange polynomial for k=2. First we define a polynomial q that is zero at all the nodes except i=k. Then \\ell_2 is found by normalizing q by q(t_k).\n\nTip\n\nWhenever we index into the node vector t, we have to add 1 since the mathematical index starts at zero.\n\nq = @(x) prod(x - t(not_k + 1));\nell_k = @(x) q(x) ./ q(t(k + 1));\n\nA plot confirms the cardinal property of the result.\n\nclf\nfplot(ell_k, [1, 3])\nhold on, grid on\nplot(t(not_k + 1), 0 * t(not_k + 1), 'o')\nplot(t(k + 1), 1, 'o')\nxlabel('x'),  ylabel('\\ell_2(x)')    \ntitle('Lagrange cardinal function')\n\nObserve that \\ell_k is not between zero and one everywhere, unlike a hat function.\n\nExample 9.1.1\n\nHere is a vector of nodes.\n\nt = array([1, 1.5, 2, 2.25, 2.75, 3])\nn = 5\n\nLet’s apply the definition of the cardinal Lagrange polynomial for k=2. First we define a polynomial q that is zero at all the nodes except i=k. Then \\ell_2 is found by normalizing q by q(t_k).\n\nk = 2\nq = lambda x: prod([x - t[i] for i in range(n + 1) if i != k])\nell_k = lambda x: q(x) / q(t[k])\n\nA plot confirms the cardinal property of the result.\n\nx = linspace(1, 3, 500)\nplot(x, [ell_k(xx) for xx in x])\ny = zeros(n+1)\ny[k] = 1\nplot(t, y, \"ko\")\nxlabel(\"$x$\"),  ylabel(\"$\\\\ell_2(x)$\")\ntitle((\"Lagrange cardinal function\"));\n\nObserve that \\ell_k is not between zero and one everywhere, unlike a hat function.\n\nBecause they are a cardinal basis, the Lagrange polynomials lead to a simple expression for the polynomial interpolating the (t_k,y_k) points.\n\nLagrange interpolation formula\n\nGiven points (t_k,y_k) for k=0,\\ldots,n with all the t_k distinct, the unique polynomial of degree n or less that interpolates the points isp(x) = \\sum_{k=0}^n y_k \\ell_k(x).\n\nAt this point we can say that we have completed the proof of \n\nTheorem 9.1.1.\n\nWe construct the Lagrange interpolating polynomials of degrees n=1 and 2 to interpolate samples of f(x) = \\tan (x).  For n=1, we use t_0= 0 and t_1 = \\pi/3. The Lagrange formula then gives\\begin{align*}\n  P_1(x) & = y_0 \\ell_0(x)  +  y_1 \\ell_1(x) \\\\\n      & = y_0 \\frac{x-t_1}{t_0-t_1} + y_1 \\frac{x-t_0}{t_1-t_0} \\\\\n      & = 0 \\cdot \\frac{x-\\frac{\\pi}{3}}{0-\\frac{\\pi}{3}} + \\sqrt{3} \\cdot \\frac{x-0}{\\frac{\\pi}{3}-0} \\\\\n      & = \\frac{3 \\sqrt{3}}{\\pi} x.\n\\end{align*}\n\nThis is the unique linear function passing through (0,0) and (\\pi/3,\\sqrt{3}).\n\nFor n=2, we use t_0= 0, _1 = \\pi/6 and t_2 = \\pi/3. We now have\\begin{align*}\n  P_2(x) & = y_0 \\ell_0(x) +  y_1 \\ell_1(x) +  y_2 \\ell_2(x) \\\\\n    & = y_0 \\frac{(x-t_1)(x-t_2)}{(t_0-t_1)(t_0-t_2)}  +\n        y_1 \\frac{(x-t_0)(x-t_2)}{(t_1-t_0)(t_1-t_2)}  +\n        y_2  \\frac{(x-t_0)(x-t_1)}{(t_2-t_0)(t_2-t_1)} \\\\\n    & = 0\n      + \\frac{1}{\\sqrt{3}} \\frac{\\left(x-0\\right)\\left(x-\\frac{\\pi}{3}\\right)}\n      {\\left(\\frac{\\pi}{6}-0\\right)\\left(\\frac{\\pi}{6}-\\frac{\\pi}{3}\\right)}\n      + \\sqrt{3} \\frac{\\left(x-0\\right)\\left(x-\\frac{\\pi}{6}\\right)}\n      {\\left(\\frac{\\pi}{3}-0\\right)\\left(\\frac{\\pi}{3}-\\frac{\\pi}{6}\\right)}\n           = \\frac{6\\sqrt{3}}{\\pi^2}x^2 + \\frac{\\sqrt{3}}{\\pi} x.\n\\end{align*}","type":"content","url":"/polynomial#lagrange-formula","position":3},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Error formula"},"type":"lvl2","url":"/polynomial#error-formula","position":4},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Error formula"},"content":"In addition to existence, uniqueness,  and the constructive Lagrange formula, we have a useful formula for the error in a polynomial interpolant when the data are samples of a smooth function. We will refer to the following definition.\n\nError indicator function\n\nThe error indicator function for a set of distinct nodes t_0,\\ldots,t_n is\\Phi(x) = \\prod_{i=0}^n (x-t_i).\n\nPolynomial interpolation error\n\nLet t_0,\\dots,t_n be distinct points in [a,b], and suppose f has at least n+1 continuous derivatives in that interval. Let p(x) be the unique polynomial of degree at most n interpolating f at t_0,\\dots,t_n. Then for each x\\in[a,b], there exists a number \\xi(x)\\in(a,b) such thatf(x) - p(x) = \\frac{f^{(n+1)}(\\xi)}{(n+1)!} \\Phi(x),\n\nwith Φ given in \n\n(9.1.7).\n\nIf x=t_i for some i, the statement of the theorem is trivially true. Otherwise, we define a new function g(s) byg_x(s) = \\Phi(s)[f(x)-p(x)] - \\Phi(x)[f(s)-p(s)].\n\nNote that x is now arbitrary but fixed. Clearly g_x(t_i)=0 for each i=0,\\dots,n, because both Φ and the error f-p have that property. Also, g_x(x)=0. So g_x has at least n+2 zeros in [a,b]. This is possible only if g_x has at least n+1 local minima in (a,b); i.e., g_x' has at least n+1 zeros. But that implies that g_x'' must have at least n zeros, etc. Eventually we conclude that g_x^{(n+1)} has at least one zero in (a,b). Let \\xi(x) be such a zero.\n\nObserve that Φ is a monic polynomial (i.e., its leading coefficient is 1) of degree n+1. Hence \\Phi^{(n+1)}(t)=(n+1)!. Since p has degree at most n, p^{(n+1)}=0. Finally, we write\\begin{align*}\n0 = g_x^{(n+1)}(\\xi) &= \\Phi^{(n+1)}(\\xi)[f(x)-p(x)] - \\Phi(x)[f^{(n+1)}(\\xi)-p^{(n+1)}(\\xi)]\\\\\n&= (n+1)!\\,[f(x)-p(x)] - \\Phi(x)f^{(n+1)}(\\xi),\n\\end{align*}\n\nwhich is a restatement of \n\n(9.1.8).\n\nUsually f^{(n+1)} and the function \\xi(x) are unknown. The importance of the formula \n\n(9.1.8) is how it helps to express the error as a function of x, and its dependence on the nodes t_0,\\dots,t_n. We will exploit this knowledge later.\n\nPolynomial interpolation error\n\nConsider the problem of interpolating \\log(x) at nodes 1, 1.6, 1.9, 2.7, 3. Then n=4 and f^{(5)}(\\xi) = 4!/\\xi^5. For \\xi\\in[1, 3] we can say that |f^{(5)}(\\xi)| \\le 4!. Hence|f(x)-p(x)| \\le \\frac{1}{5} \\left| \\Phi(x) \\right|.\n\nExample 9.1.3\n\nConsider the problem of interpolating \\log(x) at these nodes:\n\nt =  [ 1, 1.6, 1.9, 2.7, 3 ]\nn = length(t) - 1;\n\nHere n=4 and f^{(5)}(\\xi) = 4!/\\xi^5. For \\xi\\in[1,3] we can say that |f^{(5)}(\\xi)| \\le 4!. Hence|f(x)-p(x)| \\le \\frac{1}{5} \\left| \\Phi(x) \\right|.\n\nTip\n\nCharacter Φ is typed as \\PhiTab. (Note the capitalization.)\n\nusing Polynomials\nΦ(x) = prod(x - tᵢ for tᵢ in t)\nplot(x -> 0.2 * abs(Φ(x)), 1, 3, label=L\"\\frac{1}{5}|\\Phi(t)|\")\np = Polynomials.fit(t, log.(t))\nplot!(t -> abs(log(t) - p(t)), 1, 3, label=L\"|f(x)-p(x)|\")\nscatter!(t, zeros(size(t)), color=:black,\n    xaxis=(L\"x\"), title=\"Interpolation error and upper bound\")\n\nThe error is zero at the nodes, by the definition of interpolation. The error bound, as well as the error itself, has one local maximum between each consecutive pair of nodes.\n\nExample 9.1.3\n\nt =  [ 1, 1.6, 1.9, 2.7, 3 ];\nn = length(t) - 1;\nPhi = @(x) prod(x - t);\n\nclf,  fplot(@(x) Phi(x) / 5, [1, 3])\nhold on,  plot(t, 0*t, 'o')\nxlabel('x'),  ylabel('\\Phi(x)')   \ntitle('Interpolation error function')\n\nThe error is zero at the nodes, by the definition of interpolation. The error bound, as well as the error itself, has one local maximum between each consecutive pair of nodes.\n\nExample 9.1.3\n\nfrom scipy.interpolate import BarycentricInterpolator as interp\nt = array([1, 1.6, 1.9, 2.7, 3])\np = interp(t, log(t))\n\nfrom scipy.interpolate import BarycentricInterpolator as interp\nt = array([1, 1.6, 1.9, 2.7, 3])\np = interp(t, log(t))\nx = linspace(1, 3, 500)\nPhi = lambda x: prod([x - ti for ti in t])\nplot(x, [Phi(xj) / 5 for xj in x], label=\"$\\\\frac{1}{5}|\\\\Phi(x)|$\")\nplot(x, abs(log(x) - p(x)), label=\"$|f(x)-p(x)|$\")\nplot(t, zeros(t.size), \"ko\", label=\"nodes\")\nxlabel(\"$x$\"),  ylabel(\"error\")\ntitle(\"Interpolation error and upper bound\"),  legend();\n\nThe error is zero at the nodes, by the definition of interpolation. The error bound, as well as the error itself, has one local maximum between each consecutive pair of nodes.\n\nFor equispaced nodes, \n\nTheorem 9.1.1 has an immediate consequence.\n\nSuppose t_i=i h for constant step size h and all i=0,1,\\ldots,n, and that f has n+1 continuous derivatives in (t_0,t_n). If x\\in[t_0,t_n], then there exists \\xi(x)\\in(t_0,t_n) and C independent of x such that|f(x) - p(x)| \\le C f^{(n+1)}(\\xi) h^{n+1}.\n\nIn particular, |f(x)-p(x)|=O(h^{n+1}) as h\\to 0.\n\nIf x\\in[t_0,t_n], then |x-t_i|<nh for all i, and \n\n(9.1.8) implies \n\n(9.1.12). As h\\to 0, \\xi\\to x, and the continuity of f^{(n+1)} allows us to make the asymptotic conclusion.\n\nThis result is consistent with our observations in \n\nConvergence of finite differences: piecewise linear interpolation with node spacing h has accuracy O(h^2), and the error of a finite-difference method for the first derivative based on n+1 nodes of spacing h is O(h^n), remembering the division by h in a finite-difference formula.\n\nAs presented in \n\n(9.1.4), the Lagrange formula is not a good choice for numerical computation, because it is unstable (see \n\nExercise 7). In the next section we derive an algebraically equivalent formula that is both numerically stable and faster to apply.","type":"content","url":"/polynomial#error-formula","position":5},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/polynomial#exercises","position":6},{"hierarchy":{"lvl1":"Polynomial interpolation","lvl2":"Exercises"},"content":"✍ Write out the Lagrange form of the interpolating polynomial of degree n for the given functions and nodes. Using a calculator, evaluate the polynomial at x=\\pi/4 and compute the error there.\n\n(a) f(x) = \\sin(x), \\ n=1, \\ t_0=0, t_1 = \\pi/2\n\n(b) f(x) = \\sin(x), \\ n=2, \\ t_0=0, t_1 = \\pi/6, t_2 = \\pi/2\n\n(c) f(x) = \\cos(x), \\ n=2, \\ t_0=0, t_1 = \\pi/3, t_2 = \\pi/2\n\n(d) f(x) = \\tanh(x), \\ n=2, \\ t_0=0, t_1 = \\pi/3, t_2 = \\pi/2\n\n⌨ For each case, plot the requested Lagrange cardinal polynomial for the given set of nodes over the interval [t_0,t_n]. Superimpose dots or circles for the points represented by the cardinal conditions \n\n(9.1.1).\n\n(a) n=2,\\quad t_0=-1, \\, t_1=-0.2,\\, t_2=0, \\quad \\ell_2(x)\n\n(b) n=4,\\quad t_0=0, \\, t_1=1,\\, t_2=1.5,\\, t_3=2.5,\\, t_4=3, \\quad \\ell_3(x)\n\n(c) n=20, \\quad t_i=i/n \\text{ for } i=0,\\ldots,n, \\quad \\ell_0(x)\n\n(d) n=20, \\quad t_i=i/n \\text{ for } i=0,\\ldots,n, \\quad \\ell_{10}(x)\n\n(e) n=40, \\quad t_i=i/n \\text{ for } i=0,\\ldots,n, \\quad \\ell_{20}(x)\n\n✍ Suppose p is the quadratic polynomial interpolating the points (-2,12), (1,3a), and (2,0). Use \n\n(9.1.4) to compute p'(0).\n\n✍ Explain carefully why using \n\n(9.1.4) to compute p(x) at a single value of x takes O(n^2) floating-point operations.\n\n✍  Explain why for any distribution of nodes and all x,1 = \\sum_{k=0}^n \\ell_k(x).\n\n(Hint: This problem does not require any hand computation or manipulation. What is being interpolated here?)\n\n✍ Show that\\ell_k(x) = \\frac{\\Phi(x)}{(x-t_k)\\Phi'(t_k)},\n\nwhere Φ is the function defined in \n\n(9.1.7).\n\n✍ Consider the nodes t_0=0, t_1=1, t_2=\\beta, where \\beta>1.\n\n(a) Write out the Lagrange cardinal polynomials \\ell_0, \\ell_1, and \\ell_2.\n\n(b) Set x=1/2 in the part (a) results, and suppose y_1 = y_2. As \\beta\\to 1 from above, why should we expect subtractive cancellation?","type":"content","url":"/polynomial#exercises","position":7},{"hierarchy":{"lvl1":"Spectrally accurate integration"},"type":"lvl1","url":"/spectral-integration","position":0},{"hierarchy":{"lvl1":"Spectrally accurate integration"},"content":"In \n\nNumerical integration we derived methods of order 2, 4, and higher for numerical integration. They all use a formula\\int_{-1}^1 f(x)\\, dx \\approx \\sum_{k=0}^n w_k f(t_k)\n\nfor a collection of nodes t_0,\\ldots,t_n in [-1,1] and weights w_0,\\ldots,w_n. (Throughout this section we use [-1,1] as the domain of the integral; for a general interval [a,b], see \n\nExercise 4.) The nodes and weights are independent of the integrand f(x) and determine the implementation and properties of the formula.\n\nThe process for deriving a specific method was to interpolate the integrand, then integrate the interpolant. Piecewise linear interpolation at equally spaced nodes, for instance, produces the trapezoid formula. When the integrand is approximated by a spectrally accurate global function, the integration formulas are also spectrally accurate.","type":"content","url":"/spectral-integration","position":1},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Periodic functions"},"type":"lvl2","url":"/spectral-integration#periodic-functions","position":2},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Periodic functions"},"content":"For a function periodic on [-1,1], the most natural interpolant is the trigonometric polynomial \n\n(9.5.4). However, from \n\n(9.5.3) one finds that\\int_{-1}^1 \\sum_{k=-n}^n y_k\\tau_k(x)\\, dx =  \\sum_{k=-n}^n y_k\\left[ \\int_{-1}^1 \\tau_k(x)\\, dx\\right] = \\frac{2}{2n+1} \\sum_{k=-n}^n y_k.\n\nIn \n\nExercise 1 you are asked to verify that this result is identical to the value of the trapezoid formula on 2n+1 nodes.\n\nThe trapezoid integration formula is spectrally accurate for periodic functions.\n\nPerimeter of an ellipse\n\nWe use the trapezoidal integration formula to compute the perimeter of an ellipse with semi-axes 1 and 1/2. Parameterizing the ellipse as x=\\cos \\pi t, y=\\frac{1}{2}\\sin \\pi t leads to the arc-length integral\\int_{-1}^1 \\pi\\sqrt{ \\cos^2(\\pi t) + \\tfrac{1}{4}\\sin^2(\\pi t)}\\,dt.\n\nExample 9.6.1\n\nf(t) = π * sqrt( cospi(t)^2 + sinpi(t)^2 / 4 );\nn = 4:4:48\nperim = zeros(size(n))\nfor (k, n) in enumerate(n)\n    h = 2 / n\n    t = @. h * (0:n-1) - 1\n    perim[k] = h * sum(f.(t))\nend\nerr = @. abs(perim - perim[end])    # use last value as \"exact\"\n@ptconf formatters=ft_printf([\"%d\", \"%.15f\", \"%.2e\"], 1:3)\n@pt :header=[\"n\", \"perimeter\", \"error estimate\"] [n perim err][1:end-1, :]\n\nThe approximations gain about one digit of accuracy for each constant increment of n, which is consistent with spectral convergence.\n\nExample 9.6.1\n\nf = @(t) pi * sqrt( cos(pi*t).^2 + sin(pi*t).^2 / 4 );\nN = (4:4:48)';\nperim = zeros(size(N));\nfor k = 1:length(N)\n    h = 2 / N(k);\n    t = h * (0:N(k)-1);\n    perim(k) = h * sum(f(t));\nend\nerr = abs(perim - perim(end));    % use last value as \"exact\"\nformat long\ntable(N, perim, err, variableNames=[\"number of nodes\", \"perimeter\", \"error\"])\n\nThe approximations gain about one digit of accuracy for each constant increment of n, which is consistent with spectral convergence.\n\nExample 9.6.1\n\nf = lambda t: pi * sqrt(cos(pi * t) ** 2 + sin(pi * t) ** 2 / 4)\nN = arange(4, 48, 6)\nperim = zeros(N.size)\nfor k in range(N.size):\n    h = 2 / N[k]\n    t = h * arange(N[k]) - 1\n    perim[k] = h * sum(f(t))\nerr = abs(perim - perim[-1])    # use the last value as reference\nresults = PrettyTable()\nresults.add_column(\"N\", N)\nresults.add_column(\"perimeter\", perim)\nresults.add_column(\"error\", err)\nresults\n\nThe approximations gain about one digit of accuracy for each constant increment of n, which is consistent with spectral convergence.","type":"content","url":"/spectral-integration#periodic-functions","position":3},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Clenshaw–Curtis integration"},"type":"lvl2","url":"/spectral-integration#clenshaw-curtis-integration","position":4},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Clenshaw–Curtis integration"},"content":"Suppose f is smooth but not periodic. If we use a global polynomial interpolating f at the Chebyshev second-kind points from \n\n(9.3.2),%:label: chebextremerepeat\n  t_k = - \\cos\\left(\\frac{k \\pi}{n}\\right), \\qquad k=0,\\ldots,n,\n\nand integrate the resulting polynomial interpolant, the method should have spectral accuracy for a smooth integrand. The resulting algorithm is known as Clenshaw–Curtis integration.\n\nHaving specified the nodes in \n\n(9.6.1), all that remains is to find the weights. The Lagrange form of the interpolating polynomial isp(x) = \\sum_{k=0}^{n} f(x_k) \\ell_k(x).\n\nFrom this,\\begin{align*}\n  I = \\int_{-1}^1 f(x)\\, dx \\approx \\int_{-1}^1 p(x) \\, d x &= \\int_{-1}^1 \\sum_{k=0}^n f(x_k) \\ell_k(x) \\, d x\\\\\n    &= \\sum_{k=0}^n f(x_k) \\int_{-1}^1 \\ell_k(x) \\, d x = \\sum_{k=0}^n w_k f(x_k), \n\\end{align*}\n\nwhere w_k = \\int_{-1}^1 \\ell_k(x)\\,dx. For even values of n the result is  w_k =\n\\begin{cases}\n\\dfrac{1}{n^2-1}, & \\text{$k=0$ or $k=n$},\\\\[3mm]\n\\dfrac{4}{n} \\displaystyle \\sum_{j=0}^{n/2} \\frac{\\cos ( 2 \\pi j k / n)}{\\gamma_j\n(1-4 j^2) }, & k=1,\\dots,n-1,\n\\end{cases}\n  \\quad\n\\gamma_j =\n\\begin{cases}\n2, & j=0 \\text{ or } n/2,\\\\\n1, & j=1,2,\\dots,n/2-1.\n\\end{cases}\n\nThere are different formulas for odd values of n. Note that the weights also depend on n; e. g. w_2 for n=4 is not the same as w_2 for n=10. Also note that the interpolant itself never needs to be computed.\n\nFunction 9.6.1 performs Clenshaw–Curtis integration for even values of n.\n\nccint\n\nClenshaw–Curtis integration\n\n\"\"\"\n    ccint(f, n)\n\nPerform Clenshaw-Curtis integration for the function `f` on `n`+1\nnodes in [-1,1]. Returns the integral estimate and a vector of the\nnodes used. Note: `n` must be even.\n\"\"\"\nfunction ccint(f, n)\n    @assert iseven(n) \"Value of `n` must be an even integer.\"\n    # Find Chebyshev extreme nodes.\n    θ = [i * π / n for i in 0:n]\n    x = -cos.(θ)\n\n    # Compute the C-C weights.\n    c = similar(θ)\n    c[[1, n+1]] .= 1 / (n^2 - 1)\n    s = sum(cos.(2k * θ[2:n]) / (4k^2 - 1) for k in 1:n/2-1)\n    v = @. 1 - 2s - cos(n * θ[2:n]) / (n^2 - 1)\n    c[2:n] = 2v / n\n\n    # Evaluate integrand and integral.\n    I = dot(c, f.(x))   # vector inner product\n    return I, x\nend\n\nClenshaw-Curtis integration\n\nfunction [I, x] = ccint(f, n)\r\n% CCINT  Clenshaw-Curtis numerical integration.\r\n% Input:\r\n%   f     integrand (function)\r\n%   n     one less than the number of nodes (even integer)\r\n% Output:\r\n%   I     estimate of integral(f,-1,1)\r\n%   x     evaluation nodes of f (vector)\r\n\r\n% Find Chebyshev extreme nodes.\r\ntheta = pi * (0:n)' / n;\r\nx = -cos(theta);\r\n\r\n% Compute the C-C weights.\r\nc = zeros(1, n+1); \r\nc([1, n+1]) = 1 / (n^2 - 1); \r\ntheta = theta(2:n); \r\nv = ones(n-1, 1);\r\nfor k = 1:n/2-1\r\n  v = v - 2 * cos(2*k*theta) / (4*k^2 - 1);\r\nend\r\nv = v - cos(n*theta) / (n^2 - 1);\r\nc(2:n) = 2 * v / n;\r\n\r\n% Evaluate integrand and integral.\r\nI = c*f(x);   % use vector inner product\n\nClenshaw–Curtis integration\n\ndef ccint(f, n):\n    \"\"\"\n    ccint(f, n)\n\n    Perform Clenshaw-Curtis integration for the function f on n+1 nodes in [-1,1]. Return\n    integral and a vector of the nodes used. Note: n must be even.\n    \"\"\"\n    # Find Chebyshev extreme nodes.\n    theta = np.linspace(0, np.pi, n + 1)\n    x = -np.cos(theta)\n\n    # Compute the C-C weights.\n    c = np.zeros(n + 1)\n    c[[0, n]] = 1 / (n**2 - 1)\n    v = np.ones(n - 1)\n    for k in range(1, int(n / 2)):\n        v -= 2 * np.cos(2 * k * theta[1:-1]) / (4 * k**2 - 1)\n    v -= np.cos(n * theta[1:-1]) / (n**2 - 1)\n    c[1:-1] = 2 * v / n\n\n    # Evaluate integrand and integral.\n    I = np.dot(c, f(x))  # use vector inner product\n    return I, x","type":"content","url":"/spectral-integration#clenshaw-curtis-integration","position":5},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Gauss–Legendre integration"},"type":"lvl2","url":"/spectral-integration#gauss-legendre-integration","position":6},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Gauss–Legendre integration"},"content":"Let us reconsider the generic numerical integration formula \n\n(9.6.1),\\int_{-1}^1 f(x)\\, dx \\approx \\sum_{k=1}^n w_k f(t_k) = Q_{n}[f],\n\nwhere Q_n[f] stands for the application of the formula to function f. (We start the sum from k=1 instead of k=0 for notational convenience in what follows.)\n\nThe interpolation approach spurred us to use Chebyshev nodes. But it’s not clear that these are ideal nodes for the specific application of finding an integral. Instead, we can define formula as the integral of a polynomial interpolant, but with the weights and nodes chosen to satisfy an optimality criterion. As usual, we denote the set of all polynomials of degree at most m by \\mathcal{P}_m.\n\nDegree of an integration formula\n\nThe degree of integration formula Q_n is the maximum value of d such thatQ_n[p]= \\int_{-1}^1 p(x)\\, dx\n\nfor all p\\in \\mathcal{P}_d.\n\nSince there are n nodes and n weights available to choose, it seems plausible to expect m=2n-1, and this intuition turns out to be correct. Hence the goal is now to find nodes t_k and weights w_k such that\\int_{-1}^1 p(x)\\,dx = Q_{n}[p] = \\sum_{k=1}^n w_k p(t_k), \\qquad p \\in \\mathcal{P}_{2n-1}.\n\nIf these conditions are satisfied, the resulting method is called Gauss–Legendre integration or simply Gaussian integration. Because the integration formula is linear, i.e., Q_n[\\alpha p + q] = \\alpha Q_n[p] + Q_n[q], it is sufficient to show that Q_n gets the exact value for the monomials 1,x,x^2,\\ldots,x^{2n-1}.\n\nAs an example, consider the case n=2. Applying the integration formula to each monomial of degree less than 2n, we get the conditions\\begin{split}\n2 &= w_1 + w_2\\\\\n0 &= w_1 t_1 + w_2 t_2 \\\\\n\\frac{2}{3} &= w_1 t_1^2 + w_2 t_2^2\\\\\n0 &= w_1 t_1^3 + w_2 t_2^3.\n\\end{split}\n\nThese equations can be solved to obtainw_1=w_2=1, \\quad t_1 = -\\frac{1}{\\sqrt{3}}, \\quad t_2 =\n\\frac{1}{\\sqrt{3}},\n\nwhich specifies the two-point Gaussian integration formula.\n\nGeneralizing the process above to general n would be daunting, as the conditions on the nodes and weights are nonlinear. Fortunately, a more elegant approach is possible.\n\nThe roots of the Legendre polynomial P_n(x) are the nodes of an n-point Gaussian integration formula.\n\nChoose an arbitrary p\\in\\mathcal{P}_{2n-1}, and let \\hat{p}_n(x) be the lowest-degree interpolating polynomial for p using the as-yet unknown nodes t_1,\\dots,t_n. By definition,Q_n[p] = \\int_{-1}^1 \\hat{p}_n(x)\\, dx.\n\nSince \\hat{p}_n(x) has degree at most n-1, it is exactly equal to p if p\\in\\mathcal{P}_{n-1}, and \n\n(9.6.10) is trivially satisfied. Otherwise, the error formula \n\n(9.1.8) impliesp(x) - \\hat{p}_n(x) = \\frac{p^{(n)}(\\xi(x))}{n!} \\Phi(x),\n\nwhere Φ is the error indicator function \\prod_k (t-t_k). Trivially, the left-hand side is a polynomial in \\mathcal{P}_{2n-1} of degree at least n, so the right-hand side must be too. Thus, we can  writep(x) - \\hat{p}_n(x) = \\Psi(x) \\Phi(x),\n\nwhere \\Psi(x)\\in \\mathcal{P}_{n-1} is unknown. The optimality requirement \n\n(9.6.10) becomes0 = \\int_{-1}^1 p(x)\\,dx - Q_{n}[p]  = \\int_{-1}^1 \\bigl[p(x) - \\hat{p}_n(x)\\bigr]\\,dx = \\int_{-1}^1 \\Psi(x) \\Phi(x) \\, dx.\n\nGiven that \\Psi(x)\\in \\mathcal{P}_{n-1}, we can ensure that this condition is satisfied if\\int_{-1}^1 q(x)\\Phi(x) \\,dx = 0\n\nfor all q \\in {\\mathcal{P}}_{n-1}. Hence satisfaction of \n\n(9.6.17) implies satisfaction of \n\n(9.6.10). But by the orthogonality property of Legendre polynomials, satisfaction of \n\n(9.6.17) is guaranteed if \\Phi(x)=cP_n(x) for a constant c. Thus Φ and P_n have the same roots.\n\nFrom \n\nTheorem 9.4.3 we know that the roots of P_n are distinct and all within (-1,1). (Indeed, it would be strange to have the integral of a function depend on some of its values outside the integration interval!)  While there is no explicit formula for the roots, there are fast algorithms to compute them and the integration weights on demand. \n\nFunction 9.6.2 uses one of the oldest methods,  practical up to n=100 or so.\n\nglint\n\nGauss–Legendre integration\n\n\"\"\"\n    glint(f, n)\n\nPerform Gauss-Legendre integration for the function `f` on `n` nodes\nin (-1,1). Returns the integral estimate and a vector of the nodes used.\n\"\"\"\nfunction glint(f, n)\n    # Nodes and weights are found via a tridiagonal eigenvalue problem.\n    β = @. 0.5 / sqrt(1 - (2 * (1:n-1))^(-2))\n    T = diagm(-1 => β, 1 => β)\n    λ, V = eigen(T)\n    p = sortperm(λ)\n    x = λ[p]               # nodes\n    c = @. 2V[1, p]^2       # weights\n\n    # Evaluate the integrand and compute the integral.\n    I = dot(c, f.(x))      # vector inner product\n    return I, x\nend\n\nGauss-Legendre integration\n\nfunction [I, x] = glint(f, n)\r\n% GLINT  Gauss-Legendre numerical integration.\r\n% Input:\r\n%   f     integrand (function)\r\n%   n     number of nodes (integer)\r\n% Output:\r\n%   I     estimate of integral(f,-1,1)\r\n%   x     evaluation nodes of f (vector)\r\n\r\n% Nodes and weights are found via a tridiagonal eigenvalue problem.\r\nbeta = 0.5./sqrt(1 - (2*(1:n-1)).^(-2));\r\nT = diag(beta, 1) + diag(beta, -1);\r\n[V, D] = eig(T);\r\nx = diag(D); \r\n[x, idx] = sort(x);         % nodes\r\nc = 2 * V(1, idx).^2;       % weights\r\n\r\n% Evaluate the integrand and compute the integral.\r\nI = c*f(x);      % vector inner product\n\nGauss–Legendre integration\n\ndef glint(f, n):\n    \"\"\"\n    glint(f, n)\n\n    Perform Gauss-Legendre integration for the function f on n nodes in (-1,1). Return\n    integral and a vector of the nodes used.\n    \"\"\"\n    # Nodes and weights are found via a tridiagonal eigenvalue problem.\n    beta = 0.5 / np.sqrt(1 - (2.0 * np.arange(1, n)) ** (-2))\n    T = np.diag(beta, 1) + np.diag(beta, -1)\n    ev, V = eig(T)\n    ev = np.real_if_close(ev)\n    p = np.argsort(ev)\n    x = ev[p]  # nodes\n    c = 2 * V[0, p] ** 2  # weights\n\n    # Evaluate the integrand and compute the integral.\n    I = np.dot(c, f(x))  # vector inner product\n    return I, x","type":"content","url":"/spectral-integration#gauss-legendre-integration","position":7},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Convergence"},"type":"lvl2","url":"/spectral-integration#convergence","position":8},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Convergence"},"content":"Both Clenshaw–Curtis and Gauss–Legendre integration are spectrally accurate. The Clenshaw–Curtis method on n+1 points has degree n, whereas the Gauss–Legendre method with n points has degree {2n-1}. For this reason, it is possible for Gauss–Legendre to converge at a rate that is “twice as fast,” i.e., with roughly the square of the error of Clenshaw–Curtis. But the full story is not simple.\n\nComparing spectral integration methods\n\nExample 9.6.3\n\nFirst consider the integral\\int_{-1}^1 \\frac{1}{1+4x^2} \\, dx = \\arctan(2).\n\nf(x)= 1 / (1 + 4x^2);\nexact = atan(2);\n\nWe compare the two spectral integration methods for a range of n values.\n\nusing Plots\nn = 8:4:96\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n  err[k, 1] = abs(exact - FNC.ccint(f, n)[1])\n  err[k, 2] = abs(exact - FNC.glint(f, n)[1])\nend\n\nerr[iszero.(err)] .= NaN    # remove from log-scale plot\nplot(n, err, m=:o, label=[\"CC\" \"GL\"],\n    xaxis=(\"number of nodes\"),  yaxis=(:log10, \"error\", [1e-16, 1]), \n    title=\"Spectral integration\")\n\n(The missing dots are where the error is exactly zero.) Gauss–Legendre does converge faster here, but at something less than twice the rate.\n\nNow we try a more sharply peaked integrand:\\int_{-1}^1 \\frac{1}{1+16x^2} \\, dx = \\frac{1}{2}\\arctan(4).\n\nf(x) = 1 / (1 + 16x^2);\nexact = atan(4) / 2;\n\nn = 8:4:96\nerr = zeros(length(n), 2)\nfor (k,n) in enumerate(n)\n  err[k, 1] = abs(exact - FNC.ccint(f, n)[1])\n  err[k, 2] = abs(exact - FNC.glint(f, n)[1])\nend\n\nerr[iszero.(err)] .= NaN    # remove from log-scale plot\nplot(n, err, m=:o, label=[\"CC\" \"GL\"],\n    xaxis=(\"number of nodes\"),  yaxis=(:log10, \"error\", [1e-16, 1]), \n    title=\"Spectral integration\")\n\nThe two are very close until about n=40, when the Clenshaw–Curtis method slows down.\n\nNow let’s compare the spectral performance to that of our earlier adaptive method in intadapt. We will specify varying error tolerances and record the error as well as the total number of evaluations of f.\n\ntol = 10 .^(-2.0:-2:-14)\nn = zeros(size(tol))  \nerrAdapt = zeros(size(tol))\nfor (k, tol) in enumerate(tol)\n  Q, t = FNC.intadapt(f, -1, 1, tol)\n  errAdapt[k] = abs(exact - Q)\n  n[k] = length(t)\nend\n\nerrAdapt[iszero.(errAdapt)] .= NaN\nplot!(n, errAdapt, m=:o, label=\"intadapt\")\nplot!(n, n.^(-4), l=:dash, label=\"4th order\",\n        xaxis=(:log10),  title=\"Spectral vs 4th order\" )\n\nAt the core of intadapt is a fourth-order formula, and the results track that rate closely. For all but the most relaxed error tolerances, both spectral methods are far more efficient than the low-order counterpart. For other integrands, particularly those that vary nonuniformly across the interval, the adaptive method might be more competitive.\n\nExample 9.6.3\n\nFirst consider the integral\\int_{-1}^1 \\frac{1}{1+4x^2} \\, dx = \\arctan(2).\n\nf = @(x) 1 ./ (1 + 4*x.^2);\nexact = atan(2);\n\nWe compare the two spectral integration methods for a range of n values.\n\nn = (8:4:96)';\nerrCC = zeros(size(n));\nerrGL = zeros(size(n));\nfor k = 1:length(n)\n  errCC(k) = exact - ccint(f, n(k));\n  errGL(k) = exact - glint(f, n(k));\nend\nclf,  semilogy(n, abs([errCC errGL]), 'o-')\nxlabel('number of nodes'),  ylabel('error')\ntitle('Spectral integration')   \nlegend('Clenshaw–Curtis', 'Gauss–Legendre')\n\n(The missing points are where the error is exactly zero.) Gauss–Legendre does converge faster here, but at something less than twice the rate.\n\nNow we try a more sharply peaked integrand:\\int_{-1}^1 \\frac{1}{1+16x^2} \\, dx = \\frac{1}{2}\\arctan(4).\n\nf = @(x) 1 ./ (1 + 16*x.^2);\nexact = atan(4) / 2;\n\nn = (8:4:96)';\nerrCC = zeros(size(n));\nerrGL = zeros(size(n));\nfor k = 1:length(n)\n  errCC(k) = exact - ccint(f, n(k));\n  errGL(k) = exact - glint(f, n(k));\nend\nclf,  semilogy(n, abs([errCC errGL]), 'o-')\nxlabel('number of nodes'),  ylabel('error')\ntitle('Spectral integration')   \nlegend('Clenshaw–Curtis', 'Gauss–Legendre')\n\nThe two are very close until about n=40, when the Clenshaw–Curtis method slows down.\n\nNow let’s compare the spectral performance to that of our earlier adaptive method in intadapt. We will specify varying error tolerances and record the error as well as the total number of evaluations of f.\n\ntol = 10 .^ (-2:-2:-14)';\nn = zeros(size(tol));  \nerrAdapt = zeros(size(tol));\nfor k = 1:length(n)\n  [Q, t] = intadapt(f, -1, 1, tol(k));\n  errAdapt(k) = exact - Q;\n  n(k) = length(t);\nend\nhold on;  semilogy(n, abs(errAdapt), 'o-')\nplot(n, n.^(-4), 'k--')        % 4th order error\nset(gca, 'xscale', 'log')     \nlegend('ccint', 'glint', 'intadapt', '4th order')  \ntitle(('Spectral vs 4th order'));\n\nAt the core of intadapt is a fourth-order formula, and the results track that rate closely. For all but the most relaxed error tolerances, both spectral methods are far more efficient than the low-order counterpart. For other integrands, particularly those that vary nonuniformly across the interval, the adaptive method might be more competitive.\n\nExample 9.6.3\n\nFirst consider the integral\\int_{-1}^1 \\frac{1}{1+4x^2} \\, dx = \\arctan(2).\n\nf = lambda x: 1 / (1 + 4 * x**2)\nexact = arctan(2)\n\nWe compare the two spectral integration methods for a range of n values.\n\nN = range(8, 100, 4)\nerrCC = zeros(len(N))\nerrGL = zeros(len(N))\nfor k, n in enumerate(N):\n    errCC[k] = exact - FNC.ccint(f, n)[0]\n    errGL[k] = exact - FNC.glint(f, n)[0]\n\nsemilogy(N, abs(errCC), \"-o\", label=\"Clenshaw–Curtis\")\nsemilogy(N, abs(errGL), \"-o\", label=\"Gauss–Legendre\")\nxlabel(\"number of nodes\"),  ylabel(\"error\"),  ylim(1e-16, 0.01)\nlegend(),  title(\"Spectral integration\");\n\n(The missing dots are where the error is exactly zero.) Gauss–Legendre does converge faster here, but at something less than twice the rate.\n\nNow we try a more sharply peaked integrand:\\int_{-1}^1 \\frac{1}{1+16x^2} \\, dx = \\frac{1}{2}\\arctan(4).\n\nf = lambda x: 1 / (1 + 16 * x**2)\nexact = atan(4) / 2\n\nN = range(8, 100, 4)\nerrCC = zeros(len(N))\nerrGL = zeros(len(N))\nfor k, n in enumerate(N):\n    errCC[k] = exact - FNC.ccint(f, n)[0]\n    errGL[k] = exact - FNC.glint(f, n)[0]\n\nsemilogy(N, abs(errCC), \"-o\", label=\"Clenshaw–Curtis\")\nsemilogy(N, abs(errGL), \"-o\", label=\"Gauss–Legendre\")\nxlabel(\"number of nodes\"),  ylabel(\"error\"),  ylim(1e-16, 0.1)\nlegend(),  title(\"Spectral integration\");\n\nThe two are very close until about n=40, when the Clenshaw–Curtis method slows down.\n\nNow let’s compare the spectral performance to that of our earlier adaptive method in intadapt. We will specify varying error tolerances and record the error as well as the total number of evaluations of f.\n\nloglog(N, abs(errCC), \"-o\", label=\"ccint\")\nloglog(N, abs(errGL), \"-o\", label=\"glint\")\n\ntol_ = 1 / 10 ** arange(2, 15)\nn = zeros(tol_.size)\nerrAdapt = zeros(tol_.size)\nfor k, tol in enumerate(tol_):\n    Q, t = FNC.intadapt(f, -1, 1, tol)\n    errAdapt[k] = exact - Q\n    n[k] = t.size\n\nloglog(n, abs(errAdapt), \"-o\", label=\"intadapt\")\nloglog(n, 1 / (n**4), \"--\", label=\"4th order\")\nxlabel(\"number of nodes\"),  ylabel(\"error\"),  ylim(1e-16, 1)\nlegend(),  title(\"Spectral vs 4th order\");\n\nAt the core of intadapt is a fourth-order formula, and the results track that rate closely. For all but the most relaxed error tolerances, both spectral methods are far more efficient than the low-order counterpart. For other integrands, particularly those that vary nonuniformly across the interval, the adaptive method might be more competitive.\n\nThe difference in convergence between Clenshaw–Curtis and Gauss–Legendre is dwarfed by the difference between spectral and algebraic convergence. It is possible, though, to encounter integrands for which adaptivity is critical.  Choosing a method is highly problem-dependent, but a rule of thumb is that for large error tolerances, an adaptive low-order method is likely to be a good choice, while for high accuracy, the spectral methods often dominate.","type":"content","url":"/spectral-integration#convergence","position":9},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Exercises"},"type":"lvl2","url":"/spectral-integration#exercises","position":10},{"hierarchy":{"lvl1":"Spectrally accurate integration","lvl2":"Exercises"},"content":"✍  Suppose f is periodic on [-1,1]. Show that the result of applying the trapezoid formula on 2n+1 points is identical to \n\n(9.6.2).\n\n✍ For each integral, use Gauss–Legendre integration with n=2 to write out the terms w_1f(t_1) and w_2f(t_2) explicitly.\n\n(a) \\displaystyle\\int_{-1}^1 e^{-x}\\, dx = 2 \\sinh(1) \\qquad\n(b) \\displaystyle\\int_{-1}^1 e^{-x^2} \\qquad\n(c) \\displaystyle\\int_{-1}^1 (2+x)^{-1}\n\n⌨ For each integral, compute approximations using \n\nFunction 9.6.1 and \n\nFunction 9.6.2 with n=4,6,8,\\ldots,40. Plot the errors of both methods together as functions of n on a semi-log scale.\n\n(a) \\displaystyle\\int_{-1}^1 e^{-4x}\\, dx = \\sinh(4)/2\n\n(b) \\displaystyle\\int_{-1}^1 e^{-9x^2} = \\sqrt{\\pi}\\, \\operatorname{erf}(3)/3\n\n(c) \\displaystyle\\int_{-1}^1 \\operatorname{sech}(x) \\, dx = 2 \\tan^{-1} [ \\sinh (1) ]\n\n(d) \\displaystyle\\int_{-1}^1 \\frac{1}{1+9x^2}\\, dx = \\frac{2}{3} \\tan^{-1}(3)\n\n(a) ✍ (See also \n\nExercise 9.3.5.) Using the change of variablez = \\phi(x) = a + (b-a)\\frac{(x+1)}{2},\n\nshow that\\int_{a}^b f(z) \\, d z= \\frac{b-a}{2} \\int_{-1}^{1} f( \\phi(x) ) \\, d x .\n\n(b) ⌨ Rewrite \n\nFunction 9.6.1 and \n\nFunction 9.6.2 to accept additional inputs for a and b and compute integrals over [a,b].\n\n(c) ⌨  Repeat the steps of \n\nExercise 2 for the integral\\int_{\\pi/2}^{\\pi} x^2 \\sin 8x \\, d x = -\\frac{3 \\pi^2}{32}.\n\n⌨ A particle moves in a circular path with angular velocity given by \\omega(\\theta)=\\sin(\\exp(\\sin \\theta)). The time it takes to complete one full orbit isT = \\int_0^T dt = \\int_{0}^{2\\pi} \\frac{d\\theta}{d\\theta / dt } = \\int_{0}^{2\\pi} \\frac{d\\theta}{\\omega(\\theta) }.\n\nUse \n\nFunction 5.6.1 to find the period of the motion. Show results for different values of n to establish convergence to at least 12 digits.\n\n✍ Prove the claim about linearity of the Gauss–Legendre integration formula alluded to in the derivation of \n\nTheorem 9.6.1. Namely, show that condition \n\n(9.6.10) is true if and only if\\int_{-1}^1 x^j\\,dx = \\sum_{k=1}^n w_k x_k^j\n\nfor all j=0,\\ldots,2n-1.\n\nThis function is modeled after the function clencurt.m of \n\nTrefethen (2000).","type":"content","url":"/spectral-integration#exercises","position":11},{"hierarchy":{"lvl1":"Stability of polynomial interpolation"},"type":"lvl1","url":"/stability-1","position":0},{"hierarchy":{"lvl1":"Stability of polynomial interpolation"},"content":"With  barycentric interpolation available in the form of \n\nFunction 9.2.1, we can explore polynomial interpolation using a numerically stable algorithm. Any remaining sensitivity to error is due to the conditioning of the interpolation process itself.\n\nIll-conditioning in polynomial interpolation\n\nExample 9.3.1\n\nWe choose a function over the interval [0,1].\n\nf(x) = sin(exp(2x));\n\nHere is a graph of f and its polynomial interpolant using seven equally spaced nodes.\n\nusing Plots\nplot(f, 0, 1, label=\"function\", legend=:bottomleft)\nt = range(0, 1, 7)    # 7 equally spaced nodes\ny = f.(t)\nscatter!(t, y, label=\"nodes\")\n\np = FNC.polyinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"Equispaced interpolant, n=6\")\n\nThis looks pretty good. We want to track the behavior of the error as n increases. We will estimate the error in the continuous interpolant by sampling it at a large number of points and taking the max-norm.\n\nn = 5:5:60\nerr = zeros(size(n))\nx = range(0, 1, 2001)             # for measuring error\nfor (k, n) in enumerate(n)\n    t = range(0, 1, n+1)          # equally spaced nodes\n    y = f.(t)                     # interpolation data\n    p = FNC.polyinterp(t, y)\n    err[k] = norm((@. f(x) - p(x)), Inf)\nend\nplot(n, err, m=:o, \n    xaxis=(L\"n\"), yaxis=(:log10, \"max error\"),\n    title=\"Interpolation error for equispaced nodes\")\n\nThe error initially decreases as one would expect but then begins to grow. Both phases occur at rates that are exponential in n, i.e., O(K^n) for a constant K, appearing linear on a semi-log plot.\n\nExample 9.3.1\n\nWe choose a function over the interval [0,1]. Using 7 equally spaced nodes, the interpolation looks fine.\n\nf = @(x) sin(exp(2*x));\nclf,  fplot(f, [0, 1], displayname=\"function\")\nt = linspace(0, 1, 7);\ny = f(t);\nhold on,  scatter(t, y, displayname=\"nodes\")\np = polyinterp(t, y)\nfplot(p, [0, 1], displayname=\"interpolant\")\nxlabel('x'),  ylabel('f(x)') \ntitle('Test function')\n\nWe want to track the behavior of the error as n increases. We will estimate the error in the continuous interpolant by sampling it at a large number of points and taking the max-norm.\n\nn = (5:5:60)';   \nerr = zeros(size(n));\nx = linspace(0, 1, 1001)';         % for measuring error\nfor k = 1:length(n) \n  t = linspace(0, 1, n(k) + 1)';     % equally spaced nodes\n  y = f(t);                      % interpolation data\n  p = polyinterp(t, y);\n  err(k) = norm(f(x) - p(x), Inf);\nend\nclf,  semilogy(n, err, 'o-')\nxlabel('n'),  ylabel('max error')   \ntitle('Equispaced polynomial interpolation error')\n\nThe error initially decreases as one would expect but then begins to grow. Both phases occur at rates that are exponential in n, i.e., O(K^n) for a constant K, appearing linear on a semi-log plot.\n\nExample 9.3.1\n\nWe choose a function over the interval [0,1].\n\nf = lambda x: sin(exp(2 * x))\n\nHere is a graph of f and its polynomial interpolant using seven equally spaced nodes.\n\nx = linspace(0, 1, 500)\nplot(x, f(x), label=\"function\")\nt = linspace(0, 1, 7)\ny = f(t)\np = FNC.polyinterp(t, y)\nplot(x, p(x), label=\"interpolant\")\nplot(t, y, 'ko', label=\"nodes\")\nlegend(),  title(\"Equispaced interpolant, n=6\");\n\nThis looks pretty good. We want to track the behavior of the error as n increases. We will estimate the error in the continuous interpolant by sampling it at a large number of points and taking the max-norm.\n\nN = arange(5, 65, 5)\nerr = zeros(N.size)\nx = linspace(0, 1, 1001)         # for measuring error\nfor k, n in enumerate(N):\n    t = linspace(0, 1, n + 1)    # equally spaced nodes\n    y = f(t)  # interpolation data\n    p = FNC.polyinterp(t, y)\n    err[k] = max(abs(f(x) - p(x)))\n\nsemilogy(N, err, \"-o\")\nxlabel(\"$n$\"),  ylabel(\"max error\")\ntitle((\"Polynomial interpolation error\"));\n\nThe error initially decreases as one would expect but then begins to grow. Both phases occur at rates that are exponential in n, i.e., O(K^n) for a constant K, appearing linear on a semi-log plot.","type":"content","url":"/stability-1","position":1},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Runge phenomenon"},"type":"lvl2","url":"/stability-1#runge-phenomenon","position":2},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Runge phenomenon"},"content":"The disappointing loss of convergence in \n\nDemo 9.3.1 is a sign of ill conditioning due to the use of equally spaced nodes. We will examine this effect using the error formula \n\n(9.1.8) as a guide:f(x) - p(x) = \\frac{f^{(n+1)}(\\xi)}{(n+1)!} \\Phi(x), \\qquad \\Phi(x) = \\prod_{i=0}^n (x-t_i).\n\nWhile the dependence on f is messy here, the error indicator \\Phi(x) can be studied as a function of the nodes only.\n\nError indicator function for equispaced nodes\n\nExample 9.3.2\n\nWe plot |\\Phi(x)| over the interval [-1,1] with equispaced nodes for different values of n.\n\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|\\Phi(x)|\", [1e-25, 1]), legend=:bottomleft)\nx = range(-1, 1, 2001)\nfor n in 10:10:50\n    t = range(-1, 1, n+1)\n    Φ(x) = prod(x - t for t in t)\n    scatter!(x, abs.(Φ.(x)), m=(1, stroke(0)), label=\"n=$n\")\nend\ntitle!(\"Error indicator for equispaced nodes\")\n\nEach time Φ passes through zero at an interpolation node, the value on the log scale should go to -\\infty, which explains the numerous cusps on the curves.\n\nExample 9.3.2\n\nWe plot |\\Phi(x)| over the interval [-1,1] with equispaced nodes for different values of n.\n\nclf\nx = linspace(-1, 1, 1601)';\nPhi = zeros(size(x));\nfor n = 10:10:50\n    t = linspace(-1, 1, n+1)';\n    for k = 1:length(x)\n        Phi(k) = prod(x(k) - t);\n    end\n    semilogy(x, abs(Phi)),  hold on\nend\ntitle('Error indicator on equispaced nodes')    \nxlabel('x'),  ylabel('|\\Phi(x)|')\n\nEach time Φ passes through zero at an interpolation node, the value on the log scale should go to -\\infty, which explains the numerous cusps on the curves.\n\nExample 9.3.2\n\nWe plot |\\Phi(x)| over the interval [-1,1] with equispaced nodes for different values of n.\n\nx = linspace(-1, 1, 1601)\nfor n in range(10, 60, 10):\n    t = linspace(-1, 1, n + 1)\n    Phi = array([prod(xk - t) for xk in x])\n    semilogy(x, abs(Phi), \".\", markersize=2)\nxlabel(\"$x$\")\nylabel(\"$|\\Phi(x)|$\")\nylim([1e-25, 1])\ntitle((\"Effect of equispaced nodes\"));\n\nEach time Φ passes through zero at an interpolation node, the value on the log scale should go to -\\infty, which explains the numerous cusps on the curves.\n\nTwo observations from the result of \n\nDemo 9.3.2 are important. First, |\\Phi| decreases exponentially at each fixed location in the interval (note that the spacing between curves is constant for constant increments of n). Second, |\\Phi| is larger at the ends of the interval than in the middle, by an exponentially growing factor. This gap is what can ruin the convergence of polynomial interpolation.\n\nRunge phenomenon\n\nExample 9.3.3\n\nThis function has infinitely many continuous derivatives on the entire real line and looks easy to approximate over [-1,1].\n\nf(x) = 1 / (x^2 + 16)\nplot(f, -1, 1, title=\"Test function\", legend=:none)\n\nWe start by doing equispaced polynomial interpolation for some small values of n.\n\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|f(x)-p(x)|\", [1e-20, 1]))\nx = range(-1, 1, 2501)\nn = 4:4:12\nfor (k, n) in enumerate(n)\n    t = range(-1, 1, n+1)           # equally spaced nodes\n    y = f.(t)                       # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = @. abs(f(x) - p(x))\n    plot!(x, err, m=(1, :o, stroke(0)), label=\"degree $n\")\nend\ntitle!(\"Error for low degrees\")\n\nThe convergence so far appears rather good, though not uniformly so. However, notice what happens as we continue to increase the degree.\n\nn = @. 12 + 15 * (1:3)\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|f(x)-p(x)|\", [1e-20, 1]))\nfor (k, n) in enumerate(n)\n    t = range(-1, 1, n+1)           # equally spaced nodes\n    y = f.(t)                       # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = @. abs(f(x) - p(x))\n    plot!(x, err, m=(1, :o, stroke(0)), label=\"degree $n\")\nend\ntitle!(\"Error for higher degrees\")\n\nThe convergence in the middle can’t get any better than machine precision relative to the function values. So maintaining the growing gap between the center and the ends pushes the error curves upward exponentially fast at the ends, wrecking the convergence.\n\nExample 9.3.3\n\nThis function has infinitely many continuous derivatives on the entire real line and looks easy to approximate over [-1,1].\n\nf = @(x) 1 ./ (x.^2 + 16);\nclf,  fplot(f, [-1, 1])\nxlabel('x'),  ylabel('f(x)')    \ntitle('Test function')\n\nWe start by doing equispaced polynomial interpolation for some small values of n.\n\nx = linspace(-1, 1, 1601)';\nn = (4:4:12)';\nfor k = 1:length(n)\n    t = linspace(-1, 1, n(k) + 1)';        % equally spaced nodes\n    p = polyinterp(t, f(t));\n    semilogy(x, abs(f(x) - p(x)));  hold on\nend\ntitle('Error for degrees 4, 8, 12')   \nxlabel('x'), ylabel('|f(x) - p(x)|')\n\nThe convergence so far appears rather good, though not uniformly so. However, notice what happens as we continue to increase the degree.\n\nn = 12 + 15 * (1:3);\nclf\nfor k = 1:length(n)\n    t = linspace(-1, 1, n(k) + 1)';        % equally spaced nodes\n    p = polyinterp(t, f(t));\n    semilogy(x, abs(f(x) - p(x)));  hold on\nend\ntitle('Error for degrees 27, 42, 57')   \nxlabel('x'), ylabel('|f(x) - p(x)|')\n\nThe convergence in the middle can’t get any better than machine precision relative to the function values. So maintaining the growing gap between the center and the ends pushes the error curves upward exponentially fast at the ends, wrecking the convergence.\n\nExample 9.3.3\n\nThis function has infinitely many continuous derivatives on the entire real line and looks easy to approximate over [-1,1].\n\nf = lambda x: 1 / (x**2 + 16)\nx = linspace(-1, 1, 1601)\nplot(x, f(x))\ntitle(\"Test function\");\n\nWe start by doing equispaced polynomial interpolation for some small values of n.\n\nN = arange(4, 16, 4)\nlabel = []\nfor k, n in enumerate(N):\n    t = linspace(-1, 1, n + 1)  # equally spaced nodes\n    y = f(t)  # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = abs(f(x) - p(x))\n    semilogy(x, err, \".\", markersize=2)\n    label.append(f\"degree {n}\")\n\nxlabel(\"$x$\"),  ylabel(\"$|f(x)-p(x)|$\")\nylim([1e-20, 1])\nlegend(label),  title(\"Error for low degrees\");\n\nThe convergence so far appears rather good, though not uniformly so. However, notice what happens as we continue to increase the degree.\n\nN = 12 + 15 * arange(1, 4)\nlabels = []\nfor k, n in enumerate(N):\n    t = linspace(-1, 1, n + 1)  # equally spaced nodes\n    y = f(t)  # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = abs(f(x) - p(x))\n    semilogy(x, err, \".\", markersize=2)\n    labels.append(f\"degree {n}\")\nxlabel(\"$x$\"),  ylabel(\"$|f(x)-p(x)|$\"),  ylim([1e-20, 1])\nlegend(labels),  title(\"Error for higher degrees\");\n\nThe convergence in the middle can’t get any better than machine precision relative to the function values. So maintaining the growing gap between the center and the ends pushes the error curves upward exponentially fast at the ends, wrecking the convergence.\n\nThe observation of instability in \n\nDemo 9.3.3 is known as the Runge phenomenon. The Runge phenomenon is an instability manifested when the nodes of the interpolant are equally spaced and the degree of the polynomial increases. We reiterate that the phenomenon is rooted in the interpolation convergence theory and not a consequence of the algorithm chosen to implement polynomial interpolation.\n\nSignificantly, the convergence observed in \n\nDemo 9.3.3 is stable within a middle portion of the interval. By redistributing the interpolation nodes, we will next sacrifice a little of the convergence in the middle portion in order to improve it near the ends and rescue the process globally.","type":"content","url":"/stability-1#runge-phenomenon","position":3},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Chebyshev nodes"},"type":"lvl2","url":"/stability-1#chebyshev-nodes","position":4},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Chebyshev nodes"},"content":"The observations above hint that we might find success by having more nodes near the ends of the interval than in the middle. Though we will not give the details, it turns out that there is a precise asymptotic sense in which this must be done to make polynomial interpolation work over the entire interval. One especially important node family that gives stable convergence for polynomial interpolation is the Chebyshev points of the second kind (or Chebyshev extreme points) defined by t_k = - \\cos\\left(\\frac{k \\pi}{n}\\right), \\qquad k=0,\\ldots,n.\n\nThese are the projections onto the x-axis of n equally spaced points on a unit circle. They are densely clustered near the ends of [-1,1], and this feature turns out to overcome the Runge phenomenon.\n\nError indicator function for Chebyshev nodes\n\nExample 9.3.4\n\nNow we look at the error indicator function Φ for Chebyshev node sets.\n\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|\\Phi(x)|\", [1e-18, 1e-2]))\nx = range(-1, 1, 2001)\nfor n in 10:10:50\n    t = [-cospi(k / n) for k in 0:n]\n    Φ(x) = prod(x - t for t in t)\n    plot!(x, abs.(Φ.(x)), m=(1, :o, stroke(0)), label=\"n=$n\")\nend\ntitle!(\"Error indicator for Chebyshev nodes\")\n\nIn contrast to the equispaced case, |\\Phi| decreases exponentially with n almost uniformly across the interval.\n\nExample 9.3.4\n\nNow we look at the error indicator function Φ for Chebyshev node sets.\n\nclf\nx = linspace(-1, 1, 1601)';\nPhi = zeros(size(x));\nfor n = 10:10:50\n    theta = linspace(0, pi, n+1)';\n    t = -cos(theta);                    \n    for k = 1:length(x)\n        Phi(k) = prod(x(k) - t);\n    end\n    semilogy(x, abs(Phi));  hold on\nend\naxis tight, title('Effect of Chebyshev nodes')    \nxlabel('x'), ylabel('|\\Phi(x)|')   \nylim([1e-18, 1e-2])\n\nIn contrast to the equispaced case, |\\Phi| decreases exponentially with n almost uniformly across the interval.\n\nExample 9.3.4\n\nNow we look at the error indicator function Φ for Chebyshev node sets.\n\nx = linspace(-1, 1, 1601)\nlabels = []\nfor n in range(10, 60, 10):\n    theta = pi * arange(n + 1) / n\n    t = -cos(theta)\n    Phi = array([prod(xk - t) for xk in x])\n    semilogy(x, abs(Phi), \".\")\n    labels.append(f\"degree {n}\")\n\nxlabel(\"$x$\"),  ylabel(\"$|\\\\Phi(x)|$\"),  ylim([1e-18, 1e-2])\nlegend(labels),  title(\"Error indicator for Chebyshev nodes\");\n\nIn contrast to the equispaced case, |\\Phi| decreases exponentially with n almost uniformly across the interval.\n\nStability of interpolation with Chebyshev nodes\n\nExample 9.3.5\n\nHere again is the function from \n\nDemo 9.3.3 that provoked the Runge phenomenon when using equispaced nodes.\n\nf(x) = 1 / (x^2 + 16);\n\nplot(label=\"\", xaxis=(L\"x\"), yaxis=(:log10, L\"|f(x)-p(x)|\", [1e-20, 1]))\nx = range(-1, 1, 2001)\nfor (k, n) in enumerate([4, 10, 16, 40])\n    t = [-cospi(k / n) for k in 0:n]\n    y = f.(t)                           # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = @. abs(f(x) - p(x))\n    plot!(x, err, m=(1, :o, stroke(0)), label=\"degree $n\")\nend\ntitle!(\"Error for Chebyshev interpolants\")\n\nBy degree 16 the error is uniformly within machine epsilon, and, importantly, it stays there as n increases. Note that as predicted by the error indicator function, the error is uniform over the interval at each value of n.\n\nExample 9.3.5\n\nHere again is the function from \n\nDemo 9.3.3 that provoked the Runge phenomenon when using equispaced nodes.\n\nf = @(x) 1 ./ (x.^2 + 16);\n\nclf\nx = linspace(-1, 1, 1601)';\nn = [4, 10, 16, 40];\nfor k = 1:length(n) \n    theta = linspace(0, pi, n(k) + 1)';\n    t = -cos(theta);\n    p = polyinterp(t, f(t));\n    semilogy( x, abs(f(x) - p(x)) );  hold on\nend\ntitle('Error for degrees 4, 10, 16, 40')   \nxlabel('x'), ylabel('|f(x)-p(x)|')\n\nBy degree 16 the error is uniformly within machine epsilon, and, importantly, it stays there as n increases. Note that as predicted by the error indicator function, the error is uniform over the interval at each value of n.\n\nExample 9.3.5\n\nHere again is the function from \n\nDemo 9.3.3 that provoked the Runge phenomenon when using equispaced nodes.\n\nf = lambda x: 1 / (x**2 + 16)\n\nx = linspace(-1, 1, 1601)\nlabels = []\nfor k, n in enumerate([4, 10, 16, 40]):\n    t = -cos(pi * arange(n + 1) / n)         # Chebyshev nodes\n    y = f(t)                                 # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = abs(f(x) - p(x))\n    semilogy(x, err, \".\", markersize=2)\n    labels.append(f\"degree {n}\")\n\nxlabel(\"$x$\"),  ylabel(\"$|f(x)-p(x)|$\"),  ylim([1e-20, 1])\nlegend(labels),  title(\"Error for Chebyshev interpolants\");\n\nBy degree 16 the error is uniformly within machine epsilon, and, importantly, it stays there as n increases. Note that as predicted by the error indicator function, the error is uniform over the interval at each value of n.\n\nAs a bonus, for Chebyshev nodes the barycentric weights are simple:  w_k = (-1)^k d_k, \\qquad d_k =\n  \\begin{cases}\n    1/2 & \\text{if $k=0$ or $k=n$},\\\\\n    1 & \\text{otherwise}.\n  \\end{cases}","type":"content","url":"/stability-1#chebyshev-nodes","position":5},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Spectral convergence"},"type":"lvl2","url":"/stability-1#spectral-convergence","position":6},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Spectral convergence"},"content":"If we take n\\rightarrow \\infty and use polynomial interpolation on Chebyshev nodes, the convergence rate is exponential in n. The following is typical of the results that can be proved.\n\nSuppose f(x) is analytic in an open real interval containing [-1,1]. Then there exist constants C>0 and K>1 such that\\max_{x\\in[-1,1]} | f(x) - p(x) | \\le C K^{-n},\n\nwhere p is the unique polynomial of degree n or less defined by interpolation on n+1 Chebyshev second-kind points.\n\nThe condition “f is analytic” means that the Taylor series of f converges to f(x) in an open interval containing [-1,1]. A necessary condition of analyticity is that f is infinitely differentiable.\n\nIn other contexts we refer to \n\n(9.3.4) as linear convergence, but here it is usual to say that the rate is exponential or that one has spectral convergence. It achieves constant reduction factors in the error by constant increments of n. By contrast, algebraic convergence in the form O(n^{-p}) for some p>0 requires multiplying n by a constant factor in order to reduce error by a constant factor. Graphically, spectral error is a straight line on a log-linear scale, while algebraic convergence is a straight line on a log-log scale.\n\nSpectral convergence\n\nExample 9.3.6\n\nusing Logging\ndisable_logging(Logging.Warn);\n\nOn the left, we use a log-log scale, which makes second-order algebraic convergence O(n^{-4}) a straight line. On the right, we use a log-linear scale, which makes spectral convergence O(K^{-n}) linear.\n\nn = 20:20:400\nalgebraic = @. 100 / n^4\nspectral = @. 10 * 0.85^n\nplot(n, [algebraic spectral], layout=(1, 2), subplot=1,\n    xaxis=(L\"n\", :log10),  yaxis=(:log10, (1e-15, 1)),\n    label=[\"algebraic\" \"spectral\"],  title=\"Log-log\")\nplot!(n, [algebraic spectral], subplot=2,\n    xaxis=L\"n\",  yaxis=(:log10, (1e-15, 1)),\n    label=[\"algebraic\" \"spectral\"],  title=\"log-linear\")\n\nExample 9.3.6\n\nOn the left, we use a log-log scale, which makes second-order algebraic convergence O(n^{-4}) a straight line. On the right, we use a log-linear scale, which makes spectral convergence O(K^{-n}) linear.\n\nn = (20:20:400)';\nalgebraic = 100 ./ n.^4;\nspectral = 10 * 0.85.^n;\nclf, subplot(2, 1, 1)\nloglog(n, algebraic, 'o-', displayname=\"algebraic\")\nhold on;  loglog(n, spectral, 'o-', displayname=\"spectral\")\nxlabel('n'),  ylabel('error')   \ntitle('log–log')   \naxis tight,  ylim([1e-16, 1]);  legend(location=\"southwest\")   \n\nsubplot(2, 1, 2)\nsemilogy(n, algebraic, 'o-', displayname=\"algebraic\")\nhold on;  semilogy(n, spectral, 'o-', displayname=\"spectral\")\nxlabel('n'), ylabel('error'),  ylim([1e-16, 1])   \ntitle('log–linear')   \naxis tight,  ylim([1e-16, 1]);  legend(location=\"southwest\")\n\nExample 9.3.6\n\nOn the left, we use a log-log scale, which makes second-order algebraic convergence O(n^{-4}) a straight line. On the right, we use a log-linear scale, which makes spectral convergence O(K^{-n}) linear.\n\nn = arange(20, 420, 20)\nalgebraic = 100 / n**4\nspectral = 10 * 0.85**n\n\nsubplot(2, 1, 1)\nloglog(n, algebraic, 'o-', label=\"algebraic\")\nloglog(n, spectral, 'o-', label=\"spectral\")\nxlabel('n'),  ylabel('error') \ntitle('log–log'), ylim([1e-16, 1]);\nlegend() \n\nsubplot(2, 1, 2)\nsemilogy(n, algebraic, 'o-', label=\"algebraic\")\nsemilogy(n, spectral, 'o-', label=\"spectral\")\nxlabel('n'),  ylabel('error')\ntitle('log–linear') ,  ylim([1e-16, 1]);  \nlegend();","type":"content","url":"/stability-1#spectral-convergence","position":7},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/stability-1#exercises","position":8},{"hierarchy":{"lvl1":"Stability of polynomial interpolation","lvl2":"Exercises"},"content":"⌨ Revisit \n\nDemo 9.3.1 and determine an approximate value for the convergent phase of the constant K mentioned in the comments there.\n\n⌨ For each case, compute the polynomial interpolant using n second-kind Chebyshev nodes in [-1,1] for n=4,8,12,\\ldots,60. At each value of n, compute the infinity-norm error (that is, \\max |p(x)-f(x)| evaluated for at least 4000 values of x). Using a log-linear scale, plot the error as a function of n, then determine a good approximation to the constant K in \n\n(9.3.4).\n\n(a) f(x) = 1/(25x^2+1)\\qquad\n(b) f(x) = \\tanh(5 x+2)\n\n(c) f(x) = \\cosh(\\sin x)\\qquad\n(d) f(x) = \\sin(\\cosh x)\n\n⌨ Write a function chebinterp(f,n) that returns a function representing the polynomial interpolant of the input function f using n+1 Chebyshev second kind nodes over [-1,1]. You should use \n\n(9.3.3) to compute the barycentric weights directly, rather than using the method in \n\nFunction 9.2.1. Test your function by revisiting \n\nDemo 9.3.3 to use Chebyshev rather than equally spaced nodes.\n\nTheorem 9.3.1 assumes that the function being approximated has infinitely many derivatives over [-1,1]. But now consider the family of functions f_m(x)=|x|^m.\n\n(a) ✍ How many continuous derivatives over [-1,1] does f_m possess?\n\n(b) ⌨ Compute the polynomial interpolant using n second-kind Chebyshev nodes in [-1,1] for n=10,20,30,\\ldots,100. At each value of n, compute the max-norm error (that is, \\max |p(x)-f_m(x)| evaluated for at least 41000 values of x). Using a single log-log graph, plot the error as a function of n for all six values m=1,3,5,7,9,11.\n\n(c) ✍  Based on the results of parts (a) and (b), form a hypothesis about the asymptotic behavior of the error for fixed m as n\\rightarrow \\infty.\n\nThe Chebyshev points can be used when the interval of interpolation is [a,b] rather than [-1,1] by means of the change of variable  z = \\psi(x) = a + (b-a)\\frac{(x+1)}{2}.\n\n(a) ✍  Show that \\psi(-1) = a, \\psi(1) = b, and ψ is strictly increasing on [-1,1].\n\n(b) ✍ Invert the relation \n\n(9.3.5) to solve for x in terms of \\psi^{-1}(z).\n\n(c) ✍ Let t_0,\\ldots,t_n be standard second-kind Chebyshev points. Then a polynomial in x can be used to interpolate the function values f\\bigl(\\psi(t_i)\\bigr). This in turn implies an interpolating function \\tilde{P}(z) =P\\bigl(\\psi^{-1}(z)\\bigr). Show that \\tilde{P} is a polynomial in z.\n\n(d) ⌨ Implement the idea of part (c) to plot a polynomial interpolant of f(z) =\\cosh(\\sin z) over [0,2\\pi] using n+1 Chebyshev nodes with n=40.\n\nThe Chebyshev points can be used for interpolation of functions defined on the entire real line by using the change of variablez = \\phi(x) = \\frac{2x}{1-x^2},\n\nwhich maps the interval (-1,1) in one-to-one fashion to the entire real line.\n\n(a) ✍ Find \\displaystyle \\lim_{x\\to 1^-} \\phi(x) and \\displaystyle \\lim_{x\\to -1^+} \\phi(x).\n\n(b) ✍ Invert \n\n(9.3.6) to express x=\\phi^{-1}(z). (Be sure to enforce -1\\le x \\le 1.)\n\n(c) ⌨ Let t_0,\\ldots,t_n be standard second-kind Chebyshev points. These map to the z variable as \\zeta_i=\\phi(t_i) for all i. Suppose that f(z) is a given function whose domain is the entire real line. Then the function values y_i=f(\\zeta_i) can be associated with the Chebyshev nodes t_i, leading to a polynomial interpolant p(x). This in turn implies an interpolating function on the real line, defined asq(z)=p\\bigl(\\phi^{-1}(z)\\bigr) = p(x).\n\nImplement this idea to plot an interpolant of f(z)=(z^2-2z+2)^{-1} using n=30. Your plot should show q(z) evaluated at 1000 evenly spaced points in [-6,6], with markers at the nodal values (those lying within the [-6,6] window).\n\nAlternatively, analyticity means that the function is extensible to one that is differentiable in the complex plane.","type":"content","url":"/stability-1#exercises","position":9},{"hierarchy":{"lvl1":"Trigonometric interpolation"},"type":"lvl1","url":"/trig","position":0},{"hierarchy":{"lvl1":"Trigonometric interpolation"},"content":"Up to this point, all of our global approximating functions have been polynomials. While they are versatile and easy to work with, they are not always the best choice.\n\nSuppose we want to approximate a function f that is periodic, with one period represented by the standard interval [-1,1]. Mathematically, periodicity means that f(x+2)=f(x) for all real x. We could use polynomials to interpolate or project f. However, it seems more reasonable to replace polynomials by functions that are also periodic.\n\nTrigonometric polynomial\n\nFor an integer n, a trigonometric polynomial of degree n isp(x) = \\frac{a_0}{2} + \\sum_{k=1}^n  a_k \\cos(k\\pi x) + b_k \\sin(k\\pi x)\n\nfor real constants a_k,b_k.\n\nIt turns out that trigonometric interpolation allows us to return to equally spaced nodes without any problems. We therefore define N=2n+1 equally spaced nodes inside the interval [-1,1] by  t_k = \\frac{2k}{N}, \\quad k=-n,\\ldots,n.\n\nThe formulas in this section require some minor but important adjustments if N is even instead. We have modified our standard indexing scheme here to make the symmetry within [-1,1] about x=0 more transparent. Note that the endpoints \\pm 1 are not among the nodes.\n\nAs usual, we have sample values y_{-n},\\ldots,y_n, perhaps representing values of a function f(x) at the nodes.  We also now assume that the sample values can be extended periodically forever in both directions, so that y_{k+mN}=y_k for any integer m.","type":"content","url":"/trig","position":1},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Cardinal functions"},"type":"lvl2","url":"/trig#cardinal-functions","position":2},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Cardinal functions"},"content":"We can explicitly state the cardinal function basis for equispaced trigonometric interpolation. It starts with\\tau(x) = \\frac{2}{N} \\left( \\frac{1}{2} + \\cos \\pi x + \\cos 2\\pi x\n    + \\cdots + \\cos n\\pi x\\right) = \\frac{\\sin(N\\pi x/2)}{N\\sin(\\pi x/2)}.\n\nYou can directly check the following facts. (See \n\nExercise 3.)\n\nGiven the definition of τ in \n\n(9.5.3),\n\n\\tau(x) is a trigonometric polynomial of degree n.\n\n\\tau(x) is 2-periodic.\n\n\\tau(t_k)=0 for any nonzero integer k.\n\n\\displaystyle \\lim_{x \\to 0} \\tau(x) = 1.\n\nGiven also the nodes t_k in \n\n(9.5.2), the functions \\tau_k(x) = \\tau(x-t_k) form a cardinal basis for trigonometric interpolation.\n\nBecause the functions \\tau_{-n},\\ldots,\\tau_n form a cardinal basis, the coefficients of the interpolant are just the sampled function values, i.e., the interpolant of points (t_k,y_k) isp(x) = \\sum_{k=-n}^n y_k \\tau_k(x).\n\nThe convergence of a trigonometric interpolant is spectral, i.e., exponential as a function of N in the max-norm.","type":"content","url":"/trig#cardinal-functions","position":3},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Implementation"},"type":"lvl2","url":"/trig#implementation","position":4},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Implementation"},"content":"Function 9.5.1 is an implementation of trigonometric interpolation based on \n\n(9.5.4). The function accepts an N-vector of equally spaced nodes. Although we have not given the formulas above, the case of even N is included in the code.\n\ntriginterp\n\nTrigonometric interpolation\n\n\"\"\"\n    triginterp(t, y)\n\nConstruct the trigonometric interpolant for the points defined by\nvectors `t` and `y`.\n\"\"\"\nfunction triginterp(t, y)\n    N = length(t)\n\n    τ(x) =\n        if x == 0\n            return 1.0\n        else\n            denom = isodd(N) ? N * sin(π * x / 2) : N * tan(π * x / 2)\n            return sin(N * π * x / 2) / denom\n        end\n\n    return function (x)\n        return sum(y[k] * τ(x - t[k]) for k in eachindex(y))\n    end\nend\n\nAbout the code\n\nThe construct on line 13 is known as a ternary operator. It is a shorthand for an if–else statement, giving two alternative results for the true/false cases. Line 19 uses eachindex(y), which generalizes 1:length(y) to cases where a vector might have a more exotic form of indexing.\n\nTrigonometric interpolation\n\nfunction p = triginterp(t,y)\r\n% TRIGINTERP Trigonometric interpolation.\r\n% Input:\r\n%   t   equispaced interpolation nodes (vector, length N)\r\n%   y   interpolation values (vector, length N)\r\n% Output:\r\n%   p   trigonometric interpolant (function)\r\n\r\nN = length(t);\r\np = @value;\r\n\r\n    function f = value(x)\r\n        f = zeros(size(x));\r\n        for k = 1:N\r\n            f = f + y(k) * trigcardinal(x - t(k));\r\n        end\r\n    end    % value function\r\n        \r\n    function tau = trigcardinal(x)\r\n        if rem(N,2)==1   % odd\r\n            tau = sin(N*pi*x/2) ./ (N * sin(pi*x/2));\r\n        else             % even\r\n            tau = sin(N*pi*x/2) ./ (N * tan(pi*x/2));\r\n        end\r\n        tau(isnan(tau)) = 1;    % fix divisions by zero\r\n    end    % trigcardinal function\r\n        \r\nend    % triginterp function\n\nTrigonometric interpolation\n\ndef triginterp(t, y):\n    \"\"\"\n        triginterp(t, y)\n\n    Return trigonometric interpolant for points defined by vectors t and y.\n    \"\"\"\n    N = len(t)\n\n    def trigcardinal(x):\n        if x == 0:\n            tau = 1.0\n        elif np.mod(N, 2) == 1:  # odd\n            tau = np.sin(N * np.pi * x / 2) / (N * np.sin(np.pi * x / 2))\n        else:  # even\n            tau = np.sin(N * np.pi * x / 2) / (N * np.tan(np.pi * x / 2))\n        return tau\n\n    def p(x):\n        return np.sum([y[k] * trigcardinal(x - t[k]) for k in range(N)])\n\n    return np.vectorize(p)\n\nAbout the code\n\nThe construct on line 13 is known as a ternary operator. It is a shorthand for an if–else statement, giving two alternative results for the true/false cases. Line 19 uses eachindex(y), which generalizes 1:length(y) to cases where a vector might have a more exotic form of indexing.\n\nTrigonometric interpolation\n\nExample 9.5.1\n\nWe will get a cardinal function without using an explicit formula, just by passing data that is 1 at one node and 0 at the others.\n\nTip\n\nThe operator ÷, typed as \\div then Tab, returns the quotient without remainder of two integers.\n\nusing Plots\nN = 7\nn = (N - 1) ÷ 2\nt = 2 * (-n:n) / N\ny = zeros(N)\ny[n+1] = 1\n\np = FNC.triginterp(t, y);\nplot(p, -1, 1)\n\nscatter!(t, y, color=:black, \n    xaxis=(L\"x\"),  yaxis=(L\"\\tau(x)\"),\n    title=\"Trig cardinal function, N=$N\")\n\nHere is a 2-periodic function and one of its interpolants.\n\nf(x) = exp( sinpi(x) - 2*cospi(x) )\ny = f.(t)\np = FNC.triginterp(t, y)\n\nplot(f, -1, 1, label=\"function\",\n    xaxis=(L\"x\"),  yaxis=(L\"p(x)\"),\n    title=\"Trig interpolation, N=$N\", legend=:top)\nscatter!(t, y, m=:o, color=:black, label=\"nodes\")\nplot!(p, -1, 1, label=\"interpolant\")\n\nThe convergence of the interpolant is spectral. We let N go needlessly large here in order to demonstrate that unlike polynomials, trigonometric interpolation is stable on equally spaced nodes. Note that when N is even, the value of n is not an integer but works fine for defining the nodes.\n\nN = 2:2:60\nerr = zeros(size(N))\nx = range(-1, 1, 2501)  # for measuring error\nfor (k,N) in enumerate(N)\n    n = (N-1) / 2;   t = 2*(-n:n) / N;\n    p = FNC.triginterp(t, f.(t))\n    err[k] = norm(f.(x) - p.(x), Inf)\nend\n\nplot(N, err, m=:o,\n    xaxis=(L\"N\"),  yaxis=(:log10, \"max error\"),\n    title=\"Convergence of trig interpolation\")\n\nExample 9.5.1\n\nWe will get a cardinal function without using an explicit formula, just by passing data that is 1 at one node and 0 at the others.\n\nN = 7;  n = (N-1) / 2;\nt = 2 * (-n:n)' / N;\ny = zeros(N, 1);  y(n+1) = 1;\nclf,  scatter(t, y, 'k'),  hold on\n\np = triginterp(t, y);\nfplot(p, [-1, 1])\nxlabel('x'),  ylabel('p(x)')   \ntitle('Trig cardinal function')\n\nHere is a 2-periodic function and one of its interpolants.\n\nclf\nf = @(x) exp( sin(pi*x) - 2 * cos(pi*x) );\nfplot(f, [-1, 1], displayname=\"periodic function\"),  hold on\nfplot(triginterp(t, f(t)), [-1, 1], displayname=\"trig interpolant\")\ny = f(t);  scatter(t, f(t), 'k')\nxlabel('x'),  ylabel('f(x)')   \ntitle('Trig interpolation');  legend()\n\nThe convergence of the interpolant is spectral. We let N go needlessly large here in order to demonstrate that unlike polynomials, trigonometric interpolation is stable on equally spaced nodes. Note that when N is even, the value of n is not an integer but works fine for defining the nodes.\n\nN = 2:2:60;\nerr = zeros(size(N));\nx = linspace(-1, 1, 1601)';  % for measuring error\nfor k = 1:length(N)\n    n = (N(k) - 1) / 2;\n    t = 2 * (-n:n)' / N(k);\n    p = triginterp(t, f(t));\n    err(k) = norm(f(x) - p(x), Inf);\nend\nclf,  semilogy(N, err, 'o-')\naxis tight, title('Convergence of trig interpolation')   \nxlabel('N'),  ylabel('max error')\n\nExample 9.5.1\n\nWe will get a cardinal function without using an explicit formula, just by passing data that is 1 at one node and 0 at the others.\n\nTip\n\nThe operator ÷, typed as \\div then Tab, returns the quotient without remainder of two integers.\n\nN = 7\nn = int((N - 1) / 2)\nt = 2 * arange(-n, n + 1) / N\ny = zeros(N)\ny[n] = 1\n\np = FNC.triginterp(t, y)\nx = linspace(-1, 1, 600)\nplot(x, p(x))\nplot(t, y, \"ko\")\n\nxlabel(\"x\"),  ylabel(\"tau(x)\")\ntitle(\"Trig cardinal function\");\n\nHere is a 2-periodic function and one of its interpolants.\n\nf = lambda x: exp(sin(pi * x) - 2 * cos(pi * x))\n\nplot(x, f(x), label=\"periodic function\")\ny = f(t)\n\np = FNC.triginterp(t, y)\nplot(x, p(x), label=\"trig interpolant\")\nplot(t, y, \"ko\", label=\"nodes\")\n\nxlabel(\"$x$\"),  ylabel(\"$p(x)$\")\nlegend(),  title(\"Trig interpolation\");\n\nThe convergence of the interpolant is spectral. We let N go needlessly large here in order to demonstrate that unlike polynomials, trigonometric interpolation is stable on equally spaced nodes. Note that when N is even, the value of n is not an integer but works fine for defining the nodes.\n\nN = arange(2, 62, 2)\nerr = zeros(N.size)\n\nx = linspace(-1, 1, 1601)    # for measuring error\nfor k in range(N.size):\n    n = (N[k] - 1) / 2\n    t = 2 * arange(-n, n + 1) / N[k]\n    p = FNC.triginterp(t, f(t))\n    err[k] = max(abs(f(x) - p(x)))\n\nsemilogy(N, err, \"-o\")\nxlabel(\"N\"),  ylabel(\"max error\")\ntitle(\"Convergence of trig interpolation\");","type":"content","url":"/trig#implementation","position":5},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Fast Fourier transform"},"type":"lvl2","url":"/trig#fast-fourier-transform","position":6},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Fast Fourier transform"},"content":"Although the cardinal form of the interpolant is useful and stable, there is a fundamental alternative. It begins with an equivalent complex form of the trigonometric interpolant \n\n(9.5.1),  p(x) = \\sum_{k=-n}^n c_k e^{ik\\pi x}.\n\nThe connection is made through Euler’s formula,  e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta),\n\nand the resultant identities  \\cos \\theta = \\frac{e^{i \\theta}+e^{-i\\theta}}{2}, \\qquad \\sin \\theta = \\frac{e^{i \\theta}-e^{-i\\theta}}{2i}.\n\nSpecifically, we havec_k = \\begin{cases} \\frac{a_0}{2}, & k=0, \\\\[1mm] \n\\frac{1}{2}(a_k + i b_k), & k> 0, \\\\[1mm]\n\\overline{c_{-k}}, & k < 0. \n\\end{cases}\n\nWhile working with an all-real formulation seems natural when the data are real, the complex-valued version leads to more elegant formulas and is standard.\n\nThe N=2n+1 coefficients c_k are determined by interpolation nodes at the N nodes within [-1,1]. By evaluating the complex exponential functions at these nodes, we get the N\\times N linear system\\mathbf{F}\\mathbf{c} = \\mathbf{y}, \\qquad \\mathbf{F} = \\bigl[  e^{\\,is\\pi t_r}  \\bigr]_{\\, r=-n,\\ldots,n,\\, s=-n,\\ldots,n,}\n\nto be solved for the coefficients. Up to a scalar factor, the matrix \\mathbf{F} is unitary, which implies that the system can be solved in O(N^2) operations simply by a matrix-vector multiplication.\n\nHowever, one of the most important (though not entirely original) algorithmic observations of the 20th century was that the linear system can be solved in just O(N\\log N) operations by an algorithm now known as the fast Fourier transform, or FFT.\n\nThe FFTW package provides a function fft to perform this transform, but its conventions are a little different from ours. Instead of nodes in (-1,1), it expects the nodes to be defined in [0,2), and it returns the trig polynomial coefficients in the order\\begin{bmatrix}\n  c_0, & c_1, & \\cdots & c_n, & c_{-n}, & \\cdots & c_{-1}\n\\end{bmatrix}.\n\nFFT\n\nExample 9.5.2\n\nThis function has frequency content at 2\\pi, -2\\pi, and π.\n\nf(x) = 3 * cospi(2x) - cispi(x)    # cispi(x) := exp(1im * π * x)\n\nTo use fft, we set up nodes in the interval [0,2).\n\nn = 4;  N = 2n+1;\nt = [ 2j / N for j in 0:N-1 ]      # nodes in [0,2)\ny = f.(t);\n\nWe perform Fourier analysis using fft and then examine the resulting coefficients.\n\nusing FFTW\nc = fft(y) / N\nfreq = [0:n; -n:-1]\n@pt :header=[\"k\", \"coefficient\"] [freq round.(c, sigdigits=5)]\n\nNote that 1.5 e^{2i\\pi x}+1.5 e^{-2i\\pi x} = 3 \\cos(2\\pi x), so this result is sensible.\n\nFourier’s greatest contribution to mathematics was to point out that every periodic function is just a combination of frequencies—infinitely many of them in general, but truncated for computational use. Here we look at the magnitudes of the coefficients for f(x) = \\exp( \\sin(\\pi x) ).\n\nf(x) = exp( sin(pi*x) )     # content at all frequencies\nn = 9;  N = 2n+1;\nt = [ 2j / N for j in 0:N-1 ]      # nodes in [0,2)\nc = fft(f.(t)) / N\n\nfreq = [0:n; -n:-1]\nscatter(freq, abs.(c);\n    xaxis=(L\"k\", [-n, n]),  yaxis=(L\"|c_k|\", :log10), \n    title=\"Fourier coefficients\",  legend=:none)\n\nThe Fourier coefficients of smooth functions decay exponentially in magnitude as a function of the frequency. This decay rate is determines the convergence of the interpolation error.\n\nExample 9.5.2\n\nThis function has frequency content at 2\\pi, -2\\pi, and π.\n\nf = @(x) 3 * cos(2*pi * x) - exp(1i*pi * x);\n\nTo use fft, we set up nodes in the interval [0,2).\n\nn = 4;\nN = 2*n + 1;\nt = 2 * (0:N-1)' / N;      % nodes in $[0,2)$\ny = f(t);\n\nWe perform Fourier analysis using fft and then examine the resulting coefficients.\n\nc = fft(y) / N;\nfreq = [0:n, -n:-1]';\nformat short\ntable(freq, c, variableNames=[\"k\", \"coefficient\"])\n\nNote that 1.5 e^{2i\\pi x}+1.5 e^{-2i\\pi x} = 3 \\cos(2\\pi x), so this result is sensible.\n\nFourier’s greatest contribution to mathematics was to point out that every periodic function is just a combination of frequencies—infinitely many of them in general, but truncated for computational use. Here we look at the magnitudes of the coefficients for f(x) = \\exp( \\sin(\\pi x) ).\n\nf = @(x) exp( sin(pi*x) );    % content at all frequencies\nn = 9;  N = 2*n + 1;\nt = 2 * (0:N-1)' / N;         % nodes in $[0,2)$\ny = f(t);\nc = fft(y) / N;\nfreq = [0:n, -n:-1]';\n\nclf\nsemilogy(freq, abs(c), 'o')\nxlabel('k'),  ylabel('|c_k|')   \ntitle('Fourier coefficients')\n\nThe Fourier coefficients of smooth functions decay exponentially in magnitude as a function of the frequency. This decay rate is determines the convergence of the interpolation error.\n\nExample 9.5.2\n\nThis function has frequency content at 2\\pi, -2\\pi, and π.\n\nf = lambda x: 3 * cos(2 * pi * x) - exp(1j * pi * x)\n\nTo use fft, we set up nodes in the interval [0,2).\n\nn = 4\nN = 2 * n + 1\nt = 2 * arange(0, N) / N    # nodes in [0,2)\ny = f(t)\n\nWe perform Fourier analysis using fft and then examine the resulting coefficients.\n\nfrom scipy.fftpack import fft, ifft, fftshift\nc = fft(y) / N\nfreq = hstack([arange(n+1), arange(-n,0)])\nresults = PrettyTable()\nresults.add_column(\"freq\", freq) \nresults.add_column(\"coefficient\", c)\nresults\n\nNote that 1.5 e^{2i\\pi x}+1.5 e^{-2i\\pi x} = 3 \\cos(2\\pi x), so this result is sensible.\n\nFourier’s greatest contribution to mathematics was to point out that every periodic function is just a combination of frequencies—infinitely many of them in general, but truncated for computational use. Here we look at the magnitudes of the coefficients for f(x) = \\exp( \\sin(\\pi x) ).\n\nf = lambda x: exp(sin(pi * x))    # content at all frequencies\nn = 9;  N = 2*n + 1;\nt = 2 * arange(0, N) / N    # nodes in [0,2)\nc = fft(f(t)) / N\n\nsemilogy(range(-n, n+1), abs(fftshift(c)), \"o\")\nxlabel(\"$k$\"),  ylabel(\"$|c_k|$\")\ntitle(\"Fourier coefficients\");\n\nThe Fourier coefficients of smooth functions decay exponentially in magnitude as a function of the frequency. This decay rate is determines the convergence of the interpolation error.\n\nThe theoretical and computational aspects of Fourier analysis are vast and far-reaching. We have given only the briefest of introductions.","type":"content","url":"/trig#fast-fourier-transform","position":7},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Exercises"},"type":"lvl2","url":"/trig#exercises","position":8},{"hierarchy":{"lvl1":"Trigonometric interpolation","lvl2":"Exercises"},"content":"⌨  Each of the following functions is 2-periodic. Use \n\nFunction 9.5.1 to plot the function together with its trig interpolants with n=3,6,9. Then, for n=2,3,\\ldots,30, compute the max-norm error in the trig interpolant by sampling at 1000 or more points, and make a convergence plot on a semi-log scale.\n\n(a) f(x) = e^{\\sin (2\\pi x)}\\qquad\n(b) f(x) = \\log [2+ \\sin (3 \\pi x ) ]\\qquad\n(c) f(x) = \\cos^{12}[\\pi (x-0.2)]\n\n(a) ✍ Show that the functions \\sin(r\\pi x) and \\sin(s\\pi x) are identical at all of the nodes given in \n\n(9.5.2) if r-s=mN for an integer m. This important fact is called aliasing, and it implies that only finitely many frequencies can be distinguished on a fixed node set.\n\n(b) ⌨  Demonstrate part (a) with a graph for the case N=11, s=2, r=-9. Specifically, plot the two functions on one graph, and plot points to show that they intersect at all of the interpolation nodes.\n\n✍ Verify that the cardinal function given in Equation \n\n(9.5.3) is (a) 2-periodic, (b) satisfies \\tau(t_k)=0 for k\\neq 0 at the nodes \n\n(9.5.2), and (c) satisfies \\lim_{x\\to0}\\tau(x)=1.\n\n✍ Prove the equality of the two expressions in \n\n(9.5.3). (Hint: Set z=e^{i\\pi x/2} and rewrite the sum using z by applying Euler’s identity.)\n\n⌨ Spectral convergence is predicated on having infinitely many continuous derivatives. At the other extreme is a function with a jump discontinuity. Trigonometric interpolation across a jump leads to a lack of convergence altogether, a fact famously known as the Gibbs phenomenon.\n\n(a) Define f(x) = sign(x+eps()). This function jumps from -1 to 1 at x=-\\epsilon_\\text{mach}. Plot the function over -0.05\\le x \\le 0.15.\n\n(b) Let n=30 and N=2n+1. Using \n\nFunction 9.5.1, add a plot of the trigonometric interpolant to f to the graph from part (a).\n\n(c) Repeat part (b) for n=80 and n=180.\n\n(d) You should see that the interpolants overshoot and oscillate near the step. The widths of the overshoots decrease with n but the heights approach a limiting value. By zooming in to the graph, find the height of the overshoot to two decimal places.\n\n⌨ Let f(x)=x. Plot f and its trigonometric interpolants of length N=2n+1 for n=6,20,50 over -1\\le x \\le 1. What feature of the function is causing large errors?","type":"content","url":"/trig#exercises","position":9},{"hierarchy":{"lvl1":"Key language differences"},"type":"lvl1","url":"/differences","position":0},{"hierarchy":{"lvl1":"Key language differences"},"content":"This book makes extensive use of computing to both illustrate and demonstrate important facts. The three languages used are Julia, MATLAB, and Python (specifically, NumPy and SciPy). These languages share a great deal of syntax and functionality because they address the same needs. As the youngest, Julia adopted some conventions from both of the others, while NumPy itself was strongly influenced by MATLAB.\n\nHowever, there are some major differences in the languages that you should be aware of. You probably aren’t here for a history lesson, so I won’t get into the whys, but please do understand that some different choices were made for good reasons in context.\n\nWe focus here on issues that come up often in this book. There is a broader quick reference \n\nhere and a much more comprehensive analysis \n\nhere.","type":"content","url":"/differences","position":1},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Indexing: Zero or one?"},"type":"lvl2","url":"/differences#indexing-zero-or-one","position":2},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Indexing: Zero or one?"},"content":"Let’s get this out of the way.\n\nCaution\n\nIn MATLAB and Julia, indexing starts at 1. In Python, it starts at 0.\n\nWars have been fought over less. In math, it’s often—but not always—convenient to start at 1. In this book, we try to make an index in code equivalent to its mathematical definition, regardless of the language.\n\nAlso, MATLAB uses parentheses () for indexing, while Julia and Python use brackets [].","type":"content","url":"/differences#indexing-zero-or-one","position":3},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Linear algebra"},"type":"lvl2","url":"/differences#linear-algebra","position":4},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Linear algebra"},"content":"The most consequential difference has to do with how they represent the key objects from linear algebra, matrices and vectors. In MATLAB, every numerical value can be considered a matrix. A 1×1 matrix is also often considered to be a scalar (number), and a 1×n or n×1 matrix is often interpretable as a vector. This flexibility can be convenient, though it can also lead to confusion. Row and column vectors are often interchangeable, but not always. For instance,% MATLAB\nx = [1, 2, 3];       % row vector\ny = [3; 4; 5; 6];    % column vector\nx(2) == x(1, 2)      % true\nx(3) == y(1, 1)      % true\nx(3, 1) == y(1)      % error\n\nIn Julia, scalars, vectors, and matrices are different things. In particular, a vector is not identical to a matrix with one row or one column. However, there are contexts in which a vector is interpreted to have an implicit column shape. Moreover, vectors can hold any type of data, not just numbers. These rules have some subtle consequences. For example,# Julia\n[ [1, 2], 3 ]\n\nis a vector of two elements, the first of which is itself a vector. However,# Julia\n[ [1, 2]; 3 ]\n\nis a vector with three numerical elements, because it is the “vertical stacking” of a 2-vector and a scalar.\n\nIn Python, scalars, vectors, and matrices are also different things. Moreover, Python has lists that are more fundamental than vectors. Thus, while [1,2,3] is a vector in MATLAB and Julia, it is a list in Python. In NumPy, often lists can be used in place of vectors, but not always. When vector shape matters, the implicit NumPy interpretation is as a row.","type":"content","url":"/differences#linear-algebra","position":5},{"hierarchy":{"lvl1":"Key language differences","lvl3":"Vectors of vectors","lvl2":"Linear algebra"},"type":"lvl3","url":"/differences#vectors-of-vectors","position":6},{"hierarchy":{"lvl1":"Key language differences","lvl3":"Vectors of vectors","lvl2":"Linear algebra"},"content":"One recurring situation that highlights the different approaches is when data takes the form of a sequence of identically-sized vectors. This could be an iteration in a vector space, or the solution of a system of ODEs at selected times, for example.\n\nMATLAB’s choice is to arrange the data as an array. Say that x1, x2, and x3 are 2×1 vectors. Then a compact representation is% MATLAB\nX = [x1, x2, x3]    % 2×3 \nX = [x1 x2 x3]      % same thing \n\nMATLAB would call X a matrix, though it might or might not require the mathematical properties of linear algebra. One downside is that you must decide on its shape in advance: are the members of the sequence rows or columns? It’s an arbitrary choice, but a consequential one.\n\nIn Julia, the two syntaxes above are valid but different:# Julia\nX = [x1, x2, x3]    # 3-element vector of 2-element vectors\nX = [x1 x2 x3]      # 2×3 matrix\n\nEach representation has advantages and drawbacks, and you have to know which you are working with.\n\nIn NumPy, all roads lead to the same place:# Python\nX = np.array([x1, x2, x3])    # 3-element vector of 2-element vectors AND a 3×2 matrix\n\nThere is nothing to decide or remember here, because the two representations are interchangeable.","type":"content","url":"/differences#vectors-of-vectors","position":7},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Functions"},"type":"lvl2","url":"/differences#functions","position":8},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Functions"},"content":"In MATLAB, functions are traditionally defined in files with the same name as the function. The function is called from the command line or from other functions by using the root name of the file. So, if you have a function defined in a file foo.m on the MATLAB path, foo calls it. If you want to refer to the function without calling it, so that it can be passed as an argument to another function, you refer to it as @foo.\n\nIn Julia and Python, functions can be defined anywhere. The name of the function is a reference to it, not a call. To call the function, you use () after the name, even if it does not take any arguments.\n\nAll three languages also have the idea of an anonymous function, which is never given a name. These are equivalent:\n\nJulia\n\nMATLAB\n\nPython\n\nx -> x^2\n\n@(x) x^2\n\nlambda x: x**2","type":"content","url":"/differences#functions","position":9},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Vectorization"},"type":"lvl2","url":"/differences#vectorization","position":10},{"hierarchy":{"lvl1":"Key language differences","lvl2":"Vectorization"},"content":"Often we want to apply a function to every element of a vector or matrix. This can be called vectorization or broadcasting, though both terms can have other related meanings. In MATLAB and NumPy, most of the functions provided, such as cos and exp, are defined to work elementwise on vectors and matrices. NumPy takes it further, defining operators like *, /’ and ** to work elementwise as well. MATLAB, on the other hand, requires the use of .*, ./, and .^ for these, reserving *, /, and ^ for operations defined in the sense of linear algebra.\n\nWhen it comes to *, /’ and ^, Julia is like MATLAB. But it is more extreme in a different way. Mathematical functions such as cos and exp are not defined to work elementwise. Instead, you have to use a dot . after the function name. For example,# Julia\nx = [-1, 0, 1] * pi\ncos(x)    # error\ncos.(x)   # [-1, 1, -1]\n\nAt first, this seems like an enormous pain in the booty, especially when you want to combine multiple operations. But there is a nice shortcut for that:# Julia\ncos.(x.^3 + 2x.^2 .- 1)    # 🤮\n@. cos(x^3 + 2x^2 - 1)     # 💯\n\nAnd there is a huge reward: you can use a vectorizing dot with any function, including ones that you define. So you only ever need to write a function as though it will operate on a scalar.\n\nBy contrast, MATLAB and NumPy make you implement elementwise behavior yourself whenever you write a function that needs it. In MATLAB, we often end up with expressions such as% MATLAB\n@(x) cos(x.^3 + 2*x.^2 - 1)\n\nso that the function is available elementwise. NumPy would not require any dotting in this case; for more complex functions, it provides np.vectorize to help, but that is not a panacea.\n\nYes, we use the American convention of “brackets” to mean “square brackets.” Take that, England!\n\nMATLAB has blurred things in recent years by allowing function definitions within functions and script files, but not at the command line. Because of the way this book is constructed, we have to define functions in separate files.\n\nJulia fanboys would claim that the error you get for x - 1 rather than x .- 1 when x is a vector is itself a reward, because it can help you catch subtle mistakes. We concede the point, but it’s hard to feel appreciative at the moment you receive one of these errors.","type":"content","url":"/differences#vectorization","position":11},{"hierarchy":{"lvl1":"Preface to the original edition"},"type":"lvl1","url":"/preface-original","position":0},{"hierarchy":{"lvl1":"Preface to the original edition"},"content":"I’ve developed an obscene interest in computation, and I’ll be returning to the United States a better and impurer man.\n\nJohn von Neumann\n\nIt might seem that computing should simply be a matter of translating formulas from the page to the machine. But even when such formulas are known, applying them in a numerical fashion requires care. For instance, rounding off numbers at the sixteenth significant digit can lay low such stalwarts as the quadratic formula! Fortunately, the consequences of applying a numerical method to a mathematical problem are quite understandable from the right perspective. In fact, it is our mastery of what can go wrong in some approaches that gives us confidence in the rest of them.\n\nIf mathematical modeling is the process of turning real phenomena into mathematical abstractions, then numerical computation is largely about the transformation from abstract mathematics to concrete reality.  Many science and engineering disciplines have long benefited from the tremendous value of the correspondence between quantitative information and mathematical manipulation. Other fields, from biology to history to political science, are rapidly catching up. In our opinion, a young mathematician who is ignorant of numerical computation in the 21st century has much in common with one who was ignorant of calculus in the 18th century.","type":"content","url":"/preface-original","position":1},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the student"},"type":"lvl2","url":"/preface-original#to-the-student","position":2},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the student"},"content":"Welcome! We expect that you have had lessons in manipulating power series, solving linear systems of equations, calculating eigenvalues of matrices, and obtaining solutions of differential equations. We also expect that you have written computer programs that take a nontrivial number of steps to perform a well-defined task, such as sorting a list. Even if you have rarely seen how these isolated mathematical and computational tasks interact with one another, or what they have to do with practical realities, you are in the audience for this book.\n\nBased on our experiences teaching this subject, our guess is that some rough seas may lie ahead of you. Probably you do not remember learning all parts of calculus, linear algebra, differential equations, and computer science with equal skill and fondness. This book draws from all of these areas at times, so your weaknesses are going to surface once in a while. Furthermore, this may be the first course you have taken that does not fit neatly within a major discipline. Von Neumann’s use of “impurer” in the quote above is a telling one: numerical computation is about solving problems, and the search for solution methods that work well can take us across intellectual disciplinary boundaries. This mindset may be unfamiliar and disorienting at times.\n\nDon’t panic! There is a great deal to be gained by working your way through this book. It goes almost without saying that you can acquire computing skills that are in much demand for present and future use in science, engineering, and mathematics—and increasingly, in business, social science, and humanities, too. There are less tangible benefits as well. Having a new context to wrestle with concepts like Taylor series and matrices may shed new light on why they are important enough to learn. It can be exhilarating to apply skills to solve relatable problems. Finally, the computational way of thought is one that complements other methods of analysis and can serve you well.","type":"content","url":"/preface-original#to-the-student","position":3},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the instructor"},"type":"lvl2","url":"/preface-original#to-the-instructor","position":4},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"To the instructor"},"content":"The plausibly important introductory material on numerical computation for the majority of undergraduate students easily exceeds the capacity of two semesters—and of one textbook. As instructors and as authors, we face difficult choices as a result. We set aside the goal of creating an agreeable canon. Instead we hope for students to experience an echo of that “obscene interest” that von Neumann so gleefully described and pursued. For while there are excellent practical reasons to learn about numerical computing, it also stands as a subject of intellectual and even emotional relevance. We have seen students excited and motivated by applications of their newly found abilities to problems in mechanics, biology, networks, finance, and more—problems that are of unmistakable importance in the jungle beyond university textbooks, yet largely impenetrable using only the techniques learned within our well-tended gardens.\n\nIn writing this book, we have not attempted to be encyclopedic. We’re sorry if some of your favorite topics don’t appear or are minimized in the book. (It happened to us too; many painful cuts were made from prior drafts.) But in an information-saturated world, the usefulness of a textbook lies with teaching process, not content. We have aimed not for a cookbook but for an introduction to the principles of cooking.\n\nStill, there are lots of recipes in the book—it’s hard to imagine how one could become a great chef without spending time in the kitchen! Our language for these recipes is MATLAB for a number of reasons: it is precise, it is executable, it is as readable as could be hoped for our purposes, it rewards thinking at the vector and matrix level, and (at this writing) it is widespread and worth knowing.\nThere are 46 standalone functions and over 150 example scripts, all of them downloadable exactly as seen in the text. Some of our codes are quite close to production quality, some are serviceable but lacking, and others still are meant for demonstration only. Ultimately our codes are mainly meant to be clear, not ideal. We try to at least be explicit about the shortcomings of our implementations.\n\nJust as good coding and performance optimization are secondary objectives of the book, we cut some corners in the mathematics as well. We state and in some cases prove the most essential and accessible theorems, but this is not a theorem-oriented book, and in some cases we are content with less precise arguments. We have tried to make clear where solid proof ends and where approximation, estimation, heuristics, and other indispensable tools of numerical analysis begin.\n\nThe examples and exercises are meant to show and encourage a numerical mode of thought. As such they often focus on issues of convergence, experimentation leading to abstraction, and attempts to build on or refine presented ideas. Some exercises follow the premise that an algorithm’s most interesting mode of operation is failure. We expect that any learning resulting from the book is likely to take place mostly from careful study of the examples and working through the problems.","type":"content","url":"/preface-original#to-the-instructor","position":5},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"Acknowledgments"},"type":"lvl2","url":"/preface-original#acknowledgments","position":6},{"hierarchy":{"lvl1":"Preface to the original edition","lvl2":"Acknowledgments"},"content":"We are, of course, deeply indebted to all who taught us and inspired us about numerical computation over the years. We are thankful to Rodrigo Platte, who used the book before it was fully baked and offered numerous suggestions. We thank an enthusiastic group of grad students for proofreading help: Samuel Cogar, Shukai Du, Kristopher Hollingsworth, Rayanne Luke, Navid Mirzaei, Nicholas Russell, and Osman Usta.  We are also grateful to Paula Callaghan and the publishing team at SIAM, whose dedication to affordable, high-quality books makes a real difference in the field.\n\nWe thank our families for their support and endurance. Last but not least, we are grateful to the many students at the University of Delaware who have taken courses based on iterations of this book. Their experiences are what convinced us that the project was worth finishing.","type":"content","url":"/preface-original#acknowledgments","position":7},{"hierarchy":{"lvl1":"Preface to the original edition","lvl3":"Contents","lvl2":"Acknowledgments"},"type":"lvl3","url":"/preface-original#contents","position":8},{"hierarchy":{"lvl1":"Preface to the original edition","lvl3":"Contents","lvl2":"Acknowledgments"},"content":"Chapter 1 explains how computers represent numbers and arithmetic, and what doing so means for mathematical expressions. Chapter 2 discusses the solution of square systems of linear equations and, more broadly, basic numerical linear algebra. Chapter 3 extends the linear algebra to linear least squares. These topics are the bedrock of scientific computing, because “everything” has multiple dimensions, and while “everything” is also nonlinear, our preferred starting point is to linearize.\n\nChapters 4 through 6 introduce what we take to be the rest of the most common problem types in scientific computing: roots and minimization of algebraic functions, piecewise approximation of functions, numerical analogs of differentiation and integration, and initial-value problems for ordinary differential equations. We also explain some of the most familiar and reliable ways to solve these problems, effective up to a certain point of size and/or difficulty. Chapters 1 through 6 can serve for a single-semester survey course. If desired, Chapter 6 could be left out in favor of one of Chapters 7, 8, or 9.\n\nThe remaining chapters are intended for a second course in the material. They go into more sophisticated types of problems (eigenvalues and singular values, boundary value problems, and partial differential equations), as well as more advanced techniques for problems from the first half (Krylov subspace methods, spectral approximation, stiff problems, boundary conditions, and tensor-product discretizations).","type":"content","url":"/preface-original#contents","position":9},{"hierarchy":{"lvl1":"Preface to the Julia edition"},"type":"lvl1","url":"/preface","position":0},{"hierarchy":{"lvl1":"Preface to the Julia edition"},"content":"The invention of MATLAB introduced a new paradigm within research of numerical computation. Those concerned primarily with prototyping and perfecting algorithms, particularly those involving lots of linear algebra, optimization, and differential equations, were happy to adopt MATLAB as a primary computing environment. It offered concise syntax for such problems, freedom from variable types and declarations, compiling, and linking programs, convenient tools for analyzing results, and cross-platform uniformity. There were drawbacks, however, when it came to performance, scalability, and language features beyond the manipulation of vectors and matrices. While MATLAB has steadily made serious progress on closing the performance gap and introducing new language features, there remain computing tasks for which it is not ideally suited.\n\nThe landscape changed when the SciPy, NumPy, and Matplotlib packages for scientific computing in Python became stable and polished. These enabled Python to offer a fully featured MATLAB alternative that is free, open, and tightly integrated with a much larger world of computing. Among these valuable advances, though, a serious compromise lurked: performance got worse, often by orders of magnitude. While there are notable efforts to overcome the bottlenecks for many use cases, Python continues to face deep and steep performance challenges as a general-purpose scientific computing ecosystem.\n\nJulia was designed from its inception to prioritize numerical scientific computing. It has reaped the benefits of learning from decisions and adaptations made in MATLAB and Python, borrowing the best parts from them and tackling their deficiencies. Julia’s older cousins enjoy a big head start, so it’s impossible to know what the size of Julia’s niche will ultimately be, but interest has continued to build.\n\nWhy teach using Julia? The immediate benefits of Julia over MATLAB for the material in this text include:\n\nJulia allows Unicode characters, such as Greek letters, subscripts, and symbols, as variable names and operators, which makes code look more like mathematics.\n\nJulia makes it effortless to define functions inside of scripts as well as other functions.\n\nJulia’s broadcasting syntax clarifies how to apply functions elementwise to arrays.\n\nComprehensions are convenient and concise ways to construct vectors and matrices.\n\nJulia makes it easier to define keyword and optional function arguments.\n\nThere are also differences that cut both ways; for instance, Julia is often stricter about data types and sizes, which makes it more verbose and more prone to error, but arguably less likely to finish with unexpected results.\n\nMoreover, there are some tradeoffs. MATLAB ships with and installs everything needed for this text, while Julia requires a small installation effort to get started. MATLAB’s documentation is superior, and it’s easier to get accurate help on the Internet. MATLAB’s integrated desktop, particularly the debugger, are not yet fully matched in Julia.\n        \nThere is also a wider context to consider. Julia skills are more likely to be directly applicable in, or more easily transferrable to, high-performance applications. Julia interoperates easily with Python, R, C, and even MATLAB. Julia is native to the widely used Jupyter notebook system that currently dominates data science. Not least, as a free and open-source environment, Julia enables fully reproducible computing, which is increasingly appreciated as essential to long-term progress in research.","type":"content","url":"/preface","position":1},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from Julia"},"type":"lvl2","url":"/preface#what-to-expect-from-julia","position":2},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from Julia"},"content":"Unlike MATLAB and Python, Julia is just-in-time (JIT) compiled, not interpreted. As a result, large packages, including several supporting the code in this book, can take a few seconds to load. Furthermore, if you make a change to one of your own functions, or apply it to new types of function arguments, Julia may hesitate a moment while it compiles the necessary code. On slower hardware, or with frequent revision, the lag can become irritating.","type":"content","url":"/preface#what-to-expect-from-julia","position":3},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from this book"},"type":"lvl2","url":"/preface#what-to-expect-from-this-book","position":4},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"What to expect from this book"},"content":"*Supplemental material, including animations, downloadable code and examples, suggested projects, and more, can be found at \n\nhttps://​bookstore​.siam​.org​/ot177​/bonus.\n\nWe do not attempt to teach how to become a great Julia programmer. That goal is too ambitious when stacked alongside the mathematical ones. Instead we hope to exhibit decent style and avoid promoting bad habits. But when there is a conflict, clarity and simplicity usually override performance concerns.  A virtue of Julia is that one can start with a working straightforward code that can be adapted and improved to meet performance demands; we are introducing just the first stage of this process.\n\nOne choice advanced users might question is that we address vectors and matrices as starting from index 1, rather than using more general constructs such as eachindex, begin, and first. Our mathematics makes those specific references too, and in most languages, one must learn to deal directly with the difference between, say, 1-indexing and 0-indexing.\n\nAnother notable choice we have made is the use of the popular Plots package for graphics. There are many other fine choices, including and not limited to PyPlot, Makie, and PlotlyJS, but we needed to be concrete.\n\nBeyond that, we touch briefly on available packages that offer advanced functionality for the problem types we study. Our hope is that the student will not only learn fundamentals by working with simple codes in the book, but also learn about the existence and syntax of some power tools for serious applications.\n\nFinally, we have made no mention of one of Julia’s defining features, multiple dispatch. Using its power wisely edges into advanced software design and usually requires a bird’s-eye view of problems that beginners lack. We want to let students expend as much of their cognitive budget as possible on the mathematical principles that have universal application.","type":"content","url":"/preface#what-to-expect-from-this-book","position":5},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"Acknowledgments"},"type":"lvl2","url":"/preface#acknowledgments","position":6},{"hierarchy":{"lvl1":"Preface to the Julia edition","lvl2":"Acknowledgments"},"content":"We are indebted to Qinying Chen, Hugo Diaz, Mary Gockenbach, Aidan Hamilton, Pascal Kingsley Kataboh, Lindsey Jacobs, Ross Russell, and Jerome Troy, who made this text more accurate and more readable with their sharp eyes and great suggestions. And we are deeply grateful to Paula Callaghan at SIAM, whose patience, dedication, and wisdom were crucial to seeing this through to the end.\n\nIt is strongly recommended that you use at least version 1.6 of Julia. In earlier versions, the wait to compile and load packages can become long.\n\nIn a fast-changing language like Julia, yesterday’s performance roadblocks can disappear anyway.","type":"content","url":"/preface#acknowledgments","position":7},{"hierarchy":{"lvl1":"Index"},"type":"lvl1","url":"/genindex","position":0},{"hierarchy":{"lvl1":"Index"},"content":"A\n\nA New Hope: \n\nHan Solo, Star Wars: A New Hope, \n\nC3PO, Star Wars: A New Hope, \n\nHan Solo, Star Wars: A New Hope, \n\nC3PO, Star Wars: A New Hope, \n\nWedge Antilles, Star Wars: A New Hope, \n\nObi-Wan Kenobi, Star Wars: A New Hope, \n\nObi-Wan Kenobi, Star Wars: A New Hope\n\nA-stability and A(α)-stability: Definition 11.4.2\n\nAdams–Bashforth formula: Paragraph\n\nAdams–Moulton formula: Paragraph\n\nAllen–Cahn equation: \n\nExample 10.5.4, \n\nExample 13.4.4\n\nArnoldi iteration: Algorithm 8.4.1, \n\n(8.6.2), \n\nArnoldi iteration\n\nabsolute stability: Definition 11.3.1\n\naccuracy (relative vs. absolute): Paragraph\n\nadaptivity:\n\nin IVP solver:  \n\nParagraph, \n\nSection 6.7.4\n\nin integration:  \n\nSection 5.7.2adjacency matrix: Definition 7.1.1, \n\nParagraph, \n\nadjacency matrix\n\nadjoint: \n\nadjoint\n\nadjoint of a matrix: Paragraph, \n\nParagraph\n\nadvection equation: Definition 12.1.1, \n\nParagraph, \n\nadvection equation\n\nadvection-diffusion equation: Paragraph, \n\nParagraph, \n\nExample 13.2.3, \n\nExample 13.4.3\n\nalgorithm: Paragraph, \n\nalgorithm\n\nargmin: Definition 3.1.1\n\nasymptotic: \n\nasymptotic\n\nasymptotic notation: Definition 2.5.1\n\n\n\nB\n\nBauer–Fike theorem: Paragraph\n\nBessel equation: \n\nList\n\nBessel function: \n\nExample 4.1.1\n\nBlack–Scholes equation: \n\nParagraph\n\nBroyden update: Paragraph\n\nbackward difference: Definition 5.4.2\n\nbackward differentiation formula for IVPs: Paragraph\n\nbackward error: Definition 1.4.1, \n\nObservation 4.1.1, \n\nParagraph, \n\nbackward error\n\nin a linear system:  \n\nParagraphbackward substitution: \n\nParagraph, \n\nbackward substitution\n\nbanded matrix: \n\nParagraph, \n\nParagraph\n\nbandwidth: \n\nbandwidth\n\nbandwidth of a matrix: Definition 2.9.1\n\nbarycentric interpolation formula: Theorem 9.2.1, \n\nbarycentric interpolation formula\n\nbarycentric weights: Definition 9.2.1\n\nbig-O: \n\nbig-O\n\nboundary conditions:\n\ninflow:  Paragraph\n\nnumerical implementation of:  \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nperiodic:  Paragraphboundary-value problem: \n\nboundary-value problem\n\n\n\nC\n\nC3PO: \n\nC3PO, Star Wars: A New Hope, \n\nC3PO, Star Wars: A New Hope\n\nCFL condition: Theorem 12.2.1\n\nCarrier equation: \n\nList\n\nChebyshev points:\n\nfirst kind:  Paragraph\n\nsecond kind:  Paragraph, \n\nParagraphChebyshev polynomials: Definition 9.4.4\n\nCholesky factorization: \n\nTheorem 2.9.2, \n\nCholesky factorization\n\nClenshaw–Curtis integration: Paragraph\n\ncardinal function: Definition 5.1.2, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\ncardinal function\n\ncentered difference: Definition 5.4.2\n\ncharacteristic polynomial: Paragraph\n\ncollocation: Paragraph, \n\ncollocation\n\ncondition number: \n\ncondition number\n\nof a matrix:  \n\nParagraph, \n\nDefinition 3.2.3, \n\nParagraph, \n\nNotebook-code, \n\nNotebook-code, \n\nNotebook-code\n\nof a scalar function:  Definition 1.2.1\n\nof eigenvalues:  \n\nParagraph\n\nof elementary functions:  \n\nParagraph\n\nof initial-value problems:  \n\nParagraph\n\nof interpolation:  \n\nTheorem 5.1.1, \n\nTheorem 5.2.1\n\nof linear least squares:  \n\nDefinition 3.2.3\n\nof linear system:  \n\nParagraph\n\nof normal equations:  \n\nParagraph\n\nof rootfinding:  \n\nTheorem 4.1.1conjugate gradients: Definition 8.6.1\n\nconservation law: Paragraph\n\ncontraction mapping: Paragraph\n\nconvergence rate:\n\nalgebraic:  Definition 5.2.2\n\nlinear:  Definition 4.2.2, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nquadratic:  Definition 4.3.1, \n\nParagraph\n\nspectral:  Paragraph, \n\nParagraph\n\nsuperlinear:  Paragraphcubic spline: Definition 5.3.1, \n\ncubic spline\n\n\n\nD\n\nDahlquist theorems: \n\nTheorem 6.8.2, \n\nTheorem 6.8.3, \n\nTheorem 11.4.1\n\nDirichlet boundary condition: Definition 10.1.2, \n\nParagraph\n\nDirichlet boundary conditions: \n\nParagraph\n\nDirichlet condition: \n\nDirichlet condition\n\ndata fitting: \n\nParagraph\n\nby straight line:  \n\nParagraph\n\nnonlinear:  \n\nParagraph\n\npower law:  \n\nParagraphdiagonal matrix: Paragraph, \n\nDefinition 7.2.3, \n\nDefinition 7.3.1\n\ndiagonalizable matrix: Definition 7.2.3, \n\ndiagonalizable matrix\n\ndifferentiation matrix: Paragraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\ndifferentiation matrix\n\ndiffusion equation: See \n\nheat equation\n\ndimension reduction: \n\nParagraph, \n\nParagraph\n\ndivide and conquer: \n\nSection 5.7.2\n\ndomain of dependence: Paragraph\n\ndominant eigenvalue: \n\ndominant eigenvalue\n\ndouble exponential transformation: Paragraph\n\ndouble precision: \n\ndouble precision\n\n\n\nE\n\nEuler's method: Paragraph, \n\nParagraph\n\nEuler–Maclaurin formula: Paragraph\n\nEuler’s method: \n\nEuler’s method\n\neigenvalue: Definition 7.2.1, \n\nComment, \n\neigenvalue\n\nconditioning of:  Paragraph\n\ndominant:  Paragraph, \n\nParagrapheigenvalue decomposition: Definition 7.2.3, \n\nParagraph, \n\nParagraph, \n\neigenvalue decomposition\n\neigenvector: Definition 7.2.1, \n\neigenvector\n\nelliptic PDE: \n\nParagraph\n\nevolutionary PDE: \n\nParagraph, \n\nevolutionary PDE\n\nextrapolation: Paragraph, \n\nextrapolation\n\n\n\nF\n\nFFT (fast Fourier transform): Paragraph\n\nFrancis QR iteration: Paragraph\n\nFrobenius norm: \n\nFrobenius norm\n\nfill-in of sparse matrices: \n\nParagraph\n\nfinite differences: Definition 5.4.1, \n\nParagraph, \n\nParagraph, \n\nfinite differences\n\nfor boundary value problems:  \n\nParagraph\n\nfor parabolic PDE:  \n\nParagraph, \n\nParagraph\n\nmatrix:  \n\nParagraphfinite element method: Paragraph\n\nfinite element method (FEM): \n\nfinite element method (FEM)\n\nfixed point problem: \n\nfixed point problem\n\nfixed-point iteration: Algorithm 4.2.1, \n\nfixed-point iteration\n\nfixed-point problem: Definition 4.2.1\n\nfloating-point numbers: Definition 1.1.1, \n\nParagraph, \n\nfloating-point numbers\n\nflops: \n\nParagraph, \n\nflops\n\nforward difference: Definition 5.4.2\n\nforward substitution: \n\nParagraph, \n\nforward substitution\n\n\n\nG\n\nGMRES: Algorithm 8.5.1, \n\nGMRES\n\npreconditioning in:  \n\nDefinition 8.8.1\n\nrelationship to MINRES:  \n\nParagraph\n\nrestarting:  ParagraphGalerkin conditions: (10.6.10)\n\nGaussian elimination: \n\nParagraph, \n\nGaussian elimination\n\nGaussian integration: Paragraph\n\nGauss–Newton method: Algorithm 4.7.1, \n\nGauss–Newton method\n\nGram matrix: Definition 9.4.2\n\nGregory integration formula: (5.6.19)\n\ngenerating polynomials: Paragraph, \n\ngenerating polynomials\n\nglobal error: Definition 6.2.3, \n\nglobal error\n\ngraph: Definition 7.1.1, \n\ngraph\n\n\n\nH\n\nHan Solo: \n\nHan Solo, Star Wars: A New Hope, \n\nHan Solo, The Empire Strikes Back, \n\nHan Solo, Star Wars: A New Hope, \n\nHan Solo, The Empire Strikes Back\n\nHorner's algorithm: Example 1.3.1\n\nHouseholder reflector: Definition 3.4.1\n\nhat functions: \n\nParagraph, \n\nhat functions\n\nheat equation: Definition 11.1.1, \n\nParagraph, \n\nExample 13.2.2, \n\nheat equation\n\nhermitian: \n\nhermitian\n\nhermitian matrix: Paragraph, \n\nParagraph, \n\nTheorem 7.3.2\n\nhermitian positive definite matrix: \n\nhermitian positive definite matrix See \n\nsymmetric positive definite matrix\n\nhomogeneous boundary condition: \n\nDefinition 10.1.2, \n\nParagraph, \n\nhomogeneous boundary condition\n\nhyperbolic PDE: Definition 12.1.1\n\n\n\nI\n\nIEEE 754: \n\nParagraph\n\nidentity matrix: Paragraph, \n\nParagraph, \n\nidentity matrix\n\nill-conditioned: \n\nill-conditioned\n\nimage (as a matrix): \n\nParagraph, \n\nExample 7.5.1, \n\nParagraph\n\nimplicit: \n\nimplicit\n\nimplicit IVP solver: Definition 6.6.1, \n\nParagraph\n\nimproper integral: \n\nParagraph\n\ninduced matrix norm: \n\ninduced matrix norm\n\ninitial-boundary-value problem: Paragraph\n\ninitial-value problem: Definition 6.1.1, \n\ninitial-value problem\n\none-step method for:  Definition 6.2.1inner product: \n\nParagraph, \n\ninner product\n\nof functions:  Definition 9.4.1\n\nof vectors:  Paragraphinner product space: Definition 9.4.1\n\ninterpolation: Definition 5.1.1, \n\nParagraph, \n\ninterpolation\n\nby piecewise linear polynomials:  \n\nParagraph\n\nby piecewise polynomials:  \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nby polynomials:  \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nby trigonometric polynomials:  Paragraphinverse iteration: Algorithm 8.3.1, \n\ninverse iteration\n\ninvertible matrix: Paragraph\n\n\n\nJ\n\nJacobian matrix: Paragraph, \n\nParagraph, \n\nParagraph, \n\nJacobian matrix\n\nJulia:\n\n+=:  Paragraph\n\n.+:  Paragraph\n\n.-:  Paragraph\n\n::  Paragraph, \n\nParagraph\n\n@.:  Paragraph\n\n@animate:  Paragraph\n\n@sprintf:  Paragraph, Paragraph\n\nBoolean indexing:  \n\nParagraph\n\nDiagonalPreconditioner:  Paragraph\n\nFNC:  Paragraph\n\nI:  Paragraph\n\nImages:  Paragraph, Paragraph\n\nLinearMap:  Paragraph\n\nNaN:  \n\nParagraph\n\nODEProblem:  Notebook-code\n\nPair:  Paragraph\n\nRational:  Paragraph\n\nSpline1D:  Paragraph\n\n\\!:  Paragraph\n\n\\':  Paragraph, \n\nParagraph\n\n\\\\:  Paragraph, \n\nTabSet, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\nadjoint:  Paragraph, \n\nParagraph\n\nannotate!:  Notebook-code, Notebook-code\n\nanonymous functions:  Paragraph\n\nbreak:  Algorithm 4.3.2\n\nbroadcasting:  Grid, \n\nParagraph, \n\nParagraph, \n\nParagraph\n\ncg:  Paragraph\n\ncholesky:  Paragraph\n\ncollect:  Paragraph\n\ncomprehension:  Paragraph\n\ncond:  Paragraph, \n\nParagraph\n\ndestructuring:  Paragraph\n\ndiag:  Paragraph, Paragraph\n\ndiagm:  Paragraph, \n\nParagraph, \n\nParagraph\n\neachindex:  Algorithm 9.5.1\n\neigen:  Paragraph\n\neigs:  Paragraph\n\neigvals:  Paragraph\n\neltype:  Paragraph\n\nend:  Paragraph\n\nenumerate:  Paragraph, Paragraph\n\nfft:  Paragraph\n\nfill:  Paragraph\n\nfit:  Paragraph, Paragraph\n\nfor:  About the code, Paragraph\n\nfunctions:  Paragraph\n\ngmres:  Paragraph\n\ngraphplot:  Paragraph\n\nilu:  Paragraph\n\nin-place function:  Paragraph, Paragraph\n\nindexing arrays:  Paragraph, \n\nAttention, \n\nParagraph, \n\nParagraph\n\nisinf:  Algorithm 9.2.1\n\nisodd:  Algorithm 9.5.1\n\nkeyword function arguments:  Algorithm 4.3.2, \n\nAlgorithm 5.7.1, \n\nNotebook-code\n\nkron:  Paragraph\n\nlength:  About the code, Paragraph\n\nmaximum:  Paragraph\n\nminimum:  Paragraph\n\nminres:  Notebook-code\n\nnamespace:  Paragraph\n\nnnz:  Paragraph\n\nnorm:  Paragraph\n\nnormalize:  Paragraph, \n\nParagraph\n\nopnorm:  Paragraph\n\nplotting functions:  \n\nParagraph\n\npush!:  \n\nNotebook-code, \n\nNotebook-code\n\npush\\!:  Paragraph\n\nquadgk:  Paragraph\n\nrange:  Paragraph, \n\nGrid\n\nrank:  Paragraph\n\nreshape:  \n\nParagraph\n\nreturn:  Paragraph\n\nscatter:  Paragraph\n\nscientific notation:  Paragraph\n\nsize:  Paragraph\n\nsolve:  Notebook-code\n\nsortby:  Paragraph\n\nsortperm:  Paragraph\n\nsparse:  Paragraph\n\nspdiagm:  Paragraph\n\nsplatting:  Paragraph\n\nsprandsym:  Paragraph\n\nstring interpolation:  Paragraph\n\nsubplots:  Paragraph\n\nsum:  Paragraph, \n\nAbout the code\n\nsummarysize:  Paragraph\n\nsvd:  Paragraph\n\nsvdvals:  Paragraph\n\nternary operator:  Algorithm 9.5.1\n\ntranspose:  Paragraph\n\ntril:  Paragraph, \n\nParagraph\n\ntriu:  Paragraph, \n\nParagraph\n\nusing:  Paragraph\n\nvec operation:  Paragraph\n\n÷:  Paragraph\n\nK\n\nKronecker product: Definition 13.3.2, \n\nKronecker product\n\nKrylov matrix: Definition 8.4.1\n\nKrylov subspace: Definition 8.4.1, \n\nKrylov subspace\n\n\n\nL\n\nLU factorization: Definition 2.4.1, \n\nParagraph, \n\nParagraph, \n\nLU factorization\n\nincomplete:  ParagraphLagrange formula: \n\nLagrange formula\n\nLagrange interpolation formula: Theorem 9.1.2\n\nLagrange polynomial: Definition 9.1.1\n\nLanczos iteration: Paragraph, \n\n(8.6.2), \n\nLanczos iteration\n\nLaplace equation: Paragraph, \n\nLaplace equation\n\nLegendre polynomials: Definition 9.4.3\n\nLevenberg's method: Algorithm 4.6.2\n\nLipschitz condition: Definition 4.2.3\n\nLuke Skywalker: \n\nLuke Skywalker, Return of the Jedi\n\nlinear combination: Paragraph\n\nlinear convergence: Definition 4.2.2, \n\nlinear convergence\n\nlinear least-squares problem: \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nlinear least-squares problem\n\nlinearization of an ODE: Definition 11.4.1\n\nlocal truncation error: \n\nlocal truncation error\n\nlogistic equation: Paragraph\n\n\n\nM\n\nMATLAB:\n\n::  Paragraph, \n\nParagraph\n\nBoolean indexing:  \n\nParagraph\n\nNaN:  \n\nParagraph\n\n\\':  Paragraph, \n\nParagraph\n\n\\\\:  Paragraph, Paragraph, \n\nParagraph\n\n\\~:  Paragraph\n\nadjoint:  Paragraph, \n\nParagraph\n\nanimation:  Paragraph\n\nanonymous functions:  Paragraph\n\nbroadcasting:  \n\nParagraph\n\nchol:  Paragraph\n\ncond:  Paragraph\n\ndiag:  Paragraph, Paragraph, Paragraph, Paragraph\n\ndiagm:  \n\nParagraph\n\neig:  Paragraph\n\neigs:  Paragraph\n\nend:  Paragraph\n\neye:  Paragraph, Paragraph\n\nfill:  Paragraph\n\nformat:  \n\nTip\n\nfplot:  Notebook-code\n\nfunctions:  Paragraph\n\ngmres:  Paragraph\n\ngraph (network):  Paragraph\n\nhold on:  Paragraph\n\nilu:  Paragraph\n\nindexing arrays:  Paragraph\n\nintegral:  Paragraph\n\nkron:  Paragraph\n\nlength:  Paragraph\n\nlinspace:  Paragraph, Paragraph\n\nmax:  Paragraph, Paragraph\n\nminres:  Notebook-code\n\nnnz:  Paragraph\n\nnorm:  Notebook-code, Paragraph\n\node:  Notebook-code\n\nones:  Paragraph\n\npcg:  Paragraph\n\nplot:  Paragraph\n\npolyval:  \n\nNotebook-code\n\nscatter:  Paragraph\n\nscientific notation:  Paragraph\n\nsize:  Paragraph\n\nsolve:  Notebook-code\n\nsparse:  Paragraph\n\nspdiags:  Paragraph\n\nsubplot:  Notebook-code\n\nsum:  Paragraph\n\nsvd:  Notebook-code\n\ntic and toc:  Paragraph\n\ntranspose:  Paragraph\n\ntril:  Paragraph, \n\nParagraph\n\ntriu:  Paragraph, \n\nParagraph\n\nvander:  Paragraph\n\nzeros:  ParagraphMINRES: Paragraph\n\nMaxwell's equations: \n\nParagraph\n\nmachine epsilon: Definition 1.1.2, \n\nParagraph, \n\nParagraph, \n\nmachine epsilon\n\nin double precision:  \n\nParagraphmantissa: See \n\nsignificand\n\nmass matrix: Paragraph\n\nmatrix condition number: \n\nmatrix condition number\n\nmatrix factorization: \n\nTheorem 7.3.2\n\nCholesky:  Theorem 2.9.2\n\nEVD:  Definition 7.2.3\n\nLU:  Definition 2.4.1, \n\nParagraph\n\nQR:  Paragraph, \n\nParagraph\n\nSVD:  Definition 7.3.1\n\npivoted LU:  Definition 2.6.1matrix inverse: Paragraph, \n\nParagraph\n\nmatrix multiplication: Paragraph\n\nmethod of lines: Paragraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nmethod of lines\n\nmultistep: \n\nmultistep\n\nmultistep method: Definition 6.6.1, \n\nParagraph\n\nimplementation of:  \n\nParagraph\n\nN\n\nNaN: \n\nParagraph\n\nNeumann boundary condition: Definition 10.1.2, \n\nParagraph\n\nNeumann condition: \n\nNeumann condition\n\nNewton's method: Algorithm 4.3.1, \n\nParagraph, \n\nParagraph\n\nmultidimensional:  Algorithm 4.5.1Newton’s method: \n\nNewton’s method\n\nnodes: \n\nnodes\n\nnonlinear least squares: Definition 4.7.1\n\nnonlinear least-squares problem: \n\nnonlinear least-squares problem\n\nnorm: \n\nnorm\n\nFrobenius:  Paragraph\n\nmatrix:  Definition 2.7.2, \n\nTheorem 7.3.3\n\nvector:  Paragraph, \n\nParagraphnormal equations: Theorem 3.2.1, \n\nTheorem 3.2.2, \n\nParagraph, \n\nnormal equations\n\nnormal matrix: Definition 7.2.5, \n\nnormal matrix\n\nnumerical integration: Paragraph, \n\nParagraph, \n\nnumerical integration\n\n\n\nO\n\nONC matrix: Definition 3.3.2, \n\nParagraph, \n\nONC matrix\n\nObi-Wan Kenobi: \n\nObi-Wan Kenobi, Star Wars: A New Hope, \n\nObi-Wan Kenobi, Star Wars: A New Hope\n\nOregonator: \n\nExample 11.4.1\n\none-step IVP method: \n\none-step IVP method\n\norder of accuracy: \n\nParagraph, \n\norder of accuracy\n\nof a finite-difference formula:  Definition 5.5.2, \n\nParagraph\n\nof a one-step IVP method:  Paragraph\n\nof an approximation:  Definition 5.2.2\n\nof numerical integration:  Definition 5.6.3\n\nof the finite element method:  \n\nParagraphorthogonal functions: Definition 9.4.1\n\northogonal matrix: Paragraph, \n\nParagraph, \n\nDefinition 3.4.1, \n\nDefinition 7.2.2, \n\northogonal matrix\n\northogonal polynomials: Paragraph, \n\northogonal polynomials\n\northogonal vectors: Paragraph, \n\northogonal vectors\n\northonormal vectors: Paragraph, \n\northonormal vectors\n\nouter product: Paragraph, \n\nParagraph, \n\nParagraph, \n\nouter product\n\noverdetermined: \n\noverdetermined\n\n\n\nP\n\nPLU factorization: Definition 2.6.1, \n\nPLU factorization\n\nPoisson equation: Paragraph\n\nPython:\n\n::  Paragraph\n\nImages:  Paragraph\n\nLinearOperator:  Paragraph\n\nNaN:  \n\nParagraph\n\nadjoint:  Paragraph\n\nanimation:  Paragraph\n\narange:  Paragraph\n\nargsort:  Paragraph\n\nbroadcast:  Paragraph\n\nbroadcasting:  \n\nParagraph, \n\nParagraph\n\ncg:  Paragraph\n\ncholesky:  Notebook-code\n\ncond:  Paragraph, \n\nNotebook-code, \n\nParagraph\n\ndestructuring:  Paragraph\n\ndiag:  Paragraph, Paragraph\n\ndiags:  Paragraph\n\neig:  Paragraph\n\neigs:  Paragraph\n\nelementwise multiplication:  Paragraph\n\nenumerate:  Notebook-code\n\ngmres:  Paragraph\n\nhstack:  Paragraph\n\nindexing arrays:  Paragraph\n\ninterp1d:  Paragraph\n\nkron:  Paragraph\n\nlinspace:  Paragraph\n\nlstsq:  Notebook-code\n\nmatrix_power:  Notebook-code\n\nmax:  Paragraph\n\nminres:  Notebook-code, \n\nParagraph\n\nnetworkx:  Notebook-code\n\nnnz:  Notebook-code\n\nnorm:  Paragraph, Paragraph\n\nplotting functions:  \n\nParagraph\n\npolyfit:  Paragraph\n\nquad:  Paragraph\n\nreturn:  Paragraph\n\nscientific notation:  Paragraph\n\nslice:  Paragraph\n\nsolve_ivp:  Notebook-code\n\nspilu:  Paragraph\n\nsum:  \n\nParagraph\n\nsvd:  Paragraph\n\ntranspose:  Paragraph\n\ntril:  Paragraph, \n\nParagraph\n\ntriu:  Paragraph, \n\nParagraph, \n\nNotebook-code\n\nvstack:  Paragraphparabolic PDE: Definition 11.1.1\n\nparameter continuation: Paragraph\n\npiecewise linear: \n\npiecewise linear\n\npiecewise linear interpolant: Paragraph\n\npivoting: Paragraph, \n\nParagraph, \n\nTheorem 2.9.2\n\npower iteration: Algorithm 8.2.1, \n\npower iteration\n\npreconditioning: Definition 8.8.1, \n\npreconditioning\n\npredator–prey model: \n\nParagraph\n\npseudoinverse: Definition 3.2.2, \n\npseudoinverse\n\n\n\nQ\n\nQR factorization: \n\nQR factorization\n\nquadratic convergence: Definition 4.3.1, \n\nquadratic convergence\n\nquadrature: See \n\nnumerical integration\n\nquasi-Newton method: \n\nParagraph\n\nquasi-Newton methods: \n\nquasi-Newton methods\n\nquasimatrix: Definition 9.4.2, \n\nquasimatrix\n\n\n\nR\n\nRayleigh quotient: Paragraph, \n\nRayleigh quotient\n\nReturn of the Jedi: \n\nLuke Skywalker, Return of the Jedi\n\nRobin boundary condition: Definition 10.1.2\n\nRunge phenomenon: Paragraph, \n\nRunge phenomenon\n\nRunge–Kutta: \n\nRunge–Kutta\n\nRunge–Kutta method: Paragraph, \n\nParagraph, \n\nParagraph\n\nreduced QR factorization: \n\nreduced QR factorization\n\nreduced SVD: \n\nreduced SVD\n\nresidual: \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nresidual\n\nof a linear system:  Definition 2.8.2\n\nof rootfinding:  Paragraphrestarting: \n\nrestarting\n\nrootfinding problem: Definition 4.1.1, \n\nParagraph, \n\n(11.5.6), \n\nrootfinding problem\n\nmultidimensional:  Definition 4.5.1roots:\n\nmultiplicity of:  Paragraph, \n\nParagraphrow pivoting: \n\nrow pivoting\n\n\n\nS\n\nSPD matrix: See \n\nsymmetric positive definite matrix\n\nSVD: See \n\nsingular value decomposition\n\nSimpson's formula: Paragraph, \n\nParagraph\n\nSylvester equation: Paragraph\n\nsecant method: Algorithm 4.4.1, \n\nsecant method\n\nsemidiscretization:\n\nsee method of lines:  Paragraphshifted inverse iteration: See \n\ninverse iteration\n\nshock wave: \n\nParagraph\n\nshooting: \n\nshooting\n\nsignificand: Paragraph\n\nsignificant digits: \n\nParagraph\n\nsimilar matrices: \n\nsimilar matrices\n\nsimilarity transformation: Paragraph, \n\nsimilarity transformation\n\nsimple root: \n\nsimple root\n\nsingular matrix: Paragraph\n\nsingular value decomposition: Definition 7.3.1, \n\nParagraph, \n\nsingular value decomposition\n\nthin form:  Paragraphsparse matrix: Paragraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nsparse matrix\n\nspectral convergence: \n\nspectral convergence\n\nspline (cubic spline): Definition 5.3.1\n\nstability: Paragraph, \n\nParagraph\n\nof IVP solvers:  \n\nParagraph\n\nof collocation:  \n\nParagraph\n\nof multistep methods:  \n\nDefinition 6.8.1\n\nof polynomial interpolation:  \n\nParagraphstability region: Definition 11.3.2, \n\nstability region\n\nsteepest descent: \n\nParagraph\n\nstep size: \n\nstep size\n\nstiff differential equation: Paragraph, \n\nParagraph, \n\nExample 6.7.2, \n\nstiff differential equation\n\nstiffness matrix: Paragraph\n\nsubtractive cancellation: Paragraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nParagraph, \n\nsubtractive cancellation\n\nsuperlinear convergence: Paragraph, \n\nsuperlinear convergence\n\nsymmetric matrix: Paragraph, \n\nDefinition 2.9.2, \n\nParagraph, \n\nParagraph, \n\nsymmetric matrix\n\nsymmetric positive definite matrix: Definition 2.9.3, \n\nParagraph, \n\nDefinition 8.6.1, \n\nsymmetric positive definite matrix\n\n\n\nT\n\nThe Empire Strikes Back: \n\nYoda, The Empire Strikes Back, \n\nHan Solo, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back, \n\nHan Solo, The Empire Strikes Back\n\ntensor-product domain: Paragraph, \n\ntensor-product domain\n\nthin QR factorization: \n\nthin QR factorization\n\nthin SVD: \n\nthin SVD\n\ntranspose: Paragraph, \n\nParagraph\n\ntrapezoid formula: \n\ntrapezoid formula\n\nfor an IVP:  Table 6.6.1, \n\nParagraph, \n\nParagraph\n\nfor integration:  Definition 5.6.2, \n\nParagraphtriangular matrix: Paragraph, \n\nParagraph, \n\ntriangular matrix\n\ntridiagonal matrix: Definition 2.9.1, \n\ntridiagonal matrix\n\ntrigonometric interpolation: \n\ntrigonometric interpolation\n\ntrigonometric polynomial: Definition 9.5.1\n\ntruncation error: \n\ntruncation error\n\nof a finite-difference formula:  Definition 5.5.1\n\nof a multistep IVP formula:  Paragraph\n\nof a numerical integration formula:  Definition 5.6.3\n\nof a one-step IVP solver:  Paragraph\n\nU\n\nunit lower triangular matrix: Paragraph\n\nunit roundoff: \n\nDefinition 1.1.2\n\nunit triangular matrix: \n\nunit triangular matrix\n\nunit vector: Paragraph, \n\nunit vector\n\nunitary matrix: Definition 7.2.2, \n\nDefinition 7.2.5, \n\nDefinition 7.3.1, \n\nTheorem 7.4.2, \n\nunitary matrix\n\nunstable: \n\nunstable\n\nunvec: Paragraph\n\nupper Hessenberg matrix: Definition 8.4.2, \n\nupper Hessenberg matrix\n\nupwind direction: Paragraph\n\n\n\nV\n\nVandermonde matrix: Definition 2.1.2, \n\nParagraph, \n\nVandermonde matrix\n\nvec: Paragraph\n\n\n\nW\n\nWedge Antilles: \n\nWedge Antilles, Star Wars: A New Hope\n\nwave equation: Paragraph, \n\nParagraph\n\nweak solution: Definition 10.6.1\n\nweights: \n\nweights\n\n\n\nY\n\nYoda: \n\nYoda, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back, \n\nYoda, The Empire Strikes Back\n\n\n\nZ\n\nzero-stability: Definition 6.8.1, \n\nzero-stability\n\n","type":"content","url":"/genindex","position":1},{"hierarchy":{"lvl1":"Home"},"type":"lvl1","url":"/home","position":0},{"hierarchy":{"lvl1":"Home"},"content":"\n\n\n\nThis is a new edition of the textbook \n\nFundamentals of Numerical Computation by Tobin A. Driscoll and Richard J. Braun. Bound print books are available for purchase in \n\nMATLAB and \n\nJulia editions at the SIAM Bookstore. That material is copyright © Society of Applied and Industrial Mathematics.\n\nWarning\n\nThere are some changes from the print editions. Exercise numbers may not align, for example.","type":"content","url":"/home","position":1},{"hierarchy":{"lvl1":"Home","lvl2":"Supporting us"},"type":"lvl2","url":"/home#supporting-us","position":2},{"hierarchy":{"lvl1":"Home","lvl2":"Supporting us"},"content":"This resource is provided free of charge. If you find it useful, please consider \n\nsupporting us!","type":"content","url":"/home#supporting-us","position":3},{"hierarchy":{"lvl1":"Home","lvl2":"Codes"},"type":"lvl2","url":"/home#codes","position":4},{"hierarchy":{"lvl1":"Home","lvl2":"Codes"},"content":"Codes are available for \n\nJulia, \n\nMATLAB, and \n\nPython. Please see the section on \n\nKey language differences for a discussion of the differences between these languages.\n\n\n\n\n\n\n\nAll the content is generated by the code that you see on the pages (after a few setup steps that are explained in the links above). If you see it done here, you should be able to make it work for yourself.","type":"content","url":"/home#codes","position":5},{"hierarchy":{"lvl1":"Home","lvl2":"Reporting errors"},"type":"lvl2","url":"/home#reporting-errors","position":6},{"hierarchy":{"lvl1":"Home","lvl2":"Reporting errors"},"content":"In the unlikely (hah!) event that you find an error, please \n\nopen an issue on GitHub. \n## Usage tips\n\n```{figure} _static/usage.mp4\"\nUsing this book.\n```\n\n","type":"content","url":"/home#reporting-errors","position":7},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1","position":0},{"hierarchy":{"lvl1":"Chapter 1"},"content":"","type":"content","url":"/chapter1","position":1},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"type":"lvl2","url":"/chapter1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"content":"Horner’s algorithm for evaluating a polynomial\n\n\"\"\"\n    horner(c, x)\n\nEvaluate a polynomial whose coefficients are given in ascending\norder in `c`, at the point `x`, using Horner's rule.\n\"\"\"\nfunction horner(c, x)\n    n = length(c)\n    y = c[n]\n    for k in n-1:-1:1\n        y = x * y + c[k]\n    end\n    return y\nend\n\nAbout the code\n\nThe quoted lines at the beginning are a documentation string. The function itself starts off with the keyword function, followed by a list of its input arguments. The first of these is presumed to be a vector, whose length can be obtained and whose individual components are accessed through square bracket notation. After the computation is finished, the return keyword indicates which value or values are to be returned to the caller.\n\nThe length function in line 8 returns the number of elements in vector c. Here, that value is one greater than the degree of the polynomial. The syntax c[i] accesses element i of a vector c. In Julia, the first index of a vector is 1 by default, so in line 9, the last element of c is accessed.\n\nThe for / end construct in lines 10–12 is a loop. The local variable k is assigned the value n-1, then the loop body is executed, then k is assigned n-2, the body is executed again, and so on until finally k is set to 1 and the body is executed for the last time.\n\nThe return statement in line 13 terminates the function and specifies one or more values to be returned to the caller.\n\nImportant\n\nThe Polynomials package for Julia provides its own fast methods for polynomial evaluation that supersede our simple horner. This will be the case for all the codes in this book because the problems we study are well-known and important. In a more practical setting, you would take implementations of basic methods for granted and build on top of them.\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"type":"lvl2","url":"/chapter1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"content":"","type":"content","url":"/chapter1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.1 Floating-point numbers","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#id-1-1","position":6},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.1 Floating-point numbers","lvl2":"Examples"},"content":"Example 1.1.2\n\nGetting started in Julia\n\nSee \n\nSetting up Julia for this book for instructions on how to install and use Julia for this book.\n\nRecall the grade-school approximation to the number π.\n\n@show p = 22/7;\n\nNot all the digits displayed for p are the same as those of π.\n\nTip\n\nThe value of pi is predefined and equivalent to π, which is entered by typing \\pi followed immediately by the Tab key.\n\n@show float(π);\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nTip\n\nA dollar sign $ in a string substitutes (or interpolates) the named variable or expression into the string.\n\nacc = abs(p-π)\nprintln(\"absolute accuracy = $acc\")\nprintln(\"relative accuracy = $(acc/π)\")\n\nHere we calculate the number of accurate digits in p.\n\nTip\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprintln(\"Number of accurate digits = $(-log10(acc/π))\")\n\nThis last value could be rounded down by using floor.\n\nExample 1.1.3\n\nIn Julia, 1 and 1.0 are different values, because they have different types:\n\n@show typeof(1);\n@show typeof(1.0);\n\nThe standard choice for floating-point values is Float64, which is double precision using 64 binary bits. We can see all the bits by using bitstring.\n\nbitstring(1.0)\n\nThe first bit determines the sign of the number:\n\nTip\n\nSquare brackets concatenate the contained values into vectors.\n\n[bitstring(1.0), bitstring(-1.0)]\n\nThe next 11 bits determine the exponent (scaling) of the number, and so on.\n\n[bitstring(1.0), bitstring(2.0)]\n\nThe sign bit, exponent, and significand in \n\n(1.1.1) are all directly accessible.\n\nx = 3.14\n@show sign(x), exponent(x), significand(x);\n\nx = x / 8\n@show sign(x), exponent(x), significand(x);\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. You can get its value from the eps function in Julia. By default, it returns the value for double precision.\n\nTip\n\nTo call a function, including eps, you must use parentheses notation, even when there are no input arguments.\n\neps()\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps())\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nnextfloat(161.8)\n\nans - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\n@show floatmin(), floatmax();\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2^(-4)\n\nThere are some exceptions. A floating-point value can’t be used as an index into an array, for example, even if it is numerically equal to an integer. In such cases you use Int to convert it.\n\n@show 5.0, Int(5.0);\n\nIf you try to convert a noninteger floating-point value into an integer you get an InexactValue error. This occurs whenever you try to force a type conversion that doesn’t make clear sense.\n\nExample 1.1.4\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\ne = eps()/2\n(1.0 + e) - 1.0\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1.0 + (e - 1.0)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!","type":"content","url":"/chapter1#id-1-1","position":7},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.2 Problems and conditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#id-1-2","position":8},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.2 Problems and conditioning","lvl2":"Examples"},"content":"Example 1.2.5\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nTip\n\nThe statement x,y = 10,20 makes individual assignments to both x and y.\n\nϵ = 1e-6   # type \\epsilon and then press Tab\na,b,c = 1/3,(-2-ϵ)/3,(1+ϵ)/3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4a*c)\nr₁ = (-b - d) / (2a)   # type r\\_1 and then press Tab\nr₂ = (-b + d) / (2a)\n(r₁, r₂)\n\nThe relative errors in these values are\n\n@show abs(r₁ - 1) / abs(1);\n@show abs(r₂ - (1+ϵ)) / abs(1+ϵ);\n\nThe condition number of each root is\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}.\n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps() / ϵ\n\nThis matches the observation pretty well.","type":"content","url":"/chapter1#id-1-2","position":9},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.3 Algorithms","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#id-1-3","position":10},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.3 Algorithms","lvl2":"Examples"},"content":"Example 1.3.2\n\nHere we show how to use \n\nFunction 1.3.1 to evaluate a polynomial. It’s not a part of core Julia, so you need to download and install this text’s package once, and load it for each new Julia session. The download is done by the following lines.\n\n#import Pkg\n#Pkg.add(\"FNCBook\");\n\nOnce installed, any package can be loaded with the using command, as follows.\n\nTip\n\nMany Julia functions, including the ones in this text, are in packages that must be loaded via using or import in each session. Sometimes a using statement can take a few seconds or even minutes to execute, if packages have been installed or updated.\n\n#using FundamentalsNumericalComputation\nusing FNCFunctions\nFNC = FNCFunctions\n\nFor convenience, this package also imports many other packages used throughout the book and makes them available as though you had run a using command for each of them.\n\nTip\n\nIf you are not sure where a particular function is defined, you can run methods on the function name to find all its definitions.\n\nReturning to horner, let us define a vector of the coefficients of p(x)=(x-1)^3=x^3-3x^2+3x-1, in ascending degree order.\n\nc = [-1, 3, -3, 1]\n\nIn order to avoid clashes between similarly named functions, Julia has boxed all the book functions into a namespace called FNC. We use this namespace whenever we invoke one of the functions.\n\nTip\n\nYou must use the module name when a package is loaded by import, but when loaded via using, some functions may be available with no prefix.\n\nFNC.horner(c, 1.6)\n\nThe above is the value of p(1.6).\n\nWhile the namespace does lead to a little extra typing, a nice side effect of using this paradigm is that if you type FNC. (including the period) and hit the Tab key, you will see a list of all the functions known in that namespace.\n\nThe multi-line string at the start of \n\nFunction 1.3.1 is documentation, which we can access using ?FNC.horner.","type":"content","url":"/chapter1#id-1-3","position":11},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.4 Stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter1#id-1-4","position":12},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.4 Stability","lvl2":"Examples"},"content":"Example 1.4.1\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nTip\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n@show x₂ = (-b - sqrt(b^2 - 4a*c)) / 2a;\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6 - x₂) / 1e-6 \n@show accurate_digits = -log10(error);\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nExample 1.4.2\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\n@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\n@show x₂ = c / (a * x₁);\n\nAs you see in this output, Julia often suppresses trailing zeros in a decimal expansion. To be sure we have an accurate result, we compute its relative error.\n\nabs(x₂ - 1e-6) / 1e-6\n\nExample 1.4.3\n\nFor this example we will use the Polynomials package, which is installed by the FNC package.\n\nTip\n\nIn the rest of the book, we do not show the using statement needed to load the book’s package, but you will need to enter it if you want to run the codes yourself.\n\nOur first step is to construct a polynomial with six known roots.\n\nusing Polynomials\nr = [-2.0, -1, 1, 1, 3, 6]\np = fromroots(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr̃ = sort(roots(p))   # type r\\tilde and then press Tab\n\nHere are the relative errors in each of the computed roots.\n\nTip\n\nThe @. notation at the start means to do the given operations on each element of the given vectors.\n\nprintln(\"Root errors:\") \n@. abs(r - r̃) / r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply fromroots to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np̃ = fromroots(r̃)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nc,c̃ = coeffs(p), coeffs(p̃)\nprintln(\"Coefficient errors:\") \n@. abs(c - c̃) / c\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.","type":"content","url":"/chapter1#id-1-4","position":13},{"hierarchy":{"lvl1":"Chapter 10"},"type":"lvl1","url":"/chapter10","position":0},{"hierarchy":{"lvl1":"Chapter 10"},"content":"","type":"content","url":"/chapter10","position":1},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Functions"},"type":"lvl2","url":"/chapter10#functions","position":2},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Functions"},"content":"Shooting method for a two-point boundary-value problem\n\n\"\"\"\n    shoot(ϕ, xspan, g₁, g₂, init)\n\nShooting method to solve a two-point boundary value problem with\nODE u'' = `ϕ`(x, u, u') for x in `xspan`, left boundary condition\n`g₁`(u,u')=0, and right boundary condition `g₂`(u,u')=0. The\nvalue `init` is an initial estimate for vector [u,u'] at x=a.\n\nReturns vectors for the nodes, the solution u, and derivative u'.\n\"\"\"\nfunction shoot(ϕ, xspan, g₁, g₂, init, tol = 1e-5)\n    # ODE posed as a first-order equation in 2 variables.\n    shootivp = (v, p, x) -> [v[2]; ϕ(x, v[1], v[2])]\n\n    # Evaluate the difference between computed and target values at x=b.\n    function objective(s)\n        IVP = ODEProblem(shootivp, s, float.(xspan))\n        sol = solve(IVP, Tsit5(), abstol = tol / 10, reltol = tol / 10)\n        x = sol.t\n        y = sol\n        return [g₁(s...), g₂(y.u[end]...)]\n    end\n\n    # Find the unknown quantity at x=a by rootfinding.\n    x = []\n    y = []   # these values will be overwritten\n    s = levenberg(objective, init, xtol = tol)[:, end]\n\n    # Use the stored last solution of the IVP.\n    u, du_dx = y[1, :], y[2, :]\n    return x, u, du_dx\nend\n\nAbout the code\n\nBecause x and y are assigned empty values in line 24, when the function objective runs it uses those values rather than new ones in local scope. Thus, line 19 updates them to hold the latest results of the IVP solver, saving the need to solve it again after levenberg has finished the rootfinding.\n\nThe error tolerance in the IVP solver is kept smaller than in the rootfinder, to prevent the rootfinder from searching in a noisy landscape. Finally, note how line 28 uses destructuring of eachrow(y) to assign the columns of y to separate names.\n\nSecond-order differentiation matrices\n\n\"\"\"\n    diffmat2(n, xspan)\n\nCompute 2nd-order-accurate differentiation matrices on `n`+1 points\nin the interval `xspan`. Returns a vector of nodes and the matrices\nfor the first and second derivatives.\n\"\"\"\nfunction diffmat2(n, xspan)\n    a, b = xspan\n    h = (b - a) / n\n    x = [a + i * h for i in 0:n]   # nodes\n\n    # Define most of Dₓ by its diagonals.\n    dp = fill(0.5 / h, n)        # superdiagonal\n    dm = fill(-0.5 / h, n)       # subdiagonal\n    Dₓ = diagm(-1 => dm, 1 => dp)\n\n    # Fix first and last rows.\n    Dₓ[1, 1:3] = [-1.5, 2, -0.5] / h\n    Dₓ[n+1, n-1:n+1] = [0.5, -2, 1.5] / h\n\n    # Define most of Dₓₓ by its diagonals.\n    d0 = fill(-2 / h^2, n + 1)    # main diagonal\n    dp = ones(n) / h^2         # super- and subdiagonal\n    Dₓₓ = diagm(-1 => dp, 0 => d0, 1 => dp)\n\n    # Fix first and last rows.\n    Dₓₓ[1, 1:4] = [2, -5, 4, -1] / h^2\n    Dₓₓ[n+1, n-2:n+1] = [-1, 4, -5, 2] / h^2\n\n    return x, Dₓ, Dₓₓ\nend\n\nChebyshev differentiation matrices\n\n\"\"\"\n    diffcheb(n, xspan)\n\nCompute Chebyshev differentiation matrices on `n`+1 points in the\ninterval `xspan`. Returns a vector of nodes and the matrices for the\nfirst and second derivatives.\n\"\"\"\nfunction diffcheb(n, xspan)\n    x = [-cos(k * π / n) for k in 0:n]    # nodes in [-1,1]\n\n    # Off-diagonal entries.\n    c = [2; ones(n - 1); 2]    # endpoint factors\n    dij = (i, j) -> (-1)^(i + j) * c[i+1] / (c[j+1] * (x[i+1] - x[j+1]))\n    Dₓ = [dij(i, j) for i in 0:n, j in 0:n]\n\n    # Diagonal entries.\n    Dₓ[isinf.(Dₓ)] .= 0         # fix divisions by zero on diagonal\n    s = sum(Dₓ, dims = 2)\n    Dₓ -= diagm(s[:, 1])         # \"negative sum trick\"\n\n    # Transplant to [a,b].\n    a, b = xspan\n    x = @. a + (b - a) * (x + 1) / 2\n    Dₓ = 2 * Dₓ / (b - a)             # chain rule\n\n    # Second derivative.\n    Dₓₓ = Dₓ^2\n    return x, Dₓ, Dₓₓ\nend\n\nSolution of a linear boundary-value problem\n\n\"\"\"\n    bvplin(p, q, r, xspan, lval, rval, n)\n\nUse finite differences to solve a linear bopundary value problem.\nThe ODE is u''+`p`(x)u'+`q`(x)u = `r`(x) on the interval `xspan`,\nwith endpoint function values given as `lval` and `rval`. There will\nbe `n`+1 equally spaced nodes, including the endpoints.\n\nReturns vectors of the nodes and the solution values.\n\"\"\"\nfunction bvplin(p, q, r, xspan, lval, rval, n)\n    x, Dₓ, Dₓₓ = diffmat2(n, xspan)\n\n    P = diagm(p.(x))\n    Q = diagm(q.(x))\n    L = Dₓₓ + P * Dₓ + Q     # ODE expressed at the nodes\n\n    # Replace first and last rows using boundary conditions.\n    z = zeros(1, n)\n    A = [[1 z]; L[2:n, :]; [z 1]]\n    b = [lval; r.(x[2:n]); rval]\n\n    # Solve the system.\n    u = A \\ b\n    return x, u\nend\n\nAbout the code\n\nNote that there is no need to explicitly form the row-deletion matrix \\mathbf{E} from \n\n(10.4.8). Since it only appears as left-multiplying \\mathbf{L} or \\mathbf{r}, we simply perform the row deletions as needed using indexing.\n\nSolution of a nonlinear boundary-value problem\n\n\"\"\"\n    bvplin(p, q, r, xspan, lval, rval, n)\n\nUse finite differences to solve a linear bopundary value problem.\nThe ODE is u''+`p`(x)u'+`q`(x)u = `r`(x) on the interval `xspan`,\nwith endpoint function values given as `lval` and `rval`. There will\nbe `n`+1 equally spaced nodes, including the endpoints.\n\nReturns vectors of the nodes and the solution values.\n\"\"\"\nfunction bvplin(p, q, r, xspan, lval, rval, n)\n    x, Dₓ, Dₓₓ = diffmat2(n, xspan)\n\n    P = diagm(p.(x))\n    Q = diagm(q.(x))\n    L = Dₓₓ + P * Dₓ + Q     # ODE expressed at the nodes\n\n    # Replace first and last rows using boundary conditions.\n    z = zeros(1, n)\n    A = [[1 z]; L[2:n, :]; [z 1]]\n    b = [lval; r.(x[2:n]); rval]\n\n    # Solve the system.\n    u = A \\ b\n    return x, u\nend\n\nAbout the code\n\nThe nested function residual uses differentiation matrices computed externally to it, rather than computing them anew on each invocation. As in \n\nFunction 10.4.1, there is no need to form the row-deletion matrix \\mathbf{E} explicitly. In lines 23--24, we divide the values of g_1 and g_2 by a factor of h. This helps scale the residual components more uniformly and improves the robustness of convergence a bit.\n\nPiecewise linear finite elements for a linear BVP\n\n\"\"\"\n    fem(c, s, f, a, b, n)\n\nUse a piecewise linear finite element method to solve a two-point\nboundary value problem. The ODE is (`c`(x)u')' + `s`(x)u = `f`(x) on\nthe interval [`a`,`b`], and the boundary values are zero. The\ndiscretization uses `n` equal subintervals.\n\nReturn vectors for the nodes and the values of u.\n\"\"\"\nfunction fem(c, s, f, a, b, n)\n    # Define the grid.\n    h = (b - a) / n\n    x = @. a + h * (0:n)\n\n    # Templates for the subinterval matrix and vector contributions.\n    Ke = [1 -1; -1 1]\n    Me = (1 / 6) * [2 1; 1 2]\n    fe = (1 / 2) * [1; 1]\n\n    # Evaluate coefficent functions and find average values.\n    cval = c.(x)\n    cbar = (cval[1:n] + cval[2:n+1]) / 2\n    sval = s.(x)\n    sbar = (sval[1:n] + sval[2:n+1]) / 2\n    fval = f.(x)\n    fbar = (fval[1:n] + fval[2:n+1]) / 2\n\n    # Assemble global system, one interval at a time.\n    K = zeros(n - 1, n - 1)\n    M = zeros(n - 1, n - 1)\n    f = zeros(n - 1)\n    K[1, 1] = cbar[1] / h\n    M[1, 1] = sbar[1] * h / 3\n    f[1] = fbar[1] * h / 2\n    K[n-1, n-1] = cbar[n] / h\n    M[n-1, n-1] = sbar[n] * h / 3\n    f[n-1] = fbar[n] * h / 2\n    for k in 2:n-1\n        K[k-1:k, k-1:k] += (cbar[k] / h) * Ke\n        M[k-1:k, k-1:k] += (sbar[k] * h) * Me\n        f[k-1:k] += (fbar[k] * h) * fe\n    end\n\n    # Solve system for the interior values.\n    u = (K + M) \\ f\n    u = [0; u; 0]      # put the boundary values into the result\n    return x, u\nend","type":"content","url":"/chapter10#functions","position":3},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Examples"},"type":"lvl2","url":"/chapter10#examples","position":4},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter10#examples","position":5},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.1 Two-point BVP","lvl2":"Examples"},"type":"lvl3","url":"/chapter10#id-10-1","position":6},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.1 Two-point BVP","lvl2":"Examples"},"content":"Example 10.1.3\n\nAs a system, the MEMS problem from \n\nExample 10.1.2 uses y_1=w, y_2=w' to obtain\\begin{split}\ny_1' &= y_2, \\\\\ny_2' &= \\frac{\\lambda}{y_1^2} - \\frac{y_2}{r}.\n\\end{split}\n\nWe will code an in-place form of this ODE, in which the first argument is used to return the computed values of y_1' and y_2'.\n\nTip\n\nThe in-place code here saves the computing time that would otherwise be needed to allocate memory for f repeatedly.\n\nfunction ode!(f, y, λ, r)\n    f[1] = y[2]\n    f[2] = λ / y[1]^2 - y[2] / r\n    return nothing\nend;\n\nNotice that the return value is irrelevant with the in-place style. We use the same style for the boundary conditions y_2(0)=0, y_1(1)=1.\n\nfunction bc!(g, y, λ, r)\n    g[1] = y[1][2]          # first node, second component = 0\n    g[2] = y[end][1] - 1    # last node, first component = 1\n    return nothing\nend;\n\nIn the bc! function, the y argument is just like an IVP solution from \n\nBasics of IVPs. Thus, y(0) is the value of the solution at x=0, and the second component of that value is what we wish to make zero. Similarly, y(1)[1] is the notation for y_1(1), which is supposed to equal 1.\n\nThe domain of the mathematical problem is r\\in [0,1]. However, there is a division by r in the ODE, so we want to avoid r=0 by truncating the domain a bit.\n\ndomain = (eps(), 1.0)\n\nWe need one last ingredient that is not part of the mathematical setup: an initial estimate for the solution. As we will see, this plays the same role as initialization in Newton’s method for rootfinding. Here, we try a constant value for each component.\n\nest = [1, 0]\n\nNow we set up and solve a BVProblem with the parameter value \\lambda=0.6.\n\nusing BoundaryValueDiffEq, OrdinaryDiffEq, Plots\nbvp = BVProblem(ode!, bc!, est, domain, 0.6)\ny = solve(bvp, Shooting(Tsit5()))\nplot(y;\n    label = [L\"w\" L\"w'\"],\n    legend = :right,\n    xlabel = L\"r\",\n    ylabel = \"solution\",\n    title = \"Solution of MEMS problem for λ=0.6\",\n)\n\nTo visual accuracy, the boundary conditions have been enforced. We can check them numerically.\n\n@show y(0)[2];    # y_2(0)\n@show y(1)[1];    # y_1(1)","type":"content","url":"/chapter10#id-10-1","position":7},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.2 Shooting","lvl2":"Examples"},"type":"lvl3","url":"/chapter10#id-10-2","position":8},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.2 Shooting","lvl2":"Examples"},"content":"Example 10.2.1\n\nLet’s first examine the shooting approach for the TPBVP from \n\nExample 10.1.2 with \\lambda=0.6.\n\nTip\n\nThe character ϕ is typed as \\phiTab.\n\nλ = 0.6\nϕ = (r, w, dwdr) -> λ / w^2 - dwdr / r;\n\nWe convert the ODE to a first-order system in order to apply a numerical method. We also have to truncate the domain to avoid division by zero.\n\nf = (y, p, r) -> [y[2]; ϕ(r, y[1], y[2])]\na, b = eps(), 1.0;\n\nThe BVP specifies w'(0)=y_2(0)=0. We can try multiple values for the unknown w(0)=y_1(0) and plot the solutions.\n\nusing OrdinaryDiffEq, Plots\nplt = plot(\n    xaxis = (L\"x\"),  yaxis = (L\"w(x)\"),\n    title = \"Different initial values\",  legend = :bottomright)\n\nfor w0 in 0.4:0.1:0.9\n    IVP = ODEProblem(f, [w0, 0], (a, b))\n    y = solve(IVP, Tsit5())\n    plot!(y, idxs = [1], label = \"w(0) = $w0\")\nend\nplt\n\nOn the graph, it’s the curve starting at w(0)=0.8 that comes closest to the required condition w(1)=1, but it’s a bit too large.\n\nExample 10.2.2\n\nWe revisit \n\nDemo 10.2.1 but let \n\nFunction 10.2.1 do the heavy lifting.\n\nλ = 0.6\nϕ = (r, w, dwdr) -> λ / w^2 - dwdr / r;\na, b = eps(), 1.0;\n\nWe specify the given and unknown endpoint values.\n\ng₁(w, dw) = dw       # w' = 0 at left\ng₂(w, dw) = w - 1    # w = 1 at right\nr, w, dw_dx = FNC.shoot(ϕ, (a, b), g₁, g₂, [0.8, 0])\nplot(r, w, title = \"Shooting solution\", xaxis = (L\"x\"), yaxis = (L\"w(x)\"))\n\nThe value of w at r=1, meant to be exactly one, was computed to be\n\n@show w[end];\n\nThe accuracy is consistent with the error tolerance used for the IVP solution. The initial value w(0) that gave this solution is\n\n@show w[1];\n\nExample 10.2.3\n\nplt = plot(\n    xaxis = (L\"x\"),\n    yaxis = ([-1.2, 0.5], L\"u(x)\"),\n    title = \"Shooting instability\",\n    leg = :topleft,\n)\nfor λ in 6:4:18\n    g₁(u, du) = u + 1\n    g₂(u, du) = u\n    ϕ = (x, u, du_dx) -> λ^2 * (u + 1)\n    x, u = FNC.shoot(ϕ, (0.0, 1.0), g₁, g₂, [-1, 0])\n    plot!(x, u, label = \"λ=$λ\")\nend\nplt\n\nThe numerical solutions evidently don’t satisfy the right boundary condition as λ increases, which makes them invalid.","type":"content","url":"/chapter10#id-10-2","position":9},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.3 Differentiation matrices","lvl2":"Examples"},"type":"lvl3","url":"/chapter10#id-10-3","position":10},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.3 Differentiation matrices","lvl2":"Examples"},"content":"Example 10.3.1\n\nWe test first-order and second-order differentiation matrices for the function x + \\exp(\\sin 4x) over [-1,1].\n\nf = x -> x + exp(sin(4 * x));\n\nFor reference, here are the exact first and second derivatives.\n\ndf_dx = x -> 1 + 4 * exp(sin(4x)) * cos(4x);\nd2f_dx2 = x -> 4 * exp(sin(4x)) * (4 * cos(4x)^2 - 4 * sin(4x));\n\nWe discretize on equally spaced nodes and evaluate f at the nodes.\n\nt, Dₓ, Dₓₓ = FNC.diffmat2(18, [-1, 1])\ny = f.(t);\n\nThen the first two derivatives of f each require one matrix-vector multiplication.\n\nyₓ = Dₓ * y\nyₓₓ = Dₓₓ * y;\n\nThe results show poor accuracy for this small value of n.\n\nusing Plots\nplot(df_dx, -1, 1, layout = 2, xaxis = (L\"x\"), yaxis = (L\"f'(x)\"))\nscatter!(t, yₓ, subplot = 1)\nplot!(d2f_dx2, -1, 1, subplot = 2, xaxis = (L\"x\"), yaxis = (L\"f''(x)\"))\nscatter!(t, yₓₓ, subplot = 2)\n\nA convergence experiment confirms the order of accuracy. Because we expect an algebraic convergence rate, we use a log-log plot of the errors.\n\nn = @. round(Int, 2^(4:0.5:11))\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n    t, Dₓ, Dₓₓ = FNC.diffmat2(n, [-1, 1])\n    y = f.(t)\n    err[k, 1] = norm(df_dx.(t) - Dₓ * y, Inf)\n    err[k, 2] = norm(d2f_dx2.(t) - Dₓₓ * y, Inf)\nend\nplot(n, err, m = :o, label = [L\"f'\" L\"f''\"])\nplot!(n, 10 * 10 * n .^ (-2);\n    l = (:dash, :black),\n    label = \"2nd order\",\n    xaxis = (:log10, \"n\"),\n    yaxis = (:log10, \"max error\"),\n    title = \"Convergence of finite differences\")\n\nExample 10.3.2\n\nHere is a 4\\times 4 Chebyshev differentiation matrix.\n\nt, Dₓ = FNC.diffcheb(3, [-1, 1])\nDₓ\n\nWe again test the convergence rate.\n\nf = x -> x + exp(sin(4 * x));\ndf_dx = x -> 1 + 4 * exp(sin(4 * x)) * cos(4 * x);\nd2f_dx2 = x -> 4 * exp(sin(4 * x)) * (4 * cos(4 * x)^2 - 4 * sin(4 * x));\n\nn = 5:5:70\nerr1 = zeros(size(n))\nerr2 = zeros(size(n))\nfor (k, n) in enumerate(n)\n    t, Dₓ, Dₓₓ = FNC.diffcheb(n, [-1, 1])\n    y = f.(t)\n    err1[k] = norm(df_dx.(t) - Dₓ * y, Inf)\n    err2[k] = norm(d2f_dx2.(t) - Dₓₓ * y, Inf)\nend\n\nSince we expect a spectral convergence rate, we use a semi-log plot for the error.\n\nplot(n, [err1 err2]; m = :o,\n    label=[L\"f'\" L\"f''\"],\n    xaxis=(L\"n\"),  yaxis = (:log10, \"max error\"),\n    title=\"Convergence of Chebyshev derivatives\")","type":"content","url":"/chapter10#id-10-3","position":11},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.4 Collocation for linear problems","lvl2":"Examples"},"type":"lvl3","url":"/chapter10#id-10-4","position":12},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.4 Collocation for linear problems","lvl2":"Examples"},"content":"Example 10.4.1\n\nexact = x -> exp(sin(x));\n\nThe problem is presented above in our standard form, so we can identify the coefficient functions in the ODE. Each should be coded as a function.\n\np = x -> -cos(x);\nq = sin;\nr = x -> 0;      # function, not value\n\nWe solve the BVP and compare the result to the exact solution.\n\nx, u = FNC.bvplin(p, q, r, [0, 3π / 2], 1, exp(-1), 30);\n\nusing Plots\nplot(exact, 0, 3π / 2, layout = (2, 1), label = \"exact\")\nscatter!(x, u, m = :o,\n    subplot=1,  label=\"numerical\",\n    yaxis=(\"solution\"),\n    title=\"Solution of a linear BVP\")\nplot!(x, exact.(x) - u, subplot = 2, xaxis = L\"x\", yaxis = (\"error\"))\n\nExample 10.4.2\n\nλ = 10\nexact = x -> sinh(λ * x) / sinh(λ) - 1;\n\nThe following functions define the ODE.\n\np = x -> 0\nq = x -> -λ^2\nr = x -> λ^2;\n\nWe compare the computed solution to the exact one for increasing n.\n\nn = 5 * [round(Int, 10^d) for d in 0:0.25:3]\nerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    x, u = FNC.bvplin(p, q, r, [0, 1], -1, 0, n)\n    err[k] = norm(exact.(x) - u, Inf)\nend\ndata = (n = n[1:4:end], err = err[1:4:end])\n@pt :header = [\"n\", \"inf-norm error\"] data\n\nEach factor of 10 in n reduces error by a factor of 100, which is indicative of second-order convergence.\n\nplot(n, err, m = :o,\n    label = \"observed\",\n    xaxis = (:log10, L\"n\"),\n    yaxis = (:log10, \"inf-norm error\"),\n    title = \"Convergence for a linear BVP\")\nplot!(n, 0.25 * n .^ (-2), l = (:dash, :gray), label = \"2nd order\")","type":"content","url":"/chapter10#id-10-4","position":13},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.5 Nonlinearity and boundary conditions","lvl2":"Examples"},"type":"lvl3","url":"/chapter10#id-10-5","position":14},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.5 Nonlinearity and boundary conditions","lvl2":"Examples"},"content":"Example 10.5.2\n\nThe first step is to define the function ϕ that equals \\theta''.\n\nϕ = (t, θ, ω) -> -0.05 * ω - sin(θ);\n\nNext, we define the boundary conditions.\n\ng₁(u, du) = u - 2.5\ng₂(u, du) = u + 2;\n\nThe last ingredient is an initial estimate of the solution. Here we choose n=100 and a linear function between the endpoint values.\n\nTip\n\nThe collect function turns a range object into a true vector.\n\ninit = collect(range(2.5, -2, length = 101));\n\nWe find a solution with negative initial slope, i.e., the pendulum is initially pushed back toward equilibrium.\n\nusing Plots\nt, θ = FNC.bvp(ϕ, [0, 5], g₁, g₂, init)\nplot(t, θ;\n    xaxis=(L\"t\"),  yaxis=(L\"\\theta(t)\"),\n    title=\"Pendulum over [0,5]\" )\n\nIf we extend the time interval longer for the same boundary values, then the initial slope must adjust.\n\nt, θ = FNC.bvp(ϕ, [0, 8], g₁, g₂, init)\nplot(t, θ;\n    xaxis=(L\"t\"),  yaxis=(L\"\\theta(t)\"),\n    title=\"Pendulum over [0,8]\" )\n\nThis time, the pendulum is initially pushed toward the unstable equilibrium in the upright vertical position before gravity pulls it back down.\n\nExample 10.5.3\n\nHere is the problem definition. We use a truncated domain to avoid division by zero at r=0.\n\ndomain = [eps(), 1]\nλ = 0.5\nϕ = (r, w, dwdr) -> λ / w^2 - dwdr / r\ng₁(w, dw) = dw\ng₂(w, dw) = w - 1;\n\nFirst we try a constant function as the initialization.\n\ninit = ones(301)\nr, w₁ = FNC.bvp(ϕ, domain, g₁, g₂, init)\n\nplot(r, w₁;\n    xaxis = (L\"r\"),  yaxis = (L\"w(r)\"), \n    title = \"Solution of the MEMS problem\")\n\nIt’s not necessary that the initialization satisfy the boundary conditions. In fact, by choosing a different constant function as the initial guess, we arrive at another valid solution.\n\ninit = 0.5 * ones(301)\nr, w₂ = FNC.bvp(ϕ, domain, g₁, g₂, init)\nplot!(r, w₂, title = \"Two solutions of the MEMS problem\")\n\nExample 10.5.4\n\nϕ = (x, u, dudx) -> (u^3 - u) / ϵ;\ng₁(u, du) = du\ng₂(u, du) = u - 1;\n\nFinding a solution is easy at larger values of ε.\n\nϵ = 0.05\ninit = collect(range(-1, 1, length = 141))\nx, u₁ = FNC.bvp(ϕ, [0, 1], g₁, g₂, init)\n\nplot(x, u₁;\n    label=L\"\\epsilon = 0.05\",  legend=:bottomright,\n    xaxis=(L\"x\"),  yaxis=(L\"u(x)\"),\n    title = \"Allen–Cahn solution\")\n\nHowever, finding a good initialization is not trivial for smaller values of ε. Note below that the iteration stops without converging to a solution.\n\nϵ = 0.002;\nx, z = FNC.bvp(ϕ, [0, 1], g₁, g₂, init);\n\nThe iteration succeeds if we use the first solution instead as the initialization here.\n\nx, u₂ = FNC.bvp(ϕ, [0, 1], g₁, g₂, u₁)\nplot!(x, u₂; label = L\"\\epsilon = 0.002\")\n\nIn this case we can continue further.\n\nϵ = 0.0005\nx, u₃ = FNC.bvp(ϕ, [0, 1], g₁, g₂, u₂)\nplot!(x, u₃, label = L\"\\epsilon = 0.0005\")","type":"content","url":"/chapter10#id-10-5","position":15},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.6 The Galerkin method","lvl2":"Examples"},"type":"lvl3","url":"/chapter10#id-10-6","position":16},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.6 The Galerkin method","lvl2":"Examples"},"content":"Example 10.6.2\n\nHere are the coefficient function definitions. Even though s is a constant, it has to be defined as a function for \n\nFunction 10.6.1 to use it.\n\nc = x -> x^2;\nq = x -> 4;\nf = x -> sin(π * x);\n\nusing Plots\nx, u = FNC.fem(c, q, f, 0, 1, 50)\nplot(x, u;\n    xaxis=(L\"x\"),  yaxis = (L\"u\"),\n    title = \"Solution by finite elements\", legend=:none)","type":"content","url":"/chapter10#id-10-6","position":17},{"hierarchy":{"lvl1":"Chapter 11"},"type":"lvl1","url":"/chapter11","position":0},{"hierarchy":{"lvl1":"Chapter 11"},"content":"","type":"content","url":"/chapter11","position":1},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Functions"},"type":"lvl2","url":"/chapter11#functions","position":2},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Functions"},"content":"Differentiation matrices for periodic end conditions\n\n\"\"\"\n    diffper(n, xspan)\n\nConstruct 2nd-order differentiation matrices for functions with\nperiodic end conditions, using `n` unique nodes in the interval\n`xspan`. Returns a vector of nodes and the matrices for the first\nand second derivatives.\n\"\"\"\nfunction diffper(n, xspan)\n    a, b = xspan\n    h = (b - a) / n\n    x = @. a + h * (0:n-1)   # nodes, omitting the repeated data\n\n    # Construct Dx by diagonals, then correct the corners.\n    dp = fill(0.5 / h, n-1)       # superdiagonal\n    dm = fill(-0.5 / h, n-1)      # subdiagonal\n    Dx = diagm(-1 => dm, 1 => dp)\n    Dx[1, n] = -1 / 2h\n    Dx[n, 1] = 1 / 2h\n\n    # Construct Dxx by diagonals, then correct the corners.\n    d0 = fill(-2 / h^2, n)        # main diagonal\n    dp = ones(n-1) / h^2          # superdiagonal and subdiagonal\n    Dxx = diagm(-1 => dp, 0 => d0, 1 => dp)\n    Dxx[1, n] = 1 / h^2\n    Dxx[n, 1] = 1 / h^2\n\n    return x, Dx, Dxx\nend\n\nSolution of parabolic PDEs by the method of lines\n\n\"\"\"\n    parabolic(ϕ, xspan, m, g₁, g₂, tspan, init)\n\nSolve a parabolic PDE by the method of lines. The PDE is\n∂u/∂t = `ϕ`(t, x, u, ∂u/∂x, ∂^2u/∂x^2), `xspan` gives the space\ndomain, m gives the degree of a Chebyshev spectral discretization,\n`g₁` and `g₂` are functions of (u,∂u/∂x) at the domain ends that\nshould be made zero, `tspan` is the time domain, and `init` is a\nfunction of x that gives the initial condition. Returns a vector\n`x` and a function of t that gives the semidiscrete solution at `x`.\n\"\"\"\nfunction parabolic(ϕ, xspan, m, g₁, g₂, tspan, init)\n    x, Dₓ, Dₓₓ = diffcheb(m, xspan)\n    int = 2:m    # indexes of interior nodes\n\n    function extend(v)\n        function objective(ubc)\n            u₀, uₘ = ubc\n            uₓ = Dₓ * [u₀; v; uₘ]\n            return [g₁(u₀, uₓ[1]), g₂(uₘ, uₓ[end])]\n        end\n        ubc = levenberg(objective, [0, 0])[end]\n        return [ubc[1]; v; ubc[2]]\n    end\n\n    function ode!(f, v, p, t)\n        u = extend(v)\n        uₓ, uₓₓ = Dₓ * u, Dₓₓ * u\n        @. f = ϕ(t, x[int], u[int], uₓ[int], uₓₓ[int])\n    end\n\n    ivp = ODEProblem(ode!, init.(x[int]), float.(tspan))\n    u = solve(ivp)\n\n    return x, t -> extend(u(t))\nend\n\nAbout the code\n\nLine 29 uses the macro @. to assign into the vector f elementwise. Without it, the function would allocate space for the result of phi and then change f to point at that vector, and that would defeat the purpose of using the preallocated f for speed.","type":"content","url":"/chapter11#functions","position":3},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Examples"},"type":"lvl2","url":"/chapter11#examples","position":4},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter11#examples","position":5},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.1 Black–Scholes equation","lvl2":"Examples"},"type":"lvl3","url":"/chapter11#id-11-1","position":6},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.1 Black–Scholes equation","lvl2":"Examples"},"content":"Example 11.1.2\n\nWe consider the Black–Scholes problem for the following parameter values:\n\nSmax = 8 \nT = 6\nK, σ, r = (3, 0.06, 0.08);\n\nWe discretize space and time.\n\nm = 200;  h = Smax / m;\nx = h * (0:m)\nn = 1000;  τ = T / n;\nt = τ * (0:n)\nλ = τ / h^2\nμ = τ / h;\n\nWe set the initial condition and then march forward in time.\n\nV = zeros(m+1, n+1)\nV[:, 1] = @. max(0, x - K)\nfor j in 1:n\n    # Fictitious value from Neumann condition.\n    Vfict = 2h + V[m, j]\n    Vj = [ V[:, j]; Vfict ]\n    # First row is zero by the Dirichlet condition.\n    for i in 2:m+1 \n        diff1 = (Vj[i+1] - Vj[i-1])\n        diff2 = (Vj[i+1] - 2Vj[i] + Vj[i-1])\n        V[i,j+1] = Vj[i] +\n            (λ * σ^2 * x[i]^2 / 2) * diff2 +\n            (r * x[i] * μ) / 2 * diff1 -\n            (r * τ) * Vj[i]\n    end \nend\n\nHere is a plot of the solution after every 250 time steps.\n\nusing Plots\nidx = 1:250:n+1\nlabel = reshape([\"t = $t\" for t in t[idx]], 1, length(idx))\nplot(x, V[:, idx]; \n    label, legend=:topleft,\n    xaxis=(\"stock price\"),  yaxis=(\"option value\"),\n    title=\"Black–Scholes solution\")\n\nAlternatively, here is an animation of the solution.\n\nanim = @animate for j in 1:10:n+1\n    plot(x, V[:, j];\n        xaxis=(L\"S\"),  yaxis=([0,6],L\"v(S,t)\"),\n        title=\"Black–Scholes solution\",\n        dpi=150,    \n        label=@sprintf(\"t = %.2f\", t[j]))\nend\nmp4(anim, \"figures/black-scholes-6.mp4\")\n\nThe results are easy to interpret, recalling that the time variable really means time until strike. Say you are close to the option’s strike time. If the current stock price is, say, S=2, then it’s not likely that the stock will end up over the strike price K=3, and therefore the option has little value. On the other hand, if presently S=3, then there are good odds that the option will be exercised at the strike time, and you will need to pay a substantial portion of the stock price in order to take advantage. As the time to strike increases, there is an expectation that the stock price is more likely to rise somewhat, making the value of the option larger at each fixed S.\n\nExample 11.1.3\n\nLet’s try to do everything the same as in \n\nDemo 11.1.2, but extending the simulation time to T=8.\n\nT = 8;\n\nm = 200;  h = Smax / m;\nx = h*(0:m)\nn = 1000;  τ = T / n;\nt = τ*(0:n)\nλ = τ / h^2;  μ = τ / h;\n\nfor j in 1:n\n    # Fictitious value from Neumann condition.\n    Vfict = 2h + V[m,j]\n    Vj = [ V[:, j]; Vfict ]\n    # First row is zero by the Dirichlet condition.\n    for i in 2:m+1 \n        diff1 = (Vj[i+1] - Vj[i-1])\n        diff2 = (Vj[i+1] - 2Vj[i] + Vj[i-1])\n        V[i,j+1] = Vj[i] +\n            (λ * σ^2 * x[i]^2 / 2) * diff2 +\n            (r * x[i] * μ) / 2 * diff1 -\n            (r * τ) * Vj[i]\n    end   \nend\n\nidx = 1:250:n+1\nlabel = reshape([\"t = $t\" for t in t[idx]], 1, length(idx))\nplot(x, V[:, idx];\n    label, legend=:topleft,\n    title=\"Black–Scholes solution\",\n    xaxis=(\"stock price\"),  yaxis=(\"option value\",[0, 6]))\n\nanim = @animate for j in 1:10:n+1 \n    plot(x, V[:, j];\n        xaxis=(L\"S\"),  yaxis=([0,6],L\"v(S,t)\"),\n        title=\"Black–Scholes solution...?\",\n        dpi=150,  label=@sprintf(\"t = %.2f\",t[j]))\nend\nmp4(anim, \"figures/black-scholes-8.mp4\")\n\nThis so-called solution is nonsense!","type":"content","url":"/chapter11#id-11-1","position":7},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.2 The method of lines","lvl2":"Examples"},"type":"lvl3","url":"/chapter11#id-11-2","position":8},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.2 The method of lines","lvl2":"Examples"},"content":"Example 11.2.2\n\nLet’s implement the method of \n\nExample 11.2.1 with second-order space semidiscretization.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1]);\ntfinal = 0.15 \nn = 2400           # number of time steps\nτ = tfinal / n     # time step    \nt = τ * (0:n)      # time values\n\nNext we set an initial condition. It isn’t mathematically periodic, but the end values and derivatives are so small that for numerical purposes it may as well be.\n\nusing Plots\nU = zeros(m, n+1);\nU[:, 1] = @. exp( -60 * (x - 0.5)^2 )\nplot(x, U[:, 1];\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\"),\n    title=\"Initial condition\")\n\nThe Euler time stepping simply multiplies \\mathbf{u}_j by the constant matrix in \n\n(11.2.6) at each time step. Since that matrix is sparse, we will declare it as such, even though the run-time savings may not be detectable for this small value of m.\n\nusing SparseArrays\nA = sparse(I + τ * Dxx)\nfor j in 1:n\n    U[:, j+1] = A * U[:, j]\nend\n\nplot_idx = 1:10:31\nplot_times = round.(t[plot_idx], digits=4)\nlabels = [\"t = $t\" for t in plot_times]\nplot(x, U[:, plot_idx];\n    label=reshape(labels, 1, :),  legend=:topleft,  \n    title=\"Heat equation by forward Euler\",\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\", [-0.25, 1]))\n\nThings seem to start well, with the initial peak widening and shrinking. But then there is a nonphysical growth in the solution.\n\nanim = @animate for j in 1:101\n    plot(x, U[:, j];\n    label=@sprintf(\"t=%.5f\", t[j]),\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", [-1, 2]),\n    dpi=150,  title=\"Heat equation by forward Euler\")\nend\nmp4(anim, \"figures/diffusionFE.mp4\")\n\nThe growth in norm is exponential in time.\n\nM = vec( maximum(abs, U, dims=1) )   \nplot(t[1:1000], M[1:1000];\n    xaxis=(L\"t\"),  yaxis=(:log10, L\"\\max_x |u(x,t)|\"),\n    title=\"Nonphysical growth\")\n\nExample 11.2.4\n\nNow we apply backward Euler to the heat equation. We will reuse the setup from \n\nDemo 11.2.2. Since the matrix in \n\n(11.2.7) never changes during the time stepping, we do the necessary LU factorization only once.\n\nusing SparseArrays\nB = sparse(I - τ * Dxx)\nfactor = lu(B)\nfor j in 1:n\n    U[:, j+1] = factor \\ U[:, j]\nend\n\nusing Plots\nidx = 1:600:n+1\ntimes = round.(t[idx], digits=4)\nlabel = reshape([\"t = $t\" for t in times], 1, length(idx))\nplot(x,U[:, idx];\n    label, legend=:topleft,\n    title=\"Heat equation by backward Euler\",\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\", [0, 1]))\n\nanim = @animate for j in 1:20:n+1\n    plot(x, U[:, j];\n    label=@sprintf(\"t=%.5f\", t[j]),\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", [0, 1]),\n    dpi=150,  title=\"Heat equation by backward Euler\")\nend\nmp4(anim, \"figures/diffusionBE.mp4\")\n\nThis solution looks physically plausible, as the large concentration in the center diffuses outward until the solution is essentially constant. Observe that the solution remains periodic in space for all time.\n\nExample 11.2.5\n\nWe set up the semidiscretization and initial condition in x just as before.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1])\nu0 = @. exp( -60*(x - 0.5)^2 );\n\nNow, however, we apply \n\nFunction 6.5.2 (rk23) to the initial-value problem \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nusing OrdinaryDiffEq\ntfinal = 0.25\nODE = (u, p, t) -> Dxx * u  \nIVP = ODEProblem(ODE, u0, (0, tfinal))\nt, u = FNC.rk23(IVP, 1e-5);\n\nWe check that the resulting solution looks realistic.\n\nplt = plot(\n    title=\"Heat equation by rk23\",\n    legend=:topleft,  \n    xaxis=(L\"x\"),  yaxis=(L\"u(x,0)\", [0, 1]))\nfor idx in 1:600:n+1\n    plot!(x, u[idx]; label=\"t = $(round.(t[idx], digits=4))\")\nend\nplt\n\nanim = @animate for j in 1:20:1600\n    plot(x, u[j];\n    label=@sprintf(\"t=%.4f\", t[j]),\n      xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", [0, 1]),\n      dpi=150,  title=\"Heat equation by rk23\")\nend\nmp4(anim, \"figures/diffusionRK23.mp4\")\n\nThe solution appears to be correct. But the number of time steps that were selected automatically is surprisingly large, considering how smoothly the solution changes.\n\nprintln(\"Number of time steps for rk23: $(length(t)-1)\")\n\nNow we apply a solver from DifferentialEquations.\n\nu = solve(IVP, Rodas4P());\nprintln(\"Number of time steps for Rodas4P: $(length(u.t) - 1)\")\n\nThe number of steps selected is reduced by a factor of more than 100!","type":"content","url":"/chapter11#id-11-2","position":9},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.3 Absolute stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter11#id-11-3","position":10},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.3 Absolute stability","lvl2":"Examples"},"content":"Example 11.3.5\n\nEuler and Backward Euler time-stepping methods were used to solve \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nm = 40\n_, _, Dₓₓ = FNC.diffper(m, [0, 1]);\n\nThe eigenvalues of this matrix are real and negative:\n\nusing Plots\nλ = eigvals(Dₓₓ)\nscatter(real(λ), imag(λ);\n    title=\"Eigenvalues\",\n    frame=:zerolines,  aspect_ratio=1,\n    xaxis=(\"Re λ\"),  yaxis=(\"Im λ\", (-1000, 1000)))\n\nThe Euler method is absolutely stable in the region |\\zeta+1| \\le 1 in the complex plane:\n\nphi = 2π * (0:360) / 360\nz = @. cis(phi) - 1;    # unit circle shifted to the left by 1\n\nplot(Shape(real(z), imag(z));\n    color=RGB(.8, .8, 1),\n    xaxis=(\"Re ζ\"),  yaxis=(\"Im ζ\"),\n    aspect_ratio=1,  frame=:zerolines,\n    title=\"Stability region\")\n\nIn order to get inside this region, we have to find τ such that \\lambda \\tau > -2 for all eigenvalues λ. This is an upper bound on τ.\n\nλ_min = minimum(λ)\n@show max_τ = -2 / λ_min;\n\nHere we plot the resulting values of \\zeta=\\lambda \\tau.\n\nζ = λ * max_τ\nscatter!(real(ζ), imag(ζ), title=\"Stability region and ζ values\")\n\nIn backward Euler, the region is |\\zeta-1|\\ge 1. Because they are all on the negative real axis, all of the ζ values will fit no matter what τ is chosen.\n\nplot(Shape([-6, 6, 6, -6], [-6, -6, 6, 6]), color=RGB(.8, .8, 1))\nz = @. cis(phi) + 1;   # unit circle shifted right by 1\nplot!(Shape(real(z), imag(z)), color=:white)\n\nscatter!(real(ζ), imag(ζ);\n    xaxis=([-4, 2], \"Re ζ\"),  yaxis=([-3, 3], \"Im ζ\"),\n    aspect_ratio=1,  frame=:zerolines,\n    title=\"Stability region and ζ values\")","type":"content","url":"/chapter11#id-11-3","position":11},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.4 Stiffness","lvl2":"Examples"},"type":"lvl3","url":"/chapter11#id-11-4","position":12},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.4 Stiffness","lvl2":"Examples"},"content":"Example 11.4.2\n\nIn \n\nExample 11.4.1 we derived a Jacobian matrix for the Oregonator model. Here is a numerical solution of the ODE.\n\nusing OrdinaryDiffEq, Plots\nfunction ode(u,p,t)\n    s,w,q = p\n    f = [ \n        s * ( u[2]*(1 - u[1]) + u[1]*(1 - q*u[1]) ),\n        (u[3] - u[2] - u[1] * u[2]) / s,   \n        w * (u[1] - u[3])\n        ]\n    return f\nend\ns, w, q = (77.27, .161, 8.375e-6)\noregon = ODEProblem(ode, [1., 2, 3], (0., 500.), [s, w, q])\nsol = solve(oregon)\nplot(sol, yscale=:log10, legend=:none, title=\"Solution of the Oregonator\")\n\nAt each value of the numerical solution, we can compute the eigenvalues of the Jacobian. Here we plot all of those eigenvalues in the complex plane.\n\nt,u = sol.t[1:2:end], sol.u[1:2:end]\nλ = fill(0.0im, length(t), 3)\nfor (k, u) in enumerate(u)\n    J = [\n    s*(1-u[2]-2q*u[1]) s*(1-u[1])        0 \n         -u[2]/s       -(1+u[1])/s     1/s \n            w               0           -w\n        ]\n    λ[k, :] .= eigvals(J)\nend\n\nscatter(real(λ), imag(λ), t;\n    xaxis=(\"Re(λ)\", 25000*(-5:2:-1)),  ylabel=\"Im(λ)\",  zlabel=\"t\",\n    title=\"Oregonator eigenvalues\")\n\nYou can see that there is one eigenvalue that ranges over a wide portion of the negative real axis and dominates stability considerations.\n\nExample 11.4.3\n\nThe Rodas4P solver is good for stiff problems, and needs few time steps to solve the Oregonator from \n\nDemo 11.4.2.\n\noregon = remake(oregon, tspan=(0., 25.))\nsol = solve(oregon, Rodas4P())\nprintln(\"Number of time steps for Rodas4P: $(length(sol.t) - 1)\")\n\nBut if we apply \n\nFunction 6.5.2 to the problem, the step size will be made small enough to cope with the large negative eigenvalue.\n\nt,u = FNC.rk23(oregon,1e-4)\nprintln(\"Number of time steps for RK23: $(length(t) - 1)\")\n\nStarting from the eigenvalues of the Jacobian matrix, we can find an effective \\zeta(t) by multiplying with the local time step size. The values of \\zeta(t) for each time level are plotted below and color coded by component of the diagonalized system.\n\nλ = fill(1.0im, length(t),3)\nfor (k, u) in enumerate(u)\n    J = [\n    s*(1-u[2]-2q*u[1]) s*(1-u[1])        0 \n         -u[2]/s       -(1+u[1])/s     1/s \n            w               0           -w\n        ]\n    λ[k, :] .= eigvals(J)\nend\n\nζ = diff(t) .* λ[1:end-1,:]\nscatter(real(ζ), imag(ζ), m=2,\n    xlabel=\"Re(ζ)\",  ylabel=\"Im(ζ)\",\n    title=\"Oregonator stability\")\n\nRoughly speaking, the ζ values stay within or close to the RK2 stability region in \n\nFigure 11.3.2. Momentary departures from the region are possible, but time stepping repeatedly in that situation would cause instability.","type":"content","url":"/chapter11#id-11-4","position":13},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.5 Boundaries","lvl2":"Examples"},"type":"lvl3","url":"/chapter11#id-11-5","position":14},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.5 Boundaries","lvl2":"Examples"},"content":"Example 11.5.3\n\nFirst, we define functions for the PDE and each boundary condition.\n\nϕ = (t, x, u, uₓ, uₓₓ) -> uₓₓ\ng₁ = (u, uₓ) -> u\ng₂ = (u, uₓ) -> u - 2;\n\nOur next step is to write a function to define the initial condition. This one satisfies the boundary conditions exactly.\n\ninit = x -> 1 + sinpi(x/2) + 3 * (1-x^2) * exp(-4x^2);\n\nNow we can use \n\nFunction 11.5.2 to solve the problem.\n\nusing Plots\nx, u = FNC.parabolic(ϕ, (-1, 1), 60, g₁, g₂, (0, 0.75), init)\nplt = plot(\n    xlabel=L\"x\",  ylabel=L\"u(x,t)\",\n    legend=:topleft,  title=\"Solution of the heat equation\")\nfor t in 0:0.1:0.4\n    plot!(x, u(t), label=@sprintf(\"t=%.2f\", t))\nend\nplt\n\nanim = @animate for t in range(0,0.75,length=201) \n    plot(x, u(t);\n        label=@sprintf(\"t=%.2f\", t),  legend=:topleft,\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (0, 4.2)), \n        title=\"Heat equation\",  dpi=150)\nend\nmp4(anim, \"figures/boundaries-heat.mp4\", fps=30)\n\nExample 11.5.4\n\nϕ = (t, x, u, uₓ, uₓₓ) -> u^2 + uₓₓ\ng₁ = (u, uₓ) -> u\ng₂ = (u, uₓ) -> uₓ\ninit = x -> 400x^4 * (1 - x)^2\nx, u = FNC.parabolic(ϕ, (0, 1), 60, g₁, g₂, (0, 0.1), init);\n\nanim = @animate for t in range(0, 0.1, length=101) \n    plot(x, u(t);\n        label=@sprintf(\"t=%.4f\", t),  legend=:topleft,\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (0, 10)),\n        dpi=150, title=\"Heat equation with source\")\nend\nmp4(anim, \"figures/boundaries-source.mp4\", fps=30)\n\nExample 11.5.5\n\nK = 3;  σ = 0.06;  r = 0.08;  Smax = 8;\nϕ = (t, x, u, uₓ, uₓₓ) -> σ^2/2 * (x^2 * uₓₓ) + r*x*uₓ - r*u\ng₁ = (u, uₓ) -> u\ng₂ = (u, uₓ) -> uₓ - 1;\n\nu₀ = x -> max(0, x - K)\nx, u = FNC.parabolic(ϕ, (0, Smax), 80, g₁, g₂, (0, 15), u₀);\n\nanim = @animate for t in range(0, 15, 151) \n    plot(x, u(t);\n        label=@sprintf(\"t=%.4f\", t),  legend=:topleft,\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (-0.5, 8)), \n        dpi=150,  title=\"Black–Scholes equation\")\nend\nmp4(anim, \"figures/boundaries-bs.mp4\", fps=30)\n\nRecall that u is the value of the call option, and time runs backward from the strike time. The longer the horizon, the more value the option has due to anticipated growth in the stock price.","type":"content","url":"/chapter11#id-11-5","position":15},{"hierarchy":{"lvl1":"Chapter 12"},"type":"lvl1","url":"/chapter12","position":0},{"hierarchy":{"lvl1":"Chapter 12"},"content":"","type":"content","url":"/chapter12","position":1},{"hierarchy":{"lvl1":"Chapter 12","lvl2":"Examples"},"type":"lvl2","url":"/chapter12#examples","position":2},{"hierarchy":{"lvl1":"Chapter 12","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter12#examples","position":3},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.1 Traffic flow","lvl2":"Examples"},"type":"lvl3","url":"/chapter12#id-12-1","position":4},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.1 Traffic flow","lvl2":"Examples"},"content":"Example 12.1.1\n\nIn the following definition we allow the velocity c to be specified as a parameter in the ODEProblem.\n\nx, Dₓ, Dₓₓ = FNC.diffper(300, [-4, 4]);\nf = (u, c, t) -> -c * (Dₓ*u);\n\nThe following initial condition isn’t mathematically periodic, but the deviation is less than machine precision. We specify RK4 as the solver.\n\nusing OrdinaryDiffEq\nu_init = @. 1 + exp( -3x^2 )\nIVP = ODEProblem(f, u_init, (0., 4.), 2)\nsol = solve(IVP, RK4());\n\nusing Plots\nplt = plot(\n    legend=:bottomleft,\n    title=\"Advection with periodic boundary\",\n    xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\"))\nfor t in (0:4) * 2/3\n    plot!(x, sol(t), label=@sprintf(\"t=%.1f\", t))\nend\nplt\n\nAn animation shows the solution nicely. The bump moves with speed 2 to the right, reentering on the left as it exits to the right because of the periodic conditions.\n\nanim = @animate for t in range(0, 4, 120) \n    plot(x, sol(t),\n        title=@sprintf(\"Advection equation, t = %.2f\", t),\n        xaxis=(L\"x\"),  yaxis=([1, 2], L\"u(x,t)\"),\n        dpi=150)\nend\nmp4(anim, \"figures/advection-periodic.mp4\")\n\nExample 12.1.2\n\nThe following are parameters and a function relevant to defining the problem.\n\nρc = 1080;  ρm = 380;  q_m = 10000;\ndQ0 = ρ -> 4q_m * ρc^2 * (ρc-ρm) * ρm * (ρm-ρ) / (ρ*(ρc-2*ρm) + ρc*ρm)^3;\n\nHere we create a discretization on m=800 points.\n\nx, Dₓ, Dₓₓ = FNC.diffper(800, [0, 4]);\n\nNext we define the ODE resulting from the method of lines.\n\node = (ρ, ϵ, t) -> -dQ0.(ρ) .* (Dₓ*ρ) + ϵ * (Dₓₓ*ρ);\n\nOur first initial condition has moderate density with a small bump. Because of the diffusion present, we use a stiff solver for the IVP.\n\nρ_init = @. 400 + 10 * exp( -20*(x-3)^2 )\nIVP = ODEProblem(ode, ρ_init, (0., 1.), 0.02)\nsol = solve(IVP, Rodas4P());\n\nplt = plot(\n    legend=:topleft, \n    title=\"Traffic flow\",\n    xaxis=(L\"x\"),  yaxis=(\"car density\"))\nfor t in 0:0.2:1\n    plot!(x, sol(t), label=@sprintf(\"t=%.1f\", t))\nend\nplt\n\nThe bump slowly moves backward on the roadway, spreading out and gradually fading away due to the presence of diffusion.\n\nanim = @animate for t in range(0,0.9,91) \n    plot(x, sol(t);\n        xaxis=(L\"x\"),  yaxis=([400,410], \"density\"),\n        dpi=150,  title=@sprintf(\"Traffic flow, t=%.2f\",t))\nend\nmp4(anim, \"figures/traffic-small.mp4\")\n\nNow we use an initial condition with a larger bump. Note that the scale on the y-axis is much different for this solution.\n\nρ_init = @. 400 + 80 * exp( -16*(x - 3)^2 )\nIVP = ODEProblem(ode, ρ_init, (0., 0.5), 0.02)\nsol = solve(IVP, Rodas4P());\n\nplt = plot(\n    legend=:topleft,\n    title=\"Traffic jam\",\n    xaxis=(L\"x\"),  yaxis=(\"car density\"))\nfor t in range(0, 0.5, 11)\n    plot!(x, sol(t), label=@sprintf(\"t=%.1f\", t))\nend\nplt\n\nanim = @animate for t in range(0, 0.5, 101) \n    plot(x, sol(t);\n        xaxis=(L\"x\"),  yaxis=([400,480], \"density\"),\n        dpi=150,  title=@sprintf(\"Traffic jam, t=%.2f\",t))\nend\nmp4(anim,\"figures/traffic-jam.mp4\")\n\nIn this case the density bump travels backward along the road. It also steepens on the side facing the incoming traffic and decreases much more slowly on the other side. A motorist would experience this as an abrupt increase in density, followed by a much more gradual decrease in density and resulting gradual increase in speed. (You also see some transient, high-frequency oscillations. These are caused by instabilities, as we discuss in simpler situations later in this chapter.)","type":"content","url":"/chapter12#id-12-1","position":5},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.2 Upwinding and stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter12#id-12-2","position":6},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.2 Upwinding and stability","lvl2":"Examples"},"content":"Example 12.2.3\n\nFor time stepping, we use the adaptive explicit method RK4.\n\nusing OrdinaryDiffEq\nm = 400;\nx, Dₓ = FNC.diffper(m, [0, 1])\nu_init = x -> exp( -80 * (x - 0.5)^2 )\node = (u, c, t) -> -c * (Dₓ*u)\nIVP = ODEProblem(ode, u_init.(x), (0., 2.), 2.)\nu = solve(IVP, RK4());\n\nusing Plots\nt = range(0, 2, 81);\nU = reduce(hcat, u(t) for t in t)\ncontour(x, t, U'; \n    color=:redsblues,  clims=(-1, 1),\n    xaxis=(L\"x\"),  yaxis=(L\"t\"),\n    title=\"Linear advection\",  right_margin=3Plots.mm)\n\nIn the space-time plot above, you can see the initial hump traveling rightward at constant speed. It fully traverses the domain once for each integer multiple of t=1/2.\n\nIf we cut h by a factor of 2 (i.e., double m), then the CFL condition suggests that the time step should be cut by a factor of 2 also.\n\nprintln(\"Number of time steps for m = 400: $(length(u.t))\")\n\nm = 800;\nx, Dₓ = FNC.diffper(m, [0, 1])\nIVP = ODEProblem(ode, u_init.(x), (0., 2.), 2.)\nu = solve(IVP, RK4())\nprintln(\"Number of time steps for m = 800: $(length(u.t))\")\n\nExample 12.2.6\n\nIf we solve advection over [0,1] with velocity c=-1, the right boundary is in the upwind/inflow direction. Thus a well-posed boundary condition is u(1,t)=0.\n\nWe’ll pattern a solution after \n\nFunction 11.5.2. Since u(x_m,t)=0, we define the ODE interior problem \n\n(11.5.4) for \\mathbf{v} without u_m. For each evaluation of \\mathbf{v}', we must extend the data back to x_m first.\n\nm = 100\nx, Dₓ = FNC.diffmat2(m, [0, 1])\n\ninterior = 1:m\nextend = v -> [v; 0]\n\nfunction ode!(f, v, c, t)\n    u = extend(v)\n    uₓ = Dₓ * u\n    @. f = -c * uₓ[interior]\nend;\n\nNow we solve for an initial condition that has a single hump.\n\ninit = @. exp( -80*(x[interior] - 0.5)^2 )\nivp = ODEProblem(ode!, init, (0., 1), -1)\nu = solve(ivp);\n\nt = range(0, 0.75, 80)\nU = reduce(hcat, extend(u(t)) for t in t)\ncontour(x, t, U';\n    color=:blues,  clims=(0, 1), \n    xaxis=(L\"x\"),  yaxis=(L\"t\"),\n    title=\"Advection with inflow BC\")\n\nWe find that the hump gracefully exits out the downwind end.\n\nanim = @animate for t in range(0, 1, 161) \n    plot(x, extend(u(t));\n        label=@sprintf(\"t = %.4f\", t), \n        xaxis=(L\"x\"),  yaxis=(L\"u(x, t)\", (0, 1)), \n        title=\"Advection equation with inflow BC\",  dpi=150)\nend\nmp4(anim,\"figures/advection-inflow.mp4\")\n\nIf instead of u(1,t)=0 we were to try to impose the downwind condition u(0,t)=0, we only need to change the index of the interior nodes and where to append the zero value.\n\ninterior = 2:m+1\nextend = v -> [0; v]\n\ninit = @. exp( -80*(x[interior] - 0.5)^2 )\nivp = ODEProblem(ode!, init, (0., 0.25), -1)\nu = solve(ivp);\n\nt = range(0, 0.2, 61)\nU = reduce(hcat, extend(u(t)) for t in t)\ncontour(x, t, U'; \n    color=:redsblues,  clims=(-1, 1),\n    xaxis=(L\"x\"),  yaxis=(L\"t\"), \n    title=\"Advection with outflow BC\",  right_margin=3Plots.mm)\n\nThis time, the solution blows up as soon as the hump runs into the boundary because there are conflicting demands there.\n\nanim = @animate for t in range(0, 0.2, 41) \n    plot(x, extend(u(t));\n        label=@sprintf(\"t = %.4f\", t),\n        xaxis=(L\"x\"),  yaxis=(L\"u(x,t)\", (0, 1)), \n        title=\"Advection equation with outflow BC\",  dpi=150)\nend\nmp4(anim,\"figures/advection-outflow.mp4\")","type":"content","url":"/chapter12#id-12-2","position":7},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.3 Absolute stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter12#id-12-3","position":8},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.3 Absolute stability","lvl2":"Examples"},"content":"Example 12.3.1\n\nFor c=1 we get purely imaginary eigenvalues.\n\nusing Plots\nx, Dₓ = FNC.diffper(40, [0, 1])\nλ = eigvals(Dₓ);\nscatter(real(λ), imag(λ);\n    aspect_ratio = 1,  frame=:zerolines,\n    xlabel=\"Re λ\",  ylabel=\"Im λ\", \n    title=\"Eigenvalues for pure advection\",  legend=:none)\n\nLet’s choose a time step of \\tau=0.1 and compare to the stability regions of the Euler and backward Euler time steppers (shown as shaded regions):\n\nzc = @. cispi(2 * (0:360) / 360);     # points on |z|=1\nz = zc .- 1;                          # shift left by 1\nplot(Shape(real(z), imag(z)), color=RGB(.8, .8, 1))\nζ = 0.1 * λ\nscatter!(real(ζ), imag(ζ);\n    aspect_ratio=1,  frame=:zerolines,\n    xaxis=(\"Re ζ\", [-5, 5]),  yaxis=(\"Im ζ\", [-5, 5]),\n    title=\"Euler for advection\")\n\nIn the Euler case it’s clear that no real value of \\tau>0 is going to make ζ values fit within the stability region. Any method whose stability region includes none of the imaginary axis is an unsuitable choice for advection.\n\nz = zc .+ 1;                        # shift circle right by 1\nplot(Shape([-6, 6, 6, -6], [-6, -6, 6, 6]), color=RGB(.8, .8, 1))\nplot!(Shape(real(z), imag(z)), color=:white)\nscatter!(real(ζ), imag(ζ);\n    aspect_ratio=1,  frame=:zerolines,\n    xaxis=(\"Re ζ\", [-5, 5]),  yaxis=(\"Im ζ\", [-5, 5]),\n    title=\"Backward Euler for advection\")\n\nThe A-stable backward Euler time stepping tells the exact opposite story: it will be absolutely stable for any choice of the time step τ.\n\nExample 12.3.2\n\nThe eigenvalues of advection-diffusion are near-imaginary for \\epsilon\\approx 0 and get closer to the negative real axis as ε increases.\n\nplt = plot(\n    legend=:topleft,\n    aspect_ratio=1,\n    xlabel=\"Re ζ\",  ylabel=\"Im ζ\",\n    title=\"Eigenvalues for advection-diffusion\")\nx, Dₓ, Dₓₓ = FNC.diffper(40, [0, 1]);\nfor ϵ in [0.001, 0.01, 0.05]\n    λ = eigvals(-Dₓ + ϵ*Dₓₓ)\n    scatter!(real(λ), imag(λ), m=:o, label=\"\\\\epsilon = $ϵ\")\nend\nplt\n\nExample 12.3.3\n\nDeleting the last row and column places all the eigenvalues of the discretization into the left half of the complex plane.\n\nx, Dₓ, _ = FNC.diffcheb(40, [0, 1])\nA = Dₓ[1:end-1, 1:end-1];     # delete last row and column\nλ = eigvals(A);\n\nscatter(real(λ), imag(λ);\n    m=3,  aspect_ratio=1,\n    legend=:none,  frame=:zerolines,\n    xaxis=([-300, 100], \"Re λ\"),  yaxis=(\"Im λ\"),\n    title=\"Eigenvalues of advection with zero inflow\")\n\nNote that the rightmost eigenvalues have real part at most\n\nmaximum(real(λ))\n\nConsequently all solutions decay exponentially to zero as t\\to\\infty. This matches our observation of the solution: eventually, everything flows out of the domain.","type":"content","url":"/chapter12#id-12-3","position":9},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.4 The wave equation","lvl2":"Examples"},"type":"lvl3","url":"/chapter12#id-12-4","position":10},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.4 The wave equation","lvl2":"Examples"},"content":"Example 12.4.1\n\nm = 200\nx, Dₓ = FNC.diffcheb(m, [-1, 1]);\n\nThe boundary values of u are given to be zero, so they are not unknowns in the ODEs. Instead they are added or removed as necessary.\n\nextend = v -> [0; v; 0]\nchop = u -> u[2:m];\n\nThe following function computes the time derivative of the system at interior points.\n\node = function(w, c, t)\n    u = extend(w[1:m-1])\n    z = w[m:2m]\n    du_dt = Dₓ * z\n    dz_dt = c^2 * (Dₓ * u)\n    return [ chop(du_dt); dz_dt ]\nend;\n\nOur initial condition is a single hump for u.\n\nu_init = @. exp( -100*(x + 0.5)^2 )\nz_init = -u_init\nw_init = [ chop(u_init); z_init ];\n\nBecause the wave equation is hyperbolic, we can use a nonstiff explicit solver.\n\nusing OrdinaryDiffEq\nIVP = ODEProblem(ode, w_init ,(0., 2.), 2)\nw = solve(IVP, RK4());\n\nWe plot the results for the original u variable only. Its interior values are at indices 1:m-1 of the composite \\mathbf{w} variable.\n\nusing Plots\nt = range(0, 2, 80)\nU = [extend(w(t)[1:m-1]) for t in t]\ncontour(x, t, hcat(U...)';\n    levels=24,\n    color=:redsblues,  clims=(-1, 1),\n    xlabel=L\"x\",  ylabel=L\"t\",\n    title=\"Wave equation\",  right_margin=3Plots.mm)\n\nanim = @animate for t in range(0 ,2, 120)\n    plot(x, extend(w(t)[1:m-1]);\n        label=@sprintf(\"t=%.3f\",t),\n        xaxis=(L\"x\"),  yaxis=([-1, 1], L\"u(x,t)\"),\n        dpi=150,  title=\"Wave equation\")\nend\nmp4(anim, \"figures/wave-boundaries.mp4\")\n\nThe original hump breaks into two pieces of different amplitudes, each traveling with speed c=2. They pass through one another without interference. When a hump encounters a boundary, it is perfectly reflected, but with inverted shape. At time t=2, the solution looks just like the initial condition.\n\nExample 12.4.2\n\nThe ODE implementation has to change slightly.\n\node = function(w,c,t)\n    u = extend(w[1:m-1])\n    z = w[m:2m]\n    du_dt = Dₓ*z\n    dz_dt = c.^2 .* (Dₓ*u)\n    return [ chop(du_dt); dz_dt ]\nend;\n\nThe variable wave speed is passed as an extra parameter through the IVP solver.\n\nc = @. 1 + (sign(x)+1)/2\nIVP = ODEProblem(ode, w_init, (0., 5.), c)\nw = solve(IVP, RK4());\n\nt = range(0, 5, 80)\nU = [extend(w(t)[1:m-1]) for t in t]\ncontour(x, t, hcat(U...)';\n    color=:redsblues,  clims=(-1,1),\n    levels=24,\n    xlabel=L\"x\",  ylabel=L\"t\",\n    title=\"Wave equation\",\n    right_margin=3Plots.mm\n    )\n\nanim = @animate for t in range(0,5,181)\n    plot(Shape([-1, 0, 0, -1], [-1, -1, 1, 1]), color=RGB(.8, .8, .8), l=0, label=\"\")\n    plot!(x, extend(w(t, idxs=1:m-1));\n        label=@sprintf(\"t=%.2f\", t), \n        xaxis=(L\"x\"),  yaxis=([-1, 1], L\"u(x,t)\"),\n        dpi=150,  title=\"Wave equation, variable speed\")\nend\nmp4(anim, \"figures/wave-speed.mp4\")\n\nEach pass through the interface at x=0 generates a reflected and transmitted wave. By conservation of energy, these are both smaller in amplitude than the incoming bump.","type":"content","url":"/chapter12#id-12-4","position":11},{"hierarchy":{"lvl1":"Chapter 13"},"type":"lvl1","url":"/chapter13","position":0},{"hierarchy":{"lvl1":"Chapter 13"},"content":"","type":"content","url":"/chapter13","position":1},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Functions"},"type":"lvl2","url":"/chapter13#functions","position":2},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Functions"},"content":"Create a tensor-product grid\n\n\"\"\"\n    tensorgrid(x, y)\n\nCreate a tensor grid for a rectangle from its 1d projections `x` and `y`.\nReturns `unvec` to reshape a vector into a 2d array, `mtx` to evaluate a\nfunction on the grid, `X`, `Y` to give the grid coordinates, and boolean array\n`is_boundary` to identify the boundary points.\n\"\"\"\nfunction tensorgrid(x, y)\n    m, n = length(x) - 1, length(y) - 1\n    unvec(u) = reshape(u, m+1, n+1)\n    mtx(h) = [h(x, y) for x in x, y in y]\n    X = mtx((x, y) -> x)\n    Y = mtx((x, y) -> y)\n    is_boundary = trues(m+1, n+1)\n    is_boundary[2:m, 2:n] .= false\n    return mtx, X, Y, unvec, is_boundary\nend\n\nSolution of Poisson’s equation by finite differences\n\n\"\"\"\n    poissonfd(f, g, m, xspan, n, yspan)\n\nSolve Poisson's equation on a rectangle by finite differences.\nFunction `f` is the forcing function and function `g` gives the\nDirichlet boundary condition. The rectangle is the tensor product of\nintervals `xspan` and `yspan`,  and the discretization uses `m`+1\nand `n`+1 points in the two coordinates.\n\nReturns vectors defining the grid and a matrix of grid solution values.\n\"\"\"\nfunction poissonfd(f, g, m, xspan, n, yspan)\n    # Discretize the domain.\n    x, Dx, Dxx = FNC.diffmat2(m, xspan)\n    y, Dy, Dyy = FNC.diffmat2(n, yspan)\n    mtx, X, Y, unvec, is_boundary = tensorgrid(x, y)\n    N = (m+1) * (n+1)   # total number of unknowns\n\n    # Form the collocated PDE as a linear system.\n    A = kron(I(n+1), sparse(Dxx)) + kron(sparse(Dyy), I(m+1))\n    b = vec(mtx(f))\n\n    # Apply Dirichlet condition.\n    scale = maximum(abs, A[n+2, :])\n    idx = vec(is_boundary)\n    A[idx, :] = scale * I(N)[idx, :]        # Dirichet assignment\n    b[idx] = scale * g.(X[idx], Y[idx])    # assigned values\n\n    # Solve the linear system and reshape the output.\n    u = A \\ b\n    return x, y, unvec(u)\nend\n\nSolution of elliptic PDE by Chebyshev collocation\n\n\"\"\"\n    elliptic(ϕ, g, m, xspan, n, yspan)\n\nSolve the elliptic PDE\n    `ϕ`(x, y, u, u_x, u_xx, u_y, u_yy) = 0\non the rectangle `xspan`x`yspan`, subject to `g`(x,y)=0 on the boundary. Uses\n`m`+1 points in x by `n`+1 points in y in a Chebyshev discretization. Returns\nvectors defining the grid and a matrix of grid solution values.\n\"\"\"\nfunction elliptic(ϕ, g, m, xspan, n, yspan)\n    # Discretize the domain.\n    x, Dx, Dxx = diffcheb(m, xspan)\n    y, Dy, Dyy = diffcheb(n, yspan)\n    mtx, X, Y, unvec, is_boundary = tensorgrid(x, y)\n    N = (m+1) * (n+1)   # total number of unknowns\n\n    # Identify boundary locations and evaluate the boundary condition.\n    idx = vec(is_boundary)\n    gb = g.(X[idx], Y[idx])\n\n    # Evaluate the PDE+BC residual.\n    function residual(u)\n        U = unvec(u)\n        R = ϕ(X, Y, U, Dx * U, Dxx * U, U * Dy', U * Dyy')    # PDE\n        @. R[idx] = u[idx] - gb                               # boundary residual\n        return vec(R)\n    end\n\n    # Solve the equation.\n    u = levenberg(residual, vec(zeros(size(X))))[end]\n    U = unvec(u)\n\n    return function (ξ, η)\n        v = [chebinterp(x, u, ξ) for u in eachcol(U)]\n        return chebinterp(y, v, η)\n    end\nend\n\nAbout the code\n\nThe boundary values are accessed using Boolean indexing. One advantage of this style, though it is not exploited here, is that the complementary points can also be accessed via the Boolean NOT operator !. Note that any indexing array either has to be the same size as the object of the indexing, or a vector with the same number of elements. In this function, for example, X[idx], X[isboundary], and u[idx] would all be valid, but u[isboundary] would not be.","type":"content","url":"/chapter13#functions","position":3},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Examples"},"type":"lvl2","url":"/chapter13#examples","position":4},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter13#examples","position":5},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.1 Tensor-product discretizations","lvl2":"Examples"},"type":"lvl3","url":"/chapter13#id-13-1","position":6},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.1 Tensor-product discretizations","lvl2":"Examples"},"content":"Example 13.1.2\n\nHere is the grid from \n\nExample 13.1.1.\n\nm = 4\nx = range(0, 2, m+1)\nn = 2\ny = range(1, 3, n+1);\n\nFor a given f(x,y) we can find \\operatorname{mtx}(f) by using a comprehension syntax.\n\nf = (x, y) -> cos(π * x * y - y)\nF = [f(x, y) for x in x, y in y]\n\nWe can make a nice plot of the function by first choosing a much finer grid. However, the contour and surface plotting functions expect the transpose of mtx(f).\n\nTip\n\nTo emphasize departures from a zero level, use a colormap such as redsblues, and use clims to set balanced color differences.\n\nusing Plots\nm, n = 80, 60\nx = range(0, 2, m+1);\ny = range(1, 3, n+1);\nF = [f(x, y) for x in x, y in y]\ncontour(x, y, F';\n    levels=21,  aspect_ratio=1,\n    color=:redsblues,  clims=(-1, 1),\n    xlabel=\"x\",  ylabel=\"y\" )\n\nExample 13.1.3\n\nFor a function given in polar form, such as f(r,\\theta)=1-r^4, construction of a function over the unit disk is straightforward using a grid in (r,\\theta) space.\n\nr = range(0, 1, 41)\nθ = range(0, 2π, 81)\nF = [1 - r^4 for r in r, θ in θ]\nplot(r, θ, F';\n    legend=:none, \n    color=:viridis,  fill=true,\n    xlabel=\"r\",  ylabel=\"θ\", \n    title=\"A polar function\")\n\nOf course, we are used to seeing such plots over the (x,y) plane, not the (r,\\theta) plane.\n\nIn such functions the values along the line r=0 must be identical, and the values on the line \\theta=0 should be identical to those on \\theta=2\\pi. Otherwise the interpretation of the domain as the unit disk is nonsensical. If the function is defined in terms of x and y, then those can be defined in terms of r and θ using \n\n(13.1.6).\n\nExample 13.1.4\n\nWe define a function and, for reference, its two exact partial derivatives.\n\nu = (x, y) -> sin(π * x * y - y);\n∂u_∂x = (x, y) -> π * y * cos(πx * y - y);\n∂u_∂y = (x, y) -> (π * x - 1) * cos(π * x * y - y);\n\nWe use an equispaced grid and second-order finite differences as implemented by diffmat2.\n\nm = 80;\nx, Dx, _ = FNC.diffmat2(m, [0, 2]);\nn = 60;\ny, Dy, _ = FNC.diffmat2(n, [1, 3]);\nmtx = (f, x, y) -> [f(x, y) for x in x, y in y]\nU = mtx(u, x, y)\n∂xU = Dx * U\n∂yU = U * Dy';\n\nNow we compare the exact \\frac{\\partial u}{\\partial y} with its finite-difference approximation.\n\nM = maximum(abs, ∂yU)    # find the range of the result\nplot(layout=(1, 2), \n    aspect_ratio=1,   clims=(-M, M), \n    xlabel=\"x\", ylabel=\"y\")\ncontour!(x, y, mtx(∂u_∂y, x, y)';\n    levels=15,  subplot=1,\n    color=:redsblues,\n    title=\"∂u/∂y\")\ncontour!(x, y, ∂yU';\n    levels=15,  subplot=2,\n    color=:redsblues, \n    title=\"approximation\")\n\nTo the eye there is little difference to be seen, though the results have no more than a few correct digits at these discretization sizes:\n\nexact = mtx(∂u_∂y, x, y)\n# Relative difference in Frobenius norm:\nnorm(exact - ∂yU) / norm(exact)","type":"content","url":"/chapter13#id-13-1","position":7},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.2 Two-dimensional diffusion and advection","lvl2":"Examples"},"type":"lvl3","url":"/chapter13#id-13-2","position":8},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.2 Two-dimensional diffusion and advection","lvl2":"Examples"},"content":"Example 13.2.1\n\nm = 2;\nn = 3;\nV = rand(1:9, m, n);\nv = vec(V)\n\nThe unvec operation is the inverse of vec.\n\nunvec = z -> reshape(z, m, n)\nunvec(v)\n\nExample 13.2.2\n\nm, n = (60, 25)\nx, Dx, Dxx = FNC.diffper(m, [-1, 1])\ny, Dy, Dyy = FNC.diffper(n, [-1, 1])\nmtx = f -> [f(x, y) for x in x, y in y]\nunvec = z -> reshape(z, m, n);\n\nNote that the initial condition should also be periodic on the domain.\n\nusing Plots\nu_init = (x, y) -> sin(4 * π * x) * exp(cos(π * y))\nU₀ = mtx(u_init)\nM = maximum(abs, U₀)\ncontour(x, y, U₀';\n    color=:redsblues,  clims=(-M, M), \n    aspect_ratio=1,\n    xaxis=(\"x\", (-1, 1)),  yaxis=(\"y\", (-1, 1)), \n    title=\"Initial condition\" )\n\nThis function computes the time derivative for the unknowns. The actual calculations take place using the matrix shape.\n\nfunction du_dt(u, α, t)\n    U = unvec(u)\n    Uxx = Dxx * U\n    Uyy = U * Dyy'            # 2nd partials\n    du_dt = α * (Uxx + Uyy)    # PDE\n    return vec(du_dt)\nend;\n\nSince this problem is parabolic, a stiff integrator is appropriate.\n\nusing OrdinaryDiffEq\nIVP = ODEProblem(du_dt, vec(U₀), (0, 0.2), 0.1)\nsol = solve(IVP, Rodas4P());\n\nHere is an animation of the solution.\n\nTip\n\nHere clims are set so that colors remain at fixed values throughout the animation.\n\nanim = @animate for t in range(0, 0.2, 81)\n    surface(x, y, unvec(sol(t))';\n        color=:redsblues,  clims=(-M, M),\n        xaxis=(L\"x\", (-1, 1)), \n        yaxis=(L\"y\", (-1, 1)), \n        zlims=(-M, M),\n        title=@sprintf(\"Heat equation, t=%.3f\", t),\n        dpi=150, colorbar=:none)\nend\nmp4(anim, \"figures/2d-heat.mp4\");\n\nExample 13.2.3\n\nThe first step is to define a discretization of the domain.\n\nm, n = 50, 36\nx, Dx, Dxx = FNC.diffcheb(m, [-1, 1])\ny, Dy, Dyy = FNC.diffcheb(n, [-1, 1])\nmtx, X, Y, _ = FNC.tensorgrid(x, y)\nU₀ = mtx( (x, y) -> (1 + y) * (1 - x)^4 * (1 + x)^2 * (1 - y^4) );\n\nThere are really two grids now: the full grid and the subset grid of interior points. Since the IVP unknowns are on the interior grid, that is the one we need to change shapes on. We also need the functions extend and chop to add and remove boundary values.\n\nchop = U -> U[2:m, 2:n]\nextend = U -> [zeros(m+1) [zeros(1, n-1); U; zeros(1, n-1)] zeros(m+1)]\nunvec = u -> reshape(u, m-1, n-1)\npack = U -> vec(chop(U))\nunpack = w -> extend(unvec(w))\n\nNow we can define and solve the IVP using a stiff solver.\n\nfunction dw_dt(w, ϵ, t)\n    U = unpack(w)\n    Ux, Uxx = Dx * U, Dxx * U\n    Uyy = U * Dyy'\n    du_dt = @. 1 - Ux + ϵ * (Uxx + Uyy)\n    return pack(du_dt)\nend\n\nIVP = ODEProblem(dw_dt, pack(U₀), (0.0, 2), 0.05)\nw = solve(IVP, Rodas4P());\n\nWhen we evaluate the solution at a particular value of t, we get a vector of the interior grid values. The same unpack function above converts this to a complete matrix of grid values.\n\nU = t -> unpack(w(t))\ncontour(x, y, U(0.5)';\n    fill=true,  color=:blues,  levels=20, l=0,\n    aspect_ratio=1,  xlabel=L\"x\",  ylabel=L\"y\",\n    title=\"Solution at t = 0.5\")\n\nanim = @animate for t in 0:0.02:2\n    U = unpack(w(t))\n    surface(x, y, U';\n        layout=(1, 2),  size=(640, 320),\n        xlabel=L\"x\",  ylabel=L\"y\",  zaxis=((0, 2), L\"u(x,y)\"),\n        color=:blues,  alpha=0.66,  clims=(0, 2), colorbar=:none,\n        title=\"Advection-diffusion\",  dpi=150)\n    contour!(x, y, U'; \n        levels=24, \n        aspect_ratio=1,  subplot=2, \n        xlabel=L\"x\",  ylabel=L\"y\",\n        color=:blues,  clims=(0, 2),  colorbar=:none,\n        title=@sprintf(\"t = %.2f\", t))\nend\nmp4(anim, \"figures/2d-advdiff.mp4\");\n\nExample 13.2.4\n\nWe start with the discretization and initial condition.\n\nm, n = 40, 40\nx, Dx, Dxx = FNC.diffcheb(m, [-2, 2])\ny, Dy, Dyy = FNC.diffcheb(n, [-2, 2])\nmtx, X, Y, _ = FNC.tensorgrid(x, y)\nU₀ = mtx( (x, y) -> (x + 0.2) * exp(-12 * (x^2 + y^2)) )\nV₀ = zeros(size(U₀));\n\nNote that because u is known on the boundary, while v is unknown over the full grid, there are two different sizes of vec/unvec operations. We also need to define functions to pack grid unknowns into a vector and to unpack them. When the unknowns for u are packed, the boundary values are chopped off, and these are restored when unpacking.\n\n_, _, _, unvec_v, _ = FNC.tensorgrid(x, y)\n_, _, _, unvec_u, _ = FNC.tensorgrid(x[2:m], y[2:n])\nchop = U -> U[2:m, 2:n]\nextend = U -> [zeros(m+1) [zeros(1, n-1); U; zeros(1, n-1)] zeros(m+1)]\npack = (U, V) -> [vec(chop(U)); vec(V)]\nN = (m-1) * (n-1)    # number of interior unknowns\nunpack = w -> ( extend(unvec_u(w[1:N])), unvec_v(w[N+1:end]) )\n\nWe can now define and solve the IVP. Since this problem is hyperbolic, not parabolic, a nonstiff integrator is faster than a stiff one.\n\nfunction dw_dt(w, c, t)\n    U, V = unpack(w)\n    du_dt = V\n    dv_dt = c^2 * (Dxx * U + U * Dyy')\n    return pack(du_dt, dv_dt)\nend\n\nIVP = ODEProblem(dw_dt, pack(U₀, V₀), (0, 4.0), 1)\nsol = solve(IVP, Tsit5())\nU = t -> unpack(sol(t))[1]\n\nanim = @animate for t in 0:4/100:4\n    Ut = U(t)\n    surface(x, y, Ut';\n        layout=(1, 2), size=(640, 320),\n        xlabel=L\"x\",  ylabel=L\"y\",  zaxis=((-0.1, 0.1), L\"u(x,y)\"),\n        color=:redsblues,  alpha=0.66,  clims=(-0.1, 0.1), colorbar=:none,\n        title=\"Wave equation\",  dpi=150)\n    contour!(x, y, Ut'; \n        levels=24,  subplot=2, \n        aspect_ratio=1,\n        xlabel=L\"x\",  ylabel=L\"y\",\n        color=:redsblues,  clims=(-0.1, 0.1), \n        colorbar=:none,  title=@sprintf(\"t = %.2f\", t))\nend\nmp4(anim, \"figures/2d-wave.mp4\");","type":"content","url":"/chapter13#id-13-2","position":9},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.3 Laplace and Poisson equations","lvl2":"Examples"},"type":"lvl3","url":"/chapter13#id-13-3","position":10},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.3 Laplace and Poisson equations","lvl2":"Examples"},"content":"Example 13.3.1\n\nA = [1 2; -2 0]\n\nB = [1 10 100; -5 5 3]\n\nApplying the definition manually, we get\n\nA_kron_B = [\n    A[1, 1]*B A[1, 2]*B;\n    A[2, 1]*B A[2, 2]*B\n    ]\n\nThat result should be the same as the following.\n\nkron(A, B)\n\nExample 13.3.2\n\nWe make a crude discretization for illustrative purposes.\n\nm, n = 6, 5\nx, Dx, Dxx = FNC.diffmat2(m, [0, 3])\ny, Dy, Dyy = FNC.diffmat2(n, [-1, 1])\nmtx, X, Y, unvec, is_boundary = FNC.tensorgrid(x, y)\n\nNext, we evaluate ϕ on the grid to get the forcing vector of the linear system.\n\nϕ = (x, y) -> x^2 - y + 2\nb = vec(mtx(ϕ));\n\nHere are the coefficients for the PDE collocation, before any modifications are made for the boundary conditions. The combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\nusing SparseArrays, Plots\nA = kron(I(n+1), sparse(Dxx)) + kron(sparse(Dyy), I(m+1))\nspy(A;\n    color=:blues,  m=3,\n    title=\"System matrix before boundary conditions\")\n\nThe number of equations is equal to (m+1)(n+1), which is the total number of points on the grid.\n\nN = length(b)\n\nThe combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\n\n\nWe now use the Boolean array that indicates where the boundary points lie in the grid.\n\nspy(sparse(is_boundary);\n    m=3,  color=:darkblue, \n    legend=:none,  title=\"Boundary points\",\n    xaxis=(\"column index\", [0, n+2]), \n    yaxis=(\"row index\", [0, m+2]))\n\nIn order to impose Dirichlet boundary conditions, we replace the boundary rows of the system by rows of the identity.\n\nI_N = I(N)\nidx = vec(is_boundary)\nA[idx, :] .= I_N[idx, :];     # Dirichlet conditions\n\nspy(A;\n    color=:blues,  m=3,\n    title=\"System matrix with boundary conditions\")\n\nFinally, we must replace the rows in the vector \\mathbf{b} by the boundary values being assigned to the boundary points. Here, we let the boundary values be zero everywhere.\n\nb[idx] .= 0;                 # Dirichlet values\n\nNow we can solve for \\mathbf{u} and reinterpret it as the matrix-shaped \\mathbf{U}, the solution on our grid.\n\nu = A \\ b\nU = unvec(u)\n\nExample 13.3.3\n\nFirst we define the problem on [0,1]\\times[0,2].\n\nf = (x, y) -> -sin(3x * y - 4y) * (9y^2 + (3x - 4)^2);\ng = (x, y) -> sin(3x * y - 4y);\nxspan = [0, 1];\nyspan = [0, 2];\n\nHere is the finite-difference solution.\n\nx, y, U = FNC.poissonfd(f, g, 40, xspan, 60, yspan);\n\nsurface(x, y, U';\n    color=:viridis,\n    title=\"Solution of Poisson's equation\",\n    xaxis=(L\"x\"),  yaxis=(L\"y\"),  zaxis=(L\"u(x,y)\"),\n    right_margin=3Plots.mm,  camera=(70, 50))\n\nThe error is a smooth function of x and y. It must be zero on the boundary; otherwise, we have implemented boundary conditions incorrectly.\n\nerror = [g(x, y) for x in x, y in y] - U;\nM = maximum(abs, error)\ncontour(x, y, error';\n    levels=17, \n    clims=(-M, M), color=:redsblues, \n    colorbar=:bottom,  aspect_ratio=1,\n    title=\"Error\", \n    xaxis=(L\"x\"),  yaxis=(L\"y\"),\n    right_margin=7Plots.mm)\nplot!([0, 1, 1, 0, 0], [0, 0, 2, 2, 0], l=(2, :black))","type":"content","url":"/chapter13#id-13-3","position":11},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.4 Nonlinear elliptic PDEs","lvl2":"Examples"},"type":"lvl3","url":"/chapter13#id-13-4","position":12},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.4 Nonlinear elliptic PDEs","lvl2":"Examples"},"content":"Example 13.4.2\n\nAll we need to define are ϕ from \n\n(13.4.2) for the PDE, and a trivial zero function for the boundary condition.\n\nλ = 1.5\nϕ = (X, Y, U, Ux, Uxx, Uy, Uyy) -> @. Uxx + Uyy - λ / (U + 1)^2;\ng = (x, y) -> 0;\n\nHere is the solution for m=15, n=8.\n\nu = FNC.elliptic(ϕ, g, 15, [0, 2.5], 8, [0, 1]);\n\nusing Plots\nx = range(0, 2.5, 100)\ny = range(0, 1, 50)\nU = [u(x, y) for x in x, y in y]\ncontourf(x, y, U';\n    color=:blues,  l=0,\n    aspect_ratio=1,\n    xlabel=L\"x\",  ylabel=L\"y\",  zlabel=L\"u(x,y)\",\n    title=\"Deflection of a MEMS membrane\",\n    right_margin=3Plots.mm)\n\nIn the absence of an exact solution, how can we be confident that the solution is accurate? First, the Levenberg iteration converged without issuing a warning, so we should feel confident that the discrete equations were solved. We can check the boundary values easily. For example,\n\nx_test = range(0, 2.5, 100)\nnorm([u(x, 0) - g(x, 0) for x in x_test], Inf)\n\nAssuming that we encoded the PDE correctly, the remaining source error is truncation from the discretization. We can estimate that by refining the grid a bit and seeing how much the numerical solution changes.\n\nx_test = range(0, 2.5, 6)\ny_test = range(0, 1, 6)\nmtx_test, _ = FNC.tensorgrid(x_test, y_test)\nmtx_test(u)\n\nu = FNC.elliptic(ϕ, g, 25, [0, 2.5], 14, [0, 1]);\nmtx_test(u)\n\nThe original solution seems to be accurate to about four digits.\n\nExample 13.4.3\n\nϕ = (X, Y, U, Ux, Uxx, Uy, Uyy) -> @. 1 - Ux - 2Uy + 0.05 * (Uxx + Uyy)\ng = (x, y) -> 0\nu = FNC.elliptic(ϕ, g, 32, [-1, 1], 32, [-1, 1]);\n\nx = y = range(-1, 1, 80)\nU = [u(x, y) for x in x, y in y]\ncontourf(x, y, U';\n    color=:viridis, \n    aspect_ratio=1,\n    xlabel=L\"x\",  ylabel=L\"y\",  zlabel=L\"u(x,y)\",\n    title=\"Steady advection–diffusion\")\n\nExample 13.4.4\n\nThe following defines the PDE and a nontrivial Dirichlet boundary condition for the square [0,1]^2.\n\nϕ = (X, Y, U, Ux, Uxx, Uy, Uyy) -> @. U * (1 - U^2) + 0.05 * (Uxx + Uyy)\ng = (x, y) -> tanh(5 * (x + 2y - 1));\n\nWe solve the PDE and then plot the result.\n\nu = FNC.elliptic(ϕ, g, 36, [0, 1], 36, [0, 1]);\n\nx = y = range(0, 1, 80)\nU = [u(x, y) for x in x, y in y]\ncontourf(x, y, U';\n    color=:viridis, \n    aspect_ratio=1,\n    xlabel=L\"x\",  ylabel=L\"y\",  zlabel=L\"u(x,y)\", \n    title=\"Steady Allen-Cahn\",\n    right_margin=3Plots.mm)","type":"content","url":"/chapter13#id-13-4","position":13},{"hierarchy":{"lvl1":"Chapter 2"},"type":"lvl1","url":"/chapter2","position":0},{"hierarchy":{"lvl1":"Chapter 2"},"content":"","type":"content","url":"/chapter2","position":1},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"type":"lvl2","url":"/chapter2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"content":"Forward substitution\n\n\"\"\"\n    forwardsub(L,b)\n\nSolve the lower-triangular linear system with matrix `L` and\nright-hand side vector `b`.\n\"\"\"\nfunction forwardsub(L, b)\n    n = size(L, 1)\n    x = zeros(n)\n    x[1] = b[1] / L[1, 1]\n    for i in 2:n\n        s = sum(L[i, j] * x[j] for j in 1:i-1)\n        x[i] = (b[i] - s) / L[i, i]\n    end\n    return x\nend\n\nAbout the code\n\nThe sum in line 12 gives an error if i equals 1, so that case is taken care of before the loop starts.\n\nBackward substitution\n\n\"\"\"\n    backsub(U,b)\n\nSolve the upper-triangular linear system with matrix `U` and\nright-hand side vector `b`.\n\"\"\"\nfunction backsub(U, b)\n    n = size(U, 1)\n    x = zeros(n)\n    x[n] = b[n] / U[n, n]\n    for i in n-1:-1:1\n        s = sum(U[i, j] * x[j] for j in i+1:n)\n        x[i] = (b[i] - s) / U[i, i]\n    end\n    return x\nend\n\nLU factorization (not stable)\n\n\"\"\"\n    lufact(A)\n\nCompute the LU factorization of square matrix `A`, returning the\nfactors.\n\"\"\"\nfunction lufact(A)\n    n = size(A, 1)        # detect the dimensions from the input\n    L = diagm(ones(n))   # ones on main diagonal, zeros elsewhere\n    U = zeros(n, n)\n    Aₖ = float(copy(A))  # make a working copy\n\n    # Reduction by outer products\n    for k in 1:n-1\n        U[k, :] = Aₖ[k, :]\n        L[:, k] = Aₖ[:, k] / U[k, k]\n        Aₖ -= L[:, k] * U[k, :]'\n    end\n    U[n, n] = Aₖ[n, n]\n    return LowerTriangular(L), UpperTriangular(U)\nend\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out two subtle Julia issues. First, vectors and matrix variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement Aₖ=A just clones the array reference of A into the variable Aₖ. Any changes made to entries of Aₖ would then also be made to entries of A because they refer to the same location in memory. In this context we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nThe second issue is that even when A has all integer entries, its LU factors may not. So we convert Aₖ to floating point so that line 17 will not fail due to the creation of floating-point values in an integer matrix. An alternative would be to require the caller to provide a floating-point array in the first place.\n\nLU factorization with partial pivoting\n\n\"\"\"\n    plufact(A)\n\nCompute the PLU factorization of square matrix `A`, returning the\ntriangular factors and a row permutation vector.\n\"\"\"\nfunction plufact(A)\n    n = size(A, 1)\n    L = zeros(n, n)\n    U = zeros(n, n)\n    p = fill(0, n)\n    Aₖ = float(copy(A))\n\n    # Reduction by outer products\n    for k in 1:n\n        p[k] = argmax(abs.(Aₖ[:, k]))    # best pivot in column k\n        U[k, :] = Aₖ[p[k], :]\n        L[:, k] = Aₖ[:, k] / U[k, k]\n        if k < n    # no update needed on last iteration\n            Aₖ -= L[:, k] * U[k, :]'\n        end\n    end\n    return LowerTriangular(L[p, :]), U, p\nend","type":"content","url":"/chapter2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"type":"lvl2","url":"/chapter2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.1 Polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-1","position":6},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.1 Polynomial interpolation","lvl2":"Examples"},"content":"Example 2.1.1\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982, 2000, 2010, 2015]; \npop = [1008.18, 1262.64, 1337.82, 1374.62];\n\nIt’s convenient to measure time in years since 1980. We use .- to subtract a scalar from every element of a vector. We will also use a floating-point value in the subtraction, so the result is also in double precision.\n\nTip\n\nA dotted operator such as .- or .* acts elementwise, broadcasting scalar values to match up with elements of an array.\n\nt = year .- 1980.0\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nTip\n\nAn expression inside square brackets and ending with a for statement is called a comprehension. It’s often an easy and readable way to construct vectors and matrices.\n\nV = [ t[i]^j for i in 1:4, j in 0:3 ]\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nTip\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V * c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in ascending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\nTip\n\nThe Polynomials package has functions to make working with polynomials easy and efficient.\n\nusing Polynomials\np = Polynomial(c)    # construct a polynomial\np(2005-1980)         # include the 1980 time shift\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nTip\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nusing Plots\nscatter(t, y;\n    label=\"actual\",  legend=:topleft,\n    xlabel=\"years since 1980\",  ylabel=\"population (millions)\", \n    title=\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval. The dot after the name of the polynomial is a universal way to apply a function to every element of an array, a technique known as broadcasting.\n\nThe range function constructs evenly spaced values given the endpoints and either the number of values, or the step size between them.\n\nAdding a dot to the end of a function name causes it to be broadcast, i.e., applied to every element of a vector or matrix.\n\n# Choose 500 times in the interval [0,35].\ntt = range(0, 35, 500)\n\n# Evaluate the polynomial at all the vector components.\nyy = p.(tt)\n\nforeach(println, yy[1:4])\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nTip\n\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\nBy convention, functions whose names end with the bang ! change the value or state of something, in addition to possibly returning output.\n\nplot!(tt, yy, label=\"interpolant\")","type":"content","url":"/chapter2#id-2-1","position":7},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.2 Computing with matrices","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-2","position":8},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.2 Computing with matrices","lvl2":"Examples"},"content":"Example 2.2.1\n\nIn Julia, vectors and matrices are one-dimensional and two-dimensional arrays, respectively. Square brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nTip\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ 1 2 3 4 5; 50 40 30 20 10\n    π sqrt(2) exp(1) (1+sqrt(5))/2 log(3) ]\n\nm, n = size(A)\n\nA vector is not quite the same thing as a matrix: it has only one dimension, not two. Separate its elements by commas or semicolons:\n\nx = [ 3, 3, 0, 1, 0 ]\nsize(x)\n\nFor some purposes, however, an n-vector in Julia is treated like having a column shape. Note the difference if we use spaces instead of commas inside the brackets:\n\ny = [ 3 3 0 1 0 ]\nsize(y)\n\nThis 1\\times 5 matrix is not equivalent to a vector.\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nIf x is simply a vector, then its transpose has a row shape.\n\nx'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              # start:stop\n\nz = 0:3:12           # start:step:stop\n\n(Ranges are not strictly considered vectors, but they behave identically in most circumstances.) Instead of specifying the step size, you can give the number of points in the range if you use range.\n\ns = range(-1, 1, 5)\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within square brackets.\n\nTip\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A[2, end-1]\n\nx[2]\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA[1:2, end-2:end]    # first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA[:, 1:2:end]        # all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nTip\n\nUse diagm to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diagm( [-1, 0, -5] )   # create a diagonal matrix\n\n@show size(A), size(B);\nBA = B * A     # matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nTip\n\nErrors are formally called exceptions in Julia.\n\nA * B    # throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    # same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x .^ 2\n\ntwo_to_x = 2 .^ x\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, expect scalars as operands. However, you can broadcast any function, including ones that you have defined, across a vector or array by using a special dot syntax.\n\nTip\n\nA dot added to the end of a function name means to apply the function elementwise to an array.\n\nshow(cos.(π * x))    # broadcast to a function\n\nRather than dotting multiple individual functions, you can use @. before an expression to broadcast everything within it.\n\nshow(@. cospi( (x + 1)^3) )    # broadcast an entire expression","type":"content","url":"/chapter2#id-2-2","position":9},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.3 Linear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-3","position":10},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.3 Linear systems","lvl2":"Examples"},"content":"Example 2.3.2\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1, 2, 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A * x\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = [0 1; 0 0]\nb = [1, -1]\nx = A \\ b    # throws an error\n\nIn this case we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nTip\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nExample 2.3.3\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nTip\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = rand(1.:9., 5, 5)\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L,b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext we’ll engineer a problem to which we know the exact answer. Use \\alpha Tab and \\beta Tab to get the Greek letters.\n\nTip\n\nThe notation 0=>ones(5) creates a Pair. In diagm, pairs indicate the position of a diagonal and the elements that are to be placed on it.\n\nα = 0.3;\nβ = 2.2;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nU\n\nx_exact = ones(5)\nb = [α, 0, 0, 0, 1]\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nα = 0.3;\nβ = 1e12;\nU = diagm( 0=>ones(5), 1=>[-1, -1, -1, -1] )\nU[1, [4, 5]] = [ α - β, β ]\nb = [α, 0, 0, 0, 1]\n\nx = FNC.backsub(U,b)\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with 16! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.","type":"content","url":"/chapter2#id-2-3","position":11},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.4 LU factorization","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-4","position":12},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.4 LU factorization","lvl2":"Examples"},"content":"Example 2.4.2\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( rand(1:9, 3, 3) )\n\nU = triu( rand(1:9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nTip\n\nAlthough U[1,:] is a row of U, it is a vector, and as such it has a default column interpretation.\n\nL[:, 1] * U[1, :]'\n\nL[:, 2] * U[2, :]'\n\nL[:, 3] * U[3, :]'\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nExample 2.4.3\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA₁ = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = diagm(ones(4))\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[1, :] = A₁[1, :]\nU\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 1] = A₁[:, 1] / U[1, 1]\nL\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[2, :] = A₂[2, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nL\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[3, :] = A₃[3, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\nFinally, we pick up the last unknown in the factors.\n\nU[4, 4] = A₄[4, 4];\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA₁ - L * U\n\nIIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nExample 2.4.4\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4,9,9,4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A*x","type":"content","url":"/chapter2#id-2-4","position":13},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.5 Efficiency of matrix computations","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-5","position":14},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.5 Efficiency of matrix computations","lvl2":"Examples"},"content":"Example 2.5.4\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = randn(n, n)\nx = rand(n)\ny = zeros(n)\nfor i in 1:n\n    for j in 1:n\n        y[i] += A[i, j] * x[j]    # 1 multiply, 1 add\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. Note that Julia is unusual in that loops have a variable scope separate from its enclosing code. Thus, for n in n below means that inside the loop, the name n will take on each one of the values that were previously assigned to the vector n.\n\nTip\n\nThe push! function attaches a new value to the end of a vector.\n\nn = 1000:1000:5000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:80; A * x; end\n    push!(t, time)\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\n@pt :header = [\"size\", \"time (sec.)\"] [n t]\n\nLooking at the timings just for n=2000 and n=4000, they have ratio\n\nTip\n\nThe expression n.==4000 here produces a vector of Boolean (true/false) values the same size as n. This result is used to index within t, accessing only the value for which the comparison is true.\n\n@show t[n.==4000] ./ t[n.==2000];\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nExample 2.5.5\n\nLet’s repeat the experiment of the previous figure for more, and larger, values of n.\n\nrandn(5,5)*randn(5);  # throwaway to force compilation\n\nn = 400:200:6000\nt = []\nfor n in n\n    A = randn(n, n)  \n    x = randn(n)\n    time = @elapsed for j in 1:50; A * x; end\n    push!(t, time)\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nscatter(n, t, label=\"data\", legend=false,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time (sec)\"),\n    title=\"Timing of matrix-vector multiplications\")\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nplot!(n, t[end] * (n/n[end]).^2, l=:dash,\n    label=L\"O(n^2)\", legend=:topleft)\n\nExample 2.5.6\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nTip\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nlu(randn(3, 3));   # throwaway to force compilation\n\nn = 400:400:4000\nt = []\nfor n in n\n    A = randn(n, n)  \n    time = @elapsed for j in 1:12; lu(A); end\n    push!(t, time)\nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nscatter(n, t, label=\"data\", legend=:topleft,\n    xaxis=(:log10, L\"n\"), yaxis=(:log10, \"elapsed time\"))\nplot!(n, t[end ]* (n/n[end]).^3, l=:dash, label=L\"O(n^3)\")","type":"content","url":"/chapter2#id-2-5","position":15},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.6 Row pivoting","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-6","position":16},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.6 Row pivoting","lvl2":"Examples"},"content":"Example 2.6.1\n\nHere is a previously encountered matrix that factors well.\n\nA = [2 0 4 3 ; -4 5 -7 -10 ; 1 15 2 -4.5 ; -2 0 2 -13];\nL, U = FNC.lufact(A)\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[2, 4], :] = A[[4, 2], :]  \nL, U = FNC.lufact(A)\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[1, :] = A[1, :]\nL[:, 1] = A[:, 1] / U[1, 1]\nA -= L[:, 1] * U[1, :]'\n\nThe next step is U[2, :] = A[2, :], which is also OK. But then we are supposed to divide by U[2, 2], which is zero. The algorithm cannot continue.\n\nExample 2.6.2\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA₁ = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nTip\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs.(A₁[:, 1]) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = zeros(4,4),zeros(4,4)\nU[1, :] = A₁[i, :]\nL[:, 1] = A₁[:, 1] / U[1, 1]\nA₂ = A₁ - L[:, 1] * U[1, :]'\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n@show i = argmax( abs.(A₂[:, 2]) ) \nU[2, :] = A₂[i, :]\nL[:, 2] = A₂[:, 2] / U[2, 2]\nA₃ = A₂ - L[:, 2] * U[2, :]'\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n@show i = argmax( abs.(A₃[:, 3]) ) \nU[3, :] = A₃[i, :]\nL[:, 3] = A₃[:, 3] / U[3, 3]\nA₄ = A₃ - L[:, 3] * U[3, :]'\n\n@show i = argmax( abs.(A₄[:, 4]) ) \nU[4, :] = A₄[i, :]\nL[:, 4] = A₄[:, 4] / U[4, 4];\n\nWe do have a factorization of the original matrix:\n\nA₁ - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nExample 2.6.3\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = [2 0 4 3 ; -2 0 2 -13; 1 15 2 -4.5 ; -4 5 -7 -10]\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1. If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A[[4, 3, 2, 1], :]\nL, U = FNC.lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nU\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nL\n\nExample 2.6.4\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = rand(1:20, 4, 4)\nL, U, p = FNC.plufact(A)\nA[p,:] - L * U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4)\nz = FNC.forwardsub(L,b[p])\nx = FNC.backsub(U,z)\n\nA residual check is successful:\n\nb - A*x\n\nExample 2.6.5\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500)   # 500x500 with normal random entries\nA \\ rand(500)          # force compilation\n@elapsed for k=1:50; A \\ rand(500); end\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\nfactored = lu(A)     # store factorization result\nfactored \\ rand(500)   # force compilation\n@elapsed for k=1:50; factored \\ rand(500); end\n\nExample 2.6.6\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nϵ = 1e-12\nA = [-ϵ 1; 1 -1]\nb = A * [1, 1]\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nϵ = 1e-20; A = [-ϵ 1; 1 -1]\nb = A * [1, 1]\nL, U = FNC.lufact(A)\nx = FNC.backsub( U, FNC.forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b","type":"content","url":"/chapter2#id-2-6","position":17},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.7 Vector and matrix norms","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-7","position":18},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.7 Vector and matrix norms","lvl2":"Examples"},"content":"Example 2.7.1\n\nIn Julia the LinearAlgebra package has a norm function for vector norms.\n\nx = [2, -3, 1, -1]\ntwonorm = norm(x)         # or norm(x,2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nThere is also a normalize function that divides a vector by its norm, making it a unit vector.\n\nnormalize(x, Inf)\n\nExample 2.7.2\n\nA = [ 2 0; 1 -1 ]\n\nIn Julia, one uses norm for vector norms and for the Frobenius norm of a matrix, which is like stacking the matrix into a single vector before taking the 2-norm.\n\nFronorm = norm(A)\n\nMost of the time we want to use opnorm, which is an induced matrix norm. The default is the 2-norm.\n\ntwonorm = opnorm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = opnorm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nTip\n\nUse sum to sum along a dimension of a matrix. You can also sum over the entire matrix by omitting the dims argument.\nThe maximum and minimum functions also work along one dimension or over an entire matrix. To get both values at once, use extrema.\n\n# Sum down the rows (1st matrix dimension):\nmaximum( sum(abs.(A), dims=1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = opnorm(A, Inf)\n\n # Sum across columns (2nd matrix dimension):\nmaximum( sum(abs.(A), dims=2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nTip\n\nYou can use functions as values, e.g., as elements of a vector.\n\n# Construct 601 unit column vectors.\nθ = 2π * (0:1/600:1)   # type \\theta then Tab\nx = [ fun(t) for fun in [cos, sin], t in θ ];\n\nTo create an array of plots, start with a plot that has a layout argument, then do subsequent plot! calls with a subplot argument.\n\nplot(aspect_ratio=1, layout=(1, 2),\n    xlabel=L\"x_1\",  ylabel=L\"x_2\")\nplot!(x[1, :], x[2, :], subplot=1, title=\"Unit circle\")\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse.\n\nplot!(Ax[1, :], Ax[2, :], \n    subplot=2, title=\"Image under x → Ax\")\n\nThat ellipse just touches the circle of radius \\|\\mathbf{A}\\|_2.\n\nplot!(twonorm*x[1, :], twonorm*x[2, :], subplot=2, l=:dash)","type":"content","url":"/chapter2#id-2-7","position":19},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.8 Conditioning of linear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-8","position":20},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.8 Conditioning of linear systems","lvl2":"Examples"},"content":"Example 2.8.1\n\nJulia has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nTip\n\nType \\kappa followed by Tab to get the Greek letter κ.\n\nA = [ 1 / (i + j) for i in 1:6, j in 1:6 ]\nκ = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = 1:6\nb = A * x\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\n# type \\Delta then Tab to get Δ\nΔA = randn(size(A));  ΔA = 1e-10 * (ΔA / opnorm(ΔA));\nΔb = randn(size(b));  Δb = 1e-10 * normalize(Δb);\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + ΔA) \\ (b + Δb))\nΔx = new_x - x\n\nHere is the relative error in the solution.\n\n@show relative_error = norm(Δx) / norm(x);\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprintln(\"Upper bound due to b: $(κ * norm(Δb) / norm(b))\")\nprintln(\"Upper bound due to A: $(κ * opnorm(ΔA) / opnorm(A))\")\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n@show rounding_bound = κ * eps();\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = [ 1 / (i + j) for i=1:14, j=1:14 ];\nκ = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = κ*eps()\n\nLet’s put that prediction to the test.\n\nx = 1:14\nb = A * x  \nΔx = A\\b - x\n@show relative_error = norm(Δx) / norm(x);\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.","type":"content","url":"/chapter2#id-2-8","position":21},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.9 Exploiting matrix structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter2#id-2-9","position":22},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.9 Exploiting matrix structure","lvl2":"Examples"},"content":"Example 2.9.1\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nTip\n\nUse fill to create an array of a given size, with each element equal to a provided value.\n\nA = diagm( -1 => [4, 3, 2, 1, 0], \n    0 => [2, 2, 0, 2, 1, 2], \n    1 => fill(-1, 5) )\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nTip\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\n@show diag_main = diag(A);\n@show diag_minusone = diag(A, -1);\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\nL, U = FNC.lufact(A)\nL\n\nU\n\nExample 2.9.2\n\nWe begin with a symmetric \\mathbf{A}.\n\nA₁ = [  2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = diagm(ones(4))\nd = zeros(4)\nd[1] = A₁[1, 1]\nL[:, 1] = A₁[:, 1] / d[1]\nA₂ = A₁ - d[1] * L[:, 1] * L[:, 1]'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[2] = A₂[2, 2]\nL[:, 2] = A₂[:, 2] / d[2]\nA₃ = A₂ - d[2] * L[:, 2] * L[:, 2]'\n\nWe continue working our way down the diagonal.\n\nd[3] = A₃[3, 3]\nL[:, 3] = A₃[:, 3] / d[3]\nA₄ = A₃ - d[3] * L[:, 3] * L[:, 3]'\nd[4] = A₄[4, 4]\n@show d;\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nopnorm(A₁ - (L * diagm(d) * L'))\n\nExample 2.9.3\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = rand(1.0:9.0, 4, 4)\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nTip\n\nThe cholesky function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix. However, it does not check for symmetry.\n\ncholesky(B)    # throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A\ncf = cholesky(B)\n\nWhat’s returned is a factorization object. Another step is required to extract the factor as a matrix:\n\nR = cf.U\n\nHere we validate the factorization:\n\nopnorm(R' * R - B) / opnorm(B)","type":"content","url":"/chapter2#id-2-9","position":23},{"hierarchy":{"lvl1":"Chapter 3"},"type":"lvl1","url":"/chapter3","position":0},{"hierarchy":{"lvl1":"Chapter 3"},"content":"","type":"content","url":"/chapter3","position":1},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"type":"lvl2","url":"/chapter3#functions","position":2},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"content":"Solution of least squares by the normal equations\n\n\"\"\"\n    lsnormal(A, b)\n\nSolve a linear least-squares problem by the normal equations.\nReturns the minimizer of ||b-Ax||.\n\"\"\"\nfunction lsnormal(A, b)\n    N = A' * A\n    z = A' * b\n    R = cholesky(N).U\n    w = forwardsub(R', z)                   # solve R'z=c\n    x = backsub(R, w)                       # solve Rx=z\n    return x\nend\n\nAbout the code\n\nThe syntax on line 9 is a field reference to extract the matrix we want from the structure returned by cholesky.\n\nSolution of least squares by QR factorization\n\n\"\"\"\n    lsqrfact(A, b)\n\nSolve a linear least-squares problem by QR factorization. Returns\nthe minimizer of ||b-Ax||.\n\"\"\"\nfunction lsqrfact(A, b)\n    Q, R = qr(A)\n    c = Q' * b\n    x = backsub(R, c)\n    return x\nend\n\nQR factorization by Householder reflections\n\n\"\"\"\n    qrfact(A)\n\nQR factorization by Householder reflections. Returns Q and R.\n\"\"\"\nfunction qrfact(A)\n    m, n = size(A)\n    Qt = diagm(ones(m))\n    R = float(copy(A))\n    for k in 1:n\n        z = R[k:m, k]\n        w = [-sign(z[1]) * norm(z) - z[1]; -z[2:end]]\n        nrmw = norm(w)\n        if nrmw < eps()\n            continue    # already in place; skip this iteration\n        end\n        v = w / nrmw\n        # Apply the reflection to each relevant column of R and Q\n        for j in k:n\n            R[k:m, j] -= v * (2 * (v' * R[k:m, j]))\n        end\n        for j in 1:m\n            Qt[k:m, j] -= v * (2 * (v' * Qt[k:m, j]))\n        end\n    end\n    return Qt', triu(R)\nend","type":"content","url":"/chapter3#functions","position":3},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"type":"lvl2","url":"/chapter3#examples","position":4},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter3#examples","position":5},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.1 Fitting functions to data","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#id-3-1","position":6},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.1 Fitting functions to data","lvl2":"Examples"},"content":"Example 3.1.1\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = 1955:5:2000\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n       0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n    \nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", \n    legend=:bottomright)\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = @. (year - 1950) / 10\nn = length(t)\nV = [ t[i]^j for i in 1:n, j in 0:n-1 ]\nc = V \\ temp\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\nTip\n\nIf you plot a function, then the points are chosen automatically to make a smooth curve.\n\nusing Polynomials, Plots\np = Polynomial(c)\nf = yr -> p((yr - 1950) / 10)\nplot!(f, 1955, 2000, label=\"interpolant\")\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nExample 3.1.2\n\nHere are the 5-year temperature averages again.\n\nyear = 1955:5:2000\nt = @. (year - 1950) / 10\ntemp = [ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n          0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ]\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nTip\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = [ t.^0 t ]    # Vandermonde-ish matrix\n@show size(V)\nc = V \\ temp\np = Polynomial(c)\n\nf = yr -> p((yr - 1955) / 10)\nscatter(year, temp, label=\"data\",\n    xlabel=\"year\", ylabel=\"anomaly (degrees C)\", leg=:bottomright)\nplot!(f, 1955, 2000, label=\"linear fit\")\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [ t[i]^j for i in 1:length(t), j in 0:3 ]   \n@show size(V);\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nTip\n\nThe definition of f above is in terms of p. When p is changed, then f calls the new version.\n\np = Polynomial( V \\ temp )\nplot!(f, 1955, 2000, label=\"cubic fit\")\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nExample 3.1.3\n\na = [1/k^2 for k=1:100] \ns = cumsum(a)        # cumulative summation\np = @. sqrt(6*s)\n\nscatter(1:100, p;\n    title=\"Sequence convergence\",\n    xlabel=L\"k\",  ylabel=L\"p_k\")\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nϵ = @. abs(π - p)    # error sequence\nscatter(1:100, ϵ;\n    title=\"Convergence of errors\",\n    xaxis=(:log10,L\"k\"),  yaxis=(:log10,\"error\"))\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nk = 1:100\nV = [ k.^0 log.(k) ]     # fitting matrix\nc = V \\ log.(ϵ)          # coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[1]), c[2];\n@show b;\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nplot!(k, a * k.^b, l=:dash, label=\"power-law fit\")","type":"content","url":"/chapter3#id-3-1","position":7},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.2 The normal equations","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#id-3-2","position":8},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.2 The normal equations","lvl2":"Examples"},"content":"Example 3.2.1\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nTip\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = range(0, 3, 400)\nf = [ x -> sin(x)^2, x -> cos((1 + 1e-7) * x)^2, x -> 1. ]\nA = [ f(t) for t in t, f in f ]\n@show κ = cond(A);\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1., 2, 1]\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b\n@show observed_error = norm(x_BS - x) / norm(x);\n@show error_bound = κ * eps();\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A' * A\nx_NE = N \\ (A'*b)\n@show observed_err = norm(x_NE - x) / norm(x);\n@show digits = -log10(observed_err);","type":"content","url":"/chapter3#id-3-2","position":9},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.3 The QR factorization","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#id-3-3","position":10},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.3 The QR factorization","lvl2":"Examples"},"content":"Example 3.3.1\n\nJulia provides access to both the thin and full forms of the QR factorization.\n\nA = rand(1.:9., 6, 4)\n@show m,n = size(A);\n\nHere is a standard call:\n\nQ,R = qr(A);\nQ\n\nR\n\nIf you look carefully, you see that we seemingly got a full \\mathbf{Q} but a thin \\mathbf{R}. However, the \\mathbf{Q} above is not a standard matrix type. If you convert it to a true matrix, then it reverts to the thin form.\n\nTip\n\nTo enter the accented character Q̂, type Q\\hat followed by Tab.\n\nQ̂ = Matrix(Q)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nopnorm(Q' * Q - I)\n\nThe thin \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC:\n\nQ̂' * Q̂ - I\n\nExample 3.3.2\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = range(0, 3, 400)\nf = [ x -> sin(x)^2, x -> cos((1 + 1e-7) * x)^2, x -> 1. ]\nA = [ f(t) for t in t, f in f ]\nx = [1., 2, 1]\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(FNC.lsqrfact(A, b) - x) / norm(x);\n@show observed_error;\n@show error_bound = cond(A) * eps();","type":"content","url":"/chapter3#id-3-3","position":11},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.4 Computing QR factorizations","lvl2":"Examples"},"type":"lvl3","url":"/chapter3#id-3-4","position":12},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.4 Computing QR factorizations","lvl2":"Examples"},"content":"Example 3.4.1\n\nWe will use Householder reflections to produce a QR factorization of a random matrix.\n\nTip\n\nThe rand function can select randomly from within the interval [0,1], or from a vector or range that you specify.\n\nA = rand(float(1:9), 6, 4)\nm,n = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nTip\n\nI can stand for an identity matrix of any size, inferred from the context when needed.\n\nz = A[:, 1];\nv = normalize(z - norm(z) * [1; zeros(m-1)])\nP₁ = I - 2v * v'   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nP₁ * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}\\mathbf{A}.\n\nA = P₁ * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[2:m, 2]\nv = normalize(z - norm(z) * [1; zeros(m-2)])\nP₂ = I - 2v * v'\n\nWe now apply this reflector to rows 2 and below only.\n\nA[2:m, :] = P₂ * A[2:m, :]\nA\n\nWe need to iterate the process for the last two columns.\n\nfor j in 3:n\n    z = A[j:m, j]\n    v = normalize(z - norm(z) * [1; zeros(m-j)])\n    P = I - 2v * v'\n    A[j:m, :] = P * A[j:m, :]\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)","type":"content","url":"/chapter3#id-3-4","position":13},{"hierarchy":{"lvl1":"Chapter 4"},"type":"lvl1","url":"/chapter4","position":0},{"hierarchy":{"lvl1":"Chapter 4"},"content":"","type":"content","url":"/chapter4","position":1},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"type":"lvl2","url":"/chapter4#functions","position":2},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"content":"Newton’s method\n\n\"\"\"\n    newton(f, df_dx, x₁ [;maxiter,f tol, xtol])\n\nUse Newton's method to find a root of `f` starting from `x₁`, where\n`df_dx` is the derivative of `f`. Returns a vector of root estimates.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\"\"\"\nfunction newton(f, df_dx, x₁; maxiter = 40, ftol = 1e-13, xtol = 1e-13)\n    x = [float(x₁)]\n    y = f(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (abs(Δx) > xtol) && (abs(y) > ftol)\n        dy_dx = df_dx(x[k])\n        Δx = -y / dy_dx            # Newton step\n        push!(x, x[k] + Δx)        # append new estimate\n\n        k += 1\n        y = f(x[k])\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nSecant method\n\n\"\"\"\n    secant(f, x₁, x₂ [;maxiter, ftol, xtol])\n\nUse the secant method to find a root of `f` starting from `x₁` and\n`x₂`. Returns a vector of root estimates.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\"\"\"\nfunction secant(f, x₁, x₂; maxiter = 40, ftol = 1e-13, xtol = 1e-13)\n    x = [float(x₁), float(x₂)]\n    y₁ = f(x₁)\n    Δx, y₂ = Inf, Inf   # for initial pass in the loop below\n    k = 2\n\n    while (abs(Δx) > xtol) && (abs(y₂) > ftol)\n        y₂ = f(x[k])\n        Δx = -y₂ * (x[k] - x[k-1]) / (y₂ - y₁)   # secant step\n        push!(x, x[k] + Δx)        # append new estimate\n\n        k += 1\n        y₁ = y₂    # current f-value becomes the old one next time\n\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break   # exit loop\n        end\n    end\n    return x\nend\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.\n\nNewton’s method for systems\n\n\"\"\"\n    newtonsys(f, jac, x₁ [;maxiter, ftol, xtol])\n\nUse Newton's method to find a root of a system of equations,\nstarting from `x₁`. The functions `f` and `jac` should return the\nresidual vector and the Jacobian matrix, respectively. Returns the\nhistory of root estimates as a vector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction newtonsys(f, jac, x₁; maxiter = 40, ftol = 1e-13, xtol = 1e-13)\n    x = [float(x₁)]\n    y, J = f(x₁), jac(x₁)\n    Δx = Inf   # for initial pass below\n    k = 1\n\n    while (norm(Δx) > xtol) && (norm(y) > ftol)\n        Δx = -(J \\ y)             # Newton step\n        push!(x, x[k] + Δx)    # append to history\n        k += 1\n        y, J = f(x[k]), jac(x[k])\n\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n    end\n    return x\nend\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nFinite differences for Jacobian\n\n\"\"\"\n    fdjac(f, x₀ [,y₀])\n\nCompute a finite-difference approximation of the Jacobian matrix for\n`f` at `x₀`, where `y₀`=`f(x₀)` may be given.\n\"\"\"\nfunction fdjac(f, x₀, y₀ = f(x₀))\n    δ = sqrt(eps()) * max(norm(x₀), 1)    # near-optimum FD step size\n    m, n = length(y₀), length(x₀)\n    if n == 1\n        # Vector result for univariate functions.\n        J = (f(x₀ + δ) - y₀) / δ\n    else\n        J = zeros(m, n)\n        x = copy(x₀)\n        for j in 1:n\n            # Difference in the jth direction.\n            x[j] += δ\n            J[:, j] = (f(x) - y₀) / δ\n            x[j] -= δ\n        end\n    end\n    return J\nend\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.\n\nLevenberg’s method\n\n\"\"\"\n    levenberg(f, x₁ [;maxiter, ftol, xtol])\n\nUse Levenberg's quasi-Newton iteration to find a root of the system\n`f` starting from `x₁` Returns the history of root estimates as a\nvector of vectors.\n\nThe optional keyword parameters set the maximum number of iterations\nand the stopping tolerance for values of `f` and changes in `x`.\n\n\"\"\"\nfunction levenberg(f, x₁; maxiter = 40, ftol = 1e-12, xtol = 1e-12)\n    x = [float(x₁)]\n    yₖ = f(x₁)\n    k = 1\n    s = Inf\n    A = fdjac(f, x[k], yₖ)   # start with FD Jacobian\n    jac_is_new = true\n\n    λ = 10\n    while (norm(s) > xtol) && (norm(yₖ) > ftol)\n        # Compute the proposed step.\n        B = A' * A + λ * I\n        z = A' * yₖ\n        s = -(B \\ z)\n\n        x̂ = x[k] + s\n        ŷ = f(x̂)\n\n        # Do we accept the result?\n        if norm(ŷ) < norm(yₖ)    # accept\n            λ = λ / 10   # get closer to Newton\n            # Broyden update of the Jacobian.\n            A += (ŷ - yₖ - A * s) * (s' / (s' * s))\n            jac_is_new = false\n\n            push!(x, x̂)\n            yₖ = ŷ\n            k += 1\n        else    # don't accept\n            # Get closer to gradient descent.\n            λ = 4λ\n            # Re-initialize the Jacobian if it's out of date.\n            if !jac_is_new\n                A = fdjac(f, x[k], yₖ)\n                jac_is_new = true\n            end\n        end\n\n        if k == maxiter\n            @warn \"Maximum number of iterations reached.\"\n            break\n        end\n    end\n    return x\nend","type":"content","url":"/chapter4#functions","position":3},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"type":"lvl2","url":"/chapter4#examples","position":4},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter4#examples","position":5},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.1 The rootfinding problem","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-1","position":6},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.1 The rootfinding problem","lvl2":"Examples"},"content":"Example 4.1.1\n\nusing Plots, SpecialFunctions\nJ₃(x) = besselj(3, x)\nplot(J₃, 0, 20;\n    title=\"Bessel function\",\n    xaxis=(L\"x\"),  yaxis=(L\"J_3(x)\"),  grid=:xy)\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nTip\n\nType \\omega followed by Tab to get the character ω.\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nusing NLsolve\nω = []\nfor guess = [6., 10. ,13., 16., 19.]\n    s = nlsolve(x -> J₃(x[1]), [guess], ftol=1e-14)\n    append!(ω, s.zero)\nend\n\ny = J₃.(ω)\n@pt :header=[\"root estimate\", \"function value\"] [ω y]\n\nscatter!(ω, y, title=\"Bessel function with roots\")\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nr = []\nfor guess = [3., 6., 10., 13.]\n    f(x) = J₃(x[1]) - 0.2\n    s = nlsolve(f, [guess], ftol=1e-14)\n    append!(r, s.zero)\nend\nscatter!(r, J₃.(r), title=\"Roots and other Bessel values\")\n\nExample 4.1.2\n\nConsider first the function\n\nf(x) = (x - 1) * (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nTip\n\nThe syntax interval... is called splatting and means to insert all the individual elements of interval as a sequence.\n\ninterval = [0.8, 1.2]\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Well-conditioned root\")\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf(x) = (x - 1) * (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nplot(f, interval..., ribbon=0.03, aspect_ratio=1,\n    xlabel=L\"x\", yaxis=(L\"f(x)\", [-0.2, 0.2]))\n\nscatter!([1], [0], title=\"Poorly-conditioned root\")\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!","type":"content","url":"/chapter4#id-4-1","position":7},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.2 Fixed-point iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-2","position":8},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.2 Fixed-point iteration","lvl2":"Examples"},"content":"Example 4.2.1\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nusing Polynomials\np = Polynomial([3.5, -4,1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nWe define g(x)=x-p(x).\n\ng(x) = x - p(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nusing Plots\nplt = plot([g x->x], 2, 3;\n    l=2, label=[L\"y=g(x)\" L\"y=x\"],\n    xlabel=L\"x\",  ylabel=L\"y\", \n    aspect_ratio=1,\n    title=\"Finding a fixed point\",  legend=:bottomright)\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot!([x, y], [y, y], arrow=true, color=3)\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y;  y = g(x)\nplot!([x, x], [x, y], arrow=true, color=4)\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot!([x, y], [y, y], color=3);  \n    x = y       # y becomes the new x\n    y = g(x)    # g(x) becomes the new y\n    plot!([x, x], [x, y], color=4)  \nend\nplt\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - rmax) / rmax\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nplt = plot([g x->x], 1, 2, l=2, label=[\"y=g(x)\" \"y=x\"], aspect_ratio=1, \n    xlabel=L\"x\", ylabel=L\"y\", title=\"Divergence\", legend=:bottomright)\n\nx = 1.3; y = g(x);\narrow = false\nfor k = 1:5\n    plot!([x, y], [y, y], arrow=arrow, color=3)  \n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    plot!([x, x], [x, y], arrow=arrow, color=4)\n    if k > 2; arrow = true; end\nend\nplt\n\nThis time, the iteration is pushing us away from the correct answer.\n\nExample 4.2.3\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\np = Polynomial([3.5, -4, 1])\nr = roots(p)\nrmin, rmax = extrema(r)\n@show rmin, rmax;\n\nHere is the fixed-point iteration. This time we keep track of the whole sequence of approximations.\n\ng(x) = x - p(x)\nx = [2.1]\nfor k = 1:12\n    push!(x, g(x[k]))\nend\nx\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = @. abs(x - rmax)\nplot(0:12, err;\n    m=:o,\n    xaxis=(\"iteration number\"),  yaxis=(\"error\", :log10),\n    title=\"Convergence of fixed-point iteration\")\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log.(err[5:12])\np = Polynomials.fit(5:12, y, 1)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nσ = exp(p.coeffs[2])\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\n[err[i+1] / err[i] for i in 8:11]\n\nThe methods for finding σ agree well.","type":"content","url":"/chapter4#id-4-2","position":9},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.3 Newton’s method","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-3","position":10},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.3 Newton’s method","lvl2":"Examples"},"content":"Example 4.3.1\n\nSuppose we want to find a root of the function\n\nf(x) = x * exp(x) - 2\nusing Plots\nplot(f, 0, 1.5; \n    label=\"function\",  legend=:topleft,\n    grid=:y,  ylim=[-2, 4],  xlabel=L\"x\",  ylabel=L\"y\")\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx₁ = 1\ny₁ = f(x₁)\nscatter!([x₁], [y₁], label=\"initial point\")\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx(x) = exp(x) * (x + 1)\nm₁ = df_dx(x₁)\ntangent = x -> y₁ + m₁ * (x - x₁)\n\nplot!(tangent, 0, 1.5, l=:dash, label=\"tangent line\",\n    title=\"Tangent line approximation\")\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\n@show x₂ = x₁ - y₁ / m₁\nscatter!([x₂], [0], label=\"tangent root\", title=\"First iteration\")\n\ny₂ = f(x₂)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nplot(f, 0.82, 0.87;\n    label=\"function\",  legend=:topleft,\n    xlabel=L\"x\",  ylabel=L\"y\",\n    title=\"Second iteration\")\n\nscatter!([x₂], [y₂], label=\"starting point\")\n\nm₂ = df_dx(x₂)\ntangent = x -> y₂ + m₂ * (x - x₂)\nplot!(tangent, 0.82, 0.87; l=:dash, label=\"tangent line\")\n\n@show x₃ = x₂ - y₂ / m₂\nscatter!([x₃], [0], label=\"tangent root\")\n\ny₃ = f(x₃)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nExample 4.3.2\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf(x) = x * exp(x) - 2;\ndf_dx(x) = exp(x) * (x + 1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nusing NLsolve\nr = nlsolve(x -> f(x[1]), [1.0]).zero\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = [1; zeros(4)]\nfor k = 1:4\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nx\n\nHere is the sequence of errors.\n\nϵ = @. x - r\n\nBecause the error reaches machine epsilon so rapidly, we’re going to use extended precision to allow us to take a few more iterations. We’ll take the last iteration as the most accurate root estimate.\n\nTip\n\nA BigFloat uses 256 bits of precision, rather than 53 in Float64. But arithmetic is done by software emulation and is much slower.\n\nx = [BigFloat(1); zeros(7)]\nfor k = 1:7\n    x[k+1] = x[k] - f(x[k]) / df_dx(x[k])\nend\nr = x[end]\n\nϵ = @. Float64(x[1:end-1] - r)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = @. log10(abs(ϵ))\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"error\", \"log error\", \"ratio\"] [1:7 ϵ logerr ratios]\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nExample 4.3.3\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nTip\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\ng(x) = exp(x) - x\ndg_dx(x) = exp(x) - 1\ny = range(g(0), g(2), 200)\nx = zeros(length(y))\nfor (i, y) in enumerate(y)\n    f(x) = g(x) - y\n    df_dx(x) = dg_dx(x)\n    r = FNC.newton(f, df_dx, y)\n    x[i] = r[end]\nend\n\nplot(g, 0, 2, aspect_ratio=1, label=L\"g(x)\")\nplot!(y, x, label=L\"g^{-1}(y)\", title=\"Function and its inverse\")\nplot!(x -> x, 0, maximum(y), label=\"\", l=(:dash, 1), color=:black)","type":"content","url":"/chapter4#id-4-3","position":11},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.4 Interpolation-based methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-4","position":12},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.4 Interpolation-based methods","lvl2":"Examples"},"content":"Example 4.4.1\n\nWe return to finding a root of the equation x e^x=2.\n\nusing Plots\nf(x) = x * exp(x) - 2;\nplot(f, 0.25, 1.25;\n    label=\"function\",  legend=:topleft,\n    xlabel=L\"x\",  ylabel=L\"y\")\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx₁ = 1;\ny₁ = f(x₁);\nx₂ = 0.5;\ny₂ = f(x₂);\nscatter!([x₁, x₂], [y₁, y₂];\n    label=\"initial points\",\n    title=\"Two initial values\")\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nm₂ = (y₂ - y₁) / (x₂ - x₁)\nsecant = x -> y₂ + m₂ * (x - x₂)\nplot!(secant, 0.25, 1.25, label=\"secant line\", l=:dash, color=:black,\n    title=\"Secant line\")\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx₃ = x₂ - y₂ / m₂\n@show y₃ = f(x₃)\nscatter!([x₃], [0], label=\"root of secant\", title=\"First iteration\")\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nm₃ = (y₃ - y₂) / (x₃ - x₂)\nx₄ = x₃ - y₃ / m₃\n\nExample 4.4.2\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1. Again we will use extended precision to get a longer sequence than double precision allows.\n\nf(x) = x * exp(x) - 2\nx = FNC.secant(f, BigFloat(1), BigFloat(0.5), xtol=1e-80, ftol=1e-80);\n\nWe don’t know the exact root, so we use the last value as a proxy.\n\nr = x[end]\n\nHere is the sequence of errors.\n\nϵ = @. Float64(r - x[1:end-2])\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = @. log10(abs(ϵ))\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"error\", \"log error\", \"ratio\"] [eachindex(ϵ) ϵ logerr ratios]\n\nAs expected, this settles in at around 1.618.\n\nExample 4.4.3\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf(x) = x + cos(10 * x)\ninterval = [0.5, 1.5]\n\nplot(f, interval..., label=\"Function\", legend=:bottomright,\n    grid=:y, ylim=[-0.1, 3], xlabel=L\"x\", ylabel=L\"y\")\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]\ny = @. f(x)\nscatter!(x, y, label=\"initial points\")\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nusing Polynomials\nq = Polynomials.fit(x, y, 2)      # interpolating polynomial\nplot!(x -> q(x), interval..., l=:dash, label=\"interpolant\")\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nTip\n\nBy giving two functions in the plot call, we get the parametric plot (q(y),y) as a function of y.\n\nplot(f, interval..., label=\"Function\",\n    legend=:bottomright, grid=:y, xlabel=L\"x\", ylabel=L\"y\")\nscatter!(x, y, label=\"initial points\")\n\nq = Polynomials.fit(y, x, 2)       # interpolating polynomial\nplot!(y -> q(y), y -> y, -0.1, 2.6, l=:dash, label=\"inverse interpolant\")\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nq(0)\n\nLet’s restart the process with BigFloat numbers to get a convergent sequence.\n\nx = BigFloat.([8, 12, 10]) / 10\ny = @. f(x)\n\nfor k = 3:12\n    q = Polynomials.fit(y[k-2:k], x[k-2:k], 2)\n    push!(x, q(0))\n    push!(y, f(x[k+1]))\nend\n\nprintln(\"residual = $(f(x[end]))\")\n\nAs far as our current precision is concerned, we have an exact root.\n\nr = x[end]\nϵ = @. Float64(abs(r - x[1:end-1]))\nlogerr = @. log10(abs(ϵ))\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"error\", \"log error\", \"ratio\"] [eachindex(ϵ) ϵ logerr ratios]\n\nThe convergence is probably superlinear at a rate of \\alpha=1.8 or so.","type":"content","url":"/chapter4#id-4-4","position":13},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.5 Newton for nonlinear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-5","position":14},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.5 Newton for nonlinear systems","lvl2":"Examples"},"content":"Example 4.5.3\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nTip\n\nBe careful when coding a Jacobian all in one statement. Spaces separate columns, so x[3]-1 is not the same as x[3] - 1.\n\nfunction func(x)\n    [exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\nend;\n\nfunction jac(x)\n    [\n        -exp(x[2] - x[1]) exp(x[2] - x[1]) 0\n        x[2] x[1] 1\n        2*x[1] x[3]-1 x[2]\n    ]\nend;\n\nWe will use a BigFloat starting value, and commensurately small stopping tolerances, in order to get a sequence long enough to measure convergence.\n\nx₁ = BigFloat.([0, 0, 0])\nϵ = eps(BigFloat)\nx = FNC.newtonsys(func, jac, x₁, xtol=ϵ, ftol=ϵ);\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x[end]\n@show residual = norm(func(r));\n\nWe take the sequence of norms of errors, applying the log so that we can look at the exponents.\n\nlogerr = [Float64(log(norm(r - x[k]))) for k in 1:length(x)-1]\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"log error\", \"ratio\"] [eachindex(logerr) logerr ratios]\n\nThe ratio is neatly converging toward 2, which is expected for quadratic convergence.","type":"content","url":"/chapter4#id-4-5","position":15},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.6 Quasi-Newton methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-6","position":16},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.6 Quasi-Newton methods","lvl2":"Examples"},"content":"Example 4.6.1\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nf(x) = \n    [\n        exp(x[2] - x[1]) - 2,\n        x[1] * x[2] + x[3],\n        x[2] * x[3] + x[1]^2 - x[2]\n    ]\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx₁ = [0.0, 0.0, 0.0]\nx = FNC.levenberg(f, x₁)\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[end]\nprintln(\"backward error = $(norm(f(r)))\")\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method.\n\nlogerr = [log(norm(r - x[k])) for k in 1:length(x)-1]\nratios = [NaN; [logerr[i+1] / logerr[i] for i in 1:length(logerr)-1]]\n@pt :header=[\"iteration\", \"log error\", \"ratio\"] [eachindex(logerr) logerr ratios]","type":"content","url":"/chapter4#id-4-6","position":17},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.7 Nonlinear least squares","lvl2":"Examples"},"type":"lvl3","url":"/chapter4#id-4-7","position":18},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.7 Nonlinear least squares","lvl2":"Examples"},"content":"Example 4.7.1\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng(x) = [sin(x[1] + x[2]), cos(x[1] - x[2]), exp(x[1] - x[2])]\np = [1, 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nTip\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nusing Printf\nplt = plot(xlabel=\"iteration\", yaxis=(:log10, \"error\"),\n    title=\"Convergence of Gauss–Newton\")\nfor R in [1e-3, 1e-2, 1e-1]\n    # Define the perturbed function.\n    f(x) = g(x) - g(p) + R * normalize([-1, 1, -1])\n    x = FNC.levenberg(f, [0, 0])\n    r = x[end]\n    err = [norm(x - r) for x in x[1:end-1]]\n    normres = norm(f(r))\n    plot!(err, label=@sprintf(\"R=%.2g\", normres))\nend\nplt\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nExample 4.7.2\n\nm = 25;\ns = range(0.05, 6, length=m)\nŵ = @. 2 * s / (0.5 + s)                      # exactly on the curve\nw = @. ŵ + 0.15 * cos(2 * exp(s / 16) * s);     # smooth noise added\n\nscatter(s, w, label=\"noisy data\",\n    xlabel=\"s\", ylabel=\"v\", leg=:bottomright)\nplot!(s, ŵ, l=:dash, color=:black, label=\"perfect data\")\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nTip\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\nfunction misfit(x)\n    V, Km = x   # rename components for clarity\n    return @. V * s / (Km + s) - w\nend\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction misfitjac(x)\n    V, Km = x   # rename components for clarity\n    J = zeros(m, 2)\n    J[:, 1] = @. s / (Km + s)              # dw/dV\n    J[:, 2] = @. -V * s / (Km + s)^2         # dw/d_Km\n    return J\nend\n\nx₁ = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x₁)\n\n@show V, Km = x[end]  # final values\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\nmodel(s) = V * s / (Km + s)\nplot!(model, 0, 6, label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nA = [s .^ (-1) s .^ 0]\nu = 1 ./ w\nα, β = A \\ u\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel(x) = 1 / (β + α / x)\nplot!(linmodel, 0, 6, label=\"linearized fit\")\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/chapter4#id-4-7","position":19},{"hierarchy":{"lvl1":"Chapter 5"},"type":"lvl1","url":"/chapter5","position":0},{"hierarchy":{"lvl1":"Chapter 5"},"content":"","type":"content","url":"/chapter5","position":1},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"type":"lvl2","url":"/chapter5#functions","position":2},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"content":"Hat function\n\n\"\"\"\n    hatfun(t, k)\n\nCreate a piecewise linear hat function, where `t` is a\nvector of n+1 interpolation nodes and `k` is an integer in 0:n\ngiving the index of the node where the hat function equals one.\n\"\"\"\nfunction hatfun(t, k)\n    n = length(t) - 1\n    return function (x)\n        if k > 0 && t[k] ≤ x ≤ t[k+1]\n            return (x - t[k]) / (t[k+1] - t[k])\n        elseif k < n && t[k+1] ≤ x ≤ t[k+2]\n            return (t[k+2] - x) / (t[k+2] - t[k+1])\n        else\n            return 0\n        end\n    end\nend\n\nPiecewise linear interpolation\n\n\"\"\"\n    plinterp(t, y)\n\nConstruct a piecewise linear interpolating function for data values in\n`y` given at nodes in `t`.\n\"\"\"\nfunction plinterp(t, y)\n    n = length(t) - 1\n    H = [hatfun(t, k) for k in 0:n]\n    return x -> sum(y[k+1] * H[k+1](x) for k in 0:n)\nend\n\nCubic spline interpolation\n\n\"\"\"\n    spinterp(t, y)\n\nConstruct a cubic not-a-knot spline interpolating function for data\nvalues in `y` given at nodes in `t`.\n\"\"\"\nfunction spinterp(t, y)\n    n = length(t) - 1\n    h = [t[k+1] - t[k] for k in 1:n]\n\n    # Preliminary definitions.\n    Z = zeros(n, n)\n    In = I(n)\n    E = In[1:n-1, :]\n    J = diagm(0 => ones(n), 1 => -ones(n - 1))\n    H = diagm(0 => h)\n\n    # Left endpoint interpolation:\n    AL = [In Z Z Z]\n    vL = y[1:n]\n\n    # Right endpoint interpolation:\n    AR = [In H H^2 H^3]\n    vR = y[2:n+1]\n\n    # Continuity of first derivative:\n    A1 = E * [Z J 2 * H 3 * H^2]\n    v1 = zeros(n - 1)\n\n    # Continuity of second derivative:\n    A2 = E * [Z Z J 3 * H]\n    v2 = zeros(n - 1)\n\n    # Not-a-knot conditions:\n    nakL = [zeros(1, 3 * n) [1 -1 zeros(1, n - 2)]]\n    nakR = [zeros(1, 3 * n) [zeros(1, n - 2) 1 -1]]\n\n    # Assemble and solve the full system.\n    A = [AL; AR; A1; A2; nakL; nakR]\n    v = [vL; vR; v1; v2; 0; 0]\n    z = A \\ v\n\n    # Break the coefficients into separate vectors.\n    rows = 1:n\n    a = z[rows]\n    b = z[n.+rows]\n    c = z[2*n.+rows]\n    d = z[3*n.+rows]\n    S = [Polynomial([a[k], b[k], c[k], d[k]]) for k in 1:n]\n\n    # This function evaluates the spline when called with a value\n    # for x.\n    return function (x)\n        if x < t[1] || x > t[n+1]    # outside the interval\n            return NaN\n        elseif x == t[1]\n            return y[1]\n        else\n            k = findlast(x .> t)    # last node to the left of x\n            return S[k](x - t[k])\n        end\n    end\nend\n\nFornberg’s algorithm for finite difference weights\n\n\"\"\"\n    fdweights(t, m)\n\nCompute weights for the `m`th derivative of a function at zero using\nvalues at the nodes in vector `t`.\n\"\"\"\nfunction fdweights(t, m)\n    # This is a compact implementation, not an efficient one.\n    # Recursion for one weight.\n    function weight(t, m, r, k)\n        # Inputs\n        #   t: vector of nodes\n        #   m: order of derivative sought\n        #   r: number of nodes to use from t\n        #   k: index of node whose weight is found\n\n        if (m < 0) || (m > r)        # undefined coeffs must be zero\n            c = 0\n        elseif (m == 0) && (r == 0)  # base case of one-point interpolation\n            c = 1\n        else                     # generic recursion\n            if k < r\n                c =\n                    (t[r+1] * weight(t, m, r-1, k) - m * weight(t, m-1, r-1, k)) /\n                    (t[r+1] - t[k+1])\n            else\n                numer = r > 1 ? prod(t[r] - x for x in t[1:r-1]) : 1\n                denom = r > 0 ? prod(t[r+1] - x for x in t[1:r]) : 1\n                β = numer / denom\n                c =\n                    β *\n                    (m * weight(t, m - 1, r-1, r-1) - t[r] * weight(t, m, r-1, r-1))\n            end\n        end\n        return c\n    end\n    r = length(t) - 1\n    w = zeros(size(t))\n    return [weight(t, m, r, k) for k in 0:r]\nend\n\nTrapezoid formula for numerical integration\n\n\"\"\"\n    trapezoid(f, a, b, n)\n\nApply the trapezoid integration formula for integrand `f` over\ninterval [`a`,`b`], broken up into `n` equal pieces. Returns\nthe estimate, a vector of nodes, and a vector of integrand values at the\nnodes.\n\"\"\"\nfunction trapezoid(f, a, b, n)\n    h = (b - a) / n\n    t = range(a, b, length = n + 1)\n    y = f.(t)\n    T = h * (sum(y[2:n]) + 0.5 * (y[1] + y[n+1]))\n    return T, t, y\nend\n\nAdaptive integration\n\n\"\"\"\n    intadapt(f, a, b, tol)\n\nAdaptively integrate `f` over [`a`,`b`] to within target error\ntolerance `tol`. Returns the estimate and a vector of evaluation\nnodes.\n\"\"\"\nfunction intadapt(f, a, b, tol, fa = f(a), fb = f(b), m = (a + b) / 2, fm = f(m))\n    # Use error estimation and recursive bisection.\n    # These are the two new nodes and their f-values.\n    xl = (a + m) / 2\n    fl = f(xl)\n    xr = (m + b) / 2\n    fr = f(xr)\n\n    # Compute the trapezoid values iteratively.\n    h = (b - a)\n    T = [0.0, 0.0, 0.0]\n    T[1] = h * (fa + fb) / 2\n    T[2] = T[1] / 2 + (h / 2) * fm\n    T[3] = T[2] / 2 + (h / 4) * (fl + fr)\n\n    S = (4T[2:3] - T[1:2]) / 3      # Simpson values\n    E = (S[2] - S[1]) / 15           # error estimate\n\n    if abs(E) < tol * (1 + abs(S[2]))  # acceptable error?\n        Q = S[2]                   # yes--done\n        nodes = [a, xl, m, xr, b]      # all nodes at this level\n    else\n        # Error is too large--bisect and recurse.\n        QL, tL = intadapt(f, a, m, tol, fa, fm, xl, fl)\n        QR, tR = intadapt(f, m, b, tol, fm, fb, xr, fr)\n        Q = QL + QR\n        nodes = [tL; tR[2:end]]   # merge the nodes w/o duplicate\n    end\n    return Q, nodes\nend\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.","type":"content","url":"/chapter5#functions","position":3},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"type":"lvl2","url":"/chapter5#examples","position":4},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter5#examples","position":5},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.1 The interpolation problem","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-1","position":6},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.1 The interpolation problem","lvl2":"Examples"},"content":"Example 5.1.1\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nusing Plots\nn = 5\nt = range(-1, 1, n+1)\ny = @. t^2 + t + 0.05 * sin(20t)\nscatter(t, y, label=\"data\", legend=:top)\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\nusing Polynomials\np = Polynomials.fit(t, y, n)     # interpolating polynomial\nplot!(p, -1, 1, label=\"interpolant\")\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = range(-1, 1, n+1)\ny = @. t^2 + t + 0.05 * sin(20t)\nscatter(t, y, label=\"data\", leg=:top)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = Polynomials.fit(t, y, n)\nx = range(-1, 1, 1000)    # use a lot of points\nplot!(x, p.(x), label=\"interpolant\")\n\nSurely there must be functions that are more intuitively representative of those points!\n\nExample 5.1.3\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 12\nt = range(-1, 1, n+1)\ny = @. t^2 + t + 0.5 * sin(20t)\nscatter(t, y, label=\"data\", leg=:top)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\np = FNC.plinterp(t, y)\nplot!(p, -1, 1, label=\"piecewise linear\")\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\nusing Dierckx\np = Spline1D(t, y)\nplot!(x -> p(x), -1, 1, label=\"piecewise cubic\")\n\nExample 5.1.4\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18\nt = range(-1, 1, n+1)\ny = [zeros(9); 1; zeros(n - 9)];  # data for 10th cardinal function\n\nscatter(t, y, label=\"data\")\n\nϕ = Spline1D(t, y)\nplot!(x -> ϕ(x), -1, 1;\n    label=\"spline\",\n    xlabel=L\"x\",  ylabel=L\"\\phi(x)\",\n    title=\"Piecewise cubic cardinal function\")\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nscatter(t, y, label=\"data\")\n\nϕ = Polynomials.fit(t, y, n)\nplot!(x -> ϕ(x), -1, 1;\n    label=\"polynomial\",  legend=:top,\n    xlabel=L\"x\",  ylabel=L\"\\phi(x)\", \n    title=\"Polynomial cardinal function\")\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/chapter5#id-5-1","position":7},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.2 Piecewise linear interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-2","position":8},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.2 Piecewise linear interpolation","lvl2":"Examples"},"content":"Example 5.2.1\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1]\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nTip\n\nUse annotate! to add text to a plot.\n\nusing Plots\nplt = plot(layout=(4, 1),  legend=:top,\n    xlabel=L\"x\",  ylims=[-0.1, 1.1],  ytick=[])\nfor k in 0:3\n    Hₖ = FNC.hatfun(t, k)\n    plot!(Hₖ, 0, 1, subplot=k + 1)\n    scatter!(t, Hₖ.(t), m=3, subplot=k + 1)\n    annotate!(t[k+1], 0.25, text(latexstring(\"H_$k\"), 10), subplot=k+1)\nend\nplt\n\nExample 5.2.2\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = x -> exp(sin(7x))\n\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]    # nodes\ny = f.(t)                             # function values\nscatter!(t, y, label=\"values at nodes\")\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"PL interpolation\")\n\nExample 5.2.3\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = x -> exp(sin(7x))\nx = range(0, 1, 10001)  # sample the difference at many points\nn = @. round(Int, 10^(1:0.25:3.5))\nmaxerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    t = (0:n) / n    # interpolation nodes\n    p = FNC.plinterp(t, f.(t))\n    err = @. f(x) - p(x)\n    maxerr[k] = norm(err, Inf)\nend\n\ndata = (n=n[1:4:end], err=maxerr[1:4:end])\n@pt :header=[\"n\", \"max-norm error\"] data\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nh = @. 1 / n\norder2 = @. 10 * (h / h[1])^2\n\nplot(h, maxerr, m=:o, label=\"error\", xflip=true)\nplot!(h, order2;\n    l=:dash,  label=L\"O(h^2)\",\n    xaxis=(:log10, L\"h\"),  yaxis=(:log10, L\"|| f-p\\, ||_\\infty\"),\n    title=\"Convergence of PL interpolation\")","type":"content","url":"/chapter5#id-5-2","position":9},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.3 Cubic splines","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-3","position":10},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.3 Cubic splines","lvl2":"Examples"},"content":"Example 5.3.1\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nusing Plots\nf = x -> exp(sin(7x))\nplot(f, 0, 1, label=\"function\", xlabel=L\"x\", ylabel=L\"y\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1]  # nodes\ny = f.(t)                           # values at nodes\nscatter!(t, y, label=\"values at nodes\")\n\nS = FNC.spinterp(t, y)\nplot!(S, 0, 1, label=\"spline\")\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000) / 1e4              # sample the difference at many points\nn = @. round(Int, 2^(3:0.5:7))  # numbers of nodes\nerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    t = (0:n) / n\n    S = FNC.spinterp(t, f.(t))\n    dif = @. f(x) - S(x)\n    err[k] = norm(dif, Inf)\nend\n@pt :header=[\"n\", \"max-norm error\"] [n[1:2:end] err[1:2:end]]\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = @. (n / n[1])^(-4)\n\nplot(n, [err order4];\n    m=[:o :none], l=[:solid :dash],\n    label=[\"error\" \"4th order\"],\n    xaxis=(:log10, \"n\"),  yaxis=(:log10, L\"|| f-S\\,||_\\infty\"),\n    title=\"Convergence of spline interpolation\")","type":"content","url":"/chapter5#id-5-3","position":11},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.4 Finite differences","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-4","position":12},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.4 Finite differences","lvl2":"Examples"},"content":"Example 5.4.3\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = x -> exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / 2h\nCD4 = (f(-2h) - 8f(-h) + 8f(h) - f(2h)) / 12h\n@show (CD2, CD4);\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3f(0) + 4f(h) - f(2h)) / 2h\n@show (FD1, FD2);\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2h) - 4f(-h) + 3f(0)) / 2h\n@show (BD1, BD2);\n\nExample 5.4.4\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = x -> exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2f(0) + f(h)) / h^2\n@show CD2;\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2f(h) + f(2h)) / h^2\nFD2 = (2f(0) - 5f(h) + 4f(2h) - f(3h)) / h^2\n@show (FD1, FD2);\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2h) - 2f(-h) + f(0)) / h^2\nBD2 = (-f(-3h) + 4f(-2h) - 5f(-h) + 2f(0)) / h^2\n@show (BD1, BD2);\n\nExample 5.4.5\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75]   # nodes\nf = x -> cos(x^2)\ndf_dx = x -> -2 * x * sin(x^2)\nexact_value = df_dx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t .- 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f.(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nFNC.fdweights(0:3, 1)\n\nBy giving nodes of type Rational, we can get exact values instead.\n\nFNC.fdweights(Rational.(0:3), 1)","type":"content","url":"/chapter5#id-5-4","position":13},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.5 Convergence of finite differences","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-5","position":14},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.5 Convergence of finite differences","lvl2":"Examples"},"content":"Example 5.5.3\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = x -> sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = [5 / 10^n for n in 1:6]\nFD = zeros(length(h), 2)\nfor (k, h) in enumerate(h)\n    FD[k, 1] = (f(h) - f(0)) / h\n    FD[k, 2] = (f(h) - f(-h)) / 2h\nend\n@pt :header=[\"h\", \"FD1\", \"FD2\"] [h FD]\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerror_FD = @. exact_value - FD\n@pt :header=[\"h\", \"error in FD1\", \"error in FD2\"] [h error_FD]\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nusing Plots\nplot(h, abs.(error_FD); \n    m=:o,  label=[\"FD1\" \"FD2\"], leg=:bottomleft,\n    xflip=true,  xaxis=(:log10, L\"h\"),  yaxis=(:log10, \"error\"),\n    title=\"Convergence of finite differences\")\n\n# Add lines for perfect 1st and 2nd order.\nplot!(h, [h h .^ 2], l=:dash, label=[L\"O(h)\" L\"O(h^2)\"])\n\nExample 5.5.4\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = x -> exp(-1.3 * x);\nexact = -1.3\n\nh = [1 / 10^n for n in 1:12]\nFD = zeros(length(h), 3)\nfor (k, h) in enumerate(h)\n    nodes = h * (-2:2)\n    vals = @. f(nodes)\n    FD[k, 1] = dot([0 0 -1 1 0] / h, vals)\n    FD[k, 2] = dot([0 -1 / 2 0 1 / 2 0] / h, vals)\n    FD[k, 3] = dot([1 / 12 -2 / 3 0 2 / 3 -1 / 12] / h, vals)\nend\n@pt :header=[\"h\", \"FD1\", \"FD2\", \"FD4\"] [h FD]\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = @. abs(FD - exact)\n\nplot(h, err;\n    m=:o, label=[\"FD1\" \"FD2\" \"FD4\"],  legend=:bottomright,\n    xaxis=(:log10, L\"h\"),  xflip=true,  yaxis=(:log10, \"error\"),\n    title=\"FD error with roundoff\")\n\n# Add line for perfect 1st order.\nplot!(h, 0.1 * eps() ./ h, l=:dash, color=:black, label=L\"O(h^{-1})\")\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/chapter5#id-5-5","position":15},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.6 Numerical integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-6","position":16},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.6 Numerical integration","lvl2":"Examples"},"content":"Example 5.6.1\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe Julia package QuadGK has an all-purpose numerical integrator that estimates the value without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nusing QuadGK\nQ, errest = quadgk(x -> exp(x), 0, 1)\n@show Q;\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quadgk(x -> exp(sin(x)), 0, 1)\n@show Q;\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nusing Plots\nplot([exp, x -> exp(sin(x))], 0, 1, fill=0, layout=(2, 1),\n    xlabel=L\"x\", ylabel=[L\"e^x\" L\"e^{\\sin(x)}\"], ylim=[0, 2.7])\n\nExample 5.6.2\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = x -> exp(sin(7 * x));\na = 0;\nb = 2;\n\nIn lieu of the exact value, we use the QuadGK package to find an accurate result.\n\nTip\n\nIf a function has multiple return values, you can use an underscore _ to indicate a  return value you want to ignore.\n\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14);\nprintln(\"Integral = $Q\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\n@show (T, Q - T);\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = [10^n for n in 1:5]\nerr = zeros(length(n))\nfor (k, n) in enumerate(n)\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    err[k] = Q - T\nend\n@pt :header=[\"n\", \"error\"] [n err]\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nplot(n, abs.(err);\n    m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"),  yaxis=(:log10, \"error\"),\n    title=\"Convergence of trapezoidal integration\")\n\n# Add line for perfect 2nd order.\nplot!(n, 3e-3 * (n / n[1]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\n\nExample 5.6.3\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = x -> x^2 * exp(-2x);\na = 0;\nb = 2;\nQ, _ = quadgk(f, a, b, atol=1e-14, rtol=1e-14)\n@show Q;\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       # the coarsest formula\nn = N;\nh = (b - a) / n;\nt = h * (0:n);\ny = f.(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = [h * (sum(y[2:n]) + y[1] / 2 + y[n+1] / 2)]\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nWe can repeat the same code to double n again.\n\nn = 2n;\nh = h / 2;\nt = h * (0:n);\nT = [T; T[end] / 2 + h * sum(f.(t[2:2:n]))]\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = [(4T[i+1] - T[i]) / 3 for i in 1:2]\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16S[2] - S[1]) / 15\n\nWe can make a triangular table of the errors:\n\nTip\n\nThe value nothing equals nothing except nothing.\n\nerr = [T .- Q [nothing; S .- Q] [nothing; nothing; R - Q]]\n@pt :header=[\"order 2\", \"order 4\", \"order 6\"] err\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/chapter5#id-5-6","position":17},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.7 Adaptive integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter5#id-5-7","position":18},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.7 Adaptive integration","lvl2":"Examples"},"content":"Example 5.7.1\n\nThis function gets increasingly oscillatory as x increases.\n\nusing Plots\nf = x -> (x + 1)^2 * cos((2x + 1) / (x - 4.3))\nplot(f, 0, 4, xlabel=L\"x\", ylabel=L\"f(x)\")\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nusing QuadGK\nleft_val, _ = quadgk(f, 0, 2, atol=1e-14, rtol=1e-14)\nright_val, _ = quadgk(f, 2, 4, atol=1e-14, rtol=1e-14)\n\nn = [50 * 2^k for k in 0:3]\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n    T, _ = FNC.trapezoid(f, 0, 2, n)\n    err[k, 1] = T - left_val\n\n    T, _ = FNC.trapezoid(f, 2, 4, n)\n    err[k, 2] = T - right_val\nend\n\n@pt :header=[\"n\", \"left error\", \"right error\"] [n err]\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nExample 5.7.2\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = x -> (x + 1)^2 * cos((2x + 1) / (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nA, t = FNC.intadapt(f, 0, 4, 0.001)\n@show num_nodes = length(t);\n\nplot(f, 0, 4;\n    color=:black, legend=:none,\n    xlabel=L\"x\",  ylabel=L\"f(x)\", \n    title=\"Adaptive node selection\")\nplot!(t, f.(t), seriestype=:sticks, m=(:o, 2))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nQ, _ = quadgk(f, 0, 4, atol=1e-14, rtol=1e-14);    # 'exact' value\nprintln(\"error: $(Q-A)\");\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = [1 / 10^k for k in 4:14]\nerr, n = [], []\nfor tol in 10.0 .^ (-4:-1:-14)\n    A, t = FNC.intadapt(f, 0, 4, tol)\n    push!(err, Q - A)\n    push!(n, length(t))\nend\n@pt :header=[\"tolerance\", \"error\", \"number of nodes\"] [tol err n][1:2:end, :]\n\nAs you can see, even though the errors are not smaller than the tolerances, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nplot(n, abs.(err);\n    m=:o, label=\"results\",\n    xaxis=(:log10, \"number of nodes\"),  yaxis=(:log10, \"error\"),\n    title=\"Convergence of adaptive integration\")\n\norder4 = @. 0.01 * (n / n[1])^(-4)\nplot!(n, order4, l=:dash, label=L\"O(n^{-4})\")","type":"content","url":"/chapter5#id-5-7","position":19},{"hierarchy":{"lvl1":"Chapter 6"},"type":"lvl1","url":"/chapter6","position":0},{"hierarchy":{"lvl1":"Chapter 6"},"content":"","type":"content","url":"/chapter6","position":1},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"type":"lvl2","url":"/chapter6#functions","position":2},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"content":"Euler’s method for an initial-value problem\n\n\"\"\"\n    euler(ivp, n)\n\nApply Euler's method to solve the given IVP using `n` time steps.\nReturns a vector of times and a vector of solution values.\n\"\"\"\nfunction euler(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initial condition and output setup.\n    u = fill(float(ivp.u0), n+1)\n\n    # The time stepping iteration.\n    for i in 1:n\n        u[i+1] = u[i] + h * ivp.f(u[i], ivp.p, t[i])\n    end\n    return t, u\nend\n\nAbout the code\n\nThe ivp input argument is an ODEProblem, like in \n\nDemo 6.1.2. It has fields ivp.f, ivp.tspan, ivp.u0, and ivp.p that fully define the problem. The outputs are vectors of the nodes and approximate solution values at those nodes.\n\nImproved Euler method for an IVP\n\n\"\"\"\n    ie2(ivp, n)\n\nApply the Improved Euler method to solve the given IVP using `n`\ntime steps. Returns a vector of times and a vector of solution\nvalues.\n\"\"\"\nfunction ie2(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initialize output.\n    u = fill(float(ivp.u0), n+1)\n\n    # Time stepping.\n    for i in 1:n\n        uhalf = u[i] + h / 2 * ivp.f(u[i], ivp.p, t[i])\n        u[i+1] = u[i] + h * ivp.f(uhalf, ivp.p, t[i] + h / 2)\n    end\n    return t, u\nend\n\nFourth-order Runge-Kutta for an IVP\n\n\"\"\"\n    rk4(ivp, n)\n\nApply the common Runge-Kutta 4th order method to solve the given\nIVP using `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk4(ivp, n)\n\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initialize output.\n    u = fill(float(ivp.u0), n+1)\n\n    # Time stepping.\n    for i in 1:n\n        k₁ = h * ivp.f(u[i], ivp.p, t[i])\n        k₂ = h * ivp.f(u[i] + k₁ / 2, ivp.p, t[i] + h / 2)\n        k₃ = h * ivp.f(u[i] + k₂ / 2, ivp.p, t[i] + h / 2)\n        k₄ = h * ivp.f(u[i] + k₃, ivp.p, t[i] + h)\n        u[i+1] = u[i] + (k₁ + 2(k₂ + k₃) + k₄) / 6\n    end\n    return t, u\nend\n\nAdaptive IVP solver based on embedded RK formulas\n\n\"\"\"\n    rk23(ivp, tol)\n\nApply an adaptive embedded RK formula pair to solve given IVP with\nestimated error `tol`. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction rk23(ivp, tol)\n    # Initialize for the first time step.\n    a, b = ivp.tspan\n    t = [a]\n    u = [float(ivp.u0)]\n    i = 1\n    h = 0.5 * tol^(1 / 3)\n    s₁ = ivp.f(ivp.u0, ivp.p, a)\n\n    # Time stepping.\n    while t[i] < b\n        # Detect underflow of the step size.\n        if t[i] + h == t[i]\n            @warn \"Stepsize too small near t=$(t[i])\"\n            break  # quit time stepping loop\n        end\n\n        # New RK stages.\n        s₂ = ivp.f(u[i] + (h / 2) * s₁, ivp.p, t[i] + h / 2)\n        s₃ = ivp.f(u[i] + (3h / 4) * s₂, ivp.p, t[i] + 3h / 4)\n        u_new3 = u[i] + h * (2s₁ + 3s₂ + 4s₃) / 9   # 3rd order solution\n        s₄ = ivp.f(u_new3, ivp.p, t[i] + h)\n        err = h * (-5s₁ / 72 + s₂ / 12 + s₃ / 9 - s₄ / 8)  # 2nd/3rd difference\n        E = norm(err, Inf)                         # error estimate\n        maxerr = tol * (1 + norm(u[i], Inf))     # relative/absolute blend\n\n        # Accept the proposed step?\n        if E < maxerr     # yes\n            push!(t, t[i] + h)\n            push!(u, u_new3)\n            i += 1\n            s₁ = s₄       # use FSAL property\n        end\n\n        # Adjust step size.\n        q = 0.8 * (maxerr / E)^(1 / 3)   # conservative optimal step factor\n        q = min(q, 4)               # limit stepsize growth\n        h = min(q * h, b - t[i])        # don't step past the end\n    end\n    return t, u\nend\n\nAbout the code\n\nThe check t[i]+h == t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\n4th-order Adams–Bashforth formula for an IVP\n\n\"\"\"\n    ab4(ivp, n)\n\nApply the Adams-Bashforth 4th order method to solve the given IVP\nusing `n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction ab4(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Constants in the AB4 method.\n    k = 4\n    σ = [55, -59, 37, -9] / 24\n\n    # Find starting values by RK4.\n    u = fill(float(ivp.u0), n+1)\n    rkivp = ODEProblem(ivp.f, ivp.u0, (a, a + (k - 1) * h), ivp.p)\n    ts, us = rk4(rkivp, k - 1)\n    u[1:k] .= us\n\n    # Compute history of u' values, from newest to oldest.\n    f = [ivp.f(u[k-i], ivp.p, t[k-i]) for i in 1:k-1]\n\n    # Time stepping.\n    for i in k:n\n        f = [ivp.f(u[i], ivp.p, t[i]), f[1:k-1]...]   # new value of du/dt\n        u[i+1] = u[i] + h * sum(f[j] * σ[j] for j in 1:k)  # advance a step\n    end\n    return t, u\nend\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\n\"\"\"\n    am2(ivp, n)\n\nApply the Adams-Moulton 2nd order method to solve given IVP using\n`n` time steps. Returns a vector of times and a vector of\nsolution values.\n\"\"\"\nfunction am2(ivp, n)\n    # Time discretization.\n    a, b = ivp.tspan\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n\n    # Initialize output.\n    u = fill(float(ivp.u0), n+1)\n\n    # Time stepping.\n    for i in 1:n\n        # Data that does not depend on the new value.\n        known = u[i] + h / 2 * ivp.f(u[i], ivp.p, t[i])\n        # Find a root for the new value.\n        g = z -> z - h / 2 * ivp.f(z, ivp.p, t[i+1]) - known\n        u_new = levenberg(g, known)\n        u[i+1] = u_new[end]\n    end\n    return t, u\nend\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/chapter6#functions","position":3},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"type":"lvl2","url":"/chapter6#examples","position":4},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter6#examples","position":5},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.1 Basics of IVPs","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-1","position":6},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.1 Basics of IVPs","lvl2":"Examples"},"content":"Example 6.1.2\n\nThe OrdinaryDiffEq package offers solvers for IVPs. Let’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nBecause many practical problems come with parameters that are fixed within an instance but varied from one instance to another, the syntax for IVPs includes a input argument p that stays fixed throughout the solution. Here we don’t want to use that argument, but it must be in the definition for the solver to work.\n\nTip\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf(u, p, t) = sin((t + u)^2)     # defines du/dt, must include p argument\nu₀ = -1.0                       # initial value\ntspan = (0.0, 4.0)               # t interval\n\nWith the data above we define an IVP problem object and then solve it. Here we tell the solver to use the Tsit5 method, which is a good first choice for most problems.\n\nusing OrdinaryDiffEq\nivp = ODEProblem(f, u₀, tspan)\nsol = solve(ivp, Tsit5());\n\nThe resulting solution object can be shown using plot.\n\nusing Plots\nplot(sol;\n    label=\"solution\", legend=:bottom,\n    xlabel=\"t\",  ylabel=L\"u(t)\",\n    title=L\"u'=\\sin((t+u)^2)\")\n\nThe solution also acts like any callable function that can be evaluated at different values of t.\n\n@show sol(1.0);\n\nUnder the hood, the solution object holds some information about how the values and plot are produced:\n\n[sol.t sol.u]\n\nThe solver initially finds approximate values of the solution (second column above) at some automatically chosen times (first column above). To compute the solution at other times, the object performs an interpolation on those values. This chapter is about how the discrete t and u values are computed. For now, just note how we can extract them from the solution object.\n\nscatter!(sol.t, sol.u, label=\"discrete values\")\n\nExample 6.1.3\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nf(u, p, t) = (t + u)^2\nivp = ODEProblem(f, 1.0, (0.0, 1.0))\nsol = solve(ivp, Tsit5());\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nplot(sol, label=\"\";\n    xlabel=L\"t\",  yaxis=(:log10, L\"u(t)\"),\n    title=\"Finite-time blowup\")\n\nExample 6.1.5\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = range(0, 3, length=800)\nu = @. exp(t) * 1\nlower, upper = @. exp(t) * 0.7, @. exp(t) * 1.3\nplot(t, u;\n    l=:black, ribbon=(lower, upper),\n    leg=:none,  xlabel=L\"t\",  ylabel=L\"u(t)\",\n    title=\"Exponential divergence of solutions\")\n\nBut with u'=-u, solutions actually get closer together with time.\n\nu = @. exp(-t) * 1\nlower, upper = @. exp(-t) * 0.7, @. exp(-t) * 1.3\nplot(t, u;\n    l=:black,  ribbon=(lower, upper),\n    leg=:none,  xlabel=L\"t\",  ylabel=L\"u(t)\",\n    title=\"Exponential convergence of solutions\")\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.","type":"content","url":"/chapter6#id-6-1","position":7},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.2 Euler’s method","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-2","position":8},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.2 Euler’s method","lvl2":"Examples"},"content":"Example 6.2.1\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nusing OrdinaryDiffEq\nf(u, p, t) = sin((t + u)^2);\ntspan = (0.0, 4.0);\nu0 = -1.0;\nivp = ODEProblem(f, u0, tspan)\n\nHere is the call to \n\nFunction 6.2.2.\n\nusing Plots\nt, u = FNC.euler(ivp, 20)\nplot(t, u;\n    m=2,  label=\"n=20\", \n    xlabel=L\"t\",  ylabel=L\"u(t)\",\n    title=\"Solution by Euler's method\")\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(ivp, 50)\nplot!(t, u, m=2, label=\"n=50\")\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a DifferentialEquations solver to construct an accurate reference solution.\n\nu_exact = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14)\nplot!(u_exact, l=(2, :black), label=\"reference\")\n\nNow we can perform a convergence study.\n\nn = [round(Int, 5 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.euler(ivp, n)\n    push!(err, norm(u_exact.(t) - u, Inf))\nend\n@pt :header=[\"n\", \"inf-norm error\"] [n err]\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nplot(n, err;\n    m=:o, label=\"results\",\n    xaxis=(:log10, L\"n\"),  yaxis=(:log10, \"inf-norm global error\"),\n    title=\"Convergence of Euler's method\")\n\n# Add line for perfect 1st order.\nplot!(n, 0.5 * err[end] * (n / n[end]) .^ (-1), l=:dash, label=L\"O(n^{-1})\")","type":"content","url":"/chapter6#id-6-2","position":9},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.3 IVP systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-3","position":10},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.3 IVP systems","lvl2":"Examples"},"content":"Example 6.3.2\n\nWe encode the predator–prey equations via a function.\n\nfunction predprey(u, p, t)\n    α, β = p      # rename parameters for convenience\n    y, z = u      # rename solution components\n    s = (y * z) / (1 + β * y)     # appears in both equations\n    return [y * (1 - α * y) - s, -z + s]\nend;\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable.\n\nusing OrdinaryDiffEq\nu₀ = [1, 0.01]\ntspan = (0.0, 60.0)\nα, β = 0.1, 0.25\nivp = ODEProblem(predprey, u₀, tspan, [α, β])\n\nYou can use any DifferentialEquations solver on the IVP system.\n\nusing Plots\nsol = solve(ivp, Tsit5());\nplot(sol, label=[\"prey\" \"predator\"],\n    title=\"Predator-prey solution\")\n\nWe can find the discrete values used to compute the interpolated solution. The sol.u value is a vector of vectors.\n\nt, u = sol.t, sol.u    # extract times and solution values\n@show size(u);\n@show t[20];\n@show u[20];\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt, u = FNC.euler(ivp, 1200);\n\nThe solution u is a vector of [prey,predator] 2-vectors for each of the discrete times in t. Manipulating the vector-of-vectors output can be a little tricky. Here, we convert it to an n\\times 2 matrix. Each column is one component, while each row is a single value of t.\n\nu = [u[j] for u in u, j in 1:2]\nplot!(t[1:3:end], u[1:3:end, :];\n    l=(1, :black),  m=2,\n    label=[\"Euler prey\" \"Euler predator\"])\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nTip\n\nYou can use idxs in the plot of a solution produced by solve to specify the components of the solution that appear on each axis.\n\nplot(sol, idxs=(1, 2),\n    title=\"Predator-prey in the phase plane\",\n    xlabel=L\"y\",  ylabel=L\"z\")\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nExample 6.3.5\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nTip\n\nThe similar function creates an array of the same size and type as a given value, without initializing the contents.\n\nfunction couple(u, p, t)\n    γ, L, k = p\n    g = 9.8\n    udot = similar(u)\n    udot[1:2] .= u[3:4]\n    udot[3] = -γ * u[3] - (g / L) * sin(u[1]) + k * (u[2] - u[1])\n    udot[4] = -γ * u[4] - (g / L) * sin(u[2]) + k * (u[1] - u[2])\n    return udot\nend\n\nu₀ = [1.25, -0.5, 0, 0]\ntspan = (0.0, 50.0);\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nTip\n\nHere idxs is used to plot two components as functions of time.\n\nγ, L, k = 0, 0.5, 0\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], \n    label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], \n    title=\"Uncoupled pendulums\")\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 1\nivp = ODEProblem(couple, u₀, tspan, [γ, L, k])\nsol = solve(ivp, Tsit5())\nplot(sol, idxs=[1, 2], \n    label=[L\"\\theta_1\" L\"\\theta_2\"],\n    xlims=[20, 50], \n    title=\"Coupled pendulums\")\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/chapter6#id-6-3","position":11},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.4 Runge–Kutta methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-4","position":12},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.4 Runge–Kutta methods","lvl2":"Examples"},"content":"Example 6.4.1\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nusing OrdinaryDiffEq\nf(u, p, t) = sin((t + u)^2)\ntspan = (0.0, 4.0)\nu₀ = -1.0\nivp = ODEProblem(f, u₀, tspan)\n\nWe use a DifferentialEquations solver to construct an accurate approximation to the exact solution.\n\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = [round(Int, 2 * 10^k) for k in 0:0.5:3]\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n    t, u = FNC.ie2(ivp, n)\n    err[k, 1] = norm(u_ref.(t) - u, Inf)\n    t, u = FNC.rk4(ivp, n)\n    err[k, 2] = norm(u_ref.(t) - u, Inf)\nend\n@pt :header=[\"n\", \"IE2 error\", \"RK4 error\"] [n err]\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nusing Plots\nplot([2n 4n], err;\n    m=3, label=[\"IE2\" \"RK4\"], legend=:bottomleft,\n    xaxis=(:log10, \"f-evaluations\"),  yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of RK methods\")\n\nplot!(2n, 0.1 * err[end,1] * (n / n[end]) .^ (-2), l=:dash, label=L\"O(n^{-2})\")\nplot!(4n, 0.1 * err[end,2] * (n / n[end]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/chapter6#id-6-4","position":13},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.5 Adaptive Runge–Kutta","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-5","position":14},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.5 Adaptive Runge–Kutta","lvl2":"Examples"},"content":"Example 6.5.1\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nusing OrdinaryDiffEq, Plots\nf(u, p, t) = exp(t - u * sin(u))\nivp = ODEProblem(f, 0, (0.0, 5.0))\nt, u = FNC.rk23(ivp, 1e-5)\nplot(t, u, m=2,\n    xlabel=L\"t\",  ylabel=L\"u(t)\", \n    title=\"Adaptive IVP solution\")\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nΔt = diff(t)\nplot(t[1:end-1], Δt;\n    xaxis=(L\"t\", (0, 5)), yaxis=(:log10, \"step size\"),\n    title=\"Adaptive step sizes\")\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprintln(\"minimum step size = $(minimum(Δt))\")\n\nOn the other hand, the average step size that was actually taken was\n\nprintln(\"average step size = $(sum(Δt)/(length(t)-1))\")\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nExample 6.5.2\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\nf(u, p, t) = (t + u)^2\nivp = ODEProblem(f, 1, (0.0, 1.0))\nt, u = FNC.rk23(ivp, 1e-5);\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nplot(t, u;\n    legend=:none,\n    xlabel=L\"t\",  yaxis=(:log10, L\"u(t)\"), \n    title=\"Finite-time blowup\")\n\ntf = t[end]\nvline!([tf], l=:dash)\nannotate!(tf, 1e5, latexstring(@sprintf(\"t = %.6f \", tf)), :right)","type":"content","url":"/chapter6#id-6-5","position":15},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.6 Multistep methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-6","position":16},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.6 Multistep methods","lvl2":"Examples"},"content":"Example 6.7.1\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve is called to give an accurate reference solution.\n\nusing OrdinaryDiffEq\nivp = ODEProblem((u, p, t) -> sin((t + u)^2), -1.0, (0.0, 4.0))\nu_ref = solve(ivp, Tsit5(), reltol=1e-14, abstol=1e-14);\n\nNow we perform a convergence study of the AB4 code.\n\nn = @. [round(Int, 4 * 10^k) for k in 0:0.5:3]\nerr = []\nfor n in n\n    t, u = FNC.ab4(ivp, n)\n    push!(err, norm(u_ref.(t) - u, Inf))\nend\n@pt :header=[\"n\", \"inf-norm error\"] [n err]\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nusing Plots\nplot(n, err, m=3, \n    label=\"AB4\",  legend=:bottomleft,\n    xaxis=(:log10, L\"n\"),  yaxis=(:log10, \"inf-norm error\"),\n    title=\"Convergence of AB4\")\n\nplot!(n, 0.1 * err[end] * (n / n[end]) .^ (-4), l=:dash, label=L\"O(n^{-4})\")\n\nExample 6.7.2\n\nThe following simple ODE uncovers a surprise.\n\nivp = ODEProblem((u, p, t) -> u^2 - u^3, 0.005, (0, 400.0))\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(ivp, 200)\n\nplot(tI, uI;\n    label=\"AM2\", legend=:bottomright,\n    xlabel=L\"t\",  ylabel=L\"u(t)\")\n\nNow we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(ivp, 200)\nscatter!(tE, uE, m=3, label=\"AB4\", ylim=[-4, 2])\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[105:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplt = scatter(tI, uI;\n    m=3,  label=\"AM2, n=200\",  legend=:bottomright,\n    xlabel=L\"t\",  ylabel=L\"u(t)\")\n\nfor n in [1000, 1600]\n    tE, uE = FNC.ab4(ivp, n)\n    plot!(tE, uE, label=\"AM4, n=$n\")\nend\nplt\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!","type":"content","url":"/chapter6#id-6-6","position":17},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.7 Implementation of multistep methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6#id-6-7","position":18},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.7 Implementation of multistep methods","lvl2":"Examples"},"content":"Example 6.8.1\n\nWe’ll measure the error at the time t=1.\n\ndu_dt(u, t) = u\nû = exp\na, b = 0.0, 1.0;\nn = [5, 10, 20, 40, 60]\nerr = []\nt, u = [], []\nfor n in n\n    h = (b - a) / n\n    t = [a + i * h for i in 0:n]\n    u = [1; û(h); zeros(n - 1)]\n    f_val = [du_dt(u[1], t[1]); zeros(n)]\n    for i in 2:n\n        f_val[i] = du_dt(u[i], t[i])\n        u[i+1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f_val[i] + 2 * f_val[i-1])\n    end\n    push!(err, abs(û(b) - u[end]))\nend\n@pt :header=[\"n\", \"h\", \"error\"] [n (b - a) ./ n err]\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nusing Plots\nplot(t, abs.(u);\n    m=3,  label=\"\",\n    xlabel=L\"t\",  yaxis=(:log10, L\"|u(t)|\"), \n    title=\"LIAF solution\")\n\nIt’s clear that the solution is growing exponentially in time.","type":"content","url":"/chapter6#id-6-7","position":19},{"hierarchy":{"lvl1":"Chapter 7"},"type":"lvl1","url":"/chapter7","position":0},{"hierarchy":{"lvl1":"Chapter 7"},"content":"","type":"content","url":"/chapter7","position":1},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"type":"lvl2","url":"/chapter7#examples","position":2},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter7#examples","position":3},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.1 From matrix to insight","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#id-7-1","position":4},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.1 From matrix to insight","lvl2":"Examples"},"content":"Example 7.1.4\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nThe graphplot function makes a visual representation of this graph.\n\nusing Plots, GraphRecipes\ngraphplot(A, names=1:4, markersize=0.2, arrow=6)\n\nSince this adjacency matrix is not symmetric, the edges are all directed, as indicated by the arrows. Here are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0]\ngraphplot(A, names=1:4, markersize=0.2)\n\nExample 7.1.5\n\nThe Images package has many functions for image manipulation, and TestImages has some standard images to play with.\n\nusing Images, TestImages\nimg = testimage(\"mandrill\")\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nimg[100, 10]\n\nYou can use eltype to find out the type of the elements of any array.\n\neltype(img)\n\nIt’s possible to extract matrices of red, green, and blue intensities, scaled from 0 to 1.\n\nR, G, B = red.(img), green.(img), blue.(img);\n@show minB, maxB = extrema(B);\n\nOr we can convert the pixels to gray, each pixel again scaled from 0 to 1.\n\nGray.(img)\n\nIn order to do our usual operations, we need to tell Julia that we want to interpret the elements of the image matrix as floating-point values.\n\nA = Float64.(Gray.(img))\nA[1:4, 1:5]\n\nWe can use Gray to reinterpret a matrix of floating-point values as grayscale pixels.\n\nGray.(reverse(A, dims=1))","type":"content","url":"/chapter7#id-7-1","position":5},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.2 Eigenvalue decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#id-7-2","position":6},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.2 Eigenvalue decomposition","lvl2":"Examples"},"content":"Example 7.2.2\n\nThe eigvals function returns a vector of the eigenvalues of a matrix.\n\nA = π * ones(2, 2)\n\nλ = eigvals(A)\n\nIf you want the eigenvectors as well, use eigen.\n\nλ, V = eigen(A)\n\nnorm(A * V[:, 2] - λ[2] * V[:, 2])\n\nBoth functions allow you to sort the eigenvalues by specified criteria.\n\nA = diagm(-2.3:1.7)\n@show eigvals(A, sortby=real);\n@show eigvals(A, sortby=abs);\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1]\nλ, V = eigen(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nopnorm(A * V - V * diagm(λ))\n\nExample 7.2.3\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7\nA = randn(n, n) + 1im * randn(n, n)\nA = (A + A') / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nλ, V = eigen(A)\n@show cond(V);\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones.\n\nTip\n\nSince the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = 1:n\nA = triu(x * ones(n)')\nA[1:5, 1:5]\n\nThis matrix is not especially close to normal.\n\nλ, V = eigen(A)\n@show cond(V);\n\nAs a result, the eigenvalues can change by a good deal more.\n\nΔA = 1e-8 * normalize(randn(n, n) + 1im * randn(n, n))\nλ̃ = eigvals(A + ΔA)\ndist = minimum([abs(x - y) for x in λ̃, y in λ], dims=2)\nBF_bound = cond(V) * norm(ΔA)\n@show maximum(dist), BF_bound;\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nusing Plots\nplt = scatter(λ, zeros(n), aspect_ratio=1)\nfor _ in 1:200\n    ΔA = eps(Float32) * normalize(randn(n, n) + 1im * randn(n, n))\n    λ̃ = eigvals(A + ΔA)\n    scatter!(real(λ̃), imag(λ̃), m=1, color=:black)\nend\nplt\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nExample 7.2.4\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diagm([-6, -1, 2, 4, 5])\nV, R = qr(randn(5, 5))    # V is unitary\nA = V * D * V'\n\neigvals(A)\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\neigvals(A)\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in 1:40\n    Q, R = qr(A)\n    A = R * Q\nend\nA","type":"content","url":"/chapter7#id-7-2","position":7},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.3 Singular value decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#id-7-3","position":8},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.3 Singular value decomposition","lvl2":"Examples"},"content":"Example 7.3.4\n\nWe verify some of the fundamental SVD properties using standard Julia functions from LinearAlgebra.\n\nA = [i^j for i = 1:5, j = 0:3]\n\nTo get only the singular values, use svdvals.\n\nσ = svdvals(A)\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\n@show opnorm(A, 2);\n@show σ[1];\n\n@show cond(A, 2);\n@show σ[1] / σ[end];\n\nTo get singular vectors as well, use svd. The thin form of the factorization is the default.\n\nU, σ, V = svd(A);\n@show size(U);\n@show size(V);\n\nWe verify the orthogonality of the singular vectors as follows:\n\n@show opnorm(U' * U - I);\n@show opnorm(V' * V - I);","type":"content","url":"/chapter7#id-7-3","position":9},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.4 Symmetry and definiteness","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#id-7-4","position":10},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.4 Symmetry and definiteness","lvl2":"Examples"},"content":"Example 7.4.1\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nλ = 1:n\nD = diagm(λ)\nV, _ = qr(randn(n, n))   # get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = x -> (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nR(V[:, 7])\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nδ = @. 1 ./ 10^(1:5)\neval_diff = zeros(size(δ))\nfor (k, delta) in enumerate(δ)\n    e = randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 7] + e\n    eval_diff[k] = R(x) - 7\nend\nlabels = [\"perturbation δ\", \"δ²\", \"R(x) - λ\"]\n@pt :header=labels [δ δ .^ 2 eval_diff]","type":"content","url":"/chapter7#id-7-4","position":11},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.5 Dimension reduction","lvl2":"Examples"},"type":"lvl3","url":"/chapter7#id-7-5","position":12},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.5 Dimension reduction","lvl2":"Examples"},"content":"Example 7.5.1\n\nWe make an image from some text, then reload it as a matrix.\n\nusing Plots, Images\nplot(annotations=(0.5, 0.5, text(\"Hello world\", 44, :center, :center)),\n    grid=:none, frame=:none, size=(400, 150))\nsavefig(\"hello.png\")\nimg = load(\"hello.png\")\nA = @. Float64(Gray(img))\nGray.(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=45.\n\nU, σ, V = svd(A)\nscatter(σ;\n    xaxis=(L\"i\"),  yaxis=(:log10, L\"\\sigma_i\"),\n    title=\"Singular values\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nplt = plot(layout=(2, 2), frame=:none, aspect_ratio=1, titlefontsize=10)\nfor i in 1:4\n    k = 3i\n    Ak = U[:, 1:k] * diagm(σ[1:k]) * V[:, 1:k]'\n    plot!(Gray.(Ak), subplot=i, title=\"rank = $k\")\nend\nplt\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\nm, n = size(A)\ncompression = m * n / (9 * (m + n + 1))\n\nExample 7.5.2\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nusing JLD2\n@load \"voting.jld2\" A;\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nheatmap(A;\n    color=:viridis,  xlabel=\"bill\",  ylabel=\"senator\",\n    title=\"Votes in 111th U.S. Senate\")\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, σ, V = svd(A)\nτ = cumsum(σ .^ 2) / sum(σ .^ 2)\nscatter(τ[1:16];\n    xaxis=(\"k\"),  yaxis=(L\"\\tau_k\"),\n    title=\"Fraction of singular value energy\")\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nscatter(U[:, 1], label=\"\", layout=(1, 2),\n    xlabel=\"senator\",  title=\"left singular vector\")\nscatter!(V[:, 1], label=\"\", subplot=2,\n    xlabel=\"bill\",  title=\"right singular vector\")\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = A * V[:, 1];\nx2 = A * V[:, 2];\n\n@load \"voting.jld2\" Rep Dem Ind\nRep = vec(Rep);\nDem = vec(Dem);\nInd = vec(Ind);\nscatter(x1[Dem], x2[Dem];\n    color=:blue,  label=\"D\",\n    xaxis=(\"partisanship\"),  yaxis=(\"bipartisanship\"), \n    title=\"111th US Senate by voting record\")\nscatter!(x1[Rep], x2[Rep], color=:red, label=\"R\")\nscatter!(x1[Ind], x2[Ind], color=:yellow, label=\"I\")","type":"content","url":"/chapter7#id-7-5","position":13},{"hierarchy":{"lvl1":"Chapter 8"},"type":"lvl1","url":"/chapter8","position":0},{"hierarchy":{"lvl1":"Chapter 8"},"content":"","type":"content","url":"/chapter8","position":1},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"type":"lvl2","url":"/chapter8#functions","position":2},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"content":"Power iteration\n\n\"\"\"\n    poweriter(A, numiter)\n\nPerform `numiter` power iterations with the matrix `A`, starting\nfrom a random vector. Returns a vector of eigenvalue estimates\nand the final eigenvector approximation.\n\"\"\"\nfunction poweriter(A, numiter)\n    n = size(A, 1)\n    x = normalize(randn(n), Inf)\n    β = zeros(numiter)\n    for k in 1:numiter\n        y = A * x\n        m = argmax(abs.(y))\n        β[k] = y[m] / x[m]\n        x = y / y[m]\n    end\n    return β, x\nend\n\nInverse iteration\n\n\"\"\"\n    inviter(A, s, numiter)\n\nPerform `numiter` inverse iterations with the matrix `A` and shift\n`s`, starting from a random vector. Returns a vector of\neigenvalue estimates and the final eigenvector approximation.\n\"\"\"\nfunction inviter(A, s, numiter)\n    n = size(A, 1)\n    x = normalize(randn(n), Inf)\n    β = zeros(numiter)\n    fact = lu(A - s * I)\n    for k in 1:numiter\n        y = fact \\ x\n        normy, m = findmax(abs.(y))\n        β[k] = x[m] / y[m] + s\n        x = y / y[m]\n    end\n    return β, x\nend\n\nArnoldi iteration\n\n\"\"\"\n    arnoldi(A, u, m)\n\nPerform the Arnoldi iteration for `A` starting with vector `u`, out\nto the Krylov subspace of degree `m`. Returns the orthonormal basis\n(`m`+1 columns) and the upper Hessenberg `H` of size `m`+1 by `m`.\n\"\"\"\nfunction arnoldi(A, u, m)\n    n = length(u)\n    Q = zeros(n, m+1)\n    H = zeros(m+1, m)\n    Q[:, 1] = u / norm(u)\n    for j in 1:m\n        # Find the new direction that extends the Krylov subspace.\n        v = A * Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in 1:j\n            H[i, j] = dot(Q[:, i], v)\n            v -= H[i, j] * Q[:, i]\n        end\n        # Normalize and store the new basis vector.\n        H[j+1, j] = norm(v)\n        Q[:, j+1] = v / H[j+1, j]\n    end\n    return Q, H\nend\n\nGMRES\n\n\"\"\"\n    gmres(A, b, m)\n\nDo `m` iterations of GMRES for the linear system `A`*x=`b`. Returns\nthe final solution estimate x and a vector with the history of\nresidual norms. (This function is for demo only, not practical use.)\n\"\"\"\nfunction gmres(A, b, m)\n    n = length(b)\n    Q = zeros(n, m+1)\n    Q[:, 1] = b / norm(b)\n    H = zeros(m+1, m)\n\n    # Initial solution is zero.\n    x = 0\n    residual = [norm(b); zeros(m)]\n\n    for j in 1:m\n        # Next step of Arnoldi iteration.\n        v = A * Q[:, j]\n        for i in 1:j\n            H[i, j] = dot(Q[:, i], v)\n            v -= H[i, j] * Q[:, i]\n        end\n        H[j+1, j] = norm(v)\n        Q[:, j+1] = v / H[j+1, j]\n\n        # Solve the minimum residual problem.\n        r = [norm(b); zeros(j)]\n        z = H[1:j+1, 1:j] \\ r\n        x = Q[:, 1:j] * z\n        residual[j+1] = norm(A * x - b)\n    end\n    return x, residual\nend","type":"content","url":"/chapter8#functions","position":3},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"type":"lvl2","url":"/chapter8#examples","position":4},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter8#examples","position":5},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-1","position":6},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"content":"Example 8.1.1\n\nTip\n\nJulia functions to deal with sparse matrices are found in the SparseArrays package in the standard library.\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nusing SparseArrays, JLD2\n@load \"roswell.jld2\" A;      # file is on the book's website\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nTip\n\nUse nnz to count the number of nonzeros in a sparse matrix.\n\nm, n = size(A)\n@show density = nnz(A) / (m * n);\n\nThe computer memory consumed by any variable can be discovered using summarysize. We can use it to compare the space needed for the sparse representation to its dense counterpart, that is, the space needed to store all the elements, whether zero or not.\n\nF = Matrix(A)\nBase.summarysize(F) / Base.summarysize(A)\n\nAs you can see, the storage savings are dramatic. Matrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nx = randn(n)\nA * x;   # make sure * is loaded and compiled\n@elapsed for i in 1:300\n    A * x\nend\n\nF * x;\n@elapsed for i in 1:300\n    F * x\nend\n\nExample 8.1.2\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nusing GraphRecipes\n@load \"smallworld.jld2\" A\ngraphplot(A, linealpha=0.5)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nspy(A, title=\"Nonzero locations\", m=2, color=:blues)\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nplt = plot(layout=(1, 3), legend=:none, size=(600, 240))\nfor k in 2:4\n    spy!(A^k;\n        subplot=k - 1, color=:blues,\n        title=latexstring(\"\\\\mathbf{A}^$k\"))\nend\nplt\n\nExample 8.1.3\n\nThe spdiagm function creates a sparse matrix given its diagonal elements. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50;\nA = spdiagm(-3 => fill(n, n - 3),\n    0 => ones(n),\n    1 => -(1:n-1),\n    5 => fill(0.1, n - 5))\nMatrix(A[1:7, 1:7])\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nTip\n\nThe sparse function converts any matrix to sparse form. But it’s usually better to construct a sparse matrix directly, as the standard form might not fit in memory.\n\nL, U = FNC.lufact(A)\nplot(layout=2)\nspy!(sparse(L), m=2, subplot=1, title=L\"\\mathbf{L}\", color=:blues)\nspy!(sparse(U), m=2, subplot=2, title=L\"\\mathbf{U}\", color=:blues)\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\nfact = lu(A)\nplot(layout=2)\nspy!(sparse(fact.L), m=2, subplot=1, title=L\"\\mathbf{L}\", color=:blues)\nspy!(sparse(fact.U), m=2, subplot=2, title=L\"\\mathbf{U}\", color=:blues)\n\nExample 8.1.4\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nλ = @. 1 + 1 / (1:n)   # exact eigenvalues\nA = FNC.sprandsym(n, density, λ);\n\nThe eigs function from Arpack finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=:LM.\n\nusing Arpack\nλmax, V = eigs(A, nev=5, which=:LM)    # Largest Magnitude\nfmt = ft_printf(\"%20.15f\")\npretty_table([λmax λ[1:5]], header=[\"found\", \"exact\"], formatters=fmt)\n\nNow we find the 5 closest to the value 1 in the complex plane, via sigma=1.\n\nλ1, V = eigs(A, nev=5, sigma=1)    # closest to sigma\ndata = [λ1 λ[end:-1:end-4]]\npretty_table(data, header=[\"found\", \"exact\"], formatters=fmt)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nx = @. 1 / (1:n);\nb = A * x;\n\nnorm(x - A \\ b);  # force compilation\nt = @elapsed sparse_err = norm(x - A \\ b)\nprintln(\"Time for sparse solve: $t\")\n\nD = Matrix(A)  # convert to regular matrix\nnorm(x - D \\ b);\nt = @elapsed dense_err = norm(x - D \\ b)\nprintln(\"Time for dense solve: $t\")\n\n@show sparse_err;\n@show dense_err;","type":"content","url":"/chapter8#id-8-1","position":7},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-2","position":8},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"content":"Example 8.2.1\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = rand(1.0:9.0, 5, 5)\nA = A ./ sum(A, dims=1)\nx = randn(5)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A * x\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A * y\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nThis phenomenon seems to occur regardless of the starting vector.\n\nx = randn(5)\nfor j in 1:8\n    x = A * x\nend\n[x A * x]\n\nExample 8.2.2\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run the power iteration 60 times. The best estimate of the dominant eigenvalue is the last entry of the first output.\n\nβ, x = FNC.poweriter(A, 60)\neigval = β[end]\n\nWe check for linear convergence using a log-linear plot of the error.\n\nusing Plots\nerr = @. 1 - β\nplot(0:59, abs.(err); m=:o, \n    xlabel=L\"k\",  \n    yaxis=(L\"|\\lambda_1-\\beta_k|\", :log10, [1e-10, 1]),\n    title=\"Convergence of power iteration\")\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\n@show theory = λ[2] / λ[1];\n@show observed = err[40] / err[39];\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nβ[26:30]\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = @. β[end] - β[1:end-1]\nplot(0:58, abs.(err), m=:o, \n    xlabel=L\"k\", \n    yaxis=(L\"|\\beta_{60}-\\beta_k|\", :log10, [1e-10, 1]),\n    title=\"Convergence of power iteration\")\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.","type":"content","url":"/chapter8#id-8-2","position":9},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-3","position":10},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"content":"Example 8.3.1\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe run inverse iteration with the shift s=0.7 and take the final estimate as our “exact” answer to observe the convergence.\n\ns = 0.7\nβ, x = FNC.inviter(A, s, 30)\neigval = β[end]\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nusing Plots\nerr = @. abs(eigval - β)\nplot(0:28, err[1:end-1];\n    m=:o,  xlabel=L\"k\", \n    yaxis=(L\"|\\lambda_3-\\beta_k|\", :log10, [1e-16, 1]),\n    title=\"Convergence of inverse iteration\")\n\nThe observed linear convergence rate is found from the data.\n\n@show observed_rate = err[22] / err[21];\n\nWe reorder the eigenvalues to enforce \n\n(8.3.3).\n\nTip\n\nThe sortperm function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nλ = λ[sortperm(abs.(λ .- s))]\n\nHence the theoretical convergence rate is\n\n@show theoretical_rate = (λ[1] - s) / (λ[2] - s);\n\nExample 8.3.2\n\nλ = [1, -0.75, 0.6, -0.4, 0]\n# Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diagm(λ)\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\ns = 0.7\nx = ones(5)\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = β\nx = y / y[1]\ny = (A - s * I) \\ x\nβ = x[1] / y[1] + s\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in 1:4\n    s = β\n    x = y / y[1]\n    y = (A - s * I) \\ x\n    @show β = x[1] / y[1] + s\nend","type":"content","url":"/chapter8#id-8-3","position":11},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-4","position":12},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"content":"Example 8.4.1\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = [b zeros(100, 29)]\nfor m in 1:29\n    v = A * Km[:, m]\n    Km[:, m+1] = v / norm(v)\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nresid = zeros(30)\nfor m in 1:30\n    z = (A * Km[:, 1:m]) \\ b\n    x = Km[:, 1:m] * z\n    resid[m] = norm(b - A * x)\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nusing Plots\nplot(0:29, resid; m=:o,\n    xaxis=(L\"m\"), yaxis=(:log10, L\"\\| b-Ax_m \\|\"),\n    title=\"Residual for linear systems\", legend=:none)\n\nExample 8.4.2\n\nHere again is the linear system from \n\nExample 8.4.1.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nWe can use \\mathbf{b} as the seed vector for the Arnoldi iteration.\n\nQ, H = FNC.arnoldi(A, b, 30)\nprintln(\"Q has size $(size(Q))\")\nprintln(\"H has size $(size(H))\")\n\nHere’s one validation of the key identity \n\n(8.4.10).\n\nshould_be_near_zero = opnorm(A * Q[:, 1:20] - Q[:, 1:21] * H[1:21, 1:20])\n\nUsing the Krylov matrix to project the linear system into a Kyrlov subspace in \n\nExample 8.4.1 was unable to get the residual much smaller than about \n\n10-4. But the Arnoldi basis gives us a stable way to work in that subspace and get better results.\n\nz = (A * Q) \\ b\nx = Q * z\n@show resid_norm = norm(b - A * x);","type":"content","url":"/chapter8#id-8-4","position":13},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-5","position":14},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"content":"Example 8.5.1\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nλ = @. 10 + (1:100)\nA = triu(rand(100, 100), 1) + diagm(λ)\nb = rand(100);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = [norm(b); zeros(60)]\nfor m in 1:60\n    s = [norm(b); zeros(m)]\n    z = H[1:m+1, 1:m] \\ s\n    x = Q[:, 1:m] * z\n    resid[m+1] = norm(b - A * x)\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nusing Plots\nplot(0:60, resid, m=:o,\n    xaxis=(L\"m\"),  yaxis=(:log10, \"norm of mth residual\"),\n    title=\"Residual for GMRES\",  legend=:none)\n\nExample 8.5.2\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nA = FNC.poisson(50)\nn = size(A, 1)\nb = ones(n);\nspy(A, color=:blues)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from the IterativeSolvers package, since our simple implementation does not offer restarting.\n\nTip\n\nThe syntax f(x;foo) is shorthand for f(x,foo=foo).\n\nusing IterativeSolvers\nreltol = 1e-12;\nplt = plot(title=\"Convergence of restarted GMRES\", legend=:bottomleft,\n    xaxis=(L\"m\"),  yaxis=(:log10, \"residual norm\", [1e-8, 100]))\n\nfor restart in [n, 20, 40, 60]\n    x, hist = IterativeSolvers.gmres(A, b; restart, reltol,\n        maxiter=100, log=true)\n    plot!(hist[:resnorm], label=\"restart = $restart\")\nend\n\nplt\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.","type":"content","url":"/chapter8#id-8-5","position":15},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-6","position":16},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"content":"Example 8.6.2\n\nThe following matrix is indefinite.\n\nA = FNC.poisson(10) - 20I\nλ = eigvals(Matrix(A))\nisneg = @. λ < 0\n@show sum(isneg), sum(.!isneg);\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nmn, mx = extrema(-λ[isneg])\nκ₋ = mx / mn\nmn, mx = extrema(λ[.!isneg])\nκ₊ = mx / mn\nρ = (sqrt(κ₋ * κ₊) - 1) / (sqrt(κ₋ * κ₊) + 1)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nusing IterativeSolvers, Plots\nb = rand(100)\nx, hist = minres(A, b, reltol=1e-10, maxiter=51, log=true);\nrelres = hist[:resnorm] / norm(b)\nm = 0:length(relres)-1\nplot(m, relres;\n    label=\"observed\", legend=:left,\n    xaxis=L\"m\",  yaxis=(:log10, \"relative residual\"),\n    title=(\"Convergence of MINRES\"))\nplot!(m, ρ .^ (m / 2), l=:dash, label=\"upper bound\")\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nExample 8.6.3\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, 1 / 100)\nx = (1:n) / n\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from IterativeSolvers.\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"),  yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = FNC.sprandsym(n, density, 1 / 2500)\nb = A * x;\n\nplt = plot(title=\"Convergence of MINRES and CG\",\n    xaxis=(\"Krylov dimension\"), yaxis=(:log10, \"relative residual norm\"))\nfor method in [minres, cg]\n    x̃, history = method(A, b, reltol=1e-6, maxiter=1000, log=true)\n    relres = history[:resnorm] / norm(b)\n    plot!(0:length(relres)-1, relres, label=\"$method\")\n    err = round(norm(x̃ - x) / norm(x), sigdigits=4)\n    println(\"$method error: $err\")\nend\nplt\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.","type":"content","url":"/chapter8#id-8-6","position":17},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-7","position":18},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"content":"Example 8.7.1\n\nWe use a readily available test image.\n\nusing Images, TestImages\nimg = testimage(\"mandrill\")\nm, n = size(img)\nX = @. Float64(Gray(img))\nplot(Gray.(X), title=\"Original image\", aspect_ratio=1)\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nusing SparseArrays\nfunction blurmatrix(d)\n    v1 = fill(0.25, d - 1)\n    return spdiagm(0 => fill(0.5, d), 1 => v1, -1 => v1)\nend\nB, C = blurmatrix(m), blurmatrix(n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nusing Plots\nblur = X -> B^12 * X * C^12;\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nExample 8.7.2\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = testimage(\"lighthouse\")\nm, n = size(img)\nX = @. Float64(Gray(img))\n\nB = spdiagm(0 => fill(0.5, m),\n    1 => fill(0.25, m - 1), -1 => fill(0.25, m - 1))\nC = spdiagm(0 => fill(0.5, n),\n    1 => fill(0.25, n - 1), -1 => fill(0.25, n - 1))\nblur = X -> B^12 * X * C^12\nZ = blur(X)\nplot(Gray.(Z), title=\"Blurred image\")\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\n# vec (built-in) converts matrix to vector\nunvec = z -> reshape(z, m, n);  # convert vector to matrix\n\nNow we declare the three-step blur transformation as a LinearMap, supplying also the size of the vector form of an image.\n\nusing LinearMaps\nT = LinearMap(x -> vec(blur(unvec(x))), m * n);\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nTip\n\nThe function clamp01 in Images restricts values to be in the interval [0,1].\n\nusing IterativeSolvers\ny = minres(T, vec(Z), maxiter=50, reltol=1e-5);\nY = unvec(clamp01.(y))\n\nplot(Gray.(X), layout=2, title=\"Original\")\nplot!(Gray.(Y), subplot=2, title=\"Deblurred\")","type":"content","url":"/chapter8#id-8-7","position":19},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter8#id-8-8","position":20},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"content":"Example 8.8.1\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nusing MatrixDepot\nA = matrixdepot(\"wathen\", 60)\nn = size(A, 1)\n@show n, nnz(A);\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nusing Preconditioners\nb = ones(n)\nM = DiagonalPreconditioner(diag(A));\n\nWe now compare CG with and without the preconditioner.\n\nusing IterativeSolvers, Plots\nplain(b) = cg(A, b, maxiter=200, reltol=1e-4, log=true)\ntime_plain = @elapsed x, hist1 = plain(b)\nprec(b) = cg(A, b, Pl=M, maxiter=200, reltol=1e-4, log=true)\ntime_prec = @elapsed x, hist2 = prec(b)\n@show time_plain, time_prec\n\nrr = hist1[:resnorm]\nplot(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"plain\")\nrr = hist2[:resnorm]\nplot!(0:length(rr)-1, rr / rr[1], yscale=:log10, label=\"preconditioned\")\ntitle!(\"Diagonal preconditioning in CG\")\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\nExample 8.8.2\n\nHere is a nonsymmetric matrix arising from a probabilistic model in computational chemistry.\n\nusing SparseArrays\nA = sparse(matrixdepot(\"Watson/chem_master1\"))\nn = size(A, 1)\n@show n, nnz(A), issymmetric(A)\n\nWithout a preconditioner, GMRES makes essentially no progress after 100 iterations.\n\nb = rand(40000)\nconst GMRES = IterativeSolvers.gmres\nx, history = GMRES(A, b, maxiter=100, reltol=1e-5, log=true)\nresnorm = history[:resnorm]\n@show resnorm[end] / resnorm[1];\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\nusing IncompleteLU\niLU = ilu(A, τ=0.25)\n@show nnz(iLU) / nnz(A);\n\nThe result is almost 10 times as dense as \\mathbf{A} and yet still not a true factorization of it. However, it’s close enough for an approximate inverse in a preconditioner. The actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}, but we just supply the factorization to gmres.\n\n_, history = GMRES(A, b, Pl=iLU, maxiter=100, reltol=1e-5, log=true)\nhistory\n\nThe τ parameter in ilu balances the accuracy of the iLU factorization with the time needed to compute it and invert it. As \\tau\\to 0, more of the elements are kept, making the preconditioner more effective but slower per iteration.\n\nplt = plot(0:40, resnorm[1:41] / resnorm[1];\n    label=\"no preconditioning\",  legend=:bottomright,\n    xaxis=(\"iteration number\"),\n    yaxis=(:log10, \"residual norm\"),\n    title=\"Incomplete LU preconditioning\")\nfor τ in [2, 1, 0.25, 0.1]\n    t = @elapsed iLU = ilu(A; τ)\n    t += @elapsed _, history = GMRES(A, b, Pl=iLU, maxiter=100,\n        reltol=1e-5, log=true)\n    resnorm = history[:resnorm]\n    label = \"τ = $τ, time = $(round(t,digits=3))\"\n    plot!(0:length(resnorm)-1, resnorm / resnorm[1]; label)\nend\nplt\n\nIn any given problem, it’s impossible to know in advance where the right balance lies between fidelity and speed for the preconditioner.","type":"content","url":"/chapter8#id-8-8","position":21},{"hierarchy":{"lvl1":"Chapter 9"},"type":"lvl1","url":"/chapter9","position":0},{"hierarchy":{"lvl1":"Chapter 9"},"content":"","type":"content","url":"/chapter9","position":1},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Functions"},"type":"lvl2","url":"/chapter9#functions","position":2},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Functions"},"content":"Barycentric polynomial interpolation\n\n\"\"\"\n    polyinterp(t, y)\n\nConstruct a callable polynomial interpolant through the points in\nvectors `t`, `y` using the barycentric interpolation formula.\n\"\"\"\nfunction polyinterp(t, y)\n    n = length(t) - 1\n    C = (t[n+1] - t[1]) / 4           # scaling factor to ensure stability\n    tc = t / C\n\n    # Adding one node at a time, compute inverses of the weights.\n    ω = ones(n+1)\n    for m in 0:n-1\n        d = tc[1:m+1] .- tc[m+2]    # vector of node differences\n        @. ω[1:m+1] *= d            # update previous\n        ω[m+2] = prod(-d)         # compute the new one\n    end\n    w = 1 ./ ω                      # go from inverses to weights\n\n    # This function evaluates the interpolant at given x.\n    p = function (x)\n        Δ = x .- t\n        if any(iszero.(Δ))     # we're at a node exactly\n            # return the node's data value\n            idx = findfirst(iszero.(Δ))\n            f = y[idx]\n        else\n            terms = w ./ Δ\n            f = sum(y .* terms) / sum(terms)\n        end\n    end\n    return p\nend\n\nAbout the code\n\nAs noted in \n\nExample 9.2.1, a common scaling factor in the weights does not affect the barycentric formula \n\n(9.2.3). In lines 9--10 this fact is used to rescale the nodes in order to avoid eventual tiny or enormous numbers that could go outside the bounds of double precision.\n\nThe return value is a function that evaluates the polynomial interpolant. Within this function, isinf is used to detect either Inf or -Inf, which occurs when x exactly equals one of the nodes. In this event, the corresponding data value is returned.\n\nTrigonometric interpolation\n\n\"\"\"\n    triginterp(t, y)\n\nConstruct the trigonometric interpolant for the points defined by\nvectors `t` and `y`.\n\"\"\"\nfunction triginterp(t, y)\n    N = length(t)\n\n    τ(x) =\n        if x == 0\n            return 1.0\n        else\n            denom = isodd(N) ? N * sin(π * x / 2) : N * tan(π * x / 2)\n            return sin(N * π * x / 2) / denom\n        end\n\n    return function (x)\n        return sum(y[k] * τ(x - t[k]) for k in eachindex(y))\n    end\nend\n\nAbout the code\n\nThe construct on line 13 is known as a ternary operator. It is a shorthand for an if–else statement, giving two alternative results for the true/false cases. Line 19 uses eachindex(y), which generalizes 1:length(y) to cases where a vector might have a more exotic form of indexing.\n\nClenshaw–Curtis integration\n\n\"\"\"\n    ccint(f, n)\n\nPerform Clenshaw-Curtis integration for the function `f` on `n`+1\nnodes in [-1,1]. Returns the integral estimate and a vector of the\nnodes used. Note: `n` must be even.\n\"\"\"\nfunction ccint(f, n)\n    @assert iseven(n) \"Value of `n` must be an even integer.\"\n    # Find Chebyshev extreme nodes.\n    θ = [i * π / n for i in 0:n]\n    x = -cos.(θ)\n\n    # Compute the C-C weights.\n    c = similar(θ)\n    c[[1, n+1]] .= 1 / (n^2 - 1)\n    s = sum(cos.(2k * θ[2:n]) / (4k^2 - 1) for k in 1:n/2-1)\n    v = @. 1 - 2s - cos(n * θ[2:n]) / (n^2 - 1)\n    c[2:n] = 2v / n\n\n    # Evaluate integrand and integral.\n    I = dot(c, f.(x))   # vector inner product\n    return I, x\nend\n\nGauss–Legendre integration\n\n\"\"\"\n    glint(f, n)\n\nPerform Gauss-Legendre integration for the function `f` on `n` nodes\nin (-1,1). Returns the integral estimate and a vector of the nodes used.\n\"\"\"\nfunction glint(f, n)\n    # Nodes and weights are found via a tridiagonal eigenvalue problem.\n    β = @. 0.5 / sqrt(1 - (2 * (1:n-1))^(-2))\n    T = diagm(-1 => β, 1 => β)\n    λ, V = eigen(T)\n    p = sortperm(λ)\n    x = λ[p]               # nodes\n    c = @. 2V[1, p]^2       # weights\n\n    # Evaluate the integrand and compute the integral.\n    I = dot(c, f.(x))      # vector inner product\n    return I, x\nend\n\nIntegration over (-\\infty,\\infty)\n\n\"\"\"\n    intinf(f, tol)\n\nPerform adaptive doubly-exponential integration of function `f`\nover (-Inf,Inf), with error tolerance `tol`. Returns the integral\nestimate and a vector of the nodes used.\n\"\"\"\nfunction intinf(f, tol)\n    x = t -> sinh(sinh(t))\n    dx_dt = t -> cosh(t) * cosh(sinh(t))\n    g = t -> f(x(t)) * dx_dt(t)\n\n    # Find where to truncate the integration interval.\n    M = 3\n    while (abs(g(-M)) > tol / 100) || (abs(g(M)) > tol / 100)\n        M += 0.5\n        if isinf(x(M))\n            @warn \"Function may not decay fast enough.\"\n            M -= 0.5\n            break\n        end\n    end\n\n    I, t = intadapt(g, -M, M, tol)\n    return I, x.(t)\nend\n\nAbout the code\n\nThe test isinf(x(M)) in line 17 checks whether x(M) is larger than the maximum double-precision value, causing it to overflow to Inf.\n\nIntegration with endpoint singularities\n\n\"\"\"\n    intsing(f, tol)\n\nAdaptively integrate function `f` over (0,1), where `f` may be\nsingular at zero, with error tolerance `tol`. Returns the\nintegral estimate and a vector of the nodes used.\n\"\"\"\nfunction intsing(f, tol)\n    x = t -> 2 / (1 + exp(2sinh(t)))\n    dx_dt = t -> cosh(t) / cosh(sinh(t))^2\n    g = t -> f(x(t)) * dx_dt(t)\n\n    # Find where to truncate the integration interval.\n    M = 3\n    while abs(g(M)) > tol / 100\n        M += 0.5\n        if iszero(x(M))\n            @warn \"Function may grow too rapidly.\"\n            M -= 0.5\n            break\n        end\n    end\n\n    I, t = intadapt(g, 0, M, tol)\n    return I, x.(t)\nend\n\nAbout the code\n\nThe test iszero(x(M)) in line 17 checks whether x(M) is less than the smallest positive double-precision value, causing it to underflow to zero.","type":"content","url":"/chapter9#functions","position":3},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Examples"},"type":"lvl2","url":"/chapter9#examples","position":4},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Examples"},"content":"\n\ninclude(\"FNC_init.jl\")\n\n","type":"content","url":"/chapter9#examples","position":5},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.1 Polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-1","position":6},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.1 Polynomial interpolation","lvl2":"Examples"},"content":"Example 9.1.1\n\nHere is a vector of nodes.\n\nt = [ 1, 1.5, 2, 2.25, 2.75, 3 ]\nn = length(t) - 1;\n\nLet’s apply the definition of the cardinal Lagrange polynomial for k=2. First we define a polynomial q that is zero at all the nodes except i=k. Then \\ell_2 is found by normalizing q by q(t_k).\n\nTip\n\nCharacter ℓ is typed as \\ellTab.\n\nk = 2\nq(x) = prod(x - t[i] for i in [0:k-1; k+1:n] .+ 1)\nℓₖ(x) = q(x) / q(t[k+1]);\n\nA plot confirms the cardinal property of the result.\n\nusing Plots\nplot(ℓₖ, 1, 3)\ny = zeros(n+1);  y[k+1] = 1\nscatter!(t, y, color=:black,\n    xaxis=(L\"x\"),  yaxis=(L\"\\ell_2(x)\"),\n    title=\"Lagrange cardinal function\")\n\nObserve that \\ell_k is not between zero and one everywhere, unlike a hat function.\n\nExample 9.1.3\n\nConsider the problem of interpolating \\log(x) at these nodes:\n\nt =  [ 1, 1.6, 1.9, 2.7, 3 ]\nn = length(t) - 1;\n\nHere n=4 and f^{(5)}(\\xi) = 4!/\\xi^5. For \\xi\\in[1,3] we can say that |f^{(5)}(\\xi)| \\le 4!. Hence|f(x)-p(x)| \\le \\frac{1}{5} \\left| \\Phi(x) \\right|.\n\nTip\n\nCharacter Φ is typed as \\PhiTab. (Note the capitalization.)\n\nusing Polynomials\nΦ(x) = prod(x - tᵢ for tᵢ in t)\nplot(x -> 0.2 * abs(Φ(x)), 1, 3, label=L\"\\frac{1}{5}|\\Phi(t)|\")\np = Polynomials.fit(t, log.(t))\nplot!(t -> abs(log(t) - p(t)), 1, 3, label=L\"|f(x)-p(x)|\")\nscatter!(t, zeros(size(t)), color=:black,\n    xaxis=(L\"x\"), title=\"Interpolation error and upper bound\")\n\nThe error is zero at the nodes, by the definition of interpolation. The error bound, as well as the error itself, has one local maximum between each consecutive pair of nodes.","type":"content","url":"/chapter9#id-9-1","position":7},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.2 The barycentric formula","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-2","position":8},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.2 The barycentric formula","lvl2":"Examples"},"content":"Example 9.2.2\n\nusing Plots\nf(x) = sin(exp(2x))\nplot(f, 0, 1, label=\"function\", legend=:bottomleft)\n\nt = (0:3) / 3\ny = f.(t)\nscatter!(t, y, color=:black, label=\"nodes\")\n\np = FNC.polyinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"Interpolation on 4 nodes\")\n\nThe curves must intersect at the interpolation nodes. For n=6 the interpolant is noticeably better.\n\nplot(f, 0, 1, label=\"function\", legend=:bottomleft)\nt = (0:6) / 6\ny = f.(t)\np = FNC.polyinterp(t, y)\nscatter!(t, y, color=:black, label=\"nodes\")\nplot!(p, 0, 1, label=\"interpolant\", title=\"Interpolation on 7 nodes\")","type":"content","url":"/chapter9#id-9-2","position":9},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.3 Stability of polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-3","position":10},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.3 Stability of polynomial interpolation","lvl2":"Examples"},"content":"Example 9.3.1\n\nWe choose a function over the interval [0,1].\n\nf(x) = sin(exp(2x));\n\nHere is a graph of f and its polynomial interpolant using seven equally spaced nodes.\n\nusing Plots\nplot(f, 0, 1, label=\"function\", legend=:bottomleft)\nt = range(0, 1, 7)    # 7 equally spaced nodes\ny = f.(t)\nscatter!(t, y, label=\"nodes\")\n\np = FNC.polyinterp(t, y)\nplot!(p, 0, 1, label=\"interpolant\", title=\"Equispaced interpolant, n=6\")\n\nThis looks pretty good. We want to track the behavior of the error as n increases. We will estimate the error in the continuous interpolant by sampling it at a large number of points and taking the max-norm.\n\nn = 5:5:60\nerr = zeros(size(n))\nx = range(0, 1, 2001)             # for measuring error\nfor (k, n) in enumerate(n)\n    t = range(0, 1, n+1)          # equally spaced nodes\n    y = f.(t)                     # interpolation data\n    p = FNC.polyinterp(t, y)\n    err[k] = norm((@. f(x) - p(x)), Inf)\nend\nplot(n, err, m=:o, \n    xaxis=(L\"n\"), yaxis=(:log10, \"max error\"),\n    title=\"Interpolation error for equispaced nodes\")\n\nThe error initially decreases as one would expect but then begins to grow. Both phases occur at rates that are exponential in n, i.e., O(K^n) for a constant K, appearing linear on a semi-log plot.\n\nExample 9.3.2\n\nWe plot |\\Phi(x)| over the interval [-1,1] with equispaced nodes for different values of n.\n\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|\\Phi(x)|\", [1e-25, 1]), legend=:bottomleft)\nx = range(-1, 1, 2001)\nfor n in 10:10:50\n    t = range(-1, 1, n+1)\n    Φ(x) = prod(x - t for t in t)\n    scatter!(x, abs.(Φ.(x)), m=(1, stroke(0)), label=\"n=$n\")\nend\ntitle!(\"Error indicator for equispaced nodes\")\n\nEach time Φ passes through zero at an interpolation node, the value on the log scale should go to -\\infty, which explains the numerous cusps on the curves.\n\nExample 9.3.3\n\nThis function has infinitely many continuous derivatives on the entire real line and looks easy to approximate over [-1,1].\n\nf(x) = 1 / (x^2 + 16)\nplot(f, -1, 1, title=\"Test function\", legend=:none)\n\nWe start by doing equispaced polynomial interpolation for some small values of n.\n\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|f(x)-p(x)|\", [1e-20, 1]))\nx = range(-1, 1, 2501)\nn = 4:4:12\nfor (k, n) in enumerate(n)\n    t = range(-1, 1, n+1)           # equally spaced nodes\n    y = f.(t)                       # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = @. abs(f(x) - p(x))\n    plot!(x, err, m=(1, :o, stroke(0)), label=\"degree $n\")\nend\ntitle!(\"Error for low degrees\")\n\nThe convergence so far appears rather good, though not uniformly so. However, notice what happens as we continue to increase the degree.\n\nn = @. 12 + 15 * (1:3)\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|f(x)-p(x)|\", [1e-20, 1]))\nfor (k, n) in enumerate(n)\n    t = range(-1, 1, n+1)           # equally spaced nodes\n    y = f.(t)                       # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = @. abs(f(x) - p(x))\n    plot!(x, err, m=(1, :o, stroke(0)), label=\"degree $n\")\nend\ntitle!(\"Error for higher degrees\")\n\nThe convergence in the middle can’t get any better than machine precision relative to the function values. So maintaining the growing gap between the center and the ends pushes the error curves upward exponentially fast at the ends, wrecking the convergence.\n\nExample 9.3.4\n\nNow we look at the error indicator function Φ for Chebyshev node sets.\n\nplot(xaxis=(L\"x\"), yaxis=(:log10, L\"|\\Phi(x)|\", [1e-18, 1e-2]))\nx = range(-1, 1, 2001)\nfor n in 10:10:50\n    t = [-cospi(k / n) for k in 0:n]\n    Φ(x) = prod(x - t for t in t)\n    plot!(x, abs.(Φ.(x)), m=(1, :o, stroke(0)), label=\"n=$n\")\nend\ntitle!(\"Error indicator for Chebyshev nodes\")\n\nIn contrast to the equispaced case, |\\Phi| decreases exponentially with n almost uniformly across the interval.\n\nExample 9.3.5\n\nHere again is the function from \n\nDemo 9.3.3 that provoked the Runge phenomenon when using equispaced nodes.\n\nf(x) = 1 / (x^2 + 16);\n\nplot(label=\"\", xaxis=(L\"x\"), yaxis=(:log10, L\"|f(x)-p(x)|\", [1e-20, 1]))\nx = range(-1, 1, 2001)\nfor (k, n) in enumerate([4, 10, 16, 40])\n    t = [-cospi(k / n) for k in 0:n]\n    y = f.(t)                           # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = @. abs(f(x) - p(x))\n    plot!(x, err, m=(1, :o, stroke(0)), label=\"degree $n\")\nend\ntitle!(\"Error for Chebyshev interpolants\")\n\nBy degree 16 the error is uniformly within machine epsilon, and, importantly, it stays there as n increases. Note that as predicted by the error indicator function, the error is uniform over the interval at each value of n.\n\nExample 9.3.6\n\nusing Logging\ndisable_logging(Logging.Warn);\n\nOn the left, we use a log-log scale, which makes second-order algebraic convergence O(n^{-4}) a straight line. On the right, we use a log-linear scale, which makes spectral convergence O(K^{-n}) linear.\n\nn = 20:20:400\nalgebraic = @. 100 / n^4\nspectral = @. 10 * 0.85^n\nplot(n, [algebraic spectral], layout=(1, 2), subplot=1,\n    xaxis=(L\"n\", :log10),  yaxis=(:log10, (1e-15, 1)),\n    label=[\"algebraic\" \"spectral\"],  title=\"Log-log\")\nplot!(n, [algebraic spectral], subplot=2,\n    xaxis=L\"n\",  yaxis=(:log10, (1e-15, 1)),\n    label=[\"algebraic\" \"spectral\"],  title=\"log-linear\")","type":"content","url":"/chapter9#id-9-3","position":11},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.4 Orthogonal polynomials","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-4","position":12},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.4 Orthogonal polynomials","lvl2":"Examples"},"content":"Example 9.4.1\n\nLet’s approximate e^x over the interval [−1,1]. We can sample it at, say, 15 points, and find the best-fitting straight line to that data.\n\nusing Plots\nplot(exp, -1, 1, label=\"function\")\nt = range(-1, 1, 15)\ny = exp.(t)\nV = [ti^j for ti in t, j in 0:1]  # Vandermonde-ish\nc = V \\ y\nplot!(t -> c[1] + c[2] * t, -1, 1;\n    label=\"linear fit for 15 points\", legend=:bottomright,\n    xaxis=(\"x\"),  yaxis=(\"value\"),\n    title=\"Least-squares fit of exp(x)\")\n\nThere’s nothing special about 20 points. Choosing more doesn’t change the result much.\n\nt = range(-1, 1, 150)\ny = exp.(t)\nV = [ ti^j for ti in t, j=0:1 ]\nc = V \\ y\nplot!(t -> c[1] + c[2]*t, -1, 1,\n    label=\"linear fit for 150 points\",  legend=:bottomright,\n    xaxis=(\"x\"),  yaxis=(\"value\"),\n    title=\"Least-squares fit of exp(x)\")\n\nThis situation is unlike interpolation, where the degree of the interpolant increases with the number of nodes. Here, the linear fit is apparently approaching a limit that we may think of as a continuous least-squares fit.\n\nn = 40:60:400\nslope = zeros(size(n))\nintercept = zeros(size(n))\n\nfor (k, n) in enumerate(n)\n    t = range(-1, 1, n)\n    y = exp.(t)\n    V = [ ti^j for ti in t, j in 0:1 ]\n    c = V \\ y\n    intercept[k], slope[k] = c\nend\n\nlabels = [\"n\", \"intercept\", \"slope\"]\n@pt :header=labels, [n intercept slope]","type":"content","url":"/chapter9#id-9-4","position":13},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.5 Trigonometric interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-5","position":14},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.5 Trigonometric interpolation","lvl2":"Examples"},"content":"Example 9.5.1\n\nWe will get a cardinal function without using an explicit formula, just by passing data that is 1 at one node and 0 at the others.\n\nTip\n\nThe operator ÷, typed as \\div then Tab, returns the quotient without remainder of two integers.\n\nusing Plots\nN = 7\nn = (N - 1) ÷ 2\nt = 2 * (-n:n) / N\ny = zeros(N)\ny[n+1] = 1\n\np = FNC.triginterp(t, y);\nplot(p, -1, 1)\n\nscatter!(t, y, color=:black, \n    xaxis=(L\"x\"),  yaxis=(L\"\\tau(x)\"),\n    title=\"Trig cardinal function, N=$N\")\n\nHere is a 2-periodic function and one of its interpolants.\n\nf(x) = exp( sinpi(x) - 2*cospi(x) )\ny = f.(t)\np = FNC.triginterp(t, y)\n\nplot(f, -1, 1, label=\"function\",\n    xaxis=(L\"x\"),  yaxis=(L\"p(x)\"),\n    title=\"Trig interpolation, N=$N\", legend=:top)\nscatter!(t, y, m=:o, color=:black, label=\"nodes\")\nplot!(p, -1, 1, label=\"interpolant\")\n\nThe convergence of the interpolant is spectral. We let N go needlessly large here in order to demonstrate that unlike polynomials, trigonometric interpolation is stable on equally spaced nodes. Note that when N is even, the value of n is not an integer but works fine for defining the nodes.\n\nN = 2:2:60\nerr = zeros(size(N))\nx = range(-1, 1, 2501)  # for measuring error\nfor (k,N) in enumerate(N)\n    n = (N-1) / 2;   t = 2*(-n:n) / N;\n    p = FNC.triginterp(t, f.(t))\n    err[k] = norm(f.(x) - p.(x), Inf)\nend\n\nplot(N, err, m=:o,\n    xaxis=(L\"N\"),  yaxis=(:log10, \"max error\"),\n    title=\"Convergence of trig interpolation\")\n\nExample 9.5.2\n\nThis function has frequency content at 2\\pi, -2\\pi, and π.\n\nf(x) = 3 * cospi(2x) - cispi(x)    # cispi(x) := exp(1im * π * x)\n\nTo use fft, we set up nodes in the interval [0,2).\n\nn = 4;  N = 2n+1;\nt = [ 2j / N for j in 0:N-1 ]      # nodes in [0,2)\ny = f.(t);\n\nWe perform Fourier analysis using fft and then examine the resulting coefficients.\n\nusing FFTW\nc = fft(y) / N\nfreq = [0:n; -n:-1]\n@pt :header=[\"k\", \"coefficient\"] [freq round.(c, sigdigits=5)]\n\nNote that 1.5 e^{2i\\pi x}+1.5 e^{-2i\\pi x} = 3 \\cos(2\\pi x), so this result is sensible.\n\nFourier’s greatest contribution to mathematics was to point out that every periodic function is just a combination of frequencies—infinitely many of them in general, but truncated for computational use. Here we look at the magnitudes of the coefficients for f(x) = \\exp( \\sin(\\pi x) ).\n\nf(x) = exp( sin(pi*x) )     # content at all frequencies\nn = 9;  N = 2n+1;\nt = [ 2j / N for j in 0:N-1 ]      # nodes in [0,2)\nc = fft(f.(t)) / N\n\nfreq = [0:n; -n:-1]\nscatter(freq, abs.(c);\n    xaxis=(L\"k\", [-n, n]),  yaxis=(L\"|c_k|\", :log10), \n    title=\"Fourier coefficients\",  legend=:none)\n\nThe Fourier coefficients of smooth functions decay exponentially in magnitude as a function of the frequency. This decay rate is determines the convergence of the interpolation error.","type":"content","url":"/chapter9#id-9-5","position":15},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.6 Spectrally accurate integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-6","position":16},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.6 Spectrally accurate integration","lvl2":"Examples"},"content":"Example 9.6.1\n\nf(t) = π * sqrt( cospi(t)^2 + sinpi(t)^2 / 4 );\nn = 4:4:48\nperim = zeros(size(n))\nfor (k, n) in enumerate(n)\n    h = 2 / n\n    t = @. h * (0:n-1) - 1\n    perim[k] = h * sum(f.(t))\nend\nerr = @. abs(perim - perim[end])    # use last value as \"exact\"\n@ptconf formatters=ft_printf([\"%d\", \"%.15f\", \"%.2e\"], 1:3)\n@pt :header=[\"n\", \"perimeter\", \"error estimate\"] [n perim err][1:end-1, :]\n\nThe approximations gain about one digit of accuracy for each constant increment of n, which is consistent with spectral convergence.\n\nExample 9.6.3\n\nFirst consider the integral\\int_{-1}^1 \\frac{1}{1+4x^2} \\, dx = \\arctan(2).\n\nf(x)= 1 / (1 + 4x^2);\nexact = atan(2);\n\nWe compare the two spectral integration methods for a range of n values.\n\nusing Plots\nn = 8:4:96\nerr = zeros(length(n), 2)\nfor (k, n) in enumerate(n)\n  err[k, 1] = abs(exact - FNC.ccint(f, n)[1])\n  err[k, 2] = abs(exact - FNC.glint(f, n)[1])\nend\n\nerr[iszero.(err)] .= NaN    # remove from log-scale plot\nplot(n, err, m=:o, label=[\"CC\" \"GL\"],\n    xaxis=(\"number of nodes\"),  yaxis=(:log10, \"error\", [1e-16, 1]), \n    title=\"Spectral integration\")\n\n(The missing dots are where the error is exactly zero.) Gauss–Legendre does converge faster here, but at something less than twice the rate.\n\nNow we try a more sharply peaked integrand:\\int_{-1}^1 \\frac{1}{1+16x^2} \\, dx = \\frac{1}{2}\\arctan(4).\n\nf(x) = 1 / (1 + 16x^2);\nexact = atan(4) / 2;\n\nn = 8:4:96\nerr = zeros(length(n), 2)\nfor (k,n) in enumerate(n)\n  err[k, 1] = abs(exact - FNC.ccint(f, n)[1])\n  err[k, 2] = abs(exact - FNC.glint(f, n)[1])\nend\n\nerr[iszero.(err)] .= NaN    # remove from log-scale plot\nplot(n, err, m=:o, label=[\"CC\" \"GL\"],\n    xaxis=(\"number of nodes\"),  yaxis=(:log10, \"error\", [1e-16, 1]), \n    title=\"Spectral integration\")\n\nThe two are very close until about n=40, when the Clenshaw–Curtis method slows down.\n\nNow let’s compare the spectral performance to that of our earlier adaptive method in intadapt. We will specify varying error tolerances and record the error as well as the total number of evaluations of f.\n\ntol = 10 .^(-2.0:-2:-14)\nn = zeros(size(tol))  \nerrAdapt = zeros(size(tol))\nfor (k, tol) in enumerate(tol)\n  Q, t = FNC.intadapt(f, -1, 1, tol)\n  errAdapt[k] = abs(exact - Q)\n  n[k] = length(t)\nend\n\nerrAdapt[iszero.(errAdapt)] .= NaN\nplot!(n, errAdapt, m=:o, label=\"intadapt\")\nplot!(n, n.^(-4), l=:dash, label=\"4th order\",\n        xaxis=(:log10),  title=\"Spectral vs 4th order\" )\n\nAt the core of intadapt is a fourth-order formula, and the results track that rate closely. For all but the most relaxed error tolerances, both spectral methods are far more efficient than the low-order counterpart. For other integrands, particularly those that vary nonuniformly across the interval, the adaptive method might be more competitive.","type":"content","url":"/chapter9#id-9-6","position":17},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.7 Improper integrals","lvl2":"Examples"},"type":"lvl3","url":"/chapter9#id-9-7","position":18},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.7 Improper integrals","lvl2":"Examples"},"content":"Example 9.7.2\n\nusing Plots\nf(x) = 1 / (1 + x^2)\nplot(f, -4, 4, layout=(2, 1),\n    xlabel=L\"x\", \n    yaxis=(:log10, L\"f(x)\", (1e-16, 2)),\n    title=\"Original integrand\")\n\nξ(t) = sinh( π * sinh(t) / 2 )\ndξ_dt(t) = π/2 * cosh(t) * cosh(π * sinh(t) / 2)\ng(t) = f(ξ(t)) * dξ_dt(t)\n\nplot!(g,-4, 4, subplot=2,\n    xlabel=L\"t\",\n    yaxis=(:log10, L\"f(x(t))\\cdot x'(t)\", (1e-16, 2)),\n    title=\"Transformed integrand\")\n\nThis graph suggests that we capture all of the integrand values that are larger than machine epsilon by integrating in t from -4 to 4.\n\nExample 9.7.3\n\nf(x) = 1 / (1 + x^2)\ntol = [1 / 10^d for d in 5:0.5:14]\nerr = zeros(length(tol), 2)\nlen = zeros(Int, length(tol), 2)\nfor (i, tol) in enumerate(tol)\n    I1, x1 = FNC.intadapt(f, -2/tol, 2/tol, tol)\n    I2, x2 = FNC.intinf(f, tol)\n    @. err[i,:] = abs(π - [I1, I2])\n    @. len[i,:] = length([x1, x2])\nend\nplot(len, err, m=:o, label=[\"direct\" \"double exponential\"])\nn = [100, 10000]\nplot!(n, 1000n.^(-4), \n    color=:black,  l=:dash,\n    label=\"fourth-order\",  legend=:bottomleft,\n    xaxis=(:log10, \"number of nodes\"), \n    yaxis=(:log10, \"error\"),\n    title=\"Comparison of integration methods\")\n\nBoth methods are roughly fourth-order due to Simpson’s formula in the underlying adaptive integration method. At equal numbers of evaluation nodes, however, the double exponential method is consistently 2--3 orders of magnitude more accurate.\n\nExample 9.7.4\n\nf(x) = 1 / (10 * sqrt(x))\ntol = [1 / 10^d for d in 5:0.5:14]\nerr = zeros(length(tol), 2)\nlen = zeros(Int, length(tol), 2)\nfor (i, tol) in enumerate(tol)\n    I1, x1 = FNC.intadapt(f, (tol/20)^2, 1, tol)\n    I2, x2 = FNC.intsing(f, tol)\n    @. err[i, :] = abs(0.2 - [I1, I2])\n    @. len[i, :] = length([x1, x2])\nend\nplot(len, err, m=:o, label=[\"direct\" \"double exponential\"])\nn = [30, 3000]\nplot!(n, 30n.^(-4);\n    color=:black,  l=:dash,\n    label=\"fourth-order\",  legend=:bottomleft,\n    xaxis=(:log10, \"number of nodes\"),\n    yaxis=(:log10, \"error\"),\n    title=\"Comparison of integration methods\")\n\nAs in \n\nDemo 9.7.3, the double exponential method is more accurate than direct integration by a few orders of magnitude. Equivalently, the same accuracy can be reached with many fewer nodes.","type":"content","url":"/chapter9#id-9-7","position":19},{"hierarchy":{"lvl1":"Julia setup"},"type":"lvl1","url":"/setup","position":0},{"hierarchy":{"lvl1":"Julia setup"},"content":"","type":"content","url":"/setup","position":1},{"hierarchy":{"lvl1":"Julia setup","lvl2":"Setting up Julia for this book"},"type":"lvl2","url":"/setup#section-setup-julia","position":2},{"hierarchy":{"lvl1":"Julia setup","lvl2":"Setting up Julia for this book"},"content":"Julia, and all the packages this book depends on, is free and open-source. Much of the functionality outside the core is distributed via packages that need to be installed once per system.","type":"content","url":"/setup#section-setup-julia","position":3},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Installing Julia","lvl2":"Setting up Julia for this book"},"type":"lvl3","url":"/setup#installing-julia","position":4},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Installing Julia","lvl2":"Setting up Julia for this book"},"content":"To install Julia, go to the \n\nJulia website and download the appropriate version for your operating system. Any 1.x version at 1.11 or greater should be fine. I strongly recommend using the juliaup version manager rather than manually downloading and installing the application.","type":"content","url":"/setup#installing-julia","position":5},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Installing the book’s functions","lvl2":"Setting up Julia for this book"},"type":"lvl3","url":"/setup#installing-the-books-functions","position":6},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Installing the book’s functions","lvl2":"Setting up Julia for this book"},"content":"When you start Julia, you will see a prompt that looks like this:julia>\n\nIt is waiting for you to enter commands that will be executed right away. To enter package management mode, type ] (the ] key) and you will see the prompt change to something like this:(@v1.11) pkg>\n\nNow you enter add FNCFunctions and press Enter. This will install the functions that are used in this book. It may take a few minutes to download and install everything. This is a one-time operation.\n\nWhen you are done with package management, type delete or a backspace to return to the normal Julia prompt.","type":"content","url":"/setup#installing-the-books-functions","position":7},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Using packages","lvl2":"Setting up Julia for this book"},"type":"lvl3","url":"/setup#using-packages","position":8},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Using packages","lvl2":"Setting up Julia for this book"},"content":"Julia offers both import and using as ways to load packages. The difference is that import loads a package into its own namespace, so that you have to refer to its functions with a prefix. For example:julia> import Statistics\n\njulia> mean\nERROR: UndefVarError: `mean` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Statistics.\n\njulia> Statistics.mean\nmean (generic function with 6 methods)\n\nIf you use using rather than import, then the package may also make its functions available in the global namespace. For example:julia> using Statistics\n\njulia> mean\nmean (generic function with 6 methods)\n\nThis is convenient for functions that you will call frequently, but it can lead to name conflicts if you are not careful. The package written for this book do not go into the global namespace. This is a deliberate reminder that they are for learning purposes only and not meant as tools for serious work. The package does define a shortcut called FNC, though, so you can write FNC.lufact instead of FNCFunctions.lufact.","type":"content","url":"/setup#using-packages","position":9},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Installing other packages","lvl2":"Setting up Julia for this book"},"type":"lvl3","url":"/setup#installing-other-packages","position":10},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Installing other packages","lvl2":"Setting up Julia for this book"},"content":"Julia comes with a few core packages such as Statistics and LinearAlgebra that you can use right away. But if you try import or using at the prompt with an unknown package, you will get a message like this:julia> using Plots\n │ Package Plots not found, but a package named Plots is available from a registry. \n │ Install package?\n │   (@v1.11) pkg> add Plots \n └ (y/n/o) [y]: \n\nIf you answer y, then the package will be downloaded and installed. You can also install packages from the prompt manually by typing ] add PackageName. For example, to install the Plots package, you would type ] add Plots.","type":"content","url":"/setup#installing-other-packages","position":11},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Packages used in the book","lvl2":"Setting up Julia for this book"},"type":"lvl3","url":"/setup#packages-used-in-the-book","position":12},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Packages used in the book","lvl2":"Setting up Julia for this book"},"content":"In order to avoid repeating low-information code, the book demos are run with a few packages installed and always imported:\n\nFNCFunctions\n\nPrintf, LinearAlgebra (part of the default Julia installation)\n\nPlots, PrettyTables, LaTeXStrings (external packages)\n\nOf the external packages, Plots is essential for the exercises, while the others are used to make the results look nicer in the book.\n\nThroughout the book demos there are other external packages loaded by using as needed. These include:\n\nArpack\n\nBoundaryValueDiffEq\n\nDierckx\n\nFFTW\n\nGraphRecipes\n\nImages\n\nIncompleteLU\n\nIterativeSolvers\n\nJLD2\n\nLinearMaps\n\nMatrixDepot\n\nNLsolve\n\nOrdinaryDiffEq\n\nPolynomials\n\nPreconditioners\n\nQuadGK\n\nSpecialFunctions\n\nTestImages\n\nYou could simply install all of these at once and be done with them; except for the ones dealing with differential equations, they are pretty quick to install.","type":"content","url":"/setup#packages-used-in-the-book","position":13},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Coding environments","lvl2":"Setting up Julia for this book"},"type":"lvl3","url":"/setup#coding-environments","position":14},{"hierarchy":{"lvl1":"Julia setup","lvl3":"Coding environments","lvl2":"Setting up Julia for this book"},"content":"You could interact with Julia only by typing in at the prompt (also called the REPL) and then pasting the results into a word processor, but you can do much, much better. The most popular ways to use Julia are:\n\nJupyter lab. This is a notebook-based interface that mixes cells having text and code, including text and graphical output. This entire book is based on the notebook architecture. You write and run code within your web browser, but the files are local.\n\nVS Code. This is a full-featured code editor that can be extended with \n\nJulia-specific tools. It can also write and run Jupyter notebooks. This book (the version you are reading now, anyway) was written in VS Code.","type":"content","url":"/setup#coding-environments","position":15},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1-1","position":0},{"hierarchy":{"lvl1":"Chapter 1"},"content":"","type":"content","url":"/chapter1-1","position":1},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"type":"lvl2","url":"/chapter1-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"content":"Horner’s algorithm for evaluating a polynomial\n\nfunction y = horner(c,x)\r\n% HORNER   Evaluate a polynomial using Horner's rule. \r\n% Input:\r\n%   c     Coefficients of polynomial, in descending order (vector)\r\n%   x     Evaluation point (scalar)\r\n% Output:\r\n%   y     Value of the polynomial at x (scalar)\r\n\r\nn = length(c);\r\ny = c(1);\r\nfor k = 2:n\r\n  y = x*y + c(k);\r\nend","type":"content","url":"/chapter1-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"type":"lvl2","url":"/chapter1-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter1-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.1 Floating-point numbers","lvl2":"Examples"},"type":"lvl3","url":"/chapter1-1#id-1-1","position":6},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.1 Floating-point numbers","lvl2":"Examples"},"content":"Example 1.1.2\n\nGetting started in MATLAB\n\nSee \n\nSetting up MATLAB for this book for instructions on how to install functions for MATLAB for this book.\n\nRecall the grade-school approximation to the number π.\n\nTip\n\nThe number of digits displayed is controlled by format, but the underlying values are not affected by it.\n\nformat long\np = 22/7\n\nNot all the digits displayed for p are the same as those of π.\n\nTip\n\nThe value of pi is predefined.\n\nThe absolute and relative accuracies of the approximation are as follows.\n\nabs_accuracy = abs(p - pi)\nrel_accuracy = abs(p - pi) / pi\n\nHere we calculate the number of accurate digits in p.\n\nTip\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nformat short\naccurate_digits = -log10(rel_accuracy)\n\nExample 1.1.3\n\nIn MATLAB, values are double-precision floats unless declared otherwise.\n\nfprintf('1 has type: %s', class(1))\nfprintf('1.0 has type: %s', class(1.0))\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon. Its value is predefined as eps.\n\nTip\n\nWhile you can assign a different value to eps, doing so does not change any arithmetic. It’s generally a bad idea.\n\neps\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nlog2(eps)\n\nThe spacing between adjacent floating-point values is proportional to the magnitude of the value itself. This is how relative precision is kept roughly constant throughout the range of values. You can get the adjusted spacing by calling eps with a value.\n\neps(1.618)\n\neps(161.8)\n\nx = 161.8 + 0.1*eps(161.8);\nx - 161.8\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the mantissa. The actual range of positive values in double precision is\n\nformat short e\n[realmin, realmax]\n\nExample 1.1.4\n\nThere is no double-precision number between 1 and 1+\\epsilon_\\text{mach}. Thus the following difference is zero despite its appearance.\n\n( 1 + eps / 2 ) - 1\n\nHowever, the spacing between floats in [1/2,1) is \\macheps/2, so both 1-\\macheps/2 and its negative are represented exactly:\n\n1 - (1 - eps / 2)\n\nThis is now the expected result. But we have found a rather shocking breakdown of the associative law of addition!","type":"content","url":"/chapter1-1#id-1-1","position":7},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.2 Problems and conditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter1-1#id-1-2","position":8},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.2 Problems and conditioning","lvl2":"Examples"},"content":"Example 1.2.5\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nep = 1e-6;\na = 1/3;             % coefficients of p...\nb = (-2 - ep) / 3;   % ...\nc = (1 + ep) / 3;    % ...in ascending order\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b^2 - 4*a*c);\nformat long   % show all digits\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative errors are\n\nTip\n\nPutting values inside square brackets creates a vector.\n\nformat short e\nerr = abs(r1 - 1) ./ abs(1)\nerr = abs(r2 - (1 + ep)) ./ abs(1 + ep)\n\nThe condition number of each root is\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}.\n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\neps / ep\n\nThis matches the observation pretty well.","type":"content","url":"/chapter1-1#id-1-2","position":9},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.3 Algorithms","lvl2":"Examples"},"type":"lvl3","url":"/chapter1-1#id-1-3","position":10},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.3 Algorithms","lvl2":"Examples"},"content":"Example 1.3.2\n\nHere we show how to use \n\nFunction 1.3.1 to evaluate a polynomial. Let us define a vector of the coefficients of p(x)=(x-1)^3=x^3-3x^2+3x-1, in ascending degree order.\n\nc = [1, -3, 3, 1]\n\nNow we evaluate p(1.6) using the function horner.\n\nhorner(c, 1.6)\n\nThe result above is the value of p(1.6).\n\nTip\n\nThe comments at the start of \n\nFunction 1.3.1 are documentation, which we can access using help horner.","type":"content","url":"/chapter1-1#id-1-3","position":11},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.4 Stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter1-1#id-1-4","position":12},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.4 Stability","lvl2":"Examples"},"content":"Example 1.4.1\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nTip\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23 * 10^4.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a)\nx2 = (-b - sqrt(b^2 - 4*a*c)) / (2*a)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(x2 - 1e-6) / 1e-6 \naccurate_digits = -log10(error)\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nExample 1.4.2\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b^2 - 4*a*c)) / (2*a);\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a*x1)\n\nThis matches the exact root to the displayed digits; to be sure we have an accurate result, we compute its relative error.\n\nabs(x2 - 1e-6) / 1e-6\n\nExample 1.4.3\n\nOur first step is to construct a polynomial with six known roots.\n\nTip\n\nThe ' operator is used for transposition. Here, we want to make r a column vector.\n\nr = [-2 ,-1, 1, 1, 3, 6]';\np = poly(r)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nrr = sort(roots(p))\n\nHere are the relative errors in each of the computed roots.\n\nTip\n\nThe ./ operator is used for element-wise division.\n\ndisp(\"Root errors:\") \nabs(r - rr) ./ r\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\npp = poly(rr)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\ndisp(\"Coefficient errors:\") \nabs(p - pp) ./ abs(p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.","type":"content","url":"/chapter1-1#id-1-4","position":13},{"hierarchy":{"lvl1":"Chapter 10"},"type":"lvl1","url":"/chapter10-1","position":0},{"hierarchy":{"lvl1":"Chapter 10"},"content":"","type":"content","url":"/chapter10-1","position":1},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Functions"},"type":"lvl2","url":"/chapter10-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Functions"},"content":"Shooting method for a two-point boundary-value problem\n\nfunction [x, u, du_dx] = shoot(phi, a, b, ga, gb, init, tol)\r\n%SHOOT   Shooting method for a two-point boundary-value problem.\r\n% Input:\r\n%   phi      defines u'' = phi(x, u, u') (function)\r\n%   a, b     endpoints of the domain (scalars)\r\n%   ga       residual boundary function of u(a), u'(a) \r\n%   gb       residual boundary function of u(b), u'(b) \r\n%   init     initial guess for u(a) and u'(a) (column vector)\r\n%   tol      error tolerance (scalar)\r\n% Output:\r\n%   x        nodes in x (length n+1)\r\n%   u        values of u(x)  (length n+1)\r\n%   du_dx    values of u'(x) (length n+1)\r\n\r\n% To be solved by the IVP solver\r\nfunction f = shootivp(x, y)\r\n  f = [ y(2); phi(x, y(1), y(2)) ];\r\nend\r\n\r\nivp = ode(ODEFcn=@shootivp);\r\nivp.InitialTime = a;\r\nivp.AbsoluteTolerance = tol / 10;\r\nivp.RelativeTolerance = tol / 10;\r\n\r\n% To be solved by levenberg\r\nfunction residual = objective(s)\r\n  ivp.InitialValue = s;\r\n  sol = solve(ivp, a, b);\r\n  x = sol.Time;  y = sol.Solution;\r\n  residual = [ga(y(1, 1), y(2, 1)); gb(y(1, end), y(2, end))];\r\nend\r\n\r\ny = [];    % shared variable\r\ns = levenberg(@objective, init, tol);\r\n\r\n% Don't need to solve the IVP again. It was done within the\r\n% objective function already.\r\nu = y(1, :);            % solution     \r\ndu_dx = y(2, :);         % derivative\r\n\r\nend\n\nSecond-order differentiation matrices\n\nfunction [x,Dx,Dxx] = diffmat2(n,xspan)\n%DIFFMAT2   Second-order accurate differentiation matrices.\n% Input:\n%   n       number of subintervals (one less than the number of nodes)\n%   xspan   interval endpoints\n% Output:\n%   x       equispaced nodes\n%   Dx      matrix for first derivative \n%   Dxx     matrix for second derivative \n\na = xspan(1);  b = xspan(2);\nh = (b-a)/n;\nx = a + h*(0:n)';   % nodes\n\n% Define most of Dx by its diagonals.\ndp = 0.5*ones(n,1)/h;       % superdiagonal\ndm = -0.5*ones(n,1)/h;      % subdiagonal\nDx = diag(dm,-1) + diag(dp,1);\n\n% Fix first and last rows.\nDx(1,1:3) = [-1.5,2,-0.5]/h;\nDx(n+1,n-1:n+1) = [0.5,-2,1.5]/h;\n\n% Define most of Dxx by its diagonals.\nd0 =  -2*ones(n+1,1)/h^2;   % main diagonal\ndp =  ones(n,1)/h^2;        % superdiagonal and subdiagonal\nDxx = diag(dp,-1) + diag(d0) + diag(dp,1);\n\n% Fix first and last rows.\nDxx(1,1:4) = [2,-5,4,-1]/h^2;\nDxx(n+1,n-2:n+1) = [-1,4,-5,2]/h^2;\n    \n\nChebyshev differentiation matrices\n\nfunction [x,Dx,Dxx] = diffcheb(n,xspan)\n%DIFFCHEB   Chebyshev differentiation matrices.\n% Input:\n%   n      number of subintervals (integer)\n%   xspan  interval endpoints (vector)\n% Output:\n%   x      Chebyshev nodes in domain (length n+1)\n%   Dx     matrix for first derivative (n+1 by n+1)\n%   Dxx    matrix for second derivative (n+1 by n+1)\n\nx = -cos( (0:n)'*pi/n );    % nodes in [-1,1]\nDx = zeros(n+1);\nc = [2; ones(n-1,1); 2];    % endpoint factors\ni = (0:n)';                 % row indices\n\n% Off-diagonal entries\nfor j = 0:n\n  num = c(i+1).*(-1).^(i+j);\n  den = c(j+1)*(x-x(j+1));\n  Dx(:,j+1) = num./den;\nend\n\n% Diagonal entries\nDx(isinf(Dx)) = 0;          % fix divisions by zero on diagonal\nDx = Dx - diag(sum(Dx,2));  % \"negative sum trick\" \n  \n% Transplant to [a,b]\na = xspan(1);  b = xspan(2);\nx = a + (b-a)*(x+1)/2;\nDx = 2*Dx/(b-a);\n\n% Second derivative\nDxx = Dx^2;\n\nSolution of a linear boundary-value problem\n\nfunction [x, u] = bvplin(p, q, r, a, b, ua, ub,n)\r\n% BVPLIN   Solve a linear boundary-value problem.\r\n% Input:\r\n%   p, q, r  u'' + pu' + qu = r (functions)\r\n%   a, b     endpoints of the domain (scalars)\r\n%   ua       value of u(a)\r\n%   ub       value of u(b)\r\n%   n        number of subintervals (integer)\r\n% Output:\r\n%   x       collocation nodes (vector, length n+1)\r\n%   u       solution at nodes (vector, length n+1)\r\n\r\n[x, Dx, Dxx] = diffmat2(n, [a, b]);\r\n\r\nP = diag(p(x));\r\nQ = diag(q(x));\r\nL = Dxx + P * Dx + Q;    % ODE expressed at the nodes\r\nr = r(x);    \r\n\r\n% Replace first and last rows using boundary conditions. \r\nI = speye(n+1); \r\nA = [ I(:, 1)'; L(2:n, :); I(:, n+1)' ];\r\n\r\nf = [ ua; r(2:n); ub ];\r\n\r\n% Solve the system.\r\nu = A \\ f;\n\nSolution of a nonlinear boundary-value problem\n\n  function [x,u] = bvp(phi, a, b, ga, gb, init)\n%BVP      Solve a boundary-value problem by finite differences\n%         with either Dirichlet or Neumann BCs.\n% Input:\n%   phi      defines u'' = phi(x,u,u') (function)\n%   a, b     endpoints of the domain (scalars)\n%   ga       residual boundary function of u(a), u'(a) \n%   gb       residual boundary function of u(b), u'(b) \n%   init     initial guess for the solution (length n+1 vector)\n% Output:\n%   x        nodes in x (vector, length n+1)\n%   u        values of u(x)  (vector, length n+1)\n%   res      function for computing the residual\n\nn = length(init) - 1;\n[x, Dx, Dxx] = diffmat2(n, [a, b]);\nh = x(2) - x(1);\n\nu = levenberg(@residual, init);\nu = u(:, end);\n\n    function f = residual(u)\n        % Computes the difference between u'' and phi(x,u,u') at the\n        % interior nodes and appends the error at the boundaries. \n        du_dx = Dx*u;                   % discrete u'\n        d2u_dx2 = Dxx*u;                % discrete u''\n        f = d2u_dx2 - phi(x,u,du_dx);\n        \n        % Replace first and last values by boundary conditions.\n        f(1) =   ga(  u(1),   du_dx(1)) / h;\n        f(end) = gb(u(end), du_dx(end)) / h;\n    end\n\nend\n\nPiecewise linear finite elements for a linear BVP\n\nfunction [x,u] = fem(c,s,f,a,b,n)\r\n%FEM     Piecewise linear finite elements for a linear BVP.\r\n% Input:\r\n%   c,s,f    coefficient functions of x describing the ODE (functions) \r\n%   a,b      domain of the independent variable (scalars)\r\n%   n        number of grid subintervals (scalar) \r\n% Output:\r\n%   x        grid points (vector, length n+1)\r\n%   u        solution values at x (vector, length n+1)\r\n\r\n% Define the grid.\r\nh = (b-a)/n;\r\nx = a + h*(0:n)';  \r\n\r\n% Templates for the subinterval matrix and vector contributions.\r\nKe = [1 -1; -1 1];\r\nMe = (1/6)*[2 1; 1 2];\r\nfe = (1/2)*[1; 1];\r\n\r\n% Evaluate coefficent functions and find average values.\r\ncval = c(x);   cbar = (cval(1:n)+cval(2:n+1)) / 2;\r\nsval = s(x);   sbar = (sval(1:n)+sval(2:n+1)) / 2;\r\nfval = f(x);   fbar = (fval(1:n)+fval(2:n+1)) / 2;\r\n\r\n% Assemble global system, one interval at a time.\r\nK = zeros(n-1,n-1);  M = zeros(n-1,n-1);  f = zeros(n-1,1);\r\nK(1,1) = cbar(1)/h;  M(1,1) = sbar(1)*h/3;  f(1) = fbar(1)*h/2;\r\nK(n-1,n-1) = cbar(n)/h;  M(n-1,n-1) = sbar(n)*h/3;  f(n-1) = fbar(n)*h/2;\r\nfor k = 2:n-1\r\n  K(k-1:k,k-1:k) = K(k-1:k,k-1:k) + (cbar(k)/h) * Ke;\r\n  M(k-1:k,k-1:k) = M(k-1:k,k-1:k) + (sbar(k)*h) * Me;\r\n  f(k-1:k) = f(k-1:k) + (fbar(k)*h) * fe;\r\nend  \r\n\r\n% Solve system for the interior values.\r\nu = (K+M) \\ f;\r\nu = [0; u; 0];      % put the boundary values into the result","type":"content","url":"/chapter10-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Examples"},"type":"lvl2","url":"/chapter10-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter10-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.1 Two-point BVP","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-1#id-10-1","position":6},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.1 Two-point BVP","lvl2":"Examples"},"content":"Example 10.1.3\n\nTo define the BVP, we need to define some functions. (For this simple problem, we will use anonymous functions, but for a more substantial one, it would be better to use separate files.) The first defines \\mathbf{f}(x, \\mathbf{y}).\n\nlambda = 0.6;\nbvpfcn = @(r, y) [ y(2); lambda / y(1)^2 - y(2) / r  ];    % column vector\n\nOur second function defines the boundary conditions. It takes \\mathbf{y}(a) and \\mathbf{y}(b) as arguments and returns a vector of residuals; i.e., values that should be zero when the boundary conditions are satisfied.\n\nbcfcn = @(ya, yb) [ ya(2); yb(1) - 1 ];    % y_2(a) = 0;  y_1(b) = 1\n\nThe third function we define isn’t part of the mathematical formulation. Rather, it provides an initial guess for the solution. Here we choose both components to be constant.\n\ny_init = @(r) [ 1; 0 ];\n\nNow we can solve the BVP using the bvp4c function. We need to specify the nodes on which to solve the problem. The domain of the mathematical problem is r\\in [0,1].But since there is a division by r in the ODE, we want to avoid r=0 by truncating the domain a tiny bit.\n\nnodes = linspace(eps, 1, 61);\nsol_init = bvpinit(nodes, y_init);\nsol = bvp4c(bvpfcn, bcfcn, sol_init);\nplot(sol.x, sol.y, '-o')\nxlabel('r'), ylabel('y(r)')\ntitle('Solution of the membrane problem')\nlegend(\"w(r)\", \"w'(r)\", location=\"east\");\n\nIt’s smart to check visually that the boundary conditions are satisfied.","type":"content","url":"/chapter10-1#id-10-1","position":7},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.2 Shooting","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-1#id-10-2","position":8},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.2 Shooting","lvl2":"Examples"},"content":"Example 10.2.1\n\nLet’s first examine the shooting approach for the TPBVP from \n\nExample 10.1.2 with \\lambda=0.6.\n\nlambda = 0.6;\nphi = @(r, w, dwdr) lambda ./ w.^2 - dwdr ./ r;\n\nWe convert the ODE to a first-order system in order to apply a numerical method. We also have to truncate the domain to avoid division by zero.\n\nf = @(r, w) [ w(2); phi(r, w(1), w(2)) ];\na = eps;  b = 1;\n\nThe BVP specifies w'(0)=y_2(0)=0. We can try multiple values for the unknown w(0)=y_1(0) and plot the solutions.\n\nclf\nivp = ode;\nivp.ODEFcn = f;\nivp.InitialTime = a;\nfor w0 = 0.4:0.1:0.9\n    ivp.InitialValue = [w0; 0];\n    sol = solve(ivp, a, b);\n    plot(sol.Time, sol.Solution(1, :))\n    hold on\nend\nxlabel('r'),  ylabel('w(r)')\ntitle('Solutions for multiple choices of w(0)')\n\nOn the graph, it’s the curve starting at w(0)=0.8 that comes closest to the required condition w(1)=1, but it’s a bit too large.\n\nExample 10.2.2\n\nWe revisit \n\nDemo 10.2.1 but let \n\nFunction 10.2.1 do the heavy lifting.\n\nlambda = 0.6;\nphi = @(r, w, dwdr) lambda ./ w.^2 - dwdr ./ r;   \na = eps;  b = 1;    % avoid r=0 in denominator\n\nWe specify the given and unknown endpoint values.\n\nga = @(u, du) du;\ngb = @(u, du) u - 1;\n\ninit = [0.8; 0];    % initial guess for u(a) and u'(a)\n[r, w, dwdx] = shoot(phi, a, b, ga, gb, init, 1e-5);\nclf,  plot(r, w)\ntitle('Correct solution')\nxlabel('r'),  ylabel('w(r)')\n\nThe value of w at r=1, meant to be exactly one, was computed to be\n\nformat long\nw(end)\n\nThe accuracy is consistent with the error tolerance used for the IVP solution. The initial value w(0) that gave this solution is\n\nw(1)\n\nExample 10.2.3\n\nga = @(u, du) u + 1;\ngb = @(u, du) u;\nclf\nwarning off\nfor lambda = 16:4:28\n    phi = @(x, u, du_dx) lambda^2 * (u + 1);\n    [x, u, du_dx] = shoot(phi, 0.0, 1.0, ga, gb, [-1; 0], 1e-8);\n    plot(x, u, displayname=sprintf(\"lambda=%d\", lambda))\n    hold on\n    xlabel('x'),  ylabel('u(x)')\n    title('Shooting instability')\n    legend(location=\"northwest\");\nend\n\nThe numerical solution fails at the largest value of λ because the initial condition became infinite.","type":"content","url":"/chapter10-1#id-10-2","position":9},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.3 Differentiation matrices","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-1#id-10-3","position":10},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.3 Differentiation matrices","lvl2":"Examples"},"content":"Example 10.3.1\n\nWe test first-order and second-order differentiation matrices for the function x + \\exp(\\sin 4x) over [-1,1].\n\nf = @(x) x + exp(sin(4*x));\n\nFor reference, here are the exact first and second derivatives.\n\ndf_dx = @(x) 1 + 4 * exp(sin(4*x)) .* cos(4*x);\nd2f_dx2 = @(x) 4 * exp(sin(4*x)) .* (4*cos(4*x).^2 - 4*sin(4*x));\n\nWe discretize on equally spaced nodes and evaluate f at the nodes.\n\n[t, Dx, Dxx] = diffmat2(12, [-1 1]);\ny = f(t);\n\nThen the first two derivatives of f each require one matrix-vector multiplication.\n\nyx = Dx * y;\nyxx = Dxx * y;\n\nThe results show poor accuracy for this small value of n.\n\nclf,  subplot(2, 1, 1)\nfplot(df_dx, [-1, 1]),  hold on\nplot(t, yx, 'ko')\nxlabel('x'),  ylabel('f''(x)')\nsubplot(2, 1, 2)\nfplot(d2f_dx2, [-1, 1]),  hold on\nplot(t, yxx, 'ko')\nxlabel('x'),  ylabel('f''''(x)')\n\nAn convergence experiment confirms the order of accuracy. Because we expect an algebraic convergence rate, we use a log-log plot of the errors.\n\nn = round( 2 .^ (4:.5:11)' );\nerr = zeros(length(n), 2);\nfor k = 1:length(n)\n    [t, Dx, Dxx] = diffmat2(n(k), [-1, 1]);\n    y = f(t);\n    err(k, 1) = norm(df_dx(t) - Dx * y, Inf);\n    err(k, 2) = norm(d2f_dx2(t) - Dxx * y, Inf);\nend\nclf\nloglog(n, err, 'o-'), hold on\nloglog(n, 100 * n.^(-2), 'k--')\nlegend(\"f'\", \"f''\", '2nd order')\nxlabel('n'),  ylabel('max error')\ntitle('Convergence of finite differences')\n\nExample 10.3.2\n\nHere is a 4\\times 4 Chebyshev differentiation matrix.\n\n[t, Dx] = diffcheb(3, [-1, 1]);\nformat rat\nDx\n\nWe again test the convergence rate.\n\nf = @(x) x + exp(sin(4*x));\ndf_dx = @(x) 1 + 4 * exp(sin(4*x)) .* cos(4*x);\nd2f_dx2 = @(x) 4 * exp(sin(4*x)) .* (4*cos(4*x).^2 - 4*sin(4*x));\n\nn = 5:5:70;\nerr = zeros(length(n), 2);\nfor k = 1:length(n)\n    [t, Dx, Dxx] = diffcheb(n(k), [-1, 1]);\n    y = f(t);\n    err(k, 1) = norm(df_dx(t) - Dx * y, Inf);\n    err(k, 2) = norm(d2f_dx2(t) - Dxx * y, Inf);\nend\n\nSince we expect a spectral convergence rate, we use a semi-log plot for the error.\n\nclf,  format\nsemilogy(n, err, 'o-'), hold on\nlegend(\"f'\", \"f''\")\nxlabel('n'),  ylabel('max error')\ntitle('Convergence of finite differences')","type":"content","url":"/chapter10-1#id-10-3","position":11},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.4 Collocation for linear problems","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-1#id-10-4","position":12},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.4 Collocation for linear problems","lvl2":"Examples"},"content":"Example 10.4.1\n\nexact = @(x) exp(sin(x));\n\nThe problem is presented above in our standard form, so we can identify the coefficient functions in the ODE. Each should be coded as a function.\n\np = @(x) -cos(x);\nq = @(x) sin(x);\nr = @(x) 0*x;      % not a scalar\n\nWe solve the BVP and compare the result to the exact solution.\n\n[x, u] = bvplin(p, q, r, 0, 3*pi/2, 1, exp(-1), 30);\n\nclf,  subplot(2, 1, 1)\nplot(x, u)\nylabel('solution')\ntitle('Solution of a linear BVP')\nsubplot(2, 1, 2)\nplot(x, exact(x) - u, 'o-')\nylabel('error')\n\nExample 10.4.2\n\nlambda = 10;\nexact = @(x) sinh(lambda * x) / sinh(lambda) - 1;\n\nThe following functions define the ODE.\n\np = @(x) zeros(size(x));            \nq = @(x) -lambda^2 * ones(size(x));\nr = @(x) lambda^2 * ones(size(x));\n\nWe compare the computed solution to the exact one for increasing n.\n\np = @(x) zeros(size(x));            \nq = @(x) -lambda^2 * ones(size(x));\nr = @(x) lambda^2 * ones(size(x));\nn = 2 * round(10.^(1:0.25:3)');\nerr = zeros(size(n));\nfor k = 1:length(n)\n    [x, u] = bvplin(p, q, r, 0, 1, -1, 0, n(k));\n    err(k) = norm(exact(x) - u, Inf);\nend\ntable(n, err, variableNames = [\"n\", \"inf-norm error\"])\n\nEach factor of 10 in n reduces error by a factor of 100, which is indicative of second-order convergence.\n\nclf,  loglog(n, err, 'o-')\nhold on, loglog(n, n.^(-2), 'k--')\nxlabel('n'),  ylabel('max error')\ntitle('Convergence for a linear BVP') \nlegend('obs. error', '2nd order')","type":"content","url":"/chapter10-1#id-10-4","position":13},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.5 Nonlinearity and boundary conditions","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-1#id-10-5","position":14},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.5 Nonlinearity and boundary conditions","lvl2":"Examples"},"content":"Example 10.5.2\n\nSuppose a damped pendulum satisfies the nonlinear equation \\theta'' + 0.05\\theta'+\\sin \\theta =0. We want to start the pendulum at \\theta=2.5 and give it the right initial velocity so that it reaches \\theta=-2 at exactly t=5. This is a boundary-value problem with Dirichlet conditions \\theta(0)=2.5 and \\theta(5)=-2.\n\nThe first step is to define the function ϕ that equals \\theta''.\n\nphi = @(t,theta,omega) -0.05 * omega - sin(theta);\n\nNext, we define the boundary conditions.\n\nga = @(u, du) u - 2.5;\ngb = @(u, du) u + 2;\n\nThe last ingredient is an initial estimate of the solution. Here we choose n=100 and a linear function between the endpoint values.\n\ninit = linspace(2.5, -2, 101)';\n\nWe find a solution with negative initial slope, i.e., the pendulum is initially pushed back toward equilibrium.\n\n[t, theta] = bvp(phi, 0, 5, ga, gb, init);\nclf,  plot(t, theta)\nxlabel('t'),  ylabel('\\theta(t)')\ntitle('Pendulum over [0,5]')\n\nIf we extend the time interval longer for the same boundary values, then the initial slope must adjust.\n\n[t, theta] = bvp(phi, 0, 8, ga, gb, init);\nplot(t,theta)\nxlabel('t'),  ylabel('\\theta(t)')\ntitle('Pendulum over [0,8]')\n\nThis time, the pendulum is initially pushed toward the unstable equilibrium in the upright vertical position before gravity pulls it back down.\n\nExample 10.5.3\n\nHere is the problem definition. We use a truncated domain to avoid division by zero at r=0.\n\nlambda = 0.5;\nphi = @(r,w,dwdr) lambda./w.^2 - dwdr./r;\nga = @(w, dw) dw;\ngb = @(w, dw) w - 1;\na = eps;  b = 1;\n\nFirst we try a constant function as the initialization.\n\ninit = ones(301, 1);\n[r, w1] = bvp(phi, a, b, ga, gb, init);\n\nclf,  plot(r, w1)\nxlabel('r'),  ylabel('w(r)')\ntitle('Solution of the MEMS BVP')\n\nIt’s not necessary that the initialization satisfy the boundary conditions. In fact, by choosing a different constant function as the initial guess, we arrive at another valid solution.\n\ninit = 0.5 * ones(301, 1);\n[r, w2] = bvp(phi, a, b, ga, gb, init);\nhold on,  plot(r, w2)\ntitle(\"Two solutions of the MEMS BVP\")\n\nExample 10.5.4\n\nepsilon = 0.05;\nphi = @(x, u, du_dx) (u.^3 - u) / epsilon;\nga = @(u, du) du;\ngb = @(u, du) u - 1;\n\nFinding a solution is easy at larger values of ε.\n\ninit = linspace(-1, 1, 141)';\n[x, u1] = bvp(phi, 0, 1, ga, gb, init);\nclf,  plot(x, u1, displayname=\"\\epsilon = 0.05\")\nxlabel('x'),  ylabel('u(x)')\ntitle('Allen-Cahn solution') \nlegend(location=\"northwest\")\n\nHowever, finding a good initialization is not trivial for smaller values of ε. Note below that the iteration stops without converging to a solution.\n\nepsilon = 0.002;\nphi = @(x, u, du_dx) (u.^3 - u) / epsilon;\n[x, z] = bvp(phi, 0, 1, ga, gb, init);\n\nThe iteration succeeds if we use the first solution instead as the initialization here.\n\n[x, u2] = bvp(phi, 0, 1, ga, gb, u1);\nhold on,  plot(x, u2, displayname=\"\\epsilon = 0.002\")\n\nIn this case we can continue further.\n\nepsilon = 0.0005;\nphi = @(x, u, du_dx) (u.^3 - u) / epsilon;\n[x, u3] = bvp(phi, 0, 1, ga, gb, u2);\nplot(x, u3, displayname=\"\\epsilon = 0.0005\")","type":"content","url":"/chapter10-1#id-10-5","position":15},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.6 The Galerkin method","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-1#id-10-6","position":16},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.6 The Galerkin method","lvl2":"Examples"},"content":"Example 10.6.2\n\nHere are the coefficient function definitions. Even though s is a constant, it has to be defined as a function for \n\nFunction 10.6.1 to use it.\n\nc = @(x) x.^2;\nq = @(x) 4 * ones(size(x));\nf = @(x) sin(pi * x);\n\n[x,u] = fem(c, q, f, 0, 1, 50);\nclf,  plot(x, u)\nxlabel('x'),  ylabel('u')\ntitle('Solution by finite elements')","type":"content","url":"/chapter10-1#id-10-6","position":17},{"hierarchy":{"lvl1":"Chapter 11"},"type":"lvl1","url":"/chapter11-1","position":0},{"hierarchy":{"lvl1":"Chapter 11"},"content":"","type":"content","url":"/chapter11-1","position":1},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Functions"},"type":"lvl2","url":"/chapter11-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Functions"},"content":"Differentiation matrices for periodic end conditions\n\nfunction [x,Dx,Dxx] = diffper(n,xspan)\n%DIFFPER   Differentiation matrices for periodic end conditions. \n% Input:\n%   n      number of subintervals (integer)\n%   xspan  endpoints of domain (vector)\n% Output:\n%   x    equispaced nodes (length n)\n%   Dx   matrix for first derivative (n by n)\n%   Dxx  matrix for second derivative (n by n)\n\na = xspan(1);  b = xspan(2);\nh = (b-a)/n;\nx = a + h*(0:n-1)';   % nodes, omitting the repeated data\n\n% Construct Dx by diagonals, then correct the corners.\ndp = 0.5*ones(n-1,1)/h;      % superdiagonal\ndm = -0.5*ones(n-1,1)/h;     % subdiagonal\nDx = diag(dm,-1) + diag(dp,1);\nDx(1,n) = -1/(2*h);\nDx(n,1) = 1/(2*h);\n\n% Construct Dxx by diagonals, then correct the corners.\nd0 =  -2*ones(n,1)/h^2;      % main diagonal\ndp =  ones(n-1,1)/h^2;       % superdiagonal\ndm =  dp;                    % subdiagonal\nDxx = diag(dm,-1) + diag(d0) + diag(dp,1);\nDxx(1,n) = 1/(h^2);\nDxx(n,1) = 1/(h^2);\n    \n\nSolution of parabolic PDEs by the method of lines\n\nfunction [x, u] = parabolic(phi, xspan, m, ga, gb, tspan, init)\n% PARABOLIC   Solve parabolic PDE by the method of lines.\n% Input:\n%   phi      defines ∂u/∂t = phi(t, x, u, ∂u/∂x, ∂^2u/∂x^2) \n%   xspan    spatial domain\n%   m        number of spatial nodes\n%   ga, gb   boundary conditions as functions of u and ∂u/∂x\n%   tspan    time interval\n%   init     initial condition as a function of x\n% Output:       \n%   x        spatial nodes (vector)\n%   u        function for the solution u(t) at nodes\n\n    [x, Dx, Dxx] = diffcheb(m, xspan);\n    int = 2:m;    % indexes of interior nodes\n\n    function u = extend(v)\n        function residual = objective(ubc)\n            ua = ubc(1);  ub = ubc(2);\n            ux = Dx * [ua; v; ub];\n            residual = [ga(ua, ux(1)); gb(ub, ux(end))];\n        end\n        ubc = levenberg(@objective, [0, 0]);\n        ubc = ubc(:, end);\n        u = [ubc(1); v; ubc(2)];\n    end\n\n    function f = mol_ode(t, v, p)\n        u = extend(v);\n        ux = Dx * u;\n        uxx = Dxx * u;\n        f = phi(t, x(int), u(int), ux(int), uxx(int));\n    end\n\n    ivp = ode(ODEFcn=@mol_ode);\n    ivp.InitialTime = tspan(1);\n    ivp.InitialValue = init(x(int));\n    ivp.Solver = \"stiff\";\n    sol = solutionFcn(ivp, tspan(1), tspan(2));\n    u = @(t) extend(sol(t));\nend","type":"content","url":"/chapter11-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Examples"},"type":"lvl2","url":"/chapter11-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter11-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.1 Black–Scholes equation","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-1#id-11-1","position":6},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.1 Black–Scholes equation","lvl2":"Examples"},"content":"Example 11.1.2\n\nWe consider the Black–Scholes problem for the following parameter values:\n\nSmax = 8;  T = 6;\nK = 3;  sigma = 0.06;  r = 0.08;\n\nWe discretize space and time.\n\nm = 200;  h = Smax / m;\nx = h * (0:m)';\nn = 1000;  tau = T / n;\nt = tau * (0:n)';\nlambda = tau / h^2;  mu = tau / h;\n\nWe set the initial condition and then march forward in time.\n\nV = zeros(m+1, n+1);\nV(:, 1) = max(0, x-K);\nfor j = 1:n\n    % Fictitious value from Neumann condition.\n    Vfict = 2*h + V(m, j);\n    Vj = [ V(:, j); Vfict ];\n    % First row is zero by the Dirichlet condition.\n    for i = 2:m+1 \n        diff1 = (Vj(i+1) - Vj(i-1));\n        diff2 = (Vj(i+1) - 2*Vj(i) + Vj(i-1));\n        V(i, j+1) = Vj(i) ...\n            + (lambda * sigma^2* x(i)^2/2) * diff2  ...\n            + (r*mu * x(i))/2 * diff1 - r*tau * Vj(i);\n    end \nend\n\nHere is a plot of the solution after every 250 time steps.\n\nindex_times = 1:250:n+1;\nshow_times = t(index_times);\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2f\", t(j));\n    plot(x, V(:, j), displayname=str) \n    hold on\nend\ntitle('Black-Scholes solution')\nxlabel('stock price'),  ylabel('option value')\naxis tight,  grid on\nlegend(location=\"northwest\")\n\nAlternatively, here is an animation of the solution.\n\nclf\nplot(x, V(:,1))\nhold on,  grid on\naxis([0, 8, 0, 6])\ntitle('Black-Scholes solution') \nxlabel('stock price'),  ylabel('option value')\nvid = VideoWriter(\"figures/black-scholes-6.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid)\nfor frame = 1:10:n+1\n    cla, plot(x, V(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.4, 5.2, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThe results are easy to interpret, recalling that the time variable really means time until strike. Say you are close to the option’s strike time. If the current stock price is, say, S=2, then it’s not likely that the stock will end up over the strike price K=3, and therefore the option has little value. On the other hand, if presently S=3, then there are good odds that the option will be exercised at the strike time, and you will need to pay a substantial portion of the stock price in order to take advantage. As the time to strike increases, there is an expectation that the stock price is more likely to rise somewhat, making the value of the option larger at each fixed S.\n\nExample 11.1.3\n\nLet’s try to do everything the same as in \n\nDemo 11.1.2, but extending the simulation time to T=8.\n\nT = 8;\nn = 1000;  tau = T / n;\nt = tau*(0:n)';\nlambda = tau / h^2;  mu = tau / h;\nfor j = 1:n\n    % Fictitious value from Neumann condition.\n    Vfict = 2*h + V(m,j);\n    Vj = [ V(:,j); Vfict ];\n    % First row is zero by the Dirichlet condition.\n    for i = 2:m+1 \n        diff1 = (Vj(i+1) - Vj(i-1));\n        diff2 = (Vj(i+1) - 2*Vj(i) + Vj(i-1));\n        V(i,j+1) = Vj(i) ...\n             + (lambda*sigma^2 * x(i)^2/2) * diff2  ...\n             + (r*mu * x(i))/2 * diff1 - r*tau * Vj(i);\n    end   \nend\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2f\", t(j));\n    plot(x, V(:, j), displayname=str) \n    hold on\nend\ntitle('Black-Scholes instability')\nxlabel('stock price'),  ylabel('option value')\naxis tight,  grid on\nlegend(location=\"northwest\")\n\nclf\nplot(x, V(:,1))\nhold on,  grid on\naxis([0, 8, 0, 6])\ntitle('Black-Scholes solution...?') \nxlabel('stock price'),  ylabel('option value')\nvid = VideoWriter(\"figures/black-scholes-8.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:10:n+1\n    cla, plot(x, V(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.4, 5.2, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThis so-called solution is nonsense!","type":"content","url":"/chapter11-1#id-11-1","position":7},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.2 The method of lines","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-1#id-11-2","position":8},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.2 The method of lines","lvl2":"Examples"},"content":"Example 11.2.2\n\nLet’s implement the method of \n\nExample 11.2.1 with second-order space semidiscretization.\n\nm = 100;  \n[x, Dx, Dxx] = diffper(m, [0, 1]);\nIx = eye(m);\n\nNext we set an initial condition. It isn’t mathematically periodic, but the end values and derivatives are so small that for numerical purposes it may as well be.\n\ntfinal = 0.15;  n = 2400;  \ntau = tfinal / n;  t = tau * (0:n)';\nU = zeros(m, n+1);\nU(:, 1) = exp( -60*(x - 0.5).^2 );\n\nThe Euler time stepping simply multiplies the solution vector by the constant matrix in \n\n(11.2.6) at each time step. Since that matrix is sparse, we will declare it as such, even though the run-time savings may not be detectable for this small value of m.\n\nA = sparse(Ix + tau * Dxx);\nfor j = 1:n\n    U(:, j+1) = A * U(:,j);\nend\n\nindex_times = 1:10:31;\nshow_times = t(index_times);\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2e\", t(j));\n    plot(x, U(:, j), displayname=str) \n    hold on\nend\nlegend(location=\"northwest\")\nxlabel('x'), ylabel('u(x,t)')\ntitle('Heat equation by forward Euler')\n\nYou see above that things seem to start well, with the initial peak widening and shrinking. But then there is a nonphysical growth in the solution.\n\nclf\nindex_times = 1:101;\nplot(x, U(:, 1))\nhold on,  grid on\naxis([0, 1, -1, 2])\ntitle('Heat equation by forward Euler') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/diffusionFE.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = index_times\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.3f\", t(frame));\n    text(0.05, 0.92, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThe growth in norm is exponential in time.\n\nM = max(abs(U), [], 1);     % max in each column\nclf,  semilogy(t, M)\nxlabel('t'), ylabel('max_x |u(x,t)|') \ntitle('Nonphysical growth')\n\nExample 11.2.4\n\nNow we apply backward Euler to the heat equation. Mathematically this means multiplying by the inverse of a matrix, but we interpret that numerically as a linear system solution. We will reuse the setup from \n\nDemo 11.2.2.\n\nB = sparse(Ix - tau * Dxx);\n[l, u] = lu(B);\nfor j = 1:n\n    U(:, j+1) = u \\ (l \\ U(:, j));\nend\n\nindex_times = 1:600:n+1;\nshow_times = t(index_times);\nclf\nfor j = index_times\n    str = sprintf(\"t = %.2e\", t(j));\n    plot(x, U(:, j), displayname=str) \n    hold on\nend\nlegend(location=\"northwest\")\nxlabel('x'), ylabel('u(x,t)')\ntitle('Heat equation by backward Euler')\n\nclf\nindex_times = 1:24:n+1;\nplot(x, U(:, 1))\nhold on,  grid on\naxis([0, 1, -0.25, 1])\ntitle('Heat equation by backward Euler') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/diffusionBE.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = index_times\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.3f\", t(frame));\n    text(0.05, 0.92, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThis solution looks physically plausible, as the large concentration in the center diffuses outward until the solution is essentially constant. Observe that the solution remains periodic in space for all time.\n\nExample 11.2.5\n\nWe set up the semidiscretization and initial condition in x just as before.\n\nm = 100;  \n[x, Dx, Dxx] = diffper(m, [0, 1]);\nIx = eye(m);\nu0 = exp( -60 * (x - 0.5).^2 );\n\nNow, however, we apply a standard solver using solve_ivp to the initial-value problem \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\ntfinal = 0.05;\nf = @(t, u, p) Dxx * u;\nivp = ode(ODEFcn=f);\nivp.InitialTime = 0;\nivp.InitialValue = u0;\nivp.Solver = 'ode45';\n[u, sol] = solutionFcn(ivp, 0, tfinal);\n\nclf\nfor t = linspace(0, 0.05, 5)\n    str = sprintf(\"t = %.3f\", t);\n    plot(x, u(t), displayname=str)\n    hold on\nend\nxlabel(\"x\"),  ylabel(\"u(x,t)\")\nlegend()\ntitle(\"Heat equation by ode45\")\n\nThe solution appears to be correct. But the number of time steps that were selected automatically is surprisingly large, considering how smoothly the solution changes.\n\ntime_steps_ode45 = length(sol.Time) - 1\n\nNow we apply a different solver called BDF.\n\nivp.Solver = \"ode15s\";\n[u, sol] = solutionFcn(ivp, 0, tfinal);\ntime_steps_ode15s = length(sol.Time) - 1\n\nThe number of steps selected was reduced by a factor of 20!","type":"content","url":"/chapter11-1#id-11-2","position":9},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.3 Absolute stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-1#id-11-3","position":10},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.3 Absolute stability","lvl2":"Examples"},"content":"Example 11.3.5\n\nEuler and Backward Euler time-stepping methods were used to solve \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nm = 40;  \n[x, Dx, Dxx] = diffper(m, [0, 1]);\n\nThe eigenvalues of this matrix are real and negative:\n\nlambda = eig(Dxx);\nclf\nplot(real(lambda), imag(lambda), 'o')\naxis equal, grid on\nxlabel('Re \\lambda'),  ylabel('Im \\lambda')\ntitle('Eigenvalues')\n\nThe Euler method is absolutely stable in the region |\\zeta+1| \\le 1 in the complex plane:\n\nphi = linspace(0, 2*pi, 361);\nz = exp(1i*phi) - 1;   % unit circle shifted to the left by 1\nfill(real(z), imag(z), [.8, .8, 1])\naxis equal,  grid on\nxlabel('Re \\lambda'),  ylabel('Im \\lambda')\ntitle('Stability region')\n\nIn order to get inside this region, we have to find τ such that \\lambda \\tau > -2 for all eigenvalues λ. This is an upper bound on τ.\n\nlambda_min = min(lambda)\nmax_tau = -2 / lambda_min\n\nHere we plot the resulting values of \\zeta=\\lambda \\tau.\n\nzeta = lambda * max_tau;\nhold on\nplot(real(zeta), imag(zeta), 'o')\ntitle('Stability region and \\zeta values')\n\nIn backward Euler, the region is |\\zeta-1|\\ge 1. Because they are all on the negative real axis, all of the ζ values will fit no matter what τ is chosen.\n\nclf,  fill([-6, 6, 6, -6],[-6, -6, 6, 6],[.8, .8, 1])\nhold on\nz = exp(1i*phi) + 1;   % unit circle shifted right by 1\nfill(real(z), imag(z), 'w')\nplot(real(zeta), imag(zeta), 'o')\naxis equal,  axis([-4, 2, -3, 3]), grid on\nxlabel('Re \\lambda'),  ylabel('Im \\lambda')\ntitle('Stability region and \\zeta values')","type":"content","url":"/chapter11-1#id-11-3","position":11},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.4 Stiffness","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-1#id-11-4","position":12},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.4 Stiffness","lvl2":"Examples"},"content":"Example 11.4.2\n\nIn \n\nExample 11.4.1 we derived a Jacobian matrix for the Oregonator model. Here is a numerical solution of the ODE.\n\nq = 8.375e-6;  s = 77.27;  w = 0.161;\nf = @(t, u, p) [ s*(u(2)- u(1) * u(2) + u(1) - q * u(1)^2);...\n    (-u(2) - u(1) * u(2) + u(3)) / s; ...\n    w*(u(1) - u(3)) ];\n\nivp = ode(ODEFcn=f);\nivp.InitialTime = 0;\nivp.InitialValue = [1; 2; 3];\nivp.Solver = \"ode15s\";\nsol = solve(ivp, 0, 500); \nclf,  semilogy(sol.Time, sol.Solution)\nxlabel('t'),  ylabel('u(t)')\ntitle('Oregonator')\n\nAt each value of the numerical solution, we can compute the eigenvalues of the Jacobian. Here we plot all of those eigenvalues in the complex plane.\n\nJ = @(u) [ -s*(u(2)+1-2*q*u(1)), s*(1-u(1)), 0; ...\n    -u(2)/s, (-1-u(1))/s, 1/s; ...\n    w,0,-w];\n\nt = sol.Time;\nu = sol.Solution;\nlambda = zeros(length(t) - 1, 3);\nfor j = 1:length(t)-1\n    lambda(j, :) = eig(J(u(:, j)));\nend\nplot3(real(lambda), imag(lambda), t(1:end-1), 'o')\nxlabel(\"Re $\\\\lambda$\"),  ylabel(\"Im $\\\\lambda$\"),  zlabel(\"$t$\")\ntitle(\"Oregonator eigenvalues\")\n\nYou can see that there is one eigenvalue that ranges over a wide portion of the negative real axis and dominates stability considerations.\n\nExample 11.4.3\n\nThe ode15s solver is good for stiff problems and needs few time steps to solve the Oregonator from \n\nDemo 11.4.2.\n\ntic,  sol = solve(ivp, 0, 26); \ntime_ode15s = toc\nnum_steps_ode15s = length(sol.Time) - 1\n\nBut if we apply \n\nFunction 6.5.2 to the problem, the step size will be made small enough to cope with the large negative eigenvalue.\n\ntic, [t, u] = rk23(ivp, 0, 26, 1e-5);\ntime_rk23 = toc\nnum_steps_rk23 = length(t) - 1\n\nStarting from the eigenvalues of the Jacobian matrix, we can find an effective \\zeta(t) by multiplying with the local time step size. The values of \\zeta(t) for each time level are plotted below and color coded by component of the diagonalized system.\n\nzeta = zeros(length(t) - 1, 3);\nfor j = 1:length(t)-1\n    lambda = eig(J(u(:, j)));\n    zeta(j, :) = (t(j+1) - t(j)) * lambda;\nend\nplot(zeta, 'o')\naxis equal, grid on\nxlabel('Re \\zeta'),  ylabel('Im \\zeta')\ntitle(\"Oregonator stability\")\n\nRoughly speaking, the ζ values stay within or close to the RK2 stability region in \n\nFigure 11.3.2. Momentary departures from the region are possible, but time stepping repeatedly in that situation would cause instability.","type":"content","url":"/chapter11-1#id-11-4","position":13},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.5 Boundaries","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-1#id-11-5","position":14},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.5 Boundaries","lvl2":"Examples"},"content":"Example 11.5.3\n\nFirst, we define functions for the PDE and each boundary condition.\n\nphi = @(t, x, u, ux, uxx) uxx;\nga = @(u, ux) u;\ngb = @(u, ux) u - 2;\n\nOur next step is to write a function to define the initial condition. This one satisfies the boundary conditions exactly.\n\ninit = @(x) 1 + sin(pi * x/2) + 3 * (1 - x.^2) .* exp(-4*x.^2);\n\nNow we can use \n\nFunction 11.5.2 to solve the problem.\n\n[x, u] = parabolic(phi, [-1, 1], 60, ga, gb, [0, 0.75], init);\n\nclf\nfor t = 0:0.1:0.5\n    str = sprintf(\"t = %.2f\", t);\n    plot(x, u(t), displayname=str)\n    hold on\nend\nxlabel(\"x\"),  ylabel(\"u(x,t)\")\nlegend()\ntitle(\"Heat equation with Dirichlet boundaries\")\n\nclf\nplot(x, u(0))\nhold on,  grid on\naxis([-1, 1, 0, 4.2])\ntitle('Heat equation with Dirichlet boundaries') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/boundaries-heat.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 0.75, 201)\n    cla, plot(x, u(t))\n    str = sprintf(\"t = %.3f\", t);\n    text(-0.9, 3.8, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 11.5.4\n\nphi = @(t, x, u, ux, uxx) u.^2 + uxx;\nga = @(u, ux) u;\ngb = @(u, ux) ux;\n\ninit = @(x) 400 * x.^4 .* (1 - x).^2;\n[x, u] = parabolic(phi, [0, 1], 60, ga, gb, [0, 0.1], init);\n\nclf\nplot(x, u(0))\nhold on,  grid on\naxis([0, 1, 0, 10])\ntitle(\"Heat equation with source\")\nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/boundaries-source.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 0.1, 101)\n    cla, plot(x, u(t))\n    str = sprintf(\"t = %.3f\", t);\n    text(0.05, 9.2, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 11.5.5\n\nK = 3;  sigma = 0.06;  r = 0.08;  Smax = 8;\nphi = @(t, x, u, ux, uxx) sigma.^2/2 * (x.^2 .* uxx) + r * x.*ux - r*u;\nga = @(u, ux) u;\ngb = @(u, ux) ux - 1;\n\ninit = @(x) max(0, x - K);\n[x, u] = parabolic(phi, [0, Smax], 80, ga, gb, [0, 15], init);\n\nclf\nplot(x, u(0))\nhold on,  grid on\naxis([0, Smax, -0.1, 8])\ntitle(\"Black–Scholes equation with boundaries\")\nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/boundaries-bs.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 15, 151)\n    cla, plot(x, u(t))\n    str = sprintf(\"t = %.1f\", t);\n    text(0.5, 7.1, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nRecall that u is the value of the call option, and time runs backward from the strike time. The longer the horizon, the more value the option has due to anticipated growth in the stock price.","type":"content","url":"/chapter11-1#id-11-5","position":15},{"hierarchy":{"lvl1":"Chapter 12"},"type":"lvl1","url":"/chapter12-1","position":0},{"hierarchy":{"lvl1":"Chapter 12"},"content":"","type":"content","url":"/chapter12-1","position":1},{"hierarchy":{"lvl1":"Chapter 12","lvl2":"Examples"},"type":"lvl2","url":"/chapter12-1#examples","position":2},{"hierarchy":{"lvl1":"Chapter 12","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter12-1#examples","position":3},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.1 Traffic flow","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-1#id-12-1","position":4},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.1 Traffic flow","lvl2":"Examples"},"content":"Example 12.1.1\n\nIn the following definition we allow the velocity c to be specified as a parameter.\n\n[x, Dx, Dxx] = diffper(300, [-4, 4]);\nf = @(t, u, c) -c * (Dx*u);\nivp = ode(ODEFcn=f);\nivp.Parameters = 2;\nivp.InitialTime = 0;\nivp.RelativeTolerance = 1e-5;\n\nThe following initial condition isn’t mathematically periodic, but the deviation is less than machine precision. We specify RK4 as the solver.\n\nu_init = 1 + exp(-3*x.^2);\nivp.InitialValue = u_init;\nt = linspace(0, 3, 201);\nsol = solve(ivp, t);\nU = sol.Solution;\n\nwaterfall(x, t(1:5:end), U(:, 1:5:end)')\nview(-13, 65)\nxlabel('x'), ylabel('t'), zlabel('u(x,t)')\ntitle('Advection equation')\n\nAn animation shows the solution nicely. The bump moves with speed 2 to the right, reentering on the left as it exits to the right because of the periodic conditions.\n\nclf\nplot(x, U(:, 1))\nhold on,  grid on\naxis([-4, 4, 0.9, 2.1])\ntitle('Advection equation with periodic boundary') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/advection-periodic.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(-3.5, 1.9, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 12.1.2\n\nThe following are parameters and a function relevant to defining the problem.\n\nrho_c = 1080;  rho_m = 380;  q_m = 10000;\nQ0prime = @(rho) 4*q_m*rho_c^2 * (rho_c - rho_m) * rho_m ...\n    *(rho_m - rho) ./ ((rho_c - 2*rho_m) * rho + rho_c * rho_m).^3;\nep = 0.02;\n\nHere we create a discretization on m=800 points.\n\n[x, Dx, Dxx] = diffper(800, [0, 4]);\n\nNext we define the ODE resulting from the method of lines.\n\nodefun = @(t, rho) -Q0prime(rho) .* (Dx*rho) + ep * (Dxx*rho);\nivp = ode(ODEFcn=odefun);\nivp.InitialTime = 0;\nivp.RelativeTolerance = 1e-5;\n\nOur first initial condition has moderate density with a small bump. Because of the diffusion present, we use a stiff solver for the IVP.\n\nrho_init = 400 + 10 * exp(-20*(x-3).^2);\nivp.InitialValue = rho_init;\n\nt = linspace(0, 1, 101);\nsol = solve(ivp, t);\nRHO = sol.Solution;\n\nclf\nfor plot_idx = 1:20:101\n    str = sprintf(\"t = %.2f\", t(plot_idx));\n    plot(x, RHO(:, plot_idx), displayname=str)\n    hold on\nend\nxlabel('x'),  ylabel('car density')\ntitle('Traffic flow') \nlegend(location=\"northwest\")\n\nThe bump slowly moves backward on the roadway, spreading out and gradually fading away due to the presence of diffusion.\n\nclf\nplot(x, RHO(:, 1))\nhold on,  grid on\naxis([0, 4, 398, 410])\ntitle('Traffic flow') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/traffic-small.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, RHO(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.2, 409, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nNow we use an initial condition with a larger bump. Note that the scale on the y-axis is much different for this solution.\n\nrho_init = 400 + 80 * exp( -16*(x - 3).^2 );\nivp.InitialValue = rho_init;\nt = linspace(0, 0.5, 81);\nsol = solve(ivp, t);\nRHO = sol.Solution;\n\nclf\nfor plot_idx = 1:16:81\n    str = sprintf(\"t = %.2f\", t(plot_idx));\n    plot(x, RHO(:, plot_idx), displayname=str)\n    hold on\nend\nxlabel('x'),  ylabel('car density')\ntitle('Traffic jam') \nlegend(location=\"northwest\")\n\nclf\nplot(x, RHO(:, 1))\nhold on,  grid on\naxis([0, 4, 395, 480])\ntitle('Traffic jam') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/traffic-jam.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, RHO(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.2, 470, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nIn this case the density bump travels backward along the road. It also steepens on the side facing the incoming traffic and decreases much more slowly on the other side. A motorist would experience this as an abrupt increase in density, followed by a much more gradual decrease in density and resulting gradual increase in speed. (You also see some transient, high-frequency oscillations. These are caused by instabilities, as we discuss in simpler situations later in this chapter.)","type":"content","url":"/chapter12-1#id-12-1","position":5},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.2 Upwinding and stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-1#id-12-2","position":6},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.2 Upwinding and stability","lvl2":"Examples"},"content":"Example 12.2.3\n\n[x, Dx] = diffper(400, [0, 1]);\nc = 2;  \nivp = ode(ODEFcn = @(t, u) -c * (Dx*u));\nivp.RelativeTolerance = 1e-5;\nivp.InitialTime = 0;\nu_init = exp( -80*(x - 0.5).^2 );\nivp.InitialValue = u_init;\n\n[u, sol] = solutionFcn(ivp, 0, 2);\n\nclf\nt = linspace(0, 2, 81);\ncontour(x, t, u(t)', 12)\nxlabel('x'),  ylabel('t')\ntitle('Linear advection')\n\nIn the space-time plot above, you can see the initial hump traveling rightward at constant speed. It fully traverses the domain once for each integer multiple of t=1/2.\n\nIf we cut h by a factor of 2 (i.e., double m), then the CFL condition suggests that the time step should be cut by a factor of 2 also.\n\nnum_steps_400 = length(sol.Time) - 1\n\n[x, Dx] = diffper(800, [0, 1]);\nivp.ODEFcn = @(t, u) -c * (Dx*u);\nivp.InitialValue = exp( -80*(x - 0.5).^2 );\n[u, sol] = solutionFcn(ivp, 0, 2);\n\nnum_steps_800 = length(sol.Time) - 1\nratio = num_steps_800 / num_steps_400\n\nExample 12.2.6\n\nIf we solve advection over [0,1] with velocity c=-1, the right boundary is in the upwind/inflow direction. Thus a well-posed boundary condition is u(1,t)=0.\n\nWe’ll pattern a solution after \n\nFunction 11.5.2. Since u(x_m,t)=0, we define the ODE interior problem \n\n(11.5.4) for \\mathbf{v} without u_m. For each evaluation of \\mathbf{v}', we must extend the data back to x_m first.\n\nm = 100;  c = -1;\n[x, Dx] = diffmat2(m, [0, 1]);\nchop = @(u) u(1:m);  \nextend = @(v) [v; 0];\nodefun = @(t, v) -c * chop( Dx * extend(v) );\nivp = ode(ODEFcn = odefun);\nivp.RelativeTolerance = 1e-5;\nivp.InitialTime = 0;\n\nNow we solve for an initial condition that has a single hump.\n\nu_init = exp( -80*(x - 0.5).^2 );\nivp.InitialValue = chop(u_init);\nsol = solutionFcn(ivp, 0, 1);\nu = @(t) [sol(t); zeros(1, length(t))];    % extend to zero at right\n\nt = linspace(0, 1, 81);\nclf,  contour(x, t, u(t)', 0.15:0.2:1)\nxlabel x,  ylabel t\ntitle('Advection with inflow BC')\n\nWe find that the hump gracefully exits out the downwind end.\n\nclf\nplot(x, u(0))\nhold on\naxis([0, 1, -0.05, 1.05])\ntitle('Advection with inflow BC') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/advection-inflow.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, u(t(frame)))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.08, 0.85, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nIf instead of u(1,t)=0 we were to try to impose the downwind condition u(0,t)=0, we only need to change the index of the interior nodes and where to append the zero value.\n\nchop = @(u) u(2:m+1);  \nextend = @(v) [0; v];\nivp.ODEFcn = @(t, v) -c * chop( Dx * extend(v) );\nivp.InitialValue = chop(u_init);\nsol = solutionFcn(ivp, 0, 1);\nu = @(t) [zeros(1, length(t)); sol(t)];\n\ncontour(x, t, u(t)', 0.15:0.2:1)\nxlabel x,  ylabel t\ntitle('Advection with outflow BC')\n\nThis time, the solution blows up as soon as the hump runs into the boundary because there are conflicting demands there.\n\nclf\nplot(x, u(0))\nhold on\naxis([0, 1, -0.05, 1.05])\ntitle('Advection with outflow BC') \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/advection-outflow.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:45\n    cla, plot(x, u(t(frame)))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(0.08, 0.85, str);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)","type":"content","url":"/chapter12-1#id-12-2","position":7},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.3 Absolute stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-1#id-12-3","position":8},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.3 Absolute stability","lvl2":"Examples"},"content":"Example 12.3.1\n\nFor c=1 we get purely imaginary eigenvalues.\n\n[x, Dx] = diffper(40, [0, 1]);\nlambda = eig(Dx);\nclf\nscatter(real(lambda), imag(lambda))\naxis equal,  grid on\ntitle('Eigenvalues for pure advection')\n\nLet’s choose a time step of \\tau=0.1 and compare to the stability regions of the Euler and backward Euler time steppers (shown as shaded regions):\n\nzc = exp( 1i * linspace(0,2*pi,361)' );    % points on |z|=1\nz = zc - 1;    % shift circle left by 1\nclf,  fill(real(z), imag(z), [.8, .8, 1])\nhold on,  scatter(real(0.1*lambda), imag(0.1*lambda))\naxis equal,  axis square\naxis([-5, 5, -5, 5]),  grid on\ntitle('Euler')\n\nIn the Euler case it’s clear that no real value of \\tau>0 is going to make ζ values fit within the stability region. Any method whose stability region includes none of the imaginary axis is an unsuitable choice for advection.\n\nclf,  fill([-6, 6, 6, -6],[-6, -6, 6, 6], [.8, .8, 1])\nz = zc + 1;   % shift circle right by 1\nhold on,  scatter(real(0.1*lambda), imag(0.1*lambda))\nfill(real(z), imag(z), 'w')\naxis equal,  axis square\naxis([-5 5 -5 5]),  grid on\ntitle('backward Euler')\n\nThe A-stable backward Euler time stepping tells the exact opposite story: it will be absolutely stable for any choice of the time step τ.\n\nExample 12.3.2\n\nThe eigenvalues of advection-diffusion are near-imaginary for \\epsilon\\approx 0 and get closer to the negative real axis as ε increases.\n\n[x, Dx, Dxx] = diffper(40, [0, 1]);\ntau = 0.1;\nclf\nfor ep = [0.001 0.01 0.05]\n  lambda = eig(-Dx + ep*Dxx);\n  str = sprintf(\"\\\\epsilon = %.3f\", ep);\n  scatter(real(tau*lambda), imag(tau*lambda), displayname=str)\n  hold on\nend\naxis equal,  grid on\nlegend(location='northwest')\ntitle('Eigenvalues for advection-diffusion')\n\nExample 12.3.3\n\nDeleting the last row and column places all the eigenvalues of the discretization into the left half of the complex plane.\n\n[x, Dx, Dxx] = diffcheb(40, [0, 1]);\nA = -Dx(2:end, 2:end);    % leave out first row and column\nlambda = eig(A);\n\nclf\nscatter(real(lambda), imag(lambda))\naxis equal,  grid on \ntitle('Eigenvalues of advection with zero inflow')\n\nNote that the rightmost eigenvalues have real part at most\n\nmax(real(lambda))\n\nConsequently all solutions decay exponentially to zero as t\\to\\infty. This matches our observation of the solution: eventually, everything flows out of the domain.","type":"content","url":"/chapter12-1#id-12-3","position":9},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.4 The wave equation","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-1#id-12-4","position":10},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.4 The wave equation","lvl2":"Examples"},"content":"Example 12.4.1\n\nc = 2;  m = 200;\n[x, Dx] = diffcheb(m, [-1, 1]);\n\nThe boundary values of u are given to be zero, so they are not unknowns in the ODEs. Instead they are added or removed as necessary.\n\nchop = @(u) u(2:m);\nextend = @(v) [0; v; 0];\n\nThe following function computes the time derivative of the system at interior points.\n\nfunction dw_dt = wave(t, w, param)\n    [c, m, Dx, chop, extend] = param{:};\n    u = extend(w(1:m-1));\n    z = w(m:2*m);\n    du_dt = Dx * z;\n    dz_dt = c.^2 .* (Dx * u);\n    dw_dt = [ chop(du_dt); dz_dt ];\nend\n\nOur initial condition is a single hump for u.\n\nu_init = exp( -100*x.^2 );\nz_init = -u_init;\nw_init = [ chop(u_init); z_init ];\n\nBecause the wave equation is hyperbolic, we can use a nonstiff explicit solver.\n\nivp = ode(ODEFcn=@f124wave);\nivp.InitialTime = 0;\nivp.InitialValue = w_init;\nivp.RelativeTolerance = 1e-4;\nivp.Parameters = {c, m, Dx, chop, extend};\nt = linspace(0, 2, 101);\nsol = solve(ivp, t);\n\nWe plot the results for the original u variable only. Its interior values are at indices 1:m-1 of the composite \\mathbf{w} variable.\n\nW = sol.Solution;\nn = length(t)-1;\nU = [ zeros(1, n+1); W(1:m-1, :); zeros(1, n+1) ];\n\ncmap = zeros(256, 3);\ncmap(129:end, 1) = 2/3;\ncmap(1:128, 2) = linspace(1, 0, 128);\ncmap(129:256, 2) = linspace(0, 1, 128);\ncmap(1:128, 3) = linspace(1, 0.5, 128);\ncmap(129:256, 3) = linspace(0.5, 1, 128);\ncmap = hsv2rgb(cmap);\n\nclf,  contour(x, t, U', 24, linewidth=2)\ncolormap(cmap),  clim([-1, 1])\nxlabel x,  ylabel t\ntitle(\"Wave equation with boundaries\")\n\nclf\nplot(x, U(:, 1))\nhold on\naxis([-1, 1, -1.05, 1.05])\ntitle(\"Wave equation with boundaries\") \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/wave-boundaries.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(-0.92, 0.85, str, fontsize=16);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nThe original hump breaks into two pieces of different amplitudes, each traveling with speed c=2. They pass through one another without interference. When a hump encounters a boundary, it is perfectly reflected, but with inverted shape. At time t=2, the solution looks just like the initial condition.\n\nExample 12.4.2\n\nWe now use a wave speed that is discontinuous at x=0.\n\nm = 120;\n[x, Dx] = diffcheb(m, [-1, 1]);\nc = 1 + (sign(x) + 1) / 2;\nchop = @(u) u(2:m);\nextend = @(v) [0; v; 0];\n\nu_init = exp( -100*(x + 0.5).^2 );\nz_init = -u_init;\nivp.InitialValue = [ chop(u_init); z_init ]; \nivp.Parameters = {c, m, Dx, chop, extend};\nsol = solve(ivp, t);\nW = sol.Solution;\nU = [ zeros(1, n+1); W(1:m-1, :); zeros(1, n+1) ];\n\nclf,  contour(x, t, U', 24, linewidth=2)\ncolormap(cmap),  clim([-1, 1])\nxlabel x,  ylabel t\ntitle(\"Wave equation with variable speed\")\n\nclf\nplot(x, U(:, 1))\nhold on\naxis([-1, 1, -1.05, 1.05])\ntitle(\"Wave equation with variable speed\") \nxlabel('x'),  ylabel('u(x,t)')\nvid = VideoWriter(\"figures/wave-speed.mp4\", \"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor frame = 1:length(t)\n    cla, plot(x, U(:, frame))\n    str = sprintf(\"t = %.2f\", t(frame));\n    text(-0.92, 0.85, str, fontsize=16);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nEach pass through the interface at x=0 generates a reflected and transmitted wave. By conservation of energy, these are both smaller in amplitude than the incoming bump.","type":"content","url":"/chapter12-1#id-12-4","position":11},{"hierarchy":{"lvl1":"Chapter 13"},"type":"lvl1","url":"/chapter13-1","position":0},{"hierarchy":{"lvl1":"Chapter 13"},"content":"","type":"content","url":"/chapter13-1","position":1},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Functions"},"type":"lvl2","url":"/chapter13-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Functions"},"content":"Create a tensor-product grid\n\nfunction [mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y)\n% TENSORGRID Tensor-product grid.\n% Input:\n%   x, y           1d projections of the grid nodes (lengths m and n)\n% Output:\n%   mtx            evaluate a function on the grid (function)\n%   X, Y           mtx applied to the coordinate functions (m×n)\n%   vec            convert grid shape to vector shape (function)\n%   unvec          convert vector shape to grid shape (function)\n%   is_boundary    indicator of boundary nodes (logical m×n)\n    m = length(x) - 1;\n    n = length(y) - 1;\n    vec = @(U) U(:);\n    unvec = @(u) reshape(u, m+1, n+1);\n    [X, Y] = ndgrid(x, y);\n    function F = grideval(f)\n        F = zeros(size(X));\n        for k = 1:numel(X)\n            F(k) = f(X(k), Y(k));\n        end\n    end\n    mtx = @grideval;\n    \n    % Identify boundary points.\n    is_boundary = true(m+1, n+1);\n    is_boundary(2:m, 2:n) = false;\nend\n\nSolution of Poisson’s equation by finite differences\n\nfunction [X, Y, U] = poissonfd(f,g,m,xspan,n,yspan)\r\n%POISSONFD   Solve Poisson's equation by finite differences.\r\n% Input:\r\n%   f            forcing function (function of x,y)\r\n%   g            boundary condition (function of x,y)\r\n%   m            number of grid points in x (integer)\r\n%   xspan        endpoints of the domain of x (2-vector)\r\n%   n            number of grid points in y (integer)\r\n%   yspan        endpoints of the domain of y (2-vector)\r\n%\r\n% Output:\r\n%   U            solution (m+1 by n+1)\r\n%   X,Y          grid matrices (m+1 by n+1)\r\n\r\n% Discretize the domain.\r\n[x, Dx, Dxx] = diffmat2(m, xspan);\r\n[y, Dy, Dyy] = diffmat2(n, yspan);\r\n[mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y);\r\n\r\n% Form the collocated PDE as a linear system. \r\nIx = speye(m+1);  Iy = speye(n+1);\r\nA = kron(Iy, sparse(Dxx)) + kron(sparse(Dyy), Ix);  % Laplacian matrix\r\nb = vec(mtx(f));\r\n\r\n% Replace collocation equations on the boundary.\r\nscale = max(abs(A(n+2, :)));\r\nI = speye(size(A));\r\nidx = vec(is_boundary);\r\nA(idx, :) = scale * I(idx, :);           % Dirichet assignment\r\nb(idx) = scale * g( X(idx),Y(idx) );     % assigned values\r\n\r\n% Solve the linear sytem and reshape the output.\r\nu = A \\ b;\r\nU = unvec(u);\n\nSolution of elliptic PDE by Chebyshev collocation\n\nfunction u = elliptic(phi, g, m, xspan, n, yspan)\n%ELLIPTIC   Solve an elliptic PDE in 2d.\n% Input:\n%   phi          defines phi)(x,y,u,u_x,u_xx,u_y,u_yy) = 0 (function)\n%   g            boundary condition (function)\n%   m, xspan     size and interval of x discretization (integer, 2-vector)\n%   n, yspan     size and interval of y discretization (integer, 2-vector)\n% Output:\n%   U            solution (n+1 by n+1)\n%   X,Y          coordinate matrices (n+1 by n+1)\n\n    % Discretize the domain.\n    [x, Dx, Dxx] = diffcheb(m, xspan);\n    [y, Dy, Dyy] = diffcheb(n, yspan);\n    [mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y);\n\n    % Identify boundary locations and evaluate the boundary condition.\n    idx = vec(is_boundary);\n    gb = g(X(idx), Y(idx));\n\n    % Evaluate the PDE+BC residual.\n    function r = residual(u)\n        U = unvec(u);\n        R = phi(X, Y, U, Dx * U, Dxx * U, U * Dy', U * Dyy');  % PDE\n        R(idx) = u(idx) - gb;                                  % boundary\n        r = vec(R);\n    end\n\n    % Solve the equation.\n    u = levenberg(@residual, vec(zeros(size(X))));\n    U = unvec(u(:, end));\n\n    function u = evaluate(xi, eta)\n        v = zeros(1, n+1);\n        for j = 1:n+1\n            v(j) = chebinterp(x, U(:, j), xi);\n        end\n        u = chebinterp(y, v, eta);\n    end\n\n    u = @evaluate;\nend\n\nfunction f = chebinterp(x, v, xi)\n    n = length(x) - 1;\n    w = (-1.0) .^ (0:n)';\n    w([1, n+1]) = w([1, n+1]) / 2;\n\n    terms = w ./ (xi - x(:));\n    if any(isinf(terms))     % exactly at a node\n        f = v(xi == x);\n    else\n        f = sum(v(:) .* terms) / sum(terms);\n    end\nend\n","type":"content","url":"/chapter13-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Examples"},"type":"lvl2","url":"/chapter13-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter13-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.1 Tensor-product discretizations","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-1#id-13-1","position":6},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.1 Tensor-product discretizations","lvl2":"Examples"},"content":"Example 13.1.2\n\nHere is the grid from \n\nExample 13.1.1.\n\nm = 4;   \nx = linspace(0, 2, m+1);\nn = 2;   \ny = linspace(1, 3, n+1);\n\nFor a given f(x,y) we can find \\operatorname{mtx}(f) by using a comprehension syntax.\n\n[mtx, X, Y] = tensorgrid(x, y);\nf = @(x, y) cos(pi * x .* y - y);\nF = mtx(f)\n\nWe can make a nice plot of the function by first choosing a much finer grid. However, the contour and surface plotting functions expect the transpose of mtx(f).\n\nTip\n\nTo emphasize departures from a zero level, use a colormap such as redsblues and set the color limits to be symmetric around zero.\n\nWarning\n\nThe contour and surface plotting functions expect the transpose of the outputs of mtx. If you forget to do that, the x and y axes will be swapped.\n\nm = 80;  x = linspace(0, 2, m+1);\nn = 60;  y = linspace(1, 3, n+1);\n[mtx, X, Y] = tensorgrid(x, y);\nF = mtx(f);\n\npcolor(X', Y', F')\nshading interp\ncolormap(redsblues),  colorbar\naxis equal\nxlabel(\"x\"),  ylabel(\"y\")\n\nExample 13.1.3\n\nFor a function given in polar form, such as f(r,\\theta)=1-r^4, construction of a function over the unit disk is straightforward using a grid in (r,\\theta) space.\n\nr = linspace(0, 1, 41);\ntheta = linspace(0, 2*pi, 121);\n[mtx, R, Theta] = tensorgrid(r, theta);\nF = mtx(@(r, theta) 1 - r.^4);\nclf,  colormap(parula)\ncontourf(R', Theta', F', 20)\nshading flat\nxlabel(\"r\"),  ylabel(\"\\theta\"), \ntitle(\"A polar function\")\n\nOf course, we are used to seeing such plots over the (x,y) plane, not the (r,\\theta) plane. For this we create matrices for the coordinate functions x and y.\n\nX = R .* cos(Theta);  Y = R .* sin(Theta);\ncontourf(X', Y', F', 20)\naxis equal,  shading interp  \nxlabel('x'),  ylabel('y')\ntitle('Function over the unit disk')\n\nIn such functions the values along the line r=0 must be identical, and the values on the line \\theta=0 should be identical to those on \\theta=2\\pi. Otherwise the interpretation of the domain as the unit disk is nonsensical. If the function is defined in terms of x and y, then those can be defined in terms of r and θ using \n\n(13.1.6).\n\nExample 13.1.4\n\nWe define a function and, for reference, its two exact partial derivatives.\n\nu = @(x, y) sin(pi * x .* y - y);\ndu_dx = @(x, y) pi * y .* cos(pi * x .* y - y);\ndu_dy = @(x, y) (pi * x - 1) .* cos(pi * x .* y - y);\n\nWe will use an equispaced grid and second-order finite differences as implemented by diffmat2. First, we have a look at a plots of the exact partial derivatives.\n\nm = 80;  [x, Dx] = diffmat2(m, [0, 2]);\nn = 60;  [y, Dy] = diffmat2(n, [1, 4]);\n[mtx, X, Y] = tensorgrid(x, y);\nU = mtx(u);\ndU_dX = mtx(du_dx);\ndU_dY = mtx(du_dy);\n\nclf,  subplot(1, 2, 1)\npcolor(X', Y', dU_dX')\naxis equal,  shading interp\ntitle('∂u/∂x')\nsubplot(1, 2, 2)\npcolor(X', Y', dU_dY')\naxis equal,  shading interp\ntitle('∂u/∂y')\n\nNow we compare the exact partial derivatives with their finite-difference approximations. Since these are signed errors, we use a colormap that is symmetric around zero.\n\nerr = dU_dX - Dx * U;\nsubplot(1, 2, 1)\npcolor(X', Y', err')\ncolorbar,  clim([-.4, .4])\naxis equal,  shading interp\ntitle('error in ∂u/∂x')\n\nerr = dU_dY - U * Dy';\nsubplot(1,2,2)\npcolor(X', Y', err')\ncolorbar,  clim([-.1, .1])\naxis equal,  shading interp\ncolormap(redsblues)\ntitle('error in ∂u/∂y')\n\nNot surprisingly, the errors are largest where the derivatives themselves are largest.","type":"content","url":"/chapter13-1#id-13-1","position":7},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.2 Two-dimensional diffusion and advection","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-1#id-13-2","position":8},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.2 Two-dimensional diffusion and advection","lvl2":"Examples"},"content":"Example 13.2.1\n\nm = 4;  n = 3;\nx = linspace(0, 2, m+1);\ny = linspace(-3, 0, n+1);\n\nf = @(x, y) cos(0.75*pi * x .* y - 0.5*pi * y);\n[mtx, X, Y, vec, unvec] = tensorgrid(x, y);\nF = mtx(f);\ndisp(\"function on a 4x3 grid:\")\ndisp(F)\n\ndisp(\"vec(F):\")\ndisp(vec(F))\n\nThe unvec operation is the inverse of vec.\n\ndisp(\"unvec(vec(F)):\")\ndisp(unvec(vec(F)))\n\nExample 13.2.2\n\nm = 60;  n = 40;\n[x, Dx, Dxx] = diffper(m, [-1, 1]);\n[y, Dy, Dyy] = diffper(n, [-1, 1]);\n[mtx, X, Y, vec, unvec] = tensorgrid(x, y);\n\nNote that the initial condition should also be periodic on the domain.\n\nU0 = sin(4*pi*X) .* exp( cos(pi*Y) );\nclf,  surf(X', Y', U0')\nmx = max(abs(vec(U0)));\nclim([-mx, mx]),  shading interp\ncolormap(redsblues)\nxlabel('x'),  ylabel('y')  \ntitle('Initial condition')\n\nThis function computes the time derivative for the unknowns. The actual calculations take place using the matrix shape.\n\nfunction du_dt = timederiv(t, u, p)\n    [alpha, Dxx, Dyy, vec, unvec] = p{:};\n    U = unvec(u);\n    Uxx = Dxx * U;  Uyy = U * Dyy';     % 2nd partials\n    dU_dt = alpha * (Uxx + Uyy);  % PDE\n    du_dt = vec(dU_dt);\nend\n\nSince this problem is parabolic, a stiff integrator is appropriate.\n\nivp = ode(ODEFcn=@f13_2_heat);\nivp.InitialTime = 0;\nivp.InitialValue = vec(U0);\nivp.Parameters = {0.1, Dxx, Dyy, vec, unvec};\nivp.Solver = \"stiff\";\nsol = solutionFcn(ivp, 0, 0.2);\nU = @(t) unvec(sol(t));\n\nsurf(X', Y', U(0.05)')\nclim([-mx, mx]),  shading interp\ncolormap(redsblues)\nxlabel('x'),  ylabel('y')  \ntitle('Solution at t = 0.05')\n\nHere is an animation of the solution.\n\nTip\n\nHere clims are set so that colors remain at fixed values throughout the animation.\n\ntitle('Heat equation on a periodic domain')\nvid = VideoWriter(\"figures/2d-heat.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\nfor t = linspace(0, 0.2, 61)\n    cla, surf(X', Y', U(t)')\n    zlim([-3, 3]),  clim([-mx, mx])\n    shading interp\n    str = sprintf(\"t = %.2f\", t);\n    text(-0.9, 0.75, 2, str, fontsize=14);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 13.2.3\n\nThe first step is to define a discretization of the domain and the initial state.\n\nm = 50;  n = 40;\n[x, Dx, Dxx] = diffcheb(m, [-1, 1]);\n[y, Dy, Dyy] = diffcheb(n, [-1, 1]);\n[mtx, X, Y] = tensorgrid(x, y);\nu_init = @(x, y) (1+y) .* (1-x).^4 .* (1+x).^2 .* (1-y.^4);\n\nThere are really two grids now: the full grid and the subset grid of interior points. Since the IVP unknowns are on the interior grid, that is the one we need to change shapes on. We also need the functions extend and chop to add and remove boundary values.\n\n[~, ~, ~, vec, unvec] = tensorgrid(x(2:m), y(2:n));\nchop = @(U) U(2:m, 2:n);\nz = zeros(1, n-1);\nextend = @(U) [ zeros(m+1, 1) [z; U; z] zeros(m+1, 1)];\npack = @(U) vec(chop(U));\nunpack = @(u) extend(unvec(u));\n\nNow we can define and solve the IVP using a stiff solver.\n\nfunction du_dt = timederiv(t, u, p)\n    [ep, Dx, Dxx, Dy, Dyy, pack, unpack] = p{:};\n    U = unpack(u);\n    Uxx = Dxx * U;  Uyy = U * Dyy'; \n    dU_dt = 1 - Dx * U + ep * (Uxx + Uyy);  % PDE\n    du_dt = pack(dU_dt);\nend\n\nivp = ode(ODEFcn=@f13_2_advdiff);\nivp.InitialTime = 0;\nivp.InitialValue = pack(mtx(u_init));\nivp.Parameters = {0.05, Dx, Dxx, Dy, Dyy, pack, unpack};\nivp.Solver = \"stiff\";\nsol = solutionFcn(ivp, 0, 2);\n\nWhen we evaluate the solution at a particular value of t, we get a vector of the interior grid values. The same unpack function above converts this to a complete matrix of grid values.\n\nU = @(t) unpack(sol(t));\n\nclf,  pcolor(X', Y', U(0.5)')\nclim([0, 2]), shading interp\naxis equal,  colormap(sky), colorbar\ntitle('Advection-diffusion at t = 0.5')  \nxlabel('x'),  ylabel('y')\n\nhold on\nvid = VideoWriter(\"figures/2d-advdiff.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\ntitle(\"Advection-diffusion in 2d\")\nfor t = linspace(0, 2, 81)\n    cla, pcolor(X', Y', U(t)')\n    shading interp\n    str = sprintf(\"t = %.2f\", t);\n    text(-1.5, 0.75, str, fontsize=14);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)\n\nExample 13.2.4\n\nWe start with the discretization and initial condition.\n\nm = 40; n = 42;\n[x, Dx, Dxx] = diffcheb(m, [-2, 2]);\n[y, Dy, Dyy] = diffcheb(n, [-2, 2]);\n[mtx, X, Y] = tensorgrid(x, y);\n\nu_init = @(x, y) (x+0.2) .* exp(-12*(x.^2 + y.^2));\nU0 = mtx(u_init);\nV0 = zeros(size(U0));\n\nNote that because u is known on the boundary, while v is unknown over the full grid, there are two different sizes of vec/unvec operations. We also need to define functions to pack grid unknowns into a vector and to unpack them. When the unknowns for u are packed, the boundary values are chopped off, and these are restored when unpacking.\n\n[~, ~, ~, vec_v, unvec_v] = tensorgrid(x, y);\n[~, ~, ~, vec_u, unvec_u] = tensorgrid(x(2:m), y(2:n));\n\nchop = @(U) U(2:m, 2:n);\nz = zeros(1, n-1);\nextend = @(U) [ zeros(m+1, 1) [z; U; z] zeros(m+1, 1)];\npack = @(U, V) [vec_u(chop(U)); vec_v(V)];\nN = (m-1) * (n-1);\nunpack = @(u) f13_2_wave_unpack(u, N, unvec_u, unvec_v, extend);\n\nfunction [U, V] = unpack(w, N, unvec_u, unvec_v, extend)\n    U = extend( unvec_u(w(1:N)) );\n    V = unvec_v(w(N+1:end));\nend\n\nWe can now define and solve the IVP. Since this problem is hyperbolic, not parabolic, a nonstiff integrator is faster than a stiff one.\n\nfunction dw_dt = timederiv(t, w, p)\n    [Dxx, Dyy, pack, unpack] = p{:};\n    [U, V] = unpack(w);\n    dU_dt = V;\n    dV_dt = Dxx * U + U * Dyy';\n    dw_dt = pack(dU_dt, dV_dt);\nend\n\nivp = ode(ODEFcn=@f13_2_wave);\nivp.InitialTime = 0;\nivp.InitialValue = pack(U0, V0);\nivp.Parameters = {Dxx, Dyy, pack, unpack};\nivp.Solver = \"nonstiff\";\nsol = solutionFcn(ivp, 0, 4);\n\nclf\n[U, V] = unpack(sol(0.5));\npcolor(X', Y', U')\naxis equal,  clim([-0.1, 0.1])\ncolormap(redsblues),  shading interp\nxlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Wave equation at t = 0.5\")\n\nhold on\nvid = VideoWriter(\"figures/2d-wave.mp4\",\"MPEG-4\");\nvid.Quality = 85;\nopen(vid);\ntitle(\"Wave equation in 2d\")\nfor t = linspace(0, 4, 121)\n    [U, V] = unpack(sol(t));\n    cla, pcolor(X, Y, U)\n    shading interp\n    str = sprintf(\"t = %.2f\", t);\n    text(-3, 1.75, str, fontsize=14);\n    writeVideo(vid, frame2im(getframe(gcf)));\nend\nclose(vid)","type":"content","url":"/chapter13-1#id-13-2","position":9},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.3 Laplace and Poisson equations","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-1#id-13-3","position":10},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.3 Laplace and Poisson equations","lvl2":"Examples"},"content":"Example 13.3.1\n\nA = [1, 2; -2, 0];\nB = [1, 10, 100; -5, 5, 3];\ndisp(\"A:\")\ndisp(A)\ndisp(\"B:\")\ndisp(B)\n\nApplying the definition manually, we get\n\nA_kron_B = [\n    A(1,1)*B  A(1,2)*B;\n    A(2,1)*B  A(2,2)*B\n    ]\n\nBut it makes more sense to use kron.\n\nkron(A, B)\n\nExample 13.3.2\n\nWe make a crude discretization for illustrative purposes.\n\nm = 6;  n = 5;\n[x, Dx, Dxx] = diffmat2(m, [0, 3]);\n[y, Dy, Dyy] = diffmat2(n, [-1, 1]);\n[mtx, X, Y, vec, unvec, is_boundary] = tensorgrid(x, y);\n\nNext, we define ϕ and evaluate it on the grid to get the forcing vector of the linear system.\n\nphi = @(x, y) x.^2 - y + 2;\nb = vec(mtx(phi));\n\nHere are the coefficients for the PDE collocation, before any modifications are made for the boundary conditions. The combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\nA = kron(speye(n+1), sparse(Dxx)) + kron(sparse(Dyy), speye(m+1));\nclf,  spy(A)\ntitle(\"System matrix before boundary conditions\")\n\nThe number of equations is equal to (m+1)(n+1), which is the total number of points on the grid.\n\nN = length(b)\n\nWe now use the Boolean array that indicates where the boundary points lie in the grid.\n\nspy(is_boundary)\ntitle(\"Boundary points\")\n\nIn order to impose Dirichlet boundary conditions, we replace the boundary rows of the system by rows of the identity.\n\nTip\n\nChanging rows of a sparse array requires that the operands be in a particular sparse representation called lil. The conversion isn’t done automatically because it can be slow and you are encouraged to avoid it when possible. We’re just trying to keep things conceptually simple here.\n\nI = speye(N);\nidx = vec(is_boundary);\nA(idx, :) = I(idx, :);\n\nspy(A)\ntitle(\"System matrix with boundary conditions\")\n\nFinally, we must replace the rows in the vector \\mathbf{b} by the boundary values being assigned to the boundary points. Here, we let the boundary values be zero everywhere.\n\nb(idx) = 0;\n\nNow we can solve for \\mathbf{u} and reinterpret it as the matrix-shaped \\mathbf{U}, the solution on our grid.\n\nu = A \\ b;\nU = unvec(u)\n\nExample 13.3.3\n\nFirst we define the problem on [0,1]\\times[0,2].\n\nf = @(x, y) -sin(3*x .* y - 4*y) .* (9*y.^2 + (3*x - 4).^2);\ng = @(x, y) sin(3*x .* y - 4*y);\nxspan = [0, 1];\nyspan = [0, 2];\n\nHere is the finite-difference solution.\n\n[X, Y, U] = poissonfd(f, g, 40, xspan, 60, yspan);\n\nclf, surf(X', Y', U')\ncolormap(parula),  shading interp\ncolorbar\ntitle(\"Solution of Poisson's equation\")\nxlabel(\"x\"),  ylabel(\"y\"),  zlabel(\"u(x,y)\")\n\nSince this is an artificial problem with a known solution, we can plot the error, which is a smooth function of x and y. It must be zero on the boundary; otherwise, we have implemented boundary conditions incorrectly.\n\nerr = g(X, Y) - U;\nmx = max(abs(vec(err)));\npcolor(X', Y', err')\ncolormap(redsblues),  shading interp\nclim([-mx, mx]),  colorbar\naxis equal,  xlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Error\")","type":"content","url":"/chapter13-1#id-13-3","position":11},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.4 Nonlinear elliptic PDEs","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-1#id-13-4","position":12},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.4 Nonlinear elliptic PDEs","lvl2":"Examples"},"content":"Example 13.4.2\n\nAll we need to define are ϕ from \n\n(13.4.2) for the PDE, and a trivial zero function for the boundary condition.\n\nlambda = 1.5;\nphi = @(X, Y, U, Ux, Uxx, Uy, Uyy) Uxx + Uyy - lambda ./ (U + 1).^2;\ng = @(x, y) zeros(size(x));\n\nHere is the solution for m=15, n=8.\n\nu = elliptic(phi, g, 15, [0, 2.5], 8, [0, 1]);\ndisp(sprintf(\"solution at (2, 0.6) is %.7f\", u(2, 0.6)))\n\nx = linspace(0, 2.5, 91);\ny = linspace(0, 1, 51);\n[mtx, X, Y] = tensorgrid(x, y);\nclf,  pcolor(x, y, mtx(u)')\ncolormap(flipud(sky)),  shading interp,  colorbar\naxis equal\nxlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Deflection of a MEMS membrane\")\n\nIn the absence of an exact solution, how can we be confident that the solution is accurate? First, the Levenberg iteration converged without issuing a warning, so we should feel confident that the discrete equations were solved. Assuming that we encoded the PDE correctly, the remaining source of error is truncation from the discretization. We can estimate that by refining the grid a bit and seeing how much the numerical solution changes.\n\nx_test = linspace(0, 2.5, 6);\ny_test = linspace(0, 1 , 5);\nmtx_test = tensorgrid(x_test, y_test);\nformat long\nmtx_test(u)\n\nu = elliptic(phi, g, 25, [0, 2.5], 14, [0, 1]);\nmtx_test(u)\n\nThe original solution seems to be accurate to about four digits.\n\nformat\n\nExample 13.4.3\n\nphi = @(X, Y, U, Ux, Uxx, Uy, Uyy) 1 - Ux - 2*Uy + 0.05*(Uxx + Uyy);\ng = @(x, y) zeros(size(x));\nu = elliptic(phi, g, 32, [-1, 1], 32, [-1, 1]);\n\nx = linspace(-1, 1, 80);\ny = x;\nmtx = tensorgrid(x, y);\nclf,  pcolor(x, y, mtx(u)')\ncolormap(parula),  shading interp,  colorbar\naxis equal,  xlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Steady advection–diffusion\")\n\nExample 13.4.4\n\nThe following defines the PDE and a nontrivial Dirichlet boundary condition for the square [0,1]^2.\n\nphi = @(X, Y, U, Ux, Uxx, Uy, Uyy) U .* (1-U.^2) + 0.05*(Uxx + Uyy);\ng = @(x, y) tanh(5*(x + 2*y - 1));\n\nWe solve the PDE and then plot the result.\n\nu = elliptic(phi, g, 36, [0, 1], 36, [0, 1]);\n\nx = linspace(0, 1, 80);\ny = x;\nmtx = tensorgrid(x, y);\nclf,  pcolor(x, y, mtx(u)')\ncolormap(parula),  shading interp,  colorbar\naxis equal,  xlabel(\"x\"),  ylabel(\"y\")\ntitle(\"Steady Allen–Cahn\")","type":"content","url":"/chapter13-1#id-13-4","position":13},{"hierarchy":{"lvl1":"Chapter 2"},"type":"lvl1","url":"/chapter2-1","position":0},{"hierarchy":{"lvl1":"Chapter 2"},"content":"","type":"content","url":"/chapter2-1","position":1},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"type":"lvl2","url":"/chapter2-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"content":"Forward substitution\n\nfunction x = forwardsub(L,b)\r\n% FORWARDSUB   Solve a lower triangular linear system.\r\n% Input:\r\n%   L    lower triangular square matrix (n by n)\r\n%   b    right-hand side vector (n by 1)   \r\n% Output:\r\n%   x    solution of Lx=b (n by 1 vector)\r\n\r\nn = length(L);\r\nx = zeros(n,1);\r\nfor i = 1:n\r\n  x(i) = ( b(i) - L(i,1:i-1) * x(1:i-1) ) / L(i,i);\r\nend\n\nAbout the code\n\nLine 12 implements \n\n(2.3.7). It contains an inner product between row i of \\mathbf{L} and the solution vector \\mathbf{x}, using only the entries of \\mathbf{x} that have already been computed.\n\nBackward substitution\n\nfunction x = backsub(U,b)\r\n% BACKSUB   Solve an upper triangular linear system.\r\n% Input:\r\n%   U    upper triangular square matrix (n by n)\r\n%   b    right-hand side vector (n by 1)   \r\n% Output:\r\n%   x    solution of Ux=b (n by 1 vector)\r\n\r\nn = length(U);\r\nx = zeros(n,1);\r\nfor i = n:-1:1\r\n  x(i) = ( b(i) - U(i,i+1:n)*x(i+1:n) ) / U(i,i);\r\nend\n\nLU factorization (not stable)\n\nfunction [L, U] = lufact(A)\r\n% LUFACT   LU factorization (demo only--not stable!).\r\n% Input:\r\n%   A    square matrix\r\n% Output:\r\n%   L,U  unit lower triangular and upper triangular such that LU=A\r\n\r\nn = size(A, 1);     % detect the dimensions from the input\r\nL = eye(n);         % ones on main diagonal, zeros elsewhere\r\nU = zeros(n, n);\r\nA_k = A;            % make a working copy \r\n\r\n% Reduction by outer products\r\nfor k = 1:n-1\r\n    U(k, :) = A_k(k, :);\r\n    L(:, k) = A_k(:,k) / U(k, k);\r\n    A_k = A_k -  L(:, k) * U(k, :);\r\nend\r\nU(n, n) = A_k(n, n);\r\nL = tril(L); U = triu(U);    % force exact triangularity\n\nLU factorization with partial pivoting\n\nfunction [L, U, p] = plufact(A)\n% PLUFACT   Pivoted LU factorization \n% Input:\n%   A    square matrix\n% Output:\n%   L    unit lower triangular \n%   U    upper triangular\n%   p    row permutation vector such that A(p,:) = L*U\nn = size(A, 1);\nL = zeros(n, n);\nU = zeros(n, n);\np = zeros(1, n);\nA_k = A;\n\n% Reduction by outer products\nfor k = 1:n\n    [~, p(k)] = max(abs(A_k(:, k)));\n    U(k, :) = A_k(p(k), :);\n    L(:, k) = A_k(:, k) / U(k, k);\n    if k < n\n        A_k = A_k - L(:, k) * U(k, :);\n    end\nend\nL = tril(L(p, :));\nU = triu(U);","type":"content","url":"/chapter2-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"type":"lvl2","url":"/chapter2-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter2-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.1 Polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-1","position":6},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.1 Polynomial interpolation","lvl2":"Examples"},"content":"Example 2.1.1\n\nWe create two column vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = [1982; 2000; 2010; 2015]; \npop = [1008.18; 1262.64; 1337.82; 1374.62];\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980;\ny = pop;\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\n\nTo solve for the vector of polynomial coefficients, we use a backslash to solve the linear system:\n\nTip\n\nA backslash \\ is used to solve a linear system of equations.\n\nc = V \\ y\n\nThe algorithms used by the backslash operator are the main topic of this chapter. As a check on the solution, we can compute the residual.\n\ny - V * c\n\nUsing floating-point arithmetic, it is not realistic to expect exact equality of quantities; a relative difference comparable to \\macheps is all we can look for.\n\nBy our definitions, the elements of c are coefficients in descending-degree order for the interpolating polynomial. We can use the polynomial to estimate the population of China in 2005:\n\np = @(t) polyval(c, t - 1980);  % include the 1980 time shift\np(2005)\n\nThe official population value for 2005 was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points.\n\nTip\n\nThe scatter function creates a scatter plot of points; you can specify a line connecting the points as well.\n\nscatter(year, y)\nxlabel(\"years since 1980\")\nylabel(\"population (millions)\")\ntitle(\"Population of China\")\n\nWe want to superimpose a plot of the polynomial. We do that by evaluating it at a vector of points in the interval.\n\nTip\n\nThe linspace function constructs evenly spaced values given the endpoints and the number of values.\n\ntt = linspace(1980, 2015, 500);    % 500 times in the interval [1980, 2015]\nyy = p(tt);                        % evaluate p at all the vector elements\nyy(1:4)\n\nNow we use plot! to add to the current plot, rather than replacing it.\n\nTip\n\nUse hold on to add to an existing plot rather than replacing it.\nThe plot function plots lines connecting the given x and y values; you can also specify markers at the points.\n\nhold on \nplot(tt, yy)\nlegend(\"data\", \"interpolant\", \"location\", \"northwest\");","type":"content","url":"/chapter2-1#id-2-1","position":7},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.2 Computing with matrices","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-2","position":8},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.2 Computing with matrices","lvl2":"Examples"},"content":"Example 2.2.1\n\nIn MATLAB, every numerical value is treated like a matrix. A matrix with one row or one column is interpreted as a vector, and a 1\\times 1 matrix is interpreted as a scalar.\n\nSquare brackets are used to enclose elements of a matrix or vector. Use spaces for horizontal concatenation, and semicolons or new lines to indicate vertical concatenation.\n\nTip\n\nThe size function returns the number of rows and columns in a matrix. Use length to get the number of elements in a vector or matrix.\n\nA = [ \n    1       2      3             4      5; \n    50     40     30            20     10\n    pi sqrt(2) exp(1) (1+sqrt(5))/2 log(3) \n    ]\n\nm, n = size(A)\n\nx = [ 3, 3, 0, 1, 0 ];   % row vector\nsize(x)\n\nConcatenated elements within brackets may be matrices or vectors for a block representation, as long as all the block sizes are compatible.\n\n[ x  x ]\n\n[ x; x ]\n\nThe zeros and ones functions construct matrices with entries all zero or one, respectively.\n\nB = [ zeros(3, 2) ones(3, 1) ]\n\nA single quote ' after a matrix returns its adjoint. For real matrices, this is the transpose; for complex-valued matrices, the elements are also conjugated.\n\nA'\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a range with evenly spaced entries between two endpoints, you have two options. One is to use a colon :.\n\ny = 1:4              % start:stop\n\nz = 0:3:12           % start:step:stop\n\nInstead of specifying the step size, you can give the number of points in the range if you use linspace.\n\ns = linspace(-1, 1, 5)    % row result\n\nAccessing an element is done by giving one (for a vector) or two (for a matrix) index values within parentheses.\n\nTip\n\nThe end keyword refers to the last element in a dimension. It saves you from having to compute and store the size of the matrix first.\n\na = A(2, end-1)\n\nx(2)\n\nThe indices can be vectors or ranges, in which case a block of the matrix is accessed.\n\nA(1:2, end-2:end)    % first two rows, last three columns\n\nIf a dimension has only the index : (a colon), then it refers to all the entries in that dimension of the matrix.\n\nA(:, 1:2:end)        % all of the odd columns\n\nThe matrix and vector senses of addition, subtraction, scalar multiplication, multiplication, and power are all handled by the usual symbols.\n\nTip\n\nUse diag to construct a matrix by its diagonals. A more general syntax puts elements on super- or subdiagonals.\n\nB = diag([-1, 0, -5])   % create a diagonal matrix\n\nsize(A)\nsize(B)\n\nBA = B * A     % matrix product\n\nA * B causes an error here, because the dimensions aren’t compatible.\n\nTip\n\nErrors are formally called exceptions in Julia.\n\nA * B    % throws an error\n\nA square matrix raised to an integer power is the same as repeated matrix multiplication.\n\nB^3    % same as B*B*B\n\nSometimes one instead wants to treat a matrix or vector as a mere array and simply apply a single operation to each element of it. For multiplication, division, and power, the corresponding operators start with a dot.\n\nC = -A;\n\nBecause both matrices are 3\\times 5, A * C would be an error here, but elementwise operations are fine.\n\nelementwise = A .* C\n\nThe two operands of a dot operator have to have the same size—unless one is a scalar, in which case it is expanded or broadcast to be the same size as the other operand.\n\nx_to_two = x .^ 2\n\ntwo_to_x = 2 .^ x\n\nTip\n\nMost of the mathematical functions, such as cos, sin, log, exp, and sqrt, can operate elementwise on vectors and matrices.\n\ncos(pi * x)","type":"content","url":"/chapter2-1#id-2-2","position":9},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.3 Linear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-3","position":10},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.3 Linear systems","lvl2":"Examples"},"content":"Example 2.3.2\n\nFor a square matrix \\mathbf{A}, the syntax A \\ b is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = [1 0 -1; 2 2 1; -1 -3 0]\n\nb = [1; 2; 3]\n\nx = A \\ b\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision (relative to the elements in the data).\n\nresidual = b - A*x\n\nIf the matrix \\mathbf{A} is singular, you may get a warning and nonsense result.\n\nA = [0 1; 0 0]\nb = [1; -1]\nx = A \\ b\n\nIn this case, we can check that the rank of \\mathbf{A} is less than its number of columns, indicating singularity.\n\nTip\n\nThe function rank computes the rank of a matrix. However, it is numerically unstable for matrices that are nearly singular, in a sense to be defined in a later section.\n\nrank(A)\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, backslash will fail. Moreover, detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. In \n\nConditioning of linear systems we’ll find a robust way to fully describe this situation.\n\nExample 2.3.3\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nTip\n\nUse tril to return a matrix that zeros out everything above the main diagonal. The triu function zeros out below the diagonal.\n\nA = randi(9, 5, 5);\nL = tril(A)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5);\nx = forwardsub(L, b)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L * x\n\nNext, we’ll engineer a problem to which we know the exact answer.\n\nTip\n\nThe eye function creates an identity matrix. The diag function uses 0 as the main diagonal, positive integers as superdiagonals, and negative integers as subdiagonals.\n\nalpha = 0.3;\nbeta = 2.2;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta]\n\nx_exact = ones(5);\nb = [alpha; 0; 0; 0; 1];\n\nNow we use backward substitution to solve for \\mathbf{x}, and compare to the exact solution we know already.\n\nx = backsub(U, b);\nerr = x - x_exact\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = eye(5) + diag([-1 -1 -1 -1], 1);\nU(1, [4, 5]) = [alpha - beta, beta];\nb = [alpha; 0; 0; 0; 1];\n\nx = backsub(U, b);\nerr = x - x_exact\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! The source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.","type":"content","url":"/chapter2-1#id-2-3","position":11},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.4 LU factorization","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-4","position":12},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.4 LU factorization","lvl2":"Examples"},"content":"Example 2.4.2\n\nWe explore the outer product formula for two random triangular matrices.\n\nL = tril( randi(9, 3, 3) )\n\nU = triu( randi(9, 3, 3) )\n\nHere are the three outer products in the sum in \n\n(2.4.4):\n\nL(:, 1) * U(1, :)\n\nL(:, 2) * U(2, :)\n\nL(:, 3) * U(3, :)\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nExample 2.4.3\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = [\n     2    0    4     3 \n    -4    5   -7   -10 \n     1   15    2   -4.5\n    -2    0    2   -13\n    ];\nL = eye(4);\nU = zeros(4, 4);\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU(1, :) = A_1(1, :)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL(:, 1) = A_1(:, 1) / U(1, 1)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU(2, :) = A_2(2, :)\nL(:, 2) = A_2(:, 2) / U(2, 2)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU(3, :) = A_3(3, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\nFinally, we pick up the last unknown in the factors.\n\nU(4, 4) = A_4(4, 4);\n\nWe now have all of \\mathbf{L},\n\nL\n\nand all of \\mathbf{U},\n\nU\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L * U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nExample 2.4.4\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = [2 0 4 3; -4 5 -7 -10; 1 15 2 -4.5; -2 0 2 -13];\nb = [4; 9; 9; 4];\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\n[L, U] = lufact(A)\nz = forwardsub(L, b);\nx = backsub(U, z);\n\nA check on the residual assures us that we found the solution.\n\nb - A * x","type":"content","url":"/chapter2-1#id-2-4","position":13},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.5 Efficiency of matrix computations","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-5","position":14},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.5 Efficiency of matrix computations","lvl2":"Examples"},"content":"Example 2.5.4\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6;\nA = magic(n);\nx = ones(n,1);\ny = zeros(n,1);\nfor i = 1:n\n    for j = 1:n\n        y(i) = y(i) + A(i,j)*x(j);   % 2 flops\n    end\nend\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication, using tic and toc to time the operation.\n\nn = (500:500:5000)';\nt = zeros(size(n));\nfor k = 1:length(n)\n    A = randn(n(k), n(k));  x = randn(n(k), 1);\n    tic    % start a timer\n    for j = 1:200      % repeat 100 times\n        A*x;\n    end\n    time = toc;           % read the timer\n    t(k) = time / 200;   % seconds per instance\nend\n\nThe reason for doing multiple repetitions at each value of n in the loop above is to avoid having times so short that the resolution of the timer is significant.\n\ntable(n, t, 'variablenames', [\"size\", \"time\"])\n\nLooking at the timings just for n=2500 and n=5000, they have ratio\n\nTip\n\nThe expression n==5000 here produces a vector of Boolean (true/false) values the same size as n. This result is used to index within t, accessing only the value for which the comparison is true.\n\nt(n==5000) / t(n==2500)\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(5000)^2}{2(2500)^2}=4.\n\nExample 2.5.5\n\nLet’s repeat the previous experiment for more, and larger, values of n.\n\nn = (400:400:6000)';\nt = zeros(size(n));\nfor k = 1:length(n)\n    A = randn(n(k), n(k));  x = randn(n(k), 1);\n    tic    % start a timer\n    for j = 1:100      % repeat ten times\n        A*x;\n    end\n    time = toc;          % read the timer\n    t(k) = time / 100;   % seconds per instance\nend\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables.\n\nclf    % clear any existing figure\nloglog(n, t, 'o-')\nxlabel('size of matrix')\nylabel('time (sec)')\ntitle('Timing of matrix-vector multiplications')\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nhold on\nloglog(n, 0.5 * t(end) * (n / n(end)).^2, 'k--')\naxis tight\nlegend('data', 'O(n^2)', 'location', 'southeast')\n\nExample 2.5.6\n\nWe’ll test the conclusion of O(n^3) flops experimentally, using the built-in lu function instead of the purely instructive lufact.\n\nTip\n\nThe first time a function is invoked, there may be significant time needed to compile it in memory. Thus, when timing a function, run it at least once before beginning the timing.\n\nn = (200:100:2400)';\nt = zeros(size(n));\nfor k = 1:length(n)\n    A = randn(n(k), n(k));  \n    tic    % start a timer\n    for j = 1:6,  [L, U] = lu(A);  end\n    time = toc;\n    t(k) = time / 6;  \nend\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nclf\nloglog(n, t, 'o-')\nhold on\nloglog(n, 0.5 * t(end) * (n/n(end)).^3, 'k--')\naxis tight\nxlabel('size of matrix'), ylabel('time (sec)')\ntitle('Timing of LU factorization')\nlegend('lu','O(n^3)','location','southeast');","type":"content","url":"/chapter2-1#id-2-5","position":15},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.6 Row pivoting","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-6","position":16},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.6 Row pivoting","lvl2":"Examples"},"content":"Example 2.6.1\n\nHere is a previously encountered matrix that factors well.\n\nA = [\n    2 0 4 3\n    -4 5 -7 -10\n    1 15 2 -4.5\n    -2 0 2 -13\n    ];\n[L, U] = lufact(A);\nL\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA([2, 4], :) = A([4, 2], :);    % swap rows 2 and 4\n[L, U] = lufact(A);\nL\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU(1, :) = A(1, :);\nL(:, 1) = A(:, 1) / U(1, 1)\nA = A - L(:, 1) * U(1, :)\n\nThe next step is U(2, :) = A(2, :), which is also OK. But then we are supposed to divide by U(2, 2), which is zero. The algorithm cannot continue.\n\nExample 2.6.2\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nTip\n\nThe second output of max returns the location of the largest element of a vector. The ~ symbol is used to ignore the value of the first output.\n\n[~, i] = max( abs(A_1(:, 1)) )\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL = zeros(4, 4);\nU = zeros(4, 4);\nU(1, :) = A_1(i, :);\nL(:, 1) = A_1(:, 1) / U(1, 1);\nA_2 = A_1 - L(:, 1) * U(1, :)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\n[~, i] = max( abs(A_2(:, 2)) )\nU(2, :) = A_2(i, :);\nL(:, 2) = A_2(:, 2) / U(2, 2);\nA_3 = A_2 - L(:, 2) * U(2, :)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\n[~, i] = max( abs(A_3(:, 3)) ) \nU(3, :) = A_3(i, :);\nL(:, 3) = A_3(:, 3) / U(3, 3);\nA_4 = A_3 - L(:, 3) * U(3, :)\n\n[~, i] = max( abs(A_4(:, 4)) ) \nU(4, :) = A_4(i, :);\nL(:, 4) = A_4(:, 4) / U(4, 4);\n\nWe do have a factorization of the original matrix:\n\nA_1 - L * U\n\nAnd \\mathbf{U} has the required structure:\n\nU\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nL\n\nExample 2.6.3\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = [2 0 4 3; -2 0 2 -13; 1 15 2 -4.5; -4 5 -7 -10]\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1. If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A([4, 3, 2, 1], :);\n[L, U] = lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nU\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nL\n\nExample 2.6.4\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = randi(20, 4, 4);\n[L, U, p] = plufact(A);\nA(p, :) - L * U    % should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = rand(4, 1);\nz = forwardsub(L, b(p));\nx = backsub(U, z)\n\nA residual check is successful:\n\nb - A*x\n\nExample 2.6.5\n\nWith the syntax A \\ b, the matrix A is PLU-factored, followed by two triangular solves.\n\nA = randn(500, 500);    % 500x500 with normal random entries\ntic; for k=1:50; A \\ rand(500, 1); end; toc\n\nIn \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per unique matrix.\n\n[L, U, p] = lu(A, 'vector');    % keep factorization result\ntic\nfor k=1:50\n    b = rand(500, 1);\n    U \\ (L \\ b(p));\nend\ntoc\n\nExample 2.6.6\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1, 1]:\n\nep = 1e-12\nA = [-ep 1; 1 -1];\nb = A * [1; 1];\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20; A = [-ep 1; 1 -1];\nb = A * [1; 1];\n[L, U] = lufact(A);\nx = backsub( U, forwardsub(L, b) )\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nA \\ b","type":"content","url":"/chapter2-1#id-2-6","position":17},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.7 Vector and matrix norms","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-7","position":18},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.7 Vector and matrix norms","lvl2":"Examples"},"content":"Example 2.7.1\n\nx = [2; -3; 1; -1];\ntwonorm = norm(x)    % or norm(x, 2)\n\ninfnorm = norm(x, Inf)\n\nonenorm = norm(x, 1)\n\nExample 2.7.2\n\nA = [ 2 0; 1 -1 ]\n\nThe default matrix norm is the 2-norm.\n\ntwonorm = norm(A)\n\nYou can get the 1-norm as well.\n\nonenorm = norm(A, 1)\n\nAccording to \n\n(2.7.15), the matrix 1-norm is equivalent to the maximum of the sums down the columns (in absolute value).\n\nTip\n\nUse sum to sum along a dimension of a matrix. The max and min functions also work along one dimension.\n\n% Sum down the rows (1st matrix dimension):\nmax( sum(abs(A), 1) )\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\ninfnorm = norm(A, Inf)\n\n% Sum across columns (2nd matrix dimension):\nmax( sum(abs(A), 2) )\n\nNext we illustrate a geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\nTip\n\nYou can use functions as values, e.g., as elements of a vector.\n\ntheta = linspace(0, 2*pi, 601);\nx = [ cos(theta); sin(theta) ];    % 601 unit column vectors\nclf\nsubplot(1, 2, 1)\nplot(x(1, :), x(2, :)), axis equal\ntitle('Unit circle in 2-norm')\nxlabel('x_1')\nylabel(('x_2'));\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x by using a single matrix multiplication.\n\nAx = A * x;\n\nThe image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2:\n\nsubplot(1,2,2), plot(Ax(1,:), Ax(2,:)), axis equal\nhold on, plot(twonorm * x(1,:), twonorm * x(2,:), '--')\ntitle('Image of Ax, with ||A||')\nxlabel('x_1')\nylabel(('x_2'));","type":"content","url":"/chapter2-1#id-2-7","position":19},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.8 Conditioning of linear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-8","position":20},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.8 Conditioning of linear systems","lvl2":"Examples"},"content":"Example 2.8.1\n\nMATLAB has a function cond to compute matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6 case.\n\nA = hilb(6)\nkappa = cond(A)\n\nBecause \\kappa\\approx 10^8, it’s possible to lose nearly 8 digits of accuracy in the process of passing from \\mathbf{A} and \\mathbf{b} to \\mathbf{x}. That fact is independent of the algorithm; it’s inevitable once the data are expressed in finite precision.\n\nLet’s engineer a linear system problem to observe the effect of a perturbation. We will make sure we know the exact answer.\n\nx = (1:6)';\nb = A * x;\n\nNow we perturb the system matrix and vector randomly by \n\n10-10 in norm.\n\ndA = randn(size(A));  dA = 1e-10 * (dA / norm(dA));\ndb = randn(size(b));  db = 1e-10 * (db / norm(db));\n\nWe solve the perturbed problem using pivoted LU and see how the solution was changed.\n\nnew_x = ((A + dA) \\ (b + db));\ndx = new_x - x;\n\nHere is the relative error in the solution.\n\nrelative_error = norm(dx) / norm(x)\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nupper_bound_b = (kappa * norm(db) / norm(b))\nupper_bound_A = (kappa * norm(dA) / norm(A))\n\nEven if we didn’t make any manual perturbations to the data, machine roundoff does so at the relative level of \\macheps.\n\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\nrounding_bound = kappa * eps\n\nLarger Hilbert matrices are even more poorly conditioned:\n\nA = hilb(14);\nkappa = cond(A)\n\nNote that κ exceeds 1/\\macheps. In principle we therefore may end up with an answer that has relative error greater than 100%.\n\nrounding_bound = kappa * eps\n\nLet’s put that prediction to the test.\n\nx = (1:14)';  b = A * x;\ndx = A\\b - x;\nrelative_error = norm(dx) / norm(x)\n\nAs anticipated, the solution has zero accurate digits in the 2-norm.","type":"content","url":"/chapter2-1#id-2-8","position":21},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.9 Exploiting matrix structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-1#id-2-9","position":22},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.9 Exploiting matrix structure","lvl2":"Examples"},"content":"Example 2.9.1\n\nHere is a small tridiagonal matrix. Note that there is one fewer element on the super- and subdiagonals than on the main diagonal.\n\nA = [ 2 -1  0  0  0  0\n      4  2 -1  0  0  0\n      0  3  0 -1  0  0\n      0  0  2  2 -1  0\n      0  0  0  1  1 -1\n      0  0  0  0  0  2 ];\n\nWe can extract the elements on any diagonal using the diag function. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nTip\n\nThe diag function extracts the elements from a specified diagonal of a matrix.\n\ndiag_main = diag(A, 0)'\ndiag_plusone = diag(A, 1)'\ndiag_minusone = diag(A,-1)'We can also put whatever numbers we like onto any diagonal with `diag`.\n\nA = A + diag([5 8 6 7], 2)\n\nThe lower and upper bandwidths of \\mathbf{A} are repeated in the factors from the unpivoted LU factorization.\n\n[L, U] = lufact(A)\n\nExample 2.9.2\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = [ 2     4     4     2\n        4     5     8    -5\n        4     8     6     2\n        2    -5     2   -26 ];\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4);\nd = zeros(4, 1);\nd(1) = A_1(1, 1);\nL(:, 1) = A_1(:, 1) / d(1);\nA_2 = A_1 - d(1) * L(:, 1) * L(:, 1)'\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd(2) = A_2(2, 2);\nL(:, 2) = A_2(:, 2) / d(2);\nA_3 = A_2 - d(2) * L(:, 2) * L(:, 2)'\n\nWe continue working our way down the diagonal.\n\nd(3) = A_3(3, 3);\nL(:, 3) = A_3(:, 3) / d(3);\nA_4 = A_3 - d(3) * L(:, 3) * L(:, 3)'\nd(4) = A_4(4, 4);\nd\nL\n\nWe have arrived at the desired factorization, which we can validate:\n\nnorm(A_1 - (L * diag(d) * L'))\n\nExample 2.9.3\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = magic(4) + eye(4);\nB = A + A'\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nTip\n\nThe chol function computes a Cholesky factorization if possible, or throws an error for a non-positive-definite matrix.\n\nWarning\n\nThe chol function does not check for symmetry. It may give a nonsensical result if the input is not symmetric.\n\nchol(B)    % throws an error\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization.\n\nB = A' * A;\nR = chol(B)\n\nHere we validate the factorization:\n\nnorm(R' * R - B) / norm(B)","type":"content","url":"/chapter2-1#id-2-9","position":23},{"hierarchy":{"lvl1":"Chapter 3"},"type":"lvl1","url":"/chapter3-1","position":0},{"hierarchy":{"lvl1":"Chapter 3"},"content":"","type":"content","url":"/chapter3-1","position":1},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"type":"lvl2","url":"/chapter3-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"content":"Solution of least squares by the normal equations\n\nfunction x = lsnormal(A,b)\r\n% LSNORMAL   Solve linear least squares by normal equations.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\nN = A'*A;  z = A'*b;\r\nR = chol(N);\r\nw = forwardsub(R',z);                   % solve R'z=c\r\nx = backsub(R,w);                       % solve Rx=z\n\nSolution of least squares by QR factorization\n\nfunction x = lsqrfact(A,b)\r\n% LSQRFACT   Solve linear least squares by QR factorization.\r\n% Input: \r\n%   A     coefficient matrix (m by n, m>n)\r\n%   b     right-hand side (m by 1)\r\n% Output:\r\n%   x     minimizer of || b-Ax ||\r\n\r\n[Q,R] = qr(A,0);                        % compressed factorization\r\nc = Q'*b;\r\nx = backsub(R,c);                       \n\nQR factorization by Householder reflections\n\nfunction [Q,R] = qrfact(A)\r\n% QRFACT   QR factorization by Householder reflections.\r\n% (demo only--not efficient)\r\n% Input:\r\n%   A      m-by-n matrix\r\n% Output:\r\n%   Q,R    A=QR, Q m-by-m orthogonal, R m-by-n upper triangular\r\n\r\n[m,n] = size(A);\r\nQ = eye(m);\r\nfor k = 1:n\r\n  z = A(k:m,k);\r\n  v = [ -sign(z(1))*norm(z) - z(1); -z(2:end) ];\r\n  nrmv = norm(v);\r\n  if nrmv < eps, continue, end       % nothing is done in this iteration\r\n  v = v / nrmv;                      % removes v'*v in other formulas\r\n  % Apply the reflection to each relevant column of A and Q\r\n  for j = 1:n\r\n    A(k:m,j) = A(k:m,j) - v*( 2*(v'*A(k:m,j)) );\r\n  end\r\n  for j = 1:m\r\n    Q(k:m,j) = Q(k:m,j) - v*( 2*(v'*Q(k:m,j)) );\r\n  end\r\nend\r\n\r\nQ = Q';\r\nR = triu(A);                         % enforce exact triangularity","type":"content","url":"/chapter3-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"type":"lvl2","url":"/chapter3-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter3-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.1 Fitting functions to data","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#id-3-1","position":6},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.1 Fitting functions to data","lvl2":"Examples"},"content":"Example 3.1.1\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nt = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\nscatter(t, y), axis tight\nxlabel('year')\nylabel(('anomaly ({\\circ}C)'));\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (t - 1950) / 10;  \nn = length(t);\nV = ones(n, 1);    % t^0\nfor j = 1:n-1\n    V(:, j+1) = t .* V(:,j);\nend\nc = V \\ y;    % solve for coefficients\n\nWe created the Vandermonde matrix columns in increasing-degree order. Thus, the coefficients in c also follow that ordering, which is the opposite of what MATLAB uses. We need to flip the coefficients before using them in polyval.\n\np = @(year) polyval(c(end:-1:1), (year - 1950) / 10);\nhold on\nfplot(p, [1955, 2000])    % plot the interpolating function\n\nExample 3.1.2\n\nHere are the 5-year temperature averages again.\n\nyear = (1955:5:2000)';\ny = [ -0.0480; -0.0180; -0.0360; -0.0120; -0.0040;\n    0.1180; 0.2100; 0.3320; 0.3340; 0.4560 ];\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nTip\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nt = (year - 1955) / 10;    % better matrix conditioning later\nV = [ t.^0 t ];            % Vandermonde-ish matrix\nsize(V)\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\n\nclf\nscatter(year, y), axis tight\nxlabel('year'), ylabel('anomaly ({\\circ}C)')\nhold on\nfplot(f, [1955, 2000])\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = [t.^0, t.^1, t.^2, t.^3];    % Vandermonde-ish matrix  \nsize(V)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nTip\n\nThe definition of f above is in terms of c. When c is changed, then f has to be redefined.\n\nc = V \\ y;\nf = @(year) polyval(c(end:-1:1), (year - 1955) / 10);\nfplot(f, [1955, 2000]) \nlegend('data', 'linear', 'cubic', 'Location', 'northwest');\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nExample 3.1.3\n\nk = (1:100)';\na = 1./k.^2;      % sequence\ns = cumsum(a);    % cumulative summation\np = sqrt(6*s);\nclf\nplot(k, p, 'o-')\nxlabel('k'), ylabel('p_k')\ntitle('Sequence converging to \\pi')\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p);    % error sequence\nloglog(k, ep, 'o')\ntitle('Convergence')\nxlabel('k'), ylabel('|p_k - \\pi|'), axis tight\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = [ k.^0, log(k) ];    % fitting matrix\nc = V \\ log(ep)          % coefficients of linear fit\n\nIn terms of the parameters a and b used above, we have\n\na = exp(c(1)),  b = c(2)\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nhold on\nloglog(k, a * k.^b)\nlegend('sequence', 'power-law fit');","type":"content","url":"/chapter3-1#id-3-1","position":7},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.2 The normal equations","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#id-3-2","position":8},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.2 The normal equations","lvl2":"Examples"},"content":"Example 3.2.1\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nTip\n\nThe local variable scoping rule for loops applies to comprehensions as well.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nkappa = cond(A)\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = [1; 2; 1];\nb = A * x;\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nx_BS = A \\ b;\nobserved_err = norm(x_BS - x) / norm(x)\nmax_err = kappa * eps\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A'*A;\nx_NE = N\\(A'*b);\nobserved_err = norm(x_NE - x) / norm(x)\ndigits = -log10(observed_err)","type":"content","url":"/chapter3-1#id-3-2","position":9},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.3 The QR factorization","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#id-3-3","position":10},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.3 The QR factorization","lvl2":"Examples"},"content":"Example 3.3.1\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = magic(5);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nHere is the full form:\n\n[Q, R] = qr(A);\nszQ = size(Q), szR = size(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nQTQ = Q' * Q\nnorm(QTQ - eye(m))\n\nWith a second input argument given to qr, the thin form is returned. (This is usually the one we want in practice.)\n\n[Q_hat, R_hat] = qr(A, 0);\nszQ_hat = size(Q_hat), szR_hat = size(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nQ_hat' * Q_hat - eye(n)\n\nExample 3.3.2\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)';\nA = [ sin(t).^2, cos((1+1e-7)*t).^2, t.^0 ];\nx = [1; 2; 1];\nb = A * x;\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nobserved_error = norm(lsqrfact(A, b) - x) / norm(x)\nerror_bound = cond(A) * eps","type":"content","url":"/chapter3-1#id-3-3","position":11},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.4 Computing QR factorizations","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-1#id-3-4","position":12},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.4 Computing QR factorizations","lvl2":"Examples"},"content":"Example 3.4.1\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = magic(6);\nA = A(:, 1:4);\n[m, n] = size(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A(:, 1);\nv = z - norm(z) * eye(m,1);\nP_1 = eye(m) - 2 / (v' * v) * (v * v');\n\nWe check that this reflector introduces zeros as it should:\n\nP_1 * z\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 * A\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A(2:m, 2);\nv = z - norm(z) * eye(m-1, 1);\nP_2 = eye(m-1) - 2 / (v' * v) * (v * v');\n\nWe now apply this reflector to rows 2 and below only.\n\nA(2:m, 2:n) = P_2 * A(2:m, 2:n)\n\nWe need to iterate the process for the last two columns.\n\nfor j = 3:n\n    z = A(j:m,j);\n    k = m-j+1;\n    v = z - norm(z) * eye(k, 1);\n    P = eye(k) - 2 / (v' * v) * (v * v');\n    A(j:m, j:n) = P * A(j:m, j:n);\nend\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = A","type":"content","url":"/chapter3-1#id-3-4","position":13},{"hierarchy":{"lvl1":"Chapter 4"},"type":"lvl1","url":"/chapter4-1","position":0},{"hierarchy":{"lvl1":"Chapter 4"},"content":"","type":"content","url":"/chapter4-1","position":1},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"type":"lvl2","url":"/chapter4-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"content":"Newton’s method\n\nfunction x = newton(f,dfdx,x1)\r\n% NEWTON   Newton's method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   dfdx     derivative function\r\n%   x1       initial root approximation\r\n% Output       \r\n%   x        vector of root approximations (last one is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = x1;  \r\ny = f(x1);\r\ndx = Inf;   % for initial pass below\r\nk = 1;\r\n\r\nwhile (abs(dx) > xtol) && (abs(y) > funtol) && (k < maxiter)\r\n    dydx = dfdx(x(k));\r\n    dx = -y/dydx;           % Newton step\r\n    x(k+1) = x(k) + dx;\r\n\r\n    k = k+1;\r\n    y = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n  warning('Maximum number of iterations reached.')\r\nend\n\nSecant method\n\nfunction x = secant(f,x1,x2)\r\n% SECANT   Secant method for a scalar equation.\r\n% Input:\r\n%   f        objective function \r\n%   x1,x2    initial root approximations\r\n% Output       \r\n%   x        vector of root approximations (last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 100*eps;  xtol = 100*eps;  maxiter = 40;\r\n\r\nx = [x1 x2];\r\ndx = Inf;  y1 = f(x1);\r\nk = 2;  y2 = f(x2);\r\n\r\nwhile (abs(dx) > xtol) && (abs(y2) > funtol) && (k < maxiter)\r\n    dx = -y2 * (x(k)-x(k-1)) / (y2-y1);   % secant step\r\n    x(k+1) = x(k) + dx;\r\n    \r\n    k = k+1;\r\n    y1 = y2;    % current f-value becomes the old one next time\r\n    y2 = f(x(k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nNewton’s method for systems\n\nfunction x = newtonsys(f,x1)\r\n% NEWTONSYS   Newton's method for a system of equations.\r\n% Input:\r\n%   f        function that computes residual and Jacobian matrix\r\n%   x1       initial root approximation (n-vector)\r\n% Output       \r\n%   x        array of approximations (one per column, last is best)\r\n\r\n% Operating parameters.\r\nfuntol = 1000*eps;  xtol = 1000*eps;  maxiter = 40;\r\n\r\nx = x1(:);  \r\n[y,J] = f(x1);\r\ndx = Inf;\r\nk = 1;\r\n\r\nwhile (norm(dx) > xtol) && (norm(y) > funtol) && (k < maxiter)\r\n    dx = -(J\\y);   % Newton step\r\n    x(:,k+1) = x(:,k) + dx;\r\n\r\n    k = k+1;\r\n    [y,J] = f(x(:,k));\r\nend\r\n\r\nif k==maxiter\r\n    warning('Maximum number of iterations reached.')\r\nend\n\nFinite differences for Jacobian\n\nfunction J = fdjac(f,x0,y0)\n% FDJAC   Finite-difference approximation of a Jacobian.\n% Input:\n%   f        function to be differentiated\n%   x0       evaluation point (n-vector)\n%   y0       value of f at x0 (m-vector)\n% Output       \n%   J        approximate Jacobian (m-by-n)\n\ndelta = sqrt(eps);   % FD step size\nm = length(y0);  n = length(x0);\nJ = zeros(m,n);\nI = eye(n);\nfor j = 1:n\n    J(:,j) = ( f(x0+delta*I(:,j)) - y0) / delta;\nend\n\nLevenberg’s method\n\nfunction x = levenberg(f,x1,tol)\r\n% LEVENBERG   Quasi-Newton method for nonlinear systems.\r\n% Input:\r\n%   f         objective function \r\n%   x1        initial root approximation\r\n%   tol       stopping tolerance (default is 1e-12)\r\n% Output       \r\n%   x         array of approximations (one per column)\r\n\r\n% Operating parameters.\r\nif nargin < 3, tol = 1e-12; end\r\nftol = tol;  xtol = tol;  maxiter = 40;\r\n\r\nx = x1(:);     fk = f(x1);\r\nk = 1;  s = Inf;        \r\nAk = fdjac(f,x(:,1),fk);   % start with FD Jacobian\r\njac_is_new = true;\r\nI = eye(length(x));\r\n\r\nlambda = 10; \r\nwhile (norm(s) > xtol) && (norm(fk) > ftol) && (k < maxiter)\r\n    % Compute the proposed step.\r\n    B = Ak'*Ak + lambda*I;\r\n    z = Ak'*fk;\r\n    s = -(B\\z);\r\n\r\n    xnew = x(:,k) + s;   fnew = f(xnew);\r\n    \r\n    % Do we accept the result?\r\n    if norm(fnew) < norm(fk)    % accept\r\n        y = fnew - fk;\r\n        x(:,k+1) = xnew;  fk = fnew;  \r\n        k = k+1;\r\n        \r\n        lambda = lambda/10;  % get closer to Newton\r\n        % Broyden update of the Jacobian.\r\n        Ak = Ak + (y-Ak*s)*(s'/(s'*s));\r\n        jac_is_new = false;\r\n    else                       % don't accept\r\n        % Get closer to steepest descent.\r\n        lambda = lambda*4;\r\n        % Re-initialize the Jacobian if it's out of date.\r\n        if ~jac_is_new\r\n            Ak = fdjac(f,x(:,k),fk);\r\n            jac_is_new = true;\r\n        end\r\n    end\r\nend\r\n\r\nif (norm(fk) > 1e-3)\r\n    warning('Iteration did not find a root.')\r\nend","type":"content","url":"/chapter4-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"type":"lvl2","url":"/chapter4-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter4-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.1 The rootfinding problem","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-1","position":6},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.1 The rootfinding problem","lvl2":"Examples"},"content":"Example 4.1.1\n\nJ3 = @(x) besselj(3,x);\nfplot(J3, [0, 20])\ngrid on\nxlabel('x'), ylabel('J_3(x)')  \ntitle('Bessel function')\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use nlsolve from the NLsolve package to find these roots accurately. It uses vector variables, so we have to code accordingly.\n\nTip\n\nType \\omega followed by Tab to get the character ω.\nThe argument ftol=1e-14 below is called a keyword argument. Here it sets a goal for the maximum value of |f(x)|.\n\nomega = [];\nfor guess = [6, 10, 13, 16, 19]\n    omega = [omega; fzero(J3, guess)];\nend\nomega\n\ntable(omega, J3(omega), 'VariableNames', {'root estimate', 'function value'})\n\nhold on\nscatter(omega, J3(omega))\ntitle('Bessel roots')\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = [];\nfor guess = [3, 6, 10, 13]\n    f = @(x) J3(x) - 0.2;\n    omega = [omega; fzero(f, guess)];\nend\nscatter(omega, J3(omega), '<')\n\nExample 4.1.2\n\nConsider first the function\n\nf  = @(x) (x - 1) .* (x - 2);\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nclf\ninterval = [0.8, 1.2];\nfplot(f, interval)\ngrid on, hold on\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\naxis equal,  yticks([0])\nylim([-0.1, 0.1])\nxlabel('x'), ylabel('f(x)')\ntitle('Well-conditioned root')\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = @(x) (x - 1) .* (x - 1.01);\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\naxis(axis), cla\nfplot(f, interval)\nfplot(@(x) f(x) + 0.02, interval, 'k')\nfplot(@(x) f(x) - 0.02, interval, 'k')\nylim([-0.1, 0.1]), yticks([0])\ntitle('Poorly conditioned root')\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!","type":"content","url":"/chapter4-1#id-4-1","position":7},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.2 Fixed-point iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-2","position":8},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.2 Fixed-point iteration","lvl2":"Examples"},"content":"Example 4.2.1\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5])\n\nWe define g(x)=x-p(x).\n\ng = @(x) x - f(x);\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nclf\nfplot(g, [2, 3])\nhold on,  plot([2, 3], [2, 3], 'k')\ntitle('Finding a fixed point'),  axis equal  \nxlabel('x'),  ylabel('y')\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1;\ny = g(x)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nplot([x, y], [y, y], '-')\nx = y;\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\ny = g(x)\nplot([x, x],[x, y], '-')\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k = 1:5\n    plot([x, y], [y, y], '-')\n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-')  \nend\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nabs(y - r(1)) / r(1)\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\ncla\nfplot(g, [1, 2])\nhold on, plot([1, 2], [1, 2], 'k')\nylim([1, 2])\nx = 1.3;  y = g(x);\nfor k = 1:5\n    plot([x, y], [y, y], '-'),  \n    x = y;       % y --> new x\n    y = g(x);    % g(x) --> new y\n    plot([x, x], [x, y], '-') \nend\ntitle('No convergence')\n\nThis time, the iteration is pushing us away from the correct answer.\n\nExample 4.2.3\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = @(x) x.^2 - 4*x + 3.5;\nr = roots([1, -4, 3.5]);\n\nHere is the fixed-point iteration. This time we keep track of the whole sequence of approximations.\n\ng = @(x) x - f(x);\nx = 2.1; \nfor k = 1:12\n    x(k+1) = g(x(k));\nend\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - r(1));\nclf\nsemilogy(err, 'o-'), axis tight\nxlabel('iteration'),  ylabel('error')\ntitle('Convergence of fixed-point iteration')\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\ny = log(err(5:12));\np = polyfit(5:12, y, 1);\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nsigma = exp(p(1))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr(9:12) ./ err(8:11)\n\nThe methods for finding σ agree well.","type":"content","url":"/chapter4-1#id-4-2","position":9},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.3 Newton’s method","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-3","position":10},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.3 Newton’s method","lvl2":"Examples"},"content":"Example 4.3.1\n\nSuppose we want to find a root of the function\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0, 1.5])\nxlabel('x'), ylabel('y')    \nset(gca, 'ygrid', 'on')  \ntitle('Objective function')\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1;\ny1 = f(x1)\nhold on, scatter(x1, y1, 'k')\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx = @(x) exp(x) .* (x + 1);\nslope1 = df_dx(x1);\ntangent1 = @(x) y1 + slope1 * (x - x1);\naxis(axis)\nfplot(tangent1, [0, 1.5], 'k--')\ntitle('Function and tangent line')\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nscatter(x2, 0, 'r')\ntitle('Root of the tangent')\n\ny2 = f(x2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\ncla,  axis auto\nfplot(f, [0.83, 0.88])\nscatter(x2, y2, 'k')\nslope2 = df_dx(x2);\ntangent2 = @(x) y2 + slope2 * (x - x2);\naxis(axis)\nfplot(tangent2, [0.8, 0.9], 'k--')\nx3 = x2 - y2 / slope2;\nscatter(x3, 0, 'r')\ntitle('Next iteration')\n\ny3 = f(x3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nExample 4.3.2\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = @(x) x.*exp(x) - 2;\ndf_dx = @(x) exp(x).*(x+1);\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nformat long,  r = fzero(f,1)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = 1;\nfor k = 1:6\n    x(k+1) = x(k) - f(x(k)) / df_dx(x(k));\nend\nx\n\nHere is the sequence of errors.\n\nformat short e\nerr = x' - r\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nformat short\nlogerr = log(abs(err))\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nExample 4.3.3\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=e^x-x for x when y is given, which has no elementary form. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nTip\n\nWhen a function is created, it can refer to any variables in scope at that moment. Those values are locked in to the definition, which is called a closure. If the enclosed variables change values later, the function still uses the values it was created with.\n\nh = @(x) exp(x) - x;\ndh_dx = @(x) exp(x) - 1;\ny_ = linspace(h(0), h(2), 200);\nx_ = zeros(size(y_));\nfor i = 1:length(y_)\n    f = @(x) h(x) - y_(i);\n    df_dx = @(x) dh_dx(x);\n    x = newton(f, df_dx, 1);  x_(i) = x(end);\nend\n\nclf, fplot(h, [0, 2])\nhold on, axis equal\nplot(y_, x_)\nplot([0, max(y_)], [0, max(y_)], 'k--')\nxlabel('x'), ylabel('y')\nlegend('h(x)', 'inverse', 'y=x');","type":"content","url":"/chapter4-1#id-4-3","position":11},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.4 Interpolation-based methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-4","position":12},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.4 Interpolation-based methods","lvl2":"Examples"},"content":"Example 4.4.1\n\nWe return to finding a root of the equation x e^x=2.\n\nf = @(x) x .* exp(x) - 2;\nclf, fplot(f, [0.25, 1.25])\nset(gca, 'ygrid', 'on')  \nxlabel('x'), ylabel('y')    \ntitle('Objective function')\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1;    y1 = f(x1);\nx2 = 0.5;  y2 = f(x2);\nhold on, scatter([x1, x2], [y1, y2])\ntitle('Two initial values')\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1);\nsecant2 = @(x) y2 + slope2 * (x - x2);\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nfplot(secant2,[0.25, 1.25],'k--')\nx3 = x2 - y2 / slope2;\ny3 = f(x3)\nscatter(x3, 0)\ntitle('Next value')\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope2 = (y3 - y2) / (x3 - x2);\nx4 = x3 - y3 / slope2;\ny4 = f(x4)\n\nExample 4.4.2\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = @(x) x .* exp(x) - 2;\nx = secant(f, 1, 0.5);\n\nWe don’t know the exact root, so we use fzero to get a good proxy.\n\nr = fzero(f, 1);\n\nHere is the sequence of errors.\n\nformat short e\nerr = r - x(1:end-1)'\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)\n\nAs expected, this settles in at around 1.618.\n\nExample 4.4.3\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = @(x) x + cos(10 * x);\ninterval = [0.5, 1.5];\nclf, fplot(f, interval)\nset(gca, 'ygrid', 'on'), axis(axis)   \ntitle('Objective function')    \nxlabel('x'), ylabel('y')    \nr = fzero(f, 1)\n\nWe choose three values to get the iteration started.\n\nx = [0.8, 1.2, 1]';\ny = f(x);\nhold on, scatter(x, y)\ntitle('Three initial points')\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nc = polyfit(x, y, 2);    % coefficients of interpolant\nq = @(x) polyval(c, x);\nfplot(q, interval, '--')\ntitle('Parabola model')\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nTip\n\nBy giving two functions in the fplot call, we get the parametric plot (q(y),y) as a function of y.\n\ncla, fplot(f, interval)\nscatter(x, y)     \nc = polyfit(y, x, 2);    % coefficients of interpolating polynomial\nq = @(y) polyval(c, y);\nfplot(q, @(y) y, ylim,'--')    % plot x=q(y), y=y\ntitle('Sideways parabola')\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = [x; q(0)];\ny = [y; f(x(end))]\n\nWe repeat the process a few more times.\n\nfor k = 4:8\n    c = polyfit(y(k-2:k), x(k-2:k), 2);\n    x(k+1) = polyval(c, 0);\n    y(k+1) = f(x(k+1));\nend\ndisp('final residual:')\ny(end)\n\nHere is the sequence of errors.\n\nformat short e\nerr = x - r\n\nThe convergence is probably superlinear:\n\nlogerr = log(abs(err));\nratios = logerr(2:end) ./ logerr(1:end-1)","type":"content","url":"/chapter4-1#id-4-4","position":13},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.5 Newton for nonlinear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-5","position":14},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.5 Newton for nonlinear systems","lvl2":"Examples"},"content":"Example 4.5.3\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\nTip\n\nThis function needs to be defined within a script file or in a file of its own with the .m extension.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nSince our system function is defined in an external file here, we need to use @ in order to reference it as a function argument.\n\nnlsystem = @f45_nlsystem;\nx1 = [0; 0; 0];    % column vector!\nx = newtonsys(nlsystem, x1);\nnum_iter = size(x, 2)\n\nLet’s compute the residual of the last result in order to check the quality.\n\nr = x(:, end)\nback_err = norm(nlsystem(r))\n\nWe take the sequence errors in the first component of the solution, applying the log so that we can look at the exponents.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'\n\nThis sequence looks to be nearly doubling at each iteration, which is a good sign of quadratic convergence.","type":"content","url":"/chapter4-1#id-4-5","position":15},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.6 Quasi-Newton methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-6","position":16},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.6 Quasi-Newton methods","lvl2":"Examples"},"content":"Example 4.6.1\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\nTip\n\nA rule of thumb is that if you use a function as an input argument for another function, there needs to be an @ involved once: either for an anonymous definition or to reference a function defined elsewhere.\n\nfunction [f, J] = nlsystem(x)\n    f = zeros(3, 1);   % ensure a column vector output\n    f(1) = exp(x(2) - x(1)) - 2;\n    f(2) = x(1) * x(2) + x(3);\n    f(3) = x(2) * x(3) + x(1)^2 - x(2);\n    J(1, :) = [-exp(x(2) - x(1)), exp(x(2) - x(1)), 0];\n    J(2, :) = [x(2), x(1), 1];\n    J(3, :) = [2 * x(1), x(3)-1, x(2)];\nend\n\nIn all other respects usage is the same as for the newtonsys function.\n\nf = @f46_nlsystem;\nx1 = [0; 0; 0];   \nx = levenberg(f, x1);\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x(:, end)\nbackward_err = norm(f(r))\n\nLooking at the convergence of the first component, we find a rate between linear and quadratic, like with the secant method.\n\nlog10( abs(x(1, 1:end-1) - r(1)) )'","type":"content","url":"/chapter4-1#id-4-6","position":17},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.7 Nonlinear least squares","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-1#id-4-7","position":18},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.7 Nonlinear least squares","lvl2":"Examples"},"content":"Example 4.7.1\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = @(x) [sin(x(1) + x(2)); cos(x(1) - x(2)); exp(x(1) - x(2))];\np = [1; 1];\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nTip\n\n@sprintf is a way to format numerical values as strings, patterned after the C function printf.\n\nclf\nlabels = [];\nfor R = [1e-3, 1e-2, 1e-1]\n    % Define the perturbed function.\n    f = @(x) g(x) - g(p) + R * [-1; 1; -1] / sqrt(3)\n    x = levenberg(f, [0; 0]);\n    r = x(:, end);\n    err = abs(x(1, 1:end-1) - r(1));\n    normres = norm(f(r));\n    semilogy(err), hold on\n    labels = [labels; sprintf(\"R=%.2g\", normres)];\nend\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend(labels);\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nExample 4.7.2\n\nm = 25; V = 2; Km = 0.5;\ns = linspace(0.05, 6, m)';\nw = V * s ./ (Km + s);                      % exactly on the curve\nw = w + 0.15 * cos(2 * exp(s / 16) .* s);   % noise added\nclf, fplot(@(s) V * s ./ (Km + s), [0, 6], '--')\nhold on, scatter(s, w)\nxlabel('concentration'), ylabel('reaction rate')    \nlabels = [\"ideal\", \"noisy data\"];    \nlegend(labels, 'location', 'east');\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g. In the Jacobian, the derivatives are with respect to the parameters in \\mathbf{x}.\n\nfunction [f, J] = misfit(c, s, w)\n    V = c(1);   Km = c(2);\n    f = V * s ./ (Km + s) - w;\n    J(:,1) = s ./ (Km + s);            % d/d(V)\n    J(:,2) = -V * s ./ (Km + s).^2;    % d/d(Km)\nend\n\n\nThe misfit function above has to know the parameters x that are being optimized as well as the data s and w that remain fixed. We use a closure to pass the data values along.\n\nf = @(x) f47_misfit(x, s, w);\n\nNow we have a function that accepts a single 2-vector input and returns a 25-vector output. We can pass this function to levenberg to find the best-fit parameters.\n\nx1 = [1; 0.75];\nx = newtonsys(f, x1);\nV = x(1, end),  Km = x(2, end)     % final values\nmodel = @(s) V * s ./ (Km + s);    % best-fit model\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data:\n\nfinal_misfit_norm = norm(model(s) - w) \nhold on, fplot(model, [0, 6])\ntitle('Michaelis-Menten fitting')    \nlabels = [labels, \"nonlinear fit\"];    \nlegend(labels, 'location', 'east');\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nu = 1 ./ w;\nA = [s.^(-1), s.^0];  \nz = A \\ u;\nalpha = z(1);  beta = z(2);\n\nThe two fits are different because they do not optimize the same quantities.\n\nlinmodel = @(s) 1 ./ (beta + alpha ./ s);\nfinal_misfit_linearized = norm(linmodel(s) - w)\nfplot(linmodel, [0, 6])\nlabels = [labels, \"linearized fit\"];    \nlegend(labels, 'location', 'east');\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/chapter4-1#id-4-7","position":19},{"hierarchy":{"lvl1":"Chapter 5"},"type":"lvl1","url":"/chapter5-1","position":0},{"hierarchy":{"lvl1":"Chapter 5"},"content":"","type":"content","url":"/chapter5-1","position":1},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"type":"lvl2","url":"/chapter5-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"content":"Hat function\n\nfunction H = hatfun(t, k)\r\n% HATFUN   Hat function/piecewise linear basis function.\r\n% Input: \r\n%   t      interpolation nodes (vector, length n+1)\r\n%   k      node index (integer, in 0,...,n)\r\n% Output:\r\n%   H      kth hat function (function)\r\n\r\nn = length(t) - 1;\r\n\r\nfunction y = evaluate(x)\r\n    y = zeros(size(x));\r\n    for i = 1:numel(x)\r\n        if (k > 0) && (t(k) <= x(i)) && (x(i) <= t(k+1))\r\n            y(i) = (x(i) - t(k)) / (t(k+1) - t(k));\r\n        elseif (k < n) && (t(k+1) <= x(i)) && (x(i) <= t(k+2))\r\n            y(i) = (t(k+2) - x(i)) / (t(k+2) - t(k+1));\r\n        end\r\n    end\r\nend\r\n\r\nH = @evaluate;\r\nend\n\nPiecewise linear interpolation\n\nfunction p = plinterp(t,y)\r\n% PLINTERP   Piecewise linear interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   p     piecewise linear interpolant (function)\r\n\r\nn = length(t) - 1;\r\nH = {};\r\nfor k = 0:n\r\n    H{k+1} = hatfun(t, k);\r\nend\r\np = @evaluate;\r\n\r\n    % This function evaluates p when called.\r\n    function f = evaluate(x)\r\n        f = 0;\r\n        for k = 0:n\r\n            f = f + y(k+1) * H{k+1}(x);\r\n        end\r\n    end\r\n\r\nend\n\nCubic spline interpolation\n\nfunction S = spinterp(t,y)\r\n% SPINTERP   Cubic not-a-knot spline interpolation.\r\n% Input:\r\n%   t     interpolation nodes (vector, length n+1)\r\n%   y     interpolation values (vector, length n+1)\r\n% Output:\r\n%   S     not-a-knot cubic spline (function)\r\n\r\nt = t(:);  y = y(:);  % ensure column vectors\r\nn = length(t)-1;\r\nh = diff(t);          % differences of all adjacent pairs\r\n\r\n% Preliminary definitions.\r\nZ = zeros(n);\r\nI = eye(n);  E = I(1:n-1,:);\r\nJ = I - diag(ones(n-1,1),1);\r\nH = diag(h);\r\n\r\n% Left endpoint interpolation:\r\nAL = [ I, Z, Z, Z ];\r\nvL = y(1:n);\r\n\r\n% Right endpoint interpolation:\r\nAR = [ I, H, H^2, H^3 ];\r\nvR = y(2:n+1);\r\n\r\n% Continuity of first derivative:\r\nA1 = E*[ Z, J, 2*H, 3*H^2 ];\r\nv1 = zeros(n-1,1);\r\n\r\n% Continuity of second derivative:\r\nA2 = E*[ Z, Z, J, 3*H ];\r\nv2 = zeros(n-1,1);\r\n\r\n% Not-a-knot conditions:\r\nnakL = [ zeros(1,3*n), [1,-1, zeros(1,n-2)] ];\r\nnakR = [ zeros(1,3*n), [zeros(1,n-2), 1,-1] ];\r\n\r\n% Assemble and solve the full system.\r\nA = [ AL; AR; A1; A2; nakL; nakR ];\r\nv = [ vL; vR; v1; v2; 0 ;0 ];\r\nz = A\\v;\r\n\r\n% Break the coefficients into separate vectors.\r\nrows = 1:n;\r\na = z(rows);\r\nb = z(n+rows);  c = z(2*n+rows);  d = z(3*n+rows);\r\nS = @evaulate;\r\n\r\n    % This function evaluates the spline when called with a value for x.\r\n    function f = evaulate(x)\r\n        f = zeros(size(x));\r\n        for k = 1:n       % iterate over the pieces\r\n            % Evalaute this piece's cubic at the points inside it.\r\n            index = (x>=t(k)) & (x<=t(k+1));   \r\n            f(index) = polyval( [d(k),c(k),b(k),a(k)], x(index)-t(k) );\r\n        end\r\n    end\r\n\r\nend\n\nFornberg’s algorithm for finite difference weights\n\nfunction w = fdweights(t,m)\r\n%FDWEIGHTS   Fornberg's algorithm for finite difference weights.\r\n% Input:\r\n%   t    nodes (vector, length r+1)\r\n%   m    order of derivative sought at x=0 (integer scalar)\r\n% Output:\r\n%   w    weights for the approximation to the jth derivative (vector)\r\n\r\n% This is a compact implementation, not an efficient one. \r\n\r\nr = length(t)-1;\r\nw = zeros(size(t));\r\nfor k = 0:r\r\n  w(k+1) = weight(t,m,r,k);\r\nend\r\n\r\n\r\nfunction c = weight(t,m,r,k)\r\n% Implement a recursion for the weights.\r\n% Input:\r\n%   t   nodes (vector)\r\n%   m   order of derivative sought \r\n%   r   number of nodes to use from t (<= length(t))\r\n%   k   index of node whose weight is found \r\n% Output:\r\n%   c   finite difference weight \r\n\r\nif (m<0) || (m>r)        % undefined coeffs must be zero\r\n  c = 0;    \r\nelseif (m==0) && (r==0)  % base case of one-point interpolation\r\n  c = 1;   \r\nelse                     % generic recursion \r\n  if k<r\r\n    c = (t(r+1)*weight(t,m,r-1,k) - ...\r\n        m*weight(t,m-1,r-1,k))/(t(r+1)-t(k+1));\r\n  else\r\n    beta = prod(t(r)-t(1:r-1)) / prod(t(r+1)-t(1:r));\r\n    c = beta*(m*weight(t,m-1,r-1,r-1) - t(r)*weight(t,m,r-1,r-1));\r\n  end\r\nend\n\nTrapezoid formula for numerical integration\n\nfunction [T,t,y] = trapezoid(f,a,b,n)\n%TRAPEZOID   Trapezoid formula for numerical integration.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   n     number of interval divisions\n% Output:\n%   T     approximation to the integral of f over (a,b)\n%   t     vector of nodes used\n%   y     vector of function values at nodes\n\nh = (b-a)/n;\nt = a + h*(0:n)';\ny = f(t);\nT = h * ( sum(y(2:n)) + 0.5*(y(1) + y(n+1)) );\n\nAdaptive integration\n\nfunction [Q,t] = intadapt(f,a,b,tol)\n%INTADAPT   Adaptive integration with error estimation.\n% Input:\n%   f     integrand (function)\n%   a,b   interval of integration (scalars)\n%   tol   acceptable error\n% Output:\n%   Q     approximation to integral(f,a,b)\n%   t     vector of nodes used\n\nm = (b+a)/2;\n[Q,t] = do_integral(a,f(a),b,f(b),m,f(m),tol);\n\n    % Use error estimation and recursive bisection. \n    function [Q,t] = do_integral(a,fa,b,fb,m,fm,tol)\n        \n        % These are the two new nodes and their f-values.\n        xl = (a+m)/2;  fl = f(xl);\n        xr = (m+b)/2;  fr = f(xr);\n        t = [a;xl;m;xr;b];              % all 5 nodes at this level\n\n        % Compute the trapezoid values iteratively. \n        h = (b-a);\n        T(1) = h*(fa+fb)/2;\n        T(2) = T(1)/2 + (h/2)*fm;\n        T(3) = T(2)/2 + (h/4)*(fl+fr);\n        \n        S = (4*T(2:3)-T(1:2)) / 3;      % Simpson values\n        E = (S(2)-S(1)) / 15;           % error estimate\n                \n        if abs(E) < tol*(1+abs(S(2)))   % acceptable error?\n            Q = S(2);                   % yes--done\n        else\n            % Error is too large--bisect and recurse. \n            [QL,tL] = do_integral(a,fa,m,fm,xl,fl,tol);\n            [QR,tR] = do_integral(m,fm,b,fb,xr,fr,tol);\n            Q = QL + QR;\n            t = [tL;tR(2:end)];         % merge the nodes w/o duplicate\n        end        \n    end\n\nend  % main function\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.","type":"content","url":"/chapter5-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"type":"lvl2","url":"/chapter5-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter5-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.1 The interpolation problem","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-1","position":6},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.1 The interpolation problem","lvl2":"Examples"},"content":"Example 5.1.1\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5;\nt = linspace(-1,1,n+1)';  \ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t,y)\n\nThe polynomial interpolant, as computed using polyfit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on\nfplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north');\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\nc = polyfit(t, y, n);     % polynomial coefficients\np = @(x) polyval(c, x);\nhold on, fplot(p, [-1 1])\nlegend('data', 'interpolant', 'location', 'north');\n\nSurely there must be functions that are more intuitively representative of those points!\n\nExample 5.1.3\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nn = 18;\nt = linspace(-1, 1, n+1);\ny = t.^2 + t + 0.05 * sin(20 * t);\nclf, scatter(t, y)\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using interp1 from MATLAB.\n\nx = linspace(-1, 1, 400)';\nhold on, plot(x, interp1(t, y, x))\ntitle('Piecewise linear interpolant')\n\nWe may prefer a smoother interpolant that is piecewise cubic, generated using Spline1D from the Dierckx package.\n\ncla\nscatter(t, y)\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic interpolant')\n\nExample 5.1.4\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nn = 18;\nt = linspace(-1, 1, n+1)';\ny = [zeros(9, 1); 1; zeros(n - 9, 1)];    % 10th cardinal function\nclf, scatter(t, y)\nhold on\nx = linspace(-1, 1, 400)';\nplot(x, interp1(t, y, x, 'spline'))\ntitle('Piecewise cubic cardinal function') \nxlabel('x'), ylabel('p(x)')\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\nclf, scatter(t, y)\nc = polyfit(t, y, n);\nhold on, plot(x, polyval(c, x))\ntitle('Polynomial cardinal function')\nxlabel('x'), ylabel(('p(x)'));\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/chapter5-1#id-5-1","position":7},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.2 Piecewise linear interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-2","position":8},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.2 Piecewise linear interpolation","lvl2":"Examples"},"content":"Example 5.2.1\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = [0, 0.55, 0.7, 1];\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nclf\nfor k = 0:3\n    subplot(4, 1, k+1)\n    Hk = hatfun(t, k);\n    fplot(Hk, [0, 1])\n    hold on\n    scatter(t, Hk(t))\n    text(t(k+1), 0.6, sprintf(\"H_%d\", k))\nend\n\nExample 5.2.2\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = @(x) exp(sin(7 * x));\nclf\nfplot(f, [0, 1], displayname=\"function\")\nxlabel(\"x\");  ylabel((\"y\"));\n\nFirst we sample the function to create the data.\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % function values\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = plinterp(t, y);\nhold on\nfplot(p, [0, 1], displayname=\"interpolant\")\nscatter(t, y, displayname=\"values at nodes\")\ntitle(\"PL interpolation\")\nlegend();\n\nExample 5.2.3\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = @(x) exp(sin(7 * x));\nx = linspace(0, 1, 10001)';    % sample the difference at many points\nn = round(10.^(1:0.25:3.5))';\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i)) / n(i);       % interpolation nodes\n    p = plinterp(t, f(t));\n    maxerr(i) = norm(f(x) - p(x), Inf);\nend\ntable(n(1:4:end), maxerr(1:4:end), variableNames=[\"n\", \"inf-norm error\"])\n\nAs predicted, a factor of 10 in n produces a factor of 100 reduction in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder2 = 0.5 * maxerr(end) * (n / n(end)) .^ (-2);\nhold on\nloglog(n, order2, \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"|| f-p ||_{\\infty}\")\ntitle(\"Convergence of PL interpolation\")\nlegend();","type":"content","url":"/chapter5-1#id-5-2","position":9},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.3 Cubic splines","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-3","position":10},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.3 Cubic splines","lvl2":"Examples"},"content":"Example 5.3.1\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nclf\nf = @(x) exp(sin(7 * x));\nfplot(f, [0, 1], displayname=\"function\")\n\nt = [0, 0.075, 0.25, 0.55, 0.7, 1];    % nodes\ny = f(t);                              % values at nodes\nhold on, scatter(t, y, displayname=\"values at nodes\")\n\nS = spinterp(t, y);\nfplot(S, [0, 1], displayname=\"spline\")\n\nxlabel(\"x\");  ylabel(\"y\")\nlegend();\n\nNow we look at the convergence rate as the number of nodes increases.\n\nx = (0:10000)' / 1e4;              % sample the difference at many points\nn = round(2 .^ (3:0.5:7))';        % numbers of nodes\nmaxerr = zeros(size(n));\nfor i = 1:length(n)\n    t = (0:n(i))' / n(i);\n    S = spinterp(t, f(t));\n    err = f(x) - S(x);\n    maxerr(i) = norm(err, Inf);\nend\ntable(n(1:2:end), maxerr(1:2:end), variableNames=[\"n\", \"inf-norm error\"])\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\nclf\nloglog(n, maxerr, \"-o\", displayname=\"error\")\norder4 = 0.5 * maxerr(end) * (n / n(end)) .^ (-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nxlabel(\"n\");  ylabel(\"|| f-S ||_{\\infty}\")\ntitle((\"Convergence of spline interpolation\"));","type":"content","url":"/chapter5-1#id-5-3","position":11},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.4 Finite differences","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-4","position":12},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.4 Finite differences","lvl2":"Examples"},"content":"Example 5.4.3\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05;\nformat long\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\n\nExample 5.4.4\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = @(x) exp(sin(x));\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05;\nformat long\nCD2 = (f(-h) - 2*f(0) + f(h)) / h^2\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h^2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h^2\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h^2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h^2\n\nExample 5.4.5\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = [0.35, 0.5, 0.57, 0.6, 0.75];    % nodes\nf = @(x) cos(x.^2);\ndfdx = @(x) -2 * x * sin(x^2);\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nformat short\nw = fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = w * f(t)'\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nfdweights(0:3, 1)","type":"content","url":"/chapter5-1#id-5-4","position":13},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.5 Convergence of finite differences","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-5","position":14},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.5 Convergence of finite differences","lvl2":"Examples"},"content":"Example 5.5.3\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = @(x) sin(exp(x + 1));\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh = 5 ./ 10.^(1:6)';\nFD1 = zeros(size(h));\nFD2 = zeros(size(h));\nfor i = 1:length(h)\n    h_i = h(i);\n    FD1(i) = (f(h_i) - f(0)    ) / h_i;\n    FD2(i) = (f(h_i) - f(-h_i)) / (2*h_i);\nend\ntable(h, FD1, FD2)\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerr1 = abs(exact_value - FD1);\nerr2 = abs(exact_value - FD2);\ntable(h, err1, err2, variableNames=[\"h\", \"error in FD1\", \"error in FD2\"])\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nclf\nloglog(h, abs([err1 err2]), \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err1(end) * (h / h(end)) .^ 1;\norder2 = 0.1 * err2(end) * (h / h(end)) .^ 2;\nhold on\nloglog(h, order1, \"--\", h, order2, \"--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"Convergence of finite differences\")\nlegend(\"FD1\", \"FD2\", \"O(h)\", \"O(h^2)\");\n\nExample 5.5.4\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = @(x) exp(-1.3 * x);\nexact = -1.3;\n\nh = 10 .^ (-(1:12))';\nFD = zeros(length(h), 3);\nfor i = 1:length(h)\n    h_i = h(i);\n    nodes = h_i * (-2:2);\n    vals = f(nodes);\n    FD(i, 1) = dot([0      0 -1   1    0] / h_i, vals);\n    FD(i, 2) = dot([0    -1/2 0 1/2    0] / h_i, vals);\n    FD(i, 3) = dot([1/12 -2/3 0 2/3 -1/12] / h_i, vals);\nend\nformat long\ntable(h, FD(:, 1), FD(:, 2), FD(:, 3), variableNames=[\"h\", \"FD1\", \"FD2\", \"FD4\"])\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nerr = abs(FD - exact);\nclf\nloglog(h, err, \"o-\")\nset(gca, \"xdir\", \"reverse\")\norder1 = 0.1 * err(end, 1) * (h / h(end)) .^ (-1);\nhold on\nloglog(h, order1, \"k--\")\nxlabel(\"h\");  ylabel(\"error\")\ntitle(\"FD error with roundoff\")\nlegend(\"FD1\", \"FD2\", \"FD4\", \"O(1/h)\", \"location\", \"northeast\");\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/chapter5-1#id-5-5","position":15},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.6 Numerical integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-6","position":16},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.6 Numerical integration","lvl2":"Examples"},"content":"Example 5.6.1\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nformat long\nexact = exp(1) - 1\n\nMATLAB has numerical integrator integral that estimates the value without finding the antiderivative first. As you can see here, it can be as accurate as floating-point precision allows.\n\nintegral(@(x) exp(x), 0, 1)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nintegral(@(x) exp(sin(x)), 0, 1)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 201)';\nsubplot(2,1,1), fill([x; 1; 0], [exp(x); 0;0 ], [1, 0.9, 0.9])\ntitle('exp(x)')\nylabel('f(x)')\nsubplot(2, 1, 2), fill([x; 1; 0], [exp(sin(x)); 0; 0], [1, 0.9, 0.9])\ntitle('exp(sin(x))')\nxlabel('x'), ylabel(('f(x)'));\n\nExample 5.6.2\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = @(x) exp(sin(7 * x));\na = 0;  b = 2;\n\nIn lieu of the exact value, we use the integral function to find an accurate result.\n\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14);\nfprintf(\"Integral = %.15f\", I)\n\nHere is the trapezoid result at n=40, and its error.\n\nT = trapezoid(f, a, b, 40);\nfprintf(\"Trapezoid error = %.2e\", I - T)\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn = 10 .^ (1:5)';\nerr = zeros(size(n));\nfor i = 1:length(n)\n    T = trapezoid(f, a, b, n(i));\n    err(i) = I - T;\nend\ntable(n, err, variableNames=[\"n\", \"Trapezoid error\"])\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"trapezoid\")\nhold on\nloglog(n, 0.1 * abs(err(end)) * (n / n(end)).^(-2), \"k--\", displayname=\"O(n^{-2})\")\nxlabel(\"n\");  ylabel(\"error\")\ntitle(\"Convergence of trapezoidal integration\")\nlegend();\n\nExample 5.6.3\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nf = @(x) x.^2 .* exp(-2 * x);\na = 0;  b = 2;\nformat long\nI = integral(f, a, b, abstol=1e-14, reltol=1e-14)\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20;       % the coarsest formula\nn = N;  h = (b - a) / n;\nt = h * (0:n)';\ny = f(t);\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = h * ( sum(y(2:n)) + y(1) / 2 + y(n+1) / 2 )\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(2) = T(1) / 2 + h * sum( f(t(2:2:n)) )\n\nWe can repeat the same code to double n again.\n\nn = 2*n;  h = h / 2;\nt = h * (0:n)';\nT(3) = T(2) / 2 + h * sum( f(t(2:2:n)) )\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = (4 * T(2:3) - T(1:2)) / 3\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16*S(2) - S(1)) / 15\n\nWe can make a triangular table of the errors:\n\nerr2 = T(:) - I;\nerr4 = [NaN; S(:) - I];\nerr6 = [NaN; NaN; R - I];\nformat short e\ntable(err2, err4, err6, variablenames=[\"order 2\", \"order 4\", \"order 6\"])\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/chapter5-1#id-5-6","position":17},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.7 Adaptive integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-1#id-5-7","position":18},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.7 Adaptive integration","lvl2":"Examples"},"content":"Example 5.7.1\n\nThis function gets increasingly oscillatory as x increases.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\nclf\nfplot(f, [0, 4], 2000)\nxlabel('x'), ylabel(('f(x)'));\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nleft_val = integral(f, 0, 2, abstol=1e-14, reltol=1e-14);\nright_val = integral(f, 2, 4, abstol=1e-14, reltol=1e-14);\n\nn = round(50 * 2 .^ (0:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    T = trapezoid(f, 0, 2, n(i));\n    err(i, 1) = T - left_val;\n    T = trapezoid(f, 2, 4, n(i));\n    err(i, 2) = T - right_val;\nend\ntable(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"left error\", \"right error\"])\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nExample 5.7.2\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nf = @(x) (x + 1).^2 .* cos((2 * x + 1) ./ (x - 4.3));\n\nWe perform the integration and show the nodes selected underneath the curve.\n\n[Q, t] = intadapt(f, 0, 4, 0.001);\nclf, fplot(f, [0, 4], 2000)\nhold on\nstem(t, f(t), '.-')\ntitle('Adaptive node selection')\nxlabel('x'), ylabel('f(x)')\nfprintf(\"number of nodes = %d\", length(t))\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nI = integral(f, 0, 4, abstol=1e-14, reltol=1e-14);    % 'exact' value\nfprintf(\"error = %.2e\", abs(Q - I))\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol = 1 ./ 10.^(4:14)';\nerr = zeros(size(tol));\nn = zeros(size(tol));\nfor k = 1:length(tol)\n    [A, t] = intadapt(f, 0, 4, tol(k));\n    err(k) =  I - A;\n    n(k) = length(t);\nend\ntable(tol, err, n, variableNames=[\"tolerance\", \"error\", \"number of nodes\"])\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nclf\nloglog(n, abs(err), \"-o\", displayname=\"results\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\ntitle(\"Convergence of adaptive integration\")\norder4 = 0.1 * abs(err(end)) * (n / n(end)).^(-4);\nhold on\nloglog(n, order4, \"k--\", displayname=\"O(n^{-4})\")\nlegend();","type":"content","url":"/chapter5-1#id-5-7","position":19},{"hierarchy":{"lvl1":"Chapter 6"},"type":"lvl1","url":"/chapter6-1","position":0},{"hierarchy":{"lvl1":"Chapter 6"},"content":"","type":"content","url":"/chapter6-1","position":1},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"type":"lvl2","url":"/chapter6-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"content":"Euler’s method for an initial-value problem\n\nfunction [t, u] = eulerivp(ivp, a, b, n)\r\n% EULERIVP   Euler's method for a scalar initial-value problem.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;\r\nt = a + (0:n) * h;\r\n\r\n% Initialize solution array.\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0;\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  u(:, i+1) = u(:, i) + h * du_dt(t(i), u(:, i), p);\r\nend\n\nAbout the code\n\nThe ivp input argument is the same structure that is used with the built-in solve solvers. The outputs t and u are row vectors of the same length, like the fields in a solution object output by solve. While the entries of u could be simplified to u(1), u(i), etc., we chose a column-access syntax like u(:, i) that will prove useful for what’s coming next in the chapter.\n\nImproved Euler method for an IVP\n\nfunction [t, u] = ie2(ivp, a, b, n)\r\n% IE2    Improved Euler method for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping. \r\nfor i = 1:n \r\n    uhalf = u(:, i) + h/2 * du_dt(t(i), u(:, i), p);\r\n    u(:, i+1) = u(:, i) + h * du_dt(t(i) + h/2, uhalf, p);\r\nend\n\nFourth-order Runge-Kutta for an IVP\n\nfunction [t, u] = rk4(ivp, a, b, n)\r\n% RK4    Fourth-order Runge-Kutta for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Initialize solution array. \r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  k1 = h * du_dt( t(i),       u(:, i)       , p);\r\n  k2 = h * du_dt( t(i) + h/2, u(:, i) + k1/2, p );\r\n  k3 = h * du_dt( t(i) + h/2, u(:, i) + k2/2, p );\r\n  k4 = h * du_dt( t(i) + h,   u(:, i) + k3  , p);\r\n  u(:, i+1) = u(:, i) + (k1 + 2*(k2 + k3) + k4) / 6;\r\nend\n\nAdaptive IVP solver based on embedded RK formulas\n\nfunction [t, u] = rk23(ivp, a, b, tol)\r\n% RK23   Adaptive IVP solver based on embedded RK formulas.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   tol     global error target (positive scalar)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Initialize for the first time step.\r\nt = a;\r\nu(:, 1) = u0(:);  i = 1;\r\nh = 0.5 * tol^(1/3);\r\ns1 = du_dt(t(1), u(:, 1) ,p);\r\n\r\n% Time stepping.\r\nwhile t(i) < b\r\n    % Detect underflow of the step size.\r\n    if t(i) + h == t(i)\r\n        warning('Stepsize too small near t=%.6g.',t(i))\r\n        break  % quit time stepping loop\r\n    end\r\n    \r\n    % New RK stages.\r\n    s2 = du_dt(t(i) + h/2,   u(:, i) + (h/2)   * s1, p);\r\n    s3 = du_dt(t(i) + 3*h/4, u(:, i) + (3*h/4) * s2, p);\r\n    unew2 = u(:, i) + h * (2*s1 + 3*s2 + 4*s3) / 9;    % 2rd order solution\r\n    s4 = du_dt(t(i) + h, unew2, p );\r\n    err = h * (-5*s1/72 + s2/12 + s3/9 - s4/8);        % 2nd/3rd order difference\r\n    E = norm(err, Inf);                                % error estimate\r\n    maxerr = tol * (1 + norm(u(:, i), Inf));           % relative/absolute blend\r\n    \r\n    % Accept the proposed step? \r\n    if E < maxerr     % yes \r\n        t(i+1) = t(i) + h;\r\n        u(:, i+1) = unew2;\r\n        i = i+1;\r\n        s1 = s4;      % use FSAL property\r\n    end\r\n    \r\n    % Adjust step size. \r\n    q = 0.8 * (maxerr/E)^(1/3);       % conservative optimal step factor\r\n    q = min(q, 4);                    % limit stepsize growth\r\n    h = min(q*h, b - t(i));           % don't step past the end\r\nend\n\nAbout the code\n\nThe check t(i) + h == t(i)on line 24 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 36, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 47--49 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 43 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s4 as s1 for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\n4th-order Adams–Bashforth formula for an IVP\n\nfunction [t, u] = ab4(ivp, a, b, n)\r\n%AB4     4th-order Adams-Bashforth formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\n% Constants in the AB4 method.\r\nk = 4;  \r\nsigma = [55; -59; 37; -9] / 24;  \r\n\r\n% Find starting values by RK4.\r\n[ts, us] = rk4(ivp, a, a + (k-1)*h, k-1);\r\nu = zeros(length(u0), n+1);\r\nu(:, 1:k) = us(:, 1:k);\r\n\r\n% Compute history of u' values, from oldest to newest.\r\nf = zeros(length(u0), k);\r\nfor i = 1:k-1\r\n  f(:, k-i) = du_dt(t(i), u(:, i), p);\r\nend\r\n\r\n% Time stepping.\r\nfor i = k:n\r\n  f = [du_dt(t(i), u(:, i), p), f(:, 1:k-1)];   % new value of du/dt\r\n  u(:, i+1) = u(:, i) + h * (f * sigma);        % advance one step\r\nend\n\nAbout the code\n\nLine 21 sets sigma to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 24--26 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then lines 29--32 compute the vector [f_2,f_1,f_0].\n\nLine 36 computes f_i, based on the most recent solution value and time. That goes into the first column of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\nfunction [t, u] = am2(ivp, a, b, n)\r\n% AM2    2nd-order Adams-Moulton (trapezoid) formula for an IVP.\r\n% Input:\r\n%   ivp     structure defining the IVP\r\n%   a, b    endpoints of time interval (scalars)\r\n%   n       number of time steps (integer)\r\n% Output:\r\n%   t       selected nodes (vector, length n+1)\r\n%   u       solution values (array, m by (n+1))\r\n\r\ndu_dt = ivp.ODEFcn;\r\nu0 = ivp.InitialValue;\r\np = ivp.Parameters;\r\n\r\n% Define time discretization.\r\nh = (b - a) / n;   \r\nt = a + h * (0:n)';\r\n\r\nu = zeros(length(u0), n+1);\r\nu(:, 1) = u0(:);\r\n\r\n% Time stepping.\r\nfor i = 1:n\r\n  % Data that does not depend on the new value.\r\n  known = u(:,i) + h/2 * du_dt(t(i), u(:, i), p);\r\n  % Find a root for the new value. \r\n  unew = levenberg(@trapzero, known);\r\n  u(:, i+1) = unew(:, end);\r\nend\r\n\r\n% This function defines the rootfinding problem at each step.\r\nfunction F = trapzero(z)\r\n    F = z - h/2 * du_dt(t(i+1), z, p) - known;\r\nend\r\n\r\nend  % main function\n\nAbout the code\n\nLines 32--34 define the function \\mathbf{g}. This is sent to levenberg in line~27 to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/chapter6-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"type":"lvl2","url":"/chapter6-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter6-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.1 Basics of IVPs","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-1","position":6},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.1 Basics of IVPs","lvl2":"Examples"},"content":"Example 6.1.2\n\nLet’s use it to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1. To create an initial-value problem for u(t), you must create an ode with a function that computes u' and an initial condition for u. Then you create a solution by calling solve with a time interval.\n\nTip\n\nMost real ODE problems contain parameters that are constant during the solution but that can change from one problem instance to the next. Accordingly, we define the ODE function below to accept a third argument, p, which is a vector of parameters. We always include this argument for consistency, even when there are no parameters.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialTime = 0;\nivp.InitialValue = -1;\nsol = solve(ivp, 0, 4);\n\nThe resulting solution object has fields Time and Solution that contain the approximate values of the solution at automatically chosen times in the interval you provided.\n\nclf\nplot(sol.Time, sol.Solution, '-o')\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle((\"Solution of an IVP\"));\n\nYou might want to know the solution at particular times other than the ones selected by the solver. That requires an interpolation, which is done by solutionFcn.\n\nu = solutionFcn(ivp, 0, 10);\nu(0:5)\n\nExample 6.1.3\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialTime = 0;\nivp.InitialValue = 1;\nsol = solve(ivp, 0, 1);\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nclf\nsemilogy(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle((\"Finite-time blowup\"));\n\nExample 6.1.5\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')\ntitle(('Exponential divergence of solutions'));\n\nBut with u'=-u, solutions actually get closer together with time.\n\nclf\nfor u0 = [0.7, 1, 1.3]    % initial values\n    fplot(@(t) exp(-t) * u0, [0, 3]), hold on\nend\nxlabel('t')\nylabel('u(t)')\ntitle(('Exponential convergence of solutions'));\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence the exponentially growing bound e^{b-a} is a gross overestimate.","type":"content","url":"/chapter6-1#id-6-1","position":7},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.2 Euler’s method","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-2","position":8},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.2 Euler’s method","lvl2":"Examples"},"content":"Example 6.2.1\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We need to define the function for the right-hand side of the ODE, the interval for the independent variable, and the initial value.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nHere is the call to \n\nFunction 6.2.2.\n\n[t, u] = eulerivp(ivp, a, b, 20);\nclf, plot(t, u, '.-')\nxlabel('t')\nylabel('u(t)')\ntitle(('Solution by Euler''s method'));\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\n[t, u] = eulerivp(ivp, a, b, 50);\nhold on, plot(t, u, '.-')\nlegend('20 steps', '50 steps');\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use a built-in solver to construct an accurate reference solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_exact = solutionFcn(ivp, a, b);\n\nNow we can perform a convergence study.\n\nn = round(5 * 10.^(0:0.5:3));\nerr = [];\nfor k = 1:length(n)\n    [t, u] = eulerivp(ivp, a, b, n(k));\n    err(k) = norm(u_exact(t) - u, Inf);\nend\ntable(n', err', VariableNames=[\"n\", \"inf-norm error\"])\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nclf\nloglog(n, err, 'o-')\nhold on, loglog(n, 0.5 * err(end) * (n / n(end)).^(-1), '--')\nxlabel('n')\nylabel('inf-norm error')\ntitle('Convergence of Euler''s method')\nlegend('error', 'O(n^{-1})', 'location', 'southwest');","type":"content","url":"/chapter6-1#id-6-2","position":9},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.3 IVP systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-3","position":10},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.3 IVP systems","lvl2":"Examples"},"content":"Example 6.3.2\n\nWe encode the predator–prey equations via a function, defined here externally.\n\nfunction du_dt = predprey(t, u, p)\n    alpha = p(1);  beta = p(2);\n    y = u(1);      z = u(2);\n    s = (y * z) / (1 + beta * y);  % appears in both equations\n    du_dt = [ y * (1 - alpha * y) - s;  -z + s ];\nend\n\n\nThe values of alpha and beta are parameters that influence the solution of the IVP. We use the Parameters field of the IVP object to define them for the solver, which in turn passes them as the third argument into our ODE function.\n\nu0 = [1; 0.01];    % column vector\np = [0.1, 0.25];\nivp = ode;\nivp.ODEFcn = @f63_predprey;\nivp.InitialValue = u0;\nivp.Parameters = p;\nsol = solve(ivp, 0, 60);\nsize(sol.Solution)\n\nEach column of the Solution field is the solution vector \\mathbf{u} at a particular time; each row is a component of \\mathbf{u} over all time.\n\nclf\nplot(sol.Time, sol.Solution)\nxlabel(\"t\")\nylabel(\"u(t)\")\ntitle('Predator-prey solution')\nlegend('prey', 'predator');\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\n[t, u] = eulerivp(ivp, 0, 60, 1200);\n\nhold on\nplot(t, u, '.')\n\nNotice above that the accuracy of the Euler solution deteriorates rapidly.\n\nWhen there are just two components, it’s common to plot the solution in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nclf\nplot(u(1, :), u(2, :))\ntitle(\"Predator-prey in the phase plane\")\nxlabel(\"y\")\nylabel((\"z\"));\n\nFrom this plot we can deduce that the solution approaches a periodic one, which in the phase plane is represented by a closed loop.\n\nExample 6.3.5\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\nfunction udot = pendulums(t, u, p)\n    gamma = p(1);  L = p(2);  k = p(3);\n    g = 9.8;\n    udot = zeros(4, 1);\n    udot(1:2) = u(3:4);\n    udot(3) = -gamma * u(3) - (g / L) * sin(u(1)) + k * (u(2) - u(1));\n    udot(4) = -gamma * u(4) - (g / L) * sin(u(2)) + k * (u(1) - u(2));\nend\n\n\nu0 = [1.25; -0.5; 0; 0];\na = 0; b = 50;\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nTip\n\nHere OutputVariables is used to restrict output to just u_1 and u_2.\n\nparams =[0.01, 0.5, 0];    % gamma, L, k\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nt = linspace(a, b, 1001);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\");\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nparams(3) = 1;\nivp = ode(ODEFcn=@f63_pendulums, InitialValue=u0, Parameters=params);\ntheta = solutionFcn(ivp, a, b, OutputVariables = 1:2);\nclf, plot(t, theta(t))\nxlabel(\"t\");  ylabel(\"angle\")\ntitle(\"Coupled pendulums\")\nlegend(\"\\theta_1\", \"\\theta_2\");\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/chapter6-1#id-6-3","position":11},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.4 Runge–Kutta methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-4","position":12},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.4 Runge–Kutta methods","lvl2":"Examples"},"content":"Example 6.4.1\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\n\nWe use a built-in solver to construct an accurate approximation to the exact solution.\n\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = round(2 * 10.^(0:0.5:3)');\nerr = zeros(length(n), 2);\nfor i = 1:length(n)\n    [t, u] = ie2(ivp, a, b, n(i));\n    err(i, 1) = norm(u_ref(t) - u, Inf);\n    [t, u] = rk4(ivp, a, b, n(i));\n    err(i, 2) = norm(u_ref(t) - u, Inf);\nend\n\ntable(n, err(:, 1), err(:, 2), variableNames=[\"n\", \"IE2 error\", \"RK4 error\"])\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nclf, loglog([2*n 4*n], err, '-o')\nhold on\nloglog(2*n, 1e-5 * (n / n(end)) .^ (-2), '--')\nloglog(4*n, 1e-10 * (n / n(end)) .^ (-4), '--')\nxlabel(\"f-evaluations\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of RK methods\")\nlegend(\"IE2\", \"RK4\", \"O(n^{-2})\", \"O(n^{-4})\", \"location\", \"southwest\");\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/chapter6-1#id-6-4","position":13},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.5 Adaptive Runge–Kutta","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-5","position":14},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.5 Adaptive Runge–Kutta","lvl2":"Examples"},"content":"Example 6.5.1\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) exp(t - u * sin(u));\nivp.InitialValue = 0;\na = 0;  b = 5;\n\n[t, u] = rk23(ivp, a, b, 1e-5);\nclf, plot(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle((\"Adaptive IVP solution\"));\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\nDelta_t = diff(t);\nsemilogy(t(1:end-1), Delta_t) \nxlabel(\"t\");  ylabel(\"step size\")\ntitle((\"Adaptive step sizes\"));\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nfprintf(\"minimum step size = %.2e\", min(Delta_t))\n\nOn the other hand, the average step size that was actually taken was\n\nfprintf(\"average step size = %.2e\", mean(Delta_t))\n\nWe took fewer steps by a factor of almost 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nExample 6.5.2\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) (t + u)^2;\nivp.InitialValue = 1;\n[t, u] = rk23(ivp, 0, 1, 1e-5);\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nclf, semilogy(t, u)\nxlabel(\"t\");  ylabel(\"u(t)\")\ntitle(\"Adaptive solution near a singularity\")\n\ntf = t(end);\nxline(tf, \"linestyle\", \"--\")\ntext(tf, 1e5, sprintf(\" t = %.6f \", tf))","type":"content","url":"/chapter6-1#id-6-5","position":15},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.6 Multistep methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-6","position":16},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.6 Multistep methods","lvl2":"Examples"},"content":"Example 6.7.1\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, a built-in solver is called to give an accurate reference solution.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) sin((t + u)^2);\nivp.InitialValue = -1;\na = 0;  b = 4;\nivp.AbsoluteTolerance = 1e-13;\nivp.RelativeTolerance = 1e-13;\nu_ref = solutionFcn(ivp, a, b);\n\nNow we perform a convergence study of the AB4 code.\n\nn = round(4 * 10.^(0:0.5:3)');\nerr = zeros(size(n));\nfor i = 1:length(n)\n    [t, u] = ab4(ivp, a, b, n(i));\n    err(i) = norm(u_ref(t) - u, Inf);\nend\ntable(n, err, variableNames=[\"n\", \"inf-norm error\"])\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nclf, loglog(n, err, '-o')\nhold on\nloglog(n, 0.5 * err(end) * (n / n(end)) .^ (-4), '--')\nxlabel(\"n\");  ylabel(\"inf-norm error\")\ntitle(\"Convergence of AB4\")\nlegend(\"AB4\", \"O(n^{-4})\", location=\"southwest\");\n\nExample 6.7.2\n\nThe following simple ODE uncovers a surprise.\n\nivp = ode;\nivp.ODEFcn = @(t, u, p) u^2 - u^3;\nivp.InitialValue = 0.005;\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\n[tI, uI] = am2(ivp, 0, 400, 200);\nclf\nplot(tI, uI)\nxlabel(\"t\");  ylabel((\"u(t)\"));\n\nNow we repeat the process using the explicit AB4 method.\n\n[tE, uE] = ab4(ivp, 0, 400, 200);\nhold on\nplot(tE, uE, '.', 'markersize', 8)\nylim([-5, 3])\nlegend(\"AM2\", \"AB4\");\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nformat short e\nuE(105:111)\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nclf,  plot(tI, uI, '.', 'markersize', 10)\nhold on\n[tE, uE] = ab4(ivp, 0, 400, 1000);\nplot(tE, uE)\n[tE, uE] = ab4(ivp, 0, 400, 1600);\nplot(tE, uE)\nlegend(\"AM2, n=200\", \"AB4, n=1000\", \"AB4, n=1600\", location=\"northwest\");\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!","type":"content","url":"/chapter6-1#id-6-6","position":17},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.7 Implementation of multistep methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-1#id-6-7","position":18},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.7 Implementation of multistep methods","lvl2":"Examples"},"content":"Example 6.8.1\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = @(t, u) u;\nu_exact = @exp;\na = 0;  b = 1;\nn = [5, 10, 20, 40, 60]';\nerr = zeros(size(n));\nfor j = 1:length(n)\n    h = (b - a) / n(j);\n    t = a + h *(0:n(j));\n    u = [1, u_exact(h), zeros(1, n(j) - 1)];\n    f = [du_dt(t(1), u(1)), zeros(1, n(j) - 2)];\n    for i = 2:n(j)\n        f(i) = du_dt(t(i), u(i));\n        u(i+1) = -4*u(i) + 5*u(i-1) + h * (4*f(i) + 2*f(i-1));\n    end\n    err(j) = abs(u_exact(b) - u(end));\nend\n\nh = (b-a) ./ n;\ntable(n, h, err)\n\nThe error starts out promisingly, but things explode from there. A graph of the last numerical attempt yields a clue.\n\nclf\nsemilogy(t, abs(u))\nxlabel(\"t\");  ylabel(\"|u(t)|\")\ntitle((\"LIAF solution\"));\n\nIt’s clear that the solution is growing exponentially in time.","type":"content","url":"/chapter6-1#id-6-7","position":19},{"hierarchy":{"lvl1":"Chapter 7"},"type":"lvl1","url":"/chapter7-1","position":0},{"hierarchy":{"lvl1":"Chapter 7"},"content":"","type":"content","url":"/chapter7-1","position":1},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"type":"lvl2","url":"/chapter7-1#examples","position":2},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init\n\n","type":"content","url":"/chapter7-1#examples","position":3},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.1 From matrix to insight","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-1","position":4},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.1 From matrix to insight","lvl2":"Examples"},"content":"Example 7.1.4\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = [0 1 0 0; 1 0 0 0; 1 1 0 1; 0 1 1 0]\n\nSince this adjacency matrix is not symmetric, the edges are all directed. We use digraph to create a directed graph.\n\nG = digraph(A);\nplot(G)\n\nHere are the counts of all walks of length 3 in the graph:\n\nA^3\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = [0 1 1 0; 1 0 0 1; 1 0 0 0; 0 1 0 0];\nplot(graph(A))\n\nA “buckyball” is an allotrope of carbon atoms with the same connection structure as a soccer ball.\n\nplot(graph(bucky))\n\nExample 7.1.5\n\nMATLAB ships with a few test images to play with.\n\nA = imread('peppers.png');\ncolor_size = size(A)\n\nUse imshow to display the image.\n\nimshow(A)\n\nThe image has three layers or channels for red, green, and blue. We can deal with each layer as a matrix, or (as below) convert it to a single matrix indicating shades of gray from black (0) to white (255). Either way, we have to explicitly convert the entries to floating-point values rather than integers.\n\nA = im2gray(A);   % collapse from 3 dimensions to 2\ngray_size = size(A)\nimshow(A)\n\nBefore we can do any numerical computation, we need to convert the image to a matrix of floating-point numbers.\n\nA = double(A);","type":"content","url":"/chapter7-1#id-7-1","position":5},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.2 Eigenvalue decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-2","position":6},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.2 Eigenvalue decomposition","lvl2":"Examples"},"content":"Example 7.2.2\n\nThe eig function with one output argument returns a vector of the eigenvalues of a matrix.\n\nA = pi * ones(2, 2);\nlambda = eig(A)\n\nWith two output arguments given, eig returns a matrix eigenvectors and a diagonal matrix with the eigenvalues.\n\n[V, D] = eig(A)\n\nWe can check the fact that this is an EVD.\n\nnorm( A - V*D/V )   % / V is like * inv(V)\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nA = [-1 1; 0 -1];\n[V, D] = eig(A)\n\ncond(V)\n\nEven in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds.\n\nnorm(A * V - V * D)\n\nExample 7.2.3\n\nWe first define a hermitian matrix. Note that the ' operation is the adjoint and includes complex conjugation.\n\nn = 7;\nA = randn(n, n) + 1i * randn(n, n);\nA = (A + A') / 2;\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. The Bauer–Fike theorem uses absolute differences, not relative ones. Note: since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = [];\nfor j = 1:n\n    dist = [dist; min(abs(dd - lambda(j)))];\nend\ndist\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20;\nx = (1:n)';\nA = triu(x * ones(1, n));\nA(1:5, 1:5)\n\nThis matrix is not at all close to normal.\n\n[V, D] = eig(A);\nlambda = diag(D);\ncond(V)\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = randn(n, n) + 1i * randn(n, n);\nE = 1e-8 * E / norm(E);\ndd = eig(A + E);\ndist = -Inf;\nfor j = 1:n\n    dist = max(dist, min(abs(dd - lambda(j))));\nend\nfprintf(\"max change in eigenvalues: %.2e\", dist)\nfprintf(\"Bauer-Fike upper bound: %.2e\", cond(V) * norm(E))\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nscatter(lambda, 0*lambda)\naxis equal; hold on\nfor k = 1:60\n    E = randn(n, n) + 1i * randn(n, n);\n    E = eps(single(1)) * E / norm(E);\n    dd = eig(A + E);\n    plot(real(dd), imag(dd), 'k.', markersize=2)\nend\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nExample 7.2.4\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nD = diag([-6, -1, 2, 4, 5]);\n[V, R]= qr(randn(5, 5));    % V is unitary\nA = V * D * V';\n\nsort(eig(A))\n\nNow we will take the QR factorization and just reverse the factors.\n\n[Q, R] = qr(A);\nA = R * Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nsort(eig(A))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k = 1:40\n    [Q, R] = qr(A);\n    A = R * Q;\nend\nformat short e\nA","type":"content","url":"/chapter7-1#id-7-2","position":7},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.3 Singular value decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-3","position":8},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.3 Singular value decomposition","lvl2":"Examples"},"content":"Example 7.3.4\n\nWe verify some of the fundamental SVD properties using the built-in svd function.\n\nA = vander(1:5);\nA = A(:, 1:4)\n\n[U, S, V] = svd(A);\ndisp(sprintf(\"U is %d by %d. S is %d by %d. V is %d by %d.\\n\", size(U), size(S), size(V)))\n\nWe verify the orthogonality of the singular vectors as follows:\n\nnorm(U' * U - eye(5))\nnorm(V' * V - eye(4))\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\ns = diag(S);\nnorm_A = norm(A)\nsigma_max = s(1)\n\ncond_A = cond(A)\nsigma_ratio = s(1) / s(end)","type":"content","url":"/chapter7-1#id-7-3","position":9},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.4 Symmetry and definiteness","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-4","position":10},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.4 Symmetry and definiteness","lvl2":"Examples"},"content":"Example 7.4.1\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nn = 20;\nlambda = 1:n;\nD = diag(lambda);\n[V, ~] = qr(randn(n, n));    % get a random orthogonal V\nA = V * D * V';\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = @(x) (x' * A * x) / (x' * x);\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nformat long\nR(V(:, 7))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\ndelta = 1 ./ 10 .^ (1:5)';\ndif = zeros(size(delta));\nfor k = 1:length(delta)\n    e = randn(n, 1);\n    e = delta(k) * e / norm(e);\n    x = V(:, 6) + e;\n    dif(k) = R(x) - lambda(6);\nend\ntable(delta, dif, variablenames=[\"perturbation size\", \"R(x) - lambda\"])","type":"content","url":"/chapter7-1#id-7-4","position":11},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.5 Dimension reduction","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-1#id-7-5","position":12},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.5 Dimension reduction","lvl2":"Examples"},"content":"Example 7.5.1\n\nWe make an image from some text, then reload it as a matrix.\n\nclf\ntobj = text(0, 0,'Hello world','fontsize',44);\nex = get(tobj, 'extent');\naxis([ex(1) ex(1) + ex(3) ex(2) ex(2) + ex(4)]), axis off\nexportgraphics(gca, 'hello.png', resolution=300)\nA = imread('hello.png');\nA = double(im2gray(A));\nsize_A = size(A)\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around k=100.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\nsemilogy(sigma, '.')\ntitle('singular values'), axis tight \nxlabel('i'), ylabel('\\sigma_i') \nr = find(sigma / sigma(1) > 10*eps, 1, 'last')\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor i = 1:4\n    subplot(2, 2, i)\n    k = 2*i;\n    Ak = U(:, 1:k) * S(1:k, 1:k) * V(:, 1:k)';\n    imshow(Ak, [0, 255])\n    title(sprintf('rank = %d', k))\nend\n\nConsider how little data is needed to reconstruct these images. For rank-9, for instance, we have 9 left and right singular vectors plus 9 singular values, for a compression ratio of better than 12:1.\n\n[m, n] = size(A);\nfull_size = m * n;\ncompressed_size = 8 * (m + n + 1);\nfprintf(\"compression ratio: %.1f\", full_size / compressed_size)\n\nExample 7.5.2\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nload voting\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nclf\nimagesc(A)\ncolormap parula\ntitle('Votes in 111th U.S. Senate')\nylabel(('senator'),  xlabel('bill'));\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\n[U, S, V] = svd(A);\nsigma = diag(S);\ntau = cumsum(sigma.^2) / sum(sigma.^2);\nplot(tau(1:16), 'o')\nxlabel('k'),  ylabel('\\tau_k')\ntitle(('Fraction of singular value energy'));\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(211), plot(U(:, 1), '.')\nxlabel('senator number'), title('left singular vector')\nsubplot(212), plot(V(:, 1), '.')\nxlabel('bill number'), title(('right singular vector'));\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nclf\nx1 = V(:, 1)'*A';   x2 = V(:, 2)'*A'; \nscatter(x1(Dem), x2(Dem), 20, 'b'),  hold on\nscatter(x1(Rep), x2(Rep), 20, 'r')\nscatter(x1(Ind), x2(Ind), 20, 'm')\nxlabel('partisanship'),  ylabel('bipartisanship')\nlegend('Democrat', 'Republican', 'Independent')\ntitle(('111th US Senate in 2D'));","type":"content","url":"/chapter7-1#id-7-5","position":13},{"hierarchy":{"lvl1":"Chapter 8"},"type":"lvl1","url":"/chapter8-1","position":0},{"hierarchy":{"lvl1":"Chapter 8"},"content":"","type":"content","url":"/chapter8-1","position":1},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"type":"lvl2","url":"/chapter8-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"content":"Power iteration\n\nfunction [beta, x] = poweriter(A, numiter)\r\n% POWERITER   Power iteration for the dominant eigenvalue.\r\n% Input:\r\n%   A         square matrix\r\n%   numiter   number of iterations\r\n% Output: \r\n%   beta      sequence of eigenvalue approximations (vector)\r\n%   x         final eigenvector approximation\r\n\r\nn = length(A);\r\nx = randn(n, 1);\r\nx = x / norm(x, inf);\r\nfor k = 1:numiter\r\n    y = A*x;\r\n    [normy, m] = max(abs(y));\r\n    beta(k) = y(m) / x(m);\r\n    x = y / y(m);\r\nend \n\nInverse iteration\n\nfunction [beta, x] = inviter(A, s, numiter)\r\n% INVITER   Shifted inverse iteration for the closest eigenvalue.\r\n% Input:\r\n%   A         square matrix\r\n%   s         value close to targeted eigenvalue (complex scalar)\r\n%   numiter   number of iterations\r\n% Output: \r\n%   beta      sequence of eigenvalue approximations (vector)\r\n%   x         final eigenvector approximation\r\n\r\nn = length(A);\r\nx = randn(n, 1);\r\nx = x / norm(x, inf);\r\nB = A - s*eye(n);\r\n[L,U] = lu(B);\r\nfor k = 1:numiter\r\n    y = U \\ (L\\x);\r\n    [normy, m] = max(abs(y));\r\n    beta(k) = (x(m) / y(m)) + s;\r\n    x = y / y(m);\r\nend \n\nArnoldi iteration\n\nfunction [Q, H] = arnoldi(A, u, m)\r\n% ARNOLDI   Arnoldi iteration for Krylov subspaces.\r\n% Input:\r\n%   A    square matrix (n by n)\r\n%   u    initial vector\r\n%   m    number of iterations\r\n% Output: \r\n%   Q    orthonormal basis of Krylov space (n by m+1)\r\n%   H    upper Hessenberg matrix, A*Q(:,1:m)=Q*H (m+1 by m)\r\n\r\nn = length(A);\r\nQ = zeros(n, m+1);  \r\nH = zeros(m+1, m);\r\nQ(:, 1) = u / norm(u);\r\nfor j = 1:m\r\n  % Find the new direction that extends the Krylov subspace.\r\n  v = A * Q(:, j);\r\n  % Remove the projections onto the previous vectors.\r\n  for i = 1:j\r\n    H(i, j) = Q(:, i)' * v;\r\n    v = v - H(i,j) * Q(:,i);\r\n  end\r\n  % Normalize and store the new basis vector.\r\n  H(j+1, j) = norm(v);\r\n  Q(:, j+1) = v / H(j+1, j);\r\nend\n\nGMRES\n\nfunction [x, residual] = arngmres(A, b, m)\r\n% ARNGMRES   GMRES for a linear system (demo only).\r\n% Input:\r\n%   A       square matrix (n by n)\r\n%   b       right-hand side (n by 1)\r\n%   M       number of iterations\r\n% Output: \r\n%   x       approximate solution (n by 1)\r\n%   r       history of norms of the residuals\r\n\r\nn = length(A);\r\nQ = zeros(n, m+1);  \r\nQ(:, 1) = b / norm(b);\r\nH = zeros(m+1 ,m);\r\n\r\n% Initial \"solution\" is zero.\r\nresidual(1) = norm(b);\r\n\r\nfor j = 1:m\r\n  % Next step of Arnoldi iteration.\r\n  v = A * Q(:, j);\r\n  for i = 1:j\r\n      H(i, j) = Q(:, i)' * v;\r\n      v = v - H(i, j) * Q(:,i);\r\n  end\r\n  H(j+1, j) = norm(v);\r\n  Q(:, j+1) = v / H(j+1, j);\r\n  \r\n  % Solve the minimum residual problem.\r\n  r = norm(b) * eye(j+1, 1);\r\n  z = H(1:j+1, 1:j) \\ r;\r\n  x = Q(:, 1:j) * z;\r\n  residual(j+1) = norm( A*x - b );\r\nend","type":"content","url":"/chapter8-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"type":"lvl2","url":"/chapter8-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;;\n\n","type":"content","url":"/chapter8-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-1","position":6},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"content":"Example 8.1.1\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nload roswelladj\na = whos('A')\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nTip\n\nUse nnz to count the number of nonzeros in a sparse matrix.\n\nsz = size(A);  n = sz(1);\ndensity = nnz(A) / prod(sz)\n\nThe computer memory consumed by any variable can be discovered using whos. We can use it to compare the space needed for the sparse representation to its dense counterpart, that is, the space needed to store all the elements, whether zero or not.\n\nF = full(A);\nf = whos('F');\nstorage_ratio = f.bytes / a.bytes\n\nMatrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nx = randn(n,1);\ntic, for i = 1:200, A*x; end\nsparse_time = toc\n\ntic, for i = 1:200, F*x; end\ndense_time = toc\n\nHowever, the sparse storage format in MATLAB is column-oriented.  Operations on rows may take a lot longer than similar ones on columns.\n\nv = A(:, 1000);\ntic, for i = 1:n, A(:, i) = v; end\ncolumn_time = toc\nr = v';\ntic, for i = 1:n, A(i, :) = r; end\nrow_time = toc\n\nExample 8.1.2\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nload smallworld.mat\nG = graph(A);\nplot(G, nodecolor='r')\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nspy(A)\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nclf\ntiledlayout(2, 2)\nfor k = [2, 3, 4, 6]\n    nexttile\n    spy(A^k)\n    title(sprintf(\"A^{%d}\", k))\nend\n\nExample 8.1.3\n\nThe spdiags function creates a sparse matrix given its diagonal elements. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50;\nn = 50;\n% Put constant values on 3 diagonals\nA = spdiags([n, 1, 0.1], [-3, 0, 5], n, n);\n% Put other values on 1st superdiagonal\nA = spdiags(-(0:n-1)', 1, A);\nfull(A(1:7, 1:7))\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nTip\n\nThe sparse function converts any matrix to sparse form. But it’s usually better to construct a sparse matrix directly, as the standard form might not fit in memory.\n\n[L, U] = lufact(A);\nclf\nsubplot(1, 2, 1), spy(L), title('L')\nsubplot(1, 2, 2), spy(U), title(('U'));\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\n[L, U, p] = plufact(A);\nsubplot(1, 2, 1), spy(L(p, :)), title('L')\nsubplot(1, 2, 2), spy(U), title(('U'));\n\nExample 8.1.4\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000;\ndensity = 4e-4;\nlambda = 1 ./ (1:n);\nA = sprandsym(n, density, lambda);\nclf,  spy(A)\ntitle('Sparse symmetric matrix')\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude.\n\n[V, D] = eigs(A, 5);    % largest magnitude\n1 ./ diag(D)            % should be 1, 2, 3, 4, 5\n\nNow we find the 4 closest to the value 0.03 in the complex plane.\n\n[V, D] = eigs(A, 4, 0.03);    % closest to 0.03\ndiag(D)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nx = 1 ./ (1:n)';  \nb = A * x;\ntic, sparse_err = norm(x - A\\b), sparse_time = toc\n\nF = full(A);\ntic, dense_err = norm(x - F\\b), dense_time = toc","type":"content","url":"/chapter8-1#id-8-1","position":7},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-2","position":8},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"content":"Example 8.2.1\n\nHere we choose a magic 5×5 matrix and a random 5-vector.\n\nA = magic(5) / 65;\nx = randn(5, 1);\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A * x\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A * y\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nfor j = 1:8\n    x = A * x;\nend\n[x, A * x]\n\nThis phenomenon seems to occur regardless of the starting vector.\n\nx = randn(5, 1);\nfor j = 1:8\n    x = A * x;\nend\n[x, A * x]\n\nExample 8.2.2\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nev = [1, -0.75, 0.6, -0.4, 0];\n% Make a triangular matrix with eigenvalues on the diagonal.\nA = triu(ones(5, 5), 1) + diag(ev);\n\nWe run the power iteration 60 times. The best estimate of the dominant eigenvalue is the last entry of the first output.\n\n[beta, x] = poweriter(A, 60);\nformat long\nbeta(1:12)\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = 1 - beta;\nclf,  semilogy(abs(err), '.-')\ntitle('Convergence of power iteration')\nxlabel('k'),  ylabel(('|\\lambda_1 - \\beta_k|'));\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\ntheory = ev(2) / ev(1)\nobserved = err(40) / err(39)\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nbeta(26:29)\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = beta(end) - beta(1:end-1);\nsemilogy(abs(err), '.-')\ntitle('Convergence of power iteration')\nxlabel('k'),  ylabel(('|\\beta_{60} - \\beta_k|'));\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.","type":"content","url":"/chapter8-1#id-8-2","position":9},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-3","position":10},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"content":"Example 8.3.1\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nev = [1, -0.75, 0.6, -0.4, 0];\nA = triu(ones(5, 5), 1) + diag(ev);\n\nWe run inverse iteration with the shift s=0.7. The result should converge to the eigenvalue closest to 0.7, which we know to be 0.6 here.\n\ns = 0.7;\n[beta, x] = inviter(A, s, 30);\nformat short\nbeta(1:10)\n\nThe convergence is again linear.\n\nerr = abs(0.6 - beta);\nsemilogy(abs(err),'.-')\ntitle('Convergence of inverse iteration')\nxlabel('k'), ylabel(('|\\lambda_j - \\beta_k|'));\n\nLet’s reorder the eigenvalues to enforce \n\n(8.3.3).\n\nTip\n\nThe second output of sort returns the index permutation needed to sort the given vector.\n\n[~, idx] = sort(abs(ev - s));\nev = ev(idx)\n\nNow it is easy to compare the theoretical and observed linear convergence rates.\n\ntheoretical_rate = (ev(1) - s) / (ev(2) - s)\nobserved_rate = err(26) / err(25)\n\nExample 8.3.2\n\nev = [1, -0.75, 0.6, -0.4, 0];\nA = triu(ones(5, 5), 1) + diag(ev);\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\ns = 0.7;\nx = ones(5, 1);\ny = (A - s * eye(5)) \\ x;\nbeta = x(1) / y(1) + s\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = beta;\nx = y / y(1);\ny = (A - s * eye(5)) \\ x;\nbeta = x(1) / y(1) + s\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nformat long\nfor k = 1:4\n    s = beta;\n    x = y / y(1);\n    y = (A - s * eye(5)) \\ x;\n    beta = x(1) / y(1) + s\nend","type":"content","url":"/chapter8-1#id-8-3","position":11},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-4","position":12},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"content":"Example 8.4.1\n\nFirst we define a triangular matrix \\mathbf{A} with known eigenvalues and a random vector \\mathbf{b}.\n\nlambda = 10 + (1:100);\nA = diag(lambda) + triu(rand(100), 1); \nb = rand(100, 1);\n\nNext, we build up the first ten Krylov matrices iteratively. In order to keep the columns from growing exponentially in norm, we normalize them as we go. This doesn’t affect the column space of the Krylov matrix, in principle at least.\n\nKm = b;\nfor m = 1:29      \n    v = A * Km(:, m);\n    Km(:, m+1) = v / norm(v);\nend\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nwarning off  \nresid = zeros(30, 1);\nfor m = 1:30  \n    z = (A * Km(:, 1:m)) \\ b;\n    x = Km(:, 1:m) * z;\n    resid(m) = norm(b - A * x);\nend\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nclf\nsemilogy(resid, '.-')\nxlabel('m'),  ylabel('|| b-Ax_m ||')\nset(gca,'ytick',10.^(-6:2:0))\naxis tight, title('Residual for linear systems')\n\nExample 8.4.2\n\nHere again is the linear system from \n\nExample 8.4.1.\n\nlambda = 10 + (1:100);\nA = diag(lambda) + triu(rand(100), 1); \nb = rand(100, 1);\n\nWe can use \\mathbf{b} as the seed vector for the Arnoldi iteration.\n\n[Q, H] = arnoldi(A, b, 30);\ndisp(sprintf(\"Q is %d by %d\", size(Q)))\ndisp(sprintf(\"H is %d by %d\", size(H)))\n\nHere’s one validation of the key identity \n\n(8.4.10).\n\nshould_be_near_zero = norm(A * Q(:, 1:20) - Q(:, 1:21) * H(1:21, 1:20))\n\nUsing the Krylov matrix to project the linear system into a Kyrlov subspace in \n\nExample 8.4.1 was unable to get the residual much smaller than about \n\n10-4. But the Arnoldi basis gives us a stable way to work in that subspace and get better results.\n\nz = (A * Q) \\ b;\nx = Q * z;\nresid_norm = norm(b - A * x)","type":"content","url":"/chapter8-1#id-8-4","position":13},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-5","position":14},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"content":"Example 8.5.1\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nlambda = 10 + (1:100);\nA = diag(lambda) + triu(rand(100), 1); \nb = rand(100, 1);\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\n[Q, H] = arnoldi(A, b, 60);\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nresid = norm(b);\nfor m = 1:60\n    s = [norm(b); zeros(m, 1)];\n    z = H(1:m+1, 1:m) \\ s;\n    x = Q(:, 1:m) * z;\n    resid = [resid, norm(b - A * x)];\nend\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nclf\nsemilogy(resid,'.-')\nxlabel('m'),  ylabel('|| b - Ax_m ||')\naxis tight, title(('Residual for GMRES'));\n\nExample 8.5.2\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nd = 50;\nA = d^2 * gallery('poisson', d);\nn = size(A, 1)\nb = ones(n, 1);\nclf,  spy(A)\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using the built-in gmres, since our simple implementation does not offer restarting.\n\nclf\nrestart = [120, 20, 40, 60];\nfor j = 1:4\n    [~,~,~,~,rv] = gmres(A, b, restart(j), 1e-9,120 / restart(j));\n    semilogy(0:length(rv) - 1, rv),  hold on\nend\ntitle('Convergence of restarted GMRES')\nxlabel('m'),  ylabel('residual norm')\nlegend('no restart','every 20','every 40','every 60','location','southwest');\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.","type":"content","url":"/chapter8-1#id-8-5","position":15},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-6","position":16},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"content":"Example 8.6.2\n\nThe following matrix is indefinite.\n\nA = (11 / pi)^2 * gallery('poisson', 10);\nA = A - 20 * eye(100);\nlambda = eig(full(A));\nisneg = lambda < 0;\ndisp(sprintf(\"%d negative and %d positive eigenvalues\", sum(isneg), sum(~isneg)))\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nm = min(-lambda(isneg));\nM = max(-lambda(isneg));\nkappa_minus = M / m;\nm = min(lambda(~isneg));\nM = max(lambda(~isneg));\nkappa_plus = M / m;\nS = sqrt(kappa_minus * kappa_plus);\nrho = sqrt((S - 1) / (S + 1));\nfprintf(\"convergence rate: %.3f\", rho)\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nb = rand(100, 1);\n[xMR, ~,~ , ~, residMR] = minres(A, b, 1e-10, 100);\nrelres = residMR / norm(b);\nm = 0:length(relres) - 1;\nclf,  semilogy(m, relres, '.-')\nhold on\nsemilogy(m, rho .^ m, 'k--')\nxlabel('m'),  ylabel('relative residual') \ntitle('Convergence of MINRES') \nlegend('MINRES', 'upper bound', 'location', 'southwest');\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nExample 8.6.3\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000;\ndensity = 0.001;\nA = sprandsym(n, density, 1e-2, 2);\n\nWe generate a system with a known solution.\n\nx = (1:n)' / n;\nb = A * x;\n\nNow we apply both methods and compare the convergence of the system residuals.\n\n[xMR, ~, ~, ~, residMR] = minres(A, b, 1e-7, 100);\n[xCG, ~, ~, ~, residCG] = pcg(A, b, 1e-7, 100);\nM = length(residMR) - 1;\nclf,  semilogy(0:M, residMR / norm(b), '.-')\nM = length(residCG) - 1;\nhold on,  semilogy(0:M, residCG / norm(b), '.-')\ntitle('Convergence of MINRES and CG')\nxlabel('Krylov dimension m')\nylabel('||r_m|| / ||b||')\nlegend('MINRES', 'CG');\n\nThere is little difference between the two methods here. Next, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5.\n\nA = sprandsym(n, density, 1e-2 / 25, 2);\nb = A * x;\n\n[xMR, ~, ~, ~, residMR] = minres(A, b, 1e-7, 400);\n[xCG, ~, ~, ~, residCG] = pcg(A, b, 1e-7, 400);\nM = length(residMR) - 1;\nclf,  semilogy(0:M, residMR / norm(b), '.-')\nM = length(residCG) - 1;\nhold on,  semilogy(0:M, residCG / norm(b), '.-')\ntitle('Convergence of MINRES and CG')\nxlabel('Krylov dimension m')\nylabel('||r_m|| / ||b||')\nlegend('MINRES', 'CG');\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation. Both methods ultimately achieve the same reduction in the residual; MINRES stops earlier, but with a slightly larger error.","type":"content","url":"/chapter8-1#id-8-6","position":17},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-7","position":18},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"content":"Example 8.7.1\n\nWe use a readily available test image.\n\nload mandrill\n[m, n] = size(X);\nclf\nimshow(X, [0, 255])\ntitle('Original image')    % ignore this\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nv = [1/4, 1/2, 1/4];\nB = spdiags(v, -1:1, m, m);\nC = spdiags(v, -1:1, n, n);\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nblur = @(X) B^12 * X * C^12;\nimshow(blur(X), [0, 255])\ntitle(('Blurred image'));\n\nExample 8.7.2\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nload mandrill\n[m, n] = size(X);\nv = [1/4, 1/2, 1/4];\nB = spdiags(v, -1:1, m, m);\nC = spdiags(v, -1:1, n, n);\nblur = @(X) B^12 * X * C^12;\n\nZ = blur(X);\nclf,  imshow(Z, [0, 255])\ntitle((\"Blurred image\"));\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\nvec = @(X) reshape(X,m*n,1);\nunvec = @(x) reshape(x,m,n);\nT = @(x) vec( blur(unvec(x)) );\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\ny = gmres(T, vec(Z), 50, 1e-5);\nY = unvec(y);\n\nsubplot(121)\nimshow(X, [0, 255])\ntitle(\"Original\")\nsubplot(122)\nimshow(Y, [0, 255])\ntitle((\"Deblurred\"));","type":"content","url":"/chapter8-1#id-8-7","position":19},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-1#id-8-8","position":20},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"content":"Example 8.8.1\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nA = gallery(\"wathen\", 60, 60);\nn = size(A, 1);\nclf,  spy(A)\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nM = spdiags(diag(A), 0, n, n);\n\nWe now compare MINRES with and without the preconditioner.\n\nb = ones(n, 1);\n[x, ~, ~, ~, resid_plain] = minres(A, b, 1e-10, 400);\nclf,  semilogy(resid_plain)\nxlabel('iteration number'), ylabel('residual norm')\ntitle('Unpreconditioned MINRES')\n\n[x, ~, ~, ~, resid_prec] = minres(A, b, 1e-10, 400, M);\nhold on,  semilogy(resid_prec)\ntitle('Precondtioned MINRES')\nlegend('no prec.', 'with prec.');\n\nThe diagonal preconditioner cut down substantially on the number of iterations. The effect on the total time is less dramatic, but this is not a large version of the problem.\n\nExample 8.8.2\n\nHere is a random nonsymmetric matrix.\n\nn = 8000;\nA = speye(n) + sprand(n, n, 0.00035);\n\nWithout a preconditioner, restarted GMRES makes slow progress.\n\nb = rand(n, 1);\n[x, ~, ~, ~, resid_plain] = gmres(A, b, 50, 1e-10, 3);  % restart at 50\nformat short e\nresid_plain(1:30:end)\n\nThis version of incomplete LU factorization simply prohibits fill-in for the factors, freezing the sparsity pattern of the approximate factors to match the original matrix.\n\n[L, U] = ilu(A);\nclf\nsubplot(121), spy(L)\ntitle('L')\nsubplot(122), spy(U)\ntitle('U')\ndisp(sprintf(\"There are %d nonzeros in A\", nnz(A)))\n\nIt does not produce a true factorization of \\mathbf{A}.\n\nnorm( full(A - L * U) )\n\nThe actual preconditioning matrix is \\mathbf{M}=\\mathbf{L}\\mathbf{U}. However, the gmres function allows setting the preconditioner by giving the factors independently.\n\n[x, ~, ~, ~, resid_prec] = gmres(A, b, [], 1e-10, 300, L, U);\n\nThe preconditioner makes a significant difference in the number of iterations needed.\n\nclf, semilogy(resid_plain)\nhold on, semilogy(resid_prec)\nxlabel('iteration number'), ylabel('residual norm')\ntitle('Precondtioned GMRES ')\nlegend('no preconditioner', 'with preconditioner');","type":"content","url":"/chapter8-1#id-8-8","position":21},{"hierarchy":{"lvl1":"Chapter 9"},"type":"lvl1","url":"/chapter9-1","position":0},{"hierarchy":{"lvl1":"Chapter 9"},"content":"","type":"content","url":"/chapter9-1","position":1},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Functions"},"type":"lvl2","url":"/chapter9-1#functions","position":2},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Functions"},"content":"Barycentric polynomial interpolation\n\nfunction p = polyinterp(t, y)\r\n% POLYINTERP Polynomial interpolation by the barycentric formula.\r\n% Input:\r\n%   t   interpolation nodes (vector, length n+1)\r\n%   y   interpolation values (vector, length n+1)\r\n% Output:\r\n%   p   polynomial interpolant (function)\r\n\r\nt = t(:);                    % column vector\r\nn = length(t) - 1;\r\nC = (t(end) - t(1)) / 4;       % scaling factor to ensure stability\r\ntc = t / C;\r\n\r\n% Adding one node at a time, compute inverses of the weights.\r\nomega = ones(n+1, 1);\r\nfor m = 1:n\r\n    d = (tc(1:m) - tc(m+1));      % vector of node differences\r\n    omega(1:m) = omega(1:m) .* d; % update previous \r\n    omega(m+1) = prod(-d);        % compute the new one\r\nend\r\nw = 1./omega;                     % go from inverses to weights\r\np = @evaluate;\r\n\r\n    function f = evaluate(x)\r\n        % % Compute interpolant, one value of x at a time.\r\n        f = zeros(size(x));\r\n        for j = 1:numel(x)\r\n            terms = w ./ (x(j) - t );\r\n            f(j) = sum(y.*terms) / sum(terms);\r\n        end\r\n        \r\n        % Apply L'Hopital's Rule exactly.\r\n        for j = find( isnan(f(:)) )'           % where divided by zero\r\n            [~, idx] = min( abs(x(j) - t) );   % node closest to x(j)\r\n            f(j) = y(idx);                     % value at node\r\n        end        \r\n    end    % evaluate function\r\n\r\nend    % polyinterp function\n\nTrigonometric interpolation\n\nfunction p = triginterp(t,y)\r\n% TRIGINTERP Trigonometric interpolation.\r\n% Input:\r\n%   t   equispaced interpolation nodes (vector, length N)\r\n%   y   interpolation values (vector, length N)\r\n% Output:\r\n%   p   trigonometric interpolant (function)\r\n\r\nN = length(t);\r\np = @value;\r\n\r\n    function f = value(x)\r\n        f = zeros(size(x));\r\n        for k = 1:N\r\n            f = f + y(k) * trigcardinal(x - t(k));\r\n        end\r\n    end    % value function\r\n        \r\n    function tau = trigcardinal(x)\r\n        if rem(N,2)==1   % odd\r\n            tau = sin(N*pi*x/2) ./ (N * sin(pi*x/2));\r\n        else             % even\r\n            tau = sin(N*pi*x/2) ./ (N * tan(pi*x/2));\r\n        end\r\n        tau(isnan(tau)) = 1;    % fix divisions by zero\r\n    end    % trigcardinal function\r\n        \r\nend    % triginterp function\n\nClenshaw-Curtis integration\n\nfunction [I, x] = ccint(f, n)\r\n% CCINT  Clenshaw-Curtis numerical integration.\r\n% Input:\r\n%   f     integrand (function)\r\n%   n     one less than the number of nodes (even integer)\r\n% Output:\r\n%   I     estimate of integral(f,-1,1)\r\n%   x     evaluation nodes of f (vector)\r\n\r\n% Find Chebyshev extreme nodes.\r\ntheta = pi * (0:n)' / n;\r\nx = -cos(theta);\r\n\r\n% Compute the C-C weights.\r\nc = zeros(1, n+1); \r\nc([1, n+1]) = 1 / (n^2 - 1); \r\ntheta = theta(2:n); \r\nv = ones(n-1, 1);\r\nfor k = 1:n/2-1\r\n  v = v - 2 * cos(2*k*theta) / (4*k^2 - 1);\r\nend\r\nv = v - cos(n*theta) / (n^2 - 1);\r\nc(2:n) = 2 * v / n;\r\n\r\n% Evaluate integrand and integral.\r\nI = c*f(x);   % use vector inner product\n\nGauss-Legendre integration\n\nfunction [I, x] = glint(f, n)\r\n% GLINT  Gauss-Legendre numerical integration.\r\n% Input:\r\n%   f     integrand (function)\r\n%   n     number of nodes (integer)\r\n% Output:\r\n%   I     estimate of integral(f,-1,1)\r\n%   x     evaluation nodes of f (vector)\r\n\r\n% Nodes and weights are found via a tridiagonal eigenvalue problem.\r\nbeta = 0.5./sqrt(1 - (2*(1:n-1)).^(-2));\r\nT = diag(beta, 1) + diag(beta, -1);\r\n[V, D] = eig(T);\r\nx = diag(D); \r\n[x, idx] = sort(x);         % nodes\r\nc = 2 * V(1, idx).^2;       % weights\r\n\r\n% Evaluate the integrand and compute the integral.\r\nI = c*f(x);      % vector inner product\n\nIntegration over (-\\infty,\\infty)\n\nfunction [I, x] = intinf(f, tol)\r\n% INTINF   Adaptive doubly exponential integration over (-inf,inf).\r\n% Input:\r\n%   f   integrand (function)\r\n%   tol error tolerance (positive scalar)\r\n% Output:\r\n%   I   approximation to intergal(f) over (-inf,inf)\r\n%   x   evaluation nodes (vector) \r\n\r\nxi = @(t) sinh(sinh(t));\r\ndxi_dt = @(t) cosh(t) .* cosh(sinh(t));\r\ng = @(t) f(xi(t)) .* dxi_dt(t);\r\n\r\n% Find where to truncate the integration interval.\r\nM = 3;\r\nwhile (abs(g(-M)) > tol/100) || (abs(g(M)) > tol/100)\r\n    M = M + 0.5;\r\n    if isinf(xi(M)) \r\n        warning(\"Function may not decay fast enough.\")\r\n        M = M - 0.5;\r\n        break\r\n    end\r\nend\r\n\r\n[I, t] = intadapt(g, -M, M, tol);\r\nx = xi(t);\r\nend\n\nIntegration with endpoint singularities\n\nfunction [I, x] = intsing(f, tol)\r\n% INTSING   Adaptively integrate a function with a singularity at the left endpoint.\r\n% Input:\r\n%   f   integrand  (function)\r\n%   tol error tolerance (positive scalar)\r\n% Output:\r\n%   I   approximation to integral(f) over (0,1)\r\n%   x   evaluation nodes (vector)\r\n\r\nxi = @(t) 2 ./ (1 + exp( 2*sinh(t) ));\r\ndxi_dt = @(t) cosh(t) ./ cosh( sinh(t) ).^2;\r\ng = @(t) f(xi(t)) .* dxi_dt(t);\r\n\r\n% Find where to truncate the integration interval.\r\nM = 3;\r\nwhile abs(g(M)) > tol/100\r\n    M = M + 0.5;\r\n    if xi(M) == 0\r\n        warning(\"Function may grow too rapidly.\")\r\n        M = M - 0.5;\r\n        break\r\n    end\r\nend\r\n\r\n[I, t] = intadapt(g, 0, M, tol);\r\nx = xi(t);\r\nend","type":"content","url":"/chapter9-1#functions","position":3},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Examples"},"type":"lvl2","url":"/chapter9-1#examples","position":4},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Examples"},"content":"\n\ncd  /Users/driscoll/Documents/GitHub/fnc/matlab\nFNC_init;\n\n","type":"content","url":"/chapter9-1#examples","position":5},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.1 Polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-1","position":6},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.1 Polynomial interpolation","lvl2":"Examples"},"content":"Example 9.1.1\n\nHere is a vector of nodes.\n\nt = [ 1, 1.5, 2, 2.25, 2.75, 3 ];\nn = 5;  k = 2;\nnot_k = [0:k-1 k+1:n];   % all except the kth node\n\nLet’s apply the definition of the cardinal Lagrange polynomial for k=2. First we define a polynomial q that is zero at all the nodes except i=k. Then \\ell_2 is found by normalizing q by q(t_k).\n\nTip\n\nWhenever we index into the node vector t, we have to add 1 since the mathematical index starts at zero.\n\nq = @(x) prod(x - t(not_k + 1));\nell_k = @(x) q(x) ./ q(t(k + 1));\n\nA plot confirms the cardinal property of the result.\n\nclf\nfplot(ell_k, [1, 3])\nhold on, grid on\nplot(t(not_k + 1), 0 * t(not_k + 1), 'o')\nplot(t(k + 1), 1, 'o')\nxlabel('x'),  ylabel('\\ell_2(x)')    \ntitle('Lagrange cardinal function')\n\nObserve that \\ell_k is not between zero and one everywhere, unlike a hat function.\n\nExample 9.1.3\n\nt =  [ 1, 1.6, 1.9, 2.7, 3 ];\nn = length(t) - 1;\nPhi = @(x) prod(x - t);\n\nclf,  fplot(@(x) Phi(x) / 5, [1, 3])\nhold on,  plot(t, 0*t, 'o')\nxlabel('x'),  ylabel('\\Phi(x)')   \ntitle('Interpolation error function')\n\nThe error is zero at the nodes, by the definition of interpolation. The error bound, as well as the error itself, has one local maximum between each consecutive pair of nodes.","type":"content","url":"/chapter9-1#id-9-1","position":7},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.2 The barycentric formula","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-2","position":8},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.2 The barycentric formula","lvl2":"Examples"},"content":"Example 9.2.2\n\nf = @(x) sin( exp(2 * x) );\nclf,  fplot(f, [0, 1], displayname=\"function\")\nxlabel('x'),  ylabel('f(x)')   \nlegend(location=\"southwest\");\n\nWe start with 4 equally spaced nodes (n=3).\n\nt = linspace(0, 1, 4)'; \ny = f(t);\np = polyinterp(t, y);\nhold on,  fplot(p, [0, 1], displayname=\"interpolant on 4 nodes\")\nscatter(t, y, 'k', displayname=\"nodes\")\n\nThe curves always intersect at the interpolation nodes. For n=6, the interpolant is noticeably better.\n\ncla,  fplot(f, [0, 1], displayname=\"function\")\nt = linspace(0, 1, 7)'; \ny = f(t);\np = polyinterp(t, y);\nhold on,  fplot(p, [0, 1], displayname=\"interpolant on 7 nodes\")\nscatter(t, y, 'k', displayname=\"nodes\")","type":"content","url":"/chapter9-1#id-9-2","position":9},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.3 Stability of polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-3","position":10},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.3 Stability of polynomial interpolation","lvl2":"Examples"},"content":"Example 9.3.1\n\nWe choose a function over the interval [0,1]. Using 7 equally spaced nodes, the interpolation looks fine.\n\nf = @(x) sin(exp(2*x));\nclf,  fplot(f, [0, 1], displayname=\"function\")\nt = linspace(0, 1, 7);\ny = f(t);\nhold on,  scatter(t, y, displayname=\"nodes\")\np = polyinterp(t, y)\nfplot(p, [0, 1], displayname=\"interpolant\")\nxlabel('x'),  ylabel('f(x)') \ntitle('Test function')\n\nWe want to track the behavior of the error as n increases. We will estimate the error in the continuous interpolant by sampling it at a large number of points and taking the max-norm.\n\nn = (5:5:60)';   \nerr = zeros(size(n));\nx = linspace(0, 1, 1001)';         % for measuring error\nfor k = 1:length(n) \n  t = linspace(0, 1, n(k) + 1)';     % equally spaced nodes\n  y = f(t);                      % interpolation data\n  p = polyinterp(t, y);\n  err(k) = norm(f(x) - p(x), Inf);\nend\nclf,  semilogy(n, err, 'o-')\nxlabel('n'),  ylabel('max error')   \ntitle('Equispaced polynomial interpolation error')\n\nThe error initially decreases as one would expect but then begins to grow. Both phases occur at rates that are exponential in n, i.e., O(K^n) for a constant K, appearing linear on a semi-log plot.\n\nExample 9.3.2\n\nWe plot |\\Phi(x)| over the interval [-1,1] with equispaced nodes for different values of n.\n\nclf\nx = linspace(-1, 1, 1601)';\nPhi = zeros(size(x));\nfor n = 10:10:50\n    t = linspace(-1, 1, n+1)';\n    for k = 1:length(x)\n        Phi(k) = prod(x(k) - t);\n    end\n    semilogy(x, abs(Phi)),  hold on\nend\ntitle('Error indicator on equispaced nodes')    \nxlabel('x'),  ylabel('|\\Phi(x)|')\n\nEach time Φ passes through zero at an interpolation node, the value on the log scale should go to -\\infty, which explains the numerous cusps on the curves.\n\nExample 9.3.3\n\nThis function has infinitely many continuous derivatives on the entire real line and looks easy to approximate over [-1,1].\n\nf = @(x) 1 ./ (x.^2 + 16);\nclf,  fplot(f, [-1, 1])\nxlabel('x'),  ylabel('f(x)')    \ntitle('Test function')\n\nWe start by doing equispaced polynomial interpolation for some small values of n.\n\nx = linspace(-1, 1, 1601)';\nn = (4:4:12)';\nfor k = 1:length(n)\n    t = linspace(-1, 1, n(k) + 1)';        % equally spaced nodes\n    p = polyinterp(t, f(t));\n    semilogy(x, abs(f(x) - p(x)));  hold on\nend\ntitle('Error for degrees 4, 8, 12')   \nxlabel('x'), ylabel('|f(x) - p(x)|')\n\nThe convergence so far appears rather good, though not uniformly so. However, notice what happens as we continue to increase the degree.\n\nn = 12 + 15 * (1:3);\nclf\nfor k = 1:length(n)\n    t = linspace(-1, 1, n(k) + 1)';        % equally spaced nodes\n    p = polyinterp(t, f(t));\n    semilogy(x, abs(f(x) - p(x)));  hold on\nend\ntitle('Error for degrees 27, 42, 57')   \nxlabel('x'), ylabel('|f(x) - p(x)|')\n\nThe convergence in the middle can’t get any better than machine precision relative to the function values. So maintaining the growing gap between the center and the ends pushes the error curves upward exponentially fast at the ends, wrecking the convergence.\n\nExample 9.3.4\n\nNow we look at the error indicator function Φ for Chebyshev node sets.\n\nclf\nx = linspace(-1, 1, 1601)';\nPhi = zeros(size(x));\nfor n = 10:10:50\n    theta = linspace(0, pi, n+1)';\n    t = -cos(theta);                    \n    for k = 1:length(x)\n        Phi(k) = prod(x(k) - t);\n    end\n    semilogy(x, abs(Phi));  hold on\nend\naxis tight, title('Effect of Chebyshev nodes')    \nxlabel('x'), ylabel('|\\Phi(x)|')   \nylim([1e-18, 1e-2])\n\nIn contrast to the equispaced case, |\\Phi| decreases exponentially with n almost uniformly across the interval.\n\nExample 9.3.5\n\nHere again is the function from \n\nDemo 9.3.3 that provoked the Runge phenomenon when using equispaced nodes.\n\nf = @(x) 1 ./ (x.^2 + 16);\n\nclf\nx = linspace(-1, 1, 1601)';\nn = [4, 10, 16, 40];\nfor k = 1:length(n) \n    theta = linspace(0, pi, n(k) + 1)';\n    t = -cos(theta);\n    p = polyinterp(t, f(t));\n    semilogy( x, abs(f(x) - p(x)) );  hold on\nend\ntitle('Error for degrees 4, 10, 16, 40')   \nxlabel('x'), ylabel('|f(x)-p(x)|')\n\nBy degree 16 the error is uniformly within machine epsilon, and, importantly, it stays there as n increases. Note that as predicted by the error indicator function, the error is uniform over the interval at each value of n.\n\nExample 9.3.6\n\nOn the left, we use a log-log scale, which makes second-order algebraic convergence O(n^{-4}) a straight line. On the right, we use a log-linear scale, which makes spectral convergence O(K^{-n}) linear.\n\nn = (20:20:400)';\nalgebraic = 100 ./ n.^4;\nspectral = 10 * 0.85.^n;\nclf, subplot(2, 1, 1)\nloglog(n, algebraic, 'o-', displayname=\"algebraic\")\nhold on;  loglog(n, spectral, 'o-', displayname=\"spectral\")\nxlabel('n'),  ylabel('error')   \ntitle('log–log')   \naxis tight,  ylim([1e-16, 1]);  legend(location=\"southwest\")   \n\nsubplot(2, 1, 2)\nsemilogy(n, algebraic, 'o-', displayname=\"algebraic\")\nhold on;  semilogy(n, spectral, 'o-', displayname=\"spectral\")\nxlabel('n'), ylabel('error'),  ylim([1e-16, 1])   \ntitle('log–linear')   \naxis tight,  ylim([1e-16, 1]);  legend(location=\"southwest\")","type":"content","url":"/chapter9-1#id-9-3","position":11},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.4 Orthogonal polynomials","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-4","position":12},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.4 Orthogonal polynomials","lvl2":"Examples"},"content":"Example 9.4.1\n\nLet’s approximate e^x over the interval [−1,1]. We can sample it at, say, 15 points, and find the best-fitting straight line to that data.\n\nclf;  fplot(@exp, [-1, 1], displayname=\"function\")\nt = linspace(-1, 1, 15)';\ny = exp(t);\nV = [t.^0, t];\nc = V \\ y;\np = @(t) c(1) + c(2)*t;\n\nhold on,  fplot(p, [-1, 1], displayname=\"LS fit at 15 points\")\ntitle('Least-squares fit to samples of exp(x)')    \nxlabel('x'),  ylabel('f(x)')    \nlegend(location=\"northwest\")\n\nThere’s nothing special about 15 points. Choosing more doesn’t change the result much.\n\nt = linspace(-1, 1, 150)';\ny = exp(t);\nV = [t.^0, t];\nc = V \\ y;\np = @(t) c(1) + c(2)*t;\nfplot(p, [-1, 1], displayname=\"LS fit at 150 points\")\n\nThis situation is unlike interpolation, where the degree of the interpolant increases with the number of nodes. Here, the linear fit is apparently approaching a limit that we may think of as a continuous least-squares fit.\n\nn = (40:60:400)';\nslope = zeros(size(n));\nintercept = zeros(size(n));\n\nfor k = 1:length(n)\n    t = linspace(-1, 1, n(k))';\n    V = [t.^0, t];\n    c = V \\ exp(t);\n    intercept(k) = c(1);\n    slope(k) = c(2);\nend\ntable(n, intercept, slope)","type":"content","url":"/chapter9-1#id-9-4","position":13},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.5 Trigonometric interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-5","position":14},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.5 Trigonometric interpolation","lvl2":"Examples"},"content":"Example 9.5.1\n\nWe will get a cardinal function without using an explicit formula, just by passing data that is 1 at one node and 0 at the others.\n\nN = 7;  n = (N-1) / 2;\nt = 2 * (-n:n)' / N;\ny = zeros(N, 1);  y(n+1) = 1;\nclf,  scatter(t, y, 'k'),  hold on\n\np = triginterp(t, y);\nfplot(p, [-1, 1])\nxlabel('x'),  ylabel('p(x)')   \ntitle('Trig cardinal function')\n\nHere is a 2-periodic function and one of its interpolants.\n\nclf\nf = @(x) exp( sin(pi*x) - 2 * cos(pi*x) );\nfplot(f, [-1, 1], displayname=\"periodic function\"),  hold on\nfplot(triginterp(t, f(t)), [-1, 1], displayname=\"trig interpolant\")\ny = f(t);  scatter(t, f(t), 'k')\nxlabel('x'),  ylabel('f(x)')   \ntitle('Trig interpolation');  legend()\n\nThe convergence of the interpolant is spectral. We let N go needlessly large here in order to demonstrate that unlike polynomials, trigonometric interpolation is stable on equally spaced nodes. Note that when N is even, the value of n is not an integer but works fine for defining the nodes.\n\nN = 2:2:60;\nerr = zeros(size(N));\nx = linspace(-1, 1, 1601)';  % for measuring error\nfor k = 1:length(N)\n    n = (N(k) - 1) / 2;\n    t = 2 * (-n:n)' / N(k);\n    p = triginterp(t, f(t));\n    err(k) = norm(f(x) - p(x), Inf);\nend\nclf,  semilogy(N, err, 'o-')\naxis tight, title('Convergence of trig interpolation')   \nxlabel('N'),  ylabel('max error')\n\nExample 9.5.2\n\nThis function has frequency content at 2\\pi, -2\\pi, and π.\n\nf = @(x) 3 * cos(2*pi * x) - exp(1i*pi * x);\n\nTo use fft, we set up nodes in the interval [0,2).\n\nn = 4;\nN = 2*n + 1;\nt = 2 * (0:N-1)' / N;      % nodes in $[0,2)$\ny = f(t);\n\nWe perform Fourier analysis using fft and then examine the resulting coefficients.\n\nc = fft(y) / N;\nfreq = [0:n, -n:-1]';\nformat short\ntable(freq, c, variableNames=[\"k\", \"coefficient\"])\n\nNote that 1.5 e^{2i\\pi x}+1.5 e^{-2i\\pi x} = 3 \\cos(2\\pi x), so this result is sensible.\n\nFourier’s greatest contribution to mathematics was to point out that every periodic function is just a combination of frequencies—infinitely many of them in general, but truncated for computational use. Here we look at the magnitudes of the coefficients for f(x) = \\exp( \\sin(\\pi x) ).\n\nf = @(x) exp( sin(pi*x) );    % content at all frequencies\nn = 9;  N = 2*n + 1;\nt = 2 * (0:N-1)' / N;         % nodes in $[0,2)$\ny = f(t);\nc = fft(y) / N;\nfreq = [0:n, -n:-1]';\n\nclf\nsemilogy(freq, abs(c), 'o')\nxlabel('k'),  ylabel('|c_k|')   \ntitle('Fourier coefficients')\n\nThe Fourier coefficients of smooth functions decay exponentially in magnitude as a function of the frequency. This decay rate is determines the convergence of the interpolation error.","type":"content","url":"/chapter9-1#id-9-5","position":15},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.6 Spectrally accurate integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-6","position":16},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.6 Spectrally accurate integration","lvl2":"Examples"},"content":"Example 9.6.1\n\nf = @(t) pi * sqrt( cos(pi*t).^2 + sin(pi*t).^2 / 4 );\nN = (4:4:48)';\nperim = zeros(size(N));\nfor k = 1:length(N)\n    h = 2 / N(k);\n    t = h * (0:N(k)-1);\n    perim(k) = h * sum(f(t));\nend\nerr = abs(perim - perim(end));    % use last value as \"exact\"\nformat long\ntable(N, perim, err, variableNames=[\"number of nodes\", \"perimeter\", \"error\"])\n\nThe approximations gain about one digit of accuracy for each constant increment of n, which is consistent with spectral convergence.\n\nExample 9.6.3\n\nFirst consider the integral\\int_{-1}^1 \\frac{1}{1+4x^2} \\, dx = \\arctan(2).\n\nf = @(x) 1 ./ (1 + 4*x.^2);\nexact = atan(2);\n\nWe compare the two spectral integration methods for a range of n values.\n\nn = (8:4:96)';\nerrCC = zeros(size(n));\nerrGL = zeros(size(n));\nfor k = 1:length(n)\n  errCC(k) = exact - ccint(f, n(k));\n  errGL(k) = exact - glint(f, n(k));\nend\nclf,  semilogy(n, abs([errCC errGL]), 'o-')\nxlabel('number of nodes'),  ylabel('error')\ntitle('Spectral integration')   \nlegend('Clenshaw–Curtis', 'Gauss–Legendre')\n\n(The missing points are where the error is exactly zero.) Gauss–Legendre does converge faster here, but at something less than twice the rate.\n\nNow we try a more sharply peaked integrand:\\int_{-1}^1 \\frac{1}{1+16x^2} \\, dx = \\frac{1}{2}\\arctan(4).\n\nf = @(x) 1 ./ (1 + 16*x.^2);\nexact = atan(4) / 2;\n\nn = (8:4:96)';\nerrCC = zeros(size(n));\nerrGL = zeros(size(n));\nfor k = 1:length(n)\n  errCC(k) = exact - ccint(f, n(k));\n  errGL(k) = exact - glint(f, n(k));\nend\nclf,  semilogy(n, abs([errCC errGL]), 'o-')\nxlabel('number of nodes'),  ylabel('error')\ntitle('Spectral integration')   \nlegend('Clenshaw–Curtis', 'Gauss–Legendre')\n\nThe two are very close until about n=40, when the Clenshaw–Curtis method slows down.\n\nNow let’s compare the spectral performance to that of our earlier adaptive method in intadapt. We will specify varying error tolerances and record the error as well as the total number of evaluations of f.\n\ntol = 10 .^ (-2:-2:-14)';\nn = zeros(size(tol));  \nerrAdapt = zeros(size(tol));\nfor k = 1:length(n)\n  [Q, t] = intadapt(f, -1, 1, tol(k));\n  errAdapt(k) = exact - Q;\n  n(k) = length(t);\nend\nhold on;  semilogy(n, abs(errAdapt), 'o-')\nplot(n, n.^(-4), 'k--')        % 4th order error\nset(gca, 'xscale', 'log')     \nlegend('ccint', 'glint', 'intadapt', '4th order')  \ntitle(('Spectral vs 4th order'));\n\nAt the core of intadapt is a fourth-order formula, and the results track that rate closely. For all but the most relaxed error tolerances, both spectral methods are far more efficient than the low-order counterpart. For other integrands, particularly those that vary nonuniformly across the interval, the adaptive method might be more competitive.","type":"content","url":"/chapter9-1#id-9-6","position":17},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.7 Improper integrals","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-1#id-9-7","position":18},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.7 Improper integrals","lvl2":"Examples"},"content":"Example 9.7.2\n\nf = @(x) 1 ./ (1 + x.^2);\nclf,  subplot(2, 1, 1)\nfplot(f, [-4, 4]);  set(gca, 'yscale', 'log') \nxlabel('x'),  ylabel('f(x)'),  ylim([1e-20, 1])  \ntitle('Original integrand')   \n\nx = @(t) sinh( pi * sinh(t) / 2 );\nchain = @(t) pi/2 * cosh(t) .* cosh( pi * sinh(t) / 2 );\nintegrand = @(t) f(x(t)) .* chain(t);\nsubplot(2, 1, 2)\nfplot(integrand, [-4, 4]);  set(gca, 'yscale', 'log') \nxlabel('t'), ylabel('f(x(t))'),  ylim([1e-20, 1])  \ntitle('Transformed integrand')\n\nThis graph suggests that we capture all of the integrand values that are larger than machine epsilon by integrating in t from -4 to 4.\n\nExample 9.7.3\n\nf = @(x) 1 ./ (1 + x.^2);\ntol = 1 ./ 10.^(5:0.5:14);\nerr = zeros(length(tol), 2);\nlen = zeros(length(tol), 2);\nfor k = 1:length(tol)\n    [I1, x1] = intadapt(f, -2/tol(k), 2/tol(k), tol(k));\n    [I2, x2] = intinf(f, tol(k));\n    err(k, :) = abs(pi - [I1, I2]);\n    len(k, :) = [length(x1), length(x2)];\nend\nclf,  loglog(len, err, 'o-')   \nn = [100, 10000];\nhold on,  loglog(n, 1000 * n.^(-4), 'k--')  % 4th order error\nlegend(\"direct\", \"double exponential\", \"4th order\", location=\"southwest\")\ntitle((\"Comparison of integration methods\"));\n\nBoth methods are roughly fourth-order due to Simpson’s formula in the underlying adaptive integration method. At equal numbers of evaluation nodes, however, the double exponential method is consistently 2–3 orders of magnitude more accurate.\n\nExample 9.7.4\n\nf = @(x) 1 ./ (10 * sqrt(x));\ntol = 1 ./ 10.^(5:0.5:14);\nerr = zeros(length(tol), 2);\nlen = zeros(length(tol), 2);\nfor k = 1:length(tol)\n    [I1, x1] = intadapt(f, (tol(k)/20)^2, 1, tol(k));\n    [I2, x2] = intsing(f, tol(k));\n    err(k, :) = abs(0.2 - [I1, I2]);\n    len(k, :) = [length(x1), length(x2)];\nend\nclf,  loglog(len, err, 'o-')   \nn = [30, 3000];\nhold on,  loglog(n, 30 * n.^(-4), 'k--')  % 4th order error\nlegend(\"direct\", \"double exponential\", \"4th order\", location=\"southwest\")\ntitle((\"Comparison of integration methods\"));\n\nAs in \n\nDemo 9.7.3, the double exponential method is more accurate than direct integration by a few orders of magnitude. Equivalently, the same accuracy can be reached with many fewer nodes.","type":"content","url":"/chapter9-1#id-9-7","position":19},{"hierarchy":{"lvl1":"MATLAB setup"},"type":"lvl1","url":"/setup-1","position":0},{"hierarchy":{"lvl1":"MATLAB setup"},"content":"","type":"content","url":"/setup-1","position":1},{"hierarchy":{"lvl1":"MATLAB setup","lvl2":"Setting up MATLAB for this book"},"type":"lvl2","url":"/setup-1#section-setup-matlab","position":2},{"hierarchy":{"lvl1":"MATLAB setup","lvl2":"Setting up MATLAB for this book"},"content":"The book relies only on base MATLAB (no Toolboxes). The code requires MATLAB R2023b or later.","type":"content","url":"/setup-1#section-setup-matlab","position":3},{"hierarchy":{"lvl1":"MATLAB setup","lvl3":"Installation","lvl2":"Setting up MATLAB for this book"},"type":"lvl3","url":"/setup-1#installation","position":4},{"hierarchy":{"lvl1":"MATLAB setup","lvl3":"Installation","lvl2":"Setting up MATLAB for this book"},"content":"Download the \n\nlatest release and unpack somewhere on your computer. Add the FNC-matlab directory to your MATLAB path. By typing addpath /path/to/FNC-matlab at the MATLAB prompt, or by typing pathtool and using the GUI. The pathtool method allows you to save the path for all future MATLAB sessions.","type":"content","url":"/setup-1#installation","position":5},{"hierarchy":{"lvl1":"Chapter 1"},"type":"lvl1","url":"/chapter1-2","position":0},{"hierarchy":{"lvl1":"Chapter 1"},"content":"","type":"content","url":"/chapter1-2","position":1},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"type":"lvl2","url":"/chapter1-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Functions"},"content":"Horner’s algorithm for evaluating a polynomial\n\ndef horner(c,x):\n    \"\"\"\n    horner(c,x)\n\n    Evaluate a polynomial whose coefficients are given in descending order \n    in c, at the point x, using Horner's rule.\n    \"\"\"\n    n = len(c)\n    y = c[0]\n    for k in range(1, n):\n        y = x * y + c[k]   \n    return y","type":"content","url":"/chapter1-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"type":"lvl2","url":"/chapter1-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter1-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"1.1 Floating-point numbers"},"type":"lvl2","url":"/chapter1-2#id-1-1","position":6},{"hierarchy":{"lvl1":"Chapter 1","lvl2":"1.1 Floating-point numbers"},"content":"Example 1.1.2\n\nGetting started with Python\n\nSee \n\nSetting up Python for this book for guidance on how to set up Python for the demos in this book.\n\nRecall the grade-school approximation to the number π.\n\np = 22/7\nprint(p)\n\nNot all the digits displayed for p are the same as those of π.\n\nTip\n\nThe value of pi is predefined in the numpy package.\n\nprint(pi)\n\nThe absolute and relative accuracies of the approximation are as follows:\n\nTip\n\nWe often use \n\nPython f-strings to format numerical output.\n\nprint(f\"absolute accuracy: {abs(p - pi)}\")\n\nrel_acc = abs(p - pi) / pi\nprint(\"relative accuracy: {rel_acc:.4e}\")\n\nHere we calculate the number of accurate digits in p:\n\nTip\n\nThe log function is for the natural log. For other common bases, use log10 or log2.\n\nprint(f\"accurate digits: {-log10(rel_acc):.1f}\")\n\nExample 1.1.3\n\nPython has native int and float types.\n\nprint(f\"The type of {1} is {type(1)}\")\nprint(f\"The type of {float(1)} is {type(1.0)}\")\n\nThe numpy package has its own float types:\n\none = float64(1)\nprint(f\"The type of {one} is {type(one)}\")\n\nBoth float and float64 are double precision, using 64 binary bits per value. Although it is not normally necessary to do so, we can deconstruct a float into its significand and exponent:\n\nx = 3.14\nmantissa, exponent = frexp(x)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nmantissa, exponent = frexp(x / 8)\nprint(f\"significand: {mantissa * 2}, exponent: {exponent - 1}\")\n\nThe spacing between floating-point values in [2^n,2^{n+1}) is 2^n \\epsilon_\\text{mach}, where \\epsilon_\\text{mach} is machine epsilon, given here for double precision:\n\nmach_eps = finfo(float).eps\nprint(f\"machine epsilon is {mach_eps:.4e}\")\n\nBecause double precision allocates 52 bits to the significand, the default value of machine epsilon is \n\n2-52.\n\nprint(f\"machine epsilon is 2 to the power {log2(mach_eps)}\")\n\nA common mistake is to think that \\epsilon_\\text{mach} is the smallest floating-point number. It’s only the smallest relative to 1. The correct perspective is that the scaling of values is limited by the exponent, not the significand. The actual range of positive values in double precision is\n\nfinf = finfo(float)\nprint(f\"range of positive values: [{finf.tiny}, {finf.max}]\")\n\nFor the most part you can mix integers and floating-point values and get what you expect.\n\n1/7\n\n37.3 + 1\n\n2**(-4)\n\nYou can convert a floating value to an integer by wrapping it in int.\n\nint(3.14)\n\nExample 1.1.4\n\nThere is no double precision number between 1 and 1+\\varepsilon_\\text{mach}. Thus, the following difference is zero despite its appearance.\n\neps = finfo(float).eps\ne = eps/2\nprint((1.0 + e) - 1.0)\n\nHowever, 1-\\varepsilon_\\text{mach}/2 is a double precision number, so it and its negative are represented exactly:\n\nprint(1.0 + (e - 1.0))\n\nThis is now the “correct” result. But we have found a rather shocking breakdown of the associative law of addition!","type":"content","url":"/chapter1-2#id-1-1","position":7},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.2 Problems and conditioning","lvl2":"1.1 Floating-point numbers"},"type":"lvl3","url":"/chapter1-2#id-1-2","position":8},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.2 Problems and conditioning","lvl2":"1.1 Floating-point numbers"},"content":"Example 1.2.5\n\nThe polynomial p(x) = \\frac{1}{3}(x-1)(x-1-\\epsilon) has roots 1 and 1+\\epsilon. For small values of ε, the roots are ill-conditioned.\n\nTip\n\nThe statement x, y = 10, 20 makes individual assignments to both x and y.\n\nep = 1e-6   \na, b, c = 1/3, (-2 - ep) / 3, (1 + ep) / 3   # coefficients of p\n\nHere are the roots as computed by the quadratic formula.\n\nd = sqrt(b**2 - 4*a*c)\nr1 = (-b - d) / (2*a)\nr2 = (-b + d) / (2*a)\nprint(r1, r2)\n\nThe display of r2 suggests that the last five digits or so are inaccurate. The relative error in the value is\n\nprint(abs(r1 - 1) / abs(1))\nprint(abs(r2 - (1 + ep)) / abs(1 + ep))\n\nThe condition number of each root is\\kappa(r_i) = \\frac{|r_i|}{|r_1-r_2|} \\approx \\frac{1}{\\epsilon}.\n\nThus, relative error in the data at the level of roundoff can grow in the result to be roughly\n\nprint(finfo(float).eps / ep)\n\nThis matches the observation pretty well.","type":"content","url":"/chapter1-2#id-1-2","position":9},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.3 Algorithms","lvl2":"1.1 Floating-point numbers"},"type":"lvl3","url":"/chapter1-2#id-1-3","position":10},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.3 Algorithms","lvl2":"1.1 Floating-point numbers"},"content":"Example 1.3.2\n\nHere we show how to use horner to evaluate a polynomial. First, we have to ensure that the book’s package is imported.\n\nimport fncbook as FNC\n\nHere is the help string for the function:\n\nhelp(FNC.horner)\n\nWe now define a vector of the coefficients of p(x)=(x−1)^3=x^3−3x^2+3x−1, in descending degree order. Note that the textbook’s functions are all in a namespace called FNC, to help distinguish them from other Python commands and modules.\n\nc = array([1, -3, 3, -1])\nprint(FNC.horner(c, 1.6))\n\nThe above is the value of p(1.6), up to a rounding error.","type":"content","url":"/chapter1-2#id-1-3","position":11},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.4 Stability","lvl2":"1.1 Floating-point numbers"},"type":"lvl3","url":"/chapter1-2#id-1-4","position":12},{"hierarchy":{"lvl1":"Chapter 1","lvl3":"1.4 Stability","lvl2":"1.1 Floating-point numbers"},"content":"Example 1.4.1\n\nWe apply the quadratic formula to find the roots of a quadratic via \n\n(1.4.1).\n\nTip\n\nA number in scientific notation is entered as 1.23e4 rather than as 1.23*10^{4}.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\nx2 = (-b - sqrt(b**2 - 4*a*c)) / 2*a\nprint(x1, x2)\n\nThe first value is correct to all stored digits, but the second has fewer than six accurate digits:\n\nerror = abs(1e-6 - x2) / 1e-6 \nprint(f\"There are {-log10(error):.2f} accurate digits.\")\n\nThe instability is easily explained. Since a=c=1, we treat them as exact numbers. First, we compute the condition numbers with respect to b for each elementary step in finding the “good” root:\n\nCalculation\n\nResult\n\nκ\n\nu_1 = b^2\n\n1.000000000002000\\times 10^{12}\n\n2\n\nu_2 = u_1 - 4\n\n9.999999999980000\\times 10^{11}\n\n\\approx 1.00\n\nu_3 = \\sqrt{u_2}\n\n999999.9999990000\n\n1/2\n\nu_4 = u_3 - b\n\n2000000\n\n\\approx 0.500\n\nu_5 = u_4/2\n\n1000000\n\n1\n\nUsing \n\n(1.2.9), the chain rule for condition numbers, the conditioning of the entire chain is the product of the individual steps, so there is essentially no growth of relative error here. However, if we use the quadratic formula for the “bad” root, the next-to-last step becomes u_4=(-u_3) - b, and now  \\kappa=|u_3|/|u_4|\\approx 5\\times 10^{11}. So we can expect to lose 11 digits of accuracy, which is what we observed. The key issue is the subtractive cancellation in this one step.\n\nExample 1.4.2\n\nWe repeat the rootfinding experiment of \n\nDemo 1.4.1 with an alternative algorithm.\n\na = 1;  b = -(1e6 + 1e-6);  c = 1;\n\nFirst, we find the “good” root using the quadratic formula.\n\nx1 = (-b + sqrt(b**2 - 4*a*c)) / 2*a\n\nThen we use the identity x_1x_2=\\frac{c}{a} to compute the smaller root:\n\nx2 = c / (a * x1)\nprint(x1, x2)\n\nTo be sure we have an accurate result, we compute its relative error.\n\nprint(abs(x2 - 1e-6) / 1e-6)\n\nExample 1.4.3\n\nOur first step is to construct a polynomial with six known roots.\n\nr = [-2, -1, 1, 1, 3, 6]\np = poly(r)\nprint(p)\n\nNow we use a standard numerical method for finding those roots, pretending that we don’t know them already. This corresponds to \\tilde{y} in \n\nDefinition 1.4.1.\n\nr_computed = sort(roots(p))\nprint(r_computed)\n\nHere are the relative errors in each of the computed roots.\n\nprint(abs(r - r_computed) / r)\n\nIt seems that the forward error is acceptably close to machine epsilon for double precision in all cases except the double root at x=1. This is not a surprise, though, given the poor conditioning at such roots.\n\nLet’s consider the backward error. The data in the rootfinding problem is the polynomial coefficients. We can apply poly to find the coefficients of the polynomial (that is, the data) whose roots were actually computed by the numerical algorithm. This corresponds to \\tilde{x} in \n\nDefinition 1.4.1.\n\np_computed = poly(r_computed)\nprint(p_computed)\n\nWe find that in a relative sense, these coefficients are very close to those of the original, exact polynomial:\n\nprint(abs(p - p_computed) / p)\n\nIn summary, even though there are some computed roots relatively far from their correct values, they are nevertheless the roots of a polynomial that is very close to the original.","type":"content","url":"/chapter1-2#id-1-4","position":13},{"hierarchy":{"lvl1":"Chapter 10"},"type":"lvl1","url":"/chapter10-2","position":0},{"hierarchy":{"lvl1":"Chapter 10"},"content":"","type":"content","url":"/chapter10-2","position":1},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Functions"},"type":"lvl2","url":"/chapter10-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Functions"},"content":"Shooting method for a two-point boundary-value problem\n\ndef shoot(phi, a, b, ga, gb, init):\n    \"\"\"\n    shoot(phi, a, b, ga, gb, init)\n\n    Use the shooting method to solve a two-point boundary value problem. \n    The ODE is u'' = phi(x, u, u') for x in (a,b). The functions \n    ga(u(a), u'(a)) and gb(u(b), u'(b)) specify the boundary conditions. \n    The value init is an initial guess for [u(a), u'(a)].\n\n    Return vectors for the nodes, the values of u, and the values of u'.\n    \"\"\"\n\n    # Tolerances for IVP solver and rootfinder.\n    tol = 1e-5\n    # To be solved by the IVP solver\n    def shootivp(x, y):\n        return np.array([y[1], phi(x, y[0], y[1])])\n\n    # Evaluate the difference between computed and target values at x=b.\n    def objective(s):\n        nonlocal x, y  # change these values in outer scope\n\n        x = np.linspace(a, b, 400)  # make decent plots on return\n        sol = solve_ivp(shootivp, [a, b], s, atol=tol/10, rtol=tol/10, t_eval=x)\n        x = sol.t\n        y = sol.y\n        residual = np.array([ga(y[0, 0], y[1, 0]), gb(y[0, -1], y[0, -1])])\n        return residual\n\n    # Find the unknown quantity at x=a by rootfinding.\n    x, y = [], []    # the values will be overwritten\n    s = levenberg(objective, init, tol)\n\n    # Don't need to solve the IVP again. It was done within the\n    # objective function already.\n    u = y[0]        # solution\n    du_dx = y[1]    # derivative\n\n    return x, u, du_dx\n\nSecond-order differentiation matrices\n\ndef diffmat2(n, xspan):\n    \"\"\"\n    diffmat2(n, xspan)\n\n    Compute 2nd-order-accurate differentiation matrices on n+1 points in the\n    interval xspan. Return a vector of nodes, and the matrices for the first\n    and second derivatives.\n    \"\"\"\n    a, b = xspan\n    h = (b - a) / n\n    x = np.linspace(a, b, n + 1)  # nodes\n\n    # Define most of Dx by its diagonals.\n    dp = 0.5 / h * np.ones(n)  # superdiagonal\n    dm = -0.5 / h * np.ones(n)  # subdiagonal\n    Dx = np.diag(dm, -1) + np.diag(dp, 1)\n\n    # Fix first and last rows.\n    Dx[0, :3] = np.array([-1.5, 2, -0.5]) / h\n    Dx[-1, -3:] = np.array([0.5, -2, 1.5]) / h\n\n    # Define most of Dxx by its diagonals.\n    d0 = -2 / h**2 * np.ones(n + 1)  # main diagonal\n    dp = np.ones(n) / h**2  # superdiagonal and subdiagonal\n    Dxx = np.diag(d0, 0) + np.diag(dp, -1) + np.diag(dp, 1)\n\n    # Fix first and last rows.\n    Dxx[0, :4] = np.array([2, -5, 4, -1]) / h**2\n    Dxx[-1, -4:] = np.array([-1, 4, -5, 2]) / h**2\n\n    return x, Dx, Dxx\n\nChebyshev differentiation matrices\n\ndef diffcheb(n, xspan):\n    \"\"\"\n    diffcheb(n, xspan)\n\n    Compute Chebyshev differentiation matrices on n+1 points in the\n    interval xspan. Return a vector of nodes, and the matrices for the first\n    and second derivatives.\n    \"\"\"\n    x = -np.cos(np.arange(n + 1) * np.pi / n)  # nodes in [-1,1]\n    Dx = np.zeros([n + 1, n + 1])\n    c = np.hstack([2.0, np.ones(n - 1), 2.0])  # endpoint factors\n\n    # Off-diagonal entries\n    Dx = np.zeros([n + 1, n + 1])\n    for i in range(n + 1):\n        for j in range(n + 1):\n            if i != j:\n                Dx[i, j] = (-1) ** (i + j) * c[i] / (c[j] * (x[i] - x[j]))\n\n    # Diagonal entries by the \"negative sum trick\"\n    for i in range(n + 1):\n        Dx[i, i] = -np.sum([Dx[i, j] for j in range(n + 1) if j != i])\n\n    # Transplant to [a,b]\n    a, b = xspan\n    x = a + (b - a) * (x + 1) / 2\n    Dx = 2 * Dx / (b - a)\n\n    # Second derivative\n    Dxx = Dx @ Dx\n\n    return x, Dx, Dxx\n\nSolution of a linear boundary-value problem\n\ndef bvplin(p, q, r, xspan, lval, rval, n):\n    \"\"\"\n        bvplin(p, q, r, xspan, lval, rval, n)\n\n    Use finite differences to solve a linear bopundary value problem. The ODE is\n    u''+p(x)u'+q(x)u = r(x) on the interval xspan, with endpoint function\n    values given as lval and rval. There will be n+1 equally spaced nodes,\n    including the endpoints.\n\n    Return vectors of the nodes and the solution values.\n    \"\"\"\n    x, Dx, Dxx = diffmat2(n, xspan)\n\n    P = np.diag(p(x))\n    Q = np.diag(q(x))\n    L = Dxx + P @ Dx + Q  # ODE expressed at the nodes\n\n    # Replace first and last rows using boundary conditions.\n    I = np.eye(n + 1)\n    A = np.vstack([I[0], L[1:-1], I[-1]])\n    b = np.hstack([lval, r(x[1:-1]), rval])\n\n    # Solve the system.\n    u = np.linalg.solve(A, b)\n\n    return x, u\n\nAbout the code\n\nNote that there is no need to explicitly form the row-deletion matrix \\mathbf{E} from \n\n(10.4.8). Since it only appears as left-multiplying \\mathbf{L} or \\mathbf{r}, we simply perform the row deletions as needed using indexing.\n\nSolution of a nonlinear boundary-value problem\n\ndef bvp(phi, xspan, ga, gb, init):\n    \"\"\"\n    bvp(phi, xspan, ga, gb, init)\n\n    Use finite differences to solve a two-point boundary value problem. \n    The ODE is u'' = phi(x, u, u') for x in (a,b). The functions \n    ga(u(a), u'(a)) and gb(u(b), u'(b)) specify the boundary conditions. \n    The value init is an initial guess for [u(a), u'(a)].\n\n    Return vectors for the nodes and the values of u.\n    \"\"\"\n    n = len(init) - 1\n    x, Dx, Dxx = diffmat2(n, xspan)\n    h = x[1] - x[0]\n    def residual(u):\n        # Compute the difference between u'' and phi(x,u,u') at the\n        # interior nodes and appends the error at the boundaries.\n        du_dx = Dx @ u  # discrete u'\n        d2u_dx2 = Dxx @ u  # discrete u''\n        f = d2u_dx2 - phi(x, u, du_dx)\n\n        # Replace first and last values by boundary conditions.\n        f[0] = ga(u[0], du_dx[0]) / h\n        f[n] = gb(u[n], du_dx[n]) / h\n        return f\n\n    u = levenberg(residual, init.copy())\n    return x, u[-1]\n\nAbout the code\n\nThe nested function residual uses differentiation matrices computed externally to it, rather than computing them anew on each invocation. As in \n\nFunction 10.4.1, there is no need to form the row-deletion matrix \\mathbf{E} explicitly. In lines 23--24, we divide the values of g_1 and g_2 by a factor of h. This helps scale the residual components more uniformly and improves the robustness of convergence a bit.\n\nPiecewise linear finite elements for a linear BVP\n\ndef fem(c, s, f, a, b, n):\n    \"\"\"\n    fem(c, s, f, a, b, n)\n\n    Use a piecewise linear finite element method to solve a two-point boundary\n    value problem. The ODE is (c(x)u')' + s(x)u = f(x) on the interval\n    [a,b], and the boundary values are zero. The discretization uses n equal\n    subintervals.\n\n    Return vectors for the nodes and the values of u.\n    \"\"\"\n    # Define the grid.\n    h = (b - a) / n\n    x = np.linspace(a, b, n + 1)\n\n    # Templates for the subinterval matrix and vector contributions.\n    Ke = np.array([[1, -1], [-1, 1]])\n    Me = (1 / 6) * np.array([[2, 1], [1, 2]])\n    fe = (1 / 2) * np.array([1, 1])\n\n    # Evaluate coefficent functions and find average values.\n    cval = c(x)\n    cbar = (cval[:-1] + cval[1:]) / 2\n    sval = s(x)\n    sbar = (sval[:-1] + sval[1:]) / 2\n    fval = f(x)\n    fbar = (fval[:-1] + fval[1:]) / 2\n\n    # Assemble global system, one interval at a time.\n    K = np.zeros([n - 1, n - 1])\n    M = np.zeros([n - 1, n - 1])\n    f = np.zeros(n - 1)\n    K[0, 0] = cbar[0] / h\n    M[0, 0] = sbar[0] * h / 3\n    f[0] = fbar[0] * h / 2\n    K[-1, -1] = cbar[-1] / h\n    M[-1, -1] = sbar[-1] * h / 3\n    f[-1] = fbar[-1] * h / 2\n    for k in range(1, n - 1):\n        K[k - 1 : k + 1, k - 1 : k + 1] += (cbar[k] / h) * Ke\n        M[k - 1 : k + 1, k - 1 : k + 1] += (sbar[k] * h) * Me\n        f[k - 1 : k + 1] += (fbar[k] * h) * fe\n\n    # Solve system for the interior values.\n    u = np.linalg.solve(K + M, f)\n    u = np.hstack([0, u, 0])  # put the boundary values into the result\n\n    return x, u","type":"content","url":"/chapter10-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Examples"},"type":"lvl2","url":"/chapter10-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 10","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter10-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.1 Two-point BVP","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-2#id-10-1","position":6},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.1 Two-point BVP","lvl2":"Examples"},"content":"Example 10.1.3\n\nTo solve this problem, we have to define functions for the ODE and boundary conditions. The first returns the computed values of y_1' and y_2'.\n\nlamb = 0.6\ndef ode(r, y):\n    return array([\n        y[1],\n        lamb / y[0]**2 - y[1] / r\n    ])\n\nTo encode the boundary conditions y_2(0)=0, y_1(2)=1, we define a function for their residual values.\n\ndef bc(ya, yb):    # given y(a), y(b)\n    return array([\n        ya[1],\n        yb[0] - 1\n    ])\n\nThe domain of the mathematical problem is r\\in [0,1]. However, there is a division by r in the ODE, so we want to avoid r=0 by truncating the domain a bit.\n\na, b = finfo(float).eps, 1\n\nWe need one last ingredient that is not part of the mathematical setup: an initial estimate for the solution. As we will see, this plays the same role as initialization in Newton’s method for rootfinding. Here, we try a constant value for each component.\n\nr = linspace(a, b, 50)\ny_init = vstack([ones(r.size), zeros(r.size)])\n\nNow we can solve the problem using solve_bvp from scipy.integrate.\n\nfrom scipy.integrate import solve_bvp\nsol = solve_bvp(ode, bc, r, y_init)\nprint(f\"Solved at {sol.x.size} nodes.\")\nplot(sol.x, sol.y[0])\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\")\ntitle(\"Solution of MEMS problem for $\\\\lambda=0.6$\");","type":"content","url":"/chapter10-2#id-10-1","position":7},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.2 Shooting","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-2#id-10-2","position":8},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.2 Shooting","lvl2":"Examples"},"content":"Example 10.2.1\n\nLet’s first examine the shooting approach for the TPBVP from \n\nExample 10.1.2 with \\lambda=0.6.\n\nlamb = 0.6\nphi = lambda r, w, dw_dr: lamb / w**2 - dw_dr / r\n\nWe convert the ODE to a first-order system in order to apply a numerical method. We also have to truncate the domain to avoid division by zero.\n\nf = lambda r, y: hstack([y[1], phi(r, y[0], y[1])])\na, b = finfo(float).eps, 1\n\nThe BVP specifies w'(0)=y_2(0)=0. We can try multiple values for the unknown w(0)=y_1(0) and plot the solutions.\n\nfrom scipy.integrate import solve_ivp\nt = linspace(a, b, 400)\nfor w0 in arange(0.4, 1.0, 0.1):\n    sol = solve_ivp(f, [a, b], [w0, 0], t_eval=t)\n    plot(t, sol.y[0], label=f\"$w_0$ = {w0:.1f}\")\n\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\")\nlegend(),  grid(True)\ntitle(\"Solutions for choices of w(0)\");\n\nOn the graph, it’s the curve starting at w(0)=0.8 that comes closest to the required condition w(1)=1, but it’s a bit too large.\n\nExample 10.2.2\n\nWe revisit \n\nDemo 10.2.1 but let \n\nFunction 10.2.1 do the heavy lifting.\n\nlamb = 0.6\nphi = lambda r, w, dwdr: lamb / w**2 - dwdr / r\na, b = finfo(float).eps, 1\n\nWe specify the given and unknown endpoint values.\n\nga = lambda w, dw : dw       # w'=0 at left\ngb = lambda w, dw : w - 1    # w=1 at right\n\nIn this setting, we need to provide initial guesses for w(a) and w'(a).\n\ninit = array([0.8, 0])\nr, w, dw_dx = FNC.shoot(phi, a, b, ga, gb, init)\nplot(r, w)\ntitle(\"Shooting solution\")\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\");\n\nThe value of w at r=1, meant to be exactly one, was computed to be\n\nprint(f\"w at right end is {w[-1]}\")\n\nThe accuracy is consistent with the error tolerance used for the IVP solution by shoot. The initial value w(0) that gave this solution is\n\nprint(f\"w at left end is {w[0]}\")\n\nExample 10.2.3\n\nga = lambda u, du : u + 1    # u=-1 at left\ngb = lambda u, du : u        # u= 0 at right\ninit = array([-1, 0])\nfor lamb in range(6, 22, 4):\n    phi = lambda x, u, du_dx: lamb**2 * u + lamb**2\n    x, u, du_dx = FNC.shoot(phi, 0.0, 1.0, ga, gb, init)\n    plot(x, u, label=f\"$\\\\lambda$ = {lamb:.1f}\")\n\nxlabel(\"$x$\"),  ylabel(\"$u(x)$\"),  ylim(-1.0, 0.25)\ngrid(True),  legend(loc=\"upper left\")\ntitle(\"Shooting instability\");\n\nThe numerical solutions evidently don’t satisfy the right boundary condition as λ increases, which makes them invalid.","type":"content","url":"/chapter10-2#id-10-2","position":9},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.3 Differentiation matrices","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-2#id-10-3","position":10},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.3 Differentiation matrices","lvl2":"Examples"},"content":"Example 10.3.1\n\nWe test first-order and second-order differentiation matrices for the function x + \\exp(\\sin 4x) over [-1,1].\n\nf = lambda x: x + exp( sin(4 * x) )\n\nFor reference, here are the exact first and second derivatives.\n\ndf_dx = lambda x: 1 + 4 * exp(sin(4 * x)) * cos(4 * x)\nd2f_dx2 = lambda x: 4 * exp(sin(4 * x)) * (4 * cos(4 * x)**2 - 4 * sin(4 * x))\n\nWe discretize on equally spaced nodes and evaluate f at the nodes.\n\nt, Dx, Dxx = FNC.diffmat2(12, [-1, 1])\ny = f(t)\n\nThen the first two derivatives of f each require one matrix-vector multiplication.\n\nyx = Dx @ y\nyxx = Dxx @ y\n\nThe results show poor accuracy for this small value of n.\n\nx = linspace(-1, 1, 500)\nsubplot(2, 1, 1)\nplot(x, df_dx(x))\nplot(t, yx, \"ko\")\nxlabel(\"$x$\"),  ylabel(\"$f'(x)$\")\n\nsubplot(2, 1, 2)\nplot(x, d2f_dx2(x))\nplot(t, yxx, \"ko\")\nxlabel(\"$x$\"),  ylabel(\"$f''(x)$\");\n\nA convergence experiment confirms the order of accuracy. Because we expect an algebraic convergence rate, we use a log-log plot of the errors.\n\nN = array([int(2**k) for k in arange(4, 11.5, 0.5)])\nerr1 = zeros(len(N))\nerr2 = zeros(len(N))\nfor k, n in enumerate(N):\n    t, Dx, Dxx = FNC.diffmat2(n, [-1, 1])\n    y = f(t)\n    err1[k] = norm(df_dx(t) - Dx @ y, inf)\n    err2[k] = norm(d2f_dx2(t) - Dxx @ y, inf)\n\nloglog(N, err1, \"-o\", label=\"$f'$\")\nloglog(N, err2, \"-o\", label=\"$f''$\")\nplot(N, 10 * 10 / N**2, \"k--\", label=\"2nd order\")\nxlabel(\"$n$\"),  ylabel(\"max error\")\nlegend(loc=\"lower left\")\ntitle(\"Convergence of finite differences\");\n\nExample 10.3.2\n\nHere is a 4\\times 4 Chebyshev differentiation matrix.\n\nt, Dx, Dxx = FNC.diffcheb(3, [-1, 1])\nprint(Dx)\n\nWe again test the convergence rate.\n\nf = lambda x: x + exp(sin(4 * x))\ndf_dx = lambda x: 1 + 4 * exp(sin(4 * x)) * cos(4 * x)\nd2f_dx2 = lambda x: 4 * exp(sin(4 * x)) * (4 * cos(4 * x) ** 2 - 4 * sin(4 * x))\n\nN = range(5, 75, 5)\nerr1 = zeros(len(N))\nerr2 = zeros(len(N))\nerr = zeros((len(N), 2))\nfor k, n in enumerate(N):\n    t, Dx, Dxx = FNC.diffcheb(n, [-1, 1])\n    y = f(t)\n    err[k, 0] = norm(df_dx(t) - Dx @ y, inf)\n    err[k, 1] = norm(d2f_dx2(t) - Dxx @ y, inf)\n\nSince we expect a spectral convergence rate, we use a semi-log plot for the error.\n\nsemilogy(N, err, \"-o\")\nxlabel(\"$n$\"), ylabel(\"max error\")\nlegend([\"$f'$\", \"$f''$\"], loc=\"lower left\")\ntitle(\"Convergence of Chebyshev derivatives\");","type":"content","url":"/chapter10-2#id-10-3","position":11},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.4 Collocation for linear problems","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-2#id-10-4","position":12},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.4 Collocation for linear problems","lvl2":"Examples"},"content":"Example 10.4.1\n\nexact = lambda x: exp( sin(x) )\n\nThe problem is presented above in our standard form, so we can identify the coefficient functions in the ODE. Each should be coded as a function.\n\np = lambda x: -cos(x)\nq = sin\nr = lambda x: 0 * x    # must be a function\n\nWe solve the BVP and compare the result to the exact solution.\n\nx, u = FNC.bvplin(p, q, r, [0, pi/2], 1, exp(1), 25)\n\nsubplot(2, 1, 1)\nplot(x, u)\nylabel(\"solution\"),  title(\"Solution of the BVP\")\n\nsubplot(2, 1, 2)\nplot(x, exact(x) - u, \"-o\")\nylabel(\"error\");\n\nExample 10.4.2\n\nlamb = 10\nexact = lambda x: sinh(lamb * x) / sinh(lamb) - 1\n\nThe following functions define the ODE.\n\np = lambda x: zeros(size(x))\nq = lambda x: -(lamb**2) * ones(len(x))\nr = lambda x: lamb**2 * ones(len(x))\n\nWe compare the computed solution to the exact one for increasing n.\n\nN = array([int(2 * 10**d) for d in arange(1, 3.1, 0.25)])\nerr = zeros(len(N))\nresults = PrettyTable([\"n\", \"error\"])\nfor k, n in enumerate(N):\n    x, u = FNC.bvplin(p, q, r, [0, 1], -1, 0, n)\n    err[k] = norm(exact(x) - u, inf)\n    results.add_row([n, err[k]])\nprint(results)\n\nEach factor of 10 in n reduces error by a factor of 100, which is indicative of second-order convergence.\n\nloglog(N, err, \"-o\", label=\"observed\")\nloglog(N, 1 / N**2, \"--\", label=\"2nd order\")\nxlabel(\"$n$\"),  ylabel(\"max error\")\nlegend(),  title(\"Convergence of finite differences\");","type":"content","url":"/chapter10-2#id-10-4","position":13},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.5 Nonlinearity and boundary conditions","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-2#id-10-5","position":14},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.5 Nonlinearity and boundary conditions","lvl2":"Examples"},"content":"Example 10.5.2\n\nThe first step is to define the function ϕ that equals \\theta''.\n\nphi = lambda t, theta, omega: -0.05 * omega - sin(theta)\n\nNext, we define the boundary conditions.\n\nga = lambda u, du: u - 2.5\ngb = lambda u, du: u + 2\n\nThe last ingredient is an initial estimate of the solution. Here we choose n=100 and a linear function between the endpoint values.\n\ninit = linspace(2.5, -2, 101)\n\nWe find a solution with negative initial slope, i.e., the pendulum is initially pushed back toward equilibrium.\n\nt, theta = FNC.bvp(phi, [0, 5], ga, gb, init)\nplot(t, theta)\nxlabel(\"$t$\")\nylabel(\"$\\theta(t)$\")\ntitle(\"Pendulum over [0,5]\");\n\nIf we extend the time interval longer for the same boundary values, then the initial slope must adjust.\n\nt, theta = FNC.bvp(phi, [0, 8], ga, gb, init)\nplot(t, theta)\nxlabel(\"$t$\")\nylabel(\"$\\theta(t)$\")\ntitle(\"Pendulum over [0,8]\");\n\nThis time, the pendulum is initially pushed toward the unstable equilibrium in the upright vertical position before gravity pulls it back down.\n\nExample 10.5.3\n\nHere is the problem definition. We use a truncated domain to avoid division by zero at r=0.\n\nlamb = 0.5\nphi = lambda r, w, dwdr: lamb / w**2 - dwdr / r\na, b = finfo(float).eps, 1\nga = lambda w, dw: dw\ngb = lambda w, dw: w - 1\n\nFirst we try a constant function as the initialization.\n\ninit = ones(201)\nr, w1 = FNC.bvp(phi, [a, b], ga, gb, init)\nplot(r, w1)\nfig, ax = gcf(), gca()\nxlabel(\"$r$\"),  ylabel(\"$w(r)$\")\ntitle(\"Solution of the MEMS problem\");\n\nIt’s not necessary that the initialization satisfy the boundary conditions. In fact, by choosing a different constant function as the initial guess, we arrive at another valid solution.\n\nr, w2 = FNC.bvp(phi, [a, b], ga, gb, 0.5 * init)\nax.plot(r, w2)\nax.set_title(\"Multiple solutions of the MEMS problem\");\nfig\n\nExample 10.5.4\n\nphi = lambda x, u, dudx: (u**3 - u) / epsilon\nga = lambda u, du: du\ngb = lambda u, du: u - 1\n\nFinding a solution is easy at larger values of ε.\n\nepsilon = 0.05\ninit = linspace(-1, 1, 141)\nx, u1 = FNC.bvp(phi, [0, 1], ga, gb, init)\n\nplot(x, u1, label=\"$\\\\epsilon = 0.05$\")\nfig, ax = gcf(), gca()\nxlabel(\"$x$\"),  ylabel(\"$u(x)$\")\nlegend(),  title(\"Allen-Cahn solution\");\n\nFinding a good initialization is not trivial for smaller values of ε. But the iteration succeeds if we use the first solution as the initialization at the smaller ε.\n\nepsilon = 0.002\nx, u2 = FNC.bvp(phi, [0, 1], ga, gb, u1)\nax.plot(x, u2, label=\"$\\\\epsilon = 0.002$\")\nax.legend()\nfig\n\nIn this case we can continue further.\n\nϵ = 0.0005\nx, u3 = FNC.bvp(phi, [0, 1], ga, gb, u2)\nax.plot(x, u3, label=\"$\\\\epsilon = 0.005$\")\nax.legend()\nfig","type":"content","url":"/chapter10-2#id-10-5","position":15},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.6 The Galerkin method","lvl2":"Examples"},"type":"lvl3","url":"/chapter10-2#id-10-6","position":16},{"hierarchy":{"lvl1":"Chapter 10","lvl3":"10.6 The Galerkin method","lvl2":"Examples"},"content":"Example 10.6.2\n\nHere are the coefficient function definitions. Even though s is a constant, it has to be defined as a function for \n\nFunction 10.6.1 to use it.\n\nc = lambda x: x**2\nq = lambda x: 4 * ones(len(x))\nf = lambda x: sin(pi * x)\n\nx, u = FNC.fem(c, q, f, 0, 1, 50)\nplot(x, u)\nxlabel(\"$x$\"),  ylabel(\"$u$\")\ntitle(\"Solution by finite elements\");","type":"content","url":"/chapter10-2#id-10-6","position":17},{"hierarchy":{"lvl1":"Chapter 11"},"type":"lvl1","url":"/chapter11-2","position":0},{"hierarchy":{"lvl1":"Chapter 11"},"content":"","type":"content","url":"/chapter11-2","position":1},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Functions"},"type":"lvl2","url":"/chapter11-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Functions"},"content":"Differentiation matrices for periodic end conditions\n\ndef diffper(n, xspan):\n    \"\"\"\n    diffper(n, xspan)\n\n    Construct 2nd-order differentiation matrices for functions with periodic end\n    conditions, using `n` unique nodes in the interval `xspan`. Return a vector of\n    nodes and the  matrices for the first and second derivatives.\n    \"\"\"\n    a, b = xspan\n    h = (b - a) / n\n    x = a + h * np.arange(n)  # nodes, omitting the repeated data\n\n    # Construct Dx by diagonals, then correct the corners.\n    dp = 0.5 / h * np.ones(n - 1)  # superdiagonal\n    dm = -0.5 / h * np.ones(n - 1)  # subdiagonal\n    Dx = np.diag(dm, -1) + np.diag(dp, 1)\n    Dx[0, -1] = -1 / (2 * h)\n    Dx[-1, 0] = 1 / (2 * h)\n\n    # Construct Dxx by diagonals, then correct the corners.\n    d0 = -2 / h**2 * np.ones(n)  # main diagonal\n    dp = np.ones(n - 1) / h**2  # superdiagonal and subdiagonal\n    Dxx = np.diag(d0) + np.diag(dp, -1) + np.diag(dp, 1)\n    Dxx[0, -1] = 1 / (h**2)\n    Dxx[-1, 0] = 1 / (h**2)\n\n    return x, Dx, Dxx\n\nSolution of parabolic PDEs by the method of lines\n\ndef parabolic(phi, xspan, m, ga, gb, tspan, init):\n    \"\"\"\n        parabolic(phi, xspan, m, ga, gb, tspan, init)\n\n    Solve a parabolic PDE by the method of lines. The PDE is \n    ∂u/∂t = phi(t,x,u,∂u/∂x,∂^2u/∂x^2), xspan gives the space \n    domain, m gives the degree of a Chebyshev spectral discretization, ga and gb are functions of (u,∂u/∂x) at the domain ends that should be made zero, tspan is the time domain, and init is a function of x that gives the initial condition. Returns a vector x and a function of t that gives the semidiscrete solution at x. \n    \"\"\"   \n    x, Dx, Dxx = diffcheb(m, xspan)\n    int = range(1, m)    # indexes of interior nodes\n\n    def extend(v):\n        def objective(ubc):\n            u0, um = ubc\n            ux = Dx @ np.hstack([u0, v, um])\n            return np.array([ga(u0, ux[1]), gb(um, ux[-1])])\n        ubc = levenberg(objective, np.array([0, 0]))[-1]\n        return np.hstack([ubc[0], v, ubc[-1]])\n\n    def ode(t, v):\n        u = extend(v)\n        ux, uxx = Dx @ u, Dxx @ u\n        return phi(t, x[int], u[int], ux[int], uxx[int])\n\n    u0 = init(x[int])\n    sol = solve_ivp(ode, tspan, u0, method=\"BDF\", dense_output=True)\n\n    return x, lambda t: extend(sol.sol(t))","type":"content","url":"/chapter11-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Examples"},"type":"lvl2","url":"/chapter11-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 11","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter11-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.1 Black–Scholes equation","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-2#id-11-1","position":6},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.1 Black–Scholes equation","lvl2":"Examples"},"content":"Example 11.1.2\n\nWe consider the Black–Scholes problem for the following parameter values:\n\nSmax, T = 8, 6\nK = 3\nsigma = 0.06\nr = 0.08\n\nWe discretize space and time.\n\nm = 200\nh = Smax / m\nx = h * arange(m+1)\nn = 1000\ntau = T / n\nt = tau * arange(n+1)\nlamb, mu = tau / h**2, tau / h\n\nWe set the initial condition and then march forward in time.\n\nV = zeros([m + 1, n + 1])\nV[:, 0] = maximum(0, x - K)\nfor j in range(n):\n    # Fictitious value from Neumann condition.\n    Vfict = 2 * h + V[m-1, j]\n    Vj = hstack([V[:, j], Vfict])\n    # First row is zero by the Dirichlet condition.\n    for i in range(1, m+1):\n        diff1 = Vj[i+1] - Vj[i-1]\n        diff2 = Vj[i+1] - 2 * Vj[i] + Vj[i-1]\n        V[i, j+1] = (\n            Vj[i]\n            + (lamb * sigma**2 * x[i] ** 2 / 2) * diff2\n            + (r * x[i] * mu) / 2 * diff1\n            - r * tau * Vj[i]\n        )\n\nHere is a plot of the solution after every 250 time steps.\n\nselect_times = 250 * arange(5)\nshow_times = t[select_times]\n\nfor j, col in enumerate(select_times):\n    plot(x, V[:, col], label=f\"t={show_times[j]:.1f}\")\n\nlegend()\nxlabel(\"stock price\"),  ylabel(\"option value\")\ntitle(\"Black-Scholes solution\");\n\nAlternatively, here is an animation of the solution.\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 8), ylim=(0, 6))\nax.grid()\nax.set_title(\"Black-Scholes solution\")\n\nline, = ax.plot([], [], '-', lw=2)\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(j):\n    line.set_data(x, V[:, j])\n    time_text.set_text(f\"t = {t[j]:.2f}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, n+1, 10), blit=True);\nanim.save(\"figures/black-scholes-6.mp4\", fps=30)\nclose()\n\nThe results are easy to interpret, recalling that the time variable really means time until strike. Say you are close to the option’s strike time. If the current stock price is, say, S=2, then it’s not likely that the stock will end up over the strike price K=3, and therefore the option has little value. On the other hand, if presently S=3, then there are good odds that the option will be exercised at the strike time, and you will need to pay a substantial portion of the stock price in order to take advantage. As the time to strike increases, there is an expectation that the stock price is more likely to rise somewhat, making the value of the option larger at each fixed S.\n\nExample 11.1.3\n\nLet’s try to do everything the same as in \n\nDemo 11.1.2, but extending the simulation time to T=8.\n\nT = 8\nn = 1000;  tau = T / n\nt = tau * arange(n + 1)\nlamb, mu = tau / h**2, tau / h\n\nV = zeros([m+1, n+1])\nV[:, 0] = maximum(0, x - K)\nfor j in range(n):\n    # Fictitious value from Neumann condition.\n    Vfict = 2 * h + V[m - 1, j]\n    Vj = hstack([V[:, j], Vfict])\n    # First row is zero by the Dirichlet condition.\n    for i in range(1, m + 1):\n        diff1 = Vj[i + 1] - Vj[i - 1]\n        diff2 = Vj[i + 1] - 2 * Vj[i] + Vj[i - 1]\n        V[i, j + 1] = (\n            Vj[i]\n            + (lamb * sigma**2 * x[i] ** 2 / 2) * diff2\n            + (r * x[i] * mu) / 2 * diff1\n            - r * tau * Vj[i]\n        )\n\nselect_times = 250 * arange(5)\nshow_times = t[select_times]\n\nfor j, col in enumerate(select_times):\n    plot(x, V[:, col], label=f\"t={show_times[j]:.1f}\")\n\nlegend()\nxlabel(\"stock price\")\nylim([0, 6]);  ylabel(\"option value\")\ntitle(\"Black-Scholes solution\");\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 8), ylim=(0, 6))\nax.grid()\nax.set_title(\"Black-Scholes solution...?\")\n\nline, = ax.plot([], [], '-', lw=2)\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(j):\n    line.set_data(x, V[:, j])\n    time_text.set_text(f\"t = {t[j]:.2f}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, n+1), blit=True);\nanim.save(\"figures/black-scholes-8.mp4\", fps=24)\nclose()\n\nThis so-called solution is nonsense!","type":"content","url":"/chapter11-2#id-11-1","position":7},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.2 The method of lines","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-2#id-11-2","position":8},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.2 The method of lines","lvl2":"Examples"},"content":"Example 11.2.2\n\nLet’s implement the method of \n\nExample 11.2.1 with second-order space semidiscretization.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1])\n\ntfinal = 0.15  \nn = 2400                 # number of time steps  \ntau = tfinal / n         # time step\nt = tau * arange(n+1)    # time values\n\nNext we set an initial condition. It isn’t mathematically periodic, but the end values and derivatives are so small that for numerical purposes it may as well be.\n\nU = zeros([m, n+1])\nU[:, 0] = exp(-60 * (x - 0.5) ** 2)\nplot(x, U[:, 0])\nxlabel(\"x\");  ylabel(\"u(x,0)\")\ntitle(\"Initial condition\");\n\nThe Euler time stepping simply multiplies the solution vector by the constant matrix in \n\n(11.2.6) at each time step. Since that matrix is sparse, we will declare it as such, even though the run-time savings may not be detectable for this small value of m.\n\nimport scipy.sparse as sp\nI = sp.eye(m)\nA = I + tau * sp.csr_array(Dxx)\nfor j in range(n):\n    U[:, j+1] = A @ U[:, j]\n\nplot(x, U[:, :31:10])\nylim([-0.25, 1])\nxlabel(\"$x$\");  ylabel(\"$u(x,t)$\")\nlegend([f\"$t={tj:.2e}$\" for tj in t[:60:20]])\ntitle(\"Heat equation by forward Euler\");\n\nYou see above that things seem to start well, with the initial peak widening and shrinking. But then there is a nonphysical growth in the solution.\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 1), ylim=(-1, 2))\nax.grid()\n\nline, = ax.plot([], [], '-', lw=2)\nax.set_title(\"Heat equation by forward Euler\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(j):\n    line.set_data(x, U[:, j])\n    time_text.set_text(f\"t = {t[j]:.2e}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, 100), blit=True)\nanim.save(\"figures/diffusionFE.mp4\", fps=24)\nclose()\n\nThe growth in norm is exponential in time.\n\nM = abs(U).max(axis=0)  # max in each column\nsemilogy(t[:500], M[:500])\nxlabel(\"$t$\");  ylabel(\"$\\\\max_x |u(x,t)|$\")\ntitle(\"Nonphysical growth\");\n\nExample 11.2.4\n\nNow we apply backward Euler to the heat equation. Mathematically this means multiplying by the inverse of a matrix, but we interpret that numerically as a linear system solution. We will reuse the setup from \n\nDemo 11.2.2.\n\nfrom scipy.sparse.linalg import spsolve\nB = sp.csr_matrix(I - tau * Dxx)\nfor j in range(n):\n    U[:, j + 1] = spsolve(B, U[:, j])\n\nplot(x, U[:, ::500])\nxlabel(\"$x$\")\nylabel(\"$u(x,t)$\")\nlegend([f\"$t={tj:.2g}$\" for tj in t[::500]])\ntitle(\"Heat equation by backward Euler\");\n\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 1), ylim=(-0.25, 1))\nax.grid()\n\nline, = ax.plot([], [], '-', lw=2)\nax.set_title(\"Backward Euler\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=range(0, n+1, 20), blit=True)\nanim.save(\"figures/diffusionBE.mp4\", fps=30)\nclose()\n\nThis solution looks physically plausible, as the large concentration in the center diffuses outward until the solution is essentially constant. Observe that the solution remains periodic in space for all time.\n\nExample 11.2.5\n\nWe set up the semidiscretization and initial condition in x just as before.\n\nm = 100\nx, Dx, Dxx = FNC.diffper(m, [0, 1])\nu0 = exp(-60 * (x - 0.5) ** 2)\n\nNow, however, we apply a standard solver using solve_ivp to the initial-value problem \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nfrom scipy.integrate import solve_ivp\ntfinal = 0.05\nf = lambda t, u: Dxx @ u\nsol = solve_ivp(f, [0, tfinal], u0, method=\"RK45\", dense_output=True)\n\nt = linspace(0, 0.05, 5)\nplot(x, sol.sol(t))\nxlabel(\"$x$\"),  ylabel(\"$u(x,t)$\")\nlegend([f\"$t={tj:.4g}$\" for tj in t])\ntitle(\"Heat equation by RK45\");\n\nThe solution appears to be correct. But the number of time steps that were selected automatically is surprisingly large, considering how smoothly the solution changes.\n\nprint(f\"RK45 took {len(sol.t) - 1} steps\")\n\nNow we apply a different solver called BDF.\n\nsol = solve_ivp(f, [0, tfinal], u0, method=\"BDF\")\nprint(f\"BDF took {len(sol.t) - 1} steps\")\n\nThe number of steps selected was reduced by a factor of 20!","type":"content","url":"/chapter11-2#id-11-2","position":9},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.3 Absolute stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-2#id-11-3","position":10},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.3 Absolute stability","lvl2":"Examples"},"content":"Example 11.3.5\n\nEuler and Backward Euler time-stepping methods were used to solve \\mathbf{u}'=\\mathbf{D}_{xx}\\mathbf{u}.\n\nm = 40\nDxx = FNC.diffper(m, [0, 1])[2]\n\nThe eigenvalues of this matrix are real and negative:\n\nfrom scipy.linalg import eigvals\nlamb = eigvals(Dxx)\nplot(real(lamb), imag(lamb), \"o\")\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\ntitle(\"Eigenvalues\");\n\nThe Euler method is absolutely stable in the region |\\zeta+1| \\le 1 in the complex plane:\n\nphi = 2 * pi * arange(361) / 360\nz = exp(1j * phi) - 1  # unit circle shifted to the left by 1\n\nfill(real(z), imag(z), color=(0.8, 0.8, 1))\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\naxis(\"equal\")\ntitle(\"Stability region\");\n\nIn order to get inside this region, we have to find τ such that \\lambda \\tau > -2 for all eigenvalues λ. This is an upper bound on τ.\n\nlambda_min = min(real(lamb))\nmax_tau = -2 / lambda_min\nprint(f\"predicted max time step is {max_tau:.3e}\")\n\nHere we plot the resulting values of \\zeta=\\lambda \\tau.\n\nzeta = lamb * max_tau\nfill(real(z), imag(z), color=(0.8, 0.8, 1))\nplot(real(zeta), imag(zeta), \"o\")\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\naxis(\"equal\")\ntitle(\"Stability region and $\\zeta$ values\");\n\nIn backward Euler, the region is |\\zeta-1|\\ge 1. Because they are all on the negative real axis, all of the ζ values will fit no matter what τ is chosen.\n\nfill([-6, 6, 6, -6], [-6, -6, 6, 6], color=(0.8, 0.8, 1))\nz = exp(1j * phi) + 1\n# unit circle shifted right by 1\nfill(real(z), imag(z), color=\"w\")\n\nplot(real(zeta), imag(zeta), \"o\")\naxis([-4, 2, -3, 3])\naxis(\"equal\")\nxlabel(\"Re $\\\\lambda$\")\nylabel(\"Im $\\\\lambda$\")\ntitle(\"Stability region and $\\\\zeta$ values\");","type":"content","url":"/chapter11-2#id-11-3","position":11},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.4 Stiffness","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-2#id-11-4","position":12},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.4 Stiffness","lvl2":"Examples"},"content":"Example 11.4.2\n\nIn \n\nExample 11.4.1 we derived a Jacobian matrix for the Oregonator model. Here is a numerical solution of the ODE.\n\nfrom scipy.integrate import solve_ivp\nq, s, w = (8.375e-6, 77.27, 0.161)\n\ndef ode(t, u):\n    return array(\n        [\n            s * (u[1] - u[0] * u[1] + u[0] - q * u[0]**2),\n            (-u[1] - u[0] * u[1] + u[2]) / s,\n            w * (u[0] - u[2]),\n        ]\n    )\n\nu0 = array([1.0, 2.0, 3.0])\ntspan = (0, 500)\nstart = timer()\nsol = solve_ivp(ode, tspan, u0, method=\"BDF\")\nsemilogy(sol.t, sol.y.T)\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\ntitle(\"Oregonator\");\n\nAt each value of the numerical solution, we can compute the eigenvalues of the Jacobian. Here we plot all of those eigenvalues in the complex plane.\n\nJ = lambda u: array(\n    [\n        [-s * (u[1] + 1 - 2 * q * u[0]), s * (1 - u[0]), 0],\n        [-u[1] / s, (-1 - u[0]) / s, 1 / s],\n        [w, 0, -w],\n    ]\n)\n\nfrom scipy.linalg import eigvals\n\nlamb = array([eigvals(J(u)) for u in sol.y.T])\nax = figure().add_subplot(projection='3d')\nfor i in range(3):\n    ax.plot(real(lamb[:, i]), imag(lamb[:, i]), sol.t, \".\")\nax.set_xlabel(\"Re $\\\\lambda$\")\nax.set_ylabel(\"Im $\\\\lambda$\")\nax.set_zlabel(\"$t$\")\nax.set_title(\"Oregonator eigenvalues\");\n\nYou can see that there is one eigenvalue that ranges over a wide portion of the negative real axis and dominates stability considerations.\n\nExample 11.4.3\n\nThe BDF solver is good for stiff problems and needs few time steps to solve the Oregonator from \n\nDemo 11.4.2.\n\ntspan = (0, 25)\nstart = timer()\nsol = solve_ivp(ode, tspan, u0, method=\"BDF\")\nprint(f\"stiff solver took {timer() - start:.3f} seconds with {len(sol.t) - 1} time steps\")\n\nBut if we apply \n\nFunction 6.5.2 to the problem, the step size will be made small enough to cope with the large negative eigenvalue.\n\nstart = timer()\nt, u = FNC.rk23(ode, tspan, u0, 1e-6)\nprint(f\"rk23 solver took {timer() - start:.3f} seconds with {len(t) - 1} time steps\")\n\nStarting from the eigenvalues of the Jacobian matrix, we can find an effective \\zeta(t) by multiplying with the local time step size. The values of \\zeta(t) for each time level are plotted below and color coded by component of the diagonalized system.\n\nzeta = zeros([len(t)- 1, 3]) + 0j    # complex array\nfor i in range(len(t) - 1):\n    dt = t[i+1] - t[i]\n    lamb = eigvals(J(u[:, i]))\n    zeta[i] = lamb * dt\nplot(real(zeta), imag(zeta), \".\")\naxis(\"equal\")\nxlabel(\"Re $\\\\zeta$\")\nylabel(\"Im $\\\\zeta$\")\ntitle(\"Oregonator stability\");\n\nRoughly speaking, the ζ values stay within or close to the RK2 stability region in \n\nFigure 11.3.2. Momentary departures from the region are possible, but time stepping repeatedly in that situation would cause instability.","type":"content","url":"/chapter11-2#id-11-4","position":13},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.5 Boundaries","lvl2":"Examples"},"type":"lvl3","url":"/chapter11-2#id-11-5","position":14},{"hierarchy":{"lvl1":"Chapter 11","lvl3":"11.5 Boundaries","lvl2":"Examples"},"content":"Example 11.5.3\n\nFirst, we define functions for the PDE and each boundary condition.\n\nphi = lambda t, x, u, ux, uxx: uxx\nga = lambda u, ux: u\ngb = lambda u, ux: u - 2\n\nOur next step is to write a function to define the initial condition. This one satisfies the boundary conditions exactly.\n\ninit = lambda x: 1 + sin(pi * x/2) + 3 * (1 - x**2) * exp(-4*x**2)\n\nNow we can use \n\nFunction 11.5.2 to solve the problem.\n\nx, u = FNC.parabolic(phi, (-1, 1), 60, ga, gb, (0, 0.75), init)\n\nfor t in arange(0,0.5,0.1):\n    plot(x, u(t), label=f\"t={t:.2f}\")\nxlabel(\"$x$\"),  ylabel(\"$u(x,t)$\")\nlegend()\ntitle(\"Heat equation with Dirichlet boundaries\");\n\nfrom matplotlib import animation\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(-1, 1), ylim=(0, 4.2))\n\nline, = ax.plot([], [], '-')\nax.set_title(\"Heat equation with Dirichlet boundaries\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\ndef animate(t):\n    line.set_data(x, u(t))\n    time_text.set_text(f\"t = {t:.2e}\")\n    return line, time_text\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=linspace(0, 0.75, 201), blit=True)\nanim.save(\"figures/boundaries-heat.mp4\", fps=30)\nclose()\n\nExample 11.5.4\n\nphi = lambda t, x, u, ux, uxx: u**2 + uxx\nga = lambda u, ux: u\ngb = lambda u, ux: ux\ninit = lambda x: 400 * x**4 * (1 - x)**2\nx, u = FNC.parabolic(phi, (0, 1), 60, ga, gb, (0, 0.1), init);\n\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, 1), ylim=(0, 10))\n\nline, = ax.plot([], [], '-')\nax.set_title(\"Heat equation with source\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=linspace(0, 0.1, 101), blit=True)\nanim.save(\"figures/boundaries-source.mp4\", fps=30)\nclose()\n\nExample 11.5.5\n\nK = 3;  sigma = 0.06;  r = 0.08;  Smax = 8;\nphi = lambda t, x, u, ux, uxx: sigma**2/2 * (x**2 * uxx) + r*x*ux - r*u\nga = lambda u, ux: u\ngb = lambda u, ux: ux - 1\n\nu0 = lambda x: maximum(0, x - K)\nx, u = FNC.parabolic(phi, (0, Smax), 80, ga, gb, (0, 15), u0);\n\nfig = figure()\nax = fig.add_subplot(autoscale_on=False, xlim=(0, Smax), ylim=(-0.5, 8))\n\nline, = ax.plot([], [], '-')\nax.set_title(\"Black–Scholes equation with boundaries\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nanim = animation.FuncAnimation(\n    fig, animate, frames=linspace(0, 15, 151), blit=True)\nanim.save(\"figures/boundaries-bs.mp4\", fps=30)\nclose()\n\nRecall that u is the value of the call option, and time runs backward from the strike time. The longer the horizon, the more value the option has due to anticipated growth in the stock price.","type":"content","url":"/chapter11-2#id-11-5","position":15},{"hierarchy":{"lvl1":"Chapter 12"},"type":"lvl1","url":"/chapter12-2","position":0},{"hierarchy":{"lvl1":"Chapter 12"},"content":"","type":"content","url":"/chapter12-2","position":1},{"hierarchy":{"lvl1":"Chapter 12","lvl2":"Examples"},"type":"lvl2","url":"/chapter12-2#examples","position":2},{"hierarchy":{"lvl1":"Chapter 12","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter12-2#examples","position":3},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.1 Traffic flow","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-2#id-12-1","position":4},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.1 Traffic flow","lvl2":"Examples"},"content":"Example 12.1.1\n\nIn the following definition we allow the velocity c to be specified as a parameter in the ODEProblem.\n\nx, Dx, Dxx = FNC.diffper(300, [-4, 4])\nf = lambda t, u: -c * (Dx @ u)\n\nThe following initial condition isn’t mathematically periodic, but the deviation is less than machine precision. We specify RK4 as the solver.\n\nfrom scipy.integrate import solve_ivp\nu_init = 1 + exp(-3 * x**2)\nc = 2\nsol = solve_ivp(f, [0, 3.0], u_init, method=\"Radau\", dense_output=True)\n\nfor t in arange(0, 3, 2/3):\n    plot(x, sol.sol(t), label=f\"t = {t:.1f}\")\nlegend()\nxlabel(\"$x$\"),  ylabel(\"$u(x,t)$\")\ntitle(\"Advection with periodic boundary\");\n\nAn animation shows the solution nicely. The bump moves with speed 2 to the right, reentering on the left as it exits to the right because of the periodic conditions.\n\nfrom matplotlib import animation\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(0.9, 2.1)\nax.set_title(\"Advection equation with periodic boundary\")\n\ndef snapshot(t):\n    curve.set_ydata(sol.sol(t))\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 3, 201)\n    )\nanim.save(\"figures/advection-periodic.mp4\", fps=30)\nclose()\n\nExample 12.1.2\n\nThe following are parameters and a function relevant to defining the problem.\n\nrho_c = 1080\nrho_m = 380\nq_m = 10000\nQ0prime = (\n    lambda rho: q_m\n    * 4\n    * rho_c**2\n    * (rho_c - rho_m)\n    * rho_m\n    * (rho_m - rho)\n    / (rho * (rho_c - 2 * rho_m) + rho_c * rho_m) ** 3\n)\n\nHere we create a discretization on m=800 points.\n\nx, Dx, Dxx = FNC.diffper(800, [0, 4])\n\nNext we define the ODE resulting from the method of lines.\n\node = lambda t, rho: -Q0prime(rho) * (Dx @ rho) + ep * (Dxx @ rho)\n\nOur first initial condition has moderate density with a small bump. Because of the diffusion present, we use a stiff solver for the IVP.\n\nrho_init = 400 + 10 * exp(-20 * (x - 3) ** 2)\nep = 0.02\nsol = solve_ivp(ode, [0, 1.0], rho_init, method=\"Radau\", dense_output=True)\n\nfor t in linspace(0, 1, 6):\n    plot(x, sol.sol(t), label=f\"t = {t:.1f}\")\n\nxlabel(\"$x$\"),  ylabel(\"car density\")\nlegend(),  title(\"Traffic flow\");\n\nThe bump slowly moves backward on the roadway, spreading out and gradually fading away due to the presence of diffusion.\n\nfig, ax = subplots()\ncurve = ax.plot(x, rho_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"density\")\nax.set_ylim(400, 410)\nax.set_title(\"Traffic flow\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 1, 101)\n    )\nanim.save(\"figures/traffic-small.mp4\", fps=30)\nclose()\n\nNow we use an initial condition with a larger bump. Note that the scale on the y-axis is much different for this solution.\n\nrho_init = 400 + 80 * exp(-16 * (x - 3) ** 2)\nsol = solve_ivp(ode, [0, 0.5], rho_init, method=\"Radau\", dense_output=True)\n\nfor t in linspace(0, 0.5, 6):\n    plot(x, sol.sol(t), label=f\"t = {t:.1f}\")\n\nxlabel(\"$x$\"),  ylabel(\"car density\")\nlegend(),  title(\"Traffic jam\");\n\nfig, ax = subplots()\ncurve = ax.plot(x, rho_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"density\")\nax.set_ylim(400, 480)\nax.set_title(\"Traffic jam\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 0.5, 101)\n    )\nanim.save(\"figures/traffic-jam.mp4\", fps=30)\nclose()\n\nIn this case the density bump travels backward along the road. It also steepens on the side facing the incoming traffic and decreases much more slowly on the other side. A motorist would experience this as an abrupt increase in density, followed by a much more gradual decrease in density and resulting gradual increase in speed. (You also see some transient, high-frequency oscillations. These are caused by instabilities, as we discuss in simpler situations later in this chapter.)","type":"content","url":"/chapter12-2#id-12-1","position":5},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.2 Upwinding and stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-2#id-12-2","position":6},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.2 Upwinding and stability","lvl2":"Examples"},"content":"Example 12.2.3\n\nFor time stepping, we use the adaptive explicit method RK45.\n\nx, Dx, Dxx = FNC.diffper(400, [0, 1])\nu_init = exp(-80 * (x - 0.5) ** 2)\nc = 2\node = lambda t, u: -c * (Dx @ u)\nsol = solve_ivp(ode, (0, 2), u_init, method=\"RK45\", dense_output=True)\nu = sol.sol\n\nt = linspace(0, 2, 81)\nU = vstack([u(tj) for tj in t])\ncontour(x, t, U, levels=arange(0.15, 1.0, 0.2))\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Linear advection\");\n\nIn the space-time plot above, you can see the initial hump traveling rightward at constant speed. It fully traverses the domain once for each integer multiple of t=1/2.\n\nIf we cut h by a factor of 2 (i.e., double m), then the CFL condition suggests that the time step should be cut by a factor of 2 also.\n\nprint(f\"{len(sol.t) - 1} time steps taken for m = 400\")\n\nx, Dx, Dxx = FNC.diffper(800, [0, 1])\nu_init = exp(-80 * (x - 0.5) ** 2)\nsol = solve_ivp(ode, (0, 2), u_init, method=\"RK45\", dense_output=True)\nprint(f\"{len(sol.t) - 1} time steps taken for m = 800\")\n\nExample 12.2.6\n\nIf we solve advection over [0,1] with velocity c=-1, the right boundary is in the upwind/inflow direction. Thus a well-posed boundary condition is u(1,t)=0.\n\nWe’ll pattern a solution after \n\nFunction 11.5.2. Since u(x_m,t)=0, we define the ODE interior problem \n\n(11.5.4) for \\mathbf{v} without u_m. For each evaluation of \\mathbf{v}', we must extend the data back to x_m first.\n\nm = 80\nx, Dx, Dxx = FNC.diffmat2(m, [0, 1])\n\nchop = lambda u : u[:-1]\nextend = lambda v: hstack([v, 0])\n\node = lambda t, v: -c * chop( Dx @ extend(v) )\nc = -1\n\nNow we solve for an initial condition that has a single hump.\n\nu_init = exp(-80 * (x - 0.5) ** 2)\nsol = solve_ivp(ode, (0, 1), chop(u_init), method=\"RK45\", dense_output=True)\nu = lambda t: extend(sol.sol(t))\n\nt = linspace(0, 1, 80)\nU = [u(tj) for tj in t]\ncontour(x, t, U, levels=arange(0.15, 1.0, 0.2))\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Advection with inflow BC\");\n\nWe find that the hump gracefully exits out the downwind end.\n\nfrom matplotlib import animation\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-0.1, 1.1)\nax.set_title(\"Advection with inflow BC\")\n\ndef snapshot(t):\n    curve.set_ydata(u(t))\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 1, 101)\n    )\nanim.save(\"figures/advection-inflow.mp4\", fps=30)\nclose()\n\nIf, instead of u(1,t)=0, we were to try to impose the downwind condition u(0,t)=0, we only need to change the index of the interior nodes and where to append the zero value.\n\nchop = lambda u : u[1:]\nextend = lambda v: hstack([0, v])\n\nsol = solve_ivp(ode, (0, 1), chop(u_init), method=\"RK45\", dense_output=True)\nu = lambda t: extend(sol.sol(t))\n\nU = [u(tj) for tj in t]\nclf\ncontour(x, t, U, levels=arange(0.15, 1.0, 0.2))\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Outflow boundary condition\");\n\nThis time, the solution blows up as soon as the hump runs into the boundary because there are conflicting demands there.\n\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-0.1, 1.1)\nax.set_title(\"Advection with outflow BC\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 0.5, 51)\n    )\nanim.save(\"figures/advection-outflow.mp4\", fps=30)\nclose()","type":"content","url":"/chapter12-2#id-12-2","position":7},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.3 Absolute stability","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-2#id-12-3","position":8},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.3 Absolute stability","lvl2":"Examples"},"content":"Example 12.3.1\n\nFor c=1 we get purely imaginary eigenvalues.\n\nfrom scipy.linalg import eigvals\nx, Dx, Dxx = FNC.diffper(40, [0, 1])\nlamb = eigvals(Dx)\n\nplot(real(lamb), imag(lamb), \"o\")\naxis([-40, 40, -40, 40])\naxis(\"equal\")\ntitle(\"Eigenvalues for pure advection\");\n\nLet’s choose a time step of \\tau=0.1 and compare to the stability regions of the Euler and backward Euler time steppers (shown as shaded regions):\n\nzc = exp(2j * pi * arange(361) / 360)\n# points on |z|=1\n\nz = zc - 1    # shift circle left by 1\nfill(real(z), imag(z), color=(0.8, 0.8, 1))\nplot(real(0.1 * lamb), imag(0.1 * lamb), \"o\")\naxis([-5, 5, -5, 5]),  axis(\"equal\")\ntitle(\"Euler\");\n\nIn the Euler case it’s clear that no real value of \\tau>0 is going to make ζ values fit within the stability region. Any method whose stability region includes none of the imaginary axis is an unsuitable choice for advection.\n\nz = zc + 1    # shift circle right by 1\nfill([-6, 6, 6, -6], [-6, -6, 6, 6], color=(0.8, 0.8, 1))\nfill(real(z), imag(z), color=\"w\")\nplot(real(0.1 * lamb), imag(0.1 * lamb), \"o\")\naxis([-5, 5, -5, 5])\naxis(\"equal\")\ntitle(\"Backward Euler\");\n\nThe A-stable backward Euler time stepping tells the exact opposite story: it will be absolutely stable for any choice of the time step τ.\n\nExample 12.3.2\n\nThe eigenvalues of advection-diffusion are near-imaginary for \\epsilon\\approx 0 and get closer to the negative real axis as ε increases.\n\nx, Dx, Dxx = FNC.diffper(40, [0, 1])\ntau = 0.1\nfor ep in [0.001, 0.01, 0.05]:\n    lamb = eigvals(-Dx + ep * Dxx)\n    plot(real(tau * lamb), imag(tau * lamb), \"o\", label=f\"epsilon={ep:.1g}\")\naxis(\"equal\")\nlegend()\ntitle(\"Eigenvalues for advection-diffusion\");\n\nExample 12.3.3\n\nDeleting the last row and column places all the eigenvalues of the discretization into the left half of the complex plane.\n\nfrom scipy.linalg import eigvals\nx, Dx, Dxx = FNC.diffcheb(40, [0, 1])\nA = -Dx[1:, 1:]  # leave out first row and column\n\nlamb = eigvals(A)\nplot(real(lamb), imag(lamb), \"o\")\nxlim(-300, 100),  axis(\"equal\"),  grid(True)\ntitle(\"Eigenvalues of advection with zero inflow\");\n\nNote that the rightmost eigenvalues have real part at most\n\nprint(f\"rightmost extent of eigenvalues: {max(real(lamb)):.3g}\")\n\nConsequently all solutions decay exponentially to zero as t\\to\\infty. This matches our observation of the solution: eventually, everything flows out of the domain.","type":"content","url":"/chapter12-2#id-12-3","position":9},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.4 The wave equation","lvl2":"Examples"},"type":"lvl3","url":"/chapter12-2#id-12-4","position":10},{"hierarchy":{"lvl1":"Chapter 12","lvl3":"12.4 The wave equation","lvl2":"Examples"},"content":"Example 12.4.1\n\nm = 200\nx, Dx, Dxx = FNC.diffmat2(m, [-1, 1])\n\nThe boundary values of u are given to be zero, so they are not unknowns in the ODEs. Instead they are added or removed as necessary.\n\nchop = lambda u: u[1:-1]\nextend = lambda v: hstack([0, v, 0])\n\nThe following function computes the time derivative of the system at interior points.\n\ndef dw_dt(t, w):\n    u = extend(w[:m-1])\n    z = w[m-1:]\n    du_dt = Dx @ z\n    dz_dt = c**2 * (Dx @ u)\n    return hstack([chop(du_dt), dz_dt])\n\nOur initial condition is a single hump for u.\n\nu_init = exp(-100 * x**2)\nz_init = -u_init\nw_init = hstack([chop(u_init), z_init])\n\nBecause the wave equation is hyperbolic, we can use a nonstiff explicit solver.\n\nc = 2\nsol = solve_ivp(dw_dt, (0, 2), w_init, dense_output=True)\nu = lambda t: extend(sol.sol(t)[:m-1])   # extract the u component\n\nWe plot the results for the original u variable only. Its interior values are at indices 1:m-1 of the composite \\mathbf{w} variable.\n\nt = linspace(0, 2, 80)\nU = [u(tj) for tj in t]\ncontour(x, t, U, levels=24, cmap=\"RdBu\", vmin=-1, vmax=1)\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Wave equation with boundaries\");\n\nfrom matplotlib import animation\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-1.05, 1.05)\nax.set_title(\"Wave equation with boundaries\")\n\ndef snapshot(t):\n    curve.set_ydata(u(t))\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 2, 161)\n    )\nanim.save(\"figures/wave-boundaries.mp4\", fps=30)\nclose()\n\nThe original hump breaks into two pieces of different amplitudes, each traveling with speed c=2. They pass through one another without interference. When a hump encounters a boundary, it is perfectly reflected, but with inverted shape. At time t=2, the solution looks just like the initial condition.\n\nExample 12.4.2\n\nThe variable wave speed is set to be re-used\n\nm = 120\nx, Dx, Dxx = FNC.diffcheb(m, [-1, 1])\nc = 1 + (sign(x) + 1) / 2\nu_init = exp(-100 * x**2)\nz_init = -u_init\nw_init = hstack([chop(u_init), z_init])\n\nsol = solve_ivp(dw_dt, (0, 5), w_init, dense_output=True, method=\"Radau\")\nu = lambda t: extend(sol.sol(t)[:m-1])\n\nt = linspace(0, 5, 150)\nU = [u(tj) for tj in t]\ncontour(x, t, U, levels=24, cmap=\"RdBu\", vmin=-1, vmax=1)\nxlabel(\"$x$\"),  ylabel(\"$t$\")\ntitle(\"Wave equation with variable speed\");\n\nfig, ax = subplots()\ncurve = ax.plot(x, u_init)[0]\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$u(x,t)$\")\nax.set_ylim(-1.05, 1.05)\nax.set_title(\"Wave equation with variable speed\")\n\nanim = animation.FuncAnimation(\n    fig, snapshot, frames=linspace(0, 5, 251)\n    )\nanim.save(\"figures/wave-speed.mp4\", fps=30)\nclose()\n\nEach pass through the interface at x=0 generates a reflected and transmitted wave. By conservation of energy, these are both smaller in amplitude than the incoming bump.","type":"content","url":"/chapter12-2#id-12-4","position":11},{"hierarchy":{"lvl1":"Chapter 13"},"type":"lvl1","url":"/chapter13-2","position":0},{"hierarchy":{"lvl1":"Chapter 13"},"content":"","type":"content","url":"/chapter13-2","position":1},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Functions"},"type":"lvl2","url":"/chapter13-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Functions"},"content":"Create a tensor-product grid\n\ndef tensorgrid(x, y):\n    \"\"\"\n    tensorgrid(x, y)\n\n    Create a tensor grid for a rectangle from its 1d projections x and y.\n    Returns a function to reshape a 2d array to a vector, a function to reshape \n    a vector into a 2d array, a function to evaluate a function on the grid, \n    two arrays to give the grid coordinates, and a boolean array to identify \n    the boundary points.\n    \"\"\"\n    m, n = len(x) - 1, len(y) - 1\n    vec = lambda U: U.T.flatten()\n    unvec = lambda u: np.reshape(u, (n+1, m+1)).T\n    mtx = lambda h: np.array([[h(xi ,yj) for yj in y] for xi in x])\n    X = mtx(lambda x, y: x)\n    Y = mtx(lambda x, y: y)\n\n    # Identify boundary points.\n    is_boundary = np.tile(True, (m+1, n+1))\n    is_boundary[1:-1, 1:-1] = False\n    \n    return mtx, X, Y, vec, unvec, is_boundary\n\nSolution of Poisson’s equation by finite differences\n\ndef poissonfd(f, g, m, xspan, n, yspan):\n    \"\"\"\n    poissonfd(f, g, m, xspan, n, yspan)\n\n    Solve Poisson's equation on a rectangle by finite differences. Function f is the\n    forcing function and function g gives the  Dirichlet boundary condition. The rectangle\n    is the tensor product of intervals xspan and yspan,  and the discretization uses\n    m+1 and n+1 points in the two coordinates.\n\n    Return matrices of the solution values, and the coordinate functions, on the grid.\n    \"\"\"\n    # Discretize the domain.\n    x, Dx, Dxx = diffmat2(m, xspan)\n    y, Dy, Dyy = diffmat2(n, yspan)\n    mtx, X, Y, vec, unvec, is_boundary = tensorgrid(x, y)\n    N = (m+1) * (n+1)    # total number of unknowns\n\n    # Form the collocated PDE as a linear system.\n    Dxx = sp.lil_matrix(Dxx)\n    Dyy = sp.lil_matrix(Dyy)\n    A = sp.kron(sp.eye(n+1, format=\"lil\"), Dxx) + sp.kron(Dyy, sp.eye(m+1, format=\"lil\"))\n    b = vec(mtx(f))\n\n    # Apply Dirichlet condition.\n    idx = vec(is_boundary)\n    scale = np.max(abs(A[n+1, :]))\n    I = sp.eye(N, format=\"lil\")\n    A[idx, :] = scale * I[idx, :]         # Dirichet assignment\n    X_bd, Y_bd = vec(X)[idx], vec(Y)[idx]\n    b[idx] = scale * g(X_bd, Y_bd)    # assigned values\n\n    # Solve the linear sytem and reshape the output.\n    u = scipy.sparse.linalg.spsolve(A.tocsr(), b)\n    U = unvec(u)\n    return U, X, Y\n\nSolution of elliptic PDE by Chebyshev collocation\n\ndef elliptic(f, g, m, xspan, n, yspan):\n    \"\"\"\n    newtonpde(f, g, m, xspan, n, yspan)\n\n    Newton's method with finite differences to solve the PDE f(u,x,y,disc)=0 on the\n    rectangle xspan \\times yspan, subject to g(x,y)=0 on the boundary. Use m+1\n    points in x by n+1 points in y.\n\n    Return matrices of the solution values, and the coordinate functions, on the grid.\n    \"\"\"\n    from scipy.sparse.linalg import spsolve\n    x, Dx, Dxx = diffcheb(m, xspan)\n    y, Dy, Dyy = diffcheb(n, yspan)\n    mtx, X, Y, vec, unvec, is_boundary = tensorgrid(x, y)\n\n    # Evaluate the boundary condition at the boundary nodes.\n    idx = vec(is_boundary)\n    X_bd, Y_bd = vec(X)[idx], vec(Y)[idx]\n    g_bd = g(X_bd, Y_bd)\n\n    # Evaluate the PDE+BC residual.\n    def residual(u):\n        U = unvec(u)\n        R = f(X, Y, U, Dx @ U, Dxx @ U, U @ Dy.T, U @ Dyy.T)    # PDE\n        r = vec(R)\n        r[idx] = u[idx] - g_bd                                  # BC\n        return r\n    \n    # Solve the equation.\n    u = levenberg(residual, vec(np.zeros(X.shape)))[-1]\n    U = unvec(u)\n\n    def evaluate(xi, eta):\n        v = [chebinterp(y, u, eta) for u in U]\n        return chebinterp(x, v, xi)\n    \n    return np.vectorize(evaluate)","type":"content","url":"/chapter13-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Examples"},"type":"lvl2","url":"/chapter13-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 13","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter13-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.1 Tensor-product discretizations","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-2#id-13-1","position":6},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.1 Tensor-product discretizations","lvl2":"Examples"},"content":"Example 13.1.2\n\nHere is the grid from \n\nExample 13.1.1.\n\nm = 4\nx = linspace(0, 2, m+1)\nn = 2\ny = linspace(1, 3, n+1)\n\nFor a given f(x,y) we can find \\operatorname{mtx}(f) by using a comprehension syntax.\n\nf = lambda x, y: cos(pi * x * y - y)\nF = array( [ [f(xi, yj) for yj in y] for xi in x ] )\nprint(F)\n\nWe can make a nice plot of the function by first choosing a much finer grid. However, the contour and surface plotting functions expect the transpose of mtx(f).\n\nTip\n\nTo emphasize departures from a zero level, use a colormap such as RdBu and set the color limits to be symmetric around zero.\n\nWarning\n\nThe contour and surface plotting functions expect the transpose of the outputs of mtx. If you forget to do that, the x and y axes will be swapped.\n\nm, n = 80, 70\nx = linspace(0, 2, m+1)\ny = linspace(1, 3, n+1)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nF = mtx(f)\n\npcolormesh(X.T, Y.T, F.T, cmap=\"RdBu\", vmin=-1, vmax=1, shading=\"gouraud\")\naxis(\"equal\"),  colorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nExample 13.1.3\n\nFor a function given in polar form, such as f(r,\\theta)=1-r^4, construction of a function over the unit disk is straightforward using a grid in (r,\\theta) space.\n\nr = linspace(0, 1, 41)\ntheta = linspace(0, 2*pi, 121)\nmtx, R, Theta, _, _, _ = FNC.tensorgrid(r, theta)\n\nF = mtx(lambda r, theta: 1 - r**4)    \n\ncontourf(R.T, Theta.T, F.T, levels=20)\ncolorbar()\nxlabel(\"$r$\"),  ylabel(\"$\\\\theta$\");\n\nOf course, we are used to seeing such plots over the (x,y) plane, not the (r,\\theta) plane. For this we create matrices for the coordinate functions x and y.\n\nX, Y = R * cos(Theta), R * sin(Theta)\ncontourf(X.T, Y.T, F.T, levels=20)\ncolorbar(),  axis(\"equal\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nIn such functions the values along the line r=0 must be identical, and the values on the line \\theta=0 should be identical to those on \\theta=2\\pi. Otherwise the interpretation of the domain as the unit disk is nonsensical. If the function is defined in terms of x and y, then those can be defined in terms of r and θ using \n\n(13.1.6).\n\nExample 13.1.4\n\nWe define a function and, for reference, its two exact partial derivatives.\n\nu = lambda x, y: sin(pi * x * y - y)\ndu_dx = lambda x, y: pi * y * cos(pi * x * y - y)\ndu_dy = lambda x, y: (pi * x - 1) * cos(pi * x * y - y)\n\nWe will use an equispaced grid and second-order finite differences as implemented by diffmat2. First, we have a look at a plots of the exact partial derivatives.\n\nm, n = 80, 60\nx, Dx, Dxx = FNC.diffmat2(m, [0, 2])\ny, Dy, Dyy = FNC.diffmat2(n, [1, 4])\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\n\nU = mtx(u)\ndU_dX = mtx(du_dx)\ndU_dY = mtx(du_dy)\n\nsubplot(1, 2, 1)\ncontourf(X.T, Y.T, dU_dX.T)\ntitle(\"$u$\"),  axis(\"equal\")\nsubplot(1, 2, 2)\ncontourf(X.T, Y.T, dU_dY.T)\ntitle(\"$\\\\partial u/\\\\partial y$\"),  axis(\"equal\");\n\nNow we compare the exact partial derivatives with their finite-difference approximations. Since these are signed errors, we use a colormap that is symmetric around zero.\n\nsubplot(1, 2, 1)\npcolormesh(X, Y, Dx @ U  - dU_dX, shading=\"gouraud\", cmap=\"RdBu\", vmin=-0.4, vmax=0.4)\ncolorbar()\ntitle(\"error in $\\\\partial u/\\\\partial x$\"),  axis(\"equal\")\nsubplot(1, 2, 2)\npcolormesh(X, Y, U @ Dy.T - dU_dY, shading=\"gouraud\", cmap=\"RdBu\", vmin=-0.1, vmax=0.1)\ncolorbar()\ntitle(\"error in $\\\\partial u/\\\\partial y$\"),  axis(\"equal\");\n\nNot surprisingly, the errors are largest where the derivatives themselves are largest.","type":"content","url":"/chapter13-2#id-13-1","position":7},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.2 Two-dimensional diffusion and advection","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-2#id-13-2","position":8},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.2 Two-dimensional diffusion and advection","lvl2":"Examples"},"content":"Example 13.2.1\n\nm, n = 4, 3\nx = linspace(0, 2, m+1)\ny = linspace(-3, 0, n+1)\n\nf = lambda x, y: cos(0.75 * pi * x * y - 0.5 * pi * y)\nmtx, X, Y, vec, unvec, _ = FNC.tensorgrid(x, y)\nF = mtx(f)\nprint(f\"function on a {m}x{n} grid:\")\nwith printoptions(precision=4, suppress=True):\n    print(F)\n\nprint(\"vec(F):\")\nwith printoptions(precision=4, suppress=True):\n    print(vec(F))\n\nThe unvec operation is the inverse of vec.\n\nprint(\"unvec(vec(F)):\")\nwith printoptions(precision=4, suppress=True):\n    print(unvec(vec(F)))\n\nExample 13.2.2\n\nm, n = 60, 40\nx, Dx, Dxx = FNC.diffper(m, [-1, 1])\ny, Dy, Dyy = FNC.diffper(n, [-1, 1])\nmtx, X, Y, vec, unvec, _ = FNC.tensorgrid(x, y)\n\nNote that the initial condition should also be periodic on the domain.\n\nu_init = lambda x, y: sin(4 * pi * x) * exp(cos(pi * y))\nU0 = mtx(u_init)\nmx = max(abs(U0))\npcolormesh(X, Y, U0, vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\naxis(\"equal\"),  colorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\")\ntitle(\"Initial condition\");\n\nThis function computes the time derivative for the unknowns. The actual calculations take place using the matrix shape.\n\nalpha = 0.1\ndef du_dt(t, u):\n    U = unvec(u)\n    Uyy = Dxx @ U\n    Uxx = U @ Dyy.T\n    dU_dt = alpha * (Uxx + Uyy)  # PDE\n    return vec(dU_dt)\n\nSince this problem is parabolic, a stiff integrator is appropriate.\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(du_dt, (0, 0.2), vec(U0), method=\"BDF\", dense_output=True)\nU = lambda t: unvec(sol.sol(t))\n\npcolormesh(X.T, Y.T, U(0.02).T, \n    vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\naxis(\"equal\"),  colorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\")\ntitle(\"Heat equation, t=0.02\");\n\nHere is an animation of the solution.\n\nTip\n\nHere clims are set so that colors remain at fixed values throughout the animation.\n\nfrom matplotlib import animation\nfig, ax = subplots()\nobj = ax.pcolormesh(X, Y, U(0), vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\"),  ax.set_ylabel(\"$y$\")\nax.set_aspect(\"equal\")\nax.set_title(\"Heat equation on a periodic domain\")\ndef snapshot(t):\n    global obj\n    obj.remove()\n    obj = ax.pcolormesh(X, Y, U(t), vmin=-mx, vmax=mx, cmap=\"RdBu\", shading=\"gouraud\")\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(fig, snapshot, frames=linspace(0, 0.2, 41))\nanim.save(\"figures/heat-2d.mp4\", fps=30)\nclose()\n\nExample 13.2.3\n\nThe first step is to define a discretization of the domain.\n\nm, n = 50, 36\nx, Dx, Dxx = FNC.diffcheb(m, [-1, 1])\ny, Dy, Dyy = FNC.diffcheb(n, [-1, 1])\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nu_init = lambda x, y: (1 + y) * (1 - x)**4 * (1 + x)**2 * (1 - y**4)\n\nThere are really two grids now: the full grid and the subset grid of interior points. Since the IVP unknowns are on the interior grid, that is the one we need to change shapes on. We also need the functions extend and chop to add and remove boundary values.\n\n_, _, _, vec, unvec, _ = FNC.tensorgrid(x[1:-1], y[1:-1])\n\ndef chop(U):\n    return U[1:-1, 1:-1]\n\ndef extend(U):\n    UU = zeros((m+1, n+1))\n    UU[1:-1, 1:-1] = U\n    return UU\n\npack = lambda U: vec(chop(U))          # restrict to interior, then vectorize\nunpack = lambda u: extend(unvec(u))    # unvectorize, then extend to boundary\n\nNow we can define and solve the IVP using a stiff solver.\n\nep = 0.05\ndef dw_dt(t, w):\n    U = unpack(w)\n    Uyy = Dxx @ U\n    Uxx = U @ Dyy.T \n    dU_dt = 1 - Dx @ U + ep * (Uxx + Uyy)\n    return pack(dU_dt)\n\nU0 = mtx(u_init)\nsol = solve_ivp(dw_dt, (0, 2), pack(U0), method=\"BDF\", dense_output=True)\n\nWhen we evaluate the solution at a particular value of t, we get a vector of the interior grid values. The same unpack function above converts this to a complete matrix of grid values.\n\nU = lambda t: unpack(sol.sol(t))    # function of time on the grid\n\npcolormesh(X.T, Y.T, U(0.5).T, cmap=\"Blues\", shading=\"gouraud\")\ncolorbar()\nxlabel(\"$x$\"),  ylabel(\"$y$\")\naxis(\"equal\"),  title(\"Solution at t=0.5\");\n\nfig, ax = subplots()\nobj = ax.pcolormesh(X.T, Y.T, U(0).T, vmin=0, vmax=2, cmap=\"Blues\", shading=\"gouraud\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\"),  ax.set_ylabel(\"$y$\")\nax.set_aspect(\"equal\")\nax.set_title(\"Advection-diffusion in 2d\")\ndef snapshot(t):\n    global obj\n    obj.remove()\n    obj = ax.pcolormesh(X.T, Y.T, U(t).T, vmin=0, vmax=2, cmap=\"Blues\", shading=\"gouraud\")\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(fig, snapshot, frames=linspace(0, 2, 81))\nanim.save(\"figures/advdiff-2d.mp4\", fps=30)\nclose()\n\nExample 13.2.4\n\nWe start with the discretization and initial condition.\n\nm, n = 40, 42\nx, Dx, Dxx = FNC.diffcheb(m, [-2, 2])\ny, Dy, Dyy = FNC.diffcheb(n, [-2, 2])\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\n\nU0 = mtx(lambda x, y: (x + 0.2) * exp(-12 * (x**2 + y**2)))\nV0 = zeros(U0.shape)\n\nNote that because u is known on the boundary, while v is unknown over the full grid, there are two different sizes of vec/unvec operations. We also need to define functions to pack grid unknowns into a vector and to unpack them. When the unknowns for u are packed, the boundary values are chopped off, and these are restored when unpacking.\n\n_, _, _, vec_v, unvec_v, _ = FNC.tensorgrid(x, y)\n_, _, _, vec_u, unvec_u, _ = FNC.tensorgrid(x[1:-1], y[1:-1])\n\ndef extend(U):\n    UU = zeros((m+1, n+1))\n    UU[1:-1, 1:-1] = U\n    return UU\n\ndef chop(U):\n    return U[1:-1, 1:-1]\n\ndef pack(U, V): \n    return hstack([vec_u(chop(U)), vec_v(V)])\n\nN = (m-1) * (n-1)\ndef unpack(w):\n    U = extend(unvec_u(w[:N]))\n    V = unvec_v(w[N:])\n    return U, V\n\nWe can now define and solve the IVP. Since this problem is hyperbolic, not parabolic, a nonstiff integrator is faster than a stiff one.\n\ndef dw_dt(t, w):\n    U, V = unpack(w)\n    dU_dt = V\n    dV_dt = Dxx @ U + U @ Dyy.T\n    return pack(dU_dt, dV_dt)\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(dw_dt, (0, 4), pack(U0, V0), method=\"RK45\", dense_output=True)\nU = lambda t: unpack(sol.sol(t))[0]\n\nfig, ax = subplots()\nobj = ax.pcolormesh(X, Y, U(0), vmin=-0.1, vmax=0.1, cmap=\"RdBu\", shading=\"gouraud\")\ntime_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\nax.set_xlabel(\"$x$\"),  ax.set_ylabel(\"$y$\")\nax.set_aspect(\"equal\")\nax.set_title(\"Wave equation in 2d\")\n\ndef snapshot(t):\n    global obj\n    obj.remove()\n    obj = ax.pcolormesh(X, Y, U(t), vmin=-0.1, vmax=0.1, cmap=\"RdBu\", shading=\"gouraud\")\n    time_text.set_text(f\"t = {t:.2f}\")\n\nanim = animation.FuncAnimation(fig, snapshot, frames=linspace(0, 4, 91))\nanim.save(\"figures/wave-2d.mp4\", fps=30);\nclose()","type":"content","url":"/chapter13-2#id-13-2","position":9},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.3 Laplace and Poisson equations","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-2#id-13-3","position":10},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.3 Laplace and Poisson equations","lvl2":"Examples"},"content":"Example 13.3.1\n\nA = array([[1, 2], [-2, 0]])\nB = array([[1, 10, 100], [-5, 5, 3]])\nprint(\"A:\")\nprint(A)\nprint(\"B:\")\nprint(B)\n\nApplying the definition manually, we get\n\nA_kron_B = vstack([ hstack([A[0, 0] * B, A[0, 1] * B]), hstack([A[1, 0] * B, A[1, 1] * B]) ])\nprint(A_kron_B)\n\nBut it makes more sense to use kron from NumPy, or the scipy.sparse version when sparsity is to be preserved.\n\nkron(A, B)\n\nExample 13.3.2\n\nWe make a crude discretization for illustrative purposes.\n\nm, n = 5, 6\nx, Dx, Dxx = FNC.diffmat2(m, [0, 3])\ny, Dy, Dyy = FNC.diffmat2(n, [-1, 1])\nmtx, X, Y, vec, unvec, is_boundary = FNC.tensorgrid(x, y)\n\nNext, we define ϕ and evaluate it on the grid to get the forcing vector of the linear system.\n\nf = lambda x, y: x**2 - y + 2\nb = vec(mtx(f))\n\nHere are the coefficients for the PDE collocation, before any modifications are made for the boundary conditions. The combination of Kronecker products and finite differences produces a characteristic sparsity pattern.\n\nimport scipy.sparse as sp\nDxx = sp.lil_matrix(Dxx)\nDyy = sp.lil_matrix(Dyy)\nIx = sp.eye(m+1)\nIy = sp.eye(n+1)\nA = sp.kron(Iy, Dxx) + sp.kron(Dyy, Ix)\n\nspy(A)\ntitle(\"Matrix before imposing BC\");\n\nThe number of equations is equal to (m+1)(n+1), which is the total number of points on the grid.\n\nN = len(b)\n\nWe now use the Boolean array that indicates where the boundary points lie in the grid.\n\nspy(is_boundary)\ntitle(\"Boundary points\");\n\nIn order to impose Dirichlet boundary conditions, we replace the boundary rows of the system by rows of the identity.\n\nTip\n\nChanging rows of a sparse array requires that the operands be in a particular sparse representation called lil. The conversion isn’t done automatically because it can be slow and you are encouraged to avoid it when possible. We’re just trying to keep things conceptually simple here.\n\nI = sp.eye(N, format=\"lil\")\nidx = vec(is_boundary)\nA = A.tolil()\nA[idx, :] = I[idx, :];    # Dirichlet conditions\n\nspy(A)\ntitle(\"Matrix with Dirichlet BC imposed\");\n\nFinally, we must replace the rows in the vector \\mathbf{b} by the boundary values being assigned to the boundary points. Here, we let the boundary values be zero everywhere.\n\nb[idx] = 0\n\nNow we can solve for \\mathbf{u} and reinterpret it as the matrix-shaped \\mathbf{U}, the solution on our grid.\n\nfrom scipy.sparse.linalg import spsolve\nu = spsolve(A.tocsr(), b)\nU = unvec(u)\nwith printoptions(precision=4, suppress=True):\n    print(U)\n\nExample 13.3.3\n\nFirst we define the problem on [0,1]\\times[0,2].\n\nf = lambda x, y: -sin(3 * x * y - 4 * y) * (9 * y**2 + (3 * x - 4) ** 2)\ng = lambda x, y: sin(3 * x * y - 4 * y)\nxspan = [0, 1]\nyspan = [0, 2]\n\nHere is the finite-difference solution.\n\nU, X, Y = FNC.poissonfd(f, g, 50, xspan, 80, yspan)\n\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar(), title(\"Solution of Poisson's equation\");\n\nSince this is an artificial problem with a known solution, we can plot the error, which is a smooth function of x and y. It must be zero on the boundary; otherwise, we have implemented boundary conditions incorrectly.\n\nerror = g(X, Y) - U    # because we set up g as the exact solution\nM = max(abs(error))\n\npcolormesh(X.T, Y.T, error.T, vmin=-M, vmax=M, cmap=\"RdBu\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar(),  title(\"Error\");","type":"content","url":"/chapter13-2#id-13-3","position":11},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.4 Nonlinear elliptic PDEs","lvl2":"Examples"},"type":"lvl3","url":"/chapter13-2#id-13-4","position":12},{"hierarchy":{"lvl1":"Chapter 13","lvl3":"13.4 Nonlinear elliptic PDEs","lvl2":"Examples"},"content":"Example 13.4.2\n\nAll we need to define are ϕ from \n\n(13.4.2) for the PDE, and a trivial zero function for the boundary condition.\n\nlamb = 1.5\nphi = lambda x, y, u, ux, uxx, uy, uyy: uxx + uyy - lamb / (u + 1)**2\ng = lambda x, y: 0\n\nHere is the solution for m=15, n=8.\n\nu = FNC.elliptic(phi, g, 15, [0, 2.5], 8, [0, 1])\n\nprint(f\"solution at (2, 0.6) is {u(2, 0.6):.7f}\")\n\nx = linspace(0, 2.5, 90)\ny = linspace(0, 1, 60)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nU = mtx(u)\n\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar()\ntitle(\"Solution of the MEMS equation in 2d\");\n\nIn the absence of an exact solution, how can we be confident that the solution is accurate? First, the Levenberg iteration converged without issuing a warning, so we should feel confident that the discrete equations were solved. We can check the boundary values easily. For example,\n\nerr = norm(u(x, 0) - g(x, 0), inf)\nprint(f\"max error on bottom edge: {err:.2e}\")\n\nAssuming that we encoded the PDE correctly, the remaining source error is truncation from the discretization. We can estimate that by refining the grid a bit and seeing how much the numerical solution changes.\n\nx_test = linspace(0, 2.5, 6)\ny_test = linspace(0, 1, 6)\nmtx_test, X_test, Y_test, _, _, _ = FNC.tensorgrid(x_test, y_test)\n\nwith printoptions(precision=7, suppress=True):\n    print(mtx_test(u))\n\nu = FNC.elliptic(phi, g, 25, [0, 2.5], 14, [0, 1])\nwith printoptions(precision=7, suppress=True):\n    print(mtx_test(u))\n\nThe original solution seems to be accurate to about four digits.\n\nExample 13.4.3\n\nphi = lambda x, y, u, ux, uxx, uy, uyy: 1 - ux - 2*uy + 0.05 * (uxx + uyy)\ng = lambda x, y: 0\nu = FNC.elliptic(phi, g, 32, [-1, 1], 32, [-1, 1])\n\nx = y = linspace(-1, 1, 70)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nU = mtx(u)\n\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar()\ntitle(\"Steady advection–diffusion\");\n\nExample 13.4.4\n\nThe following defines the PDE and a nontrivial Dirichlet boundary condition for the square [0,1]^2.\n\nphi = lambda x, y, u, ux, uxx, uy, uyy: u * (1 - u**2) + 0.05 * (uxx + uyy)\ng = lambda x, y: tanh(5 * (x + 2*y - 1))\n\nWe solve the PDE and then plot the result.\n\nu = FNC.elliptic(phi, g, 36, [0, 1], 36, [0, 1])\n\nx = y = linspace(0, 1, 70)\nmtx, X, Y, _, _, _ = FNC.tensorgrid(x, y)\nU = mtx(u)\npcolormesh(X.T, Y.T, U.T, cmap=\"viridis\")\nxlabel(\"$x$\"),  ylabel(\"$y$\"),  axis(\"equal\")\ncolorbar(),  title(\"Steady Allen–Cahn equation\");","type":"content","url":"/chapter13-2#id-13-4","position":13},{"hierarchy":{"lvl1":"Chapter 2"},"type":"lvl1","url":"/chapter2-2","position":0},{"hierarchy":{"lvl1":"Chapter 2"},"content":"","type":"content","url":"/chapter2-2","position":1},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"type":"lvl2","url":"/chapter2-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Functions"},"content":"Forward substitution\n\ndef forwardsub(L,b):\n    \"\"\"\n     forwardsub(L,b)\n\n    Solve the lower-triangular linear system with matrix L and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n):\n        s = L[i,:i] @ x[:i]\n        x[i] = ( b[i] - s ) / L[i, i]\n    return x\n\nBackward substitution\n\ndef backsub(U,b):\n    \"\"\"\n    backsub(U,b)\n\n    Solve the upper-triangular linear system with matrix U and right-hand side\n    vector b.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n    for i in range(n-1, -1, -1):\n        s = U[i, i+1:] @ x[i+1:]\n        x[i] = ( b[i] - s ) / U[i, i]\n    return x\n\nLU factorization (not stable)\n\ndef lufact(A):\n    \"\"\"\n    lufact(A)\n\n    Compute the LU factorization of square matrix A, returning the\n    factors.\n    \"\"\"\n    n = A.shape[0]     # detect the dimensions from the input\n    L = np.eye(n)      # ones on main diagonal, np.zeros elsewhere\n    U = np.zeros((n, n))\n    A_k = np.copy(A)   # make a working np.copy \n\n    # Reduction by np.outer products\n    for k in range(n-1):\n        U[k, :] = A_k[k, :]\n        L[:, k] = A_k[:, k] / U[k,k]\n        A_k -= np.outer(L[:,k], U[k,:])\n    U[n-1, n-1] = A_k[n-1, n-1]\n    return L, U\n\nAbout the code\n\nLine 11 of \n\nFunction 2.4.1 points out a subtle issue. Array variables are really just references to blocks of memory. Such a reference is much more efficient to pass around than the complete contents of the array. However, it means that a statement A_k = A would just clone the array reference of A into the new variable. Any changes made to entries of A_k would then also be made to entries of A, because they refer to the same location in memory. In this context, we don’t want to change the original matrix, so we use copy here to create an independent copy of the array contents and a new reference to them.\n\nLU factorization with partial pivoting\n\ndef plufact(A):\n    \"\"\"\n        plufact(A)\n\n    Compute the PLU factorization of square matrix A, returning the\n    triangular factors and a row permutation vector.\n    \"\"\"\n    n = A.shape[0]\n    L = np.zeros((n, n))\n    U = np.zeros((n, n))\n    p = np.zeros(n, dtype=int)\n    A_k = np.copy(A)\n\n    # Reduction by np.outer products\n    for k in range(n):\n        p[k] = np.argmax(abs(A_k[:, k]))\n        U[k, :] = A_k[p[k], :]\n        L[:, k] = A_k[:, k] / U[k, k]\n        if k < n-1:\n            A_k -= np.outer(L[:, k], U[k, :])\n    return L[p, :], U, p","type":"content","url":"/chapter2-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"type":"lvl2","url":"/chapter2-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 2","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter2-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.1 Polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-1","position":6},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.1 Polynomial interpolation","lvl2":"Examples"},"content":"Example 2.1.1\n\nWe create two vectors for data about the population of China. The first has the years of census data and the other has the population, in millions of people.\n\nyear = arange(1980, 2020, 10)   # from 1980 to 2020 by 10\npop = array([984.736, 1148.364, 1263.638, 1330.141])\n\nIt’s convenient to measure time in years since 1980.\n\nt = year - 1980\ny = pop\n\nNow we have four data points (t_1,y_1),\\dots,(t_4,y_4), so n=4 and we seek an interpolating cubic polynomial. We construct the associated Vandermonde matrix:\n\nV = vander(t)\nprint(V)\n\nTo solve a linear system \\mathbf{V} \\mathbf{c} = \\mathbf{y} for the vector of polynomial coefficients, we use solve (imported from numpy.linalg):\n\nc = linalg.solve(V, y)\nprint(c)\n\nThe algorithms used by solve are the main topic of this chapter. As a check on the solution, we can compute the residual \\mathbf{y} - \\mathbf{V} \\mathbf{c}, which should be small (near machine precision).\n\nTip\n\nMatrix multiplication in NumPy is done with @ or matmul.\n\nprint(y - V @ c)\n\nBy our definitions, the coefficients in c are given in descending order of power in t. We can use the resulting polynomial to estimate the population of China in 2005:\n\np = poly1d(c)          # construct a polynomial\nprint(p(2005 - 1980))     # apply the 1980 time shift\n\nThe official figure was 1303.72, so our result is rather good.\n\nWe can visualize the interpolation process. First, we plot the data as points. Then we add a plot of the interpolant, taking care to shift the t variable back to actual years.\n\nscatter(year, y, color=\"k\", label=\"data\");\ntt = linspace(0, 30, 300)   # 300 times from 1980 to 2010\nplot(1980 + tt, p(tt), label=\"interpolant\");\nxlabel(\"year\");\nylabel(\"population (millions)\");\ntitle(\"Population of China\");\nlegend();","type":"content","url":"/chapter2-2#id-2-1","position":7},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.2 Computing with matrices","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-2","position":8},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.2 Computing with matrices","lvl2":"Examples"},"content":"Example 2.2.1\n\nNote\n\nWhile NumPy does have distinct representations for matrices and 2D arrays, use of the explicit matrix class is officially discouraged. We follow this advice here and use arrays to represent both matrices and vectors. :::{index}\nsee: Python; size, Python; shape\n::: \n\nA vector is created using square brackets and commas to enclose and separate its entries.\n\nx = array([3, 3, 0, 1, 0 ])\nprint(x.shape)\n\nTo construct a matrix, you nest the brackets to create a “vector of vectors”. The inner vectors are the rows.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    [pi, sqrt(2), exp(1), (1+sqrt(5))/2, log(3)] \n    ])\n\nprint(A)\nprint(A.shape)\n\nIn this text, we treat all vectors as equivalent to matrices with a single column. That isn’t true in NumPy, because even an n \\times 1 array has two dimensions, unlike a vector.\n\narray([[3], [1], [2]]).shape\n\nYou can concatenate arrays with compatible dimensions using hstack and vstack.\n\nprint( hstack([A, A]) )\n\nprint( vstack([A, A]) )\n\nTransposing a matrix is done by appending .T to it.\n\nprint(A.T)\n\nFor matrices with complex values, we usually want instead the adjoint or hermitian, which is .conj().T.\n\nprint((x + 1j).conj().T)\n\nThere are many convenient shorthand ways of building vectors and matrices other than entering all of their entries directly or in a loop. To get a vector with evenly spaced entries between two endpoints, you have two options.\n\nprint(arange(1, 7, 2))   # from 1 to 7 (not inclusive), step by 2\n\nprint(linspace(-1, 1, 5))   # from -1 to 1 (inclusive), with 5 total values\n\nThe practical difference between these is whether you want to specify the step size in arange or the number of points in linspace.\n\nAccessing an element is done by giving one (for a vector) or two index values in square brackets. In Python, indexing always starts with zero, not 1.\n\nA = array([ \n    [1, 2, 3, 4, 5],\n    [50, 40, 30, 20, 10], \n    linspace(-5, 5, 5) \n    ])\nx = array([3, 2, 0, 1, -1 ])\n\nprint(\"row 2, col 3 of A:\", A[1, 2])\nprint(\"first element of x:\", x[0])\n\nThe indices can be ranges, in which case a slice or block of the matrix is accessed. You build these using a colon in the form start:stop. However, the last value of this range is stop-1, not stop.\n\nprint(A[1:3, 0:2])    # rows 2 and 3, cols 1 and 2\n\nIf start or stop is omitted, the range extends to the first or last index.\n\nprint(x[1:])  # elements 2 through the end\n\nprint(A[:2, 0])  # first two rows in column 1\n\nNotice in the last case above that even when the slice is in the shape of a column vector, the result is just a vector with one dimension and neither row nor column shape.\n\nThere are more variations on the colon ranges. A negative value means to count from the end rather than the beginning. And a colon by itself means to include everything from the relevant dimension.\n\nprint(A[:-1, :])    # all rows up to the last, all columns\n\nFinally, start:stop:step means to step size or stride other than one. You can mix this with the other variations.\n\nprint(x[::2])  # all the odd indexes\n\nprint(A[:, ::-1])  # reverse the columns\n\nThe matrix and vector senses of addition, subtraction, and scalar multiplication and division are all handled by the usual symbols. Two matrices of the same size (what NumPy calls shape) are operated on elementwise.\n\nprint(A - 2 * ones([3, 5]))  # subtract two from each element\n\nIf one operand has a smaller number of dimensions than the other, Python tries to broadcast it in the “missing” dimension(s), and the operation proceeds if the resulting shapes are identical.\n\nprint(A - 2)    # subtract two from each element\n\nu = array([1, 2, 3, 4, 5])\nprint(A - u)    # repeat this row for every row of A\n\nv = array([1, 2, 3])\nprint(A - v)  # broadcasting this would be 3x3, so it's an error\n\nprint(A - v.reshape([3, 1]))    # broadcasts to each column of A ```{index} \nsee: Python; matrix multiplication, Python; \\@\n``` \n\nMatrix–matrix and matrix–vector products are computed using @ or matmul.\n\nB = diag([-1, 0, -5])    # create a diagonal 3x3\nprint(B @ A)    # matrix product\n\nAB is undefined for these matrix sizes.\n\nprint(A @ B)    # incompatible sizes\n\nThe multiplication operator * is reserved for elementwise multiplication. Both operands have to be the same size, after any potential broadcasts.\n\nprint(B * A)    # not the same size, so it's an error\n\nprint((A / 2) * A)    # elementwise\n\nTo raise to a power elementwise, use a double star. This will broadcast as well.\n\nprint(B)\nprint(B**3)\n\nprint(x)\nprint(2.0**x)\n\nDanger\n\nIf A is a matrix, A**2 is not the same as mathematically raising it to the power 2.\n\nMost of the mathematical functions, such as cos, sin, log, exp and sqrt, expecting scalars as operands will be broadcast to arrays.\n\nprint(cos(pi * x))","type":"content","url":"/chapter2-2#id-2-2","position":9},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.3 Linear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-3","position":10},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.3 Linear systems","lvl2":"Examples"},"content":"Example 2.3.2\n\nFor a square matrix A, the command solve(A, B) from numpy.linalg is mathematically equivalent to \\mathbf{A}^{-1} \\mathbf{b}.\n\nA = array([[1, 0, -1], [2, 2, 1], [-1, -3, 0]])\nb = array([1, 2, 3])\n\nx = linalg.solve(A, b)\nprint(x)\n\nOne way to check the answer is to compute a quantity known as the residual. It is (ideally) close to machine precision(relative to the elements in the data).\n\nresidual = b - A @ x\nprint(residual)\n\nIf the matrix \\mathbf{A} is singular, you may get an error.\n\nA = array([[0, 1], [0, 0]])\nb = array([1, -1])\nlinalg.solve(A, b)    # error, singular matrix\n\nA linear system with a singular matrix might have no solution or infinitely many solutions, but in either case, a numerical solution becomes trickier. Detecting singularity is a lot like checking whether two floating-point numbers are exactly equal: because of roundoff, it could be missed. We’re headed toward a more robust way to fully describe this situation.\n\nExample 2.3.3\n\nIt’s easy to get just the lower triangular part of any matrix using the tril function.\n\nA = 1 + floor(9 * random.rand(5, 5))\nL = tril(A)\nprint(L)\n\nWe’ll set up and solve a linear system with this matrix.\n\nb = ones(5)\nx = FNC.forwardsub(L, b)\nprint(x)\n\nIt’s not clear how accurate this answer is. However, the residual should be zero or comparable to \\macheps.\n\nb - L @ x\n\nNext we’ll engineer a problem to which we know the exact answer.\n\nalpha = 0.3;\nbeta = 2.2;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nprint(U)\n\nx_exact = ones(5)\nb = array([alpha, 0, 0, 0, 1])\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nEverything seems OK here. But another example, with a different value for β, is more troubling.\n\nalpha = 0.3;\nbeta = 1e12;\nU = diag(ones(5)) + diag([-1, -1, -1, -1], k=1)\nU[0, 3:5] = [ alpha - beta, beta ]\nb = array([alpha, 0, 0, 0, 1])\n\nx = FNC.backsub(U, b)\nprint(\"error:\", x - x_exact)\n\nIt’s not so good to get 4 digits of accuracy after starting with sixteen! But the source of the error is not hard to track down. Solving for x_1 performs (\\alpha-\\beta)+\\beta in the first row. Since |\\alpha| is so much smaller than |\\beta|, this a recipe for losing digits to subtractive cancellation.","type":"content","url":"/chapter2-2#id-2-3","position":11},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.4 LU factorization","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-4","position":12},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.4 LU factorization","lvl2":"Examples"},"content":"Example 2.4.2\n\nWe explore the outer product formula for two random triangular matrices.\n\nfrom numpy.random import randint\nL = tril(randint(1, 10, size=(3, 3)))\nprint(L)\n\nU = triu(randint(1, 10, size=(3, 3)))\nprint(U)\n\nHere are the three outer products appearing in the sum in \n\n(2.4.4):\n\nprint(outer(L[:, 0], U[0, :]))\n\nprint(outer(L[:, 1], U[1, :]))\n\nprint(outer(L[:, 2], U[2, :]))\n\nSimply because of the triangular zero structures, only the first outer product contributes to the first row and first column of the entire product.\n\nExample 2.4.3\n\nFor illustration, we work on a 4 \\times 4 matrix. We name it with a subscript in preparation for what comes.\n\nA_1 = array([\n     [2,    0,    4,    3], \n     [-4,    5,   -7,  -10], \n     [1,   15,    2,   -4.5],\n     [-2,    0,    2,  -13]\n        ])\nL = eye(4)\nU = zeros((4, 4));\n\nNow we appeal to \n\n(2.4.5). Since L_{11}=1, we see that the first row of \\mathbf{U} is just the first row of \\mathbf{A}_1.\n\nU[0, :] = A_1[0, :]\nprint(U)\n\nFrom \n\n(2.4.6), we see that we can find the first column of \\mathbf{L} from the first column of \\mathbf{A}_1.\n\nL[:, 0] = A_1[:, 0] / U[0, 0]\nprint(L)\n\nWe have obtained the first term in the sum \n\n(2.4.4) for \\mathbf{L}\\mathbf{U}, and we subtract it away from \\mathbf{A}_1.\n\nA_2 = A_1 - outer(L[:, 0],  U[0, :])\n\nNow \\mathbf{A}_2 = \\boldsymbol{\\ell}_2\\mathbf{u}_2^T + \\boldsymbol{\\ell}_3\\mathbf{u}_3^T + \\boldsymbol{\\ell}_4\\mathbf{u}_4^T. If we ignore the first row and first column of the matrices in this equation, then in what remains we are in the same situation as at the start. Specifically, only \\boldsymbol{\\ell}_2\\mathbf{u}_2^T has any effect on the second row and column, so we can deduce them now.\n\nU[1, :] = A_2[1, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nprint(L)\n\nIf we subtract off the latest outer product, we have a matrix that is zero in the first two rows and columns.\n\nA_3 = A_2 - outer(L[:, 1], U[1, :])\n\nNow we can deal with the lower right 2\\times 2 submatrix of the remainder in a similar fashion.\n\nU[2, :] = A_3[2, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\n\nFinally, we pick up the last unknown in the factors.\n\nU[3, 3] = A_4[3, 3]\n\nWe now have all of \\mathbf{L},\n\nprint(L)\n\nand all of \\mathbf{U},\n\nprint(U)\n\nWe can verify that we have a correct factorization of the original matrix by computing the backward error:\n\nA_1 - L @ U\n\nIn floating point, we cannot expect the difference to be exactly zero as we found in this toy example. Instead, we would be satisfied to see that each element of the difference above is comparable in size to machine precision.\n\nExample 2.4.4\n\nHere are the data for a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nA = array([\n    [2, 0, 4, 3], \n    [-4, 5, -7, -10], \n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nb = array([4, 9, 9, 4])\n\nWe apply \n\nFunction 2.4.1 and then do two triangular solves.\n\nL, U = FNC.lufact(A)\nz = FNC.forwardsub(L, b)\nx = FNC.backsub(U, z)\n\nA check on the residual assures us that we found the solution.\n\nb - A @ x","type":"content","url":"/chapter2-2#id-2-4","position":13},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.5 Efficiency of matrix computations","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-5","position":14},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.5 Efficiency of matrix computations","lvl2":"Examples"},"content":"Example 2.5.4\n\nHere is a straightforward implementation of matrix-vector multiplication.\n\nn = 6\nA = random.rand(n, n)\nx = ones(n)\ny = zeros(n)\nfor i in range(n):\n    for j in range(n):\n        y[i] += A[i, j] * x[j]   # 2 flops\n\nEach of the loops implies a summation of flops. The total flop count for this algorithm is\\sum_{i=1}^n \\sum_{j=1}^n 2 = \\sum_{i=1}^n 2n = 2n^2.\n\nSince the matrix \\mathbf{A} has n^2 elements, all of which have to be involved in the product, it seems unlikely that we could get a flop count that is smaller than O(n^2) in general.\n\nLet’s run an experiment with the built-in matrix-vector multiplication. We assume that flops dominate the computation time and thus measure elapsed time.\n\nN = 400 * arange(1, 11)\nt = []\nprint(\"  n           t\")\nfor i, n in enumerate(N):\n    A = random.randn(n, n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(50): A @ x\n    t.append(timer() - start)\n    print(f\"{n:5}   {t[-1]:10.3e}\")\n\nThe reason for doing multiple repetitions at each value of n above is to avoid having times so short that the resolution of the timer is a factor.\n\nLooking at the timings just for n=2000 and n=4000, they have ratio:\n\nprint(t[9] / t[4])\n\nIf the run time is dominated by flops, then we expect this ratio to be\\frac{2(4000)^2}{2(2000)^2}=4.\n\nExample 2.5.5\n\nLet’s repeat the experiment of the previous example for more, and larger, values of n.\n\nN = arange(400, 6200, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    x = random.randn(n)\n    start = timer()\n    for j in range(20): A@x\n    t[i] = timer() - start\n\nPlotting the time as a function of n on log-log scales is equivalent to plotting the logs of the variables, but is formatted more neatly.\n\nfig, ax = subplots()\nax.loglog(N, t, \"-o\", label=\"observed\")\nylabel(\"elapsed time (sec)\");\nxlabel(\"$n$\");\ntitle(\"Timing of matrix-vector multiplications\");\n\nYou can see that while the full story is complicated, the graph is trending to a straight line of positive slope. For comparison, we can plot a line that represents O(n^2) growth exactly. (All such lines have slope equal to 2.)\n\nax.loglog(N, t[-1] * (N/N[-1])**2, \"--\", label=\"$O(n^2)$\")\nax.legend();  fig\n\nExample 2.5.6\n\nWe’ll test the conclusion of O(n^3) flops experimentally using the lu function imported from scipi.linalg.\n\nfrom scipy.linalg import lu\nN = arange(200, 2600, 200)\nt = zeros(len(N))\nfor i, n in enumerate(N):\n    A = random.randn(n,n)  \n    start = timer()\n    for j in range(5): lu(A)\n    t[i] = timer() - start\n\nWe plot the timings on a log-log graph and compare it to O(n^3). The result could vary significantly from machine to machine, but in theory the data should start to parallel the line as n\\to\\infty.\n\nloglog(N, t, \"-o\", label=\"obseved\")\nloglog(N, t[-1] * (N / N[-1])**3, \"--\", label=\"$O(n^3)$\")\nlegend();\nxlabel(\"$n$\");\nylabel(\"elapsed time (sec)\");\ntitle(\"Timing of LU factorizations\");","type":"content","url":"/chapter2-2#id-2-5","position":15},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.6 Row pivoting","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-6","position":16},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.6 Row pivoting","lvl2":"Examples"},"content":"Example 2.6.1\n\nHere is a previously encountered matrix that factors well.\n\nA = array([\n    [2, 0, 4, 3],\n    [-4, 5, -7, -10],\n    [1, 15, 2, -4.5],\n    [-2, 0, 2, -13]\n    ])\nL, U = FNC.lufact(A)\nprint(L)\n\nIf we swap the second and fourth rows of \\mathbf{A}, the result is still nonsingular. However, the factorization now fails.\n\nA[[1, 3], :] = A[[3, 1], :]  \nL, U = FNC.lufact(A)\nprint(L)\n\nThe presence of NaN in the result indicates that some impossible operation was required. The source of the problem is easy to locate. We can find the first outer product in the factorization just fine:\n\nU[0, :] = A[0, :]\nL[:, 0] = A[:, 0] / U[0, 0]\nA -= outer(L[:, 0],  U[0, :])\nprint(A)\n\nThe next step is U[1, :] = A[1, :], which is also OK. But then we are supposed to divide by U[1, 1], which is zero. The algorithm cannot continue.\n\nExample 2.6.2\n\nHere is the trouble-making matrix from \n\nDemo 2.6.1.\n\nA_1 = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nWe now find the largest candidate pivot in the first column. We don’t care about sign, so we take absolute values before finding the max.\n\nTip\n\nThe argmax function returns the location of the largest element of a vector or matrix.\n\ni = argmax( abs(A_1[:, 0]) )\nprint(i)\n\nThis is the row of the matrix that we extract to put into \\mathbf{U}. That guarantees that the division used to find \\boldsymbol{\\ell}_1 will be valid.\n\nL, U = eye(4), zeros((4, 4))\nU[0, :] = A_1[i, :]\nL[:, 0] = A_1[:, 0] / U[0, 0]\nA_2 = A_1 - outer(L[:, 0], U[0, :])\nprint(A_2)\n\nObserve that \\mathbf{A}_2 has a new zero row and zero column, but the zero row is the fourth rather than the first. However, we forge on by using the largest possible pivot in column 2 for the next outer product.\n\ni = argmax( abs(A_2[:, 1]) ) \nprint(f\"new pivot row is {i}\")\nU[1, :] = A_2[i, :]\nL[:, 1] = A_2[:, 1] / U[1, 1]\nA_3 = A_2 - outer(L[:, 1], U[1, :])\nprint(A_3)\n\nNow we have zeroed out the third row as well as the second column. We can finish out the procedure.\n\ni = argmax( abs(A_3[:, 2]) ) \nprint(f\"new pivot row is {i}\")\nU[2, :] = A_3[i, :]\nL[:, 2] = A_3[:, 2] / U[2, 2]\nA_4 = A_3 - outer(L[:, 2], U[2, :])\nprint(A_4)\n\ni = argmax( abs(A_4[:, 3]) ) \nprint(f\"new pivot row is {i}\")\nU[3, :] = A_4[i, :]\nL[:, 3] = A_4[:, 3] / U[3, 3];\n\nWe do have a factorization of the original matrix:\n\nA_1 - L @ U\n\nAnd \\mathbf{U} has the required structure:\n\nprint(U)\n\nHowever, the triangularity of \\mathbf{L} has been broken.\n\nprint(L)\n\nExample 2.6.3\n\nHere again is the matrix from \n\nDemo 2.6.2.\n\nA = array([\n    [2, 0, 4, 3],\n    [-2, 0, 2, -13],\n    [1, 15, 2, -4.5],\n    [-4, 5, -7, -10]\n    ])\n\nAs the factorization proceeded, the pivots were selected from rows 4, 3, 2, and finally 1 (with NumPy indices being one less). If we were to put the rows of \\mathbf{A} into that order, then the algorithm would run exactly like the plain LU factorization from \n\nLU factorization.\n\nB = A[[3, 2, 1, 0], :]\nL, U = FNC.lufact(B);\n\nWe obtain the same \\mathbf{U} as before:\n\nprint(U)\n\nAnd \\mathbf{L} has the same rows as before, but arranged into triangular order:\n\nprint(L)\n\nExample 2.6.4\n\nThe third output of plufact is the permutation vector we need to apply to \\mathbf{A}.\n\nA = random.randn(4, 4)\nL, U, p = FNC.plufact(A)\nA[p, :] - L @ U   # should be ≈ 0\n\nGiven a vector \\mathbf{b}, we solve \\mathbf{A}\\mathbf{x}=\\mathbf{b} by first permuting the entries of \\mathbf{b} and then proceeding as before.\n\nb = random.randn(4)\nz = FNC.forwardsub(L, b[p])\nx = FNC.backsub(U, z)\n\nA residual check is successful:\n\nb - A @ x\n\nExample 2.6.5\n\nIn linalg.solve, the matrix A is PLU-factored, followed by two triangular solves. If we want to do those steps seamlessly, we can use the lu_factor and lu_solve from scipy.linalg.\n\nfrom scipy.linalg import lu_factor, lu_solve\nA = random.randn(500, 500) \nb = ones(500)  \nLU, perm = lu_factor(A)\nx = lu_solve((LU, perm), b)\n\nWhy would we ever bother with this? In \n\nEfficiency of matrix computations we showed that the factorization is by far the most costly part of the solution process. A factorization object allows us to do that costly step only once per matrix, but solve with multiple right-hand sides.\n\nstart = timer()\nfor k in range(50): linalg.solve(A, random.rand(500))\nprint(f\"elapsed time for 50 full solves: {timer() - start}\")\n\nstart = timer()\nLU, perm = lu_factor(A)\nfor k in range(50): lu_solve((LU, perm), random.rand(500))\nprint(f\"elapsed time for 50 shortcut solves: {timer() - start}\")\n\nExample 2.6.6\n\nWe construct a linear system for this matrix with \\epsilon=10^{-12} and exact solution [1,1]:\n\nep = 1e-12\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\n\nWe can factor the matrix without pivoting and solve for \\mathbf{x}.\n\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nNote that we have obtained only about 5 accurate digits for x_1. We could make the result even more inaccurate by making ε even smaller:\n\nep = 1e-20;\nA = array([[-ep, 1], [1, -1]])\nb = A @ array([1, 1])\nL, U = FNC.lufact(A)\nprint(FNC.backsub( U, FNC.forwardsub(L, b) ))\n\nThis effect is not due to ill conditioning of the problem—a solution with PLU factorization works perfectly:\n\nprint(linalg.solve(A, b))","type":"content","url":"/chapter2-2#id-2-6","position":17},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.7 Vector and matrix norms","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-7","position":18},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.7 Vector and matrix norms","lvl2":"Examples"},"content":"Example 2.7.1\n\nThe norm function from numpy.linalg computes vector norms.\n\nfrom numpy.linalg import norm\nx = array([2, -3, 1, -1])\nprint(norm(x))       # 2-norm by default\n\nprint(norm(x, inf))\n\nprint(norm(x, 1))\n\nExample 2.7.2\n\nfrom numpy.linalg import norm\nA = array([ [2, 0], [1, -1] ])\n\nThe default matrix norm is not the 2-norm. Instead, you must provide the 2 explicitly.\n\nprint(norm(A, 2))\n\nYou can get the 1-norm as well.\n\nprint(norm(A, 1))\n\nThe 1-norm is equivalent to\n\nprint(max( sum(abs(A), axis=0)) )  # sum down the rows\n\nSimilarly, we can get the ∞-norm and check our formula for it.\n\nprint(norm(A, inf))\n\nprint(max( sum(abs(A), axis=1)) )  # sum across columns\n\nHere we illustrate the geometric interpretation of the 2-norm. First, we will sample a lot of vectors on the unit circle in \\mathbb{R}^2.\n\ntheta = linspace(0, 2*pi, 601)\nx = vstack([cos(theta), sin(theta)])  # 601 unit columns\n\nThe linear function \\mathbf{f}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} defines a mapping from \\mathbb{R}^2 to \\mathbb{R}^2. We can apply A to every column of x simply by using a matrix multiplication.\n\ny = A @ x\n\nWe plot the unit circle on the left and the image of all mapped vectors on the right:\n\nsubplot(1,2,1)\nplot(x[0, :], x[1, :])\naxis(\"equal\")\ntitle(\"Unit circle\")\nxlabel(\"$x_1$\")\nylabel(\"$x_2$\")\n\nsubplot(1,2,2)\nplot(y[0, :], y[1, :])\nplot(norm(A, 2) * x[0, :], norm(A,2) * x[1, :],\"--\")\naxis(\"equal\")\ntitle(\"Image under map\")\nxlabel(\"$y_1$\")\nylabel(\"$y_2$\");\n\nAs seen on the right-side plot, the image of the transformed vectors is an ellipse that just touches the circle of radius \\|\\mathbf{A}\\|_2.","type":"content","url":"/chapter2-2#id-2-7","position":19},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.8 Conditioning of linear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-8","position":20},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.8 Conditioning of linear systems","lvl2":"Examples"},"content":"Example 2.8.1\n\nThe function cond from numpy.linalg is used to computes matrix condition numbers. By default, the 2-norm is used. As an example, the family of Hilbert matrices is famously badly conditioned. Here is the 6\\times 6  case.\n\nA = array([ \n    [1/(i + j + 2) for j in range(6)] \n    for i in range(6) \n    ])\nprint(A)\n\nfrom numpy.linalg import cond\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nNext we engineer a linear system problem to which we know the exact answer.\n\nx_exact = 1.0 + arange(6)\nb = A @ x_exact\n\nNow we perturb the data randomly with a vector of norm \n\n10-12.\n\ndA = random.randn(6, 6)\ndA = 1e-12 * (dA / norm(dA, 2))\ndb = random.randn(6)\ndb = 1e-12 * (db / norm(db, 2))\n\nWe solve the perturbed problem using built-in pivoted LU and see how the solution was changed.\n\nx = linalg.solve(A + dA, b + db) \ndx = x - x_exact\n\nHere is the relative error in the solution.\n\nprint(f\"relative error is {norm(dx) / norm(x_exact):.2e}\")\n\nAnd here are upper bounds predicted using the condition number of the original matrix.\n\nprint(f\"b_bound: {kappa * 1e-12 / norm(b):.2e}\")\nprint(f\"A_bound: {kappa * 1e-12 / norm(A, 2):.2e}\")\n\nEven if we don’t make any manual perturbations to the data, machine epsilon does when we solve the linear system numerically.\n\nx = linalg.solve(A, b)\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nBecause \\kappa\\approx 10^8, it’s possible to lose 8 digits of accuracy in the process of passing from A and b to x. That’s independent of the algorithm; it’s inevitable once the data are expressed in double precision.\n\nLarger Hilbert matrices are even more poorly conditioned.\n\nA = array([ [1/(i+j+2) for j in range(14)] for i in range(14) ])\nkappa = cond(A)\nprint(f\"kappa is {kappa:.3e}\")\n\nBefore we compute the solution, note that κ exceeds 1/eps. In principle we therefore might end up with an answer that is completely wrong (i.e., a relative error greater than 100%).\n\nprint(f\"rounding bound: {kappa / 2**52:.2e}\")\n\nx_exact = 1.0 + arange(14)\nb = A @ x_exact  \nx = linalg.solve(A, b)\n\nWe got an answer. But in fact, the error does exceed 100%:\n\nprint(f\"relative error: {norm(x - x_exact) / norm(x_exact):.2e}\")","type":"content","url":"/chapter2-2#id-2-8","position":21},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.9 Exploiting matrix structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter2-2#id-2-9","position":22},{"hierarchy":{"lvl1":"Chapter 2","lvl3":"2.9 Exploiting matrix structure","lvl2":"Examples"},"content":"Example 2.9.1\n\nHere is a matrix with both lower and upper bandwidth equal to one. Such a matrix is called tridiagonal.\n\nA = array([ \n    [2, -1,  0,  0,  0,  0],\n    [4,  2, -1,  0,  0,  0],\n    [0,  3,  0, -1,  0,  0],\n    [0,  0,  2,  2, -1,  0],\n    [0,  0,  0,  1,  1, -1],\n    [0,  0,  0,  0,  0,  2 ]\n    ])\n\nWe can extract the elements on any diagonal using the diag command. The “main” or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nprint( diag(A) )\n\nprint( diag(A, 1) )\n\nprint( diag(A, -1) )\n\nWe can also construct matrices by specifying a diagonal with the diag function.\n\nA = A + diag([pi, 8, 6, 7], 2)\nprint(A)\n\nL, U = FNC.lufact(A)\nprint(L)\n\nprint(U)\n\nObserve above that the lower and upper bandwidths of \\mathbf{A} are preserved in the factor matrices.\n\nExample 2.9.2\n\nWe begin with a symmetric \\mathbf{A}.\n\nA_1 = array([\n    [2,     4,     4,     2],\n    [4,     5,     8,    -5],\n    [4,     8,     6,     2],\n    [2,    -5,     2,   -26]\n    ])\n\nWe won’t use pivoting, so the pivot element is at position (1,1). This will become the first element on the diagonal of \\mathbf{D}. Then we divide by that pivot to get the first column of \\mathbf{L}.\n\nL = eye(4)\nd = zeros(4)\nd[0] = A_1[0, 0]\nL[:, 0] = A_1[:, 0] / d[0]\nA_2 = A_1 - d[0] * outer(L[:, 0], L[:, 0])\nprint(A_2)\n\nWe are now set up the same way for the submatrix in rows and columns 2–4.\n\nd[1] = A_2[1, 1]\nL[:, 1] = A_2[:, 1] / d[1]\nA_3 = A_2 - d[1] * outer(L[:, 1], L[:, 1])\nprint(A_3)\n\nWe continue working our way down the diagonal.\n\nd[2] = A_3[2, 2]\nL[:, 2] = A_3[:, 2] / d[2]\nA_4 = A_3 - d[2] * outer(L[:, 2], L[:, 2])\nprint(A_4)\n\nWe have arrived at the desired factorization.\n\nd[3] = A_4[3, 3]\nprint(\"diagonal of D:\")\nprint(d)\nprint(\"L:\")\nprint(L)\n\nThis should be comparable to machine roundoff:\n\nprint(norm(A_1 - (L @ diag(d) @ L.T), 2) / norm(A_1))\n\nExample 2.9.3\n\nA randomly chosen matrix is extremely unlikely to be symmetric. However, there is a simple way to symmetrize one.\n\nA = 1.0 + floor(9 * random.rand(4, 4))\nB = A + A.T\nprint(B)\n\nSimilarly, a random symmetric matrix is unlikely to be positive definite. The Cholesky algorithm always detects a non-PD matrix by quitting with an error.\n\nfrom numpy.linalg import cholesky\ncholesky(B)    # raises an exception, not positive definite\n\nIt’s not hard to manufacture an SPD matrix to try out the Cholesky factorization:\n\nB = A.T @ A\nR = cholesky(B)\nprint(R)\n\nprint(norm(R @ R.T - B) / norm(B))","type":"content","url":"/chapter2-2#id-2-9","position":23},{"hierarchy":{"lvl1":"Chapter 3"},"type":"lvl1","url":"/chapter3-2","position":0},{"hierarchy":{"lvl1":"Chapter 3"},"content":"","type":"content","url":"/chapter3-2","position":1},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"type":"lvl2","url":"/chapter3-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Functions"},"content":"Solution of least squares by the normal equations\n\ndef lsnormal(A, b):\n    \"\"\"\n    lsnormal(A, b)\n    \n    Solve a linear least squares problem by the normal equations. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    N = A.T @ A\n    z = A.T @ b\n    R = scipy.linalg.cholesky(N)\n    w = forwardsub(R.T, z)                   # solve R'z=c\n    x = backsub(R, w)                        # solve Rx=z\n    return x\n\nAbout the code\n\ncholesky is imported from scipy.linalg.\n\nSolution of least squares by QR factorization\n\ndef lsqrfact(A, b):\n    \"\"\"\n    lsqrfact(A, b)\n    \n    Solve a linear least squares problem by QR factorization. Returns the\n    minimizer of ||b-Ax||.\n    \"\"\"\n    Q, R = np.linalg.qr(A)\n    c = Q.T @ b\n    x = backsub(R, c)\n    return x\n\nQR factorization by Householder reflections\n\ndef qrfact(A):\n    \"\"\"\n        qrfact(A)\n\n    QR factorization by Householder reflections. Returns Q and R.\n    \"\"\"\n    m, n = A.shape\n    Qt = np.eye(m)\n    R = np.copy(A)\n    for k in range(n):\n        z = R[k:, k]\n        w = np.hstack((-np.sign(z[0]) * np.linalg.norm(z) - z[0], -z[1:]))\n        nrmw = np.linalg.norm(w)\n        if nrmw < np.finfo(float).eps: continue    # skip this iteration\n        v = w / nrmw\n        # Apply the reflection to each relevant column of R and Q\n        for j in range(k, n):\n            R[k:, j] -= 2 * np.dot(v, R[k:, j]) * v\n        for j in range(m):\n            Qt[k:, j] -= 2 * np.dot(v, Qt[k:, j]) * v \n    return Qt.T, np.triu(R)","type":"content","url":"/chapter3-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"type":"lvl2","url":"/chapter3-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 3","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter3-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.1 Fitting functions to data","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#id-3-1","position":6},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.1 Fitting functions to data","lvl2":"Examples"},"content":"Example 3.1.1\n\nHere are 5-year averages of the worldwide temperature anomaly as compared to the 1951–1980 average (source: NASA).\n\nyear = arange(1955,2005,5)\ny = array([ -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560 ])\n\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\n\nA polynomial interpolant can be used to fit the data. Here we build one using a Vandermonde matrix. First, though, we express time as decades since 1950, as it improves the condition number of the matrix.\n\nt = (year - 1950) / 10\nV = vander(t)\nc = linalg.solve(V, y)\nprint(c)\n\nThe coefficients in vector c are used to create a polynomial. Then we create a function that evaluates the polynomial after changing the time variable as we did for the Vandermonde matrix.\n\np = poly1d(c)    # convert to a polynomial\ntt = linspace(1955, 2000, 500)\nax.plot(tt, p((tt - 1950) / 10), label=\"interpolant\")\nax.legend();\nfig\n\nAs you can see, the interpolant does represent the data, in a sense. However it’s a crazy-looking curve for the application. Trying too hard to reproduce all the data exactly is known as overfitting.\n\nExample 3.1.2\n\nHere are the 5-year temperature averages again.\n\nyear = arange(1955, 2005, 5)\ny = array([-0.0480, -0.0180, -0.0360, -0.0120, -0.0040,\n    0.1180, 0.2100, 0.3320, 0.3340, 0.4560])\nt = (year - 1950) / 10\n\nThe standard best-fit line results from using a linear polynomial that meets the least-squares criterion.\n\nTip\n\nBackslash solves overdetermined linear systems in a least-squares sense.\n\nV = array([ [t[i], 1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nfrom numpy.linalg import lstsq\nc, res, rank, sv = lstsq(V, y)\np = poly1d(c)\nf = lambda year: p((year - 1950) / 10)\n```{code-cell}\nfig, ax = subplots()\nax.scatter(year, y, color=\"k\", label=\"data\")\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"linear fit\")\n\nxlabel(\"year\")\nylabel(\"anomaly (degrees C)\")\ntitle(\"World temperature anomaly\");\nax.legend();\n\nIf we use a global cubic polynomial, the points are fit more closely.\n\nV = array([ [t[i]**3,t[i]**2,t[i],1] for i in range(t.size) ])    # Vandermonde-ish matrix\nprint(V.shape)\n\nNow we solve the new least-squares problem to redefine the fitting polynomial.\n\nTip\n\nThe definition of f above is in terms of c. When c is changed, f is updated with it.\n\nc, res, rank, sv = lstsq(V, y, rcond=None)\nyr = linspace(1955, 2000, 500)\nax.plot(yr, f(yr), label=\"cubic fit\")\nfig\n\nIf we were to continue increasing the degree of the polynomial, the residual at the data points would get smaller, but overfitting would increase.\n\nExample 3.1.3\n\na = array([1 / (k+1)**2 for k in range(100)])\ns = cumsum(a)        # cumulative summation\np = sqrt(6*s)\n\nplot(range(100), p, \"o\")\nxlabel(\"$k$\") \nylabel(\"$p_k$\") \ntitle(\"Sequence convergence\");\n\nThis graph suggests that maybe p_k\\to \\pi, but it’s far from clear how close the sequence gets. It’s more informative to plot the sequence of errors, \\epsilon_k= |\\pi-p_k|. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship.\n\nep = abs(pi - p)    # error sequence\nloglog(range(100), ep, \"o\")\nxlabel(\"$k$\") \nylabel(\"error\") \ntitle(\"Sequence convergence\");\n\nThe straight line on the log-log scale suggests a power-law relationship where \\epsilon_k\\approx a k^b, or \\log \\epsilon_k \\approx b (\\log k) + \\log a.\n\nV = array([ [1, log(k+1)] for k in range(100) ])     # fitting matrix\nc = lstsq(V, log(ep), rcond=None)[0]           # coefficients of linear fit\nprint(c)\n\nIn terms of the parameters a and b used above, we have\n\na, b = exp(c[0]), c[1]\nprint(f\"b: {b:.3f}\")\n\nIt’s tempting to conjecture that the slope b\\to -1 asymptotically. Here is how the numerical fit compares to the original convergence curve.\n\nloglog(range(100), ep, \"o\", label=\"sequence\")\nk = arange(1,100)\nplot(k, a*k**b, \"--\", label=\"power fit\")\nxlabel(\"$k$\");  ylabel(\"error\"); \nlegend(); title(\"Sequence convergence\");","type":"content","url":"/chapter3-2#id-3-1","position":7},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.2 The normal equations","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#id-3-2","position":8},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.2 The normal equations","lvl2":"Examples"},"content":"Example 3.2.1\n\nBecause the functions \\sin^2(t), \\cos^2(t), and 1 are linearly dependent, we should find that the following matrix is somewhat ill-conditioned.\n\nfrom numpy.linalg import cond\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nkappa = cond(A)\nprint(f\"cond(A) is {kappa:.3e}\")\n\nNow we set up an artificial linear least-squares problem with a known exact solution that actually makes the residual zero.\n\nx = array([1, 2, 1])\nb = A @ x\n\nUsing backslash to find the least-squares solution, we get a relative error that is well below κ times machine epsilon.\n\nfrom numpy.linalg import lstsq\nx_BS = lstsq(A, b, rcond=None)[0]\nprint(f\"observed error: {norm(x_BS - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {kappa * finfo(float).eps:.3e}\")\n\nIf we formulate and solve via the normal equations, we get a much larger relative error. With \\kappa^2\\approx 10^{14}, we may not be left with more than about 2 accurate digits.\n\nN = A.T @ A\nx_NE = linalg.solve(N, A.T @ b)\nrelative_err = norm(x_NE - x) / norm(x)\nprint(f\"observed error: {relative_err:.3e}\")\nprint(f\"accurate digits: {-log10(relative_err):.2f}\")","type":"content","url":"/chapter3-2#id-3-2","position":9},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.3 The QR factorization","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#id-3-3","position":10},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.3 The QR factorization","lvl2":"Examples"},"content":"Example 3.3.1\n\nMATLAB provides access to both the thin and full forms of the QR factorization.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nA.shape\n\nHere is the full form:\n\nfrom numpy.linalg import qr\nQ, R = qr(A, \"complete\")\nprint(f\"size of Q is {Q.shape}\")\nprint(\"R:\")\nprint(R)\n\nWe can test that \\mathbf{Q} is an orthogonal matrix:\n\nprint(f\"norm of (Q^T Q - I) is {norm(Q.T @ Q - eye(6)):.3e}\")\n\nThe default for qr, and the one you usually want, is the thin form.\n\nQ_hat, R_hat = qr(A)\nprint(f\"size of Q_hat is {Q_hat.shape}\")\nprint(\"R_hat:\")\nprint(R_hat)\n\nNow \\hat{\\mathbf{Q}} cannot be an orthogonal matrix, because it is not square, but it is still ONC. Mathematically, \\hat{\\mathbf{Q}}^T \\hat{\\mathbf{Q}} is a 4\\times 4 identity matrix.\n\nprint(f\"norm of (Q_hat^T Q_hat - I) is {norm(Q_hat.T @ Q_hat - eye(4)):.3e}\")\n\nExample 3.3.2\n\nWe’ll repeat the experiment of \n\nDemo 3.2.1, which exposed instability in the normal equations.\n\nt = linspace(0, 3, 400)\nA = array([ [sin(t)**2, cos((1+1e-7)*t)**2, 1] for t in t ])\nx = array([1, 2, 1])\nb = A @ x\n\nThe error in the solution by \n\nFunction 3.3.2 is similar to the bound predicted by the condition number.\n\nprint(f\"observed error: {norm(FNC.lsqrfact(A, b) - x) / norm(x):.3e}\")\nprint(f\"conditioning bound: {cond(A) * finfo(float).eps:.3e}\")","type":"content","url":"/chapter3-2#id-3-3","position":11},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.4 Computing QR factorizations","lvl2":"Examples"},"type":"lvl3","url":"/chapter3-2#id-3-4","position":12},{"hierarchy":{"lvl1":"Chapter 3","lvl3":"3.4 Computing QR factorizations","lvl2":"Examples"},"content":"Example 3.4.1\n\nWe will use Householder reflections to produce a QR factorization of a matrix.\n\nA = 1.0 + floor(9 * random.rand(6,4))\nm, n = A.shape\nprint(A)\n\nOur first step is to introduce zeros below the diagonal in column 1 by using \n\n(3.4.4) and \n\n(3.4.1).\n\nz = A[:, 0]\nv = z - norm(z) * hstack([1, zeros(m-1)])\nP_1 = eye(m) - (2 / dot(v, v)) * outer(v, v)   # reflector\n\nWe check that this reflector introduces zeros as it should:\n\nprint(P_1 @ z)\n\nNow we replace \\mathbf{A} by \\mathbf{P}_1\\mathbf{A}.\n\nA = P_1 @ A\nprint(A)\n\nWe are set to put zeros into column 2. We must not use row 1 in any way, lest it destroy the zeros we just introduced. So we leave it out of the next reflector.\n\nz = A[1:, 1]\nv = z - norm(z) * hstack([1, zeros(m-2)])\nP_2 = eye(m-1) - (2 / dot(v, v)) * outer(v, v)\n\nWe now apply this reflector to rows 2 and below only.\n\nA[1:, 1:] = P_2 @ A[1:, 1:]\nprint(A)\n\nWe need to iterate the process for the last two columns.\n\nfor j in [2, 3]:\n    z = A[j:, j]\n    v = z - norm(z) * hstack([1, zeros(m-j-1)])\n    P = eye(m-j) - (2 / dot(v, v)) * outer(v, v)\n    A[j:, j:] = P @ A[j:, j:]\n\nWe have now reduced the original to an upper triangular matrix using four orthogonal Householder reflections:\n\nR = triu(A)\nprint(R)","type":"content","url":"/chapter3-2#id-3-4","position":13},{"hierarchy":{"lvl1":"Chapter 4"},"type":"lvl1","url":"/chapter4-2","position":0},{"hierarchy":{"lvl1":"Chapter 4"},"content":"","type":"content","url":"/chapter4-2","position":1},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"type":"lvl2","url":"/chapter4-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Functions"},"content":"Newton’s method\n\ndef newton(f, dfdx, x1):\n    \"\"\"\n    newton(f, dfdx, x1)\n\n    Use Newton's method to find a root of f starting from x1, where dfdx is the\n    derivative of f. Returns a vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[0] = x1\n    y = f(x1)\n    dx = np.inf  # for initial pass below\n    k = 0\n\n    while (abs(dx) > xtol) and (abs(y) > funtol) and (k < maxiter):\n        dydx = dfdx(x[k])\n        dx = -y / dydx  # Newton step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y = f(x[k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n\n    return x[:k+1]\n\nAbout the code\n\nFunction 4.3.2 accepts keyword arguments. In the function declaration, these follow the semicolon, and when the function is called, they may be supplied as keyword=value in the argument list. Here, these arguments are also given default values by the assignments within the declaration. This arrangement is useful when there are multiple optional arguments, because the ordering of them doesn’t matter.\n\nThe break statement, seen here in line 25, causes an immediate exit from the innermost loop in which it is called. It is often used as a safety valve to escape an iteration that may not be able to terminate otherwise.\n\nSecant method\n\ndef secant(f, x1, x2):\n    \"\"\"\n    secant(f, x1, x2)\n\n    Use the secant method to find a root of f starting from x1 and x2. Returns a\n    vector of root estimates.\n    \"\"\"\n    # Operating parameters.\n    eps = np.finfo(float).eps\n    funtol = 100 * eps\n    xtol = 100 * eps\n    maxiter = 40\n\n    x = np.zeros(maxiter)\n    x[:2] = [x1, x2]\n    y1 = f(x1)\n    y2 = 100\n    dx = np.inf  # for initial pass below\n    k = 1\n\n    while (abs(dx) > xtol) and (abs(y2) > funtol) and (k < maxiter):\n        y2 = f(x[k])\n        dx = -y2 * (x[k] - x[k - 1]) / (y2 - y1)  # secant step\n        x[k + 1] = x[k] + dx  # new estimate\n\n        k = k + 1\n        y1 = y2  # current f-value becomes the old one next time\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:k+1]\n\nAbout the code\n\nBecause we want to observe the convergence of the method, \n\nFunction 4.4.2 stores and returns the entire sequence of root estimates. However, only the most recent two are needed by the iterative formula. This is demonstrated by the use of y₁ and y₂ for the two most recent values of f.\n\nNewton’s method for systems\n\ndef newtonsys(f, jac, x1):\n    \"\"\"\n        newtonsys(f, jac, x1)\n\n    Use Newton's method to find a root of a system of equations, starting from x1. The\n    function f should return the residual vector, and the function jac should return \n    the Jacobian matrix. Returns root estimates as a matrix, one estimate per column.\n    \"\"\"\n    # Operating parameters.\n    funtol = 1000 * np.finfo(float).eps\n    xtol = 1000 * np.finfo(float).eps\n    maxiter = 40\n\n    x = np.zeros((maxiter, len(x1)))\n    x[0] = x1\n    y, J = f(x1), jac(x1)\n    dx = 10.0  # for initial pass below\n    k = 0\n\n    while (norm(dx) > xtol) and (norm(y) > funtol) and (k < maxiter):\n        dx = -lstsq(J, y)[0]  # Newton step\n        x[k+1] = x[k] + dx\n\n        k = k + 1\n        y, J = f(x[k]), jac(x[k])\n\n    if k == maxiter:\n        warnings.warn(\"Maximum number of iterations reached.\")\n    return x[:k+1]\n\nAbout the code\n\nThe output of \n\nFunction 4.5.2 is a vector of vectors representing the entire history of root estimates. Since these should be in floating point, the starting value is converted with float before the iteration starts.\n\nFinite differences for Jacobian\n\ndef fdjac(f, x0, y0):\n    \"\"\"\n    fdjac(f,x0,y0)\n\n    Compute a finite-difference approximation of the Jacobian matrix for f at x0,\n    where y0=f(x0) is given.\n    \"\"\"\n\n    delta = np.sqrt(np.finfo(float).eps)  # FD step size\n    m, n = len(y0), len(x0)\n    J = np.zeros((m, n))\n    I = np.eye(n)\n    for j in range(n):\n        J[:, j] = (f(x0 + delta * I[:, j]) - y0) / delta\n    return J\n\nAbout the code\n\nFunction 4.6.1 is written to accept the case where \\mathbf{f} maps n variables to m values with m\\neq n, in anticipation of \n\nNonlinear least squares.\n\nNote that a default value is given for the third argument y₀, and it refers to earlier arguments in the list. The reason is that in some contexts, the caller of fdjac may have already computed y₀ and can supply it without computational cost, while in other contexts, it must be computed fresh. The configuration here adapts to either situation.\n\nLevenberg’s method\n\ndef levenberg(f, x1, tol=1e-12):\n    \"\"\"\n    levenberg(f,x1,tol)\n\n    Use Levenberg's quasi-Newton iteration to find a root of the system f, \n    starting from x1, with tol as the stopping tolerance in both step size and residual norm. Returns root estimates as a matrix, one estimate per column.\n    \"\"\"\n\n    # Operating parameters.\n    ftol = tol\n    xtol = tol\n    maxiter = 40\n\n    n = len(x1)\n    x = np.zeros((maxiter+1, n))\n    x[0] = x1\n    fk = f(x1)\n    k = 0\n    s = 10.0\n    Ak = fdjac(f, x[0], fk)  # start with FD Jacobian\n    jac_is_new = True\n\n    lam = 10\n    while (norm(s) > xtol) and (norm(fk) > ftol) and (k < maxiter):\n        # Compute the proposed step.\n        B = Ak.T @ Ak + lam * np.eye(n)\n        z = Ak.T @ fk\n        s = -lstsq(B, z)[0]\n\n        xnew = x[k] + s\n        fnew = f(xnew)\n\n        # Do we accept the result?\n        if norm(fnew) < norm(fk):  # accept\n            y = fnew - fk\n            x[k + 1] = xnew\n            fk = fnew\n            k = k + 1\n\n            lam = lam / 10  # get closer to Newton\n            # Broyden update of the Jacobian.\n            Ak = Ak + np.outer(y - Ak @ s, s / np.dot(s, s))\n            jac_is_new = False\n        else:  # don't accept\n            # Get closer to steepest descent.\n            lam = lam * 4\n            # Re-initialize the Jacobian if it's out of date.\n            if not jac_is_new:\n                Ak = fdjac(f, x[k], fk)\n                jac_is_new = True\n\n    if norm(fk) > 1e-3:\n        warnings.warn(\"Iteration did not find a root.\")\n    return x[:k+1]\n","type":"content","url":"/chapter4-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"type":"lvl2","url":"/chapter4-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 4","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter4-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.1 The rootfinding problem","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-1","position":6},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.1 The rootfinding problem","lvl2":"Examples"},"content":"Example 4.1.1\n\nimport scipy.special as special\ndef J3(x):\n    return special.jv(3.0, x)\n\nxx = linspace(0, 20, 500)\nfig, ax = subplots()\nax.plot(xx, J3(xx))\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$J_3(x)$\")\ntitle(\"Bessel function\");\n\nFrom the graph we see roots near 6, 10, 13, 16, and 19. We use root_scalar from the scipy.optimize package to find these roots accurately.\n\nfrom scipy.optimize import root_scalar\n\nomega = []\nfor guess in [6.0, 10.0, 13.0, 16.0, 19.0]:\n    s = root_scalar(J3, bracket=[guess - 0.5, guess + 0.5]).root\n    omega.append(s)\n\nresults = PrettyTable()\nresults.add_column(\"root estimate\", omega)\nresults.add_column(\"function value\", [J3(ω) for ω in omega])\nprint(results)\n\nax.scatter(omega, J3(omega))\nax.set_title(\"Bessel function roots\")\nfig\n\nIf instead we seek values at which J_3(x)=0.2, then we must find roots of the function J_3(x)-0.2.\n\nomega = []\nfor guess in [3., 6., 10., 13.]:\n    f = lambda x: J3(x) - 0.2\n    s = root_scalar(f, x0=guess).root\n    omega.append(s)\n\nax.scatter(omega, J3(omega))\nfig\n\nExample 4.1.2\n\nConsider first the function\n\nf = lambda x: (x - 1) * (x - 2)\n\nAt the root r=1, we have f'(r)=-1. If the values of f were perturbed at every point by a small amount of noise, we can imagine finding the root of the function drawn with a thick ribbon, giving a range of potential roots.\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Well-conditioned root\");\n\nThe possible values for a perturbed root all lie within the interval where the ribbon intersects the x-axis. The width of that zone is about the same as the vertical thickness of the ribbon.\n\nBy contrast, consider the function\n\nf = lambda x: (x - 1) * (x - 1.01)\n\nNow f'(1)=-0.01, and the graph of f will be much shallower near x=1. Look at the effect this has on our thick rendering:\n\nxx = linspace(0.8, 1.2, 400)\nplot(xx, f(xx))\nplot(xx, f(xx) + 0.02, \"k\")\nplot(xx, f(xx) - 0.02, \"k\")\naxis(\"equal\"), grid(True)\nxlabel(\"x\"), ylabel(\"f(x)\")\ntitle(\"Poorly-conditioned root\");\n\nThe vertical displacements in this picture are exactly the same as before. But the potential horizontal displacement of the root is much wider. In fact, if we perturb the function entirely upward by the amount drawn here, the root disappears!","type":"content","url":"/chapter4-2#id-4-1","position":7},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.2 Fixed-point iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-2","position":8},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.2 Fixed-point iteration","lvl2":"Examples"},"content":"Example 4.2.1\n\nLet’s convert the roots of a quadratic polynomial f(x) to a fixed point problem.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nWe define g(x)=x - f(x).\n\ng = lambda x: x - f(x)\n\nIntersections of y=g(x) with the line y=x are fixed points of g and thus roots of f. (Only one is shown in the chosen plot range.)\n\nfig, ax = subplots()\ng = lambda x: x - f(x)\nxx = linspace(2, 3, 400)\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\naxis(\"equal\"), legend()\ntitle(\"Finding a fixed point\");\n\nIf we evaluate g(2.1), we get a value of almost 2.6, so this is not a fixed point.\n\nx = 2.1\ny = g(x)\nprint(y)\n\nHowever, y=g(x) is considerably closer to the fixed point at around 2.7 than x is. Suppose then that we adopt y as our new x value. Changing the x coordinate in this way is the same as following a horizontal line over to the graph of y=x.\n\nax.plot([x, y], [y, y], \"r:\", label=\"\")\nfig\n\nNow we can compute a new value for y. We leave x alone here, so we travel along a vertical line to the graph of g.\n\nx = y\ny = g(x)\nprint(\"y:\", y)\nax.plot([x, x], [x, y], \"k:\")\nfig\n\nYou see that we are in a position to repeat these steps as often as we like. Let’s apply them a few times and see the result.\n\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y       # y --> new x\n    y = g(x)    # g(x) --> new y\n    ax.plot([x, x], [x, y], \"k:\")  \nfig\n\nThe process spirals in beautifully toward the fixed point we seek. Our last estimate has almost 4 accurate digits.\n\nprint(abs(y - max(r)) / max(r))\n\nNow let’s try to find the other fixed point \\approx 1.29 in the same way. We’ll use 1.3 as a starting approximation.\n\nxx = linspace(1, 2, 400)\nfig, ax = subplots()\nax.plot(xx, g(xx), label=\"y=g(x)\")\nax.plot(xx, xx, label=\"y=x\")\nax.set_aspect(1.0)\nax.legend()\n\nx = 1.3\ny = g(x)\nfor k in range(5):\n    ax.plot([x, y], [y, y], \"r:\")\n    x = y\n    y = g(x)\n    ax.plot([x, x], [x, y], \"k:\")\nylim(1, 2.5)\ntitle(\"No convergence\");\n\nThis time, the iteration is pushing us away from the correct answer.\n\nExample 4.2.3\n\nWe revisit \n\nDemo 4.2.1 and investigate the observed convergence more closely. Recall that above we calculated g'(p)\\approx-0.42 at the convergent fixed point.\n\nf = poly1d([1, -4, 3.5])\nr = f.roots\nprint(r)\n\nHere is the fixed-point iteration. This time we keep track of the whole sequence of approximations.\n\ng = lambda x: x - f(x)\nx = zeros(12)\nx[0] = 2.1\nfor k in range(11):\n    x[k + 1] = g(x[k])\n\nprint(x)\n\nIt’s illuminating to construct and plot the sequence of errors.\n\nerr = abs(x - max(r))\nsemilogy(err, \"-o\")\nxlabel(\"iteration number\"), ylabel(\"error\")\ntitle(\"Convergence of fixed-point iteration\");\n\nIt’s quite clear that the convergence quickly settles into a linear rate. We could estimate this rate by doing a least-squares fit to a straight line. Keep in mind that the values for small k should be left out of the computation, as they don’t represent the linear trend.\n\np = polyfit(arange(5, 13), log(err[4:]), 1)\nprint(p)\n\nWe can exponentiate the slope to get the convergence constant σ.\n\nprint(\"sigma:\", exp(p[0]))\n\nThe error should therefore decrease by a factor of σ at each iteration. We can check this easily from the observed data.\n\nerr[8:] / err[7:-1]\n\nThe methods for finding σ agree well.","type":"content","url":"/chapter4-2#id-4-2","position":9},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.3 Newton’s method","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-3","position":10},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.3 Newton’s method","lvl2":"Examples"},"content":"Example 4.3.1\n\nSuppose we want to find a root of this function:\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0, 1.5, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$y$\");\n\nFrom the graph, it is clear that there is a root near x=1. So we call that our initial guess, x_1.\n\nx1 = 1\ny1 = f(x1)\nax.plot(x1, y1, \"ko\", label=\"initial point\")\nax.legend()\nfig\n\nNext, we can compute the tangent line at the point \\bigl(x_1,f(x_1)\\bigr), using the derivative.\n\ndf_dx = lambda x: exp(x) * (x + 1)\nslope1 = df_dx(x1)\ntangent1 = lambda x: y1 + slope1 * (x - x1)\n\nax.plot(xx, tangent1(xx), \"--\", label=\"tangent line\")\nax.set_ylim(-2, 4)\nax.legend()\nfig\n\nIn lieu of finding the root of f itself, we settle for finding the root of the tangent line approximation, which is trivial. Call this x_2, our next approximation to the root.\n\nx2 = x1 - y1 / slope1\nax.plot(x2, 0, \"ko\", label=\"tangent root\")\nax.legend()\nfig\n\ny2 = f(x2)\nprint(y2)\n\nThe residual (i.e., value of f) is smaller than before, but not zero. So we repeat the process with a new tangent line based on the latest point on the curve.\n\nxx = linspace(0.83, 0.88, 200)\n\nplot(xx, f(xx))\nplot(x2, y2, \"ko\")\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\n\nslope2 = df_dx(x2)\ntangent2 = lambda x: y2 + slope2 * (x - x2)\nplot(xx, tangent2(xx), \"--\")\nx3 = x2 - y2 / slope2\nplot(x3, 0, \"ko\")\ntitle(\"Second iteration\");\n\ny3 = f(x3)\nprint(y3)\n\nJudging by the residual, we appear to be getting closer to the true root each time.\n\nExample 4.3.2\n\nWe again look at finding a solution of x e^x=2 near x=1. To apply Newton’s method, we need to calculate values of both the residual function f and its derivative.\n\nf = lambda x: x * exp(x) - 2\ndf_dx = lambda x: exp(x) * (x + 1)\n\nWe don’t know the exact root, so we use nlsolve to determine a proxy for it.\n\nr = root_scalar(f, bracket=[0.8, 1.0]).root\nprint(r)\n\nWe use x_1=1 as a starting guess and apply the iteration in a loop, storing the sequence of iterates in a vector.\n\nx = ones(5)\nfor k in range(4):\n    x[k + 1] = x[k] - f(x[k]) / df_dx(x[k])\n\nprint(x)\n\nHere is the sequence of errors.\n\nerr = x - r\nprint(err)\n\nThe exponents in the scientific notation definitely suggest a squaring sequence. We can check the evolution of the ratio in \n\n(4.3.9).\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])\n\nThe clear convergence to 2 above constitutes good evidence of quadratic convergence.\n\nExample 4.3.3\n\nSuppose we want to evaluate the inverse of the function h(x)=e^x-x. This means solving y=h(x), or h(x)-y=0, for x when y is given. That equation has no solution in terms of elementary functions. If a value of y is given numerically, though, we simply have a rootfinding problem for f(x)=e^x-x-y.\n\nTip\n\nThe enumerate function produces a pair of values for each iteration: a positional index and the corresponding contents.\n\nh = lambda x: exp(x) - x\ndh_dx = lambda x: exp(x) - 1\ny_ = linspace(h(0), h(2), 200)\nx_ = zeros(y_.shape)\nfor (i, y) in enumerate(y_):\n    f = lambda x: h(x) - y\n    df_dx = lambda x: dh_dx(x)\n    x = FNC.newton(f, df_dx, y)\n    x_[i] = x[-1]\n\nplot(x_, y_, label=\"$y=h(x)$\")\nplot(y_, x_, label=\"$y=h^{-1}(x)$\")\nplot([0, max(y_)], [0, max(y_)], 'k--', label=\"\")\ntitle(\"Function and its inverse\")\nxlabel(\"x\"), ylabel(\"y\"), axis(\"equal\")\nax.grid()\nlegend();","type":"content","url":"/chapter4-2#id-4-3","position":11},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.4 Interpolation-based methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-4","position":12},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.4 Interpolation-based methods","lvl2":"Examples"},"content":"Example 4.4.1\n\nf = lambda x: x * exp(x) - 2\nxx = linspace(0.25, 1.25, 400)\n\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.set_xlabel(\"$x$\")\nax.set_ylabel(\"$f(x)$\")\nax.grid();\n\nFrom the graph, it’s clear that there is a root near x=1. To be more precise, there is a root in the interval [0.5,1]. So let us take the endpoints of that interval as two initial approximations.\n\nx1 = 1\ny1 = f(x1)\nx2 = 0.5\ny2 = f(x2)\nax.plot([x1, x2], [y1, y2], \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nInstead of constructing the tangent line by evaluating the derivative, we can construct a linear model function by drawing the line between the two points \\bigl(x_1,f(x_1)\\bigr) and \\bigl(x_2,f(x_2)\\bigr). This is called a secant line.\n\nslope2 = (y2 - y1) / (x2 - x1)\nsecant2 = lambda x: y2 + slope2 * (x - x2)\nax.plot(xx, secant2(xx), \"--\", label=\"secant line\")\nax.legend()\nfig\n\nAs before, the next root estimate in the iteration is the root of this linear model.\n\nx3 = x2 - y2 / slope2\nax.plot(x3, 0, \"o\", label=\"root of secant\")\ny3 = f(x3)\nprint(y3)\nax.legend()\nfig\n\nFor the next linear model, we use the line through the two most recent points. The next iterate is the root of that secant line, and so on.\n\nslope3 = (y3 - y2) / (x3 - x2)\nx4 = x3 - y3 / slope3\nprint(f(x4))\n\nExample 4.4.2\n\nWe check the convergence of the secant method from \n\nDemo 4.4.1.\n\nf = lambda x: x * exp(x) - 2\nx = FNC.secant(f, 1, 0.5)\nprint(x)\n\nWe don’t know the exact root, so we use root_scalar to get a substitute.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.5, 1]).root\nprint(r)\n\nHere is the sequence of errors.\n\nerr = r - x\nprint(err)\n\nIt’s not easy to see the convergence rate by staring at these numbers. We can use \n\n(4.4.8) to try to expose the superlinear convergence rate.\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 2):\n    print(logerr[i+1] / logerr[i])\n\nAs expected, this settles in at around 1.618.\n\nExample 4.4.3\n\nHere we look for a root of x+\\cos(10x) that is close to 1.\n\nf = lambda x: x + cos(10 * x)\nxx = linspace(0.5, 1.5, 400)\nfig, ax = subplots()\nax.plot(xx, f(xx), label=\"function\")\nax.grid()\nxlabel(\"$x$\"), ylabel(\"$y$\")\nfig\n\nWe choose three values to get the iteration started.\n\nx = array([0.8, 1.2, 1])\ny = f(x)\nax.plot(x, y, \"ko\", label=\"initial points\")\nax.legend()\nfig\n\nIf we were using forward interpolation, we would ask for the polynomial interpolant of y as a function of x. But that parabola has no real roots.\n\nq = poly1d(polyfit(x, y, 2))  # interpolating polynomial\nax.plot(xx, q(xx), \"--\", label=\"interpolant\")\nax.set_ylim(-0.1, 3), ax.legend()\nfig\n\nTo do inverse interpolation, we swap the roles of x and y in the interpolation.\n\nplot(xx, f(xx), label=\"function\")\nplot(x, y, \"ko\", label=\"initial points\")\n\nq = poly1d(polyfit(y, x, 2))  # inverse interpolating polynomial\nyy = linspace(-0.1, 2.6, 400)\nplot(q(yy), yy, \"--\", label=\"inverse interpolant\")\n\ngrid(), xlabel(\"$x$\"), ylabel(\"$y$\")\nlegend();\n\nWe seek the value of x that makes y zero. This means evaluating q at zero.\n\nx = hstack([x, q(0)])\ny = hstack([y, f(x[-1])])\nprint(\"x:\", x, \"\\ny:\", y)\n\nWe repeat the process a few more times.\n\nfor k in range(6):\n    q = poly1d(polyfit(y[-3:], x[-3:], 2))\n    x = hstack([x, q(0)])\n    y = hstack([y, f(x[-1])])\nprint(f\"final residual is {y[-1]:.2e}\")\n\nHere is the sequence of errors.\n\nfrom scipy.optimize import root_scalar\nr = root_scalar(f, bracket=[0.9, 1]).root\nerr = x - r\nprint(err)\n\nThe error seems to be superlinear, but subquadratic:\n\nlogerr = log(abs(err))\nfor i in range(len(err) - 1):\n    print(logerr[i+1] / logerr[i])","type":"content","url":"/chapter4-2#id-4-4","position":13},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.5 Newton for nonlinear systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-5","position":14},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.5 Newton for nonlinear systems","lvl2":"Examples"},"content":"Example 4.5.3\n\nA system of nonlinear equations is defined by its residual and Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\ndef jac(x):\n    return array([\n            [-exp(x[1] - x[0]), exp(x[1] - x[0]), 0],\n            [x[1], x[0], 1],\n            [2 * x[0], x[2] - 1, x[1]],\n    ])\n\nOur initial guess at a root is the origin.\n\nx1 = zeros(3)\nx = FNC.newtonsys(func, jac, x1)\nprint(x)\n\nThe output has one row per iteration, so the last row contains the final Newton estimate. Let’s compute its residual.\n\nr = x[-1]\nf = func(r)\nprint(\"final residual:\", f)\n\nLet’s check the convergence rate:\n\nlogerr = [log(norm(x[k] - r)) for k in range(x.shape[0] - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])\n\nThe ratio is apparently converging toward 2, as expected for quadratic convergence.","type":"content","url":"/chapter4-2#id-4-5","position":15},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.6 Quasi-Newton methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-6","position":16},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.6 Quasi-Newton methods","lvl2":"Examples"},"content":"Example 4.6.1\n\nTo solve a nonlinear system, we need to code only the function defining the system, and not its Jacobian.\n\ndef func(x):\n    return array([\n        exp(x[1] - x[0]) - 2, \n        x[0] * x[1] + x[2], \n        x[1] * x[2] + x[0]**2 - x[1]\n    ])\n\nIn all other respects usage is the same as for the newtonsys function.\n\nx1 = zeros(3)\nx = FNC.levenberg(func, x1)\nprint(f\"Took {len(x) - 1} iterations.\")\n\nIt’s always a good idea to check the accuracy of the root, by measuring the residual (backward error).\n\nr = x[-1]\nprint(\"backward error:\", norm(func(r)))\n\nLooking at the convergence in norm, we find a convergence rate between linear and quadratic, like with the secant method:\n\nlogerr = [log(norm(x[k] - r)) for k in range(len(x) - 1)]\nfor k in range(len(logerr) - 1):\n    print(logerr[k+1] / logerr[k])","type":"content","url":"/chapter4-2#id-4-6","position":17},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.7 Nonlinear least squares","lvl2":"Examples"},"type":"lvl3","url":"/chapter4-2#id-4-7","position":18},{"hierarchy":{"lvl1":"Chapter 4","lvl3":"4.7 Nonlinear least squares","lvl2":"Examples"},"content":"Example 4.7.1\n\nWe will observe the convergence of \n\nFunction 4.6.3 for different levels of the minimum least-squares residual. We start with a function mapping from \\real^2 into \\real^3, and a point that will be near the optimum.\n\ng = lambda x: array([sin(x[0] + x[1]), cos(x[0] - x[1]), exp(x[0] - x[1])])\np = array([1, 1])\n\nThe function \\mathbf{g}(\\mathbf{x}) - \\mathbf{g}(\\mathbf{p}) obviously has a zero residual at \\mathbf{p}. We’ll make different perturbations of that function in order to create nonzero residuals.\n\nfor R in [1e-3, 1e-2, 1e-1]:\n    # Define the perturbed function.\n    f = lambda x: g(x) - g(p) + R * array([-1, 1, -1]) / sqrt(3)\n    x = FNC.levenberg(f, [0, 0])\n    r = x[-1]\n    err = [norm(x[j] - r) for j in range(len(x) - 1)]\n    normres = norm(f(r))\n    semilogy(err, label=f\"R={normres:.2g}\")\ntitle(\"Convergence of Gauss–Newton\")\nxlabel(\"iteration\"), ylabel(\"error\")\nlegend();\n\nIn the least perturbed case, where the minimized residual is less than \n\n10-3, the convergence is plausibly quadratic. At the next level up, the convergence starts similarly but suddenly stagnates for a long time. In the most perturbed case, the quadratic phase is nearly gone and the overall shape looks linear.\n\nExample 4.7.2\n\nm = 25\nV, Km = 2, 0.5\ns = linspace(0.05, 6, m)\nmodel = lambda x: V * x / (Km + x)\nw = model(s) + 0.15 * cos(2 * exp(s / 16) * s)    # noise added\n\nfig, ax = subplots()\nax.scatter(s, w, label=\"data\")\nax.plot(s, model(s), 'k--', label=\"unperturbed model\")\nxlabel(\"s\"), ylabel(\"w\")\nlegend();\n\nThe idea is to pretend that we know nothing of the origins of this data and use nonlinear least squares to find the parameters in the theoretical model function v(s). In \n\n(4.7.2), the s variable plays the role of t, and v plays the role of g.\n\nTip\n\nPutting comma-separated values on the left of an assignment will destructure the right-hand side, drawing individual assignments from entries of a vector, for example.\n\ndef misfit(c):\n    V, Km = c  # rename components for clarity\n    f = V * s / (Km + s) - w\n    return f\n\nIn the Jacobian the derivatives are with respect to the parameters in \\mathbf{x}.\n\ndef misfitjac(x):\n    V, Km = x   # rename components for clarity\n    J = zeros([m, 2])\n    J[:, 0] = s / (Km + s)          # d/d(V)\n    J[:, 1] = -V * s / (Km + s)**2  # d/d(Km)\n    return J\n\nx1 = [1, 0.75]\nx = FNC.newtonsys(misfit, misfitjac, x1)\nV, Km = x[-1]  # final values\nprint(f\"estimates are V = {V:.3f}, Km = {Km:.3f}\")\n\nThe final values are reasonably close to the values V=2, K_m=0.5 that we used to generate the noise-free data. Graphically, the model looks close to the original data.\n\n# since V and Km have been updated, model() is too\nax.plot(s, model(s), label=\"nonlinear fit\")\n\nFor this particular model, we also have the option of linearizing the fit process. Rewrite the model as\\frac{1}{w} = \\frac{\\alpha}{s} + \\beta = \\alpha \\cdot s^{-1} + \\beta\n\nfor the new fitting parameters \\alpha=K_m/V and \\beta=1/V. This corresponds to the misfit function whose entries aref_i([\\alpha,\\beta]) = \\left(\\alpha \\cdot \\frac{1}{s_i} + \\beta\\right) - \\frac{1}{w_i}\n\nfor i=1,\\ldots,m. Although this misfit is nonlinear in s and w, it’s linear in the unknown parameters α and β. This lets us pose and solve it as a linear least-squares problem.\n\nfrom numpy.linalg import lstsq\nA = array( [[1 / s[i], 1.0] for i in range(len(s))] )\nz = lstsq(A, 1 / w, rcond=None)[0]\nalpha, beta = z\nprint(\"alpha:\", alpha, \"beta:\", beta)\n\nThe two fits are different; they do not optimize the same quantities.\n\nlinmodel = lambda x: 1 / (beta + alpha / x)\nax.plot(s, linmodel(s), label=\"linear fit\")\nax.legend()\nfig\n\nThe truly nonlinear fit is clearly better in this case. It optimizes a residual for the original measured quantity rather than a transformed one we picked for algorithmic convenience.","type":"content","url":"/chapter4-2#id-4-7","position":19},{"hierarchy":{"lvl1":"Chapter 5"},"type":"lvl1","url":"/chapter5-2","position":0},{"hierarchy":{"lvl1":"Chapter 5"},"content":"","type":"content","url":"/chapter5-2","position":1},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"type":"lvl2","url":"/chapter5-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Functions"},"content":"Hat function\n\ndef hatfun(t, k):\n    \"\"\"\n    hatfun(t, k)\n\n    Returns a piecewise linear \"hat\" function,  where t is a vector of\n    n+1 interpolation nodes and k is an integer in 0:n giving the index of the node\n    where the hat function equals one.\n    \"\"\"\n    n = len(t) - 1\n\n    def evaluate(x):\n        H = np.zeros(np.array(x).shape)\n        for (j, xj) in enumerate(x):\n            if (k > 0) and (t[k-1] <= xj) and (xj <= t[k]):\n                H[j] = (xj - t[k-1]) / (t[k] - t[k-1])\n            elif (k < n) and (t[k] <= xj) and (xj <= t[k+1]):\n                H[j] = (t[k+1] - xj) / (t[k+1] - t[k])\n        return H\n    return evaluate\n\nPiecewise linear interpolation\n\ndef plinterp(t, y):\n    \"\"\"\n    plinterp(t, y)\n\n    Create a piecewise linear interpolating function for data values in y given at nodes\n    in t.\n    \"\"\"\n    n = len(t) - 1\n    H = [hatfun(t, k) for k in range(n+1)]\n    def evaluate(x):\n        f = 0\n        for k in range(n+1):\n            f += y[k] * H[k](x)\n        return f\n    return evaluate\n\nCubic spline interpolation\n\ndef spinterp(t, y):\n    \"\"\"\n    spinterp(t, y)\n\n    Create a cubic not-a-knot spline interpolating function for data values in y given at nodes in t.\n    \"\"\"\n    n = len(t) - 1\n    h = [t[i + 1] - t[i] for i in range(n)]\n\n    # Preliminary definitions.\n    Z = np.zeros([n, n])\n    I = np.eye(n)\n    E = I[: n - 1, :]\n    J = np.eye(n) + np.diag(-np.ones(n - 1), 1)\n    H = np.diag(h)\n\n    # Left endpoint interpolation:\n    AL = np.hstack([I, Z, Z, Z])\n    vL = y[:-1]\n\n    # Right endpoint interpolation:\n    AR = np.hstack([I, H, H**2, H**3])\n    vR = y[1:]\n\n    # Continuity of first derivative:\n    A1 = E @ np.hstack([Z, J, 2 * H, 3 * H**2])\n    v1 = np.zeros(n - 1)\n\n    # Continuity of second derivative:\n    A2 = E @ np.hstack([Z, Z, J, 3 * H])\n    v2 = np.zeros(n - 1)\n\n    # Not-a-knot conditions:\n    nakL = np.hstack([np.zeros(3 * n), np.hstack([1, -1, np.zeros(n - 2)])])\n    nakR = np.hstack([np.zeros(3 * n), np.hstack([np.zeros(n - 2), 1, -1])])\n\n    # Assemble and solve the full system.\n    A = np.vstack([AL, AR, A1, A2, nakL, nakR])\n    v = np.hstack([vL, vR, v1, v2, 0, 0])\n    z = solve(A, v)\n\n    # Break the coefficients into separate vectors.\n    rows = np.arange(n)\n    a = z[rows]\n    b = z[n + rows]\n    c = z[2 * n + rows]\n    d = z[3 * n + rows]\n    S = [np.poly1d([d[k], c[k], b[k], a[k]]) for k in range(n)]\n\n    # This function evaluates the spline when called with a value for x.\n    def evaluate(x):\n        f = np.zeros(x.shape)\n        for k in range(n):\n            # Evaluate this piece's cubic at the points inside it.\n            index = (x >= t[k]) & (x <= t[k + 1])\n            f[index] = S[k](x[index] - t[k])\n        return f\n\n    return evaluate\n\nFornberg’s algorithm for finite difference weights\n\ndef fdweights(t, m):\n    \"\"\"\n    fdweights(t, m)\n\n    Return weights for the mth derivative of a function at zero using values at the\n    nodes in vector t.\n    \"\"\"\n    # This is a compact implementation, not an efficient one.\n\n    def weight(t, m, r, k):\n        # Recursion for one weight.\n        # Input:\n        #   t   nodes (vector)\n        #   m   order of derivative sought\n        #   r   number of nodes to use from t (<= length(t))\n        #   k   index of node whose weight is found\n\n        if (m < 0) or (m > r):  # undefined coeffs must be zero\n            c = 0\n        elif (m == 0) and (r == 0):  # base case of one-point interpolation\n            c = 1\n        else:  # generic recursion\n            if k < r:\n                denom = t[r] - t[k]\n                c = (t[r] * weight(t, m, r-1, k) - m * weight(t, m-1, r-1, k)) / denom\n            else:\n                beta = np.prod(t[r-1] - t[:r-1]) / np.prod(t[r] - t[:r])\n                c = beta * (m * weight(t, m-1, r-1, r-1) - t[r-1] * weight(t, m, r-1, r-1))\n        return c\n\n    r = len(t) - 1\n    w = np.zeros(t.shape)\n    return np.array([ weight(t, m, r, k) for k in range(r+1) ])\n\nTrapezoid formula for numerical integration\n\ndef trapezoid(f, a, b, n):\n    \"\"\"\n    trapezoid(f, a, b, n)\n\n    Apply the trapezoid integration formula for integrand f over interval [a,b], broken up into n equal pieces. Returns estimate, vector of nodes, and vector of integrand values at the nodes.\n    \"\"\"\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n    y = f(t)\n    T = h * (np.sum(y[1:-1]) + 0.5 * (y[0] + y[-1]))\n    return T, t, y\n\nAdaptive integration\n\ndef intadapt(f, a, b, tol):\n    \"\"\"\n    intadapt(f, a, b, tol)\n\n    Do adaptive integration to estimate the integral of f over [a,b] to desired\n    error tolerance tol. Returns estimate and a vector of evaluation nodes used.\n    \"\"\"\n\n    # Use error estimation and recursive bisection.\n    def do_integral(a, fa, b, fb, m, fm, tol):\n        # These are the two new nodes and their f-values.\n        xl = (a + m) / 2\n        fl = f(xl)\n        xr = (m + b) / 2\n        fr = f(xr)\n        t = np.array([a, xl, m, xr, b])  # all 5 nodes at this level\n\n        # Compute the trapezoid values iteratively.\n        h = b - a\n        T = np.zeros(3)\n        T[0] = h * (fa + fb) / 2\n        T[1] = T[0] / 2 + (h / 2) * fm\n        T[2] = T[1] / 2 + (h / 4) * (fl + fr)\n\n        S = (4 * T[1:] - T[:-1]) / 3  # Simpson values\n        E = (S[1] - S[0]) / 15  # error estimate\n\n        if abs(E) < tol * (1 + abs(S[1])):  # acceptable error?\n            Q = S[1]  # yes--done\n        else:\n            # Error is too large--bisect and recurse.\n            QL, tL = do_integral(a, fa, m, fm, xl, fl, tol)\n            QR, tR = do_integral(m, fm, b, fb, xr, fr, tol)\n            Q = QL + QR\n            t = np.hstack([tL, tR[1:]])  # merge the nodes w/o duplicate\n        return Q, t\n\n    m = (b + a) / 2\n    Q, t = do_integral(a, f(a), b, f(b), m, f(m), tol)\n    return Q, t\n\n\nAbout the code\n\nThe intended way for a user to call \n\nFunction 5.7.1 is with only f, a, b, and tol provided. We then use default values on the other parameters to compute the function values at the endpoints, the interval’s midpoint, and the function value at the midpoint. Recursive calls from within the function itself will provide all of that information, since it was already calculated along the way.","type":"content","url":"/chapter5-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"type":"lvl2","url":"/chapter5-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 5","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter5-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.1 The interpolation problem","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-1","position":6},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.1 The interpolation problem","lvl2":"Examples"},"content":"Example 5.1.1\n\nHere are some points that we could consider to be observations of an unknown function on [-1,1].\n\nn = 5\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nThe polynomial interpolant, as computed using fit, looks very sensible. It’s the kind of function you’d take home to meet your parents.\n\np = poly1d(polyfit(t, y, n))  # interpolating polynomial\ntt = linspace(-1, 1, 400)\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nBut now consider a different set of points generated in almost exactly the same way.\n\nn = 18\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.05 * sin(20 * t)\nfig, ax = subplots()\nplot(t, y, \"o\", label=\"data\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nThe points themselves are unremarkable. But take a look at what happens to the polynomial interpolant.\n\np = poly1d(polyfit(t, y, n))\nax.plot(tt, p(tt), label=\"interpolant\")\nax.legend()\nfig\n\nSurely there must be functions that are more intuitively representative of those points!\n\nExample 5.1.3\n\nLet us recall the data from \n\nDemo 5.1.1.\n\nclf\nn = 12\nt = linspace(-1, 1, n + 1)\ny = t**2 + t + 0.5 * sin(20 * t)\nfig, ax = subplots()\nscatter(t, y, label=\"data\")\nxlabel(\"$x$\"),  ylabel(\"$y$\");\n\nHere is an interpolant that is linear between each consecutive pair of nodes, using plinterp from \n\nPiecewise linear interpolation.\n\nfrom scipy.interpolate import interp1d\ntt = linspace(-1, 1, 400)\np = interp1d(t, y, kind=\"linear\")\nax.plot(tt, p(tt), label=\"piecewise linear\")\nax.legend()\nfig\n\nWe may prefer a smoother interpolant that is piecewise cubic:\n\nscatter(t, y, label=\"data\")\np = interp1d(t, y, kind=\"cubic\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cubic spline\")\nxlabel(\"$x$\"),  ylabel(\"$y$\")\nlegend();\n\nExample 5.1.4\n\nIn \n\nDemo 5.1.1 and \n\nDemo 5.1.3 we saw a big difference between polynomial interpolation and piecewise polynomial interpolation of some arbitrarily chosen data. The same effects can be seen clearly in the cardinal functions, which are closely tied to the condition numbers.\n\nclf\nn = 18\nt = linspace(-1, 1, n + 1)\ny = zeros(n + 1)\ny[9] = 1.0\np = interp1d(t, y, kind=\"cubic\")\n\nscatter(t, y, label=\"data\")\ntt = linspace(-1, 1, 400)\nplot(tt, p(tt), label=\"cardinal function\")\ntitle(\"Cubic spline cardinal function\")\nlegend();\n\nThe piecewise cubic cardinal function is nowhere greater than one in absolute value. This happens to be true for all the cardinal functions, ensuring a good condition number for any interpolation with these functions. But the story for global polynomials is very different.\n\np = poly1d(polyfit(t, y, n))\nscatter(t, y, label=\"data\")\nplot(tt, p(tt), label=\"cardinal function\")\nxlabel(\"$x$\")\nylabel(\"$y$\")\ntitle(\"Polynomial cardinal function\")\nlegend();\n\nFrom the figure we can see that the condition number for polynomial interpolation on these nodes is at least 500.","type":"content","url":"/chapter5-2#id-5-1","position":7},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.2 Piecewise linear interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-2","position":8},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.2 Piecewise linear interpolation","lvl2":"Examples"},"content":"Example 5.2.1\n\nLet’s define a set of four nodes (i.e., n=3 in our formulas).\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])\n\nWe plot the hat functions H_0,\\ldots,H_3.\n\nx = linspace(0, 1, 300)\nfor k in range(6):\n    plot(x, FNC.hatfun(t, k)(x))\nxlabel(\"$x$\"),  ylabel(\"$H_k(x)$\")\ntitle(\"Hat functions\");\n\nExample 5.2.2\n\nWe generate a piecewise linear interpolant of f(x)=e^{\\sin 7x}.\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 400)\nfig, ax = subplots()\nplot(x, f(x), label=\"function\")\nxlabel(\"$x$\")\nylabel(\"$f(x)$\");\n\nFirst we sample the function to create the data.\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # function values\n\nax.plot(t, y, \"o\", label=\"nodes\")\nax.legend()\nfig\n\nNow we create a callable function that will evaluate the piecewise linear interpolant at any x, and then plot it.\n\np = FNC.plinterp(t, y)\nax.plot(x, p(x), label=\"interpolant\")\nax.legend()\nfig\n\nExample 5.2.3\n\nWe measure the convergence rate for piecewise linear interpolation of e^{\\sin 7x} over x \\in [0,1].\n\nf = lambda x: exp(sin(7 * x))\nx = linspace(0, 1, 10000)  # sample the difference at many points\nN = 2 ** arange(3, 11)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.plinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nAs predicted, a factor of 10 in n produces a factor of 100 in the error. In a convergence plot, it is traditional to have h decrease from left to right, so we expect a straight line of slope -2 on a log-log plot.\n\norder2 = 0.1 * (N / N[0]) ** (-2)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order2, \"--\", label=\"2nd order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-p\\|_\\infty$\")\nlegend();","type":"content","url":"/chapter5-2#id-5-2","position":9},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.3 Cubic splines","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-3","position":10},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.3 Cubic splines","lvl2":"Examples"},"content":"Example 5.3.1\n\nFor illustration, here is a spline interpolant using just a few nodes.\n\nf = lambda x: exp(sin(7 * x))\n\nx = linspace(0, 1, 500)\nfig, ax = subplots()\nax.plot(x, f(x), label=\"function\")\n\nt = array([0, 0.075, 0.25, 0.55, 0.7, 1])  # nodes\ny = f(t)  # values at nodes\n\nxlabel(\"$x$\")\nylabel(\"$y$\")\nax.scatter(t, y, label=\"nodes\")\n\nS = FNC.spinterp(t, y)\nax.plot(x, S(x), label=\"spline\")\nax.legend()\nfig\n\nNow we look at the convergence rate as the number of nodes increases.\n\nN = floor(2 ** linspace(3, 8, 17)).astype(int)\nerr = zeros(N.size)\nfor i, n in enumerate(N):\n    t = linspace(0, 1, n + 1)  # interpolation nodes\n    p = FNC.spinterp(t, f(t))\n    err[i] = max(abs(f(x) - p(x)))\nprint(err)\n\nSince we expect convergence that is O(h^4)=O(n^{-4}), we use a log-log graph of error and expect a straight line of slope -4.\n\norder4 = (N / N[0]) ** (-4)\nloglog(N, err, \"-o\", label=\"observed error\")\nloglog(N, order4, \"--\", label=\"4th order\")\nxlabel(\"$n$\")\nylabel(\"$\\|f-S\\|_\\infty$\")\nlegend();","type":"content","url":"/chapter5-2#id-5-3","position":11},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.4 Finite differences","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-4","position":12},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.4 Finite differences","lvl2":"Examples"},"content":"Example 5.4.3\n\nIf f(x)=e^{\\,\\sin(x)}, then f'(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere are the first two centered differences from \n\nTable 5.4.1.\n\nh = 0.05\nCD2 = (-f(-h) + f(h)) / (2*h)\nCD4 = (f(-2*h) - 8*f(-h) + 8*f(h) - f(2*h)) / (12*h)\nprint(f\"CD2 is {CD2:.9f} and CD4 is {CD4:.9f}\")\n\nHere are the first two forward differences from \n\nTable 5.4.2.\n\nFD1 = (-f(0) + f(h)) / h\nFD2 = (-3*f(0) + 4*f(h) - f(2*h)) / (2*h)\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward differences that come from reverse-negating the forward differences.\n\nBD1 = (-f(-h) + f(0)) / h\nBD2 = (f(-2*h) - 4*f(-h) + 3*f(0)) / (2*h)\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")\n\nExample 5.4.4\n\nIf f(x)=e^{\\,\\sin(x)}, then f''(0)=1.\n\nf = lambda x: exp(sin(x))\n\nHere is a centered estimate given by \n\n(5.4.12).\n\nh = 0.05\nCD2 = (f(-h) - 2*f(0) + f(h)) / h**2\nprint(f\"CD2 is {CD2:.9f}\")\n\nFor the same h, here are forward estimates given by \n\n(5.4.13) and \n\n(5.4.14).\n\nFD1 = (f(0) - 2*f(h) + f(2*h)) / h**2\nFD2 = (2*f(0) - 5*f(h) + 4*f(2*h) - f(3*h)) / h**2\nprint(f\"FD1 is {FD1:.9f} and FD2 is {FD2:.9f}\")\n\nFinally, here are the backward estimates that come from reversing \n\n(5.4.13) and \n\n(5.4.14).\n\nBD1 = (f(-2*h) - 2*f(-h) + f(0)) / h**2\nBD2 = (-f(-3*h) + 4*f(-2*h) - 5*f(-h) + 2*f(0)) / h**2\nprint(f\"BD1 is {BD1:.9f} and BD2 is {BD2:.9f}\")\n\nExample 5.4.5\n\nWe will estimate the derivative of \\cos(x^2) at x=0.5 using five nodes.\n\nt = array([0.35, 0.5, 0.57, 0.6, 0.75])   # nodes\nf = lambda x: cos(x**2)\ndfdx = lambda x: -2 * x * sin(x**2)\nexact_value = dfdx(0.5)\n\nWe have to shift the nodes so that the point of estimation for the derivative is at x=0. (To subtract a scalar from a vector, we must use the .- operator.)\n\nw = FNC.fdweights(t - 0.5, 1)\n\nThe finite-difference formula is a dot product (i.e., inner product) between the vector of weights and the vector of function values at the nodes.\n\nfd_value = dot(w, f(t))\n\nWe can reproduce the weights in the finite-difference tables by using equally spaced nodes with h=1. For example, here is a one-sided formula at four nodes.\n\nprint(FNC.fdweights(linspace(0, 3, 4), 1))","type":"content","url":"/chapter5-2#id-5-4","position":13},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.5 Convergence of finite differences","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-5","position":14},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.5 Convergence of finite differences","lvl2":"Examples"},"content":"Example 5.5.3\n\nLet’s observe the convergence of the formulas in \n\nExample 5.5.1 and \n\nExample 5.5.2, applied to the function \\sin(e^{x+1}) at x=0.\n\nf = lambda x: sin(exp(x + 1))\nexact_value = exp(1) * cos(exp(1))\n\nWe’ll compute the formulas in parallel for a sequence of h values.\n\nh_ = array([5 / 10**(n+1) for n in range(6)])\nFD = zeros((len(h_), 2))\nfor (i, h) in enumerate(h_):\n    FD[i, 0] = (f(h) - f(0)) / h \n    FD[i, 1] = (f(h) - f(-h)) / (2*h)\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nprint(results)\n\nAll that’s easy to see from this table is that FD2 appears to converge to the same result as FD1, but more rapidly. A table of errors is more informative.\n\nerrors = FD - exact_value\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"error in FD1\", errors[:, 0])\nresults.add_column(\"error in FD2\", errors[:, 1])\nprint(results)\n\nIn each row, h is decreased by a factor of 10, so that the error is reduced by a factor of 10 in the first-order method and 100 in the second-order method.\n\nA graphical comparison can be useful as well. On a log-log scale, the error should (as h\\to 0) be a straight line whose slope is the order of accuracy. However, it’s conventional in convergence plots to show h decreasing from left to right, which negates the slopes.\n\nplot(h_, abs(errors), \"o-\", label=[\"FD1\", \"FD2\"])\ngca().invert_xaxis()\n# Add lines for perfect 1st and 2nd order.\nloglog(h_, h_, \"--\", label=\"$O(h)$\")\nloglog(h_, h_**2, \"--\", label=\"$O(h^2)$\")\nxlabel(\"$h$\")\nylabel(\"error\")\nlegend();\n\nExample 5.5.4\n\nLet f(x)=e^{-1.3x}. We apply finite-difference formulas of first, second, and fourth order to estimate f'(0)=-1.3.\n\nf = lambda x: exp(-1.3 * x)\nexact = -1.3\n\nh_ = array([1 / 10**(n+1) for n in range(12)])\nFD = zeros((len(h_), 3))\nfor (i, h) in enumerate(h_):\n    nodes = h * linspace(-2, 2, 5)\n    vals = f(nodes)\n    FD[i, 0] = dot(array([0, 0, -1, 1, 0]) / h, vals)\n    FD[i, 1] = dot(array([0, -1/2, 0, 1/2, 0]) / h, vals)\n    FD[i, 2] = dot(array([1/12, -2/3, 0, 2/3, -1/12]) / h, vals)\n\nresults = PrettyTable()\nresults.add_column(\"h\", h_)\nresults.add_column(\"FD1\", FD[:, 0])\nresults.add_column(\"FD2\", FD[:, 1])\nresults.add_column(\"FD4\", FD[:, 2])\nprint(results)\n\nThey all seem to be converging to -1.3. The convergence plot reveals some interesting structure to the errors, though.\n\nloglog(h_, abs(FD[:, 0] + 1.3), \"-o\", label=\"FD1\")\nloglog(h_, abs(FD[:, 1] + 1.3), \"-o\", label=\"FD2\")\nloglog(h_, abs(FD[:, 2] + 1.3), \"-o\", label=\"FD4\")\ngca().invert_xaxis()\nplot(h_, 0.1 * 2 ** (-52) / h_, \"--\", color=\"k\", label=\"$O(h^{-1})$\")\nxlabel(\"$h$\")\nylabel(\"total error\")\ntitle(\"FD error with roundoff\")\nlegend();\n\nAgain the graph is made so that h decreases from left to right. The errors are dominated at first by truncation error, which decreases most rapidly for the fourth-order formula. However, increasing roundoff error eventually equals and then dominates the truncation error as h continues to decrease. As the order of accuracy increases, the crossover point moves to the left (greater efficiency) and down (greater accuracy).","type":"content","url":"/chapter5-2#id-5-5","position":15},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.6 Numerical integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-6","position":16},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.6 Numerical integration","lvl2":"Examples"},"content":"Example 5.6.1\n\nThe antiderivative of e^x is, of course, itself. That makes evaluation of \\int_0^1 e^x\\,dx by the Fundamental Theorem trivial.\n\nexact = exp(1) - 1\n\nThe module scipy.integrate has multiple functions that estimate the value of an integral numerically without finding the antiderivative first. As you can see here, it’s often just as accurate.\n\nfrom scipy.integrate import quad\nQ, errest = quad(exp, 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nThe numerical approach is also far more robust. For example, e^{\\,\\sin x} has no useful antiderivative. But numerically, it’s no more difficult.\n\nQ, errest = quad(lambda x: exp(sin(x)), 0, 1, epsabs=1e-13, epsrel=1e-13)\nprint(Q)\n\nWhen you look at the graphs of these functions, what’s remarkable is that one of these areas is basic calculus while the other is almost impenetrable analytically. From a numerical standpoint, they are practically the same problem.\n\nx = linspace(0, 1, 300)\nsubplot(1, 2, 1)\nplot(x, exp(x))\nylim([0, 2.7]), title(\"exp(x)\")\nsubplot(1, 2, 2)\nplot(x, exp(sin(x)))\nylim([0, 2.7]), title(\"exp(sin(x))\");\n\nExample 5.6.2\n\nWe will approximate the integral of the function f(x)=e^{\\sin 7x} over the interval [0,2].\n\nf = lambda x: exp(sin(7 * x))\na, b = 0, 2\n\nIn lieu of the exact value, we will use the quad function to find an accurate result.\n\nfrom scipy.integrate import quad\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nHere is the trapezoid result at n=40, and its error.\n\nT, t, y = FNC.trapezoid(f, a, b, 40)\nprint(f\"Trapezoid estimate is {T:.14f} with error {I - T:.2e}\")\n\nIn order to check the order of accuracy, we increase n by orders of magnitude and observe how the error decreases.\n\nn_ = 40 * 2 ** arange(6)\nerr = zeros(size(n_))\nprint(\"     n     error\")\nfor k, n in enumerate(n_):\n    T, t, y = FNC.trapezoid(f, a, b, n)\n    err[k] = I - T\n    print(f\"{n:6d}   {err[k]:8.3e} \")\n\nEach increase by a factor of 10 in n cuts the error by a factor of about 100, which is consistent with second-order convergence. Another check is that a log-log graph should give a line of slope -2 as n\\to\\infty.\n\nloglog(n_, abs(err), \"-o\", label=\"results\")\nloglog(n_, 3e-3 * (n_ / n_[0]) ** (-2), \"--\", label=\"2nd order\")\ngca().invert_xaxis()\nxlabel(\"$n$\")\nylabel(\"error\")\nlegend()\ntitle(\"Convergence of trapezoidal integration\");\n\nExample 5.6.3\n\nWe estimate \\displaystyle\\int_0^2 x^2 e^{-2x}\\, dx using extrapolation. First we use quadgk to get an accurate value.\n\nfrom scipy.integrate import quad\nf = lambda x: x**2 * exp(-2 * x)\na = 0\nb = 2\nI, errest = quad(f, a, b, epsabs=1e-13, epsrel=1e-13)\nprint(f\"Integral = {I:.14f}\")\n\nWe start with the trapezoid formula on n=N nodes.\n\nN = 20    # the coarsest formula\nn = N\nh = (b - a) / n\nt = h * arange(n + 1)\ny = f(t)\n\nWe can now apply weights to get the estimate T_f(N).\n\nT = zeros(3)\nT[0] = h * (sum(y[1:-1]) + y[0] / 2 + y[-1] / 2)\nprint(f\"error (2nd order): {I - T[0]:.2e}\")\n\nNow we double to n=2N, but we only need to evaluate f at every other interior node and apply \n\n(5.6.18).\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[1] = T[0] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:2])\n\nAs expected for a second-order estimate, the error went down by a factor of about 4. We can repeat the same code to double n again.\n\nn = 2 * n\nh = h / 2\nt = h * arange(n + 1)\nT[2] = T[1] / 2 + h * sum(f(t[1:-1:2]))\nprint(\"error (2nd order):\", I - T[:3])\n\nLet us now do the first level of extrapolation to get results from Simpson’s formula. We combine the elements T[i] and T[i+1] the same way for i=1 and i=2.\n\nS = array([(4 * T[i + 1] - T[i]) / 3 for i in range(2)])\nprint(\"error (4th order):\", I - S)\n\nWith the two Simpson values S_f(N) and S_f(2N) in hand, we can do one more level of extrapolation to get a sixth-order accurate result.\n\nR = (16 * S[1] - S[0]) / 15\nprint(\"error (6th order):\", I - R)\n\nWe can make a triangular table of the errors:\n\nerr = nan * ones((3, 3))\nerr[0, :] = I - T\nerr[1, 1:] = I - S\nerr[2, 2] = I - R\nresults = PrettyTable([\"2nd order\", \"4th order\", \"6th order\"])\nresults.add_rows(err.T)\nprint(results)\n\nIf we consider the computational time to be dominated by evaluations of f, then we have obtained a result with about twice as many accurate digits as the best trapezoid result, at virtually no extra cost.","type":"content","url":"/chapter5-2#id-5-6","position":17},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.7 Adaptive integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter5-2#id-5-7","position":18},{"hierarchy":{"lvl1":"Chapter 5","lvl3":"5.7 Adaptive integration","lvl2":"Examples"},"content":"Example 5.7.1\n\nThis function gets increasingly oscillatory as x increases.\n\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nx = linspace(0, 4, 600)\nplot(x, f(x))\nxlabel(\"$x$\")\nylabel(\"$f(x)$\");\n\nAccordingly, the trapezoid rule is more accurate on the left half of this interval than on the right half.\n\nn_ = 50 * 2 ** arange(4)\nTleft = zeros(4)\nTright = zeros(4)\nfor i, n in enumerate(n_):\n    Tleft[i] = FNC.trapezoid(f, 0, 2, n)[0]\n    Tright[i] = FNC.trapezoid(f, 2, 4, n)[0]\nprint(\"left half:\", Tleft)\nprint(\"right half:\", Tright)\n\nfrom scipy.integrate import quad\nleft_val, err = quad(f, 0, 2, epsabs=1e-13, epsrel=1e-13)\nright_val, err = quad(f, 2, 4, epsabs=1e-13, epsrel=1e-13)\n\nprint(\"    n     left error   right error\")\nfor k in range(n_.size):\n    print(f\"  {n_[k]:4}    {Tleft[k]-left_val:8.3e}    {Tright[k]-right_val:8.3e}\")\n\nBoth the picture and the numerical results suggest that more nodes should be used on the right half of the interval than on the left half.\n\nExample 5.7.2\n\nWe’ll integrate the function from \n\nDemo 5.7.1.\n\nfrom scipy.integrate import quad\nf = lambda x: (x + 1) ** 2 * cos((2 * x + 1) / (x - 4.3))\nI, errest = quad(f, 0, 4, epsabs=1e-12, epsrel=1e-12)\nprint(\"integral:\", I)    # 'exact' value\n\nWe perform the integration and show the nodes selected underneath the curve.\n\nQ, t = FNC.intadapt(f, 0, 4, 0.001)\nprint(\"number of nodes:\", t.size)\n\nx = linspace(0, 4, 600)\nplot(x, f(x), \"k\")\nstem(t, f(t))\nxlabel(\"$x$\"); ylabel(\"$f(x)$\");\n\nThe error turns out to be a bit more than we requested. It’s only an estimate, not a guarantee.\n\nprint(\"error:\", I - Q)\n\nLet’s see how the number of integrand evaluations and the error vary with the requested tolerance.\n\ntol_ = 10.0 ** arange(-4, -12, -1)\nerr_ = zeros(tol_.size)\nnum_ = zeros(tol_.size, dtype=int)\nprint(\"    tol         error     # f-evals\")\nfor i, tol in enumerate(tol_):\n    Q, t = FNC.intadapt(f, 0, 4, tol)\n    err_[i] = I - Q\n    num_[i] = t.size\n    print(f\"  {tol:6.1e}    {err_[i]:10.3e}    {num_[i]:6d}\")\n\nAs you can see, even though the errors are not smaller than the estimates, the two columns decrease in tandem. If we consider now the convergence not in h, which is poorly defined now, but in the number of nodes actually chosen, we come close to the fourth-order accuracy of the underlying Simpson scheme.\n\nloglog(num_, abs(err_), \"-o\", label=\"results\")\norder4 = 0.01 * (num_ / num_[0]) ** (-4)\nloglog(num_, order4, \"--\", label=\"$O(n^{-4})$\")\nxlabel(\"number of nodes\"), ylabel(\"error\")\nlegend()\ntitle(\"Convergence of adaptive quadrature\");","type":"content","url":"/chapter5-2#id-5-7","position":19},{"hierarchy":{"lvl1":"Chapter 6"},"type":"lvl1","url":"/chapter6-2","position":0},{"hierarchy":{"lvl1":"Chapter 6"},"content":"","type":"content","url":"/chapter6-2","position":1},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"type":"lvl2","url":"/chapter6-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Functions"},"content":"Euler’s method for an initial-value problem\n\ndef euler(du_dt, tspan, u0, n):\n    \"\"\"\n    euler(du_dt, tspan, u0, n)\n\n    Apply Euler's method to solve the IVP u'=du_dt(u,t) over the interval tspan with\n    u(tspan[1])=u0, using n subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * du_dt(t[i], u[i])\n\n    return t, u.T\n\nImproved Euler method for an IVP\n\ndef ie2(du_dt, tspan, u0, n):\n    \"\"\"\n    ie2(du_dt, tspan, u0, n)\n\n    Apply the Improved Euler method to solve the vector-valued IVP u'=du_dt(u,p,t) over the\n    interval tspan with u(tspan[1])=u0, using n subintervals/steps. Returns a vector\n    of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        uhalf = u[i] + h / 2 * du_dt(t[i], u[i])\n        u[i+1] = u[i] + h * du_dt(t[i] + h / 2, uhalf)\n\n    return t, u.T\n\nFourth-order Runge-Kutta for an IVP\n\ndef rk4(du_dt, tspan, u0, n):\n    \"\"\"\n    rk4(du_dt, tspan, u0, n)\n\n    Apply \"the\" Runge-Kutta 4th order method to solve the vector-valued IVP u'=du_dt(u,p,t)\n    over the interval tspan with u(tspan[1])=u0, using n subintervals/steps.\n    Return a vector of times and a vector of solution values/vectors.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        k1 = h * du_dt(t[i], u[i])\n        k2 = h * du_dt(t[i] + h / 2, u[i] + k1 / 2)\n        k3 = h * du_dt(t[i] + h / 2, u[i] + k2 / 2)\n        k4 = h * du_dt(t[i] + h, u[i] + k3)\n        u[i+1] = u[i] + (k1 + 2 * (k2 + k3) + k4) / 6\n\n    return t, u.T\n\nAdaptive IVP solver based on embedded RK formulas\n\ndef euler(du_dt, tspan, u0, n):\n    \"\"\"\n    euler(du_dt, tspan, u0, n)\n\n    Apply Euler's method to solve the IVP u'=du_dt(u,t) over the interval tspan with\n    u(tspan[1])=u0, using n subintervals/steps. Return vectors of times and solution\n    values.\n    \"\"\"\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    for i in range(n):\n        u[i+1] = u[i] + h * du_dt(t[i], u[i])\n\n    return t, u.T\n\nAbout the code\n\nThe check t[i]+h==t[i]on line 19 is to detect when h has become so small that it no longer changes the floating-point value of t_i. This may be a sign that the underlying exact solution has a singularity near t=t_i, but in any case, the solver must halt by using a break statement to exit the loop.\n\nOn line 30, we use a combination of absolute and relative tolerances to judge the acceptability of a solution value, as in \n\n(5.7.6). In lines 41--43 we underestimate the step factor q a bit and prevent a huge increase in the step size, since a rejected step is expensive, and then we make sure that our final step doesn’t take us past the end of the domain.\n\nFinally, line 37 exploits a subtle property of the BS23 formula called first same as last (FSAL).\nWhile \n\n(6.5.5) calls for four stages to find the paired second- and third-order estimates, the final stage computed in stepping from t_i to t_{i+1} is identical to the first stage needed to step from t_{i+1} to t_{i+2}. By repurposing s₄ as s₁ for the next pass, one of the stage evaluations comes for free, and only three evaluations of f are needed per successful step.\n\n4th-order Adams–Bashforth formula for an IVP\n\ndef ab4(du_dt, tspan, u0, n):\n    \"\"\"\n    ab4(du_dt, tspan, u0, n)\n\n    Apply the Adams-Bashforth 4th order method to solve the vector-valued IVP u'=du_dt(u,p,t)\n    over the interval tspan with u(tspan[1])=u0, using n subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Constants in the AB4 method.\n    k = 4\n    sigma = np.array([55, -59, 37, -9]) / 24\n\n    # Find starting values by RK4.\n    ts, us = rk4(du_dt, [a, a + (k - 1) * h], u0, k - 1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[:k] = us[:k].T\n\n    # Compute history of u' values, from newest to oldest.\n    f = np.array([du_dt(t[k-j-2], u[k-j-2]) for j in range(k)])\n\n    # Time stepping.\n    for i in range(k-1, n):\n        f = np.vstack([du_dt(t[i], u[i]), f[:-1]])  # new value of du/dt\n        u[i+1] = u[i] + h * np.dot(sigma, f)  # advance one step\n\n    return t, u.T\n\nAbout the code\n\nLine 15 sets σ to be the coefficients of the generating polynomial \\sigma(z) of AB4. Lines 19--21 set up the IVP over the time interval a \\le t \\le a+3 h, call rk4 to solve it using the step size h, and use the result to fill the first four values of the solution. Then line 24 computes the vector [f_2,f_1,f_0].\n\nLine 28 computes f_i, based on the most recent solution value and time. That goes into the first spot of f, followed by the three values that were previously most recent. These are the four values that appear in \n\n(6.7.1). Each particular f_i value starts at the front of f, moves through each position in the vector over three iterations, and then is forgotten.\n\n2nd-order Adams–Moulton (trapezoid) formula for an IVP\n\ndef am2(du_dt, tspan, u0, n):\n    \"\"\"\n    am2(du_dt, tspan, u0, n)\n\n    Apply the Adams-Moulton 2nd order method to solve the vector-valued IVP u'=du_dt(u,p,t)\n    over the interval tspan with u(tspan[1])=u0, using n subintervals/steps.\n    \"\"\"\n    # Time discretization.\n    a, b = tspan\n    h = (b - a) / n\n    t = np.linspace(a, b, n + 1)\n\n    # Initialize output.\n    u = np.tile(np.array(u0), (n+1, 1))\n\n    # Time stepping.\n    for i in range(n):\n        # Data that does not depend on the new value.\n        known = u[i] + h / 2 * du_dt(t[i], u[i])\n        # Find a root for the new value.\n        F = lambda z: z - h / 2 * du_dt(t[i+1], z) - known\n        unew = levenberg(F, known)\n        u[i+1] = unew[-1]\n\n    return t, u.T\n\nAbout the code\n\nLines 22-23 define the function \\mathbf{g} and call levenberg to find the new solution value, using an Euler half-step as its starting value. A robust code would have to intercept the case where levenberg fails to converge, but we have ignored this issue for the sake of brevity.","type":"content","url":"/chapter6-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"type":"lvl2","url":"/chapter6-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 6","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter6-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.1 Basics of IVPs","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-1","position":6},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.1 Basics of IVPs","lvl2":"Examples"},"content":"Example 6.1.2\n\nLet’s use solve_ivp from scipy.integrate to define and solve an initial-value problem for u'=\\sin[(u+t)^2] over t \\in [0,4], such that u(0)=-1.\n\nTo create an initial-value problem for u(t), you must supply a function that computes u', an initial value for u, and the endpoints of the interval for t. The t interval should be defined as (a,b), where at least one of the values is a float.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = [-1.0]\n\nNote above that even though this is a problem for a scalar function u(t), we had to set the initial condition as a “one-dimensional vector.”\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, u0)\n\nThe resulting solution object has fields t and y that contain the values of the independent and dependent variables, respectively; those field names are the same regardless of what we use in our own codes.\n\nprint(\"t shape:\", sol.t.shape)\nprint(\"u shape:\", sol.y.shape)\nplot(sol.t, sol.y[0, :], \"-o\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle((\"Solution of $u' = sin((t+u)^2)$\"));\n\nYou can see above that the solution was not computed at enough points to make a smooth graph. There is a way to request output at times of your choosing.\n\nsol = solve_ivp(f, tspan, u0, t_eval=linspace(0, 4, 200))\nplot(sol.t, sol.y[0, :], \"-\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle((\"Solution of $u' = sin((t+u)^2)$\"));\n\nAnother option is to enable interpolation to evaluate the solution anywhere after the fact:\n\nsol = solve_ivp(f, tspan, u0, dense_output=True)\nfor t in linspace(0, 4, 6):\n    print(f\"u({t:.2f}) = {sol.sol(t)[0]:.4f}\")\n\nExample 6.1.3\n\nThe equation u'=(u+t)^2 gives us some trouble.\n\nTip\n\nIt’s a good idea to check sol.success after calling solve_ivp. If it’s False, the solution may not be reliable.\n\nf = lambda t, u: (t + u) ** 2\nsol = solve_ivp(f, [0.0, 1.0], [1.0])\nif not sol.success:\n    print(sol.message)\n\nThe warning message we received can mean that there is a bug in the formulation of the problem. But if everything has been done correctly, it suggests that the solution may not exist past the indicated time. This is a possibility in nonlinear ODEs.\n\nsemilogy(sol.t, sol.y[0, :])\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle((\"Blowup in finite time\"));\n\nExample 6.1.5\n\nConsider the ODEs u'=u and u'=-u. In each case we compute \\partial f/\\partial u = \\pm 1, so the condition number bound from \n\nTheorem 6.1.2 is e^{b-a} in both problems. However, they behave quite differently. In the case of exponential growth, u'=u, the bound is the actual condition number.\n\nt = linspace(0, 3, 200)\nu = array([exp(t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle((\"Exponential divergence of solutions\"));\n\nBut with u'=-u, solutions actually get closer together with time.\n\nt = linspace(0, 3, 200)\nu = array([exp(-t) * u0 for u0 in [0.7, 1, 1.3]])\nplot(t, u.T)\nxlabel(\"$t$\")\nylabel(\"$u(t)$\")\ntitle((\"Exponential convergence of solutions\"));\n\nIn this case the actual condition number is one, because the initial difference between solutions is the largest over all time. Hence, the exponentially growing upper bound e^{b-a} is a gross overestimate.","type":"content","url":"/chapter6-2#id-6-1","position":7},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.2 Euler’s method","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-2","position":8},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.2 Euler’s method","lvl2":"Examples"},"content":"Example 6.2.1\n\nWe consider the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1.\n\nf = lambda t, u: sin((t + u) ** 2)\ntspan = [0.0, 4.0]\nu0 = -1.0\nt, u = FNC.euler(f, tspan, u0, 20)\n\nfig, ax = subplots()\nax.plot(t, u[0, :], \"-o\", label=\"$n=20$\")\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle(\"Solution by Euler's method\")\nlegend();\n\nWe could define a different interpolant to get a smoother picture above, but the derivation of Euler’s method assumed a piecewise linear interpolant. We can instead request more steps to make the interpolant look smoother.\n\nt, u = FNC.euler(f, tspan, u0, 200)\nax.plot(t, u[0, :], label=\"$n=200$\")\nax.legend()\nfig\n\nIncreasing n changed the solution noticeably. Since we know that interpolants and finite differences become more accurate as h\\to 0, we should anticipate the same behavior from Euler’s method. We don’t have an exact solution to compare to, so we will use solve_ivp to construct an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\nsol = solve_ivp(f, tspan, [u0], dense_output=True, atol=1e-8, rtol=1e-8)\nax.plot(t, sol.sol(t)[0, :], \"--\", label=\"accurate\")\nax.legend()\nfig\n\nNow we can perform a convergence study.\n\nn_ = array([int(5 * 10**k) for k in arange(0, 3, 0.5)])\nerr_ = zeros(6)\nresults = PrettyTable([\"n\", \"error\"])\nfor j, n in enumerate(n_):\n    t, u = FNC.euler(f, tspan, u0, n)\n    err_[j] = norm(sol.sol(t)[0, :] - u[0, :], inf)\n    results.add_row((n, err_[j]))\nprint(results)\n\nThe error is approximately cut by a factor of 10 for each increase in n by the same factor. A log-log plot also confirms first-order convergence. Keep in mind that since h=(b-a)/n, it follows that O(h)=O(n^{-1}).\n\nloglog(n_, err_, \"-o\", label=\"results\")\nplot(n_, 0.5 * (n_ / n_[0])**(-1), \"--\", label=\"1st order\")\nxlabel(\"$n$\"), ylabel(\"inf-norm error\")\ntitle(\"Convergence of Euler's method\")\nlegend();","type":"content","url":"/chapter6-2#id-6-2","position":9},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.3 IVP systems","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-3","position":10},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.3 IVP systems","lvl2":"Examples"},"content":"Example 6.3.2\n\nWe encode the predator–prey equations via a function.\n\ndef predprey(t, u):\n    y, z = u                        # rename for convenience\n    s = (y * z) / (1 + beta * y)    # appears in both equations\n    return array([y * (1 - alpha * y) - s, -z + s])\n\nAs before, the ODE function must accept three inputs, u, p, and t, even though in this case there is no explicit dependence on t. The second input is used to pass parameters that don’t change throughout a single instance of the problem.\n\nTo specify the IVP we must also provide the initial condition, which is a 2-vector here, and the interval for the independent variable. These are given in the call to solve_ivp.\n\nfrom scipy.integrate import solve_ivp\nu0 = array([1, 0.01])\ntspan = [0.0, 80.0]\nalpha, beta = 0.1, 0.25\nsol = solve_ivp(predprey, tspan, u0, dense_output=True)\nprint(f\"solved with {sol.y.shape[1]} time steps\")\n\nAs in scalar problems, the solution object has fields t and y that contain the values of the independent and dependent variables, respectively. Each row of y represents one component of the solution at every time step, and each column of y is the entire solution vector at one time step. Since we used dense_output=True, there is also a method sol that can be used to evaluate the solution at any time.\n\nt = linspace(0, 80, 1200)\nu = vstack([sol.sol(t[i]) for i in range(t.size)]).T    # same shape as sol.y\nfig, ax = subplots()\nax.plot(t, u[0, :], label=\"prey\")\nax.plot(t, u[1, :], label=\"predator\")\nxlabel(\"$t$\"), ylabel(\"population\")\ntitle((\"Predator-prey solution\"));\n\nWe can also use \n\nFunction 6.2.2 to find the solution.\n\nt_E, u_E = FNC.euler(predprey, tspan, u0, 800)\nax.scatter(t_E, u_E[0, :], label=\"prey (Euler)\", s=1)\nax.scatter(t_E, u_E[1, :], label=\"predator (Euler)\", s=2)\nax.legend()\nfig\n\nYou can see above that the Euler solution is not very accurate. When the solution has two components, it’s common to plot the it in the phase plane, i.e., with u_1 and u_2 along the axes and time as a parameterization of the curve.\n\nplot(u[0, :], u[1, :])\nxlabel(\"prey\"), ylabel(\"predator\")\ntitle((\"Predator-prey phase plane\"));\n\nFrom this plot we can see that the solution approaches a periodic one, which in the phase plane is represented by a closed path.\n\nExample 6.3.5\n\nLet’s implement the coupled pendulums from \n\nExample 6.3.4. The pendulums will be pulled in opposite directions and then released together from rest.\n\ndef couple(t, u, params):\n    gamma, L, k = params\n    g = 9.8\n    udot = copy(u)\n    udot[:2] = u[2:4]\n    udot[2] = -gamma * u[2] - (g / L) * sin(u[0]) + k * (u[1] - u[0])\n    udot[3] = -gamma * u[3] - (g / L) * sin(u[1]) + k * (u[0] - u[1])\n    return udot\n\nu0 = array([1.25, -0.5, 0, 0])\ntspan = [0.0, 50.0]\n\nFirst we check the behavior of the system when the pendulums are uncoupled, i.e., when k=0.\n\nTip\n\nWe use a closure here to pass the fixed parameter values into couple.\n\ngamma, L, k = 0.01, 0.5, 0.0\ndu_dt = lambda t, u: couple(t, u, (gamma, L, k))\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)    # first two components of solution\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Uncoupled pendulums\");\n\nYou can see that the pendulums swing independently. Because the model is nonlinear and the initial angles are not small, they have slightly different periods of oscillation, and they go in and out of phase.\n\nWith coupling activated, a different behavior is seen.\n\nk = 0.75    # changes the value in the du_dt closure\nsol = solve_ivp(du_dt, tspan, u0, t_eval=linspace(0, 50, 1000))\nplot(sol.t, sol.y[:2, :].T)\nxlabel(\"t\"), ylabel(\"angle\")\ntitle(\"Coupled pendulums\");\n\nThe coupling makes the pendulums swap energy back and forth.","type":"content","url":"/chapter6-2#id-6-3","position":11},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.4 Runge–Kutta methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-4","position":12},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.4 Runge–Kutta methods","lvl2":"Examples"},"content":"Example 6.4.1\n\nWe solve the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. We start by getting a reference solution to validate against.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = -1.0\nsol = solve_ivp(du_dt, tspan, [u0], dense_output=True, atol=1e-13, rtol=1e-13)\nu_ref = sol.sol\n\nNow we perform a convergence study of our two Runge–Kutta implementations.\n\nn = array([int(2 * 10**k) for k in linspace(0, 3, 7)])\nerr = {\"IE2\" : [], \"RK4\" : []}\nresults = PrettyTable([\"n\", \"IE2 error\", \"RK4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ie2(du_dt, tspan, u0, n[i])\n    err[\"IE2\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    t, u = FNC.rk4(du_dt, tspan, u0, n[i])\n    err[\"RK4\"].append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[\"IE2\"][-1], err[\"RK4\"][-1]])\n\nprint(results)\n\nThe amount of computational work at each time step is assumed to be proportional to the number of stages. Let’s compare on an apples-to-apples basis by using the number of f-evaluations on the horizontal axis.\n\nloglog(2 * n, err[\"IE2\"], \"-o\", label=\"IE2\")\nloglog(4 * n, err[\"RK4\"], \"-o\", label=\"RK4\")\nplot(2 * n, 0.5 * err[\"IE2\"][-1] * (n / n[-1])**(-2), \"--\", label=\"2nd order\")\nplot(4 * n, 0.5 * err[\"RK4\"][-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"f-evaluations\"),  ylabel(\"inf-norm error\")\nlegend()\ntitle(\"Convergence of RK methods\");\n\nThe fourth-order variant is more efficient in this problem over a wide range of accuracy.","type":"content","url":"/chapter6-2#id-6-4","position":13},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.5 Adaptive Runge–Kutta","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-5","position":14},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.5 Adaptive Runge–Kutta","lvl2":"Examples"},"content":"Example 6.5.1\n\nLet’s run adaptive RK on  u'=e^{t-u\\sin u}.\n\nf = lambda t, u: exp(t - u * sin(u))\nt, u = FNC.rk23(f, [0.0, 5.0], [0.0], 1e-5)\nscatter(t, u[0, :])\nxlabel(\"$t$\"), ylabel(\"$u(t)$\")\ntitle((\"Adaptive IVP solution\"));\n\nThe solution makes a very abrupt change near t=2.4. The resulting time steps vary over three orders of magnitude.\n\ndt = [t[i + 1] - t[i] for i in range(t.size - 1)]\nsemilogy(t[:-1], dt)\nxlabel(\"$t$\"), ylabel(\"time step\")\ntitle((\"Adaptive step sizes\"));\n\nIf we had to run with a uniform step size to get this accuracy, it would be\n\nprint(f\"min step size was {min(dt):.2e}\")\n\nOn the other hand, the average step size that was actually taken was\n\nprint(f\"mean step size was {mean(dt):.2e}\")\n\nWe took fewer steps by a factor of 1000! Even accounting for the extra stage per step and the occasional rejected step, the savings are clear.\n\nExample 6.5.2\n\nIn \n\nDemo 6.1.3 we saw an IVP that appears to blow up in a finite amount of time. Because the solution increases so rapidly as it approaches the blowup, adaptive stepping is required even to get close.\n\ndu_dt = lambda t, u: (t + u)**2\ntspan = (0.0, 2.0)\nu0 = [1.0]\nt, u = FNC.rk23(du_dt, tspan, u0, 1e-5)\n\nIn fact, the failure of the adaptivity gives a decent idea of when the singularity occurs.\n\nsemilogy(t, u[0, :])\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\ntitle(\"Finite-time blowup\")\n\ntf = t[-1]\naxvline(x=tf, color='k', linestyle='--', label=f\"t = {tf:.6f}\")\nlegend();","type":"content","url":"/chapter6-2#id-6-5","position":15},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.6 Multistep methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-6","position":16},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.6 Multistep methods","lvl2":"Examples"},"content":"Example 6.7.1\n\nWe study the convergence of AB4 using the IVP u'=\\sin[(u+t)^2] over 0\\le t \\le 4, with u(0)=-1. As usual, solve_ivp is called to give an accurate reference solution.\n\nfrom scipy.integrate import solve_ivp\ndu_dt = lambda t, u: sin((t + u)**2)\ntspan = (0.0, 4.0)\nu0 = [-1.0]\nu_ref = solve_ivp(du_dt, tspan, u0, dense_output=True, rtol=1e-13, atol=1e-13).sol\n\nNow we perform a convergence study of the AB4 code.\n\nn = array([int(4 * 10**k) for k in linspace(0, 3, 7)])\nerr = []\nresults = PrettyTable([\"n\", \"AB4 error\"])\nfor i in range(len(n)):\n    t, u = FNC.ab4(du_dt, tspan, u0, n[i])\n    err.append( abs(u_ref(4)[0] - u[0][-1]) )\n    results.add_row([n[i], err[-1]])\n\nprint(results)\n\nThe method should converge as O(h^4), so a log-log scale is appropriate for the errors.\n\nloglog(n, err, \"-o\", label=\"AB4\")\nloglog(n, 0.5 * err[-1] * (n / n[-1])**(-4), \"--\", label=\"4th order\")\n\nxlabel(\"$n$\"),  ylabel(\"final error\")\nlegend(), title(\"Convergence of AB4\");\n\nExample 6.7.2\n\nThe following simple ODE uncovers a surprise.\n\nf = lambda t, u: u**2 - u**3\nu0 = array([0.005])\ntspan = [0, 400]\n\nWe will solve the problem first with the implicit AM2 method using n=200 steps.\n\ntI, uI = FNC.am2(f, [0.0, 400.0], u0, 200)\nfig, ax = subplots()\nax.plot(tI, uI[0], label=\"AM2\")\nxlabel(\"$t$\"), ylabel(\"$y(t)$\");\n\nSo far, so good. Now we repeat the process using the explicit AB4 method.\n\ntE, uE = FNC.ab4(f, [0.0, 400.0], u0, 200)\nax.scatter(tE, uE[0], label=\"AB4\")\nax.set_ylim([-4, 2]), ax.legend()\nfig\n\nOnce the solution starts to take off, the AB4 result goes catastrophically wrong.\n\nuE[0, 104:111]\n\nWe hope that AB4 will converge in the limit h\\to 0, so let’s try using more steps.\n\nplot(tI, uI[0], color=\"k\", label=\"AM2\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1000)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1000\")\ntE, uE = FNC.ab4(f, [0, 400], u0, 1600)\nplot(tE, uE[0], \".-\", label=\"AM4, n=1600\")\nxlabel(\"$t$\"),  ylabel(\"$u(t)$\")\nlegend();\n\nSo AB4, which is supposed to be more accurate than AM2, actually needs something like 8 times as many steps to get a reasonable-looking answer!","type":"content","url":"/chapter6-2#id-6-6","position":17},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.7 Implementation of multistep methods","lvl2":"Examples"},"type":"lvl3","url":"/chapter6-2#id-6-7","position":18},{"hierarchy":{"lvl1":"Chapter 6","lvl3":"6.7 Implementation of multistep methods","lvl2":"Examples"},"content":"Example 6.8.1\n\nWe’ll measure the error at the time t=1.\n\ndu_dt = lambda t, u: u\nu_exact = exp\na, b = (0.0, 1.0)\n\ndef LIAF(du_dt, tspan, u0, n):\n    a, b = tspan\n    h = (b - a) / n\n    t = linspace(a, b, n+1)\n    u = np.tile(np.array(u0), (n+1, 1))\n    u[1] = u_exact(t[1])    # use an exact starting value\n    f = copy(u)\n    f[0] = du_dt(t[0], u[0])\n    for i in range(n):\n        f[i] = du_dt(t[i], u[i])\n        u[i + 1] = -4 * u[i] + 5 * u[i-1] + h * (4 * f[i] + 2 * f[i-1])\n\n    return t, u.T\n\nn = [5, 10, 20, 40, 60]\nresults = PrettyTable([\"n\", \"error\"])\nfor j in range(5):\n    t, u = LIAF(du_dt, [a, b], [1.0], n[j])\n    err = abs(u_exact(b) - u[0, -1])\n    results.add_row([n[j], err])\nprint(results)\n\nThere is no convergence in sight! A graph of the last numerical attempt yields a clue:\n\nsemilogy(t, abs(u[0]), \"-o\")\nxlabel(\"$t$\"), ylabel(\"$|u|$\")\ntitle((\"LIAF solution\"));\n\nIt’s clear that the solution is growing exponentially in time.","type":"content","url":"/chapter6-2#id-6-7","position":19},{"hierarchy":{"lvl1":"Chapter 7"},"type":"lvl1","url":"/chapter7-2","position":0},{"hierarchy":{"lvl1":"Chapter 7"},"content":"","type":"content","url":"/chapter7-2","position":1},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"type":"lvl2","url":"/chapter7-2#examples","position":2},{"hierarchy":{"lvl1":"Chapter 7","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter7-2#examples","position":3},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.1 From matrix to insight","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#id-7-1","position":4},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.1 From matrix to insight","lvl2":"Examples"},"content":"Example 7.1.4\n\nHere we create an adjacency matrix for a graph on four nodes.\n\nA = array([[0, 1, 0, 0], [1, 0, 0, 0], [1, 1, 0, 1], [0, 1, 1, 0]])\nprint(A)\n\nThe networkx package has many functions for working with graphs. Here, we instruct it to create a directed graph from the adjacency matrix, then make a drawing of it.\n\nimport networkx as nx\nG = nx.from_numpy_array(A, create_using=nx.DiGraph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nHere are the counts of all walks of length 3 in the graph:\n\nprint(linalg.matrix_power(A, 3))\n\nIf the adjacency matrix is symmetric, the result is an undirected graph: all edges connect in both directions.\n\nA = array([[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 0], [0, 1, 0, 0]])\nG = nx.from_numpy_array(A, create_using=nx.Graph)\nnx.draw(G, with_labels=True, node_color=\"yellow\")\n\nExample 7.1.5\n\nWe will use a test image from the well-known scikit-image package.\n\nfrom skimage import data as testimages\nimg = getattr(testimages, \"coffee\")()\nimshow(img)\n\nThe variable img is a matrix.\n\nsize(img)\n\nHowever, its entries are colors, not numbers.\n\nprint(f\"image has shape {img.shape}\")\nprint(f\"first pixel has value {img[0, 0]}\")\n\nThe three values at each pixel are for intensities of red, green, and blue. We can convert each of those layers into an ordinary matrix of values between 0 and 255, which is maximum intensity.\n\nR = img[:, :, 0]\nprint(\"upper left corner of the red plane is:\")\nprint(R[:5, :5])\nprint(f\"red channel values range from {R.min()} to {R.max()}\")\n\nIt may also be convenient to convert the image to grayscale, which has just one layer of values from zero (black) to one (white).\n\nfrom skimage.color import rgb2gray\nA = rgb2gray(img)\nA[:5, :5]\nprint(\"upper left corner of grayscale:\")\nprint(A[:5, :5])\nprint(f\"gray values range from {A.min()} to {A.max()}\")\n\nimshow(A, cmap='gray')\naxis('off');\n\nSome changes we make to the grayscale matrix are easy to interpret visually.\n\nimshow(flipud(A), cmap='gray')\naxis('off');","type":"content","url":"/chapter7-2#id-7-1","position":5},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.2 Eigenvalue decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#id-7-2","position":6},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.2 Eigenvalue decomposition","lvl2":"Examples"},"content":"Example 7.2.2\n\nThe eig function from scipy.linalg will return a vector of eigenvalues and a matrix of associated eigenvectors.\n\nfrom numpy.linalg import eig\nA = pi * ones([2, 2])\nd, V = eig(A)\nprint(\"eigenvalues:\", d)\n\nWe can check the fact that this is an EVD (although in practice we never invert a matrix).\n\nfrom numpy.linalg import inv\nD = diag(d)\nprint(f\"should be near zero: {norm(A - V @ D @ inv(V), 2):.2e}\")\n\nIf the matrix is not diagonalizable, no message is given, but V will be singular. The robust way to detect that circumstance is via \\kappa(\\mathbf{V}).\n\nfrom numpy.linalg import cond\nA = array([[1, 1], [0, 1]])\nd, V = eig(A)\nprint(f\"cond(V) is {cond(V):.2e}\")\n\nBut even in the nondiagonalizable case, \\mathbf{A}\\mathbf{V} = \\mathbf{V}\\mathbf{D} holds up to roundoff error.\n\nprint(f\"should be near zero: {norm(A @ V - V @ diag(d), 2):.2e}\")\n\nExample 7.2.3\n\nWe first define a hermitian matrix. Note that we add the conjugate transpose of a matrix to itself.\n\nn = 7\nA = random.randn(n, n) + 1j * random.randn(n, n)\nA = (A + conj(A.T)) / 2\n\nWe confirm that the matrix \\mathbf{A} is normal by checking that \\kappa(\\mathbf{V}) = 1 (to within roundoff).\n\nfrom numpy.linalg import eig\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.5f}\")\n\nNow we perturb \\mathbf{A} and measure the effect on the eigenvalues. Note that the Bauer–Fike theorem uses absolute differences, not relative ones. Since the ordering of eigenvalues can change, we look at all pairwise differences and take the minima.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(dist)\n\nAs promised, the perturbations in the eigenvalues do not exceed the normwise perturbation to the original matrix.\n\nNow we see what happens for a triangular matrix.\n\nn = 20\nx = arange(n) + 1\nA = triu(outer(x, ones(n)))\nprint(A[:5, :5])\n\nThis matrix is not at all close to normal.\n\nd, V = eig(A)\nprint(f\"eigenvector matrix has condition number {cond(V):.2e}\")\n\nAs a result, the eigenvalues can change by a good deal more.\n\nE = random.randn(n, n) + 1j * random.randn(n, n)\nE = 1e-8 * E / norm(E, 2)\ndd, _ = eig(A + E)\ndist = array([min([abs(x - y) for x in dd]) for y in d])\nprint(f\"Maximum eigenvalue change is {max(dist):.2e}\")\nprint(f\"The Bauer-Fike upper bound is {cond(V) * norm(E, 2):.2e}\")\n\nIf we plot the eigenvalues of many perturbations, we get a cloud of points that roughly represents all the possible eigenvalues when representing this matrix with single-precision accuracy.\n\nclf\nscatter(d, zeros(n), 18)\naxis(\"equal\") \nfor _ in range(100):\n    E = random.randn(n, n) + 1j * random.randn(n, n)\n    E = finfo(np.float32).eps * E / norm(E, 2)\n    dd, _ = eig(A + E)\n    scatter(real(dd), imag(dd), 2, 'k')\n\nThe plot shows that some eigenvalues are much more affected than others. This situation is not unusual, but it is not explained by the Bauer–Fike theorem.\n\nExample 7.2.4\n\nLet’s start with a known set of eigenvalues and an orthogonal eigenvector basis.\n\nfrom numpy.linalg import qr\nD = diag([-6, -1, 2, 4, 5])\nV, R = qr(random.randn(5, 5))\nA = V @ D @ V.T    # note that V.T = inv(V) here\n\nprint(sort(eig(A)[0]))\n\nNow we will take the QR factorization and just reverse the factors.\n\nQ, R = qr(A)\nA = R @ Q;\n\nIt turns out that this is a similarity transformation, so the eigenvalues are unchanged.\n\nprint(sort(eig(A)[0]))\n\nWhat’s remarkable, and not elementary, is that if we repeat this transformation many times, the resulting matrix converges to \\mathbf{D}.\n\nfor k in range(40):\n    Q, R = qr(A)\n    A = R @ Q\nset_printoptions(precision=4)\nprint(A)","type":"content","url":"/chapter7-2#id-7-2","position":7},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.3 Singular value decomposition","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#id-7-3","position":8},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.3 Singular value decomposition","lvl2":"Examples"},"content":"Example 7.3.4\n\nWe verify some of the fundamental SVD properties using standard functions from numpy.linalg.\n\nA = array([[(i + 1.0) ** j for j in range(4)] for i in range(5)])\nset_printoptions(precision=4)\nprint(A)\n\nThe factorization is obtained using svd from numpy.linalg.\n\nfrom numpy.linalg import svd\nU, sigma, Vh = svd(A)\nprint(\"singular values:\")\nprint(sigma)\n\nBy default, the full factorization type is returned. This can be a memory hog if one of the dimensions of \\mathbf{A} is very large.\n\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.T.shape)\n\nBoth \\mathbf{U} and \\mathbf{V} are orthogonal (in the complex case, unitary). Note that it’s \\mathbf{V}^* that is returned, not \\mathbf{V}.\n\nprint(f\"should be near zero: {norm(U.T @ U - eye(5), 2):.2e}\")\nprint(f\"should be near zero: {norm(Vh @ Vh.T - eye(4), 2):.2e}\")\n\nNext we test that we have the factorization promised by the SVD, using diagsvd to construct a rectangular diagonal matrix.\n\nfrom scipy.linalg import diagsvd\nS = diagsvd(sigma, 5, 4)\nprint(f\"should be near zero: {norm(A - U @ S @ Vh, 2):.2e}\")\n\nHere is verification of the connections between the singular values, norm, and condition number.\n\nfrom numpy.linalg import cond\nprint(\"largest singular value:\", sigma[0])\nprint(\"2-norm of the matrix:  \", norm(A, 2))\nprint(\"singular value ratio:\", sigma[0] / sigma[-1])\nprint(\"2-norm condition no.:\", cond(A, 2))\n\nFor matrices that are much taller than they are wide, the thin SVD form is more memory-efficient, because \\mathbf{U} takes the same shape.\n\nA = random.randn(1000, 10)\nU, sigma, Vh = svd(A, full_matrices=False)\nprint(\"size of U:\", U.shape)\nprint(\"size of V:\", Vh.shape)","type":"content","url":"/chapter7-2#id-7-3","position":9},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.4 Symmetry and definiteness","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#id-7-4","position":10},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.4 Symmetry and definiteness","lvl2":"Examples"},"content":"Example 7.4.1\n\nWe will use a symmetric matrix with a known EVD and eigenvalues equal to the integers from 1 to 20.\n\nfrom numpy.linalg import qr\nn = 20\nd = arange(n) + 1\nD = diag(d)\nV, _ = qr(random.randn(n, n))    # get a random orthogonal V\nA = V @ D @ V.T\n\nThe Rayleigh quotient is a scalar-valued function of a vector.\n\nR = lambda x: dot(x, A @ x) / dot(x, x)\n\nThe Rayleigh quotient evaluated at an eigenvector gives the corresponding eigenvalue.\n\nprint(R(V[:, 6]))\n\nIf the input to he Rayleigh quotient is within a small δ of an eigenvector, its output is within O(\\delta^2) of the corresponding eigenvalue. In this experiment, we observe that each additional digit of accuracy in an approximate eigenvector gives two more digits to the eigenvalue estimate coming from the Rayleigh quotient.\n\nresults = PrettyTable([\"perturbation size\", \"R.Q. - λ\"])\nfor delta in 1 / 10 ** arange(1, 6):\n    e = random.randn(n)\n    e = delta * e / norm(e)\n    x = V[:, 5] + e\n    quotient = R(x)\n    results.add_row([delta, quotient - d[5]])\n\nprint(results)","type":"content","url":"/chapter7-2#id-7-4","position":11},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.5 Dimension reduction","lvl2":"Examples"},"type":"lvl3","url":"/chapter7-2#id-7-5","position":12},{"hierarchy":{"lvl1":"Chapter 7","lvl3":"7.5 Dimension reduction","lvl2":"Examples"},"content":"Example 7.5.1\n\nWe make an image from some text, then reload it as a matrix.\n\ntext(\n    0.5,\n    0.5,\n    \"Hello world\",\n    dict(fontsize=44),\n    horizontalalignment=\"center\",\n    verticalalignment=\"center\",\n)\naxis(\"off\")\nsavefig(\"hello.png\")\n\nimg = imread(\"hello.png\")[:, :, :3]\nA = rgb2gray(img)\nprint(f\"image of size {A.shape}\")\n\nNext we show that the singular values decrease until they reach zero (more precisely, until they are about \\epsilon_\\text{mach} times the norm of the matrix) at around index 38.\n\nfrom numpy.linalg import svd\nU, sigma, Vt = svd(A)\nsemilogy(sigma, \"o\")\ntitle(\"Singular values\")\nxlabel(\"$i$\"), ylabel(\"$\\\\sigma_i$\");\n\nsignificant = sigma / sigma[0] > 10 * 2**-52\nprint(f\"last significant singular value at index {max(where(significant)[0])}\")\n\nThe rapid decrease suggests that we can get fairly good low-rank approximations.\n\nfor k in range(4):\n    r = 2 + 2 * k\n    Ak = U[:, :r] @ diag(sigma[:r]) @ Vt[:r, :]\n    subplot(2, 2, k + 1)\n    imshow(Ak, cmap=\"gray\", clim=(0.0, 1.0))\n    title(f\"rank = {r}\")\n    xticks([]), yticks([])\n\nConsider how little data is needed to reconstruct these images. For rank-8, for instance, we have 8 left and right singular vectors plus 8 singular values.\n\nm, n = A.shape\nfull_size = m * n\ncompressed_size = 8 * (m + n + 1)\nprint(f\"compression ratio: {full_size / compressed_size:.1f}\")\n\nExample 7.5.2\n\nThis matrix describes the votes on bills in the 111th session of the United States Senate. (The data set was obtained from [\n\nhttps://​voteview​.com].) Each row is one senator, and each column is a vote item.\n\nfrom scipy.io import loadmat\nvars = loadmat(\"voting.mat\")\nA = vars[\"A\"]\nm, n = A.shape\nprint(\"size:\", (m, n))\n\nIf we visualize the votes (yellow is “yea,” blue is “nay”), we can see great similarity between many rows, reflecting party unity.\n\nimshow(A, cmap=\"viridis\")\nxlabel(\"bill\")\nylabel(\"senator\")\ntitle(\"Votes in 111th U.S. Senate\");\n\nWe use \n\n(7.5.4) to quantify the decay rate of the values.\n\nU, sigma, Vt = svd(A)\ntau = cumsum(sigma**2) / sum(sigma**2)\nplot(range(1, 17), tau[:16], \"o\")\nxlabel(\"$k$\")\nylabel(\"$\\tau_k$\")\ntitle(\"Fraction of singular value energy\");\n\nThe first and second singular triples contain about 58% and 17%, respectively, of the energy of the matrix. All others have far less effect, suggesting that the information is primarily two-dimensional. The first left and right singular vectors also contain interesting structure.\n\nsubplot(1, 2, 1)\nplot(U[:, 0], \"o\")\nxlabel(\"senator\"),title(\"left singular vector\")\nsubplot(1, 2, 2)\nplot(Vt[0, :], \"o\")\nxlabel(\"bill\"), title(\"right singular vector\");\n\nBoth vectors have values greatly clustered near \\pm C for a constant C. These can be roughly interpreted as how partisan a particular senator or bill was, and for which political party. Projecting the senators’ vectors into the first two \\mathbf{V}-coordinates gives a particularly nice way to reduce them to two dimensions. Political scientists label these dimensions partisanship and bipartisanship. Here we color them by actual party affiliation (also given in the data file): red for Republican, blue for Democrat, and yellow for independent.\n\nx1 = sigma[0] * U[:, 0]\nx2 = sigma[1] * U[:, 1]\n\nRep = vars[\"Rep\"] - 1\nDem = vars[\"Dem\"] - 1\nInd = vars[\"Ind\"] - 1\n\nscatter(x1[Dem], x2[Dem], color=\"blue\", label=\"D\")\nscatter(x1[Rep], x2[Rep], color=\"red\", label=\"R\")\nscatter(x1[Ind], x2[Ind], color=\"darkorange\", label=\"I\")\n\nxlabel(\"partisanship\"),  ylabel(\"bipartisanship\")\nlegend(),  title(\"111th US Senate in 2D\");","type":"content","url":"/chapter7-2#id-7-5","position":13},{"hierarchy":{"lvl1":"Chapter 8"},"type":"lvl1","url":"/chapter8-2","position":0},{"hierarchy":{"lvl1":"Chapter 8"},"content":"","type":"content","url":"/chapter8-2","position":1},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"type":"lvl2","url":"/chapter8-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Functions"},"content":"Power iteration\n\ndef poweriter(A, numiter):\n    \"\"\"\n    poweriter(A, numiter)\n\n    Perform numiter power iterations with the matrix A, starting from a random vector, \n    and return a vector of eigenvalue estimates and the final eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    for k in range(numiter):\n        y = A @ x\n        m = np.argmax(abs(y))\n        gamma[k] = y[m] / x[m]\n        x = y / y[m]\n\n    return gamma, x\n\nInverse iteration\n\ndef inviter(A, s, numiter):\n    \"\"\"\n    inviter(A, s, numiter)\n\n    Perform numiter inverse iterations with the matrix A and shift s, starting\n    from a random vector, and return a vector of eigenvalue estimates and the final\n    eigenvector approximation.\n    \"\"\"\n    n = A.shape[0]\n    x = np.random.randn(n)\n    x = x / np.linalg.norm(x, np.inf)\n    gamma = np.zeros(numiter)\n    PL, U = lu(A - s * np.eye(n), permute_l=True)\n    for k in range(numiter):\n        y = np.linalg.solve(U, np.linalg.solve(PL, x))\n        m = np.argmax(abs(y))\n        gamma[k] = x[m] / y[m] + s\n        x = y / y[m]\n\n    return gamma, x\n\nArnoldi iteration\n\ndef arnoldi(A, u, m):\n    \"\"\"\n    arnoldi(A, u, m)\n\n    Perform the Arnoldi iteration for A starting with vector u, out to the Krylov\n    subspace of degree m. Return the orthonormal basis (m+1 columns) and the upper\n    Hessenberg H of size m+1 by m.\n    \"\"\"\n    n = u.size\n    Q = np.zeros([n, m + 1])\n    H = np.zeros([m + 1, m])\n    Q[:, 0] = u / np.linalg.norm(u)\n    for j in range(m):\n        # Find the new direction that extends the Krylov subspace.\n        v = A @ Q[:, j]\n        # Remove the projections onto the previous vectors.\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        # Normalize and store the new basis vector.\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n    return Q, H\n\nGMRES\n\ndef gmres(A, b, m):\n    \"\"\"\n    gmres(A, b, m)\n\n    Do m iterations of GMRES for the linear system A*x=b. Return the final solution\n    estimate x and a vector with the history of residual norms. (This function is for\n    demo only, not practical use.)\n    \"\"\"\n    n = len(b)\n    Q = np.zeros([n, m + 1])\n    Q[:, 0] = b / np.linalg.norm(b)\n    H = np.zeros([m + 1, m])\n\n    # Initial \"solution\" is zero.\n    residual = np.hstack([np.linalg.norm(b), np.zeros(m)])\n\n    for j in range(m):\n        # Next step of Arnoldi iteration.\n        v = A @ Q[:, j]\n        for i in range(j + 1):\n            H[i, j] = Q[:, i] @ v\n            v -= H[i, j] * Q[:, i]\n        H[j + 1, j] = np.linalg.norm(v)\n        Q[:, j + 1] = v / H[j + 1, j]\n\n        # Solve the minimum residual problem.\n        r = np.hstack([np.linalg.norm(b), np.zeros(j + 1)])\n        z = np.linalg.lstsq(H[:j + 2, :j + 1], r)[0]\n        x = Q[:, :j + 1] @ z\n        residual[j + 1] = np.linalg.norm(A @ x - b)\n\n    return x, residual","type":"content","url":"/chapter8-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"type":"lvl2","url":"/chapter8-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 8","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter8-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-1","position":6},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.1 Sparsity and structure","lvl2":"Examples"},"content":"Example 8.1.1\n\nTip\n\nFunctions to work with sparse matrices are found in the scipy.sparse module.\n\nHere we load the adjacency matrix of a graph with 2790 nodes. Each node is a web page referring to Roswell, NM, and the edges represent links between web pages. (Credit goes to Panayiotis Tsaparas and the University of Toronto for making this data public.)\n\nimport scipy.sparse as sp\nfrom scipy.io import loadmat\n\nvars = loadmat(\"roswelladj.mat\")    # get from the book's website\nA = sp.csr_matrix(vars[\"A\"])\n\nWe may define the density of \\mathbf{A} as the number of nonzeros divided by the total number of entries.\n\nm, n = A.shape\nprint(f\"density is {A.nnz / (m * n):.3%}\")\n\nWe can compare the storage space needed for the sparse \\mathbf{A} with the space needed for its dense / full counterpart.\n\nF = A.todense()\nprint(f\"{A.data.nbytes/1e6:.3f} MB for sparse form, {F.nbytes/1e6:.3f} MB for dense form\")\n\nMatrix-vector products are also much faster using the sparse form because operations with structural zeros are skipped.\n\nfrom timeit import default_timer as timer\nx = random.randn(n)\nstart = timer()\nfor i in range(1000):\n    A @ x\nprint(f\"sparse time: {timer() - start:.4g} sec\")\n\nstart = timer()\nfor i in range(1000):\n    F @ x\nprint(f\"dense time: {timer() - start:.4g} sec\")\n\nExample 8.1.2\n\nHere is the adjacency matrix of a graph representing a small-world network, featuring connections to neighbors and a small number of distant contacts.\n\nimport networkx as nx\nwsg = nx.watts_strogatz_graph(200, 4, 0.02)\n\nBecause each node connects to relatively few others, the adjacency matrix is quite sparse.\n\nA = nx.adjacency_matrix(wsg)\nspy(A)\ntitle(\"Adjacency matrix $A$\");\n\nBy \n\nTheorem 7.1.1, the entries of \\mathbf{A}^k give the number of walks of length k between pairs of nodes, as with “k degrees of separation” within a social network. As k grows, the density of \\mathbf{A}^k also grows.\n\nTip\n\nWhile A**6 is valid syntax here, it means elementwise power, not matrix power.\n\nfrom scipy.sparse.linalg import matrix_power\nspy(matrix_power(A, 6))\ntitle((\"$A^6$\"));\n\nExample 8.1.3\n\nThe scipi.sparse.diags function creates a sparse matrix given its diagonal elements and the diagonal indexes to put them on. The main or central diagonal is numbered zero, above and to the right of that is positive, and below and to the left is negative.\n\nn = 50\ndata = [n * ones(n-3), ones(n), linspace(-1, 1-n, n-1)]\noffsets = [-3, 0, 1]    # 3rd below, main, 1st above\nA = sp.diags(data, offsets, format=\"lil\")\nprint(A[:7, :7].todense())\n\nWithout pivoting, the LU factors have the same lower and upper bandwidth as the original matrix.\n\nL, U = FNC.lufact(A.todense())\nsubplot(1, 2, 1), spy(L)\nsubplot(1, 2, 2), spy(U);\n\nHowever, if we introduce row pivoting, bandedness may be expanded or destroyed.\n\nL, U, p = FNC.plufact(A.todense())\nsubplot(1, 2, 1), spy(L[p, :])\nsubplot(1, 2, 2), spy(U)\n\nExample 8.1.4\n\nThe following generates a random sparse matrix with prescribed eigenvalues.\n\nn = 4000\ndensity = 4e-4\nev = 1 / arange(1, n + 1)\nA = FNC.sprandsym(n, density, eigvals=ev)\nprint(f\"density is {A.nnz / prod(A.shape):.3%}\")\n\nThe eigs function finds a small number eigenvalues meeting some criterion. First, we ask for the 5 of largest (complex) magnitude using which=\"LM\".\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=5, which=\"LM\")    # largest magnitude\nprint(1 / ev)\n\nNow we find the 4 closest to the value 1 in the complex plane, via sigma=1.\n\nfrom scipy.sparse.linalg import eigs\nev, V = eigs(A, k=4, sigma=0.03)    # closest to sigma\nprint(ev)\n\nThe time needed to solve a sparse linear system is not easy to predict unless you have some more information about the matrix. But it will typically be orders of magnitude faster than the dense version of the same problem.\n\nfrom scipy.sparse.linalg import spsolve\nx = 1 / arange(1, n + 1)\nb = A @ x\nstart = timer()\nxx = spsolve(A, b)\nprint(f\"sparse time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")\n\nfrom numpy.linalg import solve\nF = A.todense()\nstart = timer()\nxx = solve(F, b)\nprint(f\"dense time: {timer() - start:.3g} sec\")\nprint(f\"residual: {norm(b - A @ xx, 2):.1e}\")","type":"content","url":"/chapter8-2#id-8-1","position":7},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-2","position":8},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.2 Power iteration","lvl2":"Examples"},"content":"Example 8.2.1\n\nHere we choose a random 5×5 matrix and a random 5-vector.\n\nA = random.choice(range(10), (5, 5))\nA = A / sum(A, 0)\nx = random.randn(5)\nprint(x)\n\nApplying matrix-vector multiplication once doesn’t do anything recognizable.\n\ny = A @ x\nprint(y)\n\nRepeating the multiplication still doesn’t do anything obvious.\n\nz = A @ y\nprint(z)\n\nBut if we keep repeating the matrix-vector multiplication, something remarkable happens: \\mathbf{A} \\mathbf{x} \\approx \\mathbf{x}.\n\nx = random.randn(5)\nfor j in range(6):\n    x = A @ x\nprint(x)\nprint(A @ x)\n\nThis phenomenon is unlikely to be a coincidence!\n\nExample 8.2.2\n\nWe will experiment with the power iteration on a 5×5 matrix with prescribed eigenvalues and dominant eigenvalue at 1.\n\nev = [1, -0.75, 0.6, -0.4, 0]\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run the power iteration 60 times. The first output should be a sequence of estimates converging to the dominant eigenvalue—which, in this case, we set up to be 1.\n\nbeta, x = FNC.poweriter(A, 60)\nprint(beta)\n\nWe check for linear convergence using a log-linear plot of the error.\n\nerr = 1 - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1)\nxlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe asymptotic trend seems to be a straight line, consistent with linear convergence. To estimate the convergence rate, we look at the ratio of two consecutive errors in the linear part of the convergence curve. The ratio of the first two eigenvalues should match the observed rate.\n\nprint(f\"theory: {ev[1] / ev[0]:.5f}\")\nprint(f\"observed: {err[40] / err[39]:.5f}\")\n\nNote that the error is supposed to change sign on each iteration. The effect of these alternating signs is that estimates oscillate around the exact value.\n\nprint(beta[26:30])\n\nIn practical situations, we don’t know the exact eigenvalue that the algorithm is supposed to find. In that case we would base errors on the final β that was found, as in the following plot.\n\nerr = beta[-1] - beta\nsemilogy(arange(60), abs(err), \"-o\")\nylim(1e-10, 1), xlabel(\"$k$\")\nylabel(\"$|\\\\lambda_1 - \\\\beta_k|$\")\ntitle(\"Convergence of power iteration\");\n\nThe results are very similar until the last few iterations, when the limited accuracy of the reference value begins to show. That is, while it is a good estimate of \\lambda_1, it is less good as an estimate of the error in nearby estimates.","type":"content","url":"/chapter8-2#id-8-2","position":9},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-3","position":10},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.3 Inverse iteration","lvl2":"Examples"},"content":"Example 8.3.1\n\nWe set up a 5\\times 5 triangular matrix with prescribed eigenvalues on its diagonal.\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe run inverse iteration with the shift s=0.7. Convergence should be to the eigenvalue closest to the shift, which we know to be 0.6 here.\n\nbeta, x = FNC.inviter(A, 0.7, 30)\nprint(beta)\n\nAs expected, the eigenvalue that was found is the one closest to 0.7. The convergence is again linear.\n\nerr = beta[-1] - beta    # last estimate is our best\nsemilogy(arange(30), abs(err), \"-o\")\nylim(1e-16, 1)\nxlabel(\"$k$\"),  ylabel(\"$|\\\\lambda_3 - \\\\beta_k|$\")\ntitle((\"Convergence of inverse iteration\"));\n\nLet’s reorder the eigenvalues to enforce \n\n(8.3.3).\n\nTip\n\nThe argsort function returns the index permutation needed to sort the given vector, rather than the sorted vector itself.\n\nev = ev[argsort(abs(ev - 0.7))]\nprint(ev)\n\nNow it is easy to compare the theoretical and observed linear convergence rates.\n\nprint(f\"theory: {(ev[0] - 0.7) / (ev[1] - 0.7):.5f}\")\nprint(f\"observed: {err[21] / err[20]:.5f}\")\n\nExample 8.3.2\n\nev = array([1, -0.75, 0.6, -0.4, 0])\nA = triu(ones([5, 5]), 1) + diag(ev)    # triangular matrix, eigs on diagonal\n\nWe begin with a shift s=0.7, which is closest to the eigenvalue 0.6.\n\nfrom numpy.linalg import solve\ns = 0.7\nx = ones(5)\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nNote that the result is not yet any closer to the targeted 0.6. But we proceed (without being too picky about normalization here).\n\ns = beta\nx = y / y[0]\ny = solve(A - s * eye(5), x)\nbeta = x[0] / y[0] + s\nprint(f\"latest estimate: {beta:.8f}\")\n\nStill not much apparent progress. However, in just a few more iterations the results are dramatically better.\n\nfor k in range(4):\n    s = beta\n    x = y / y[0]\n    y = solve(A - s * eye(5), x)\n    beta = x[0] / y[0] + s\n    print(f\"latest estimate: {beta:.12f}\")","type":"content","url":"/chapter8-2#id-8-3","position":11},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-4","position":12},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.4 Krylov subspaces","lvl2":"Examples"},"content":"Example 8.4.1\n\nFirst we define a triangular matrix with known eigenvalues, and a random vector b.\n\nev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100)\n\nNext we build up the first ten Krylov matrices iteratively, using renormalization after each matrix-vector multiplication.\n\nKm = zeros([100, 30])\nKm[:, 0] = b\nfor m in range(29):\n    v = A @ Km[:, m]\n    Km[:, m + 1] = v / norm(v)\n\nNow we solve least-squares problems for Krylov matrices of increasing dimension, recording the residual in each case.\n\nfrom numpy.linalg import lstsq\nresid = zeros(30)\nresid[0] = norm(b)\nfor m in range(1, 30):\n    z = lstsq(A @ Km[:, :m], b, rcond=None)[0]\n    x = Km[:, :m] @ z\n    resid[m] = norm(b - A @ x)\n\nThe linear system approximations show smooth linear convergence at first, but the convergence stagnates after only a few digits have been found.\n\nsemilogy(range(30), resid, \"-o\")\nxlabel(\"$m$\"),  ylabel(\"$\\\\| b-Ax_m \\\\|$\")\ntitle((\"Residual for linear systems\"));\n\nExample 8.4.2\n\nHere again is the linear system from \n\nExample 8.4.1.\n\nev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100);\n\nWe can use \\mathbf{b} as the seed vector for the Arnoldi iteration.\n\nQ, H = FNC.arnoldi(A, b, 30)\nprint(\"Q has size\", Q.shape)\nprint(\"H has size\", H.shape)\n\nHere’s one validation of the key identity \n\n(8.4.10).\n\nfrom numpy.linalg import norm\nshould_be_near_zero = norm(A @ Q[:, :20] - Q[:, :21] @ H[:21, :20])\nprint(should_be_near_zero)\n\nUsing the Krylov matrix to project the linear system into a Kyrlov subspace in \n\nExample 8.4.1 was unable to get the residual much smaller than about \n\n10-4. But the Arnoldi basis gives us a stable way to work in that subspace and get better results.\n\nz, _, _, _ = linalg.lstsq(A @ Q, b)\nx = Q @ z\nresid_norm = norm(b - A @ x)\nprint(f\"residual norm: {resid_norm:.2e}\")","type":"content","url":"/chapter8-2#id-8-4","position":13},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-5","position":14},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.5 GMRES","lvl2":"Examples"},"content":"Example 8.5.1\n\nWe define a triangular matrix with known eigenvalues and a random vector \\mathbf{b}.\n\nev = 10 + arange(1, 101)\nA = triu(random.rand(100, 100), 1) + diag(ev)\nb = random.rand(100)\n\nInstead of building the Krylov matrices, we use the Arnoldi iteration to generate equivalent orthonormal vectors.\n\nQ, H = FNC.arnoldi(A, b, 60)\nprint(H[:5, :5])\n\nThe Arnoldi bases are used to solve the least-squares problems defining the GMRES iterates.\n\nfrom numpy.linalg import lstsq\nresid = zeros(61)\nresid[0] = norm(b)\nfor m in range(1, 61):\n    s = hstack([norm(b), zeros(m)])\n    z = lstsq(H[: m + 1, :m], s, rcond=None)[0]\n    x = Q[:, :m] @ z\n    resid[m] = norm(b - A @ x)\n\nThe approximations converge smoothly, practically all the way to machine epsilon.\n\nsemilogy(range(61), resid, \"-o\")\nxlabel(\"$m$\"),  ylabel(\"$\\| b-Ax_m \\|$\")\ntitle(\"Residual for GMRES\");\n\nExample 8.5.2\n\nThe following experiments are based on a matrix resulting from discretization of a partial differential equation.\n\nd = 50;  n = d**2\nA = FNC.poisson2d(d)\nb = ones(n)\nspy(A);\n\nWe compare unrestarted GMRES with three different thresholds for restarting. Here we are using gmres from scipy.sparse.linalg, since our simple implementation does not offer restarting. We’re also using a trick to accumulate the vector of residual norms as it runs.\n\nfrom scipy.sparse.linalg import gmres\nctr = lambda rvec: resid.append(norm(rvec))\nresid = [1.]\nx, flag = gmres(A, b, restart=None, rtol=1e-8, atol=1e-14, maxiter=120, callback=ctr)\nsemilogy(resid); \nxlabel(\"$m$\"), ylabel(\"residual norm\")\ntitle((\"Convergence of unrestarted GMRES\"));\n\nmaxit = 120\nrtol = 1e-8\nrestarts = [maxit, 20, 40, 60]\nhist = lambda rvec: resid.append(norm(rvec))\nfor r in restarts:\n    resid = [1.]\n    x, flag = gmres(A, b, restart=r, rtol=rtol, atol=1e-14, maxiter=maxit, callback=hist)\n    semilogy(resid)\n\nylim(1e-8, 2)\nlegend([\"none\", \"20\", \"40\", \"60\"])\ntitle((\"Convergence of restarted GMRES\"));\n\nThe “pure” GMRES curve is the lowest one. All of the other curves agree with it until the first restart. Decreasing the restart value makes the convergence per iteration generally worse, but the time required per iteration smaller as well.","type":"content","url":"/chapter8-2#id-8-5","position":15},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-6","position":16},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.6 MINRES and conjugate gradients","lvl2":"Examples"},"content":"Example 8.6.2\n\nThe following matrix is indefinite.\n\nfrom numpy.linalg import eig\nimport scipy.sparse as sp\nA = FNC.poisson2d(10) - 20*sp.eye(100)\nev, _ = eig(A.todense())\nnum_negative_ev = sum(ev < 0)\nprint(f\"There are {sum(ev < 0)} negative and {sum(ev > 0)} positive eigenvalues\")\n\nWe can compute the relevant quantities from \n\nTheorem 8.6.1.\n\nm, M = min(-ev[ev < 0]), max(-ev[ev < 0])\nkappa_minus = M / m\nm, M = min(ev[ev > 0]), max(ev[ev > 0])\nkappa_plus = M / m\nS = sqrt(kappa_plus * kappa_minus)\nrho = sqrt((S - 1) / (S + 1))\nprint(f\"Condition numbers: {kappa_minus:.2e}, {kappa_plus:.2e}\")\nprint(f\"Convergence rate: {rho:.3f}\")\n\nBecause the iteration number m is halved in \n\n(8.6.4), the rate constant of linear convergence is the square root of this number, which makes it even closer to 1.\n\nNow we apply MINRES to a linear system with this matrix, and compare the observed convergence to the upper bound from the theorem.\n\nfrom scipy.sparse.linalg import minres\nb = random.rand(100)\nresid = [norm(b)]\nhist = lambda x: resid.append(norm(b - A @ x))\nx, flag = minres(A, b, rtol=1e-8, maxiter=1000, callback=hist)\n\nsemilogy(resid, \".-\");\nupper = norm(b) * rho**arange(len(resid))\nsemilogy(upper, \"k--\")\nxlabel(\"$m$\"),  ylabel(\"residual norm\")\nlegend([\"MINRES\", \"upper bound\"], loc=\"lower left\")\ntitle(\"Convergence of MINRES\");\n\nThe upper bound turns out to be pessimistic here, especially in the later iterations. However, you can see a slow linear phase in the convergence that tracks the bound closely.\n\nExample 8.6.3\n\nWe will compare MINRES and CG on some quasi-random SPD problems.  The first matrix has a condition number of 100.\n\nn = 5000\ndensity = 0.001\nA = FNC.sprandsym(n, density, rcond=1e-2)\nx = arange(1, n+1) / n\nb = A @ x\n\nNow we apply both methods and compare the convergence of the system residuals, using implementations imported from scipy.sparse.linalg.\n\nfrom scipy.sparse.linalg import cg, minres\nhist = lambda x: resid.append(norm(b - A @ x))\n\nresid = [norm(b)]\nxMR, flag = minres(A, b, rtol=1e-12, maxiter=100, callback=hist)\nsemilogy(resid / norm(b), label=\"MINRES\")\n\nresid = [norm(b)]\nxCG, flag = cg(A, b, rtol=1e-12, maxiter=100, callback=hist)\nsemilogy(resid / norm(b), label=\"CG\")\n\nxlabel(\"Krylov dimension $m$\"), ylabel(\"$\\\\|r_m\\\\| / \\\\|b\\\\|$\")\ngrid(),  legend(),  title(\"Convergence of MINRES and CG\");\n\nThere is little difference between the two methods here. Both achieve relative residual of \n\n10-6 in aout 60 iterations, for example. The final errors are similar, too.\n\nprint(f\"MINRES error: {norm(xMR - x) / norm(x):.2e}\")\nprint(f\"CG error: {norm(xCG - x) / norm(x):.2e}\")\n\nNext, we increase the condition number of the matrix by a factor of 25. The rule of thumb predicts that the number of iterations required should increase by a factor of about 5; i.e., 300 iterations to reach \n\n10-6.\n\nA = FNC.sprandsym(n, density, rcond=1e-2 / 25)\nx = arange(1, n+1) / n\nb = A @ x\n\nfrom scipy.sparse.linalg import cg, minres\nhist = lambda x: resid.append(norm(b - A @ x))\n\nresid = [norm(b)]\nxMR, flag = minres(A, b, rtol=1e-12, maxiter=400, callback=hist)\nsemilogy(resid / norm(b), label=\"MINRES\")\n\nresid = [norm(b)]\nxCG, flag = cg(A, b, rtol=1e-12, maxiter=400, callback=hist)\nsemilogy(resid / norm(b), label=\"CG\")\n\nxlabel(\"Krylov dimension $m$\"), ylabel(\"$\\\\|r_m\\\\| / \\\\|b\\\\|$\")\ngrid(),  legend(),  title(\"Convergence of MINRES and CG\")\n\nprint(f\"MINRES error: {norm(xMR - x) / norm(x):.2e}\")\nprint(f\"CG error: {norm(xCG - x) / norm(x):.2e}\")\n\nBoth methods have an early superlinear phase that allow them to finish slightly sooner than the factor of 5 predicted: \n\nTheorem 8.6.2 is an upper bound, not necessarily an approximation.","type":"content","url":"/chapter8-2#id-8-6","position":17},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-7","position":18},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.7 Matrix-free iterations","lvl2":"Examples"},"content":"Example 8.7.1\n\nWe use a readily available test image.\n\nfrom skimage import data as testimages\nfrom skimage.color import rgb2gray\nimg = getattr(testimages, \"coffee\")()\nX = rgb2gray(img)\nimshow(X, cmap=\"gray\");\n\nWe define the one-dimensional tridiagonal blurring matrices.\n\nimport scipy.sparse as sp\ndef blurmatrix(d):\n    data = [[0.25] * (d-1), [0.5] * d, [0.25] * (d-1)]\n    return sp.diags(data, [-1, 0, 1], shape=(d, d))\n\nm, n = X.shape\nB = blurmatrix(m)\nC = blurmatrix(n)\n\nFinally, we show the results of using k=12 repetitions of the blur in each direction.\n\nfrom scipy.sparse.linalg import matrix_power\nblur = lambda X: matrix_power(B, 12) @ X @ matrix_power(C, 12)\n\nimshow(blur(X), cmap=\"gray\")\ntitle(\"Blurred image\");\n\nExample 8.7.2\n\nWe repeat the earlier process to blur an original image \\mathbf{X} to get \\mathbf{Z}.\n\nimg = getattr(testimages, \"coffee\")()\nX = rgb2gray(img)\nm, n = X.shape\n\nimport scipy.sparse as sp\ndef blurmatrix(d):\n    data = [[0.25] * (d-1), [0.5] * d, [0.25] * (d-1)]\n    return sp.diags(data, [-1, 0, 1], shape=(d, d))\nB = blurmatrix(m)\nC = blurmatrix(n)\n\nfrom scipy.sparse.linalg import matrix_power\nblur = lambda X: matrix_power(B, 12) @ X @ matrix_power(C, 12)\n\nZ = blur(X)\nimshow(Z, cmap=\"gray\")\ntitle(\"Blurred image\");\n\nNow we imagine that \\mathbf{X} is unknown and that we want to recover it from \\mathbf{Z}. We first need functions that translate between vector and matrix representations.\n\nfrom scipy.sparse.linalg import LinearOperator\nvec = lambda Z: Z.reshape(m * n)\nunvec = lambda z: z.reshape(m, n)\nxform = lambda x: vec(blur(unvec(x)))\n\nNow we declare the three-step blur transformation as a LinearOperator, supplying also the size of the vector form of an image.\n\nT = LinearOperator((m * n, m * n), matvec=xform)\n\nThe blurring operators are symmetric, so we apply minres to the composite blurring transformation T.\n\nfrom scipy.sparse.linalg import gmres\ny, flag = gmres(T, vec(Z), rtol=1e-5, maxiter=50)\nY = unvec(maximum(0, minimum(1, y)))\n\n\nsubplot(1, 2, 1),  imshow(X, cmap=\"gray\")\naxis(\"off\"),  title(\"Original\")\nsubplot(1, 2, 2),  imshow(Y, cmap=\"gray\")\naxis(\"off\"),  title(\"Deblurred\");","type":"content","url":"/chapter8-2#id-8-7","position":19},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"type":"lvl3","url":"/chapter8-2#id-8-8","position":20},{"hierarchy":{"lvl1":"Chapter 8","lvl3":"8.8 Preconditioning","lvl2":"Examples"},"content":"Example 8.8.1\n\nHere is an SPD matrix that arises from solving partial differential equations.\n\nfrom scipy.sparse import sparray\nimport rogues\nA = rogues.wathen(60, 60)\nn = A.shape[0]\nprint(f\"Matrix is {n} x {n} with {A.nnz} nonzeros\")\n\nThere is an easy way to use the diagonal elements of \\mathbf{A}, or any other vector, as a diagonal preconditioner.\n\nimport scipy.sparse as sp\nprec = sp.diags(1 / A.diagonal(), 0)\n\nWe now compare CG with and without the preconditioner.\n\nfrom scipy.sparse.linalg import cg\nb = ones(n)\nhist = lambda x: resid.append(norm(b - A @ x))\nresid = [norm(b)]\nstart = timer()\nx, _ = cg(A, b, rtol=1e-4, maxiter=200, callback=hist)\nprint(f\"No preconditioner: Finished in {timer() - start:.2f} sec\")\nresid_plain = resid.copy()\nresid = [norm(b)]\nstart = timer()\nx, _ = cg(A, b, rtol=1e-4, maxiter=200, M=prec, callback=hist)\nprint(f\"Diagonal preconditioner: Finished in {timer() - start:.2f} sec\")\nresid_prec = resid.copy()\n\nsemilogy(resid_plain, label=\"no preconditioner\")\nsemilogy(resid_prec, label=\"diagonal preconditioner\")\nxlabel(\"iteration\"), ylabel(\"residual norm\")\nlegend(),  title(\"Convergence of CG with and without preconditioning\");\n\nThe diagonal preconditioner cut down substantially on the number of iterations and the execution time.\n\nExample 8.8.2\n\nHere is a random nonsymmetric matrix.\n\nimport scipy.sparse as sp\nn = 8000\nA = 2.8 * sp.eye(n) + sp.rand(n, n, 0.002)\n\nWithout a preconditioner, GMRES can solve a system with this matrix.\n\nfrom scipy.sparse.linalg import gmres\n\nb = random.rand(n)\nhist = lambda rvec: resid.append(norm(rvec))\nresid = [1.]\n\nstart = timer()\nx, flag = gmres(A, b, maxiter=300, rtol=1e-10, restart=50, callback=hist)\nprint(f\"time for plain GMRES: {timer() - start:.3f} sec\")\nresid_plain = resid.copy()\n\nThe following version of incomplete LU factorization drops all sufficiently small values (i.e., replaces them with zeros). This keeps the number of nonzeros in the factors under control.\n\nfrom scipy.sparse.linalg import spilu\niLU = spilu(A, drop_tol=0.2)\nprint(f\"Factors have {iLU.nnz} nonzeros, while A has {A.nnz}\")\n\nThe result is not a true factorization of the original matrix. However, it’s close enough for an approximate inverse in a preconditioner.\n\nfrom scipy.sparse.linalg import LinearOperator\nprec = LinearOperator((n, n), matvec=lambda y: iLU.solve(y))\n\nresid = [1.];  start = timer()\nx, flag = gmres(A, b, M=prec, maxiter=300, rtol=1e-10, restart=50, callback=hist)\nprint(f\"time for preconditioned GMRES: {timer() - start:.3f} sec\")\nresid_prec = resid\n\nsemilogy(resid_plain, label=\"no prec.\")\nsemilogy(resid_prec, label=\"iLU prec.\")\nxlabel(\"iteration number\"),  ylabel(\"residual norm\")\nlegend()\ntitle(\"GMRES convergence compared\");","type":"content","url":"/chapter8-2#id-8-8","position":21},{"hierarchy":{"lvl1":"Chapter 9"},"type":"lvl1","url":"/chapter9-2","position":0},{"hierarchy":{"lvl1":"Chapter 9"},"content":"","type":"content","url":"/chapter9-2","position":1},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Functions"},"type":"lvl2","url":"/chapter9-2#functions","position":2},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Functions"},"content":"Barycentric polynomial interpolation\n\ndef polyinterp(t, y):\n    \"\"\"\n    polyinterp(t, y)\n\n    Return a callable polynomial interpolant through the points in vectors t, y. Uses\n    the barycentric interpolation formula.\n    \"\"\"\n    n = len(t) - 1\n    C = (t[-1] - t[0]) / 4  # scaling factor to ensure stability\n    tc = t / C\n\n    # Adding one node at a time, compute inverses of the weights.\n    omega = np.ones(n + 1)\n    for m in range(n):\n        d = tc[: m + 1] - tc[m + 1]  # vector of node differences\n        omega[: m + 1] = omega[: m + 1] * d  # update previous\n        omega[m + 1] = np.prod(-d)  # compute the new one\n    w = 1 / omega  # go from inverses to weights\n\n    def p(x):\n        # Compute interpolant.\n        z = np.where(x == t)[0]\n        if len(z) > 0:  # avoid dividing by zero\n            # Apply L'Hopital's Rule exactly.\n            f = y[z[0]]\n        else:\n            terms = w / (x - t)\n            f = np.sum(y * terms) / np.sum(terms)\n        return f\n\n    return np.vectorize(p)\n\nAbout the code\n\nAs noted in \n\nExample 9.2.1, a common scaling factor in the weights does not affect the barycentric formula \n\n(9.2.3). In lines 9--10 this fact is used to rescale the nodes in order to avoid eventual tiny or enormous numbers that could go outside the bounds of double precision.\n\nThe return value is a function that evaluates the polynomial interpolant. Within this function, isinf is used to detect either Inf or -Inf, which occurs when x exactly equals one of the nodes. In this event, the corresponding data value is returned.\n\nTrigonometric interpolation\n\ndef triginterp(t, y):\n    \"\"\"\n        triginterp(t, y)\n\n    Return trigonometric interpolant for points defined by vectors t and y.\n    \"\"\"\n    N = len(t)\n\n    def trigcardinal(x):\n        if x == 0:\n            tau = 1.0\n        elif np.mod(N, 2) == 1:  # odd\n            tau = np.sin(N * np.pi * x / 2) / (N * np.sin(np.pi * x / 2))\n        else:  # even\n            tau = np.sin(N * np.pi * x / 2) / (N * np.tan(np.pi * x / 2))\n        return tau\n\n    def p(x):\n        return np.sum([y[k] * trigcardinal(x - t[k]) for k in range(N)])\n\n    return np.vectorize(p)\n\nAbout the code\n\nThe construct on line 13 is known as a ternary operator. It is a shorthand for an if–else statement, giving two alternative results for the true/false cases. Line 19 uses eachindex(y), which generalizes 1:length(y) to cases where a vector might have a more exotic form of indexing.\n\nClenshaw–Curtis integration\n\ndef ccint(f, n):\n    \"\"\"\n    ccint(f, n)\n\n    Perform Clenshaw-Curtis integration for the function f on n+1 nodes in [-1,1]. Return\n    integral and a vector of the nodes used. Note: n must be even.\n    \"\"\"\n    # Find Chebyshev extreme nodes.\n    theta = np.linspace(0, np.pi, n + 1)\n    x = -np.cos(theta)\n\n    # Compute the C-C weights.\n    c = np.zeros(n + 1)\n    c[[0, n]] = 1 / (n**2 - 1)\n    v = np.ones(n - 1)\n    for k in range(1, int(n / 2)):\n        v -= 2 * np.cos(2 * k * theta[1:-1]) / (4 * k**2 - 1)\n    v -= np.cos(n * theta[1:-1]) / (n**2 - 1)\n    c[1:-1] = 2 * v / n\n\n    # Evaluate integrand and integral.\n    I = np.dot(c, f(x))  # use vector inner product\n    return I, x\n\nGauss–Legendre integration\n\ndef glint(f, n):\n    \"\"\"\n    glint(f, n)\n\n    Perform Gauss-Legendre integration for the function f on n nodes in (-1,1). Return\n    integral and a vector of the nodes used.\n    \"\"\"\n    # Nodes and weights are found via a tridiagonal eigenvalue problem.\n    beta = 0.5 / np.sqrt(1 - (2.0 * np.arange(1, n)) ** (-2))\n    T = np.diag(beta, 1) + np.diag(beta, -1)\n    ev, V = eig(T)\n    ev = np.real_if_close(ev)\n    p = np.argsort(ev)\n    x = ev[p]  # nodes\n    c = 2 * V[0, p] ** 2  # weights\n\n    # Evaluate the integrand and compute the integral.\n    I = np.dot(c, f(x))  # vector inner product\n    return I, x\n\nIntegration over (-\\infty,\\infty)\n\ndef intinf(f, tol):\n    \"\"\"\n    intinf(f, tol)\n\n    Perform doubly-exponential integration of function f over (-Inf,Inf), using\n    error tolerance tol. Return integral and a vector of the nodes used.\n    \"\"\"\n    xi = lambda t: np.sinh(np.sinh(t))\n    dxi_dt = lambda t: np.cosh(t) * np.cosh(np.sinh(t))\n    g = lambda t: f(xi(t)) * dxi_dt(t)\n    M = 3\n    while (abs(g(-M)) > tol/100) or (abs(g(M)) > tol/100):\n        M += 0.5\n        if np.isinf(xi(M)):\n            warnings.warn(\"Function may not decay fast enough.\")\n            M -= 0.5\n            break\n\n    I, t = intadapt(g,-M,M,tol)\n    x = xi(t)\n    return I, x\n\nAbout the code\n\nThe test isinf(x(M)) in line 17 checks whether x(M) is larger than the maximum double-precision value, causing it to overflow to Inf.\n\nIntegration with endpoint singularities\n\ndef intsing(f, tol):\n    \"\"\"\n    intsing(f, tol)\n\n    Adaptively integrate function f over (0,1), where f may be \n    singular at zero, with error tolerance tol. Returns the\n    integral estimate and a vector of the nodes used.\n    \"\"\"\n    xi = lambda t: 2 / (1 + np.exp( 2*np.sinh(t) ))\n    dxi_dt = lambda t: np.cosh(t) / np.cosh(np.sinh(t))**2\n    g = lambda t: f(xi(t)) * dxi_dt(t)\n    # Find where to truncate the integration interval.\n    M = 3\n    while abs(g(M)) > tol/100:\n        M += 0.5\n        if xi(M) == 0:\n            warnings.warn(\"Function may grow too rapidly.\")\n            M -= 0.5\n            break\n\n    I, t = intadapt(g, 0, M, tol)\n    x = xi(t)\n    return I, x\n\nAbout the code\n\nThe test iszero(x(M)) in line 17 checks whether x(M) is less than the smallest positive double-precision value, causing it to underflow to zero.","type":"content","url":"/chapter9-2#functions","position":3},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Examples"},"type":"lvl2","url":"/chapter9-2#examples","position":4},{"hierarchy":{"lvl1":"Chapter 9","lvl2":"Examples"},"content":"\n\nexec(open(\"FNC_init.py\").read())\n\n","type":"content","url":"/chapter9-2#examples","position":5},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.1 Polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-1","position":6},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.1 Polynomial interpolation","lvl2":"Examples"},"content":"Example 9.1.1\n\nHere is a vector of nodes.\n\nt = array([1, 1.5, 2, 2.25, 2.75, 3])\nn = 5\n\nLet’s apply the definition of the cardinal Lagrange polynomial for k=2. First we define a polynomial q that is zero at all the nodes except i=k. Then \\ell_2 is found by normalizing q by q(t_k).\n\nk = 2\nq = lambda x: prod([x - t[i] for i in range(n + 1) if i != k])\nell_k = lambda x: q(x) / q(t[k])\n\nA plot confirms the cardinal property of the result.\n\nx = linspace(1, 3, 500)\nplot(x, [ell_k(xx) for xx in x])\ny = zeros(n+1)\ny[k] = 1\nplot(t, y, \"ko\")\nxlabel(\"$x$\"),  ylabel(\"$\\\\ell_2(x)$\")\ntitle((\"Lagrange cardinal function\"));\n\nObserve that \\ell_k is not between zero and one everywhere, unlike a hat function.\n\nExample 9.1.3\n\nfrom scipy.interpolate import BarycentricInterpolator as interp\nt = array([1, 1.6, 1.9, 2.7, 3])\np = interp(t, log(t))\n\nfrom scipy.interpolate import BarycentricInterpolator as interp\nt = array([1, 1.6, 1.9, 2.7, 3])\np = interp(t, log(t))\nx = linspace(1, 3, 500)\nPhi = lambda x: prod([x - ti for ti in t])\nplot(x, [Phi(xj) / 5 for xj in x], label=\"$\\\\frac{1}{5}|\\\\Phi(x)|$\")\nplot(x, abs(log(x) - p(x)), label=\"$|f(x)-p(x)|$\")\nplot(t, zeros(t.size), \"ko\", label=\"nodes\")\nxlabel(\"$x$\"),  ylabel(\"error\")\ntitle(\"Interpolation error and upper bound\"),  legend();\n\nThe error is zero at the nodes, by the definition of interpolation. The error bound, as well as the error itself, has one local maximum between each consecutive pair of nodes.","type":"content","url":"/chapter9-2#id-9-1","position":7},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.2 The barycentric formula","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-2","position":8},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.2 The barycentric formula","lvl2":"Examples"},"content":"Example 9.2.2\n\nf = lambda x: sin(exp(2 * x))\nx = linspace(0, 1, 500)\nfig, ax = subplots()\nax.plot(x, f(x), label=\"function\")\n\nt = linspace(0, 1, 4)\ny = f(t)\np = FNC.polyinterp(t, y)\n\nax.plot(x, p(x), label=\"interpolant\")\nax.plot(t, y, \"ko\", label=\"nodes\")\nax.legend()\nax.set_title(\"Interpolation on 4 nodes\")\nfig\n\nThe curves must intersect at the interpolation nodes. For n=6 the interpolant is noticeably better.\n\nplot(x, f(x), label=\"function\")\nt = linspace(0, 1, 7)\ny = f(t)\np = FNC.polyinterp(t, y)\nplot(x, p(x), label=\"interpolant\")\nplot(t, y, \"ko\", label=\"nodes\")\nlegend(),  title(\"Interpolation on 7 nodes\");","type":"content","url":"/chapter9-2#id-9-2","position":9},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.3 Stability of polynomial interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-3","position":10},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.3 Stability of polynomial interpolation","lvl2":"Examples"},"content":"Example 9.3.1\n\nWe choose a function over the interval [0,1].\n\nf = lambda x: sin(exp(2 * x))\n\nHere is a graph of f and its polynomial interpolant using seven equally spaced nodes.\n\nx = linspace(0, 1, 500)\nplot(x, f(x), label=\"function\")\nt = linspace(0, 1, 7)\ny = f(t)\np = FNC.polyinterp(t, y)\nplot(x, p(x), label=\"interpolant\")\nplot(t, y, 'ko', label=\"nodes\")\nlegend(),  title(\"Equispaced interpolant, n=6\");\n\nThis looks pretty good. We want to track the behavior of the error as n increases. We will estimate the error in the continuous interpolant by sampling it at a large number of points and taking the max-norm.\n\nN = arange(5, 65, 5)\nerr = zeros(N.size)\nx = linspace(0, 1, 1001)         # for measuring error\nfor k, n in enumerate(N):\n    t = linspace(0, 1, n + 1)    # equally spaced nodes\n    y = f(t)  # interpolation data\n    p = FNC.polyinterp(t, y)\n    err[k] = max(abs(f(x) - p(x)))\n\nsemilogy(N, err, \"-o\")\nxlabel(\"$n$\"),  ylabel(\"max error\")\ntitle((\"Polynomial interpolation error\"));\n\nThe error initially decreases as one would expect but then begins to grow. Both phases occur at rates that are exponential in n, i.e., O(K^n) for a constant K, appearing linear on a semi-log plot.\n\nExample 9.3.2\n\nWe plot |\\Phi(x)| over the interval [-1,1] with equispaced nodes for different values of n.\n\nx = linspace(-1, 1, 1601)\nfor n in range(10, 60, 10):\n    t = linspace(-1, 1, n + 1)\n    Phi = array([prod(xk - t) for xk in x])\n    semilogy(x, abs(Phi), \".\", markersize=2)\nxlabel(\"$x$\")\nylabel(\"$|\\Phi(x)|$\")\nylim([1e-25, 1])\ntitle((\"Effect of equispaced nodes\"));\n\nEach time Φ passes through zero at an interpolation node, the value on the log scale should go to -\\infty, which explains the numerous cusps on the curves.\n\nExample 9.3.3\n\nThis function has infinitely many continuous derivatives on the entire real line and looks easy to approximate over [-1,1].\n\nf = lambda x: 1 / (x**2 + 16)\nx = linspace(-1, 1, 1601)\nplot(x, f(x))\ntitle(\"Test function\");\n\nWe start by doing equispaced polynomial interpolation for some small values of n.\n\nN = arange(4, 16, 4)\nlabel = []\nfor k, n in enumerate(N):\n    t = linspace(-1, 1, n + 1)  # equally spaced nodes\n    y = f(t)  # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = abs(f(x) - p(x))\n    semilogy(x, err, \".\", markersize=2)\n    label.append(f\"degree {n}\")\n\nxlabel(\"$x$\"),  ylabel(\"$|f(x)-p(x)|$\")\nylim([1e-20, 1])\nlegend(label),  title(\"Error for low degrees\");\n\nThe convergence so far appears rather good, though not uniformly so. However, notice what happens as we continue to increase the degree.\n\nN = 12 + 15 * arange(1, 4)\nlabels = []\nfor k, n in enumerate(N):\n    t = linspace(-1, 1, n + 1)  # equally spaced nodes\n    y = f(t)  # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = abs(f(x) - p(x))\n    semilogy(x, err, \".\", markersize=2)\n    labels.append(f\"degree {n}\")\nxlabel(\"$x$\"),  ylabel(\"$|f(x)-p(x)|$\"),  ylim([1e-20, 1])\nlegend(labels),  title(\"Error for higher degrees\");\n\nThe convergence in the middle can’t get any better than machine precision relative to the function values. So maintaining the growing gap between the center and the ends pushes the error curves upward exponentially fast at the ends, wrecking the convergence.\n\nExample 9.3.4\n\nNow we look at the error indicator function Φ for Chebyshev node sets.\n\nx = linspace(-1, 1, 1601)\nlabels = []\nfor n in range(10, 60, 10):\n    theta = pi * arange(n + 1) / n\n    t = -cos(theta)\n    Phi = array([prod(xk - t) for xk in x])\n    semilogy(x, abs(Phi), \".\")\n    labels.append(f\"degree {n}\")\n\nxlabel(\"$x$\"),  ylabel(\"$|\\\\Phi(x)|$\"),  ylim([1e-18, 1e-2])\nlegend(labels),  title(\"Error indicator for Chebyshev nodes\");\n\nIn contrast to the equispaced case, |\\Phi| decreases exponentially with n almost uniformly across the interval.\n\nExample 9.3.5\n\nHere again is the function from \n\nDemo 9.3.3 that provoked the Runge phenomenon when using equispaced nodes.\n\nf = lambda x: 1 / (x**2 + 16)\n\nx = linspace(-1, 1, 1601)\nlabels = []\nfor k, n in enumerate([4, 10, 16, 40]):\n    t = -cos(pi * arange(n + 1) / n)         # Chebyshev nodes\n    y = f(t)                                 # interpolation data\n    p = FNC.polyinterp(t, y)\n    err = abs(f(x) - p(x))\n    semilogy(x, err, \".\", markersize=2)\n    labels.append(f\"degree {n}\")\n\nxlabel(\"$x$\"),  ylabel(\"$|f(x)-p(x)|$\"),  ylim([1e-20, 1])\nlegend(labels),  title(\"Error for Chebyshev interpolants\");\n\nBy degree 16 the error is uniformly within machine epsilon, and, importantly, it stays there as n increases. Note that as predicted by the error indicator function, the error is uniform over the interval at each value of n.\n\nExample 9.3.6\n\nOn the left, we use a log-log scale, which makes second-order algebraic convergence O(n^{-4}) a straight line. On the right, we use a log-linear scale, which makes spectral convergence O(K^{-n}) linear.\n\nn = arange(20, 420, 20)\nalgebraic = 100 / n**4\nspectral = 10 * 0.85**n\n\nsubplot(2, 1, 1)\nloglog(n, algebraic, 'o-', label=\"algebraic\")\nloglog(n, spectral, 'o-', label=\"spectral\")\nxlabel('n'),  ylabel('error') \ntitle('log–log'), ylim([1e-16, 1]);\nlegend() \n\nsubplot(2, 1, 2)\nsemilogy(n, algebraic, 'o-', label=\"algebraic\")\nsemilogy(n, spectral, 'o-', label=\"spectral\")\nxlabel('n'),  ylabel('error')\ntitle('log–linear') ,  ylim([1e-16, 1]);  \nlegend();","type":"content","url":"/chapter9-2#id-9-3","position":11},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.4 Orthogonal polynomials","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-4","position":12},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.4 Orthogonal polynomials","lvl2":"Examples"},"content":"Example 9.4.1\n\nLet’s approximate e^x over the interval [−1,1]. We can sample it at, say, 15 points, and find the best-fitting straight line to that data.\n\nfrom numpy.linalg import lstsq\nt = linspace(-1, 1, 15)\ny = exp(t)\nplot(t, y, label=\"function\")\n\nV = [[ti**j for j in range(2)] for ti in t]\nc = lstsq(V, y, rcond=None)[0]\nprint(\"fit coeffs:\", c)\n\nx = linspace(-1, 1, 600)\nplot(x, c[1] + c[0] * x, label=\"fit\")\nxlabel(\"x\"),  ylabel(\"value\")\nlegend(),  title(\"Least squares fit of exp(x)\");\n\nThere’s nothing special about 15 points. Choosing more doesn’t change the result much.\n\nt = linspace(-1, 1, 150)\ny = exp(t)\nplot(t, y, label=\"function\")\n\nV = [[ti**j for j in range(2)] for ti in t]\nc = lstsq(V, y, rcond=None)[0]\nprint(\"fit coeffs:\", c)\n\nx = linspace(-1, 1, 600)\nplot(x, c[1] + c[0] * x, label=\"fit\")\nxlabel(\"x\"),  ylabel(\"value\")\nlegend(),  title(\"Least squares fit of exp(x)\");\n\nThis situation is unlike interpolation, where the degree of the interpolant increases with the number of nodes. Here, the linear fit is apparently approaching a limit that we may think of as a continuous least-squares fit.\n\nn = arange(40, 420, 60)\nresults = PrettyTable([\"n\", \"intercept\", \"slope\"])\nslope = zeros(n.size)\nintercept = zeros(n.size)\n\nfor k in range(n.size):\n    t = linspace(-1, 1, n[k])\n    y = exp(t)\n    V = [[ti**j for j in range(2)] for ti in t]\n    c = lstsq(V, y, rcond=None)[0]\n    results.add_row([n[k], c[1], c[0]])\n\nprint(results)","type":"content","url":"/chapter9-2#id-9-4","position":13},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.5 Trigonometric interpolation","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-5","position":14},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.5 Trigonometric interpolation","lvl2":"Examples"},"content":"Example 9.5.1\n\nWe will get a cardinal function without using an explicit formula, just by passing data that is 1 at one node and 0 at the others.\n\nTip\n\nThe operator ÷, typed as \\div then Tab, returns the quotient without remainder of two integers.\n\nN = 7\nn = int((N - 1) / 2)\nt = 2 * arange(-n, n + 1) / N\ny = zeros(N)\ny[n] = 1\n\np = FNC.triginterp(t, y)\nx = linspace(-1, 1, 600)\nplot(x, p(x))\nplot(t, y, \"ko\")\n\nxlabel(\"x\"),  ylabel(\"tau(x)\")\ntitle(\"Trig cardinal function\");\n\nHere is a 2-periodic function and one of its interpolants.\n\nf = lambda x: exp(sin(pi * x) - 2 * cos(pi * x))\n\nplot(x, f(x), label=\"periodic function\")\ny = f(t)\n\np = FNC.triginterp(t, y)\nplot(x, p(x), label=\"trig interpolant\")\nplot(t, y, \"ko\", label=\"nodes\")\n\nxlabel(\"$x$\"),  ylabel(\"$p(x)$\")\nlegend(),  title(\"Trig interpolation\");\n\nThe convergence of the interpolant is spectral. We let N go needlessly large here in order to demonstrate that unlike polynomials, trigonometric interpolation is stable on equally spaced nodes. Note that when N is even, the value of n is not an integer but works fine for defining the nodes.\n\nN = arange(2, 62, 2)\nerr = zeros(N.size)\n\nx = linspace(-1, 1, 1601)    # for measuring error\nfor k in range(N.size):\n    n = (N[k] - 1) / 2\n    t = 2 * arange(-n, n + 1) / N[k]\n    p = FNC.triginterp(t, f(t))\n    err[k] = max(abs(f(x) - p(x)))\n\nsemilogy(N, err, \"-o\")\nxlabel(\"N\"),  ylabel(\"max error\")\ntitle(\"Convergence of trig interpolation\");\n\nExample 9.5.2\n\nThis function has frequency content at 2\\pi, -2\\pi, and π.\n\nf = lambda x: 3 * cos(2 * pi * x) - exp(1j * pi * x)\n\nTo use fft, we set up nodes in the interval [0,2).\n\nn = 4\nN = 2 * n + 1\nt = 2 * arange(0, N) / N    # nodes in [0,2)\ny = f(t)\n\nWe perform Fourier analysis using fft and then examine the resulting coefficients.\n\nfrom scipy.fftpack import fft, ifft, fftshift\nc = fft(y) / N\nfreq = hstack([arange(n+1), arange(-n,0)])\nresults = PrettyTable()\nresults.add_column(\"freq\", freq) \nresults.add_column(\"coefficient\", c)\nresults\n\nNote that 1.5 e^{2i\\pi x}+1.5 e^{-2i\\pi x} = 3 \\cos(2\\pi x), so this result is sensible.\n\nFourier’s greatest contribution to mathematics was to point out that every periodic function is just a combination of frequencies—infinitely many of them in general, but truncated for computational use. Here we look at the magnitudes of the coefficients for f(x) = \\exp( \\sin(\\pi x) ).\n\nf = lambda x: exp(sin(pi * x))    # content at all frequencies\nn = 9;  N = 2*n + 1;\nt = 2 * arange(0, N) / N    # nodes in [0,2)\nc = fft(f(t)) / N\n\nsemilogy(range(-n, n+1), abs(fftshift(c)), \"o\")\nxlabel(\"$k$\"),  ylabel(\"$|c_k|$\")\ntitle(\"Fourier coefficients\");\n\nThe Fourier coefficients of smooth functions decay exponentially in magnitude as a function of the frequency. This decay rate is determines the convergence of the interpolation error.","type":"content","url":"/chapter9-2#id-9-5","position":15},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.6 Spectrally accurate integration","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-6","position":16},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.6 Spectrally accurate integration","lvl2":"Examples"},"content":"Example 9.6.1\n\nf = lambda t: pi * sqrt(cos(pi * t) ** 2 + sin(pi * t) ** 2 / 4)\nN = arange(4, 48, 6)\nperim = zeros(N.size)\nfor k in range(N.size):\n    h = 2 / N[k]\n    t = h * arange(N[k]) - 1\n    perim[k] = h * sum(f(t))\nerr = abs(perim - perim[-1])    # use the last value as reference\nresults = PrettyTable()\nresults.add_column(\"N\", N)\nresults.add_column(\"perimeter\", perim)\nresults.add_column(\"error\", err)\nresults\n\nThe approximations gain about one digit of accuracy for each constant increment of n, which is consistent with spectral convergence.\n\nExample 9.6.3\n\nFirst consider the integral\\int_{-1}^1 \\frac{1}{1+4x^2} \\, dx = \\arctan(2).\n\nf = lambda x: 1 / (1 + 4 * x**2)\nexact = arctan(2)\n\nWe compare the two spectral integration methods for a range of n values.\n\nN = range(8, 100, 4)\nerrCC = zeros(len(N))\nerrGL = zeros(len(N))\nfor k, n in enumerate(N):\n    errCC[k] = exact - FNC.ccint(f, n)[0]\n    errGL[k] = exact - FNC.glint(f, n)[0]\n\nsemilogy(N, abs(errCC), \"-o\", label=\"Clenshaw–Curtis\")\nsemilogy(N, abs(errGL), \"-o\", label=\"Gauss–Legendre\")\nxlabel(\"number of nodes\"),  ylabel(\"error\"),  ylim(1e-16, 0.01)\nlegend(),  title(\"Spectral integration\");\n\n(The missing dots are where the error is exactly zero.) Gauss–Legendre does converge faster here, but at something less than twice the rate.\n\nNow we try a more sharply peaked integrand:\\int_{-1}^1 \\frac{1}{1+16x^2} \\, dx = \\frac{1}{2}\\arctan(4).\n\nf = lambda x: 1 / (1 + 16 * x**2)\nexact = atan(4) / 2\n\nN = range(8, 100, 4)\nerrCC = zeros(len(N))\nerrGL = zeros(len(N))\nfor k, n in enumerate(N):\n    errCC[k] = exact - FNC.ccint(f, n)[0]\n    errGL[k] = exact - FNC.glint(f, n)[0]\n\nsemilogy(N, abs(errCC), \"-o\", label=\"Clenshaw–Curtis\")\nsemilogy(N, abs(errGL), \"-o\", label=\"Gauss–Legendre\")\nxlabel(\"number of nodes\"),  ylabel(\"error\"),  ylim(1e-16, 0.1)\nlegend(),  title(\"Spectral integration\");\n\nThe two are very close until about n=40, when the Clenshaw–Curtis method slows down.\n\nNow let’s compare the spectral performance to that of our earlier adaptive method in intadapt. We will specify varying error tolerances and record the error as well as the total number of evaluations of f.\n\nloglog(N, abs(errCC), \"-o\", label=\"ccint\")\nloglog(N, abs(errGL), \"-o\", label=\"glint\")\n\ntol_ = 1 / 10 ** arange(2, 15)\nn = zeros(tol_.size)\nerrAdapt = zeros(tol_.size)\nfor k, tol in enumerate(tol_):\n    Q, t = FNC.intadapt(f, -1, 1, tol)\n    errAdapt[k] = exact - Q\n    n[k] = t.size\n\nloglog(n, abs(errAdapt), \"-o\", label=\"intadapt\")\nloglog(n, 1 / (n**4), \"--\", label=\"4th order\")\nxlabel(\"number of nodes\"),  ylabel(\"error\"),  ylim(1e-16, 1)\nlegend(),  title(\"Spectral vs 4th order\");\n\nAt the core of intadapt is a fourth-order formula, and the results track that rate closely. For all but the most relaxed error tolerances, both spectral methods are far more efficient than the low-order counterpart. For other integrands, particularly those that vary nonuniformly across the interval, the adaptive method might be more competitive.","type":"content","url":"/chapter9-2#id-9-6","position":17},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.7 Improper integrals","lvl2":"Examples"},"type":"lvl3","url":"/chapter9-2#id-9-7","position":18},{"hierarchy":{"lvl1":"Chapter 9","lvl3":"9.7 Improper integrals","lvl2":"Examples"},"content":"Example 9.7.2\n\nf = lambda x: 1 / (1 + x**2)\nx = linspace(-4, 4, 500)\nsubplot(2, 1, 1)\nplot(x, f(x)),  yscale('log')\nxlabel('x'),  ylabel('f(x)'),  ylim([1e-16, 1])  \ntitle('Original integrand')   \n\nxi = lambda t: sinh( pi * sinh(t) / 2 )\ndxi_dt = lambda t: pi/2 * cosh(t) * cosh( pi * sinh(t) / 2 )\nintegrand = lambda t: f(xi(t)) * dxi_dt(t)\nsubplot(2, 1, 2)\nplot(x, integrand(x)),  yscale('log')\nxlabel('t'),  ylabel('f(x(t))'),  ylim([1e-16, 1])  \ntitle('Transformed integrand')\n\nThis graph suggests that we capture all of the integrand values that are larger than machine epsilon by integrating in t from -4 to 4.\n\nExample 9.7.3\n\nf = lambda x: 1 / (1 + x**2)\nexact = pi\ntol = array([1 / 10**d for d in arange(5, 14, 0.5)])\nerr = zeros((tol.size, 2))\nlength = zeros((tol.size, 2))\nfor k in range(tol.size):\n    I1, x1 = FNC.intadapt(f, -2/tol[k], 2/tol[k], tol[k])\n    I2, x2 = FNC.intinf(f, tol[k])\n    err[k] = abs(exact - array([I1, I2]))\n    length[k] = [x1.size, x2.size]\nloglog(length, err, \"-o\")\n# plot(len,err,m=:o,label=[\"direct\" \"double exponential\"])\nn = array([100, 10000])\nloglog(n, 1000 / n**4, 'k--')\nxlabel(\"number of nodes\"),  ylabel(\"error\")\ntitle(\"Comparison of integration methods\")\nlegend([\"direct\", \"double exponential\", \"4th-order\"], loc=\"lower left\");\n\nBoth methods are roughly fourth-order due to Simpson’s formula in the underlying adaptive integration method. At equal numbers of evaluation nodes, however, the double exponential method is consistently 2--3 orders of magnitude more accurate.\n\nExample 9.7.4\n\nf = lambda x: 1 / (10 * sqrt(x))\nexact = 0.2\ntol = array([1 / 10**d for d in arange(5, 14, 0.5)])\nerr = zeros((tol.size, 2))\nlength = zeros((tol.size, 2))\nfor k in range(tol.size):\n    I1, x1 = FNC.intadapt(f, (tol[k]/20)**2, 1, tol[k])\n    I2, x2 = FNC.intsing(f, tol[k])\n    err[k] = abs(exact - array([I1, I2]))\n    length[k] = [x1.size, x2.size]\nloglog(length, err, \"-o\")\n# plot(len,err,m=:o,label=[\"direct\" \"double exponential\"])\nn = array([100, 10000])\nloglog(n, 30 / n**4, 'k--')\nxlabel(\"number of nodes\"),  ylabel(\"error\")\ntitle(\"Comparison of integration methods\")\nlegend([\"direct\", \"double exponential\", \"4th-order\"], loc=\"lower left\");\n\nAs in \n\nDemo 9.7.3, the double exponential method is more accurate than direct integration by a few orders of magnitude. Equivalently, the same accuracy can be reached with many fewer nodes.","type":"content","url":"/chapter9-2#id-9-7","position":19},{"hierarchy":{"lvl1":"Python setup"},"type":"lvl1","url":"/setup-2","position":0},{"hierarchy":{"lvl1":"Python setup"},"content":"","type":"content","url":"/setup-2","position":1},{"hierarchy":{"lvl1":"Python setup","lvl2":"Setting up Python for this book"},"type":"lvl2","url":"/setup-2#section-setup-python","position":2},{"hierarchy":{"lvl1":"Python setup","lvl2":"Setting up Python for this book"},"content":"Python, and all the packages this book depends on, is free and open-source. Much of the functionality outside the core is distributed via packages that need to be installed once per system.","type":"content","url":"/setup-2#section-setup-python","position":3},{"hierarchy":{"lvl1":"Python setup","lvl3":"Installing Python","lvl2":"Setting up Python for this book"},"type":"lvl3","url":"/setup-2#installing-python","position":4},{"hierarchy":{"lvl1":"Python setup","lvl3":"Installing Python","lvl2":"Setting up Python for this book"},"content":"There are tons of ways and guides. \n\nAnaconda is a popular distribution that comes with many packages pre-installed. The free version is fine and, while it is overkill for this book, it is a solid choice for beginners. Command-line users are encouraged to consider \n\nMamba, which is a fast version of Anaconda. If you are a VS Code user, you can install Python from within the editor.","type":"content","url":"/setup-2#installing-python","position":5},{"hierarchy":{"lvl1":"Python setup","lvl3":"Installing the book’s functions","lvl2":"Setting up Python for this book"},"type":"lvl3","url":"/setup-2#installing-the-books-functions","position":6},{"hierarchy":{"lvl1":"Python setup","lvl3":"Installing the book’s functions","lvl2":"Setting up Python for this book"},"content":"The book relies on functions that are distributed as a \n\nPyPi package. You can install it by typing pip install fncbook at a command prompt, or by following instructions for your installation method.","type":"content","url":"/setup-2#installing-the-books-functions","position":7},{"hierarchy":{"lvl1":"Python setup","lvl3":"Using packages","lvl2":"Setting up Python for this book"},"type":"lvl3","url":"/setup-2#using-packages","position":8},{"hierarchy":{"lvl1":"Python setup","lvl3":"Using packages","lvl2":"Setting up Python for this book"},"content":"Python uses import to load packages. For all the demos in the book, its package is loaded viaimport fncbook as FNC\n\n(FNC is chosen to be uniform with the Julia versions of the codes. You can choose any name you like.) Then you access its functions like FNC.horner, etc. You can also type FNC. and then press Tab to see a list of available functions.","type":"content","url":"/setup-2#using-packages","position":9},{"hierarchy":{"lvl1":"Python setup","lvl3":"Packages used in the book","lvl2":"Setting up Python for this book"},"type":"lvl3","url":"/setup-2#packages-used-in-the-book","position":10},{"hierarchy":{"lvl1":"Python setup","lvl3":"Packages used in the book","lvl2":"Setting up Python for this book"},"content":"In order to avoid repeating low-information code, the book demos are run with a few packages installed and always imported:from numpy import *\nfrom matplotlib.pyplot import *\nfrom numpy.linalg import norm\nfrom prettytable import PrettyTable\nfrom timeit import default_timer as timer\n\nNote that a lot of sources discourage using import * because it can lead to so-called namespace pollution. But we rely so heavily on numpy and pyplot that it is convenient here.\n\nOther packages are loaded as needed. These include\n\nscipy\n\nscikit-image\n\nnetworkx\n\nrogues\n\nOnly scipy is essential. The others are used for a few applications and illustrations.","type":"content","url":"/setup-2#packages-used-in-the-book","position":11},{"hierarchy":{"lvl1":"Python setup","lvl3":"Coding environments","lvl2":"Setting up Python for this book"},"type":"lvl3","url":"/setup-2#coding-environments","position":12},{"hierarchy":{"lvl1":"Python setup","lvl3":"Coding environments","lvl2":"Setting up Python for this book"},"content":"You could interact with Python only by typing in at the prompt (also called the REPL) and then pasting the results into a word processor, but you can do much, much better. The most popular ways to use Julia are:\n\nJupyter lab. This is a notebook-based interface that mixes cells having text and code, including text and graphical output. This entire book is based on the notebook architecture. You write and run code within your web browser, but the files are local.\n\nVS Code. This is a full-featured code editor that can be extended with lots of \n\nPython-specific tools. It can also write and run Jupyter notebooks. This book (the version you are reading now, anyway) was written in VS Code.","type":"content","url":"/setup-2#coding-environments","position":13}]}